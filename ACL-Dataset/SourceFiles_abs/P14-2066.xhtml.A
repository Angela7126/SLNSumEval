<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <title>
   A Corpus of Sentence-level Revisions in Academic Writing: A Step towards Understanding Statement Strength in Communication.
  </title>
 </head>
 <body>
  <div class="ltx_page_main">
   <div class="ltx_page_content">
    <div class="ltx_document ltx_authors_1line">
     <div class="ltx_section" id="S1">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        1
       </span>
       Introduction
      </h2>
      <div class="ltx_para" id="S1.p1">
       <p class="ltx_p">
        It is important for
authors and speakers to find the appropriate “pitch” to
convey a desired message to the public.
Indeed,
sometimes heated debates can
arise around the choice of statement strength. For instance, on March 1,
2014,
an attack
at Kunming’s railway
station left 29 people dead and more than 140 others
injured.
        In the aftermath, Chinese media accused Western media of “soft-pedaling
the attack and failing to state clearly that it was an act of
        terrorism
        ”.
        In particular, regarding the statement by the US embassy that referred
to this incident as the “terrible and
senseless act of violence in Kunming”, a Weibo user posted
“If you say that the Kunming attack is a ‘terrible and senseless act
of violence’, then the 9/11 attack can be called a ‘regrettable
traffic
incident”’.
       </p>
      </div>
      <div class="ltx_para" id="S1.p2">
       <p class="ltx_p">
        This example is striking but not an isolated case, for
settings in which one party is trying to convince another are
pervasive;
scenarios range from court trials to conference
submissions.
Since the strength and scope of an
argument can be a crucial factor in its success,
it is
important to understand the effects of
statement strength in communication.
       </p>
      </div>
      <div class="ltx_para" id="S1.p3">
       <p class="ltx_p">
        A first step towards addressing this question is to be able to
distinguish between strong and weak statements.
As strength is inherently
relative, it is natural to look at
        revisions
        that change
statement strength, which we
refer to as “
        strength changes
        ”.
Though careful and repeated revisions are presumably ubiquitous in
politics, legal systems, and journalism, it is
not clear how to
collect
them;
on the other hand,
revisions to research papers may be more accessible, and
many researchers spend significant time
on editing
to
convey the right message regarding the strength of a project’s contributions, novelty, and limitations. Indeed,
statement strength in science communication matters
to writers:
understating contributions can affect whether people
recognize the true importance of the work;
at the same time, overclaiming can cause papers to be rejected.
       </p>
      </div>
      <div class="ltx_para" id="S1.p4">
       <p class="ltx_p">
        With the increasing popularity of e-print services
such as the arXiv
        ,
strength changes in scientific papers are becoming more
readily available.
Since the arXiv started
in 1991,
it has become “the standard repository for new papers
in mathematics, physics, statistics, computer science, biology, and
other disciplines”
        []
        .
An intriguing observation is that many researchers submit multiple versions of
the same paper on arXiv. For instance, among the 70K
papers submitted in 2011, almost 40% (27.7K)
have multiple versions.
Many
differences between these versions constitute a source of valid
and motivated strength differences, as can be seen from the sentential
revisions in Table
        1
        .
Pair 1 makes the contribution seem more impressive by replacing
“studied” with “proposed”. Pair 2 downgrades “human communication
activity” to “mobile phone communication”. Pair 3 removes
“significantly” and the emphasis on “same privacy guarantees”.
Pair 4 shows an insertion of hedging, a relatively well-known type of strength reduction.
Pair 5 is an interesting case that shows the complexity of this
problem: on the one hand, S2
claims that
something is
“inefficient”, which is an absolute statement,
compared to “efficiency loss” in S1, where the possibility of
efficiency still exists; on the
other hand, S1
employs an
active tone that emphasizes a causal relationship.
       </p>
      </div>
      <div class="ltx_para" id="S1.p5">
       <p class="ltx_p">
        The main contribution of this work is to provide the first large-scale
corpus of sentence-level revisions for studying
a broad range of variations in statement strength.
We collected labels for a subset of
these
revisions.
Given the
possibility of all kinds of disagreement, the fair level of agreement
(Fleiss’ Kappa)
among our annotators
was decent. But
in some cases, the labels
differed from our expectations,
indicating
that the general public can interpret the strength of scientific
statements differently from researchers.
The participants’ comments
may further
shed light on science communication and point to better ways to define and understand
strength differences.
       </p>
      </div>
     </div>
     <div class="ltx_section" id="S2">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        2
       </span>
       Related Work and Data
      </h2>
      <div class="ltx_para" id="S2.p1">
       <p class="ltx_p">
        Hedging, which can lead to strength differences,
has received some attention in the study of science communication
        []
        .
The CoNLL 2010 Shared Task was devoted to hedge detection
        []
        .
Hedge detection was also used to understand scientific framing in
debates over genetically-modified organisms in food
        []
        .
       </p>
      </div>
      <div class="ltx_para" id="S2.p2">
       <p class="ltx_p">
        Revisions on Wikipedia have been shown
useful for various applications, including
spelling correction
        []
        ,
sentence compression
        []
        , text simplification
        []
        ,
paraphrasing
        []
        , and textual entailment
        []
        .
But none of the
categories of Wikipedia revisions
previously examined
        []
        relate to
statement strength. After all, the objective of editing on Wikipedia is to
present neutral and objective articles.
       </p>
      </div>
      <div class="ltx_para" id="S2.p3">
       <p class="ltx_p">
        Public datasets of science communication are available, such as the ACL
Anthology,
        collections of
NIPS papers,
        and so on. These
datasets are useful for understanding the progress of
disciplines or the evolution of topics. But the lack of edit histories or
revisions makes them not
immediately suitable for studying strength
differences. Recently, there
have been
experiments with
        open
        peer review.
        Records from open reviewing
can provide additional insights
into the revision process
once enough data is
collected.
       </p>
      </div>
     </div>
     <div class="ltx_section" id="S3">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        3
       </span>
       Dataset Description
      </h2>
      <div class="ltx_para" id="S3.p1">
       <p class="ltx_p">
        Our main dataset was constructed from all
papers submitted in 2011 on the arXiv.
We first extracted
the
textual content from papers that have multiple
versions of tex source files. All
mathematical environments were ignored.
Section titles were not included in the final texts but are used in
alignment.
       </p>
      </div>
      <div class="ltx_para" id="S3.p2">
       <p class="ltx_p">
        In order to align the first version and the final version of the same
paper,
we first did macro alignment
of paper sections
based on section
titles. Then, for micro alignment
of sentences,
we employed a dynamic programming
algorithm similar to
that of
        .
Instead of cosine similarity, we used
an
idf-weighted longest-common-subsequence
algorithm
to define the similarity between
two sentences, because changes in word
ordering can also be interesting. Formally, the similarity score between
sentence
        i
        and sentence
        j
        is defined as
       </p>
       S⁢i⁢m⁢(i,j)=Weighted-LCS⁢(Si,Sj)m⁢a⁢x⁢(∑w∈Sii⁢d⁢f⁢(w),∑w∈Sji⁢d⁢f⁢(w)),
       <p class="ltx_p">
        where
        Si
        and
        Sj
        refer to
sentence
        i
        and sentence
        j
        .
Since it is likely that a new version adds or deletes a large
sequence of sentences, we did not impose
a skip penalty.
We set the mismatch penalty
to 0.1.
       </p>
      </div>
      <div class="ltx_para" id="S3.p3">
       <p class="ltx_p">
        In the end, there are 23K
papers where the first version was
different from the last version.
        We categorize
sentential revisions
into the
following three types:
       </p>
       <ul class="ltx_itemize" id="I1">
        <li class="ltx_item" id="I1.i1" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_itemize">
          •
         </span>
         <div class="ltx_para" id="I1.i1.p1">
          <p class="ltx_p">
           Deletion: we cannot find a match in the final
version.
          </p>
         </div>
        </li>
        <li class="ltx_item" id="I1.i2" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_itemize">
          •
         </span>
         <div class="ltx_para" id="I1.i2.p1">
          <p class="ltx_p">
           Typo: all sequences in a pair of matched sentences are typos, where a sequence-level typo is one where the edit distance between the matched sequences is less than three.
          </p>
         </div>
        </li>
        <li class="ltx_item" id="I1.i3" style="list-style-type:none;">
         <span class="ltx_tag ltx_tag_itemize">
          •
         </span>
         <div class="ltx_para" id="I1.i3.p1">
          <p class="ltx_p">
           Rewrite:
matched sentences that are
not typos. This type is
the focus of this study.
          </p>
         </div>
        </li>
       </ul>
      </div>
      <div class="ltx_paragraph" id="S3.SS0.SSS0.P1">
       <h3 class="ltx_title ltx_title_paragraph">
        What kinds of changes are being made?
       </h3>
       <div class="ltx_para" id="S3.SS0.SSS0.P1.p1">
        <p class="ltx_p">
         One
might initially
think that
typo fixes represent a large proportion of revisions,
but this is not correct, as shown in Figure
         4
         .
Deletions represent a substantial fraction, especially in
the middle section of a paper.
But it is clear
that the majority of changes are rewrites; thus revisions on the arXiv indeed provide a
great source for potential strength differences.
        </p>
       </div>
      </div>
      <div class="ltx_paragraph" id="S3.SS0.SSS0.P2">
       <h3 class="ltx_title ltx_title_paragraph">
        Who makes changes?
       </h3>
       <div class="ltx_para" id="S3.SS0.SSS0.P2.p1">
        <p class="ltx_p">
         Figure
         4
         shows that the Math subarchive makes the largest number
of changes. This is consistent with
the mathematics community’s custom of using the arXiv to get findings out early.
In terms of
changes per sentence (Figure
         4
         ), statistics and quantitative studies are the top
subareas.
        </p>
       </div>
       <div class="ltx_para" id="S3.SS0.SSS0.P2.p2">
        <p class="ltx_p">
         Further, Figure
         7
         shows the
effect of the number of
authors. It is interesting that both in terms of sheer
number and percentage, single-authored papers have the most
changes. This could be because a single author enjoys
greater freedom
and has stronger motivation to make changes,
or because multiple authors
tend to submit a more polished initial version. This echoes the finding in
         that the collaborative writing process differs considerably
from individual writing.
Also, more than 25% of the first
versions
are changed, which again shows that
substantive
edits are being made in
these resubmissions.
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S4">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        4
       </span>
       Annotating Strength Differences
      </h2>
      <div class="ltx_para" id="S4.p1">
       <p class="ltx_p">
        In order to
study statement strength,
reliable strength-difference labels
are needed.
In this section, we describe how
we tried to define
strength differences, compiled labeling
instructions, and
gathered labels
using Amazon Mechanical Turk.
       </p>
      </div>
      <div class="ltx_paragraph" id="S4.SS0.SSS0.P1">
       <h3 class="ltx_title ltx_title_paragraph">
        Label definition and collection procedure.
       </h3>
       <div class="ltx_para" id="S4.SS0.SSS0.P1.p1">
        <p class="ltx_p">
         We focused on matched sentences
from abstracts
and introductions to maximize the proportion of strength differences
(as opposed to factual/no strength changes).
We required pairs to
have similarity score larger than 0.5 in our
labeling task to make pairs more comparable.
We also replaced all math environments with “[MATH]”.
         We obtained 108K
pairs that satisfy the above conditions,
available at
         http://chenhaot.com/pages/statement-strength.html
         .
To create the pool of pairs for labeling, we randomly sampled 1000 pairs
and then removed pairs that we thought were processing errors.
        </p>
       </div>
       <div class="ltx_para" id="S4.SS0.SSS0.P1.p2">
        <p class="ltx_p">
         We used Amazon Mechanical Turk.
It may initially seem surprising to have annotations of technical
statements not done by
domain experts; we did this intentionally because it is common to
communicate unfamiliar topics to the public in political and science
communication (we comment
on non-expert
rationales later).
We use the following set of labels:
         Stronger, Weaker, No Strength Change, I can’t tell
         .
Table
         2
         gives our
definitions.
The instructions included 8 pairs as examples and 10 pairs to label
as a
training exercise.
Participants were then asked to choose labels and write
mandatory comments for 50 pairs.
According to the comments written by
participants,
we believe that they did the labeling in good faith.
        </p>
       </div>
      </div>
      <div class="ltx_paragraph" id="S4.SS0.SSS0.P2">
       <h3 class="ltx_title ltx_title_paragraph">
        Quantitative overview.
       </h3>
       <div class="ltx_para" id="S4.SS0.SSS0.P2.p1">
        <p class="ltx_p">
         We collected 9 labels each for 500 pairs.
Among the 500 pairs, Fleiss’ Kappa was 0.242, which indicates fair
agreement
         []
         .
We took a conservative approach and only considered pairs with
an absolute majority label, i.e., at least 5 of 9 labelers chose the
same label. There are 386 pairs that satisfy this requirement (93
weaker, 194 stronger, 99 no change).
On this subset of pairs, Fleiss’ Kappa is 0.322, and
74.4% of pairs
were strength changes.
Considering all the possible disagreement,
this result was acceptable.
        </p>
       </div>
      </div>
      <div class="ltx_paragraph" id="S4.SS0.SSS0.P3">
       <h3 class="ltx_title ltx_title_paragraph">
        Qualitative observations.
       </h3>
       <div class="ltx_para" id="S4.SS0.SSS0.P3.p1">
        <p class="ltx_p">
         We were excited about the labels from these participants:
despite the apparent difficulty of the task, we found that many labels
for the 386 pairs were reasonable.
However, in some cases, the labels were counter-intuitive.
Table
         3
         shows some representative examples.
        </p>
       </div>
       <div class="ltx_para" id="S4.SS0.SSS0.P3.p2">
        <p class="ltx_p">
         First, participants tend to take details as evidence even when these
details are not germane to the statement.
For pair 1,
while one turker pointed out the decline in number of
experiments, most turkers simply
labeled it as stronger because it was more
specific. “Specific” turned out to be a common reason used
in the comments, even though we said in the instructions that only additional justification
and evidence matter.
This echoes the finding in
         that even
unrelated details influenced judgments of guilt.
        </p>
       </div>
       <div class="ltx_para" id="S4.SS0.SSS0.P3.p3">
        <p class="ltx_p">
         Second, participants interpret constraints/conditions
not in strictly logical ways,
seeming
to care
little about
scope
at times.
For instance, the majority labeled
pair 2
as
“stronger”.
But in S2
for that pair, the
result
holds for
strictly
fewer possible worlds.
But it should be said
that there are cases that labelers interpreted logically, e.g., “compelling evidence”
subsumes
“compelling
experimental evidence”.
        </p>
       </div>
       <div class="ltx_para" id="S4.SS0.SSS0.P3.p4">
        <p class="ltx_p">
         Both of the above cases share the property that they seem to be
correlated with a tendency to judge lengthier statements as stronger.
Another interesting case that does not share this characteristic is that
participants can have a different understanding of
domain-specific terms. For pair 3, the majority thought that
“vectors” sounds more impressive than “images”; for pair 4, the
majority considered “adapt” stronger than “discover”.
This issue is common when communicating new topics to the public not
only in science communication but also in politics and other
scenarios.
It may partly explain
miscommunications and misinterpretations of scientific studies in
journalism.
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S5">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        5
       </span>
       Looking ahead
      </h2>
      <div class="ltx_para" id="S5.p1">
       <p class="ltx_p">
        Our observations regarding the annotation results raise questions regarding what is
a generalizable way to define strength differences, how to use the
labels that we collected,
and how to collect labels in the future.
We believe that this corpus of sentence-level revisions, together with
the labels and comments from participants, can
provide insights
into better ways to
approach this problem and help further understand strength of
statements.
       </p>
      </div>
      <div class="ltx_para" id="S5.p2">
       <p class="ltx_p">
        One interesting direction that this enables is a potentially new kind
of learning problem. The comments indicate features that humans think
salient. Is it possible to automatically learn new features from the comments?
       </p>
      </div>
      <div class="ltx_para" id="S5.p3">
       <p class="ltx_p">
        The ultimate goal of our study is to understand the effects of
statement strength
on the public, which can lead to
various applications in public communication.
       </p>
      </div>
     </div>
    </div>
   </div>
  </div>
 </body>
</html>
