<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
 <head>
  <title>
   Weak semantic context helps phonetic learningin a model of infant language acquisition.
  </title>
 </head>
 <body>
  <div class="ltx_page_main">
   <div class="ltx_page_content">
    <div class="ltx_document ltx_authors_1line">
     <span class="ltx_ERROR undefined">
      \pgfplotscreateplotcyclelist
     </span>
     <div class="ltx_para" id="p1">
      <p class="ltx_p">
       goodred,blue,teal,green!60!black,orange,
      </p>
     </div>
     <div class="ltx_section" id="S1">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        1
       </span>
       Introduction
      </h2>
      <div class="ltx_para" id="S1.p1">
       <p class="ltx_p">
        Infants begin learning the phonetic categories of their native language
in their first year
        (19; 29; 51)
        .
In theory, semantic information could offer a valuable cue for phoneme
induction
        by helping infants distinguish between minimal pairs, as linguists do
        (48)
        .
However, due to a widespread assumption that infants do not know the
meanings of many words at the age when they are learning phonetic
categories (see
        42
        for a review), most recent
models of early phonetic category acquisition have explored the phonetic
learning problem in the absence of semantic information
        (8; 9; 11; 26; 50)
        .
       </p>
      </div>
      <div class="ltx_para" id="S1.p2">
       <p class="ltx_p">
        Models without any semantic information are likely to underestimate
infants‚Äô ability to learn phonetic categories.
Infants learn language in the wild, and quickly attune to the fact that
words have (possibly unknown) meanings.
The extent of infants‚Äô semantic knowledge is not yet known, but existing
evidence shows that six-month-olds can associate some words with their
referents
        (4; 46; 47)
        , leverage
non-acoustic contexts such as objects or articulations to distinguish
similar sounds
        (44; 52)
        , and map meaning (in the
form of objects or images) to new word-forms in some laboratory settings
        (15; 16; 39)
        .
These findings indicate that young infants are sensitive to
co-occurrences between linguistic stimuli and at least some aspects of
the world.
       </p>
      </div>
      <div class="ltx_para" id="S1.p3">
       <p class="ltx_p">
        In this paper we explore the potential contribution of semantic
information to phonetic learning by formalizing a model in which
learners attend to the word-level context in which phones appear (as in
the lexical-phonetic learning model of
        11
        ) and also
to the situations in which word-forms are used.
The modeled situations consist of combinations of categories of salient
activities or objects, similar to the activity contexts explored by
        Roy et al. (37)
        , e.g.,‚Äògetting dressed‚Äô or ‚Äòeating breakfast‚Äô.
We assume that child learners are able to infer a representation of the
situational context from their non-linguistic environment.
However, in our simulations we approximate the environmental information
by running a topic model
        (5)
        over a corpus of
child-directed speech to infer a topic distribution for each situation.
These topic distributions are then used as input to our model to
represent situational contexts.
       </p>
      </div>
      <div class="ltx_para" id="S1.p4">
       <p class="ltx_p">
        The situational information in our model is similar to that assumed by
theories of cross-situational word learning
        (14; 40; 53)
        , but our model does not require
learners to map individual words to their referents.
Even in the absence of word-meaning mappings, situational information is
potentially useful because similar-sounding words uttered in similar
situations are more likely to be tokens of the same lexeme
(containing the same phones) than similar-sounding words uttered in
different situations.
       </p>
      </div>
      <div class="ltx_para" id="S1.p5">
       <p class="ltx_p">
        In simulations of vowel learning, inspired by
        Vallabha et al. (50)
        and
        Feldman et al. (11)
        , we show a clear improvement over previous models
in both phonetic and lexical (word-form) categorization when situational
context is used as an additional source of information.
This improvement is especially noticeable when the word-level context is
providing less information, arguably the more realistic setting.
These results demonstrate that relying on situational co-occurrence can
improve phonetic learning, even if learners do not yet know the meanings
of individual words.
       </p>
      </div>
     </div>
     <div class="ltx_section" id="S2">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        2
       </span>
       Background and overview of models
      </h2>
      <div class="ltx_para" id="S2.p1">
       <p class="ltx_p">
        Infants attend to distributional characteristics of their input
        (24; 23)
        , leading to the hypothesis that phonetic
categories could be acquired on the basis of bottom-up distributional
learning alone
        (8; 50; 26)
        .
However, this would require sound categories to be well separated, which
often is not the case‚Äîfor example, see¬†Figure
        1
        , which shows
the English vowel space that is the focus of this paper.
       </p>
      </div>
      <div class="ltx_para" id="S2.p2">
       <p class="ltx_p">
        Recent work has investigated whether infants could overcome such
distributional ambiguity by incorporating top-down information,
in particular, the fact that phones appear within words.
At six months, infants begin to recognize word-forms
such as their name and other frequently occurring words
        (21; 18)
        , without necessarily linking a
meaning to these forms.
This ‚Äúprotolexicon‚Äù can help differentiate phonetic categories by
adding word contexts in which certain sound categories appear
        (42; 12)
        .
To explore this idea further,
        Feldman et al. (11)
        implemented the
Lexical-Distributional (LD) model, which jointly learns a set of
phonetic vowel categories and a set of word-forms containing those
categories.
Simulations showed that the use of lexical context greatly improved
phonetic learning.
       </p>
      </div>
      <div class="ltx_para" id="S2.p3">
       <p class="ltx_p">
        Our own Topic-Lexical-Distributional (TLD) model extends the LD model to
include an additional type of context: the situations in which words
appear.
To motivate this extension and clarify the differences between the
models, we now provide a high-level overview of both models; details are
given in Sections
        3
        and
        4
        .
       </p>
      </div>
      <div class="ltx_subsection" id="S2.SS1">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         2.1
        </span>
        Overview of LD model
       </h3>
       <div class="ltx_para" id="S2.SS1.p1">
        <p class="ltx_p">
         Both the LD and TLD models are computational-level models of phonetic
(specifically, vowel) categorization where phones (vowels) are presented
to the model in the context of words.
         The task is to infer a set of phonetic categories and a set of
lexical items on the basis of the data observed for each word token
         xi
         .
In the original LD model, the observations for token
         xi
         are its frame
         fi
         , which consists of a list of consonants and slots for vowels, and
the list of vowel tokens
         ùíòi
         .
(The TLD model includes additional observations, described below.)
A single vowel token,
         wi‚Å¢j
         , is a two dimensional vector representing
the first two formants (peaks in the frequency spectrum, ordered from
lowest to highest).
For example, a token of the word
         kitty
         would have the frame
         fi=k_t_
         , containing two consonant phones, /
         k
         /
and /
         t
         /, with two vowel phone slots in between, and two vowel
formant vectors,
         wi‚Å¢0=[464,2294]
         and
         wi‚Å¢1=[412,2760]
         .
        </p>
       </div>
       <div class="ltx_para" id="S2.SS1.p2">
        <p class="ltx_p">
         Given the data, the model must assign each vowel token to a vowel
category,
         wi‚Å¢j=c
         . Both the LD and the TLD models do this using
intermediate lexemes,
         ‚Ñì
         , which contain vowel category
assignments,
         v‚Ñì‚Å¢j=c
         , as well as a frame
         f‚Ñì
         .
If a word token is assigned to a lexeme,
         xi=‚Ñì
         , the vowels within
the word are assigned to that lexeme‚Äôs vowel categories,
         wi‚Å¢j=v‚Ñì‚Å¢j=c
         .
         The word and lexeme frames must match,
         fi=f‚Ñì
         .
        </p>
       </div>
       <div class="ltx_para" id="S2.SS1.p3">
        <p class="ltx_p">
         Lexical information helps with phonetic categorization because it can
disambiguate highly overlapping categories, such as the
         ae
         and
         eh
         categories in Figure
         1
         .
A purely distributional learner who observes a cluster of data points in
the
         ae
         -
         eh
         region is likely to assume all these points belong
to a single category because the distributions of the categories are so
similar.
However, a learner who attends to lexical context will notice a
difference: contexts that only occur with
         ae
         will be observed in
one part of the
         ae
         -
         eh
         region, while contexts that only
occur with
         eh
         will be observed in a different (though partially
overlapping) space.
The learner then has evidence of two different categories occurring in
different sets of lexemes.
        </p>
       </div>
       <div class="ltx_para" id="S2.SS1.p4">
        <p class="ltx_p">
         Simulations with the LD model show that using lexical information to
constrain phonetic learning can greatly improve categorization accuracy
         (11)
         , but it can also introduce errors.
When two word tokens contain the same consonant frame but different
vowels (i.e., minimal pairs), the model is more likely to categorize
those two vowels together.
Thus, the model has trouble distinguishing minimal pairs.
Although young children also have trouble with minimal pairs
         (41; 45)
         , the LD model may overestimate the
degree of the problem.
We hypothesize that if a learner is able to associate words with the
contexts of their use (as children likely are), this could provide a
weak source of information for disambiguating minimal pairs even without
knowing their exact meanings.
That is, if the learner hears
         kV1t
         and
         kV2t
         in
different situational contexts, they are likely to be different lexical
items (and
         V1
         and
         V2
         different phones), despite the lexical
similarity between them.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S2.SS2">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         2.2
        </span>
        Overview of TLD model
       </h3>
       <div class="ltx_para" id="S2.SS2.p1">
        <p class="ltx_p">
         To demonstrate the benefit of situational information, we develop the
Topic-Lexical-Distributional (TLD) model, which extends the LD model
by assuming that words appear in
         situations
         analogous to documents in a topic model.
Each situation
         h
         is associated with a mixture of topics
         Œ∏h
         ,
which is assumed to be observed.
Thus, for the
         i
         th token in situation
         h
         , denoted
         xh‚Å¢i
         , the
observed data will be its frame
         fh‚Å¢i
         , vowels
         ùíòh‚Å¢i
         , and topic
vector
         Œ∏h
         .
        </p>
       </div>
       <div class="ltx_para" id="S2.SS2.p2">
        <p class="ltx_p">
         From an acquisition perspective, the observed topic distribution
represents the child‚Äôs knowledge of the context of the interaction:
she can distinguish bathtime from dinnertime, and is able to recognize
that some topics appear in certain contexts (e.g.¬†animals on walks,
vegetables at dinnertime) and not in others (few vegetables appear at
bathtime). We assume that the child would learn these topics from
observing the world around her and the co-occurrences of entities and
activities in the world. Within any given situation, there might be a
mixture of different (actual or possible) topics that are salient to the
child. We assume further that as the child learns the language, she will
begin to associate specific words with each topic as well.
        </p>
       </div>
       <div class="ltx_para" id="S2.SS2.p3">
        <p class="ltx_p">
         Thus, in the TLD model, the words used in a
situation are topic-dependent, implying meaning, but without pinpointing
specific referents. Although the model observes the distribution of
topics in each situation (corresponding to the child observing her
non-linguistic environment), it must learn to associate each
(phonetically and lexically ambiguous) word token with a particular
topic from that distribution.
The occurrence of similar-sounding words in different situations with
mostly non-overlapping topics will provide evidence that those words
belong to different topics and that they are therefore different
lexemes.
Conversely, potential minimal pairs that occur in situations with
similar topic distributions are more likely to belong to the same topic
and thus the same lexeme.
        </p>
       </div>
       <div class="ltx_para" id="S2.SS2.p4">
        <p class="ltx_p">
         Although we assume that children infer topic distributions from the
non-linguistic environment, we will use transcripts from
         childes
         to create the word/phone learning input for our model.
These transcripts are not annotated with environmental context, but
         Roy et al. (37)
         found that topics learned from similar
transcript data using a topic model were strongly correlated with
immediate activities and contexts.
We therefore obtain the topic distributions used as input to the TLD
model by training an LDA topic model
         (5)
         on a superset of
the child-directed transcript data we use for lexical-phonetic learning,
dividing the transcripts into small sections (the ‚Äòdocuments‚Äô in LDA)
that serve as our distinct situations
         ùíâ
         . As noted above, the
learned document-topic distributions
         ùúΩ
         are treated as
observed variables in the TLD model to represent the situational
context. The topic-word distributions learned by LDA are discarded,
since these are based on the (correct and unambiguous) words in the
transcript, whereas the TLD model is presented with phonetically
ambiguous versions of these word tokens and must learn to disambiguate
them and associate them with topics.
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S3">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        3
       </span>
       Lexical-Distributional Model
      </h2>
      <div class="ltx_para" id="S3.p1">
       <p class="ltx_p">
        In this section we describe more formally the
generative process for the LD model
        (11)
        ,
a joint Bayesian model over phonetic categories and a lexicon,
before describing the TLD extension in the following section.
       </p>
      </div>
      <div class="ltx_para" id="S3.p2">
       <p class="ltx_p">
        The set of phonetic categories and the lexicon are
both modeled using non-parametric Dirichlet Process
priors, which return a potentially infinite number of categories or
lexemes.
A DP is parametrized as
        D‚Å¢P‚Å¢(Œ±,H)
        , where
        Œ±
        is a
real-valued hyperparameter and
        H
        is a base distribution.
        H
        may be continuous, as when it generates phonetic categories in
formant space, or discrete, as when it generates lexemes as a list of
phonetic categories.
       </p>
      </div>
      <div class="ltx_para" id="S3.p3">
       <p class="ltx_p">
        A draw from a DP,
        G‚àºD‚Å¢P‚Å¢(Œ±,H)
        , returns a distribution over a
set of draws from
        H
        , i.e., a discrete distribution over a set of
categories or lexemes generated by
        H
        .
In the mixture model setting, the category assignments are then
generated from
        G
        , with the datapoints themselves generated by the
corresponding components from
        H
        .
If
        H
        is infinite, the support of the DP is likewise infinite.
During inference, we marginalize over
        G
        .
       </p>
      </div>
      <div class="ltx_subsection" id="S3.SS1">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         3.1
        </span>
        Phonetic Categories: IGMM
       </h3>
       <div class="ltx_para" id="S3.SS1.p1">
        <p class="ltx_p">
         Following previous models of vowel learning
         (8; 50; 26; 9)
         we assume that vowel tokens are drawn from a Gaussian mixture model.
The Infinite Gaussian Mixture Model (IGMM)
         (35)
         includes a DP prior, as described above, in which the base distribution
         HC
         generates multivariate Gaussians drawn from a Normal
Inverse-Wishart prior.
         Each observation, a formant vector
         wi‚Å¢j
         , is drawn from the Gaussian
corresponding to its category assignment
         ci‚Å¢j
         :
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx1">
         <tr class="ltx_equation ltx_align_baseline" id="S3.E1">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           Œºc,Œ£c
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºHC=ùëÅùêºùëä(Œº0,Œ£0,ŒΩ0)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (1)
           </span>
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S3.E2">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           GC
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºD‚Å¢P‚Å¢(Œ±c,HC)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (2)
           </span>
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S3.E3">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           ci‚Å¢j
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºGC
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (3)
           </span>
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S3.E4">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           wi‚Å¢j|ci‚Å¢j=c
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºN‚Å¢(Œºc,Œ£c)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (4)
           </span>
          </td>
         </tr>
        </table>
        <p class="ltx_p">
         The above model generates a category assignment
         ci‚Å¢j
         for each vowel
token
         wi‚Å¢j
         .
This is the baseline IGMM model, which clusters vowel tokens using
bottom-up distributional information only; the LD model adds top-down
information by assigning categories in the lexicon, rather than on the
token level.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S3.SS2">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         3.2
        </span>
        Lexicon
       </h3>
       <div class="ltx_para" id="S3.SS2.p1">
        <p class="ltx_p">
         In the LD model, vowel phones appear within words drawn from the
lexicon. Each such lexeme is represented as a frame plus a list of
vowel categories
         ùíó‚Ñì
         .
Lexeme assignments for each token are drawn from a DP
with a lexicon-generating base distribution
         HL
         .
The category for each vowel token in the word is determined by the
lexeme; the formant values are drawn from the corresponding Gaussian as
in the IGMM:
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx2">
         <tr class="ltx_equation ltx_align_baseline" id="S3.E5">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           GL
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºD‚Å¢P‚Å¢(Œ±l,HL)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (5)
           </span>
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S3.E6">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           xi=‚Ñì
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºGL
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (6)
           </span>
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S3.E7">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           wi‚Å¢j|v‚Ñì‚Å¢j=c
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àºN‚Å¢(Œºc,Œ£c)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (7)
           </span>
          </td>
         </tr>
        </table>
       </div>
       <div class="ltx_para" id="S3.SS2.p2">
        <p class="ltx_p">
         HL
         generates lexemes by first drawing the number of phones from a
geometric distribution and the number of consonant phones from a
binomial distribution.
The consonants are then generated from a DP with a uniform base
distribution (but note they are fixed at inference time, i.e.,¬†are
observed categorically), while the vowel phones
         ùíó‚Ñì
         are generated
by the IGMM DP above,
         v‚Ñì‚Å¢j‚àºGC
         .
        </p>
       </div>
       <div class="ltx_para" id="S3.SS2.p3">
        <p class="ltx_p">
         Note that two draws from
         HL
         may result in identical lexemes; these
are nonetheless considered to be separate (homophone) lexemes.
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S4">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        4
       </span>
       Topic-Lexical-Distributional Model
      </h2>
      <div class="ltx_para" id="S4.p1">
       <p class="ltx_p">
        The TLD model retains the IGMM vowel phone component, but extends the
lexicon of the LD model by adding topic-specific lexicons, which capture
the notion that lexeme probabilities are topic-dependent.
Specifically, the TLD model replaces the Dirichlet Process lexicon with
a Hierarchical Dirichlet Process (HDP;
        Teh (43)
        ).
In the HDP lexicon, a top-level global lexicon is generated as in the LD
model.
Topic-specific lexicons are then drawn from the global lexicon,
containing a subset of the global lexicon (but since the size of the
global lexicon is unbounded, so are the topic-specific lexicons).
These topic-specific lexicons are used to generate the tokens in a
similar manner to the LD model.
There are a fixed number of lower level topic-lexicons; these
are matched to the number of topics in the LDA model used to
infer the topic distributions (see Section
        6.4
        ).
       </p>
      </div>
      <div class="ltx_para" id="S4.p2">
       <p class="ltx_p">
        More formally, the global lexicon is generated as a top-level DP:
        GL‚àºD‚Å¢P‚Å¢(Œ±l,HL)
        (see Section
        3.2
        ; remember
        HL
        includes draws from the IGMM over vowel categories).
        GL
        is in turn used as the base distribution in the topic-level
DPs,
        Gk‚àºD‚Å¢P‚Å¢(Œ±k,GL)
        .
In the Chinese Restaurant Franchise metaphor often used to describe
HDPs,
        GL
        is a global menu of dishes (lexemes).
The topic-specific lexicons are restaurants, each with its own
distribution over dishes; this distribution is defined by seating
customers (word tokens) at
        tables
        , each of which serves a single
dish from the menu: all tokens
        x
        at the same table
        t
        are assigned to
the same lexeme
        ‚Ñìt
        .
Inference (Section
        5
        ) is defined in terms of tables
rather than lexemes; if multiple tables draw the same dish from
        GL
        ,
tokens at these tables share a lexeme.
       </p>
      </div>
      <div class="ltx_para" id="S4.p3">
       <p class="ltx_p">
        In the TLD model, tokens appear within situations, each of which
has a distribution over topics
        Œ∏h
        .
Each token
        xh‚Å¢i
        has a co-indexed topic assignment variable,
        zh‚Å¢i
        , drawn from
        Œ∏h
        , designating the topic-lexicon from
which the table for
        xh‚Å¢i
        is to be drawn.
The formant values for
        wh‚Å¢i‚Å¢j
        are drawn in the same way as in the LD
model, given the lexeme assignment at
        xh‚Å¢i
        .
This results in the following model, shown in Figure
        2
        :
       </p>
       <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx3">
        <tr class="ltx_equation ltx_align_baseline" id="S4.E8">
         <td class="ltx_eqn_center_padleft">
         </td>
         <td class="ltx_td ltx_align_right">
          GL
         </td>
         <td class="ltx_td ltx_align_left">
          ‚àºD‚Å¢P‚Å¢(Œ±l,HL)
         </td>
         <td class="ltx_eqn_center_padright">
         </td>
         <td class="ltx_align_middle ltx_align_right" rowspan="1">
          <span class="ltx_tag ltx_tag_equation">
           (8)
          </span>
         </td>
        </tr>
        <tr class="ltx_equation ltx_align_baseline" id="S4.E9">
         <td class="ltx_eqn_center_padleft">
         </td>
         <td class="ltx_td ltx_align_right">
          Gk
         </td>
         <td class="ltx_td ltx_align_left">
          ‚àºD‚Å¢P‚Å¢(Œ±k,GL)
         </td>
         <td class="ltx_eqn_center_padright">
         </td>
         <td class="ltx_align_middle ltx_align_right" rowspan="1">
          <span class="ltx_tag ltx_tag_equation">
           (9)
          </span>
         </td>
        </tr>
        <tr class="ltx_equation ltx_align_baseline" id="S4.E10">
         <td class="ltx_eqn_center_padleft">
         </td>
         <td class="ltx_td ltx_align_right">
          zh‚Å¢i
         </td>
         <td class="ltx_td ltx_align_left">
          ‚àºM‚Å¢u‚Å¢l‚Å¢t‚Å¢(Œ∏h)
         </td>
         <td class="ltx_eqn_center_padright">
         </td>
         <td class="ltx_align_middle ltx_align_right" rowspan="1">
          <span class="ltx_tag ltx_tag_equation">
           (10)
          </span>
         </td>
        </tr>
        <tr class="ltx_equation ltx_align_baseline" id="S4.E11">
         <td class="ltx_eqn_center_padleft">
         </td>
         <td class="ltx_td ltx_align_right">
          xh‚Å¢i=t|zh‚Å¢i=k
         </td>
         <td class="ltx_td ltx_align_left">
          ‚àºGk
         </td>
         <td class="ltx_eqn_center_padright">
         </td>
         <td class="ltx_align_middle ltx_align_right" rowspan="1">
          <span class="ltx_tag ltx_tag_equation">
           (11)
          </span>
         </td>
        </tr>
        <tr class="ltx_equation ltx_align_baseline" id="S4.E12">
         <td class="ltx_eqn_center_padleft">
         </td>
         <td class="ltx_td ltx_align_right">
          wh‚Å¢i‚Å¢j|xh‚Å¢i=t,v‚Ñìt‚Å¢j=c
         </td>
         <td class="ltx_td ltx_align_left">
          ‚àºN‚Å¢(Œºc,Œ£c)
         </td>
         <td class="ltx_eqn_center_padright">
         </td>
         <td class="ltx_align_middle ltx_align_right" rowspan="1">
          <span class="ltx_tag ltx_tag_equation">
           (12)
          </span>
         </td>
        </tr>
       </table>
      </div>
     </div>
     <div class="ltx_section" id="S5">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        5
       </span>
       Inference: Gibbs Sampling
      </h2>
      <div class="ltx_para" id="S5.p1">
       <p class="ltx_p">
        We use Gibbs sampling to infer three sets of variables in the TLD
model: assignments to vowel categories in the lexemes,
assignments of tokens to topics, and assignments of tokens to
tables (from which the assignment to lexemes can be read off).
       </p>
      </div>
      <div class="ltx_subsection" id="S5.SS1">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         5.1
        </span>
        Sampling lexeme vowel categories
       </h3>
       <div class="ltx_para" id="S5.SS1.p1">
        <p class="ltx_p">
         Each vowel in the lexicon must be assigned to a category in the
IGMM.
The posterior probability of a category assignment is composed of
the DP prior over categories and the likelihood of the observed vowels
belonging to that category.
We use
         ùíò‚Ñì‚Å¢j
         to denote the set of vowel formants at position
         j
         in
words that have been assigned to lexeme
         ‚Ñì
         . Then,
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx4">
         <tr class="ltx_equation ltx_align_baseline" id="S5.Ex1">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           P(
          </td>
          <td class="ltx_td ltx_align_left">
           v‚Ñì‚Å¢j=c|ùíò,ùíô,‚Ñì‚àñ‚Ñì)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S5.E13">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àùP(v‚Ñì‚Å¢j=c|‚Ñì‚àñ‚Ñì)p(ùíò‚Ñì‚Å¢j|v‚Ñì‚Å¢j=c,ùíò‚àñ‚Ñì‚Å¢j)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (13)
           </span>
          </td>
         </tr>
        </table>
       </div>
       <div class="ltx_para" id="S5.SS1.p2">
        <p class="ltx_p">
         The first (DP prior) factor is defined as:
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx5">
         <tr class="ltx_equation ltx_align_baseline" id="S5.E14">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           P(v‚Ñì‚Å¢j=c
          </td>
          <td class="ltx_td ltx_align_left">
           |ùíó‚àñ‚Ñì‚Å¢j)={nc‚àëcnc+Œ±cif¬†c¬†existsŒ±c‚àëcnc+Œ±cif¬†c¬†new
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (14)
           </span>
          </td>
         </tr>
        </table>
        <p class="ltx_p">
         where
         nc
         is the number of other vowels in the lexicon,
         ùíó‚àñl‚Å¢j
         , assigned to category
         c
         .
Note that there is always positive probability of creating a new
category.
        </p>
       </div>
       <div class="ltx_para" id="S5.SS1.p3">
        <p class="ltx_p">
         The likelihood of the vowels is calculated by marginalizing over all
possible means and variances of the Gaussian category parameters, given
the NIW prior. For a single point (if
         |ùíò‚Ñì‚Å¢j|=1
         ),
this predictive posterior is in the form of a Student-
         t
         distribution;
for the more general case see
         Feldman et al. (11)
         , Eq. B3.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S5.SS2">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         5.2
        </span>
        Sampling table &amp; topic assignments
       </h3>
       <div class="ltx_para" id="S5.SS2.p1">
        <p class="ltx_p">
         We jointly sample
         ùíô
         and
         ùíõ
         , the variables assigning tokens to
tables and topics.
Resampling the table assignment includes the possibility of
changing to a table with a different lexeme or drawing a new table with
a previously seen or novel lexeme.
The joint conditional probability of a table and topic assignment, given
all other current token assignments, is:
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx6">
         <tr class="ltx_equation ltx_align_baseline" id="S5.Ex2">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           P
          </td>
          <td class="ltx_td ltx_align_left">
           (xh‚Å¢i=t,zh‚Å¢i=k|ùíòh‚Å¢i,Œ∏h,ùíï‚àñh‚Å¢i,‚Ñì,ùíò‚àñh‚Å¢i)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S5.Ex3">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
          </td>
          <td class="ltx_td ltx_align_left">
           =P(k|Œ∏h)P(t|k,‚Ñìt,ùíï‚àñh‚Å¢i)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
         </tr>
         <tr class="ltx_equation ltx_align_baseline" id="S5.E15">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
          </td>
          <td class="ltx_td ltx_align_left">
           ‚àèc‚ààCp(ùíòh‚Å¢i‚Å£‚ãÖ|v‚Ñìt‚Å£‚ãÖ=c,ùíò‚àñh‚Å¢i)
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (15)
           </span>
          </td>
         </tr>
        </table>
       </div>
       <div class="ltx_para" id="S5.SS2.p2">
        <p class="ltx_p">
         The first factor, the prior probability of topic
         k
         in document
         h
         ,
is given by
         Œ∏h‚Å¢k
         obtained from the LDA.
The second factor is the prior probability of assigning word
         xi
         to
table
         t
         with lexeme
         ‚Ñì
         given topic
         k
         . It is given by the HDP,
and depends on whether the table
         t
         exists in the HDP topic-lexicon for
         k
         and, likewise, whether any table in the topic-lexicon has the lexeme
         ‚Ñì
         :
        </p>
        <table class="ltx_equationgroup ltx_eqn_align" id="Sx1.EGx7">
         <tr class="ltx_equation ltx_align_baseline" id="S5.E16">
          <td class="ltx_eqn_center_padleft">
          </td>
          <td class="ltx_td ltx_align_right">
           P(t|k,‚Ñì,ùíï‚àñh‚Å¢i)‚àù
          </td>
          <td class="ltx_td ltx_align_left">
           {nk‚Å¢tnk+Œ±kif¬†t¬†in¬†kŒ±knk+Œ±k‚Å¢m‚Ñìm+Œ±lif¬†t¬†new,¬†‚Ñì¬†knownŒ±knk+Œ±k‚Å¢Œ±‚Ñìm+Œ±lif¬†t¬†and¬†‚Ñì¬†new
          </td>
          <td class="ltx_eqn_center_padright">
          </td>
          <td class="ltx_align_middle ltx_align_right" rowspan="1">
           <span class="ltx_tag ltx_tag_equation">
            (16)
           </span>
          </td>
         </tr>
        </table>
        <p class="ltx_p">
         Here
         nk‚Å¢t
         is the number of other tokens at table
         t
         ,
         nk
         are the total number of tokens in topic
         k
         ,
         m‚Ñì
         is the number
of tables across all topics with the lexeme
         ‚Ñì
         , and
         m
         is the total
number of tables.
        </p>
       </div>
       <div class="ltx_para" id="S5.SS2.p3">
        <p class="ltx_p">
         The third factor, the likelihood of the vowel formants
         ùíòh‚Å¢i
         in
the categories given by the lexeme
         ùíól
         , is of the same
form as the likelihood of vowel categories when resampling lexeme vowel
assignments. However, here it is calculated over the set of vowels in the token
assigned to each vowel category (i.e.,¬†the vowels at indices where
         v‚Ñìt‚Å£‚ãÖ=c
         ).
For a new lexeme, we approximate the likelihood using 100 samples
drawn from the prior, each weighted by
         Œ±/100
         (28)
         .
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S5.SS3">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         5.3
        </span>
        Hyperparameters
       </h3>
       <div class="ltx_para" id="S5.SS3.p1">
        <p class="ltx_p">
         The three hyperparameters governing the HDP over the lexicon,
         Œ±l
         and
         Œ±k
         , and the DP over vowel categories,
         Œ±c
         , are
estimated using a slice sampler.
The remaining hyperparameters for the vowel category and lexeme priors are
set to the same values used by
         Feldman et al. (11)
         .
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S6">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        6
       </span>
       Experiments
      </h2>
      <div class="ltx_subsection" id="S6.SS1">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.1
        </span>
        Corpus
       </h3>
       <div class="ltx_para" id="S6.SS1.p1">
        <p class="ltx_p">
         We test our model on situated child directed speech, taken from the
C1 section of the Brent corpus in
         childes
         (6; 20)
         .
This corpus consists of transcripts of speech directed at infants
between the ages of 9 and 15 months, captured in a naturalistic setting
as parent and child went about their day.
This ensures variability of situations.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS1.p2">
        <p class="ltx_p">
         Utterances with unintelligible words or quotes are removed.
We restrict the corpus to content words by retaining only words
tagged as
         adj, n, part
         and
         v
         (adjectives, nouns,
particles, and verbs).
This is in line with evidence that infants distinguish content and
function words on the basis of acoustic signals
         (38)
         .
Vowel categorization improves when attending only to more prosodically
and phonologically salient tokens
         (1)
         , which generally
appear within content, not function words.
The final corpus consists of 13138 tokens and 1497 word types.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S6.SS2">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.2
        </span>
        Hillenbrand Vowels
       </h3>
       <div class="ltx_para" id="S6.SS2.p1">
        <p class="ltx_p">
         The transcripts do not include phonetic information,
so, following
         Feldman et al. (11)
         , we
synthesize the formant values using data from
         Hillenbrand et al. (17)
         .
This dataset consists of a set of 1669 manually gathered formant
values from 139 American English speakers (men, women and
children) for 12 vowels. For each vowel category, we construct a
Gaussian from the mean and covariance of the datapoints belonging to
that category, using the first and second formant values
measured at steady state.
We also construct a second dataset using only datapoints from adult
female speakers.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS2.p2">
        <p class="ltx_p">
         Each word in the dataset is converted to a phonemic representation
using the CMU pronunciation dictionary, which returns a sequence of Arpabet phoneme symbols.
If there are multiple possible pronunciations, the first one is used.
Each vowel phoneme in the word is then replaced by formant values drawn
from the corresponding Hillenbrand Gaussian for that vowel.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S6.SS3">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.3
        </span>
        Merging Consonant Categories
       </h3>
       <div class="ltx_para" id="S6.SS3.p1">
        <p class="ltx_p">
         The Arpabet encoding used in the phonemic representation includes 24
consonants. We construct datasets
both using the full set of consonants‚Äîthe ‚ÄòC24‚Äô dataset‚Äîand
with less fine-grained consonant categories.
Distinguishing all consonant categories assumes perfect learning of
consonants prior to vowel categorization and is thus somewhat
unrealistic
         (29)
         , but provides an upper limit on the
information that word-contexts can give.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS3.p2">
        <p class="ltx_p">
         In the ‚ÄòC15‚Äô dataset,
the voicing distinction is collapsed,
leaving 15 consonant categories. The collapsed categories are
         B/P, G/K, D/T, CH/JH, V/F, TH/DH, S/Z, SH/ZH, R/L
         while
         HH, M, NG, N, W, Y
         remain separate phonemes.
This dataset mirrors the finding in
         Mani and Plunkett (22)
         that 12 month old
infants are not sensitive to voicing mispronunciations.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS3.p3">
        <p class="ltx_p">
         The ‚ÄòC6‚Äô dataset distinguishes between only 6 coarse consonant phonemes,
corresponding to stops (
         B,P,G,K,D,T
         ), affricates (
         CH,JH
         ),
fricatives (
         V, F, TH, DH, S, Z, SH, ZH, HH
         ), nasals (
         M, NG,
N
         ), liquids (
         R, L
         ), and semivowels/glides (
         W, Y
         ).
This dataset makes minimal assumptions about the category categories
that infants could use in this learning setting.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS3.p4">
        <p class="ltx_p">
         Decreasing the number of consonants increases the ambiguity in the
corpus:
         bat
         not only shares a frame (
         b_t
         )
with
         boat
         and
         bite
         , but also, in the C15 dataset, with
         put
         ,
         pad
         and
         bad
         (
         b/p_d/t
         ),
and in the C6 dataset, with
         dog
         and
         kite
         , among many others (
         STOP_STOP
         ).
Table
         1
         shows the percentage of types and tokens that
are ambiguous in each dataset, that is, words in frames
that match multiple wordtypes.
Note that we always evaluate against the
         gold
         word identities,
even when these are not distinguished in the model‚Äôs input.
These datasets are intended to evaluate the degree of reliance on
consonant information in the LD and TLD models, and to what
extent the topics in the TLD model can replace this information.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S6.SS4">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.4
        </span>
        Topics
       </h3>
       <div class="ltx_para" id="S6.SS4.p1">
        <p class="ltx_p">
         The input to the TLD model includes a distribution over topics for each
situation, which we infer in advance from the full Brent
corpus (not only the C1 subset) using LDA.
Each transcript in the Brent corpus captures about 75 minutes of
parent-child interaction, and thus multiple situations will be included
in each file.
The transcripts do not delimit situations, so we do this somewhat
arbitrarily by splitting each transcript after 50 CDS utterances,
resulting in 203 situations for the Brent C1 dataset.
As well as function words, we also remove the five most frequent
content words (
         be, go, get, want, come
         ).
On average, situations are only 59 words long, reflecting the relative
lack of content words in CDS utterances.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS4.p2">
        <p class="ltx_p">
         We infer 50 topics for this set of situations
using the
         mallet
         toolkit
         (25)
         .
Hyperparameters are inferred, which leads to a dominant
topic that includes mainly light verbs (
         have, let, see, do
         ).
The other topics are less frequent but capture stronger semantic
meaning (e.g.
         yummy, peach, cookie, daddy, bib
         in one topic,
         shoe, let, put, hat, pants
         in another).
The word-topic assignments are used to calculate unsmoothed
situation-topic distributions
         ùúΩ
         used by the TLD model.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S6.SS5">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.5
        </span>
        Evaluation
       </h3>
       <div class="ltx_para" id="S6.SS5.p1">
        <p class="ltx_p">
         We evaluate against adult categories, i.e.,¬†the ‚Äògold-standard‚Äô, since
all learners of a language eventually converge on similar categories.
(Since our model is not a model of the learning process, we do not
compare the infant learning process to the learning algorithm.)
We evaluate both the inferred phonetic categories and words using the
clustering evaluation measure V-Measure (VM;
         36
         ).
         VM is the harmonic mean of two components, similar to F-score, where the
components (VC and VH) are measures of cross entropy between the gold
and model categorization.
For vowels, VM measures how well the inferred phonetic
categorizations match the gold categories; for lexemes, it measures
whether tokens have been assigned to the same lexemes both by
the model and the gold standard. Words are evaluated against
gold orthography, so homophones,¬†e.g.
         hole
         and
         whole
         , are
distinct gold words.
        </p>
       </div>
      </div>
      <div class="ltx_subsection" id="S6.SS6">
       <h3 class="ltx_title ltx_title_subsection">
        <span class="ltx_tag ltx_tag_subsection">
         6.6
        </span>
        Results
       </h3>
       <div class="ltx_para" id="S6.SS6.p1">
        <p class="ltx_p">
         We compare all three models‚ÄîTLD, LD, and IGMM‚Äîon the vowel categorization
task, and TLD and LD on the lexical categorization task (since IGMM does
not infer a lexicon). The datasets correspond to two sets of conditions:
firstly, either using vowel categories synthesized from all speakers or
only adult female speakers, and secondly, varying the coarseness
of the observed consonant categories.
Each condition (model, vowel speakers, consonant set) is run five times,
using 1500 iterations of Gibbs sampling with hyperparameter sampling.
Overall, we find that TLD
outperforms the other models in both tasks, across all conditions.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS6.p2">
        <p class="ltx_p">
         Vowel categorization results are shown in
Figure
         3
         .
IGMM performs substantially worse than both TLD and LD, with scores more
than 30 points lower than the best results for these models,
clearly showing the value of the protolexicon and replicating the
results found by
         Feldman et al. (11)
         on this dataset.
Furthermore, TLD consistently outperforms the LD model, finding
better phonetic categories, both for vowels generated from the combined
categories of all speakers (‚Äòall‚Äô) and vowels generated from adult
female speakers only (‚Äòw‚Äô), although the latter are clearly much easier
for both models to learn.
Both models perform less well when the consonant frames provide less
information, but the TLD model performance degrades less than the LD
performance.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS6.p3">
        <p class="ltx_p">
         Both the TLD and the LD models find ‚Äòsupervowel‚Äô categories, which cover
multiple vowel categories and are used to merge minimal pairs into a
single lexical item.
Figure
         4
         shows example vowel categories inferred by the TLD
model, including two supervowels.
The TLD supervowels are used much less frequently than the supervowels
found by the LD model, containing, on average, only two-thirds as many
tokens.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS6.p4">
        <p class="ltx_p">
         Figure
         5
         shows that TLD also outperforms LD on
the lexeme/word categorization task.
Again performance decreases as the consonant categories become coarser,
but the additional semantic information in the TLD model compensates for
the lack of consonant information. In the individual components of VM,
TLD and LD have similar VC (‚Äúrecall‚Äù), but TLD has higher VH
(‚Äúprecision‚Äù), demonstrating that the semantic information given by
the topics can separate potentially ambiguous words, as hypothesized.
        </p>
       </div>
       <div class="ltx_para" id="S6.SS6.p5">
        <p class="ltx_p">
         Overall, the contextual semantic information added in the TLD model
leads to both better phonetic categorization and to a better
protolexicon, especially when the input is noisier, using
degraded consonants.
Since infants are not likely to have perfect
knowledge of phonetic categories at this stage, semantic
information is a potentially rich source of information that could be
drawn upon to offset noise from other domains.
The form of the semantic information added in the TLD model is itself
quite weak, so the improvements shown here are in line with what infant
learners could achieve.
        </p>
       </div>
      </div>
     </div>
     <div class="ltx_section" id="S7">
      <h2 class="ltx_title ltx_title_section">
       <span class="ltx_tag ltx_tag_section">
        7
       </span>
       Conclusion
      </h2>
      <div class="ltx_para" id="S7.p1">
       <p class="ltx_p">
        Language acquisition is a complex task, in which many heterogeneous
sources of information may be useful. In this paper, we investigated
whether contextual semantic information could be of help when learning
phonetic categories. We found that this contextual information can
improve phonetic learning performance considerably, especially in
situations where there is a high degree of phonetic ambiguity in the
word-forms that learners hear. This suggests that previous models that
have ignored semantic information may have underestimated the
information that is available to infants. Our model illustrates one way
in which language learners might harness the rich information that is
present in the world without first needing to acquire a full inventory
of word meanings.
       </p>
      </div>
      <div class="ltx_para" id="S7.p2">
       <p class="ltx_p">
        The contextual semantic information that the TLD model tracks is similar
to that potentially used in other linguistic learning tasks.
Theories of cross-situational word learning
        (40; 53)
        assume that sensitivity to situational co-occurrences between words and
non-linguistic contexts is a precursor to learning the meanings of
individual words. Under this view, contextual semantics is available to
infants well before they have acquired large numbers of semantic minimal
pairs. However, recent experimental evidence indicates that learners do
not always retain detailed information about the referents that are
present in a scene when they hear a word
        (27; 49)
        . This evidence poses a direct
challenge to theories of cross-situational word learning. Our account
does not necessarily require learners to track co-occurrences between
words and individual objects, but instead focuses on more abstract
information about salient events and topics in the environment; it will
be important to investigate to what extent infants encode this
information and use it in phonetic learning.
       </p>
      </div>
      <div class="ltx_para" id="S7.p3">
       <p class="ltx_p">
        Regardless of the specific way in which infants encode semantic
information, our method of adding this information by using LDA topics
from transcript data was shown to be effective. This method is
practical because it can approximate semantic information without
relying on extensive manual annotation.
       </p>
      </div>
      <div class="ltx_para" id="S7.p4">
       <p class="ltx_p">
        The LD model extended the phonetic categorization task by adding word
contexts; the TLD model presented here goes even further, adding larger
situational contexts. Both forms of top-down information help the
low-level task of classifying acoustic signals into phonetic categories,
furthering a holistic view of language learning with interaction across
multiple levels.
       </p>
      </div>
     </div>
    </div>
   </div>
  </div>
 </body>
</html>
