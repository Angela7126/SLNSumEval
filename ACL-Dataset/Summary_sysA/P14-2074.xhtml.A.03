<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:168">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this paper we estimate the correlation of human judgements with five automatic evaluation measures on two image description data sets.</a>
<a href="#1" id="1">We estimate Spearman ’ s Ρ for five different automatic evaluation measures against human judgements for the automatic image description task.</a>
<a href="#2" id="2">Bleu measures the effective overlap between a reference sentence X and a candidate sentence Y.</a>
<a href="#3" id="3">Ter measures the number of modifications a human would need to make to transform a candidate Y into a reference X.</a>
<a href="#4" id="4">The sentence-level evaluation measures were calculated for each image – description – reference tuple.</a>
<a href="#5" id="5">We failed to find significant correlations between grammatlicality judgements and any of the automatic measures on the Elliott and Keller ( 2013 ) data.</a>
<a href="#6" id="6">In this paper we performed a sentence-level correlation analysis of automatic evaluation measures against expert human judgements for the automatic image description task.</a>
<a href="#7" id="7">Nevertheless, we propose that unigram bleu should no longer be used as an objective function for automatic image description because it has a weak correlation with human accuracy judgements.</a>
</body>
</html>