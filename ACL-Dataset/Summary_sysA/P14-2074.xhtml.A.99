<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:156">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this paper we estimate the correlation of human judgements with five automatic evaluation measures on two image description data sets.</a>
<a href="#1" id="1">Our work extends previous studies of evaluation measures for image description [ 7 ] , which focused on unigram-based measures and reported agreement scores such as Cohen ’ s Κ rather than correlations.</a>
<a href="#2" id="2">The main finding of our analysis is that ter and unigram bleu are weakly correlated against human judgements, rouge-su4 and Smoothed bleu are moderately correlated, and the strongest correlation is found with Meteor.</a>
<a href="#3" id="3">On the Flickr8k data set, all evaluation measures can be classified as either weakly correlated or moderately correlated with human judgements and all results are significant ter is only weakly correlated with human judgements but could prove useful in comparing the types of differences between models.</a>
<a href="#4" id="4">In this paper we performed a sentence-level correlation analysis of automatic evaluation measures against expert human judgements for the automatic image description task.</a>
</body>
</html>