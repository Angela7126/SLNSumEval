<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:101">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this approach, a topic model on a given set of unlabeled training documents is constructed using LDA, then an annotator assigns a class label to some topics based on their most probable words.</a>
<a href="#1" id="1">These topics are very few, when compared to the number of documents.</a>
<a href="#2" id="2">As the most probable words of topics are representative of the dataset, there is no need for the annotator to search for the right set of features for each class.</a>
<a href="#3" id="3">As LDA topics are semantically more meaningful than individual words and can be acquired easily, our approach overcomes limitations of the semi-supervised methods discussed above.</a>
</body>
</html>