<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:154">
</head>
<body bgcolor="white">
<a href="#0" id="0">Consider a unigram language model 𝒮 S that models the lexical characteristics of solution posts, and a translation model 𝒯 S that models the lexical correlation between problems and solutions.</a>
<a href="#1" id="1">Where 𝒯 S p denotes the multionomial distribution obtained from 𝒯 S conditioned over the words in the post p ; this is obtained by assigning each candidate solution word w a weight equal to a ⁢ v ⁢ g ⁢ { 𝒯 S ⁢ [ w ′ ] ⁢ [ w ] w ′∈ p } , and normalizing such weights across all solution words.</a>
<a href="#2" id="2">In short, each solution word is assumed to be generated from the language model or the translation model (conditioned on the problem words) with a probability of Λ and 1 - Λ respectively, thus accounting for the correlation assumption.</a>
<a href="#3" id="3">The generative model above is similar to the proposal in [ 5 ] , adapted suitably for our scenario.</a>
</body>
</html>