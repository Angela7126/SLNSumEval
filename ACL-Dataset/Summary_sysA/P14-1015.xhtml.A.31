<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:154">
</head>
<body bgcolor="white">
<a href="#0" id="0">Consider a unigram language model ğ’® S that models the lexical characteristics of solution posts, and a translation model ğ’¯ S that models the lexical correlation between problems and solutions.</a>
<a href="#1" id="1">Where ğ’¯ S p denotes the multionomial distribution obtained from ğ’¯ S conditioned over the words in the post p ; this is obtained by assigning each candidate solution word w a weight equal to a â¢ v â¢ g â¢ { ğ’¯ S â¢ [ w â€² ] â¢ [ w ] w â€²âˆˆ p } , and normalizing such weights across all solution words.</a>
<a href="#2" id="2">In short, each solution word is assumed to be generated from the language model or the translation model (conditioned on the problem words) with a probability of Î› and 1 - Î› respectively, thus accounting for the correlation assumption.</a>
<a href="#3" id="3">The generative model above is similar to the proposal in [ 5 ] , adapted suitably for our scenario.</a>
</body>
</html>