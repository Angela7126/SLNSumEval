<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:120">
</head>
<body bgcolor="white">
<a href="#0" id="0">Thus, they can supervise each other to learn their semantic phrase embeddings.</a>
<a href="#1" id="1">Therefore, we can imagine that learning semantic phrase embedding is reasonable if we are given gold vector representations of the phrases.</a>
<a href="#2" id="2">Given a phrase pair ( s , t ) , the BRAE model first obtains their semantic phrase representations ( p s , p t ) , and then transforms p s into target semantic space p s * , p t into source semantic space p t *.</a>
<a href="#3" id="3">To have a better intuition about the power of the BRAE model at learning semantic phrase embeddings, we show some examples in Table 3.</a>
<a href="#4" id="4">This indicates that the proposed BRAE model is effective at learning semantic phrase embeddings.</a>
</body>
</html>