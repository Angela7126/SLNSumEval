<html>
<head>
<meta name="TextLength" content="SENT_NUM:2, WORD_NUM:137">
</head>
<body bgcolor="white">
<a href="#0" id="0">1) we propose concurrent learning using multi-agent RL as a way to deal with some of the issues of current approaches to dialogue policy learning (i.e.,, the need for SUs and corpora), which may also potentially prove useful for learning via live interaction with human users; (2) we show that concurrent learning can address changes in user behavior over time, and requires multi-agent RL techniques and variable exploration rates; (3) to our knowledge this is the first time that PHC and PHC-WoLF are used for learning dialogue policies; (4) for the first time, the above techniques are applied to a negotiation domain; and (5) this is the first study that compares Q-learning, PHC, and PHC-WoLF in such a variety of situations (varying a large number of parameters.</a>
<a href="#1" id="1">Table 3 also shows the number of state-action pairs (Q-values.</a>
</body>
</html>