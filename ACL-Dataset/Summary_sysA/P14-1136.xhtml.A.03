<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:106">
</head>
<body bgcolor="white">
<a href="#0" id="0">So the second baseline has the same input representation as Wsabie Embedding but uses a log-linear model instead of Wsabie.</a>
<a href="#1" id="1">We learn the initial embedding representations for our frame identification model (§ 3 ) using a deep neural language model similar to the one proposed by Bengio et al.</a>
<a href="#2" id="2">Hyperparameters For our frame identification model with embeddings, we search for the Wsabie hyperparameters using the development data.</a>
<a href="#3" id="3">Consequently, the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model.</a>
<a href="#4" id="4">Recall that the Wsabie Embedding model needs to estimate the label location in ℝ m for each frame.</a>
</body>
</html>