<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:148">
</head>
<body bgcolor="white">
<a href="#0" id="0">A second baseline was constructed by weighing the probabilities from the translation table directly with the L2 language model described earlier.</a>
<a href="#1" id="1">It adds a LM component to the MLF baseline.</a>
<a href="#2" id="2">This LM baseline allows the comparison of classification through L1 fragments in an L2 context, with a more traditional L2 context modelling (i.e., target language modelling) which is also customary in MT decoders.</a>
<a href="#3" id="3">Computing this baseline is done in the same fashion as previously illustrated in Equation 1 , where s ⁢ c ⁢ o ⁢ r ⁢ e T then represents the normalised p ( t s ) score from the phrase-translation table rather than the class probability from the classifier.</a>
<a href="#4" id="4">In this study we have shown the feasibility of a classifier-based translation assistance system in which L1 fragments are translated in an L2 context, in which the classifier experts are built individually per word or phrase.</a>
</body>
</html>