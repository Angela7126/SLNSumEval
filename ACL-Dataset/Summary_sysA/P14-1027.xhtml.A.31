<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:165">
</head>
<body bgcolor="white">
<a href="#0" id="0">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝗌𝟥.</a>
<a href="#1" id="1">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝟥.</a>
<a href="#2" id="2">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝟥.</a>
<a href="#3" id="3">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝟥.</a>
<a href="#4" id="4">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝗌𝟣.</a>
<a href="#5" id="5">𝖥𝗎𝗇𝖼𝖶𝗈𝗋𝖽𝟣.</a>
<a href="#6" id="6">Section 4 explains how a learner could use Bayesian model selection to determine that function words appear on the left periphery in English by comparing the posterior probability of the data under our “ function word ” Adaptor Grammar to that obtained using a grammar which is identical except that rules ( 22 – 24 ) are replaced with the mirror-image rules in which “ function words ” are attached to the right periphery.</a>
<a href="#7" id="7">As noted earlier, the “ function word ” model generates function words via adapted nonterminals other than the 𝖶𝗈𝗋𝖽 category.</a>
<a href="#8" id="8">In order to better understand just how the model works, we give the 5 most frequent words in each word category found during 8 MCMC runs of the left-peripheral “ function word ” grammar above.</a>
<a href="#9" id="9">This paper showed that the word segmentation accuracy of a state-of-the-art Adaptor Grammar model is significantly improved by extending it so that it explicitly models some properties of function words.</a>
</body>
</html>