<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:152">
</head>
<body bgcolor="white">
<a href="#0" id="0">Liu et al.</a>
<a href="#1" id="1">2013 ) apply DNN to SMT decoding, but not in a recursive manner.</a>
<a href="#2" id="2">A feature is learnt via a one-hidden-layer neural network, and the embedding of words in the phrase pairs are used as the input vector.</a>
<a href="#3" id="3">Our model generates the representation of a translation pair based on its child nodes.</a>
<a href="#4" id="4">Li et al.</a>
<a href="#5" id="5">2013 ) also generate the representation of phrase pairs in a recursive way.</a>
<a href="#6" id="6">In their work, the representation is optimized to learn a distortion model using recursive neural network, only based on the representation of the child nodes.</a>
<a href="#7" id="7">Our R 2 NN is used to model the end-to-end translation process, with recurrent global information added.</a>
<a href="#8" id="8">We also explore phrase pair embedding method to model translation confidence directly, which is introduced in Section 5.</a>
<a href="#9" id="9">In this paper, we propose a Recursive Recurrent Neural Network(R 2 NN) to combine the recurrent neural network and recursive neural network.</a>
</body>
</html>