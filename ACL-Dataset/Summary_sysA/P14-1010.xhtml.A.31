<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:128">
</head>
<body bgcolor="white">
<a href="#0" id="0">Like us, Luong et al.</a>
<a href="#1" id="1">2010 ) tune on unsegmented references, 1 1 Tuning on unsegmented references does not require substantial modifications to the standard SMT pipeline.</a>
<a href="#2" id="2">For example, Badr et al.</a>
<a href="#3" id="3">2008 ) also tune on unsegmented references by simply desegmenting SMT output before MERT collects sufficient statistics for BLEU and translate with both segmented and unsegmented language models for English-to-Finnish translation.</a>
<a href="#4" id="4">However, they adopt a scheme of word-boundary-aware morpheme-level phrase extraction, meaning that target phrases include only complete words, though those words are segmented into morphemes.</a>
<a href="#5" id="5">This enables full decoder integration, where we do n -best and lattice re-ranking.</a>
<a href="#6" id="6">But it also comes at a substantial cost when target phrases include only complete words, the system can only generate word forms that were seen during training.</a>
</body>
</html>