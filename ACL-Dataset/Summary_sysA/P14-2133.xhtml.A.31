<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:99">
</head>
<body bgcolor="white">
<a href="#0" id="0">It has been less clear how (and indeed whether) word embeddings in and of themselves are useful for constituency parsing.</a>
<a href="#1" id="1">With the goal of exploring how much useful syntactic information is provided by unsupervised word embeddings, we have presented three variations on a state-of-the-art parsing model, with extensions to the out-of-vocabulary model, lexicon, and feature set.</a>
<a href="#2" id="2">Evaluation of these modified parsers revealed modest gains on extremely small training sets, which quickly vanish as training set size increases.</a>
<a href="#3" id="3">Thus, at least restricted to phenomena which can be explained by the experiments described here, our results are consistent with two claims.</a>
</body>
</html>