<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:186">
</head>
<body bgcolor="white">
<a href="#0" id="0">This model memoises (i.e.,, learns) both the individual “ function words ” and the sequences of “ function words ” that modify the 𝖢𝗈𝗅𝗅𝗈𝖼𝟣 - 𝖢𝗈𝗅𝗅𝗈𝖼𝟥 constituents.</a>
<a href="#1" id="1">This means that “ function words ” are memoised independently of the “ content words ” that 𝖶𝗈𝗋𝖽 expands to; i.e.,, the model learns distinct “ function word ” and “ content word ” vocabularies.</a>
<a href="#2" id="2">Section 4 explains how a learner could use Bayesian model selection to determine that function words appear on the left periphery in English by comparing the posterior probability of the data under our “ function word ” Adaptor Grammar to that obtained using a grammar which is identical except that rules ( 22 – 24 ) are replaced with the mirror-image rules in which “ function words ” are attached to the right periphery.</a>
<a href="#3" id="3">As noted earlier, the “ function word ” model generates function words via adapted nonterminals other than the 𝖶𝗈𝗋𝖽 category.</a>
<a href="#4" id="4">This paper showed that the word segmentation accuracy of a state-of-the-art Adaptor Grammar model is significantly improved by extending it so that it explicitly models some properties of function words.</a>
</body>
</html>