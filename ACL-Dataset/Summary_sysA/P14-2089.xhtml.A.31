<html>
<head>
<meta name="TextLength" content="SENT_NUM:3, WORD_NUM:68">
</head>
<body bgcolor="white">
<a href="#0" id="0">We propose a new training objective for learning word embeddings that incorporates prior knowledge.</a>
<a href="#1" id="1">Our model builds on word2vec [] , a neural network based language model that learns word embeddings by maximizing the probability of raw text.</a>
<a href="#2" id="2">We extend the objective to include prior knowledge about synonyms from semantic resources; we consider both the Paraphrase Database [] and WordNet [] , which annotate semantic relatedness between words.</a>
</body>
</html>