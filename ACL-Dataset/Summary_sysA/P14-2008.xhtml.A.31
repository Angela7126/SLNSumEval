<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:150">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our initial experiments simply extend those of Chen et al.</a>
<a href="#1" id="1">2012 ) (and others who have used MDSD) by adding another domain, citations.</a>
<a href="#2" id="2">We train on each of the domains from the MDSD – books, dvd, electronics, and kitchen – and test on the citation data.</a>
<a href="#3" id="3">We split the labeled data 80/20 following Blitzer et al.</a>
<a href="#4" id="4">2007 ) (cf.</a>
<a href="#5" id="5">Chen et al.</a>
<a href="#6" id="6">2012 ) train on all “ labeled ” data and test on the “ unlabeled ” data.</a>
<a href="#7" id="7">These experiments should help answer two questions does a larger amount of training data, even if out of domain, improve citation classification; and how well do the different product domains generalize to citations (i.e.,, which domains are most similar to citations.</a>
<a href="#8" id="8">Robust citation classification has been hindered by the relative lack of annotated data.</a>
<a href="#9" id="9">In this paper we successfully use a large, out-of-domain, annotated corpus to improve the citation polarity classification.</a>
</body>
</html>