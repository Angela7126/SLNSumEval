<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:144">
</head>
<body bgcolor="white">
<a href="#0" id="0">This is achieved by means of a simple neural network trained to project image-extracted feature vectors to text-based vectors through a hidden layer that can be interpreted as a cross-modal semantic space.</a>
<a href="#1" id="1">For ESP, given the size and amount of noise in this dataset, we build vectors for visual concepts , by normalizing and summing the BoVW vectors of all the images that have the relevant concept as a tag.</a>
<a href="#2" id="2">Note that relevant literature [ 41 ] has emphasized the importance of learners self-generating multiple views when faced with new objects.</a>
<a href="#3" id="3">Thus, our multiple-image assumption should not be considered as problematic in the current setup.</a>
<a href="#4" id="4">The analysis demonstrates that, although prior knowledge about categories was not explicitly used to train the network, the latter induced an organization of concepts into superordinate categories in which the hidden layer acts as a cross-modal concept categorization/organization system.</a>
</body>
</html>