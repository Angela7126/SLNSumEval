<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:143">
</head>
<body bgcolor="white">
<a href="#0" id="0">Word embedding is used as the input to learn translation confidence score, which is combined with commonly used features in the conventional log-linear model.</a>
<a href="#1" id="1">So as to model the translation confidence for a translation phrase pair, we initialize the phrase pair embedding by leveraging the sparse features and recurrent neural network.</a>
<a href="#2" id="2">We also explore phrase pair embedding method to model translation confidence directly, which is introduced in Section 5.</a>
<a href="#3" id="3">In this section, we split the phrase pair embedding into two parts to model the translation confidence directly translation confidence with sparse features and translation confidence with recurrent neural network.</a>
<a href="#4" id="4">We first get two translation confidence vectors separately using sparse features and recurrent neural network, and then concatenate them to be the phrase pair embedding.</a>
<a href="#5" id="5">We use recurrent neural network to generate two smoothed translation confidence scores based on source and target word embeddings.</a>
</body>
</html>