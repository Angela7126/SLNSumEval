<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:160">
</head>
<body bgcolor="white">
<a href="#0" id="0">We propose a three-step semi-supervised training approach to optimizing the parameters of R 2 NN, which includes recursive auto-encoding for unsupervised pre-training, supervised local training based on the derivation trees of forced decoding, and supervised global training using early update strategy.</a>
<a href="#1" id="1">So as to model the translation confidence for a translation phrase pair, we initialize the phrase pair embedding by leveraging the sparse features and recurrent neural network.</a>
<a href="#2" id="2">The sparse features are phrase pairs in translation table, and recurrent neural network is utilized to learn a smoothed translation score with the source and target side information.</a>
<a href="#3" id="3">However, some global information , which cannot be generated by the child representations, is crucial for SMT performance, such as language model score and distortion model score.</a>
<a href="#4" id="4">So as to integrate such global information, and also keep the ability to generate tree structure, we combine the recurrent neural network and the recursive neural network to be a recursive recurrent neural network (R 2 NN.</a>
</body>
</html>