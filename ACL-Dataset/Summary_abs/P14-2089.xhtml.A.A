<html>
 <head>
  <meta content="SENT_NUM: 3, WORD_NUM: 71" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   Word embeddings learned on unlabeled data are a popular tool in semantics, but may not capture the desired semantics.
  </a>
  <a href="#1" id="1">
   We propose a new learning objective that incorporates both a neural language model objective [] and prior knowledge from semantic resources to learn improved lexical semantic embeddings.
  </a>
  <a href="#2" id="2">
   We demonstrate that our embeddings improve over those learned solely on raw text in three settings language modeling, measuring semantic similarity, and predicting human judgements.
  </a>
 </body>
</html>