<html>
 <head>
  <meta content="SENT_NUM: 6, WORD_NUM: 136" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   We aim to improve spoken term detection performance by incorporating contextual information beyond traditional N-gram language models.
  </a>
  <a href="#1" id="1">
   Instead of taking a broad view of topic context in spoken documents, variability of word co-occurrence statistics across corpora leads us to focus instead the on phenomenon of word repetition within single documents.
  </a>
  <a href="#2" id="2">
   We show that given the detection of one instance of a term we are more likely to find additional instances of that term in the same document.
  </a>
  <a href="#3" id="3">
   We leverage this burstiness of keywords by taking the most confident keyword hypothesis in each document and interpolating with lower scoring hits.
  </a>
  <a href="#4" id="4">
   We then develop a principled approach to select interpolation weights using only the ASR training data.
  </a>
  <a href="#5" id="5">
   Using this re-weighting approach we demonstrate consistent improvement in the term detection performance across all five languages in the BABEL program.
  </a>
 </body>
</html>