<html>
 <head>
  <meta content="SENT_NUM: 5, WORD_NUM: 120" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   We present a novel approach for inducing unsupervised dependency parsers for languages that have no labeled training data, but have translated text in a resource-rich language.
  </a>
  <a href="#1" id="1">
   We train probabilistic parsing models for resource-poor languages by transferring cross-lingual knowledge from resource-rich language with entropy regularization.
  </a>
  <a href="#2" id="2">
   Our method can be used as a purely monolingual dependency parser, requiring no human translations for the test data, thus making it applicable to a wide range of resource-poor languages.
  </a>
  <a href="#3" id="3">
   We perform experiments on three Data sets Version 1.0 and version 2.0 of Google Universal Dependency Treebanks and Treebanks from CoNLL shared-tasks, across ten languages.
  </a>
  <a href="#4" id="4">
   We obtain state-of-the art performance of all the three data sets when compared with previously studied unsupervised and projected parsing systems.
  </a>
 </body>
</html>