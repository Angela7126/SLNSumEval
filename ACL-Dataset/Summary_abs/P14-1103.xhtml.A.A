<html>
 <head>
  <meta content="SENT_NUM: 5, WORD_NUM: 120" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   We present a method to jointly learn features and weights directly from distributional data in a log-linear framework.
  </a>
  <a href="#1" id="1">
   Specifically, we propose a non-parametric Bayesian model for learning phonological markedness constraints directly from the distribution of input-output mappings in an Optimality Theory (OT) setting.
  </a>
  <a href="#2" id="2">
   The model uses an Indian Buffet Process prior to learn the feature values used in the log-linear method, and is the first algorithm for learning phonological constraints without presupposing constraint structure.
  </a>
  <a href="#3" id="3">
   The model learns a system of constraints that explains observed data as well as the phonologically-grounded constraints of a standard analysis, with a violation structure corresponding to the standard constraints.
  </a>
  <a href="#4" id="4">
   These results suggest an alternative data-driven source for constraints instead of a fully innate constraint set.
  </a>
 </body>
</html>