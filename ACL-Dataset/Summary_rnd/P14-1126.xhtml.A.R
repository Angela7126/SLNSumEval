<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:116">
</head>
<body bgcolor="white">
<a href="#0" id="0">Obviously, bilingual treebanks are much more difficult to acquire than the resources required in our scenario, since the labeled training data and the parallel text in our case are completely separated.</a>
<a href="#1" id="1">Table 2 shows the number of tokens in the parallel data used in the experiments.</a>
<a href="#2" id="2">So it is not directly comparable to our work.</a>
<a href="#3" id="3">For comparison with previous studies, nevertheless, we also run experiments on CoNLL treebanks (see Section 4.4 for more details).</a>
<a href="#4" id="4">Maximum likelihood training chooses parameters such that the log-likelihood L⁢(λ) is maximized.</a>
<a href="#5" id="5">To make a thorough empirical comparison with previous studies, we also evaluate our system without unlabeled data (-U) on treebanks from CoNLL shared task on dependency parsing [6, 38] .</a>
</body>
</html>