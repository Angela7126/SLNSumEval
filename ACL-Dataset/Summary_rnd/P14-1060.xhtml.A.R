<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:126">
</head>
<body bgcolor="white">
<a href="#0" id="0">We observe that this model has a very high precision (since many token sequences marked as motifs would recur in similar contexts, and would thus have the same motif boundaries).</a>
<a href="#1" id="1">Ideally, it fragments a given sentence into non-overlapping, semantically meaningful, empirically frequent contiguous sub-units or motifs.</a>
<a href="#2" id="2">Supervised learning: In the supervised case, optimal state sequences ùê≤(ùê§) are fully observed for the training set.</a>
<a href="#3" id="3">A small fraction of the training split was set apart for development and validation.</a>
<a href="#4" id="4">This paper is organized as follows: In Section 2, we briefly review related work in the domain of compositional distributional semantics, and motivate our formulation.</a>
<a href="#5" id="5">While there is considerable variety in approaches and formulations, existing approaches for phrasal level and sentential semantics can broadly be partitioned into two categories.</a>
</body>
</html>