<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:150">
</head>
<body bgcolor="white">
<a href="#0" id="0">In Figure 1 , we compare the Proposed cross-domain sentiment classification method (Section 4.2 ) against several baselines and the current state-of-the-art methods.</a>
<a href="#1" id="1">3 Distribution Prediction 3.1 In-domain Feature Vector Construction</a>
<a href="#2" id="2">Prior knowledge of the sentiment of words, such as sentiment lexicons, has been incorporated into cross-domain sentiment classification.</a>
<a href="#3" id="3">The L-BFGS [] method is used to train the CRF and logistic regression models.</a>
<a href="#4" id="4">Next, we train a binary classification model, θ→ , using those feature vectors.</a>
<a href="#5" id="5">Note that our proposed distribution prediction method can be applied to numerous other NLP tasks that involve sequence labelling and document classification.</a>
<a href="#6" id="6">Our proposed cross-domain word distribution prediction method is unsupervised in the sense that it does not require any labeled data in either of the two steps.</a>
<a href="#7" id="7">The matrices, 𝚲 , 𝚪 , \mat⁢P , and \mat⁢Q are constructed respectively by arranging λ→l , γ→l , p→l , and q→l vectors as columns.</a>
</body>
</html>