<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:173">
</head>
<body bgcolor="white">
<a href="#0" id="0">Because NLP models typically treat sentences independently, NLP problems have long been seen as “embarrassingly parallel” – large corpora can be processed arbitrarily fast by simply sending different sentences to different machines.</a>
<a href="#1" id="1">Now we turn to the algorithmic and architectural changes in our approach.</a>
<a href="#2" id="2">For instance, one might want to maximize the expected number of correct constituents [3] , or the expected rule counts [10, 9] .</a>
<a href="#3" id="3">It is of course important verify the correctness of our system; one easy way to do so is to examine parsing accuracy, as compared to the original Berkeley parser.</a>
<a href="#4" id="4">Clustering using this method is labeled ‘Parent’ in Table 1 .</a>
<a href="#5" id="5">GPUs work by executing thousands of threads at once, but impose the constraint that large blocks of threads must be executing the same instructions in lockstep, differing only in their input data.</a>
<a href="#6" id="6">The resulting speed is 187.5 sentences per second, labeled in Table 1 as row labeled ‘Reimpl’ with ‘Labeled, Coarse’ pruning.</a>
<a href="#7" id="7">This particular MBR algorithm has the advantage that it is relatively straightforward to implement.</a>
</body>
</html>