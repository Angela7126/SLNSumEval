<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:112">
</head>
<body bgcolor="white">
<a href="#0" id="0">For each position j , there is a weight matrix ùêñ(j)‚àà‚ÑùH√óD , which is used to model the interaction between the hidden layer and the word projection in position j .</a>
<a href="#1" id="1">In this work, we investigate both strategies and give empirical comparisons in the cross-domain setting.</a>
<a href="#2" id="2">!‚Äù are collapsed into one.</a>
<a href="#3" id="3">The tagging performance is evaluated according to the official evaluation metrics of SANCL 2012.</a>
<a href="#4" id="4">However, for the email domain, RBM-W yields much smaller improvement compared with RBM-E, and vice versa.</a>
<a href="#5" id="5">In this section, we give some background on RBMs and then show how they can be used to learn representations of the web text.</a>
<a href="#6" id="6">This result is to some degree expected.</a>
</body>
</html>