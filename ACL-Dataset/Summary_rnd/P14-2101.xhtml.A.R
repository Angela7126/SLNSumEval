<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:181">
</head>
<body bgcolor="white">
<a href="#0" id="0">3 Experimental Setup 3.1 Dataset</a>
<a href="#1" id="1">We evaluated these summarisation approaches with the ROUGE-1 method [17] , a widely used summarisation evaluation metric that correlates well with human evaluation [18] .</a>
<a href="#2" id="2">More recent approaches have explored the use of external sources (e.g. Wikipedia, WordNet) for supporting the automatic labelling of topics by deriving candidate labels by means of lexical [14, 21, 22] or graph-based [12] algorithms applied on these sources.</a>
<a href="#3" id="3">To alleviate this issue here, we followed the distribution similarity approach, which has been widely applied in the automatic generation of gold standards ( GS s) for summary evaluations [7, 16, 19, 20] .</a>
<a href="#4" id="4">For each word n‚àà{1..‚Å¢Nd} in document d :</a>
<a href="#5" id="5">2 Methodology</a>
<a href="#6" id="6">They then built a Support Vector Regression (SVR) model for ranking the label candidates.</a>
<a href="#7" id="7">This experiment shows that frequency based summarisation techniques outperform graph-based and relevance based summarisation techniques for generating topic labels that improve upon the top-terms baseline, without relying on external sources.</a>
<a href="#8" id="8">In this case the document frequency is computed as the number of times a word appears in a micropost from the collection ùíû .</a>
</body>
</html>