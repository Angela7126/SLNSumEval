<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:173">
</head>
<body bgcolor="white">
<a href="#0" id="0">This model learns the syntax and semantics of the negator’s argument with a recursive neural network.</a>
<a href="#1" id="1">We will show that this simple modification improves the fitting performance statistically significantly.</a>
<a href="#2" id="2">The training of RNTN uses conventional forward-backward propagation.</a>
<a href="#3" id="3">Discriminating negators The results in Table 1 has demonstrated the benefit of discriminating negators.</a>
<a href="#4" id="4">More specifically, MAE is calculated as: M⁢A⁢E=1N⁢∑⟨wn,w→⟩|(s^⁢(wn,w→)-s⁢(wn,w→))| , where s^⁢(wn,w→) denotes the gold sentiment value and s⁢(wn,w→) the predicted one for the pair ⟨wn,w→⟩ , and N is the total number of test instances.</a>
<a href="#5" id="5">Figure 1 illustrates the effect of a common list of negators on sentiment as observed on the Stanford Sentiment Treebank.</a>
<a href="#6" id="6">For each negator, a 95% confidence interval is shown by the boxes in the figure, which is calculated with the bootstrapping resampling method.</a>
<a href="#7" id="7">We then propose to extend them to consider lexical information of the negators themselves.</a>
<a href="#8" id="8">With the new matrix and tensor, we then have θ=(V,Vs⁢e⁢n,W,Ws⁢e⁢n,Wl⁢a⁢b⁢e⁢l,L) as the PSTN model’s parameters.</a>
<a href="#9" id="9">Similarly, for the derivative of each slice k(k=1,…,d) of the Vs⁢e⁢n tensor, we have the following:</a>
</body>
</html>