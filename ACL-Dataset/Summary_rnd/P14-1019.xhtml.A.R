<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:129">
</head>
<body bgcolor="white">
<a href="#0" id="0">The procedure is described in Figure 2 with a graphic illustration in Figure 3 .</a>
<a href="#1" id="1">In this view, the use of more expressive scoring functions leads to more challenging combinatorial problems of finding the maximizing parse.</a>
<a href="#2" id="2">One shortcoming of the Gibbs sampler is that it only changes one variable (arc) at a time.</a>
<a href="#3" id="3">For both languages, the tree score improves over time.</a>
<a href="#4" id="4">Experimental Details Following Koo and Collins (2010) , we always first train a first-order pruner.</a>
<a href="#5" id="5">•</a>
<a href="#6" id="6">Let c⁢(tg,tp) be the count when the gold tag is tg and the predicted one is tp .</a>
<a href="#7" id="7">One such sampling algorithm is the random walk sampler of Wilson (1996) .</a>
<a href="#8" id="8">Because the number of alternatives is small, the scoring function could in principle involve arbitrary (global) features of parse trees.</a>
</body>
</html>