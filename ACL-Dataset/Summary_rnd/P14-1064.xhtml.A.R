<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:130">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our method obtained much of the gains achieved by the supervised baseline approach that utilizes the noisy parallel data in conjunction with the NIST-provided parallel data (“Baseline+Noisy”), but with fewer assumptions on the nature of the corpora (monolingual vs. parallel).</a>
<a href="#1" id="1">In this set of experiments, we examined if the improvements in § 3.2 can be explained primarily through the extraction of language model characteristics during the semi-supervised learning phase, or through orthogonal pieces of evidence.</a>
<a href="#2" id="2">After graph propagation, each unlabeled phrase is labeled with a categorical distribution over the set of translation candidates defined in § 2.3 .</a>
<a href="#3" id="3">Co-occurrence counts for each feature (context word) are accumulated over the monolingual corpus, and these counts are converted to pointwise mutual information (PMI) values, as is standard practice when computing distributional similarities.</a>
</body>
</html>