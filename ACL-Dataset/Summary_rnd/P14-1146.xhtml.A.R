<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:178">
</head>
<body bgcolor="white">
<a href="#0" id="0">Instead of directly using the distant-supervised data as training set, Liu et al. [25] adopt the tweets with emoticons to smooth the language model and Hu et al. [20] incorporate the emotional signals into an unsupervised learning framework for Twitter sentiment classification.</a>
<a href="#1" id="1">NRC-ngram refers to the feature set of NRC leaving out ngram features.</a>
<a href="#2" id="2">We empirically set the window size as 3, the embedding length as 50, the length of hidden layer as 20 and the learning rate of AdaGrad as 0.1 for all baseline and our models.</a>
<a href="#3" id="3">An intuitive solution to integrate the sentiment information is predicting the sentiment distribution of text based on input ngram.</a>
<a href="#4" id="4">We can see that SSWE u performs better when Î± is in the range of [0.5, 0.6], which balances the syntactic context and sentiment information.</a>
<a href="#5" id="5">A typical case in sentiment analysis is that the composed phrase and multiword expression may have a different sentiment polarity than the individual words it contains, such as not [bad] and [great] deal of (the word in the bracket has different sentiment polarity with the ngram).</a>
</body>
</html>