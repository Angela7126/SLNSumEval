<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:150">
</head>
<body bgcolor="white">
<a href="#0" id="0">The language model is a trigram-based back-off language model with Kneser-Ney smoothing, computed using SRILM [] and trained on the same training data as the translation model.</a>
<a href="#1" id="1">Several automated metrics exist for the evaluation of L2 system output against the L2 reference output in the test set.</a>
<a href="#2" id="2">In this study we have shown the feasibility of a classifier-based translation assistance system in which L1 fragments are translated in an L2 context, in which the classifier experts are built individually per word or phrase.</a>
<a href="#3" id="3">Step 4 is effectively a filter: two thresholds can be configured to discard weak alignments, i.e. those with low probabilities, from the phrase-translation table so that only strong couplings make it into the generated set.</a>
<a href="#4" id="4">Here X indicates the left context size and Y the right context size.</a>
<a href="#5" id="5">6.1 Context optimisation</a>
<a href="#6" id="6">This is done using the scripts provided by the Statistical Machine Translation system Moses [] .</a>
</body>
</html>