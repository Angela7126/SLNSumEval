<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:166">
</head>
<body bgcolor="white">
<a href="#0" id="0">The annotator verbally states the sentiment of this sentence, before (s)he can proceed to the next.</a>
<a href="#1" id="1">For both domains, we observe a weak yet negative correlation which suggests that the perception of difficulty by the classifiers are in line with that of humans, as captured through SAC.</a>
<a href="#2" id="2">Eye-tracking annotations have been used to study the cognitive aspects of language processing tasks like translation by Dragsted2010 and sense disambiguation by Joshi et al.2011 .</a>
<a href="#3" id="3">The actual prediction of SAC is done using linguistic features alone.</a>
<a href="#4" id="4">We carry out a 5-fold cross validation for both in-domain and cross-domain settings, to validate that the regressor does not overfit.</a>
<a href="#5" id="5">Measuring annotation complexity is beneficial in annotation crowdsourcing.</a>
<a href="#6" id="6">It may be thought that inter-annotator agreement (IAA) provides implicit annotation: the higher the agreement, the easier the piece of text is for sentiment annotation.</a>
<a href="#7" id="7">This experiment results in a data set of 1059 sentences with a fixation duration recorded for each sentence-annotator pair The multi-rater kappa IAA for sentiment annotation is 0.686.</a>
</body>
</html>