<html>
 <head>
  <meta content="SENT_NUM:8, WORD_NUM:150" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   We have introduced a novel generalized language model as the systematic combination of skip n -grams and modified Kneser-Ney smoothing.
  </a>
  <a href="#1" id="1">
   The main strength of our approach is the combination of a simple and elegant idea with an an empirically convincing result.
  </a>
  <a href="#2" id="2">
   Mathematically one can see that the GLM includes the standard language model with modified Kneser-Ney smoothing as a sub model and is consequently a real generalization.
  </a>
  <a href="#3" id="3">
   In an empirical evaluation, we have demonstrated that for higher orders the GLM outperforms MKN for all test cases.
  </a>
  <a href="#4" id="4">
   The relative improvement in perplexity is up to 12.7 % for large data sets.
  </a>
  <a href="#5" id="5">
   GLMs also performs particularly well on small and sparse sets of training data.
  </a>
  <a href="#6" id="6">
   On a very small training data set we observed a reduction of perplexity by 25.7 %.
  </a>
  <a href="#7" id="7">
   Our experiments underline that the generalized language models overcome in particular the weaknesses of modified Kneser-Ney smoothing on sparse training data.
  </a>
 </body>
</html>