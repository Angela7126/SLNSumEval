<html>
 <head>
  <meta content="SENT_NUM:8, WORD_NUM:207" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   In this paper we have presented Citation Resolution an evaluation method for context-based citation recommendation (CBCR) systems.
  </a>
  <a href="#1" id="1">
   Our method exploits the implicit human relevance judgements found in existing scientific articles and so does not require purpose-specific human annotation.
  </a>
  <a href="#2" id="2">
   We have employed Citation Resolution to test three approaches to building a document representation for a CBCR system internal (based on the contents of the document), external (based on the surrounding contexts to citations to that document) and mixed (a mixture of the two.
  </a>
  <a href="#3" id="3">
   Our evaluation shows that.
  </a>
  <a href="#4" id="4">
   1) using chunks of a document (passages) as its representation yields better results that using its full text, 2) external methods obtain higher scores than internal ones, and 3) mixed methods yield better results than either in isolation.
  </a>
  <a href="#5" id="5">
   We intend to investigate more sophisticated ways of document representation and of extracting a citation s context.
  </a>
  <a href="#6" id="6">
   Our ultimate goal is not just to suggest to the author documents that are relevant to a specific chunk of the paper (sentence, paragraph, etc.), but to do so with attention to rhetorical structure and thus to citation function.
  </a>
  <a href="#7" id="7">
   We also aim to apply our evaluation to other document collections in different scientific domains in order to test to what degree these results can be generalized.
  </a>
 </body>
</html>