<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:259">
</head>
<body bgcolor="white">
<a href="#0" id="0">The results of the second experiment reveal that the most indicative bigrams are quite similar across different language sets.</a>
<a href="#1" id="1">For example, if we train the classifier using words as features, with values representing their frequency relative to the length of the document, the features corresponding to the word China might receive the following weights.</a>
<a href="#2" id="2">These weights indicate that the word provides strong positive evidence for Chinese as L1, as opposed to the other four languages.</a>
<a href="#3" id="3">In this section, we describe two experiments aimed at quantifying the importance of the discriminative words and the indicative character bigrams that are identified by Algorithm 2.</a>
<a href="#4" id="4">We see a statistically significant drop in the accuracy of the classifier with respect to the baseline in all sets except T3.</a>
<a href="#5" id="5">The words that are identified as the most discriminative include function words, punctuation, very common content words, and the toponymic terms.</a>
<a href="#6" id="6">Specifically, we discard all tokens that correspond to 100 word types that have the same or slightly higher frequency as the discriminative words.</a>
<a href="#7" id="7">However, the fact that the two bigrams are also on the list for the I2 set, which does not include these languages, suggests that their importance is mostly due to the function words.</a>
<a href="#8" id="8">In the first experiment, we showed that the removal of the 100 most discriminative words from the training data results in a significant drop in the accuracy of the classifier that is based exclusively on character bigrams.</a>
<a href="#9" id="9">In the second experiment, we found that the majority of the most indicative character bigrams are shared among different language sets.</a>
</body>
</html>