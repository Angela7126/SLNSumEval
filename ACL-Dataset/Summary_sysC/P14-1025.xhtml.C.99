<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:290">
</head>
<body bgcolor="white">
<a href="#0" id="0">Such an approach requires knowledge of predominant senses; however, word sense distributions — and predominant senses too — vary from corpus to corpus.</a>
<a href="#1" id="1">Therefore, methods for automatically learning predominant senses and sense distributions for specific corpora are required [ 12 ].</a>
<a href="#2" id="2">There has been a considerable amount of research on representing word senses and disambiguating usages of words in context ( wsd ) as, in order to produce computational systems that understand and produce natural language, it is essential to have a means of representing and disambiguating word sense wsd algorithms require word sense information to disambiguate token instances of a given ambiguous word, e.g., in the form of sense definitions [] , semantic relationships [ 17 ] or annotated data [ 20 ].</a>
<a href="#3" id="3">One extremely useful piece of information is the word sense prior or expected word sense frequency distribution.</a>
<a href="#4" id="4">In predominant sense acquisition, the task is to learn, for each target lemma, the most frequently occurring word sense in a particular domain or corpus, relative to a predefined sense inventory.</a>
<a href="#5" id="5">The authors evaluated their method in terms of wsd accuracy over a given corpus, based on assigning all instances of a target word with the predominant sense learned from that corpus.</a>
<a href="#6" id="6">We refer to these two datasets as ukWaC and Twitter henceforth.</a>
<a href="#7" id="7">To apply our method to the two datasets, we use HDP-WSIto train a model for each target noun, based on the combined set of usages of that lemma in each of the two background corpora, namely the original Twitter crawl that gave rise to the Twitter dataset, and all of ukWaC.</a>
<a href="#8" id="8">As in Section 4 , we evaluate in terms of wsd accuracy (Table 4 ) and JS divergence over the gold-standard sense distribution (Table 5.</a>
</body>
</html>