<html>
<head>
<meta name="TextLength" content="SENT_NUM:2, WORD_NUM:85">
</head>
<body bgcolor="white">
<a href="#0" id="0">These experiments should help answer two questions does a larger amount of training data, even if out of domain, improve citation classification; and how well do the different product domains generalize to citations (i.e.,, which domains are most similar to citations.</a>
<a href="#1" id="1">Our approach achieves similar macro- F 1 on only the citation sentence, but using a different corpus we have shown that you can improve citation polarity classification by leveraging large amounts of annotated data from other domains and using a simple set of features.</a>
</body>
</html>