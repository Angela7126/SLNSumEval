<html>
<head>
<meta name="TextLength" content="SENT_NUM:12, WORD_NUM:308">
</head>
<body bgcolor="white">
<a href="#0" id="0">Here, we present a novel formulation for a neural network joint model (NNJM), which augments the NNLM with a source context window.</a>
<a href="#1" id="1">Specifically, we introduce a novel formulation for a neural network joint model (NNJM), which augments an n -gram target language model with an m -word source window.</a>
<a href="#2" id="2">The NNJM features produce an improvement of +3.0 BLEU on top of a baseline that is already better than the 1st place MT12 result and includes a powerful NNLM.</a>
<a href="#3" id="3">Additionally, on top of a simpler decoder equivalent to Chiang ’ s [ 5 ] original Hiero implementation, our NNJM features are able to produce an improvement of +6.3 BLEU – as much as all of the other features in our strong baseline system combined.</a>
<a href="#4" id="4">An example of the NNJM context model for a Chinese-English parallel sentence is given in Figure 1.</a>
<a href="#5" id="5">However, note that there are only 3 possible positions for each target word, and 11 for each source word.</a>
<a href="#6" id="6">The decoding cost is based on a measurement of ∼ 1200 unique NNJM lookups per source word for our Arabic-English system.</a>
<a href="#7" id="7">One issue with the S2T NNJM is that the probability is computed over every target word, so it does not explicitly model NULL-aligned source words.</a>
<a href="#8" id="8">In order to assign a probability to every source word during decoding, we also train a neural network lexical translation model (NNLMT.</a>
<a href="#9" id="9">It is easy and computationally inexpensive to use this model in decoding, since only one neural network computation must be made for each source word.</a>
<a href="#10" id="10">We can see that going from the standard model to the pre-computed model only reduces the BLEU improvement from +6.4 to +6.1, while increasing the NNJM lookup speed by a factor of 10,000x.</a>
<a href="#11" id="11">In Table 2 we showed that the cost of unique lookups for the pre-computed NNJM is only ∼ 0.001 seconds per source word.</a>
</body>
</html>