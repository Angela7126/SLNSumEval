<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:218">
</head>
<body bgcolor="white">
<a href="#0" id="0">Multi-modal models in which perceptual input is filtered according to our algorithm learn higher-quality semantic representations than previous approaches, resulting in a significant performance improvement of up to 17% in capturing the semantic similarity of concepts.</a>
<a href="#1" id="1">Since research has demonstrated the applicability of concreteness to a range of other NLP tasks [ 28 , 16 ] , it is important to examine the connection between image dispersion and concreteness in more detail.</a>
<a href="#2" id="2">To evaluate the effectiveness of image dispersion as a proxy for concreteness we evaluated our algorithm on a binary classification task based on the set of 100 concrete and 100 abstract concepts A âˆª C introduced in Section 2.</a>
<a href="#3" id="3">The importance of the visual modality is significantly greater when evaluating on pairs for which both concepts are classified as concrete than on pairs of two abstract concepts.</a>
<a href="#4" id="4">Image dispersion is also an effective predictor of concreteness on samples for which the abstract/concrete distinction is less clear.</a>
<a href="#5" id="5">On this more diverse sample, which reflects the range of concepts typically found in linguistic corpora, image dispersion is a particularly useful diagnostic for identifying the very abstract or very concrete concepts.</a>
<a href="#6" id="6">As Table 1 illustrates, the concepts with the lowest dispersion in this sample are, without exception, highly concrete, and the concepts of highest dispersion are clearly very abstract.</a>
</body>
</html>