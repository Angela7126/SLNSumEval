<html>
<head>
<meta name="TextLength" content="SENT_NUM:18, WORD_NUM:526">
</head>
<body bgcolor="white">
<a href="#0" id="0">Moreover, to compensate the lack of background knowledge in practical inference, we combine our framework with the idea of tree transformation [] , to propose a way of generating knowledge in logical representation from entailment rules [] , which are by now typically considered as syntactic rewriting rules.</a>
<a href="#1" id="1">We test our system on FraCaS [] and PASCAL RTE datasets [].</a>
<a href="#2" id="2">In this section we describe the idea of representing natural language semantics by DCS trees, and achieving inference by computing logical relations among the corresponding abstract denotations.</a>
<a href="#3" id="3">DCS trees has been proposed to represent natural language semantics with a structure similar to dependency trees [] (Figure 1.</a>
<a href="#4" id="4">Our solution is to redefine DCS trees without the aid of any databases, by considering each node of a DCS tree as a content word in a sentence (but may no longer be a table in a specific database), while each edge represents semantic relations between two words.</a>
<a href="#5" id="5">The labels on both ends of an edge, such as SUBJ (subject) and OBJ (object), are considered as semantic roles of the corresponding words 1 1 The semantic role ARG is specifically defined for denoting nominal predicate.</a>
<a href="#6" id="6">To formulate the database querying process defined by a DCS tree, we provide formal semantics to DCS trees by employing relational algebra [] for representing the query.</a>
<a href="#7" id="7">As described below, we represent meanings of sentences with abstract denotations , and logical relations among sentences are computed as relations among their abstract denotations.</a>
<a href="#8" id="8">Generally we admit projections onto multiple semantics roles, denoted by Π R where R is a set of semantic roles.</a>
<a href="#9" id="9">These are algebraic properties of abstract denotations, among which we choose a set of axioms that can be handled efficiently and enable most common types of inference seen in natural language.</a>
<a href="#10" id="10">We built an inference engine to perform logical inference on abstract denotations as above.</a>
<a href="#11" id="11">In this logical system, we treat abstract denotations as terms and statements as atomic sentences , which are far more easier to handle than first order predicate logic (FOL) formulas.</a>
<a href="#12" id="12">Furthermore, all implemented axioms are horn clauses, hence we can employ forward-chaining, which is very efficient.</a>
<a href="#13" id="13">A path is considered as joining two germs in a DCS tree, where a germ is defined as a specific semantic role of a node.</a>
<a href="#14" id="14">For example, Figure 5 shows DCS trees of the following sentences (a simplified pair from RTE2-dev.</a>
<a href="#15" id="15">Furthermore, since the on-the-fly knowledge is generated by transformed pairs of DCS trees, all contexts are preserved in Figure 6 , though the tree transformation can be seen as generated from the entailment rule “ X is blamed for death → X causes loss of life ” , the generated on-the-fly knowledge, as shown above the trees, only fires with the additional condition that X is a tropical storm and is Debby.</a>
<a href="#16" id="16">Hence, the process can also be used to generate knowledge from context sensitive rules [] , which are known to have higher quality [].</a>
<a href="#17" id="17">Since our system uses an off-the-shelf dependency parser, and semantic representations are obtained from simple rule-based conversion from dependency trees, there will be only one (right or wrong) interpretation in face of ambiguous sentences.</a>
</body>
</html>