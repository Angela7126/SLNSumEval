<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:306">
</head>
<body bgcolor="white">
<a href="#0" id="0">Unlike previous approaches to joint modeling [ 13 ] , our feature can be easily integrated into any statistical machine translation (SMT) decoder, which leads to substantially larger improvements than k -best rescoring only.</a>
<a href="#1" id="1">Additionally, on top of a simpler decoder equivalent to Chiang ’ s [ 5 ] original Hiero implementation, our NNJM features are able to produce an improvement of +6.3 BLEU – as much as all of the other features in our strong baseline system combined.</a>
<a href="#2" id="2">We also show strong improvements on the NIST OpenMT12 Chinese-English task, as well as the DARPA BOLT (Broad Operational Language Translation) Arabic-English and Chinese-English conditions.</a>
<a href="#3" id="3">We chose these values for the hidden layer size, vocabulary size, and source window size because they seemed to work best on our data sets – larger sizes did not improve results, while smaller sizes degraded results.</a>
<a href="#4" id="4">The baseline used in the last section is a highly-engineered research system, which uses a wide array of features that were refined over a number of years, and some of which require linguistic resources.</a>
<a href="#5" id="5">Because of this, the baseline BLEU scores are much higher than a typical MT system – especially a real-time, production engine which must support many language pairs.</a>
<a href="#6" id="6">Therefore, we also present results using a simpler version of our decoder which emulates Chiang ’ s original Hiero implementation [ 5 ].</a>
<a href="#7" id="7">Le ’ s basic procedure is to re-order the source to match the linear order of the target, and then segment the hypothesis into minimal bilingual phrase pairs.</a>
<a href="#8" id="8">Le ’ s model also uses minimal phrases rather than being purely lexicalized, which has two main downsides a) a number of complex, hand-crafted heuristics are required to define phrase boundaries, which may not transfer well to new languages, (b) the effective vocabulary size is much larger, which substantially increases data sparsity issues.</a>
</body>
</html>