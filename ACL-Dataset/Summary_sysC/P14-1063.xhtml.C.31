<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:198">
</head>
<body bgcolor="white">
<a href="#0" id="0">Where 𝐚 i ∈ℝ n d , 1 ≤ d ≤ D.</a>
<a href="#1" id="1">A D th order tensor 𝒯∈ℝ n 1 × n 2 × …⁢ n D can be factorized into a sum of component rank-1 tensors as.</a>
<a href="#2" id="2">In general, if V features are defined for a learning problem, and we (i) organize the feature set as a tensor 𝚽∈ℝ n 1 × n 2 × …⁢ n D and (ii) use H component rank-1 tensors to approximate the corresponding target weight tensor.</a>
<a href="#3" id="3">Then the total number of parameters to be learned for this tensor model is H ⁢∑ d = 1 D n d , which is usually much smaller than V = ∏ d = 1 D n d for a traditional vector space model.</a>
<a href="#4" id="4">Therefore we expect the tensor model to be more effective in a low-resource training environment.</a>
<a href="#5" id="5">Therefore, in order for tensor 𝒬 to represent the same set of real numbers that 𝒫 represents, there needs to exist a vector [ s 1 d , … , s n d d ] that can be represented by a rank-1 matrix as indicated by Equation ( 12 ), which is in general not guaranteed.</a>
</body>
</html>