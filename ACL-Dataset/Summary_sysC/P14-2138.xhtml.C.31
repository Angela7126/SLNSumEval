<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:250">
</head>
<body bgcolor="white">
<a href="#0" id="0">The relative frequencies of character bigrams appear to contain much information for predicting the first language (L1) of the writer of a text in another language (L2.</a>
<a href="#1" id="1">Tsur and Rappoport ( 2007 ) interpret this fact as evidence that word choice is dictated by the phonology of L1.</a>
<a href="#2" id="2">In order to test their hypothesis, we design an algorithm to identify the most discriminative words and the corresponding character bigrams, and perform two experiments to quantify their impact on the L1 identification task.</a>
<a href="#3" id="3">In this paper, we provide evidence against the above hypothesis.</a>
<a href="#4" id="4">We design an algorithm to identify the most discriminative words and the character bigrams that are indicative of such words, and perform two experiments to quantify their impact on the NLI task.</a>
<a href="#5" id="5">The results of the first experiment demonstrate that the removal of a relatively small set of discriminative words from the training data significantly impairs the accuracy of a bigram-based classifier.</a>
<a href="#6" id="6">The results of the second experiment reveal that the most indicative bigrams are quite similar across different language sets.</a>
<a href="#7" id="7">We conclude that character bigrams are effective in determining L1 of the author because they reflect differences in L2 word usage that are unrelated to the phonology of L1.</a>
<a href="#8" id="8">Tsur and Rappoport ( 2007 ) report that character bigrams are more effective for the NLI task than either unigrams or trigrams.</a>
<a href="#9" id="9">We are interested in identifying the character bigrams that are indicative of the most discriminative words in order to quantify their impact on the bigram-based classifier.</a>
</body>
</html>