<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:164">
</head>
<body bgcolor="white">
<a href="#0" id="0">Statistical Machine Translation (SMT) usually utilizes contextual information to disambiguate translation candidates.</a>
<a href="#1" id="1">However, it is often limited to contexts within sentence boundaries, hence broader topical information cannot be leveraged.</a>
<a href="#2" id="2">In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data.</a>
<a href="#3" id="3">In this section, we explain our neural network based topic similarity model in detail, as well as how to incorporate the topic similarity features into SMT decoding procedure.</a>
<a href="#4" id="4">Figure 1 sketches the high-level overview which illustrates how to learn topic representations using sentence-level parallel data.</a>
<a href="#5" id="5">Given a parallel sentence pair ⟨ f , e ⟩ , the first step is to treat f and e as queries, and use IR methods to retrieve relevant documents to enrich contextual information for them.</a>
<a href="#6" id="6">Specifically, the ranking model we used is a Vector Space Model (VSM), where the query and document are converted into tf-idf weighted vectors.</a>
</body>
</html>