<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:222">
</head>
<body bgcolor="white">
<a href="#0" id="0">Consider a unigram language model 𝒮 S that models the lexical characteristics of solution posts, and a translation model 𝒯 S that models the lexical correlation between problems and solutions.</a>
<a href="#1" id="1">Our generative model models the reply part of a ( p , r ) pair (in which r is a solution) as being generated from the statistical models in { 𝒮 S , 𝒯 S } as follows.</a>
<a href="#2" id="2">Where 𝒯 S p denotes the multionomial distribution obtained from 𝒯 S conditioned over the words in the post p ; this is obtained by assigning each candidate solution word w a weight equal to a ⁢ v ⁢ g ⁢ { 𝒯 S ⁢ [ w ′ ] ⁢ [ w ] w ′∈ p } , and normalizing such weights across all solution words.</a>
<a href="#3" id="3">In short, each solution word is assumed to be generated from the language model or the translation model (conditioned on the problem words) with a probability of Λ and 1 - Λ respectively, thus accounting for the correlation assumption.</a>
<a href="#4" id="4">The generative model above is similar to the proposal in [ 5 ] , adapted suitably for our scenario.</a>
<a href="#5" id="5">We model non-solution posts similarly with the sole difference being that they would be sampled from the analogous models 𝒮 N and 𝒯 N that characterize behavior of non-solution posts.</a>
</body>
</html>