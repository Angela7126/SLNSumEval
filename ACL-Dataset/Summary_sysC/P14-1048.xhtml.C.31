<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:222">
</head>
<body bgcolor="white">
<a href="#0" id="0">For both intra- and multi-sentential parsing, our bottom-up tree-building process adopts a similar greedy pipeline framework like the HILDA discourse parser (discussed in Section 2.1 ), to guarantee efficiency for large documents.</a>
<a href="#1" id="1">In particular, starting from the constituents on the bottom level (EDUs for intra-sentential parsing and sentence-level discourse trees for multi-sentential parsing), at each step of the tree-building, we greedily merge a pair of adjacent discourse constituents such that the merged constituent has the highest probability as predicted by our structure model.</a>
<a href="#2" id="2">Figure 6 shows our intra-sentential structure model M i ⁢ n ⁢ t ⁢ r ⁢ a s ⁢ t ⁢ r ⁢ u ⁢ c ⁢ t in the form of a linear-chain CRF.</a>
<a href="#3" id="3">Similar to Joty et al ’ s intra-sentential model, the first layer of the chain is composed of discourse constituents U j ’ s, and the second layer is composed of binary nodes S j ’ s to indicate the probability of merging adjacent discourse constituents.</a>
<a href="#4" id="4">The intra-sentential relation model M i ⁢ n ⁢ t ⁢ r ⁢ a r ⁢ e ⁢ l , shown in Figure 9 , works in a similar way to M i ⁢ n ⁢ t ⁢ r ⁢ a s ⁢ t ⁢ r ⁢ u ⁢ c ⁢ t , as described in Section 4.2.1.</a>
</body>
</html>