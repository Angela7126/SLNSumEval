<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:189">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this paper, we propose a novel approach to learning topic representation for parallel data using a neural network architecture, where abundant topical contexts are embedded via topic relevant monolingual data.</a>
<a href="#1" id="1">These topic-related documents are utilized to learn a specific topic representation for each sentence using a neural network based approach.</a>
<a href="#2" id="2">We integrate topic similarity features in the log-linear model and evaluate the performance on the NIST Chinese-to-English translation task.</a>
<a href="#3" id="3">In this section, we explain our neural network based topic similarity model in detail, as well as how to incorporate the topic similarity features into SMT decoding procedure.</a>
<a href="#4" id="4">The learned neural networks are used to obtain sentence topic representations, which will be further leveraged to infer topic representations of bilingual translation rules.</a>
<a href="#5" id="5">Therefore, it helps to train a smarter translation model with the embedded topic information.</a>
<a href="#6" id="6">We evaluate the performance of our neural network based topic similarity model on a Chinese-to-English machine translation task.</a>
<a href="#7" id="7">This proves that bilingually induced topic representation with neural network helps the SMT system disambiguate translation candidates.</a>
<a href="#8" id="8">In our work, a novel neural network based approach is proposed to infer topic representations for parallel data.</a>
</body>
</html>