<html>
<head>
<meta name="TextLength" content="SENT_NUM:13, WORD_NUM:333">
</head>
<body bgcolor="white">
<a href="#0" id="0">Traditional models of distributional semantics suffer from computational issues such as data sparsity for individual lexemes and complexities of modeling semantic composition when dealing with structures larger than single lexical items.</a>
<a href="#1" id="1">In this work, we present a frequency-driven paradigm for robust distributional semantics in terms of semantically cohesive lineal constituents, or motifs.</a>
<a href="#2" id="2">The framework subsumes issues such as differential compositional as well as non-compositional behavior of phrasal consituents, and circumvents some problems of data sparsity by design.</a>
<a href="#3" id="3">We briefly discuss data-driven learning of weights for features that define the motif affinity scores and penalties.</a>
<a href="#4" id="4">We describe learning of the model parameters with fully annotated training data, as well as an approach for learning motif segmentation that requires only partial supervision.</a>
<a href="#5" id="5">With the segmentation model described in the previous section, we process text from the English Gigaword corpus and the Simple English Wikipedia to partition sentences into motifs.</a>
<a href="#6" id="6">Since the segmentation model accounts for the contexts of the entire sentence in determining motifs, different instances of the same token could evoke different meaning representations.</a>
<a href="#7" id="7">Consider the following sentences tagged by the segmentation model, that would correspond to different representations of the token ‘ remains ’ once as a standalone motif, and once as part of an encompassing bigram motif ( ‘ remains classified ’.</a>
<a href="#8" id="8">On the metaphor detection task, we use the Metaphor dataset [ 12 ].</a>
<a href="#9" id="9">The data consists of sentences with defined phrases, and the task consists of identifying the linguistic use in these phrases as metaphorical or literal.</a>
<a href="#10" id="10">For this task, the motif based model is expected to perform well as common metaphorical usage is generally through idiosyncratic MWEs, which the motif based models is specially geared to capture through the features of the segmentation model.</a>
<a href="#11" id="11">For this task, we again use the VTK formalism for combining vector representations of the individual motifs.</a>
<a href="#12" id="12">Table 5 shows that the motif-based DSM does better than discriminative models such as CRFs and SVMs, and also slightly improves on the VTK kernel with distributional embeddings.</a>
</body>
</html>