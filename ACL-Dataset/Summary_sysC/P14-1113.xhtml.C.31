<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:172">
</head>
<body bgcolor="white">
<a href="#0" id="0">However, we further observe that hypernym – hyponym relations are more complicated than a single offset can represent.</a>
<a href="#1" id="1">To address this challenge, we propose a more sophisticated and general method — learning a linear projection which maps words to their hypernyms (Section 3.3.1.</a>
<a href="#2" id="2">Furthermore, we propose a piecewise linear projection method based on relation clustering to better model hypernym – hyponym relations (Section 3.3.2.</a>
<a href="#3" id="3">The training data for projection learning is collected from CilinE (Section 3.3.3.</a>
<a href="#4" id="4">We obtain 15,247 word pairs of hypernym – hyponym relations (9,288 for direct relations and 5,959 for indirect relations.</a>
<a href="#5" id="5">We analyze error cases after experiments.</a>
<a href="#6" id="6">Some cases are shown in Figure 8.</a>
<a href="#7" id="7">We can see that there is only one general relation “ æ¤ç© ( plant ) ”→𝐻“ çç© ( organism ) ” existing in CilinE.</a>
<a href="#8" id="8">Some fine-grained relations exist in Wikipedia, but the coverage is limited.</a>
<a href="#9" id="9">Our method based on word embeddings can discover more hypernym – hyponym relations than the previous methods can.</a>
<a href="#10" id="10">When we combine the methods together, we get the correct hierarchy.</a>
</body>
</html>