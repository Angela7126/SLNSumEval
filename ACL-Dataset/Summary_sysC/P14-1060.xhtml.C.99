<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:332">
</head>
<body bgcolor="white">
<a href="#0" id="0">We present a simple model to segment a sentence into such motifs using a feature-set drawing from frequency statistics, information theory, linguistic theories and shallow syntactic analysis.</a>
<a href="#1" id="1">Section 3 describes our methodology, which consists of a frequency-driven segmentation model to partition text into semantically meaningful recurring lineal-subunits, a representation learning framework for learning new semantic embeddings based on this segmentation, and an approach to use such embeddings in downstream applications.</a>
<a href="#2" id="2">While word embeddings and language models from such methods have been useful for tasks such as relation classification, polarity detection, event coreference and parsing; much of existing literature on composition is based on abstract linguistic theory and conjecture, and there is little evidence to support that learnt representations for larger linguistic units correspond to their semantic meanings.</a>
<a href="#3" id="3">While this framework is attractive in the lack of assumptions on representation that it makes, the use of distributional embeddings for individual tokens means that it suffers from the same shortcomings as described for the example in Table 1, and hence these methods model semantic relations between word-nodes very weakly.</a>
<a href="#4" id="4">Figure 1 shows an example of the shortcomings of this general approach.</a>
<a href="#5" id="5">We describe learning of the model parameters with fully annotated training data, as well as an approach for learning motif segmentation that requires only partial supervision.</a>
<a href="#6" id="6">Since the segmentation model accounts for the contexts of the entire sentence in determining motifs, different instances of the same token could evoke different meaning representations.</a>
<a href="#7" id="7">For evaluating distributional representations for motifs (in terms of other motifs) learnt by the framework, we test these representations in two downstream tasks sentence polarity classification and metaphor detection.</a>
<a href="#8" id="8">The data consists of sentences with defined phrases, and the task consists of identifying the linguistic use in these phrases as metaphorical or literal.</a>
<a href="#9" id="9">For this task, the motif based model is expected to perform well as common metaphorical usage is generally through idiosyncratic MWEs, which the motif based models is specially geared to capture through the features of the segmentation model.</a>
</body>
</html>