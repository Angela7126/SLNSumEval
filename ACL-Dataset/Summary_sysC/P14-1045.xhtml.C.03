<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:263">
</head>
<body bgcolor="white">
<a href="#0" id="0">A distributional thesaurus is a lexical network that lists semantic neighbours, computed from a corpus and a similarity measure between lexical items, which generally captures the similarity of contexts in which the items occur.</a>
<a href="#1" id="1">A distributional thesaurus includes a lot of “ noise ” from a semantic point of view, but also lists relevant lexical pairs that escape classical lexical relations such as synonymy or hypernymy.</a>
<a href="#2" id="2">We present the experiments we set up to automatically filter semantic relations in context, with various groups of features that take into account information from the corpus used to build the thesaurus and contextual information related to occurrences of semantic neighbours 3.</a>
<a href="#3" id="3">In order to evaluate the resource, we set up an annotation in context pairs of lexical items are to be judged in their context of use, in texts where they occur together.</a>
<a href="#4" id="4">For the preliminary test, we asked three annotators to judge the similarity of pairs of lexical items without any context ( no-context ), and to judge the similarity of pairs presented within a paragraph where they both occur ( in context.</a>
<a href="#5" id="5">For the no-context annotation, candidate pairs had a Lin score above 0.2 , which placed them in the top 14 ⁢ % of lexical neighbours with respect to the similarity level.</a>
<a href="#6" id="6">The first thing we can analyse from the annotated data is the impact of a threshold on Lin ’ s score to select relevant lexical pairs.</a>
<a href="#7" id="7">For each pair neighbour a / neighbour b , we computed a set of features from Wikipedia (the corpus used to derive the distributional similarity.</a>
</body>
</html>