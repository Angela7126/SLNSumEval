<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:279">
</head>
<body bgcolor="white">
<a href="#0" id="0">Using the unsupervised pre-trained deep belief net (DBN) to initialize DAE ’ s parameters and using the input original phrase features as a teacher for semi-supervised fine-tuning, we learn new semi-supervised DAE features, which are more effective and stable than the unsupervised DBN features.</a>
<a href="#1" id="1">First, the input original features for the DBN feature learning are too simple, the limited 4 phrase features of each phrase pair, such as bidirectional phrase translation probability and bidirectional lexical weighting [ Koehn et al.2003 ] , which are a bottleneck for learning effective feature representation.</a>
<a href="#2" id="2">For our semi-supervised DAE feature learning task, we use the unsupervised pre-trained DBN to initialize DAE ’ s parameters and use the input original phrase features as the “ teacher ” for semi-supervised back-propagation.</a>
<a href="#3" id="3">Our semi-supervised DAE features significantly outperform the unsupervised DBN features and the baseline features, and our introduced input phrase features significantly improve the performance of DAE feature learning.</a>
<a href="#4" id="4">Section 3 presents our introduced input features for DNN feature learning.</a>
<a href="#5" id="5">Next, we adapt and extend some original phrase features as the input features for DAE feature learning.</a>
<a href="#6" id="6">Thus, these new m 1 + m 2 -dimensional DAE features are added as extra features to the phrase table.</a>
<a href="#7" id="7">Compared with the unsupervised DBN features, our semi-supervised DAE features are more effective for translation decoder (row 3 vs.</a>
<a href="#8" id="8">Except for the phrase feature X 1 [ Maskey and Zhou2012 ] , our introduced input features X significantly improve the DAE feature learning (row 11 vs.</a>
<a href="#9" id="9">Specially, Table 4 shows the detailed effectiveness of our introduced input features for DAE feature learning, and the results show that each type of features are very effective for DAE feature learning.</a>
</body>
</html>