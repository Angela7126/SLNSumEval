<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:265">
</head>
<body bgcolor="white">
<a href="#0" id="0">Focusing on the adaptability to user and domain changes, we report the results of comparative experiments with two online algorithms and the standard batch approach.</a>
<a href="#1" id="1">The evaluation is carried out by measuring the global error of each algorithm on test sets featuring different degrees of similarity with the data used for training.</a>
<a href="#2" id="2">Our results show that the sensitivity of online QE models to different distributions of training and test instances makes them more suitable than batch methods for integration in a CAT framework.</a>
<a href="#3" id="3">In the last round of experiments we evaluate the reactivity of different online models to simultaneous user and domain changes.</a>
<a href="#4" id="4">To this aim, our QE models are created using a training set coming from one domain (L or IT), and then used to predict the HTER labels for the test instances coming from the other domain ( e.g., training on L, testing on IT.</a>
<a href="#5" id="5">Intuitively, dealing with simultaneous user and domain changes represents a more challenging problem compared to the previous setting where only post-editors changes were considered.</a>
<a href="#6" id="6">Such intuition is confirmed by the results of the adaptive models that outperform both the baseline ( Μ ) and the batch models even for low Δ HTER values.</a>
<a href="#7" id="7">Although in these cases the distance between training and test data is comparable to the experiments with similar post-editors working in the same domain ( sim1 and sim2 ), here the predictive power of the batch models seems in fact to be lower.</a>
<a href="#8" id="8">The same holds also for the empty models except in two cases where the Δ HTER is the smallest (2.2 and 5.0.</a>
</body>
</html>