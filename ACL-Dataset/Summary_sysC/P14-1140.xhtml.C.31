<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:153">
</head>
<body bgcolor="white">
<a href="#0" id="0">We propose a three-step semi-supervised training approach to optimizing the parameters of R 2 NN, which includes recursive auto-encoding for unsupervised pre-training, supervised local training based on the derivation trees of forced decoding, and supervised global training using early update strategy.</a>
<a href="#1" id="1">Liu et al.</a>
<a href="#2" id="2">2013 ) apply DNN to SMT decoding, but not in a recursive manner.</a>
<a href="#3" id="3">A feature is learnt via a one-hidden-layer neural network, and the embedding of words in the phrase pairs are used as the input vector.</a>
<a href="#4" id="4">Our model generates the representation of a translation pair based on its child nodes.</a>
<a href="#5" id="5">Li et al.</a>
<a href="#6" id="6">2013 ) also generate the representation of phrase pairs in a recursive way.</a>
<a href="#7" id="7">In their work, the representation is optimized to learn a distortion model using recursive neural network, only based on the representation of the child nodes.</a>
<a href="#8" id="8">Our R 2 NN is used to model the end-to-end translation process, with recurrent global information added.</a>
</body>
</html>