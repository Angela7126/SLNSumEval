<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:157">
</head>
<body bgcolor="white">
<a href="#0" id="0">Other approaches train an SMT system to predict lemmas instead of surface forms, and then inflect the SMT output as a post-processing step [ 21 , 7 , 11 , 10 ].</a>
<a href="#1" id="1">Alternatively, one can reparameterize existing phrase tables as exponential models, so that translation probabilities account for source context and morphological features [ 16 , 30 ].</a>
<a href="#2" id="2">The one-best approach can be extended easily by desegmenting n -best lists of segmented decoder output.</a>
<a href="#3" id="3">Doing so enables the inclusion of an unsegmented target language model, and with a small amount of bookkeeping, it also allows the inclusion of features related to the operations performed during desegmentation (see Section 3.4.</a>
<a href="#4" id="4">Equation 1 may need to be modified for other languages or segmentation schemes, but our techniques generalize to any definition that can be written as a regular expression.</a>
<a href="#5" id="5">A desegmenting transducer can be constructed by first encoding our desegmenter as a table that maps morpheme sequences to words.</a>
</body>
</html>