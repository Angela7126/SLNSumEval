<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:135">
</head>
<body bgcolor="white">
<a href="#0" id="0">Given a dependency parse (1) the model extracts all words matching a set of paths from the frame evoking predicate and its direct dependents (2.</a>
<a href="#1" id="1">Given x , the sentence with a marked predicate, the argument identification model assumes that the predicate frame y has been disambiguated.</a>
<a href="#2" id="2">So the second baseline has the same input representation as Wsabie Embedding but uses a log-linear model instead of Wsabie.</a>
<a href="#3" id="3">We learn the initial embedding representations for our frame identification model (ยง 3 ) using a deep neural language model similar to the one proposed by Bengio et al.</a>
<a href="#4" id="4">Hyperparameters For our frame identification model with embeddings, we search for the Wsabie hyperparameters using the development data.</a>
<a href="#5" id="5">Consequently, the Wsabie Embedding model can share more information between different examples in the training data than the Log-Linear Embedding model.</a>
</body>
</html>