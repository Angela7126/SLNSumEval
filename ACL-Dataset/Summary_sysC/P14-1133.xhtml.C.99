<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:479">
</head>
<body bgcolor="white">
<a href="#0" id="0">Given an input utterance, we first use a simple method to deterministically generate a set of candidate logical forms with a canonical realization in natural language for each.</a>
<a href="#1" id="1">For instance, the utterances “ Where is ACL in 2014 ” and “ What is the location of ACL 2014 ” cannot be used in traditional semantic parsing methods, since the KB does not contain an entity ACL2014 , but this pair clearly contains valuable linguistic information.</a>
<a href="#2" id="2">As another reference point, out of 500,000 relations extracted by the ReVerb Open IE system [ 9 ] , only about 10,000 can be aligned to Freebase [ 1 ].</a>
<a href="#3" id="3">Given (i) a knowledge base 𝒦 , and (ii) a training set of question-answer pairs { ( x i , y i ) } i = 1 n , output a semantic parser that maps new questions x to answers y via latent logical forms z.</a>
<a href="#4" id="4">Given an utterance x and the KB, we construct a set of candidate logical forms 𝒵 x , and then for each z ∈𝒵 x generate a small set of canonical natural language utterances 𝒞 z.</a>
<a href="#5" id="5">Our goal at this point is only to generate a manageable set of logical forms containing the correct one, and then generate an appropriate canonical utterance from it.</a>
<a href="#6" id="6">Our framework accommodates any paraphrasing method, and in this paper we propose an association model that learns to associate natural language phrases that co-occur frequently in a monolingual parallel corpus, combined with a vector space model , which learns to score the similarity between vector representations of natural language utterances (Section 5.</a>
<a href="#7" id="7">Where the parameters Θ pr define the paraphrase model (Section 5 ), which is based on features extracted from text only (the input and canonical utterance.</a>
<a href="#8" id="8">The parameters Θ lf correspond to semantic parsing features based on the logical form and input utterance, and are briefly described in this section.</a>
<a href="#9" id="9">Lastly, Freebase formulas have types (see Section 4 ), and we conjoin the type of z with the first word of x , to capture the correlation between a word (e.g.,, “ where ” ) with the Freebase type (e.g.,, Location.</a>
<a href="#10" id="10">To construct candidate logical forms 𝒵 x for a given utterance x , our strategy is to find an entity in x and grow the logical form from that entity.</a>
<a href="#11" id="11">As we show later, this procedure actually produces a set with better coverage than constructing logical forms recursively from spans of x , as is done in traditional semantic parsing.</a>
<a href="#12" id="12">While mapping general language utterances to logical forms is hard, we observe that it is much easier to generate a canonical natural language utterances of our choice given a logical form.</a>
<a href="#13" id="13">Once the candidate set of logical forms paired with canonical utterances is constructed, our problem is reduced to scoring pairs ( c , z ) based on a paraphrase model.</a>
</body>
</html>