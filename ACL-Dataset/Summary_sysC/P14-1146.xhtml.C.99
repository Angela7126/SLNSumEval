<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:151">
</head>
<body bgcolor="white">
<a href="#0" id="0">Most existing algorithms for learning continuous word representations typically only model the syntactic context of words but ignore the sentiment of text.</a>
<a href="#1" id="1">The most serious problem is that traditional methods typically model the syntactic context of words but ignore the sentiment information of text.</a>
<a href="#2" id="2">As a result, words with opposite polarity, such as good and bad , are mapped into close vectors.</a>
<a href="#3" id="3">To this end, we extend the existing word embedding learning algorithm [ 9 ] and develop three neural networks to effectively incorporate the supervision from sentiment polarity of text (e.g., sentences or tweets) in their loss functions.</a>
<a href="#4" id="4">We apply sentiment-specific word embedding for Twitter sentiment classification under a supervised learning framework as in previous work [ 33 ].</a>
<a href="#5" id="5">Instead of hand-crafting features, we incorporate the continuous representation of words and phrases as the feature of a tweet.</a>
<a href="#6" id="6">The sentiment classifier is built from tweets with manually annotated sentiment polarity.</a>
</body>
</html>