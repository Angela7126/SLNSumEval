<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Improved Correction Detection in Revised ESL Sentences</title>
<!--Generated on Wed Jun 11 18:12:46 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
<link rel="stylesheet" href="ltx-ulem.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Improved Correction Detection in Revised ESL Sentences</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Huichao Xue 
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rebecca Hwa
<br class="ltx_break"/>Department of Computer Science,
<br class="ltx_break"/>University of Pittsburgh,
<br class="ltx_break"/>210 S Bouquet St, Pittsburgh, PA 15260, USA
<br class="ltx_break"/>{<span class="ltx_text ltx_font_typewriter">hux10,hwa</span>}<span class="ltx_text ltx_font_typewriter">@cs.pitt.edu</span>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">This work explores methods of automatically detecting corrections of
individual mistakes in sentence revisions for ESL students. We have
trained a classifier that specializes in determining whether
consecutive basic-edits (word insertions, deletions, substitutions)
address the same mistake. Experimental result shows that the
proposed system achieves an <math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi>F</mi><mn>1</mn></msub></math>-score of 81% on correction
detection and 66% for the overall system, out-performing the
baseline by a large margin.</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Quality feedback from language tutors can help
English-as-a-Second-Language (ESL) students improve their writing
skills. One of the tutors’ tasks is to isolate writing mistakes
within sentences, and point out (1) why each case is considered a
mistake, and (2) how each mistake should be corrected. Because this is
time consuming, tutors often just rewrite the sentences without giving
any explanations <cite class="ltx_cite">[<a href="#bib.bib187" title="Preparing ESL students for college writing: two case studies" class="ltx_ref">5</a>]</cite>. Due to the effort involved in
comparing revisions with the original texts, students often fail to
learn from these revisions <cite class="ltx_cite">[<a href="#bib.bib186" title="Providing feedback on ESL studentsâ written assignments" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Computer aided language learning tools offer a solution for providing more detailed feedback.
Programs can be developed to compare the student’s original sentences
with the tutor-revised sentences. <cite class="ltx_cite">Swanson and Yamangil (<a href="#bib.bib14" title="Correction detection and error type selection as an ESL educational aid" class="ltx_ref">2012</a>)</cite> have proposed
a promising framework for this purpose. Their approach has two
components: one to detect individual corrections within a revision,
which they termed <span class="ltx_text ltx_font_italic">correction detection</span>; another to determine
what the correction fixes, which they termed <em class="ltx_emph">error type
selection</em>. Although they reported a high accuracy for the error
type selection classifier alone, the bottleneck of their system is the
other component – correction detection. An analysis of their system
shows that approximately 70% of the system’s mistakes are caused by
mis-detections in the first place. Their correction detection
algorithm relies on a set of heuristics developed from one single data
collection (the FCE corpus <cite class="ltx_cite">[<a href="#bib.bib49" title="A new dataset and method for automatically grading esol texts" class="ltx_ref">17</a>]</cite>). When determining
whether a set of basic-edits (word insertions, deletions,
substitutions) contributes to the same correction, these heuristics
lack the flexibility to adapt to a specific context. Furthermore, it
is not clear if the heuristics will work as well for tutors trained to
mark up revisions under different guidelines.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">We propose to improve upon the correction detection component by
training a classifier that determines which edits in a revised
sentence address the same error in the original sentence. The
classifier can make more accurate decisions adjusted to
contexts. Because the classifier were trained on revisions where
corrections are explicitly marked by English experts, it is also
possible to build systems adjusted to different annotation standards.</p>
</div>
<div id="S1.F1" class="ltx_figure"><img src="P14-2098/image001.png" id="S1.F1.g1" class="ltx_graphics ltx_centering" width="435" height="64" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span><span class="ltx_text ltx_font_small">Detecting corrections from revisions. Our system detects
individual corrections by comparing the original sentence with its
revision, so that each correction addresses one error. Each
polygon corresponds to one correction; the labels are codes of the
error types. The codes follow the annotation standard in FCE
corpus <cite class="ltx_cite">[<a href="#bib.bib271" title="The Cambridge Learner Corpus: Error coding and analysis for lexicography and ELT" class="ltx_ref">11</a>]</cite>. In this example, <em class="ltx_emph">W</em> is incorrect
<span class="ltx_text" style="text-decoration:underline;">W</span>ord order; <em class="ltx_emph">UT</em> is <span class="ltx_text" style="text-decoration:underline;">U</span>nnecessary
preposi<span class="ltx_text" style="text-decoration:underline;">T</span>ion; <em class="ltx_emph">FV</em> is wrong <span class="ltx_text" style="text-decoration:underline;">V</span>erb
<span class="ltx_text" style="text-decoration:underline;">F</span>orm; <em class="ltx_emph">RN</em> is <span class="ltx_text" style="text-decoration:underline;">N</span>noun needs to be
<span class="ltx_text" style="text-decoration:underline;">R</span>eplaced; <em class="ltx_emph">ID</em> is <span class="ltx_text" style="text-decoration:underline;">ID</span>iom error.</span></div>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">The contributions of this paper are: (1) We show empirically that a
major challenge in correction detection is to determine the number of
edits that address the same error. (2) We have developed a merging
model that reduces mis-detection by 1/3, leading to significant
improvement in the accuracies of combined <span class="ltx_text ltx_font_italic">correction detection</span>
and <span class="ltx_text ltx_font_italic">error type selection</span>. (3) We have conducted experiments
across multiple corpora, indicating that the proposed merging model is
generalizable.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Correction Detection</h2>

<div id="S2.F2" class="ltx_figure"><img src="P14-2098/image006.png" id="S2.F2.g1" class="ltx_graphics ltx_centering" width="460" height="71" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span><span class="ltx_text ltx_font_small">A portion of the example from Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> undergoing the two-step correction detection process. The basic edits are indicated by black polygons. The corrections are shown in red polygons.</span></div>
</div>
<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Comparing a student-written sentence with its revision, we observe
that each correction can be decomposed into a set of more basic edits
such as word insertions, word deletions and word substitutions. In the
example shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the correction
“<em class="ltx_emph">to change</em> <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m1" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo>⇒</mo></math> <em class="ltx_emph">changing</em>” is composed of a
deletion of <em class="ltx_emph">to</em> and a substitution from <em class="ltx_emph">change</em> to
<em class="ltx_emph">changing</em>; the correction “<em class="ltx_emph">moment</em> <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m2" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo>⇒</mo></math>
<em class="ltx_emph">minute</em>” is itself a single word substitution. Thus,
we can build systems to detect corrections which operates in two steps: (1) detecting the basic edits that took place during the revision, and (2) merging those basic edits that address the same error. Figure <a href="#S2.F2" title="Figure 2 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates the process for a fragment of the example sentence from Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.F5" class="ltx_figure"><span class="ltx_ERROR undefined ltx_centering">{subfigure}</span>
<p class="ltx_p ltx_align_center">[b]0.23
<img src="P14-2098/image010.png" id="S2.F5.g1" class="ltx_graphics" width="432" height="215" alt=""/></p>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span></div><span class="ltx_ERROR undefined ltx_centering">{subfigure}</span>
<p class="ltx_p ltx_align_center">[b]0.23
<img src="P14-2098/image007.png" id="S2.F5.g2" class="ltx_graphics" width="432" height="221" alt=""/></p>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span></div>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span><span class="ltx_text ltx_font_small">Basic edits extracted by the edit-distance algorithm <cite class="ltx_cite">[<a href="#bib.bib4" title="Binary codes capable of correcting deletions, insertions, and reversals" class="ltx_ref">10</a>]</cite> do not necessarily match our linguistic intuition. The ideal basic-edits are shown in Figure <a href="#S2.F5" title="Figure 5 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, but since the algorithm only cares about minimizing the number of edits, it may end up extracting basic-edits shown in Figure <a href="#S2.F5" title="Figure 5 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</span></div>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">In practice, however, this two-step approach may result in
mis-detections due to ambiguities. Mis-detections may be introduced
from either steps. While detecting basic edits,
Figures <a href="#S2.F5" title="Figure 5 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> gives an example of problems that
might arise. Because the Levenshtein algorithm only tries to minimize
the number of edits, it does not care whether the edits make any
linguistic sense. For merging basic edits, Swanson and Yamangilapplied a distance
heuristic – basic-edits that are close to each other (e.g. basic
edits with at most one word lying in between) are merged.
Figure <a href="#S2.F8" title="Figure 8 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows cases for which the heuristic results
in the wrong scope.</p>
</div>
<div id="S2.F8" class="ltx_figure"><span class="ltx_ERROR undefined">{subfigure}</span>
<p class="ltx_p">[b]0.5
<img src="P14-2098/image008.png" id="S2.F8.g1" class="ltx_graphics ltx_centering" width="432" height="94" alt=""/></p>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span class="ltx_text ltx_font_small">The basic edits are addressing the same problem. But
these basic edits are non-adjacent, and therefore not merged by
S&amp;Y’s algorithm.</span></div><span class="ltx_ERROR undefined">{subfigure}</span>
<p class="ltx_p">[b]0.5
<img src="P14-2098/image004.png" id="S2.F8.g2" class="ltx_graphics ltx_centering ltx_centering" width="325" height="91" alt=""/></p>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span class="ltx_text ltx_font_small">The basic edits in the above two cases address different
problems though they are adjacent. S&amp;Y’s merging algorithm
incorrectly merges them.</span></div>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span class="ltx_text ltx_font_small">Merging mistakes by the algorithm proposed in
<cite class="ltx_cite">Swanson and Yamangil (<a href="#bib.bib14" title="Correction detection and error type selection as an ESL educational aid" class="ltx_ref">2012</a>)</cite> (S&amp;Y), which merges adjacent basic edits.</span></div>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">These errors caused their system to mis-detect 30% of the
corrections. Since mis-detected corrections cannot be analyzed down
the pipeline, the correction detection component became the
bottle-neck of their overall system. Out of the 42% corrections that
are incorrectly analyzed<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup> Swanson and Yamangilreported an overall system with
58% F-score.</span></span></span>, 30%/42%<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p3.m1" class="ltx_Math" alttext="\approx" display="inline"><mo>≈</mo></math>70% are caused by mis-detections
in the first place. An improvement in correction detection may
increase the system accuracy overall.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">We conducted an error analysis to attribute errors to either step when
the system detects a wrong set of corrections for a sentence. We
examine the first step’s output. If the resulting basic edits do not
match with those that compose the actual corrections, we attribute the
error to the first step. Otherwise, we attribute the error to the
second step. Our analysis confirms that the merging step is the
bottleneck in the current correction detection system – it accounts
for 75% of the mis-detections. Therefore, to effectively reduce the
algorithm’s mis-detection errors, we propose to build a classifier to
merge with better accuracies.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p">Other previous tasks also involve comparing two sentences. Unlike
evaluating grammar error correction systems <cite class="ltx_cite">[<a href="#bib.bib20" title="Better evaluation for grammatical error correction" class="ltx_ref">3</a>]</cite>,
correction detection cannot refer to a gold standard. Our error
analysis above also highlights our task’s difference with previous
work that identify corresponding phrases between two sentences,
including phrase extraction <cite class="ltx_cite">[<a href="#bib.bib139" title="Statistical phrase-based translation" class="ltx_ref">9</a>]</cite> and paraphrase extraction
<cite class="ltx_cite">[<a href="#bib.bib199" title="Constructing corpora for the development and evaluation of paraphrase systems" class="ltx_ref">1</a>]</cite>. They are fundamentally different in that the granularity
of the extracted phrase pairs is a major concern in our work – we
need to guarantee each detected phrase pair to address exactly one
writing problem. In comparison, phrase extraction systems aim to
improve the end-to-end MT or paraphrasing systems. A bigger concern
is to guarantee the extracted phrase pairs are indeed translations or
paraphrases. Recent work therefore focuses on identifying the
alignment/edits between two sentences <cite class="ltx_cite">[<a href="#bib.bib203" title="TER-Plus: paraphrase, semantic, and alignment enhancements to translation edit rate" class="ltx_ref">13</a>, <a href="#bib.bib57" title="Tree edit models for recognizing textual entailments, paraphrases, and answers to questions" class="ltx_ref">8</a>]</cite>.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>A Classifier for Merging Basic-Edits</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">Figures <a href="#S2.F8" title="Figure 8 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> highlights the problems with
indiscriminantly merging basic-edits that are adjacent. Intuitively,
it seems that the decision should be more context dependent. Certain
patterns may indicate that two adjacent basic-edits are a part of the
same correction while others may indicate that they each address a
different problem. For example, in Figure <a href="#S3.F11" title="Figure 11 ‣ 3 A Classifier for Merging Basic-Edits ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>,
when the insertion of one word is followed by the deletion of the same
word, the insertion and deletion are likely addressing one single
error. This is because these two edits would combine together as a
word-order change. On the other hand, in Figure
<a href="#S3.F11" title="Figure 11 ‣ 3 A Classifier for Merging Basic-Edits ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, if one edit includes a substitution
between words with the same POS’s, then it is likely fixing a word
choice error by itself. In this case, it should not be merged with
other edits.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">To predict whether
two basic-edits address the same writing problem
more discriminatively, we train a Maximum Entropy binary classifier based on features extracted from relevant contexts for the basic edits.</p>
</div>
<div id="S3.F11" class="ltx_figure"><span class="ltx_ERROR undefined">{subfigure}</span>
<p class="ltx_p">[b]0.23
<img src="P14-2098/image003.png" id="S3.F11.g1" class="ltx_graphics ltx_centering" width="271" height="177" alt=""/></p>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span><span class="ltx_text ltx_font_small">The pattern indicates that the two edits address the same
problem</span></div><span class="ltx_ERROR undefined">{subfigure}</span>
<p class="ltx_p">[b]0.23
<img src="P14-2098/image005.png" id="S3.F11.g2" class="ltx_graphics ltx_centering ltx_centering" width="379" height="227" alt=""/></p>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span><span class="ltx_text ltx_font_small">The pattern indicates that the two edits do not address
the same problem</span></div>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span><span class="ltx_text ltx_font_small">Patterns indicating whether two edits address the same writing mistake.</span></div>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">We use features in Table <a href="#S3.T1" title="Table 1 ‣ 3 A Classifier for Merging Basic-Edits ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> in the proposed
classifier. We design the features to indicate: <span class="ltx_text ltx_font_bold">(A)</span> whether
merging the two basic-edits matches the pattern for a common
correction. <span class="ltx_text ltx_font_bold">(B)</span> whether one basic-edit addresses one single
error.</p>
</div>
<div id="S3.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Type</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">name</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">description</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="5"><span class="ltx_text ltx_font_small">A</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">gap-between-edits</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">Gap between the two edits. In particular, we use the number of words between the two edits’ original words, as well as the revised
words. Note that Swanson and Yamangil’s approach is a special case
that only considers if the basic-edits have zero gap in both sentences.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">tense-change</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">We detect patterns such as: if the
original-revision pair matches the pattern “V-ing</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T1.m1" class="ltx_Math" alttext="\Rightarrow" display="inline"><mo>⇒</mo></math><span class="ltx_text ltx_font_small">to
V”.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">word-order-error</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">Whether the basic-edits’ original word set and
the revised word set are the same (one or zero).</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">same-word-set</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">If the original sentence and the revised
sentence have the same word set, then it’s likely that all the edits
are fixing the word order error.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">revised-to</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">The phrase comprised of the two revised words.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span class="ltx_text ltx_font_small">B</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">editdistance=1</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">If one basic-edit is a substitution, and the
original/revised word only has 1 edit distance, it indicates that
the basic-edit is fixing a misspelling error.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">not-in-dict</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">If the original word does not have a valid dictionary entry,
then it indicates a misspelling error.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">word-choice</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">If the original and the revised words have the same POS, then it is likely fixing a word choice error.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">preposition-error</span></td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" style="width:325.2pt;" width="325.2pt"><span class="ltx_text ltx_font_small">Whether the original and the revised words are both prepositions.</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 1: </span>Features used in our proposed classifier.</div>
</div>
<div id="S3.p4" class="ltx_para">
<p class="ltx_p">We train the classifier using samples extracted from
revisions where individual corrections are explicitly annotated. We
first extract the basic-edits that compose each correction. We then
create a training instance for each pair of two consecutive basic
edits: if two consecutive basic edits need to be merged, we will mark
the outcome as <em class="ltx_emph">True</em>, otherwise it is <em class="ltx_emph">False</em>. We
illustrate this in Figure <a href="#S3.F12" title="Figure 12 ‣ 3 A Classifier for Merging Basic-Edits ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>.</p>
</div>
<div id="S3.F12" class="ltx_figure"><img src="P14-2098/image009.png" id="S3.F12.g1" class="ltx_graphics ltx_centering" width="271" height="62" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span><span class="ltx_text ltx_font_small">Extracting training instances for the merger. Our goal is
to train classifiers to tell if two basic edits should be merged
(<em class="ltx_emph">True</em> or <em class="ltx_emph">False</em>). We break each correction (outer
polygons, also colored in red) in the training corpus into a set
of basic edits (black polygons). We construct an instance for each
consecutive pair of basic edits. If two basic edits were extracted
from the same correction, we will mark the outcome as <em class="ltx_emph">True</em>,
otherwise we will mark the outcome as <em class="ltx_emph">False</em>.</span></div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Experimental Setup</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">We combine Levenshtein algorithm with different merging algorithms
for correction detection.</p>
</div>
<div id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">An ideal data resource would be a real-world collection of student essays and their revisions
<cite class="ltx_cite">[<a href="#bib.bib13" title="Tense and aspect error correction for ESL learners using global context" class="ltx_ref">15</a>]</cite>.
However, existing revision corpora do not have
the fine-grained annotations necessary for our experimental gold standard.
We instead use error
annotated data, in which the corrections were provided by human
experts. We simulate the revisions by applying corrections onto the
original sentence. The teachers’ annotations are treated as gold
standard for the detailed corrections.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p">We considered four corpora with different ESL populations and
annotation standards, including FCE corpus <cite class="ltx_cite">[<a href="#bib.bib49" title="A new dataset and method for automatically grading esol texts" class="ltx_ref">17</a>]</cite>,
NUCLE corpus <cite class="ltx_cite">[<a href="#bib.bib8" title="Building a large annotated corpus of learner english: the NUS corpus of learner english" class="ltx_ref">2</a>]</cite>, UIUC corpus<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>UIUC corpus
contains annotations of essays collected from ICLE
<cite class="ltx_cite">[<a href="#bib.bib247" title="The International Corpus of Learner English: a new resource for foreign language learning and teaching and second language acquisition research" class="ltx_ref">6</a>]</cite> and CLEC <cite class="ltx_cite">[<a href="#bib.bib249" title="Zhongguo xuexizhe yingyu yuliaohu.(chinese learner english corpus)" class="ltx_ref">7</a>]</cite>.</span></span></span> <cite class="ltx_cite">[<a href="#bib.bib67" title="Annotating ESL errors: challenges and rewards" class="ltx_ref">12</a>]</cite>
and HOO2011 corpus <cite class="ltx_cite">[<a href="#bib.bib318" title="Helping our own: the HOO 2011 pilot shared task" class="ltx_ref">4</a>]</cite>. These corpora all provide
experts’ corrections along with error type mark-ups. The basic
statistics of the corpora are shown in Table
<a href="#S4.T2" title="Table 2 ‣ 4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. In these corpora, around half of revised
sentences contains multiple corrections.</p>
</div>
<div id="S4.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">corpus</span></th>
<th class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">sentences</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m1" class="ltx_Math" alttext="\frac{\textrm{sentences with $\geq 2$ corrections}}{\textrm{revised sentences}}" display="inline"><mfrac><mrow><mtext mathvariant="italic">sentences with </mtext><mrow><mi/><mo>≥</mo><mn>2</mn></mrow><mtext mathvariant="italic"> corrections</mtext></mrow><mtext mathsize="small" stretchy="false">revised sentences</mtext></mfrac></math></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FCE</span></td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">33,900</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">53.45%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">NUCLE</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text ltx_font_small">61,625</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.74%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">UIUC</span></td>
<td class="ltx_td ltx_align_right ltx_border_r"><span class="ltx_text ltx_font_small">883</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">61.32%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">HOO2011</span></td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">966</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">42.05%</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 2: </span>Basic statistics of the corpora that we consider.</div>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p">We have split each corpus into 11 equal parts. One part is used as the development dataset; the rest are used for 10-fold cross validation.</p>
</div>
</div>
<div id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation Metrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p">In addition to
evaluating the merging algorithms on the stand-alone task of
correction detection, we have also plugged in the merging algorithms
into an end-to-end system in which every automatically detected
correction is further classified into an error type. We replicated
the error type selector described in <cite class="ltx_cite">Swanson and Yamangil (<a href="#bib.bib14" title="Correction detection and error type selection as an ESL educational aid" class="ltx_ref">2012</a>)</cite>. The error
type selector’s accuracies are shown in Table
<a href="#S4.T3" title="Table 3 ‣ MaxEntMerger ‣ 4.2 Evaluation Metrics ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>Our replication has a slightly lower
error type selection accuracy on FCE (80.02%) than the figure
reported by Swanson and Yamangil(82.5%). This small difference on error type
selection does not affect our conclusions about correction
detection.</span></span></span> . We compare two merging algorithms, combined with
Levenshtein algorithm:</p>
</div>
<div id="S4.SS2.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">S&amp;Y</h4>

<div id="S4.SS2.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">The merging heuristic proposed by Swanson and Yamangil,
which merges the adjacent basic edits into single corrections.</p>
</div>
</div>
<div id="S4.SS2.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">MaxEntMerger</h4>

<div id="S4.SS2.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">We use the Maximum Entropy
classifier to predict whether we should merge the two edits, as
described in Section <a href="#S3" title="3 A Classifier for Merging Basic-Edits ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup> We use the
implementation at
<a href="http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://homepages.inf.ed.ac.uk/lzhang10/maxent_toolkit.html</span></a>.</span></span></span>.</p>
</div>
<div id="S4.T3" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Corpus</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Error Types</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Accuracy</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FCE</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">73</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">80.02%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">NUCLE</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">27</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">67.36%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">UIUC</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">8</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">80.23%</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">HOO2011</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">38</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">64.88%</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 3: </span>Error type selection accuracies on different corpora. We use a
Maximum Entropy classifier along with features suggested by Swanson and Yamangilfor this task. The reported figures come from 10-fold cross validations
on different corpora. </div>
</div>
<div id="S4.SS2.SSS0.P2.p2" class="ltx_para">
<p class="ltx_p">We evaluate extrinsically the merging components’ effect on overall
system performance by comparing the boundaries of system’s detected
corrections with the gold standard. We evaluate both (1) the F-score
in detecting corrections (2) the F-score in correctly detecting both
the corrections’ and the error types they address.</p>
</div>
</div>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">We design experiments to answer two questions:</p>
</div>
<div id="S5.SS2.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">1.</h4>

<div id="S5.SS2.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">Do the additional contextual information about correction patterns
help guide the merging decisions? How much does a classifier
trained for this task improve the system’s overall accuracy?</p>
</div>
</div>
<div id="S5.SS2.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">2.</h4>

<div id="S5.SS2.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">How well does our method generalize over
revisions from different sources?</p>
</div>
<div id="S5.SS2.SSS0.P2.p2" class="ltx_para">
<p class="ltx_p">Our major experimental results are presented in Table
<a href="#S6.T4" title="Table 4 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a href="#S6.T6" title="Table 6 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. Table
<a href="#S6.T4" title="Table 4 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> compares the overall educational system’s
accuracies with different merging algorithms. Table
<a href="#S6.T6" title="Table 6 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the system’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS0.P2.p2.m1" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi>F</mi><mn>1</mn></msub></math> score when trained
and tested on different corpora. We make the following observations:</p>
</div>
<div id="S5.SS2.SSS0.P2.p3" class="ltx_para">
<p class="ltx_p">First, Table <a href="#S6.T4" title="Table 4 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that by incorporating
correction patterns into the merging algorithm, the errors in
correction detection step were reduced. This led to a
significant improvement on the overall system’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS0.P2.p3.m1" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi>F</mi><mn>1</mn></msub></math>-score on all
corpora. The improvement is most noticeable on FCE corpus, where the
error in correction detection step was reduced by
9%. That is, one third of the correction mis-detections were eliminated.
Table <a href="#S6.T5" title="Table 5 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows that the number of
merging errors are significantly reduced by the new merging
algorithm. In particular, the number of false positives (system
proposes merges when it should not) is significantly reduced.</p>
</div>
<div id="S5.SS2.SSS0.P2.p4" class="ltx_para">
<p class="ltx_p">Second, our proposed model is able to generalize over different
corpora. As shown in Table <a href="#S6.T6" title="Table 6 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The models built
on corpora can generally improve the correction detection
accuracy<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>We currently do not evaluate the end-to-end system
over different corpora. This is because different corpora employ
different error type categorization standards. </span></span></span>. Models built on
the same corpus generally perform the best. Also, as suggested by the
experimental result, among the four corpora, FCE corpus is a
comparably good resource for training correction detection models with
our current feature set. One reason is that FCE corpus has many more
training instances, which benefits model training. We tried varying
the training dataset size, and test it on different corpora. Figure
<a href="#S6.F13" title="Figure 13 ‣ 6 Conclusions ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> suggests that the model’s accuracies
increase with the training corpus size.</p>
</div>
</div>
</div>
<div id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">A revision often contains multiple corrections that address different
writing mistakes. We explore building computer programs to accurately
detect individual corrections in one single revision. One major
challenge lies in determining whether consecutive basic-edits address
the same mistake. We propose a classifier specialized in this task.
Our experiments suggest that: (1) the proposed classifier reduces
correction mis-detections in previous systems by 1/3, leading to
significant overall system performance. (2) our method is
generalizable over different data collections.</p>
</div>
<div id="S6.T4" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">Method</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">Corpus</span></th>
<th class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_small">Correction Detection </span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S6.T4.m1" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi>F</mi><mn>1</mn></msub></math></th>
<th class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_small">Overall </span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S6.T4.m2" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi>F</mi><mn>1</mn></msub></math><span class="ltx_text ltx_font_small">-score</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">FCE</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_small">70.40%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_small">57.10%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_small">MaxEntMerger</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr"><span class="ltx_text ltx_font_small">FCE</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_bold ltx_font_small">80.96%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_bold ltx_font_small">66.36%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">NUCLE</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_small">61.18%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_small">39.32%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_small">MaxEntMerger</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr"><span class="ltx_text ltx_font_small">NUCLE</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_bold ltx_font_small">63.88%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_bold ltx_font_small">41.00%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">UIUC</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_small">76.57%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_small">65.08%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_small">MaxEntMerger</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr"><span class="ltx_text ltx_font_small">UIUC</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_bold ltx_font_small">82.81%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_bold ltx_font_small">70.55%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></th>
<th class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">HOO2011</span></th>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_small">68.73%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_r ltx_border_t" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_small">50.95%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_small">MaxEntMerger</span></th>
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_rr"><span class="ltx_text ltx_font_small">HOO2011</span></th>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" style="width:48.4pt;" width="48.4pt"><span class="ltx_text ltx_font_bold ltx_font_small">75.71%</span></td>
<td class="ltx_td ltx_align_justify ltx_border_b ltx_border_r" style="width:39.8pt;" width="39.8pt"><span class="ltx_text ltx_font_bold ltx_font_small">56.14%</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 4: </span>Extrinsic evaluation, where we plugged the two merging models
into an end-to-end feedback detection system by Swanson and Yamangil. </div>
</div>
<div id="S6.T5" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Merging algorithm</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">TP</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FP</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FN</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">TN</span></th>
<th class="ltx_td ltx_border_t"/></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">33.73%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">13.46%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">5.71%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">47.10%</span></td>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">MaxEntMerger</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">36.04%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">3.26%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">3.41%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">57.30%</span></td>
<td class="ltx_td ltx_border_b"/></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 5: </span>Intrinsic evaluation, where we evaluate the proposed merging model’s prediction accuracy on
FCE corpus. This
table shows a breakdown of true-positives (TP), false-positives (FP),
false-negatives (FN) and true-negatives (TN) for the system built
on FCE corpus.</div>
</div>
<div id="S6.T6" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_ERROR undefined">\diagbox</span><span class="ltx_text ltx_font_small">[width=2cm]trainingtesting</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FCE</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">NUCLE</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">UIUC</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">HOO2011</span></th></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">S&amp;Y</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">70.44</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">61.18%</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">76.57%</span></th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">68.73%</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">FCE</span></th>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_small">80.96%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">61.26%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_small">83.07%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">75.43%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">NUCLE</span></th>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">74.53%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_small">63.88%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">78.57%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">74.73%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">UIUC</span></th>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">77.25%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">58.21%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">82.81%</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_small">70.83%</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text ltx_font_small">HOO2011</span></th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">71.94%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">54.99%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">71.19%</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_small">75.71%</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering ltx_font_small"><span class="ltx_tag ltx_tag_table">Table 6: </span>Correction detection experiments by building the model on one corpus, and applying it onto another. We evaluate the correction detection performance with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S6.T6.m2" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi mathsize="normal" stretchy="false">F</mi><mn mathsize="normal" stretchy="false">1</mn></msub></math> score. When training and testing on the same corpus, we run a 10-fold cross validation.</div>
</div>
<div id="S6.F13" class="ltx_figure"><img src="P14-2098/image002.png" id="S6.F13.g1" class="ltx_graphics ltx_centering" width="270" height="204" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span><span class="ltx_text ltx_font_small">We illustrate the performance of correction detection
systems trained on subsets of FCE corpus. Each curve in this
figure represents the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S6.F13.m3" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi mathsize="normal" stretchy="false">F</mi><mn mathsize="normal" stretchy="false">1</mn></msub></math>-scores for correction detection of
the model trained on a subset of FCE and tested on different
corpora. When testing on FCE, we used <math xmlns="http://www.w3.org/1998/Math/MathML" id="S6.F13.m4" class="ltx_Math" alttext="\frac{1}{11}" display="inline"><mfrac><mn mathsize="normal" stretchy="false">1</mn><mn mathsize="normal" stretchy="false">11</mn></mfrac></math> of the FCE
corpus, which we kept as development data.</span></div>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">This work is supported by U.S. National Science Foundation Grant
IIS-0745914. We thank the anonymous reviewers for their suggestions;
we also thank Homa Hashemi, Wencan Luo, Fan Zhang, Lingjia Deng,
Wenting Xiong and Yafei Wei for helpful discussions.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib199" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Cohn, C. Callison-Burch and M. Lapata</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Constructing corpora for the development and evaluation of paraphrase systems</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Computational Linguistics</span> <span class="ltx_text ltx_bib_volume">34</span> (<span class="ltx_text ltx_bib_number">4</span>), <span class="ltx_text ltx_bib_pages"> pp. 597–614</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">D. Dahlmeier, H. T. Ng and S. M. Wu</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Building a large annotated corpus of learner english: the NUS corpus of learner english</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 22–31</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib20" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">D. Dahlmeier and H. T. Ng</span><span class="ltx_text ltx_bib_year">(2012-06)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Better evaluation for grammatical error correction</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Montréal, Canada</span>, <span class="ltx_text ltx_bib_pages"> pp. 568–572</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.aclweb.org/anthology/N/N12/N12-1067" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib318" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Dale and A. Kilgarriff</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Helping our own: the HOO 2011 pilot shared task</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 242–249</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib187" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. A. Fregeau</span><span class="ltx_text ltx_bib_year">(1999)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Preparing ESL students for college writing: two case studies</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">The Internet TESL Journal</span> <span class="ltx_text ltx_bib_volume">5</span> (<span class="ltx_text ltx_bib_number">10</span>).
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib247" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Granger</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The International Corpus of Learner English: a new resource for foreign language learning and teaching and second language acquisition research</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Tesol Quarterly</span> <span class="ltx_text ltx_bib_volume">37</span> (<span class="ltx_text ltx_bib_number">3</span>), <span class="ltx_text ltx_bib_pages"> pp. 538–546</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib249" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Gui and H. Yang</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Zhongguo xuexizhe yingyu yuliaohu.(chinese learner english corpus)</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Shanghai: Shanghai Waiyu Jiaoyu Chubanshe</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib57" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Heilman and N. A. Smith</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Tree edit models for recognizing textual entailments, paraphrases, and answers to questions</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1011–1019</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib139" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Koehn, F.J. Och and D. Marcu</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Statistical phrase-based translation</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 48–54</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib4" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">V. I. Levenshtein</span><span class="ltx_text ltx_bib_year">(1966)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Binary codes capable of correcting deletions, insertions, and reversals</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Soviet Physics Doklady</span> <span class="ltx_text ltx_bib_volume">10</span> (<span class="ltx_text ltx_bib_number">8</span>), <span class="ltx_text ltx_bib_pages"> pp. 707â710</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.F5" title="Figure 5 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
</span></li>
<li id="bib.bib271" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">D. Nicholls</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The Cambridge Learner Corpus: Error coding and analysis for lexicography and ELT</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 572–581</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib67" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Rozovskaya and D. Roth</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Annotating ESL errors: challenges and rewards</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 28–36</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib203" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. G. Snover, N. Madnani, B. Dorr and R. Schwartz</span><span class="ltx_text ltx_bib_year">(2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">TER-Plus: paraphrase, semantic, and alignment enhancements to translation edit rate</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Machine Translation</span> <span class="ltx_text ltx_bib_volume">23</span> (<span class="ltx_text ltx_bib_number">2-3</span>), <span class="ltx_text ltx_bib_pages"> pp. 117–127</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib14" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Swanson and E. Yamangil</span><span class="ltx_text ltx_bib_year">(2012-06)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Correction detection and error type selection as an ESL educational aid</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_place">Montréal, Canada</span>, <span class="ltx_text ltx_bib_pages"> pp. 357–361</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.aclweb.org/anthology/N12-1037" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.F8" title="Figure 8 ‣ 2 Correction Detection ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>,
<a href="#S4.SS2.p1" title="4.2 Evaluation Metrics ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>.
</span></li>
<li id="bib.bib13" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Tajiri, M. Komachi and Y. Matsumoto</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Tense and aspect error correction for ESL learners using global context</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 198–202</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.p1" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
<li id="bib.bib186" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. G. Williams</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Providing feedback on ESL studentsâ written assignments</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">The Internet TESL Journal</span> <span class="ltx_text ltx_bib_volume">4</span> (<span class="ltx_text ltx_bib_number">10</span>).
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib49" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Yannakoudakis, T. Briscoe and B. Medlock</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A new dataset and method for automatically grading esol texts</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 180–189</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S4.SS1.p2" title="4.1 Dataset ‣ 4 Experimental Setup ‣ Improved Correction Detection in Revised ESL Sentences" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 18:12:46 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
