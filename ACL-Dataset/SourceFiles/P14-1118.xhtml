<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Opinion Mining on YouTube</title>
<!--Generated on Tue Jun 10 18:54:16 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Opinion Mining on YouTube</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aliaksei Severyn<math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="{}^{1}" display="inline"><msup><mi/><mn>1</mn></msup></math>, Alessandro Moschitti<math xmlns="http://www.w3.org/1998/Math/MathML" id="m2" class="ltx_Math" alttext="{}^{3,1}" display="inline"><msup><mi/><mrow><mn>3</mn><mo>,</mo><mn>1</mn></mrow></msup></math>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold">Olga Uryupina<math xmlns="http://www.w3.org/1998/Math/MathML" id="m3" class="ltx_Math" alttext="{}^{1}" display="inline"><msup><mi/><mn mathvariant="normal">1</mn></msup></math></span>, <span class="ltx_text ltx_font_bold">Barbara Plank<math xmlns="http://www.w3.org/1998/Math/MathML" id="m4" class="ltx_Math" alttext="{}^{2}" display="inline"><msup><mi/><mn mathvariant="normal">2</mn></msup></math></span>, <span class="ltx_text ltx_font_bold">Katja Filippova<math xmlns="http://www.w3.org/1998/Math/MathML" id="m5" class="ltx_Math" alttext="{}^{4}" display="inline"><msup><mi/><mn mathvariant="normal">4</mn></msup></math>
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m6" class="ltx_Math" alttext="{}^{1}" display="inline"><msup><mi/><mn mathvariant="normal">1</mn></msup></math></span>DISI - University of Trento, <math xmlns="http://www.w3.org/1998/Math/MathML" id="m7" class="ltx_Math" alttext="{}^{2}" display="inline"><msup><mi/><mn>2</mn></msup></math>CLT - University of Copenhagen, 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m8" class="ltx_Math" alttext="{}^{3}" display="inline"><msup><mi/><mn>3</mn></msup></math>Qatar Computing Research Institute, <math xmlns="http://www.w3.org/1998/Math/MathML" id="m9" class="ltx_Math" alttext="{}^{4}" display="inline"><msup><mi/><mn>4</mn></msup></math>Google Inc. 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">severyn@disi.unitn.it, amoschitti@qf.org.qa,</span> 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">uryupina@gmail.com, bplank@cst.dk, katjaf@google.com</span>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">This paper defines a systematic approach to Opinion Mining (OM) on YouTube comments by (i) modeling classifiers for predicting the opinion polarity and the type of comment and (ii) proposing robust shallow syntactic structures for improving model adaptability.
We rely on the tree kernel technology to automatically extract and learn features with better generalization power than bag-of-words.
An extensive empirical evaluation on our manually annotated YouTube comments corpus shows a high classification accuracy and highlights the benefits of structural models in a cross-domain setting.</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Social media such as Twitter, Facebook or YouTube contain rapidly changing information generated by millions of users that can dramatically affect the reputation of a person or an organization. This raises the importance of automatic extraction of sentiments and opinions expressed in social media.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">YouTube is a unique environment, just like Twitter, but probably even richer: multi-modal, with a social graph, and discussions between people sharing an interest.
Hence, doing sentiment research in such an environment is highly relevant for the community.
While the linguistic conventions used on Twitter and YouTube indeed show similarities <cite class="ltx_cite">[<a href="#bib.bib9" title="How noisy social media text, how diffrnt social media sources?" class="ltx_ref">2</a>]</cite>, focusing on YouTube allows to exploit context information, possibly also multi-modal information, not available in isolated tweets, thus rendering it a valuable resource for the future research.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">Nevertheless, there is almost no work showing effective OM on YouTube comments. To the best of our knowledge, the only exception is given by the classification system of YouTube comments proposed by <cite class="ltx_cite">Siersdorfer<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib1" title="How useful are your comments?: Analyzing and predicting YouTube comments and comment ratings" class="ltx_ref">2010</a>)</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">While previous state-of-the-art models for opinion classification have been successfully applied to traditional corpora <cite class="ltx_cite">[<a href="#bib.bib6" title="Opinion mining and sentiment analysis" class="ltx_ref">15</a>]</cite>,
YouTube comments pose additional challenges: (i) polarity words can refer to either video or product while expressing contrasting sentiments; (ii) many comments are unrelated or contain spam; and (iii) learning supervised models requires training data for each different YouTube domain, e.g., <span class="ltx_text ltx_font_italic">tablets</span>, <span class="ltx_text ltx_font_italic">automobiles</span>, etc.
For example, consider a typical comment on a YouTube review video about a <span class="ltx_text ltx_font_italic">Motorola Xoom</span> tablet:</p>
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">this guy really puts a <span class="ltx_text" style="color:#FF0000;"> negative</span> spin on this , and I ’m not sure why , this seems <span class="ltx_text" style="color:#FF0000;"> crazy</span> fast , and I ’m not entirely sure why his pinch to zoom his <span class="ltx_text" style="color:#FF0000;"> laggy</span> all the other <span class="ltx_text ltx_font_bold">xoom</span> reviews</span></p>
</blockquote>
<p class="ltx_p">The comment contains a product name <span class="ltx_text ltx_font_italic">xoom</span> and some negative expressions, thus, a bag-of-words model would derive a negative polarity for this product. In contrast, the opinion towards the product is neutral as the negative sentiment is expressed towards the video.
Similarly, the following comment:</p>
<blockquote class="ltx_quote">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">iPad 2 is <span class="ltx_text" style="color:#0000FF;">better</span>. the <span class="ltx_text" style="color:#0000FF;">superior</span> apps just <span class="ltx_text" style="color:#FF0000;"> destroy</span> the <span class="ltx_text ltx_font_bold">xoom</span>.</span></p>
</blockquote>
<p class="ltx_p">contains two positive and one negative word, yet the sentiment towards the product is negative (the negative word <em class="ltx_emph">destroy</em> refers to <em class="ltx_emph">Xoom</em>). Clearly, the bag-of-words lacks the structural information linking the sentiment with the target product.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">In this paper, we carry out a systematic study on OM targeting YouTube comments; its contribution is three-fold: firstly, to
solve the problems outlined above, we define a classification schema, which separates spam and not related comments from the informative ones, which are, in turn, further categorized into video- or product-related comments (type classification). At the final stage, different classifiers assign polarity (positive, negative or neutral) to each type of a meaningful comment. This allows us to filter out irrelevant comments, providing accurate OM distinguishing comments about the video and the target product.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">The second contribution of the paper is the creation and annotation (by an expert coder) of a comment corpus containing 35k manually labeled comments for two product YouTube domains: <em class="ltx_emph">tablets</em> and <em class="ltx_emph">automobiles</em>.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>The corpus and the annotation guidelines are publicly available at: <a href="http://projects.disi.unitn.it/iKernels/projects/sentube/" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://projects.disi.unitn.it/iKernels/projects/sentube/</span></a></span></span></span> It is the first manually annotated corpus that enables researchers to use supervised methods on YouTube for comment classification and opinion analysis. The comments from different product domains exhibit different properties (cf. Sec. <a href="#S5.SS2" title="5.2 Data ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>), which give the possibility to study the domain adaptability of the supervised models by training on one category and testing on the other (and vice versa).</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">The third contribution of the paper is a novel structural representation, based on shallow syntactic trees enriched with conceptual information, i.e., tags generalizing the specific topic of the video, e.g., <em class="ltx_emph">iPad</em>, <em class="ltx_emph">Kindle</em>, <em class="ltx_emph">Toyota Camry</em>.
Given the complexity and the novelty of the task, we exploit structural kernels to automatically engineer novel features. In particular, we define an efficient tree kernel derived from the Partial Tree Kernel, <cite class="ltx_cite">[<a href="#bib.bib42" title="Efficient convolution kernels for dependency and constituent syntactic trees" class="ltx_ref">10</a>]</cite>, suitable for encoding structural representation of comments into Support Vector Machines (SVMs).
Finally, our results show that our models are adaptable, especially when the structural information is used. Structural models generally improve on both tasks – polarity and type classification – yielding up to 30% of relative improvement, when little data is available.
Hence, the impractical task of annotating data for each YouTube category can be mitigated by the use of models that adapt better across domains.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Most prior work on more general OM has been carried out on more
standardized forms of text, such as consumer reviews or newswire. The
most commonly used datasets include: the MPQA corpus of news documents
<cite class="ltx_cite">[<a href="#bib.bib22" title="Recognizing contextual polarity in phrase-level sentiment analysis" class="ltx_ref">29</a>]</cite>, web customer review data <cite class="ltx_cite">[<a href="#bib.bib21" title="Mining and summarizing customer reviews" class="ltx_ref">6</a>]</cite>, Amazon review
data <cite class="ltx_cite">[<a href="#bib.bib17" title="Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification" class="ltx_ref">3</a>]</cite>, the JDPA corpus of blogs
<cite class="ltx_cite">[<a href="#bib.bib16" title="The 2010 ICWSM JDPA sentiment corpus for the automotive domain" class="ltx_ref">8</a>]</cite>, etc. The aforementioned corpora are, however, only
partially suitable for developing models on social media, since the
informal text poses additional challenges for Information Extraction
and Natural Language Processing. Similar to Twitter, most YouTube
comments are very short, the language is informal with numerous
accidental and deliberate errors and grammatical inconsistencies,
which makes previous corpora less suitable to train models for OM on
YouTube. A recent study focuses on sentiment analysis for
Twitter <cite class="ltx_cite">[<a href="#bib.bib8" title="Twitter as a corpus for sentiment analysis and opinion mining." class="ltx_ref">14</a>]</cite>, however, their corpus was compiled automatically by
searching for emoticons expressing positive and negative sentiment
only.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p"><cite class="ltx_cite">Siersdorfer<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib1" title="How useful are your comments?: Analyzing and predicting YouTube comments and comment ratings" class="ltx_ref">2010</a>)</cite> focus on exploiting user ratings
(counts of ‘thumbs up/down’ as flagged by other users) of
YouTube video comments to train classifiers to predict the community
acceptance of new comments. Hence, their goal is different: predicting comment ratings, rather than predicting the sentiment expressed in a YouTube comment or its information content. Exploiting
the information from user ratings is a feature that we have not
exploited thus far, but we believe that it is a valuable feature to
use in future work.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">Most of the previous work on supervised sentiment analysis use feature
vectors to encode documents. While a few successful attempts have been
made to use more involved linguistic analysis for opinion mining,
such as dependency trees with latent nodes <cite class="ltx_cite">[<a href="#bib.bib25" title="Semi-supervised latent variable models for sentence-level sentiment analysis" class="ltx_ref">26</a>]</cite> and
syntactic parse trees with vectorized nodes <cite class="ltx_cite">[<a href="#bib.bib24" title="Semi-supervised recursive autoencoders for predicting sentiment distributions" class="ltx_ref">24</a>]</cite>,
recently, a comprehensive study by <cite class="ltx_cite">Wang and Manning (<a href="#bib.bib23" title="Baselines and bigrams: simple, good sentiment and topic classification" class="ltx_ref">2012</a>)</cite> showed that a
simple model using bigrams and SVMs performs on par with more complex
models.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">In contrast, we show that adding structural features from syntactic
trees is particularly useful for the cross-domain setting.
They help to build a system that is more robust across domains.
Therefore, rather than trying to build a specialized system for every
new target domain, as it has been done in most prior work on domain
adaptation <cite class="ltx_cite">[<a href="#bib.bib17" title="Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification" class="ltx_ref">3</a>, <a href="#bib.bib10" title="Frustratingly easy domain adaptation" class="ltx_ref">4</a>]</cite>, the domain
adaptation problem boils down to finding a more robust
system <cite class="ltx_cite">[<a href="#bib.bib4" title="Robust learning in random subspaces: equipping nlp for oov effects." class="ltx_ref">25</a>, <a href="#bib.bib5" title="Embedding semantic similarity in tree kernels for domain adaptation of relation extraction" class="ltx_ref">17</a>]</cite>.
This is in line with recent advances in parsing the
web <cite class="ltx_cite">[<a href="#bib.bib3" title="Overview of the 2012 shared task on parsing the web" class="ltx_ref">16</a>]</cite>, where participants where asked to build
a single system able to cope with different yet related domains.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p">Our approach relies on robust syntactic structures to automatically
generate patterns that adapt better. These representations have been inspired by the semantic models developed for Question Answering <cite class="ltx_cite">[<a href="#bib.bib53" title="Kernel methods, syntax and semantics for relational text categorization" class="ltx_ref">12</a>, <a href="#bib.bib54" title="Structural relationships for large-scale learning of answer re-ranking" class="ltx_ref">19</a>, <a href="#bib.bib36" title="Automatic feature engineering for answer selection and extraction" class="ltx_ref">20</a>]</cite> and Semantic Textual Similarity <cite class="ltx_cite">[<a href="#bib.bib35" title="Learning semantic textual similarity with structural representations" class="ltx_ref">21</a>]</cite>.
Moreover, we introduce additional tags,
e.g., video concepts, polarity and negation words, to achieve better generalization across different domains where the word distribution and vocabulary changes.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Representations and models</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">Our approach to OM on YouTube relies on the design of classifiers to predict comment type and opinion polarity. Such classifiers are traditionally based on bag-of-words and more advanced features. In the next sections, we define a baseline feature vector model and a novel structural model based on kernel methods.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Feature Set</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We enrich the traditional bag-of-word representation with features from a sentiment lexicon and features quantifying the negation present in the comment. Our model (<span class="ltx_text ltx_font_typewriter">FVEC</span>) encodes each document using the following feature groups:</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">- <span class="ltx_text ltx_font_bold">word n-grams</span>: we compute unigrams and bigrams over lower-cased word lemmas where binary values are used to indicate the presence/absence of a given item.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">- <span class="ltx_text ltx_font_bold">lexicon</span>: a sentiment lexicon is a collection of words associated with a positive or negative sentiment. We use two manually constructed sentiment lexicons that are freely available: the MPQA Lexicon <cite class="ltx_cite">[<a href="#bib.bib22" title="Recognizing contextual polarity in phrase-level sentiment analysis" class="ltx_ref">29</a>]</cite> and the lexicon of <cite class="ltx_cite">Hu and Liu (<a href="#bib.bib21" title="Mining and summarizing customer reviews" class="ltx_ref">2004</a>)</cite>. For each of the lexicons, we use the number of words found in the comment that have <span class="ltx_text ltx_font_italic">positive</span> and <span class="ltx_text ltx_font_italic">negative</span> sentiment as a feature.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p class="ltx_p">- <span class="ltx_text ltx_font_bold">negation</span>: the count of negation words, e.g., {<span class="ltx_text ltx_font_italic">don’t, never, not, etc.</span>}, found in a comment.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>The list of negation words is adopted from http://sentiment.christopherpotts.net/lingstruc.html</span></span></span> Our structural representation (defined next) enables a more involved treatment of negation.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p">- <span class="ltx_text ltx_font_bold">video concept</span>: cosine similarity between a comment and the title/description of the video. Most of the videos come with a title and a short description, which can be used to encode the topicality of each comment by looking at their overlap.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Structural model</h3>

<div id="S3.F1" class="ltx_figure ltx_align_center"><img src="P14-1118/image005.png" id="S3.F1.g1" class="ltx_graphics" width="379" height="133" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Shallow tree representation of the example comment (labeled with <span class="ltx_text ltx_font_typewriter">product</span> type and <span class="ltx_text ltx_font_typewriter">negative</span> sentiment): <span class="ltx_text ltx_font_italic">“iPad 2 is better. the superior apps just destroy the xoom.”</span> (lemmas are replaced with words for readability) taken from the video “Motorola Xoom Review”. We introduce additional tags in the tree nodes to encode the central concept of the video (motorola <span class="ltx_text ltx_font_italic">xoom</span>) and sentiment-bearing words <span class="ltx_text ltx_font_italic">(better, superior, destroy)</span> directly in the tree nodes. For the former we add a <span class="ltx_text ltx_font_typewriter">PRODUCT</span> tag on the chunk and part-of-speech nodes of the word <span class="ltx_text ltx_font_italic">xoom</span>) and polarity tags (<span class="ltx_text ltx_font_italic">positive</span> and <span class="ltx_text ltx_font_italic">negative</span>) for the latter. Two sentences are split into separate root nodes <span class="ltx_text ltx_font_typewriter">S</span>.</div>
</div>
<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">We go beyond traditional feature vectors by employing structural models (<span class="ltx_text ltx_font_typewriter">STRUCT</span>), which encode each comment into a shallow syntactic tree. These trees are input to tree kernel functions for generating structural features. Our structures are specifically adapted to the noisy user-generated texts and encode important aspects of the comments, e.g., words from the sentiment lexicons, product concepts and negation words, which specifically targets the sentiment and comment type classification tasks.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">In particular, our shallow tree structure is a two-level syntactic hierarchy built from word lemmas (leaves) and part-of-speech tags that are further grouped into chunks (Fig. <a href="#S3.F1" title="Figure 1 ‣ 3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>). As full syntactic parsers such as constituency or dependency tree parsers would significantly degrade in performance on noisy texts, e.g., Twitter or YouTube comments, we opted for shallow structures, which rely on simpler and more robust components: a part-of-speech tagger and a chunker. Moreover, such taggers have been recently updated with models <cite class="ltx_cite">[<a href="#bib.bib20" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">18</a>, <a href="#bib.bib19" title="Part-of-speech tagging for Twitter: annotation, features, and experiments" class="ltx_ref">5</a>]</cite> trained specifically to process noisy texts showing significant reductions in the error rate on user-generated texts, e.g., Twitter. Hence, we use the CMU Twitter pos-tagger <cite class="ltx_cite">[<a href="#bib.bib19" title="Part-of-speech tagging for Twitter: annotation, features, and experiments" class="ltx_ref">5</a>, <a href="#bib.bib7" title="Improved part-of-speech tagging for online conversational text with word clusters" class="ltx_ref">13</a>]</cite> to obtain the part-of-speech tags.
Our second component – chunker – is taken from <cite class="ltx_cite">[<a href="#bib.bib20" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">18</a>]</cite>, which also comes with a model trained on Twitter data<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>The chunker from <cite class="ltx_cite">[<a href="#bib.bib20" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">18</a>]</cite> relies on its own POS tagger, however, in our structural representations we favor the POS tags from the CMU Twitter tagger and take only the chunk tags from the chunker.</span></span></span> and shown to perform better on noisy data such as user comments.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p">To address the specifics of OM tasks on YouTube comments, we enrich syntactic trees with semantic tags to encode: (i) central concepts of the video, (ii) sentiment-bearing words expressing <span class="ltx_text ltx_font_italic">positive</span> or <span class="ltx_text ltx_font_italic">negative</span> sentiment and (iii) negation words. To automatically identify concept words of the video we use context words (tokens detected as nouns by the part-of-speech tagger) from the video title and video description and match them in the tree. For the matched words, we enrich labels of their parent nodes (part-of-speech and chunk) with the <span class="ltx_text ltx_font_typewriter">PRODUCT</span> tag. Similarly, the nodes associated with words found in the sentiment lexicon are enriched with a polarity tag (either <span class="ltx_text ltx_font_italic">positive</span> or <span class="ltx_text ltx_font_italic">negative</span>), while negation words are labeled with the <span class="ltx_text ltx_font_typewriter">NEG</span> tag. It should be noted that vector-based (<span class="ltx_text ltx_font_typewriter">FVEC</span>) model relies only on feature counts whereas the proposed tree encodes powerful contextual syntactic features in terms of tree fragments. The latter are automatically generated and learned by SVMs with expressive tree kernels.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p class="ltx_p">For example, the comment in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows two <span class="ltx_text ltx_font_italic">positive</span> and one <span class="ltx_text ltx_font_italic">negative</span> word from the sentiment lexicon. This would strongly bias the <span class="ltx_text ltx_font_typewriter">FVEC</span> sentiment classifier to assign a <span class="ltx_text ltx_font_typewriter">positive</span> label to the comment. In contrast, the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model relies on the fact that the negative word, <em class="ltx_emph">destroy</em>, refers to the PRODUCT (<em class="ltx_emph">xoom</em>) since they form a verbal phase (VP). In other words, the tree fragment: <span class="ltx_text ltx_font_typewriter">[S [negative-VP [negative-V [destroy]] [PRODUCT-NP [PRODUCT-N [xoom]]]]</span> is a strong feature (induced by tree kernels) to help the classifier to discriminate such hard cases. Moreover, tree kernels generate all possible subtrees, thus producing generalized (back-off) features, e.g., <span class="ltx_text ltx_font_typewriter">[S [negative-VP [negative-V [destroy]] [PRODUCT-NP]]]]</span> or <span class="ltx_text ltx_font_typewriter">[S [negative-VP [PRODUCT-NP]]]]</span>.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Learning</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">We perform OM on YouTube using supervised methods, e.g., SVM. Our goal is to learn a model to automatically detect the sentiment and type of each comment. For this purpose, we build a multi-class classifier using the one-vs-all scheme. A binary classifier is trained for each of the classes and the predicted class is obtained by taking a class from the classifier with a maximum prediction score. Our back-end binary classifier is SVM-light-TK<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>http://disi.unitn.it/moschitti/Tree-Kernel.htm</span></span></span>, which encodes structural kernels in the SVM-light <cite class="ltx_cite">[<a href="#bib.bib49" title="Optimizing search engines using clickthrough data" class="ltx_ref">7</a>]</cite> solver. We define a novel and efficient tree kernel function, namely, <span class="ltx_text ltx_font_bold" style="text-decoration:underline;">Sh</span>allow syntactic <span class="ltx_text ltx_font_bold" style="text-decoration:underline;">T</span>ree <span class="ltx_text ltx_font_bold" style="text-decoration:underline;">K</span>ernel (SHTK), which is as expressive as the Partial Tree Kernel (PTK) <cite class="ltx_cite">[<a href="#bib.bib42" title="Efficient convolution kernels for dependency and constituent syntactic trees" class="ltx_ref">10</a>]</cite> to handle feature engineering over the structural representations of the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model. A polynomial kernel of degree 3 is applied to feature vectors (<span class="ltx_text ltx_font_typewriter">FVEC</span>).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Combining structural and vector models.</span>
A typical kernel machine, e.g., SVM, classifies a test input <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m1" class="ltx_Math" alttext="\boldsymbol{x}" display="inline"><mi>𝒙</mi></math> using the following prediction function: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m2" class="ltx_Math" alttext="h(\boldsymbol{x})=\sum_{i}\alpha_{i}y_{i}K(\boldsymbol{x},\boldsymbol{x}_{i})" display="inline"><mrow><mrow><mi>h</mi><mo>⁢</mo><mrow><mo>(</mo><mi>𝒙</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mi>i</mi></msub><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>⁢</mo><msub><mi>y</mi><mi>i</mi></msub><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>𝒙</mi><mo>,</mo><msub><mi>𝒙</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m3" class="ltx_Math" alttext="\alpha_{i}" display="inline"><msub><mi>α</mi><mi>i</mi></msub></math> are the model parameters estimated from the training data, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m4" class="ltx_Math" alttext="y_{i}" display="inline"><msub><mi>y</mi><mi>i</mi></msub></math> are target variables, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m5" class="ltx_Math" alttext="\boldsymbol{x}_{i}" display="inline"><msub><mi>𝒙</mi><mi>i</mi></msub></math> are support vectors, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m6" class="ltx_Math" alttext="K(\cdot,\cdot)" display="inline"><mrow><mi>K</mi><mrow><mo>(</mo><mo>⋅</mo><mo>,</mo><mo>⋅</mo><mo>)</mo></mrow></mrow></math> is a kernel function. The latter computes the <em class="ltx_emph">similarity</em> between two comments.
The <span class="ltx_text ltx_font_typewriter">STRUCT</span> model treats each comment as a tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m7" class="ltx_Math" alttext="\boldsymbol{x}=\langle\boldsymbol{T},\boldsymbol{v}\rangle" display="inline"><mrow><mi>𝒙</mi><mo>=</mo><mrow><mo>⟨</mo><mrow><mi>𝑻</mi><mo>,</mo><mi>𝒗</mi></mrow><mo>⟩</mo></mrow></mrow></math> composed of a shallow syntactic tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m8" class="ltx_Math" alttext="\boldsymbol{T}" display="inline"><mi>𝑻</mi></math> and a feature vector <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m9" class="ltx_Math" alttext="\boldsymbol{v}" display="inline"><mi>𝒗</mi></math>. Hence, for each pair of comments <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m10" class="ltx_Math" alttext="\boldsymbol{x}_{1}" display="inline"><msub><mi>𝒙</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m11" class="ltx_Math" alttext="\boldsymbol{x}_{2}" display="inline"><msub><mi>𝒙</mi><mn>2</mn></msub></math>, we define the following comment similarity kernel:</p>
<table id="S3.E1" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E1.m1" class="ltx_Math" alttext="\begin{array}[]{lcl}K(\boldsymbol{x}_{1},\boldsymbol{x}_{2})=K_{\text{TK}}(%&#10;\boldsymbol{T}_{1},\boldsymbol{T}_{2})+K_{\text{v}}(\boldsymbol{v}_{1},%&#10;\boldsymbol{v}_{2}),\end{array}\vspace{-.7em}" display="block"><mtable align="center" columnspacing="0.4em" rowspacing="0.2ex"><mtr><mtd columnalign="left"><mrow><mrow><mrow><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>𝒙</mi><mn>1</mn></msub><mo>,</mo><msub><mi>𝒙</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><msub><mi>K</mi><mtext>TK</mtext></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>𝑻</mi><mn>1</mn></msub><mo>,</mo><msub><mi>𝑻</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><msub><mi>K</mi><mtext>v</mtext></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>𝒗</mi><mn>1</mn></msub><mo>,</mo><msub><mi>𝒗</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>,</mo></mrow></mtd><mtd/><mtd/></mtr></mtable></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(1)</span></td></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m12" class="ltx_Math" alttext="K_{\text{TK}}" display="inline"><msub><mi>K</mi><mtext>TK</mtext></msub></math> computes SHTK (defined next), and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p2.m13" class="ltx_Math" alttext="K_{\text{v}}" display="inline"><msub><mi>K</mi><mtext>v</mtext></msub></math> is a kernel over feature vectors, e.g., linear, polynomial, Gaussian, etc.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Shallow syntactic tree kernel.</span>
Following the convolution kernel framework, we define the new SHTK function from Eq. <a href="#S3.E1" title="(1) ‣ 3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> to compute the similarity between tree structures. It counts the number of common substructures between two trees <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m1" class="ltx_Math" alttext="T_{1}" display="inline"><msub><mi>T</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m2" class="ltx_Math" alttext="T_{2}" display="inline"><msub><mi>T</mi><mn>2</mn></msub></math> without explicitly considering the whole fragment space. The general equations for Convolution Tree Kernels is:</p>
<table id="S3.E2" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E2.m1" class="ltx_Math" alttext="TK(T_{1},T_{2})=\sum_{n_{1}\in N_{T_{1}}}\sum_{n_{2}\in N_{T_{2}}}\Delta(n_{1}%&#10;,n_{2}),\vspace{-.5em}" display="block"><mrow><mrow><mrow><mi>T</mi><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>∈</mo><msub><mi>N</mi><msub><mi>T</mi><mn>1</mn></msub></msub></mrow></munder><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>2</mn></msub><mo>∈</mo><msub><mi>N</mi><msub><mi>T</mi><mn>2</mn></msub></msub></mrow></munder><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(2)</span></td></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m3" class="ltx_Math" alttext="N_{T_{1}}" display="inline"><msub><mi>N</mi><msub><mi>T</mi><mn>1</mn></msub></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m4" class="ltx_Math" alttext="N_{T_{2}}" display="inline"><msub><mi>N</mi><msub><mi>T</mi><mn>2</mn></msub></msub></math> are the sets of the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m5" class="ltx_Math" alttext="T_{1}" display="inline"><msub><mi>T</mi><mn>1</mn></msub></math>’s and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m6" class="ltx_Math" alttext="T_{2}" display="inline"><msub><mi>T</mi><mn>2</mn></msub></math>’s nodes, respectively and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m7" class="ltx_Math" alttext="\Delta(n_{1},n_{2})" display="inline"><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></math> is equal to the number of common fragments rooted in the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m8" class="ltx_Math" alttext="n_{1}" display="inline"><msub><mi>n</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m9" class="ltx_Math" alttext="n_{2}" display="inline"><msub><mi>n</mi><mn>2</mn></msub></math> nodes, according to several possible definition of the atomic fragments.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p class="ltx_p">To improve the speed computation of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m1" class="ltx_Math" alttext="TK" display="inline"><mrow><mi>T</mi><mo>⁢</mo><mi>K</mi></mrow></math>, we consider pairs of nodes <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m2" class="ltx_Math" alttext="(n_{1},n_{2})" display="inline"><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></math> belonging to the same tree level. Thus, given <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m3" class="ltx_Math" alttext="H" display="inline"><mi>H</mi></math>, the height of the <span class="ltx_text ltx_font_typewriter">STRUCT</span> trees, where each level <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m4" class="ltx_Math" alttext="h" display="inline"><mi>h</mi></math> contains nodes of the same type, i.e., chunk, POS, and lexical nodes, we define SHTK as the following<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>To have a similarity score between 0 and 1, a normalization in the kernel space, i.e. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m5" class="ltx_Math" alttext="\frac{SHTK(T_{1},T_{2})}{\sqrt{SHTK(T_{1},T_{1})\times SHTK(T_{2},T_{2})}}" display="inline"><mfrac><mrow><mi>S</mi><mo>⁢</mo><mi>H</mi><mo>⁢</mo><mi>T</mi><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><msqrt><mrow><mrow><mrow><mi>S</mi><mo>⁢</mo><mi>H</mi><mo>⁢</mo><mi>T</mi><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>1</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>×</mo><mi>S</mi></mrow><mo>⁢</mo><mi>H</mi><mo>⁢</mo><mi>T</mi><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>2</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></msqrt></mfrac></math> is applied.</span></span></span>:</p>
<table id="S3.E3" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E3.m1" class="ltx_Math" alttext="\hskip{-5.0pt}SHTK(T_{1},T_{2})=\hskip{-2.0pt}\sum_{h=1}^{H}\sum_{n_{1}\in N^{%&#10;h}_{T_{1}}}\hskip{-3.0pt}\sum_{n_{2}\in N^{h}_{T_{2}}}\hskip{-3.0pt}\Delta(n_{%&#10;1},n_{2}),\hskip{-8.0pt}\vspace{-.8em}" display="block"><mrow><mrow><mrow><mpadded lspace="-5.0pt" width="-5.0pt"><mi>S</mi></mpadded><mo>⁢</mo><mi>H</mi><mo>⁢</mo><mi>T</mi><mo>⁢</mo><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo rspace="0.5pt">=</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>h</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover><mrow><mpadded width="-3.0pt"><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>∈</mo><msubsup><mi>N</mi><msub><mi>T</mi><mn>1</mn></msub><mi>h</mi></msubsup></mrow></munder></mpadded><mrow><mpadded width="-3.0pt"><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>2</mn></msub><mo>∈</mo><msubsup><mi>N</mi><msub><mi>T</mi><mn>2</mn></msub><mi>h</mi></msubsup></mrow></munder></mpadded><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(3)</span></td></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m6" class="ltx_Math" alttext="N^{h}_{T_{1}}" display="inline"><msubsup><mi>N</mi><msub><mi>T</mi><mn>1</mn></msub><mi>h</mi></msubsup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m7" class="ltx_Math" alttext="N^{h}_{T_{2}}" display="inline"><msubsup><mi>N</mi><msub><mi>T</mi><mn>2</mn></msub><mi>h</mi></msubsup></math> are sets of nodes at height <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m8" class="ltx_Math" alttext="h" display="inline"><mi>h</mi></math>.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p class="ltx_p">The above equation can be applied with any <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m1" class="ltx_Math" alttext="\Delta" display="inline"><mi mathvariant="normal">Δ</mi></math> function. To have a more general and expressive kernel, we use <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m2" class="ltx_Math" alttext="\Delta" display="inline"><mi mathvariant="normal">Δ</mi></math> previously defined for PTK. More formally: if <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m3" class="ltx_Math" alttext="n_{1}" display="inline"><msub><mi>n</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m4" class="ltx_Math" alttext="n_{2}" display="inline"><msub><mi>n</mi><mn>2</mn></msub></math> are leaves then <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m5" class="ltx_Math" alttext="\Delta(n_{1},n_{2})=\mu\lambda(n_{1},n_{2})" display="inline"><mrow><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>μ</mi><mo>⁢</mo><mi>λ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></math>;
else <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m6" class="ltx_Math" alttext="\Delta(n_{1},n_{2})=" display="inline"><mrow><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math> 
<br class="ltx_break"/></p>
<table id="S3.Ex1" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex1.m1" class="ltx_Math" alttext="\mu\Big(\lambda^{2}+\hskip{-20.0pt}\sum_{\vec{I}_{1},\vec{I}_{2},|\vec{I}_{1}|%&#10;=|\vec{I}_{2}|}\hskip{-20.0pt}\lambda^{\scriptscriptstyle d(\vec{I}_{1})+d(%&#10;\vec{I}_{2})}\prod_{j=1}^{|\vec{I}_{1}|}\Delta(c_{n_{1}}({\vec{I}_{1j}}),c_{n_%&#10;{2}}({\vec{I}_{2j})})\Big)," display="block"><mrow><mrow><mi>μ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msup><mi>λ</mi><mn>2</mn></msup><mo rspace="0pt">+</mo><mrow><mpadded width="-20.0pt"><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mrow><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo>,</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub><mo>,</mo><mrow><mo fence="true">|</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo fence="true">|</mo></mrow></mrow><mo>=</mo><mrow><mo fence="true">|</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub><mo fence="true">|</mo></mrow></mrow></munder></mpadded><mrow><msup><mi>λ</mi><mrow><mrow><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub><mo>)</mo></mrow></mrow></mrow></msup><mo>⁢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mrow><mo fence="true">|</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo fence="true">|</mo></mrow></munderover><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mrow><msub><mi>c</mi><msub><mi>n</mi><mn>1</mn></msub></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mrow><mn>1</mn><mo>⁢</mo><mi>j</mi></mrow></msub><mo>)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>c</mi><msub><mi>n</mi><mn>2</mn></msub></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mrow><mn>2</mn><mo>⁢</mo><mi>j</mi></mrow></msub><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m7" class="ltx_Math" alttext="\lambda,\mu\in[0,1]" display="inline"><mrow><mrow><mi>λ</mi><mo>,</mo><mi>μ</mi></mrow><mo>∈</mo><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>]</mo></mrow></mrow></math> are decay factors; the large sum is adopted from a definition of the subsequence kernel <cite class="ltx_cite">[<a href="#bib.bib43" title="Kernel methods for pattern analysis" class="ltx_ref">22</a>]</cite> to generate children subsets with gaps, which are then used in a recursive call to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m8" class="ltx_Math" alttext="\Delta" display="inline"><mi mathvariant="normal">Δ</mi></math>.
Here, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m9" class="ltx_Math" alttext="c_{n_{1}}(i)" display="inline"><mrow><msub><mi>c</mi><msub><mi>n</mi><mn>1</mn></msub></msub><mo>⁢</mo><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></mrow></math> is the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m10" class="ltx_Math" alttext="i^{th}" display="inline"><msup><mi>i</mi><mrow><mi>t</mi><mo>⁢</mo><mi>h</mi></mrow></msup></math> child of the node <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m11" class="ltx_Math" alttext="n_{1}" display="inline"><msub><mi>n</mi><mn>1</mn></msub></math>; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m12" class="ltx_Math" alttext="\vec{I}_{1}" display="inline"><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m13" class="ltx_Math" alttext="\vec{I}_{2}" display="inline"><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub></math> are two sequences of indexes that enumerate subsets of children with gaps, i.e., <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m14" class="ltx_Math" alttext="\vec{I}=(i_{1},i_{2},..,|I|)" display="inline"><mrow><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mo>=</mo><mrow><mo>(</mo><msub><mi>i</mi><mn>1</mn></msub><mo>,</mo><msub><mi>i</mi><mn>2</mn></msub><mo>,</mo><mo>.</mo><mo>.</mo><mo>,</mo><mo>|</mo><mi>I</mi><mo>|</mo><mo>)</mo></mrow></mrow></math>, with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m15" class="ltx_Math" alttext="1\leq i_{1}&lt;i_{2}&lt;..&lt;i_{|I|}" display="inline"><mrow><mn>1</mn><mo>≤</mo><msub><mi>i</mi><mn>1</mn></msub><mo>&lt;</mo><msub><mi>i</mi><mn>2</mn></msub><mo>&lt;</mo><mo>.</mo><mo>.</mo><mo>&lt;</mo><msub><mi>i</mi><mrow><mo fence="true">|</mo><mi>I</mi><mo fence="true">|</mo></mrow></msub></mrow></math>; and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m16" class="ltx_Math" alttext="{d(\vec{I}_{1})}=\vec{I}_{1l(\vec{I}_{1})}-\vec{I}_{11}+1" display="inline"><mrow><mrow><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mrow><mn>1</mn><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>1</mn></msub><mo>)</mo></mrow></mrow></msub><mo>-</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>11</mn></msub><mo>+</mo><mn>1</mn></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m17" class="ltx_Math" alttext="d(\vec{I}_{2})=\vec{I}_{2l(\vec{I}_{2})}-\vec{I}_{21}+1" display="inline"><mrow><mrow><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mrow><mn>2</mn><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>2</mn></msub><mo>)</mo></mrow></mrow></msub><mo>-</mo><msub><mover accent="true"><mi>I</mi><mo stretchy="false">→</mo></mover><mn>21</mn></msub><mo>+</mo><mn>1</mn></mrow></mrow></math>, which penalizes subsequences with larger gaps.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p class="ltx_p">It should be noted that:
firstly, the use of a subsequence kernel makes it possible to generate child subsets of the two nodes, i.e., it allows for gaps, which makes matching of syntactic patterns less rigid. Secondly, the resulting SHTK is essentially a special case of PTK <cite class="ltx_cite">[<a href="#bib.bib42" title="Efficient convolution kernels for dependency and constituent syntactic trees" class="ltx_ref">10</a>]</cite>, adapted to the shallow structural representation <span class="ltx_text ltx_font_typewriter">STRUCT</span> (see Sec. <a href="#S3.SS2" title="3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). When applied to <span class="ltx_text ltx_font_typewriter">STRUCT</span> trees, SHTK exactly computes the same feature space as PTK, but in faster time (on average). Indeed, SHTK required to be only applied to node pairs from the same level (see Eq. <a href="#S3.E3" title="(3) ‣ 3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>), where the node labels can match – chunk, POS or lexicals. This reduces the time for selecting the matching-node pairs carried out in PTK <cite class="ltx_cite">[<a href="#bib.bib42" title="Efficient convolution kernels for dependency and constituent syntactic trees" class="ltx_ref">10</a>, <a href="#bib.bib2" title="Making tree kernels practical for natural language learning" class="ltx_ref">11</a>]</cite>. The fragment space is obviously the same, as the node labels of different levels in <span class="ltx_text ltx_font_typewriter">STRUCT</span> are different and will not be matched by PTK either.</p>
</div>
<div id="S3.SS3.p7" class="ltx_para">
<p class="ltx_p">Finally, given its recursive definition in Eq. <a href="#S3.E3" title="(3) ‣ 3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and the use of subsequence (with gaps), SHTK can derive useful dependencies between its elements. For example, it will generate the following subtree fragments: <span class="ltx_text ltx_font_typewriter">[positive-NP [positive-A N]], [S [negative-VP [negative-V [destroy]] [PRODUCT-NP]]]]</span> and so on.</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>YouTube comments corpus</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">To build a corpus of YouTube comments, we focus on a particular set of videos (technical reviews and advertisings) featuring commercial products. In particular, we chose two product categories: automobiles (<span class="ltx_text ltx_font_typewriter">AUTO</span>) and tablets (<span class="ltx_text ltx_font_typewriter">TABLETS</span>). To collect the videos, we compiled a list of products and queried the YouTube gData API<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup>https://developers.google.com/youtube/v3/</span></span></span> to retrieve the videos. We then manually excluded irrelevant videos. For each video, we extracted all available comments (limited to maximum 1k comments per video) and manually annotated each comment with its type and polarity. We distinguish between the following types:</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">product</span>: discuss the topic product in general or some features of the product;</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">video</span>: discuss the video or some of its details;</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">spam</span>: provide advertising and malicious links; and</p>
</div>
<div id="S4.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">off-topic</span>: comments that have almost no content (“lmao”) or content that is not related to the video (“Thank you!”).</p>
</div>
<div id="S4.p6" class="ltx_para">
<p class="ltx_p">Regarding the polarity, we distinguish between {<span class="ltx_text ltx_font_italic">positive, negative, neutral</span>} sentiments with respect to the product and the video. If the comment contains several statements of different polarities, it is annotated as both <span class="ltx_text ltx_font_italic">positive</span> and <span class="ltx_text ltx_font_italic">negative</span>:
“Love the video but waiting for iPad 4”.
In total we have annotated 208 videos with around 35k comments (128 videos <span class="ltx_text ltx_font_typewriter">TABLETS</span> and 80 for <span class="ltx_text ltx_font_typewriter">AUTO</span>).</p>
</div>
<div id="S4.p7" class="ltx_para">
<p class="ltx_p">To evaluate the quality of the produced labels, we asked 5 annotators to label a sample set of one hundred comments and measured the agreement. The resulting annotator agreement <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p7.m1" class="ltx_Math" alttext="\alpha" display="inline"><mi>α</mi></math> value <cite class="ltx_cite">[<a href="#bib.bib13" title="Content analysis: an introduction to its methodology, second edition" class="ltx_ref">9</a>, <a href="#bib.bib12" title="Inter-coder agreement for computational linguistics" class="ltx_ref">1</a>]</cite> scores are 60.6 (<span class="ltx_text ltx_font_typewriter">AUTO</span>), 72.1 (<span class="ltx_text ltx_font_typewriter">TABLETS</span>) for the sentiment task and 64.1 (<span class="ltx_text ltx_font_typewriter">AUTO</span>), 79.3 (<span class="ltx_text ltx_font_typewriter">TABLETS</span>) for the <span class="ltx_text ltx_font_bold">type</span> classification task. For the rest of the comments, we assigned the entire annotation task to a single coder. Further details on the corpus can be found in <cite class="ltx_cite">Uryupina<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib11" title="SenTube: a corpus for sentiment analysis on YouTube social media" class="ltx_ref">2014</a>)</cite>.</p>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">This section reports: (i) experiments on individual subtasks of opinion and type classification; (ii) the full task of predicting type and sentiment; (iii) study on the adaptability of our system by learning on one domain and testing on the other; (iv) learning curves that provide an indication on the required amount and type of data and the scalability to other domains.</p>
</div>
<div id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.1 </span>Task description</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sentiment classification.</span>
We treat each comment as expressing <span class="ltx_text ltx_font_typewriter">positive</span>, <span class="ltx_text ltx_font_typewriter">negative</span> or <span class="ltx_text ltx_font_typewriter">neutral</span> sentiment. Hence, the task is a three-way classification.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Type classification.</span>
One of the challenging aspects of sentiment analysis of YouTube data is that the comments may express the sentiment not only towards the <span class="ltx_text ltx_font_typewriter">product</span> shown in the video, but also the <span class="ltx_text ltx_font_typewriter">video</span> itself, i.e., users may post positive comments to the video while being generally negative about the product and vice versa. Hence, it is of crucial importance to distinguish between these two types of comments. Additionally, many comments are irrelevant for both the product and the video (<span class="ltx_text ltx_font_typewriter">off-topic</span>) or may even contain <span class="ltx_text ltx_font_typewriter">spam</span>.
Given that the main goal of sentiment analysis is to select sentiment-bearing comments and identify their polarity, distinguishing between <span class="ltx_text ltx_font_typewriter">off-topic</span> and <span class="ltx_text ltx_font_typewriter">spam</span> categories is not critical.
Thus, we merge the <span class="ltx_text ltx_font_typewriter">spam</span> and <span class="ltx_text ltx_font_typewriter">off-topic</span> into a single <span class="ltx_text ltx_font_typewriter">uninformative</span> category. Similar to the opinion classification task, comment type classification is a multi-class classification with three classes: <span class="ltx_text ltx_font_typewriter">video</span>, <span class="ltx_text ltx_font_typewriter">product</span> and <span class="ltx_text ltx_font_typewriter">uninform</span>.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Full task.</span>
While the previously discussed sentiment and type identification tasks are useful to model and study in their own right, our end goal is: given a stream of comments, to jointly predict both the type and the sentiment of each comment.
We cast this problem as a single multi-class classification task with seven classes: the Cartesian product between {<span class="ltx_text ltx_font_typewriter">product, video</span>} type labels and {<span class="ltx_text ltx_font_typewriter">positive, neutral, negative</span>} sentiment labels plus the <span class="ltx_text ltx_font_typewriter">uninformative</span> category (<em class="ltx_emph">spam</em> and <em class="ltx_emph">off-topic</em>). Considering a real-life application, it is important not only to detect the polarity of the comment, but to also identify if it is expressed towards the product or the video.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup>We exclude comments annotated as both <span class="ltx_text ltx_font_typewriter">video</span> and <span class="ltx_text ltx_font_typewriter">product</span>. This enables the use of a simple flat multi-classifiers with seven categories for the full task, instead of a hierarchical multi-label classifiers (i.e., type classification first and then opinion polarity). The number of comments assigned to both <span class="ltx_text ltx_font_typewriter">product</span> and <span class="ltx_text ltx_font_typewriter">video</span> is relatively small (8% for <span class="ltx_text ltx_font_typewriter">TABLETS</span> and 4% for <span class="ltx_text ltx_font_typewriter">AUTO</span>).</span></span></span></p>
</div>
</div>
<div id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.2 </span>Data</h3>

<div id="S5.T1" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:433.6pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2">Task</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="2">class</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">AUTO</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">TABLETS</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">TRAIN</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">TEST</td>
<td class="ltx_td ltx_align_left ltx_border_t">TRAIN</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">TEST</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4">Sentiment</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">positive</th>
<td class="ltx_td ltx_align_left ltx_border_t">2005 (36%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">807 (27%)</td>
<td class="ltx_td ltx_align_left ltx_border_t">2393 (27%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1872 (27%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">neutral</th>
<td class="ltx_td ltx_align_left">2649 (48%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1413 (47%)</td>
<td class="ltx_td ltx_align_left">4683 (53%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">3617 (52%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">negative</th>
<td class="ltx_td ltx_align_left">878 (16%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">760 (26%)</td>
<td class="ltx_td ltx_align_left">1698 (19%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1471 (21%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">total</th>
<td class="ltx_td ltx_align_left ltx_border_t">5532</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2980</td>
<td class="ltx_td ltx_align_left ltx_border_t">8774</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">6960</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4">Type</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">product</th>
<td class="ltx_td ltx_align_left ltx_border_t">2733 (33%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1761 (34%)</td>
<td class="ltx_td ltx_align_left ltx_border_t">7180 (59%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5731 (61%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video</th>
<td class="ltx_td ltx_align_left">3008 (36%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1369 (26%)</td>
<td class="ltx_td ltx_align_left">2088 (17%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1674 (18%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">off-topic</th>
<td class="ltx_td ltx_align_left">2638 (31%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">2045 (39%)</td>
<td class="ltx_td ltx_align_left">2334 (19%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1606 (17%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">spam</th>
<td class="ltx_td ltx_align_left">26 (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T1.m1" class="ltx_Math" alttext="&gt;" display="inline"><mo>&gt;</mo></math>1%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">17 (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T1.m2" class="ltx_Math" alttext="&gt;" display="inline"><mo>&gt;</mo></math>1%)</td>
<td class="ltx_td ltx_align_left">658 (5%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">361 (4%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">total</th>
<td class="ltx_td ltx_align_left ltx_border_t">8405</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5192</td>
<td class="ltx_td ltx_align_left ltx_border_t">12260</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">9372</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4">Full</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">product-pos.</th>
<td class="ltx_td ltx_align_left ltx_border_t">1096 (13%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">517 (10%)</td>
<td class="ltx_td ltx_align_left ltx_border_t">1648 (14%)</td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1278 (14%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">product-neu.</th>
<td class="ltx_td ltx_align_left">908 (11%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">729 (14%)</td>
<td class="ltx_td ltx_align_left">3681 (31%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">2844 (32%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">product-neg.</th>
<td class="ltx_td ltx_align_left">554 (7%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">370 (7%)</td>
<td class="ltx_td ltx_align_left">1404 (12%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1209 (14%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video-pos.</th>
<td class="ltx_td ltx_align_left">909 (11%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">290 (6%)</td>
<td class="ltx_td ltx_align_left">745 (6%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">594 (7%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_r">video-neu.</th>
<td class="ltx_td ltx_align_left">1741 (21%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">683 (14%)</td>
<td class="ltx_td ltx_align_left">1002 (9%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">773 (9%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_r">video-neg.</th>
<td class="ltx_td ltx_align_left">324 (4%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">390 (8%)</td>
<td class="ltx_td ltx_align_left">294 (2%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">262 (3%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_r">off-topic</th>
<td class="ltx_td ltx_align_left">2638 (32%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">2045 (41%)</td>
<td class="ltx_td ltx_align_left">2334 (20%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">1606 (18%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_r">spam</th>
<td class="ltx_td ltx_align_left">26 (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T1.m3" class="ltx_Math" alttext="&gt;" display="inline"><mo>&gt;</mo></math>1%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">17 (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T1.m4" class="ltx_Math" alttext="&gt;" display="inline"><mo>&gt;</mo></math>1%)</td>
<td class="ltx_td ltx_align_left">658 (6%)</td>
<td class="ltx_td ltx_align_left ltx_border_r">361 (4%)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_b ltx_border_l ltx_border_r"/>
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">total</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t">8196</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">5041</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t">11766</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">8927</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Summary of YouTube comments data used in the sentiment, type and full classification tasks. The comments come from two product categories: AUTO and TABLETS. Numbers in parenthesis show proportion w.r.t. to the total number of comments used in a task.</div>
</div>
<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p">We split all the videos 50% between training set (TRAIN) and test set (TEST), where each video contains all its comments. This ensures that all comments from the same video appear either in TRAIN or in TEST. Since the number of comments per video varies, the resulting sizes of each set are different (we use the larger split for TRAIN). Table <a href="#S5.T1" title="Table 1 ‣ 5.2 Data ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the data distribution across the task-specific classes – <span class="ltx_text ltx_font_bold">sentiment</span> and <span class="ltx_text ltx_font_bold">type</span> classification. For the <span class="ltx_text ltx_font_bold">sentiment</span> task we exclude <span class="ltx_text ltx_font_typewriter">off-topic</span> and <span class="ltx_text ltx_font_typewriter">spam</span> comments as well as comments with ambiguous sentiment, i.e., annotated as both <span class="ltx_text ltx_font_typewriter">positive</span> and <span class="ltx_text ltx_font_typewriter">negative</span>.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p class="ltx_p">For the <span class="ltx_text ltx_font_bold">sentiment</span> task about 50% of the comments have <span class="ltx_text ltx_font_typewriter">neutral</span> polarity, while the <span class="ltx_text ltx_font_typewriter">negative</span> class is much less frequent. Interestingly, the ratios between polarities expressed in comments from <span class="ltx_text ltx_font_typewriter">AUTO</span> and <span class="ltx_text ltx_font_typewriter">TABLETS</span> are very similar across both TRAIN and TEST.
Conversely, for the <span class="ltx_text ltx_font_bold">type</span> task, we observe that comments from <span class="ltx_text ltx_font_typewriter">AUTO</span> are uniformly distributed among the three classes, while for the <span class="ltx_text ltx_font_typewriter">TABLETS</span> the majority of comments are <span class="ltx_text ltx_font_typewriter">product</span> related. It is likely due to the nature of the <span class="ltx_text ltx_font_typewriter">TABLETS</span> videos, that are more geek-oriented, where users are more prone to share their opinions and enter involved discussions about a product. Additionally, videos from the <span class="ltx_text ltx_font_typewriter">AUTO</span> category (both commercials and user reviews) are more visually captivating and, being generally oriented towards a larger audience, generate more video-related comments.
Regarding the <span class="ltx_text ltx_font_bold">full</span> setting, where the goal is to have a joint prediction of the comment sentiment and type, we observe that <span class="ltx_text ltx_font_typewriter">video-negative</span> and <span class="ltx_text ltx_font_typewriter">video-positive</span> are the most scarce classes, which makes them the most difficult to predict.</p>
</div>
</div>
<div id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.3 </span>Results</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p class="ltx_p">We start off by presenting the results for the traditional in-domain setting, where both TRAIN and TEST come from the same domain, e.g., <span class="ltx_text ltx_font_typewriter">AUTO</span> or <span class="ltx_text ltx_font_typewriter">TABLETS</span>. Next, we show the learning curves to analyze the behavior of <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models according to the training size. Finally, we perform a set of cross-domain experiments that describe the enhanced adaptability of the patterns generated by the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model.</p>
</div>
<div id="S5.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.3.1 </span>In-domain experiments</h4>

<div id="S5.T2" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:346.9pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="3">Task</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t" rowspan="3">class</th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">AUTO</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">TABLETS</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">FVEC</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">STRUCT</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">FVEC</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="3">STRUCT</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center">P</td>
<td class="ltx_td ltx_align_center">R</td>
<td class="ltx_td ltx_align_center ltx_border_r">F1</td>
<td class="ltx_td ltx_align_center">P</td>
<td class="ltx_td ltx_align_center">R</td>
<td class="ltx_td ltx_align_center ltx_border_r">F1</td>
<td class="ltx_td ltx_align_center">P</td>
<td class="ltx_td ltx_align_center">R</td>
<td class="ltx_td ltx_align_center ltx_border_r">F1</td>
<td class="ltx_td ltx_align_center">P</td>
<td class="ltx_td ltx_align_center">R</td>
<td class="ltx_td ltx_align_center ltx_border_r">F1</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r" rowspan="4">Sent</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">positive</th>
<td class="ltx_td ltx_align_center ltx_border_t">49.1</td>
<td class="ltx_td ltx_align_center ltx_border_t">72.1</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">58.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">50.1</td>
<td class="ltx_td ltx_align_center ltx_border_t">73.9</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">59.0</td>
<td class="ltx_td ltx_align_center ltx_border_t">67.5</td>
<td class="ltx_td ltx_align_center ltx_border_t">70.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.9</td>
<td class="ltx_td ltx_align_center ltx_border_t">71.2</td>
<td class="ltx_td ltx_align_center ltx_border_t">71.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.3</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">neutral</th>
<td class="ltx_td ltx_align_center">68.2</td>
<td class="ltx_td ltx_align_center">55.0</td>
<td class="ltx_td ltx_align_center ltx_border_r">61.4</td>
<td class="ltx_td ltx_align_center">70.1</td>
<td class="ltx_td ltx_align_center">57.6</td>
<td class="ltx_td ltx_align_center ltx_border_r">63.1</td>
<td class="ltx_td ltx_align_center">81.3</td>
<td class="ltx_td ltx_align_center">71.4</td>
<td class="ltx_td ltx_align_center ltx_border_r">76.9</td>
<td class="ltx_td ltx_align_center">81.1</td>
<td class="ltx_td ltx_align_center">73.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">77.8</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">negative</th>
<td class="ltx_td ltx_align_center">42.0</td>
<td class="ltx_td ltx_align_center">36.9</td>
<td class="ltx_td ltx_align_center ltx_border_r">39.6</td>
<td class="ltx_td ltx_align_center">41.3</td>
<td class="ltx_td ltx_align_center">35.8</td>
<td class="ltx_td ltx_align_center ltx_border_r">38.8</td>
<td class="ltx_td ltx_align_center">48.3</td>
<td class="ltx_td ltx_align_center">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_r">54.8</td>
<td class="ltx_td ltx_align_center">50.2</td>
<td class="ltx_td ltx_align_center">62.6</td>
<td class="ltx_td ltx_align_center ltx_border_r">56.5</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Acc</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">54.7</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">55.7</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">68.6</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">70.5</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="4">Type</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">product</th>
<td class="ltx_td ltx_align_center ltx_border_t">66.8</td>
<td class="ltx_td ltx_align_center ltx_border_t">73.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">69.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">68.8</td>
<td class="ltx_td ltx_align_center ltx_border_t">75.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">71.7</td>
<td class="ltx_td ltx_align_center ltx_border_t">78.2</td>
<td class="ltx_td ltx_align_center ltx_border_t">95.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">86.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">80.1</td>
<td class="ltx_td ltx_align_center ltx_border_t">95.5</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">87.6</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video</th>
<td class="ltx_td ltx_align_center">45.0</td>
<td class="ltx_td ltx_align_center">52.8</td>
<td class="ltx_td ltx_align_center ltx_border_r">48.2</td>
<td class="ltx_td ltx_align_center">47.8</td>
<td class="ltx_td ltx_align_center">49.9</td>
<td class="ltx_td ltx_align_center ltx_border_r">48.7</td>
<td class="ltx_td ltx_align_center">83.6</td>
<td class="ltx_td ltx_align_center">45.7</td>
<td class="ltx_td ltx_align_center ltx_border_r">58.9</td>
<td class="ltx_td ltx_align_center">83.5</td>
<td class="ltx_td ltx_align_center">46.7</td>
<td class="ltx_td ltx_align_center ltx_border_r">59.4</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">uninform</th>
<td class="ltx_td ltx_align_center">59.3</td>
<td class="ltx_td ltx_align_center">48.2</td>
<td class="ltx_td ltx_align_center ltx_border_r">53.1</td>
<td class="ltx_td ltx_align_center">60.6</td>
<td class="ltx_td ltx_align_center">53.0</td>
<td class="ltx_td ltx_align_center ltx_border_r">56.4</td>
<td class="ltx_td ltx_align_center">70.2</td>
<td class="ltx_td ltx_align_center">52.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">60.7</td>
<td class="ltx_td ltx_align_center">72.9</td>
<td class="ltx_td ltx_align_center">58.6</td>
<td class="ltx_td ltx_align_center ltx_border_r">65.0</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Acc</th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">57.4</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">59.4</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">77.2</td>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t" colspan="3">78.6</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="8">Full</th>
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">product-pos</th>
<td class="ltx_td ltx_align_center ltx_border_t">34.0</td>
<td class="ltx_td ltx_align_center ltx_border_t">49.6</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">39.2</td>
<td class="ltx_td ltx_align_center ltx_border_t">36.5</td>
<td class="ltx_td ltx_align_center ltx_border_t">51.2</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">43.0</td>
<td class="ltx_td ltx_align_center ltx_border_t">48.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">56.8</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">52.0</td>
<td class="ltx_td ltx_align_center ltx_border_t">52.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">59.3</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">56.4</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">product-neu</th>
<td class="ltx_td ltx_align_center">43.4</td>
<td class="ltx_td ltx_align_center">31.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">36.1</td>
<td class="ltx_td ltx_align_center">41.4</td>
<td class="ltx_td ltx_align_center">36.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">38.4</td>
<td class="ltx_td ltx_align_center">68.0</td>
<td class="ltx_td ltx_align_center">67.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">68.1</td>
<td class="ltx_td ltx_align_center">59.7</td>
<td class="ltx_td ltx_align_center">83.4</td>
<td class="ltx_td ltx_align_center ltx_border_r">70.0</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">product-neg</th>
<td class="ltx_td ltx_align_center">26.3</td>
<td class="ltx_td ltx_align_center">29.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">28.8</td>
<td class="ltx_td ltx_align_center">26.3</td>
<td class="ltx_td ltx_align_center">25.3</td>
<td class="ltx_td ltx_align_center ltx_border_r">25.6</td>
<td class="ltx_td ltx_align_center">43.0</td>
<td class="ltx_td ltx_align_center">49.9</td>
<td class="ltx_td ltx_align_center ltx_border_r">45.4</td>
<td class="ltx_td ltx_align_center">44.7</td>
<td class="ltx_td ltx_align_center">53.7</td>
<td class="ltx_td ltx_align_center ltx_border_r">48.4</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video-pos</th>
<td class="ltx_td ltx_align_center">23.2</td>
<td class="ltx_td ltx_align_center">47.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">31.9</td>
<td class="ltx_td ltx_align_center">26.1</td>
<td class="ltx_td ltx_align_center">54.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">35.5</td>
<td class="ltx_td ltx_align_center">69.1</td>
<td class="ltx_td ltx_align_center">60.0</td>
<td class="ltx_td ltx_align_center ltx_border_r">64.7</td>
<td class="ltx_td ltx_align_center">64.9</td>
<td class="ltx_td ltx_align_center">68.8</td>
<td class="ltx_td ltx_align_center ltx_border_r">66.4</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video-neu</th>
<td class="ltx_td ltx_align_center">26.1</td>
<td class="ltx_td ltx_align_center">30.0</td>
<td class="ltx_td ltx_align_center ltx_border_r">29.0</td>
<td class="ltx_td ltx_align_center">26.5</td>
<td class="ltx_td ltx_align_center">31.6</td>
<td class="ltx_td ltx_align_center ltx_border_r">28.8</td>
<td class="ltx_td ltx_align_center">56.4</td>
<td class="ltx_td ltx_align_center">32.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">40.0</td>
<td class="ltx_td ltx_align_center">55.1</td>
<td class="ltx_td ltx_align_center">35.7</td>
<td class="ltx_td ltx_align_center ltx_border_r">43.3</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">video-neg</th>
<td class="ltx_td ltx_align_center">21.9</td>
<td class="ltx_td ltx_align_center">3.7</td>
<td class="ltx_td ltx_align_center ltx_border_r">6.0</td>
<td class="ltx_td ltx_align_center">17.7</td>
<td class="ltx_td ltx_align_center">2.3</td>
<td class="ltx_td ltx_align_center ltx_border_r">4.8</td>
<td class="ltx_td ltx_align_center">39.0</td>
<td class="ltx_td ltx_align_center">17.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">23.9</td>
<td class="ltx_td ltx_align_center">39.5</td>
<td class="ltx_td ltx_align_center">6.1</td>
<td class="ltx_td ltx_align_center ltx_border_r">11.5</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">uninform</th>
<td class="ltx_td ltx_align_center">56.5</td>
<td class="ltx_td ltx_align_center">52.4</td>
<td class="ltx_td ltx_align_center ltx_border_r">54.9</td>
<td class="ltx_td ltx_align_center">60.0</td>
<td class="ltx_td ltx_align_center">53.3</td>
<td class="ltx_td ltx_align_center ltx_border_r">56.3</td>
<td class="ltx_td ltx_align_center">60.0</td>
<td class="ltx_td ltx_align_center">65.5</td>
<td class="ltx_td ltx_align_center ltx_border_r">62.2</td>
<td class="ltx_td ltx_align_center">63.3</td>
<td class="ltx_td ltx_align_center">68.4</td>
<td class="ltx_td ltx_align_center ltx_border_r">66.9</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Acc</th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" colspan="3">40.0</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" colspan="3">41.5</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" colspan="3">57.6</td>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r ltx_border_t" colspan="3">60.3</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>In-domain experiments on AUTO and TABLETS using two models: FVEC and STRUCT. The results are reported for sentiment, type and full classification tasks. The metrics used are precision (P), recall (R) and F1 for each individual class and the general accuracy of the multi-class classifier (Acc).</div>
</div>
<div id="S5.SS3.SSS1.p1" class="ltx_para">
<p class="ltx_p">We compare <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models on three tasks described in Sec. <a href="#S5.SS1" title="5.1 Task description ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>: sentiment, type and full. Table <a href="#S5.T2" title="Table 2 ‣ 5.3.1 In-domain experiments ‣ 5.3 Results ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> reports the per-class performance and the overall accuracy of the multi-class classifier.
Firstly, we note that the performance on <span class="ltx_text ltx_font_typewriter">TABLETS</span> is much higher than on <span class="ltx_text ltx_font_typewriter">AUTO</span> across all tasks. This can be explained by the following: (i) <span class="ltx_text ltx_font_typewriter">TABLETS</span> contains more training data and (ii) videos from <span class="ltx_text ltx_font_typewriter">AUTO</span> and <span class="ltx_text ltx_font_typewriter">TABLETS</span> categories draw different types of audiences – well-informed users and geeks expressing better-motivated opinions about a product for the former vs. more general audience for the latter. This results in the different quality of comments with the <span class="ltx_text ltx_font_typewriter">AUTO</span> being more challenging to analyze.
Secondly, we observe that the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model provides 1-3% of absolute improvement in accuracy over <span class="ltx_text ltx_font_typewriter">FVEC</span> for every task. For individual categories the F1 scores are also improved by the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model (except for the <em class="ltx_emph">negative</em> classes for <span class="ltx_text ltx_font_typewriter">AUTO</span>, where we see a small drop). We conjecture that sentiment prediction for <span class="ltx_text ltx_font_typewriter">AUTO</span> category is largely driven by one-shot phrases and statements where it is hard to improve upon the bag-of-words and sentiment lexicon features. In contrast, comments from <span class="ltx_text ltx_font_typewriter">TABLETS</span> category tend to be more elaborated and well-argumented, thus, benefiting from the expressiveness of the structural representations.</p>
</div>
<div id="S5.SS3.SSS1.p2" class="ltx_para">
<p class="ltx_p">Considering per-class performance, correctly predicting <span class="ltx_text ltx_font_typewriter">negative</span> sentiment is most difficult for both <span class="ltx_text ltx_font_typewriter">AUTO</span> and <span class="ltx_text ltx_font_typewriter">TABLETS</span>, which is probably caused by the smaller proportion of the negative comments in the training set. For the <span class="ltx_text ltx_font_bold">type</span> task, video-related class is substantially more difficult than product-related for both categories. For the <span class="ltx_text ltx_font_bold">full</span> task, the class <span class="ltx_text ltx_font_typewriter">video-negative</span> accounts for the largest error. This is confirmed by the results from the previous sentiment and type tasks, where we saw that handling negative sentiment and detecting video-related comments are most difficult.</p>
</div>
</div>
<div id="S5.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.3.2 </span>Learning curves</h4>

<div id="S5.SS3.SSS2.p1" class="ltx_para">
<p class="ltx_p">The learning curves depict the behavior of <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models as we increase the size of the training set. Intuitively, the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model relies on more general syntactic patterns and may overcome the sparseness problems incurred by the <span class="ltx_text ltx_font_typewriter">FVEC</span> model when little training data is available.</p>
</div>
<div id="S5.SS3.SSS2.p2" class="ltx_para">
<p class="ltx_p">Nevertheless, as we see in Figure <a href="#S5.F2" title="Figure 2 ‣ 5.3.2 Learning curves ‣ 5.3 Results ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the learning curves for sentiment and type classification tasks across both product categories do not confirm this intuition. The <span class="ltx_text ltx_font_typewriter">STRUCT</span> model consistently outperforms the <span class="ltx_text ltx_font_typewriter">FVEC</span> across all training sizes, but the gap in the performance does not increase when we move to smaller training sets. As we will see next, this picture changes when we perform the cross-domain study.</p>
</div>
<div id="S5.F2" class="ltx_figure">
<table style="width:100%;">
<tr>
<td class="ltx_subfigure">
<div id="S5.F1.sf1" class="ltx_figure ltx_align_center"><img src="P14-1118/image001.png" id="S5.F1.sf1.g1" class="ltx_graphics" width="608" height="434" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Sentiment classification</div>
</div></td>
<td class="ltx_subfigure">
<div id="S5.F1.sf2" class="ltx_figure ltx_align_center"><img src="P14-1118/image002.png" id="S5.F1.sf2.g1" class="ltx_graphics" width="608" height="434" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Type classification</div>
</div></td></tr>
</table>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>In-domain learning curves. ALL refers to the entire TRAIN set for a given product category, i.e., <span class="ltx_text ltx_font_typewriter">AUTO</span> and <span class="ltx_text ltx_font_typewriter">TABLETS</span> (see Table 
<a href="#S5.T1" title="Table 1 ‣ 5.2 Data ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>)</div>
</div>
<div id="S5.T3" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:433.6pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_t">Source</th>
<th class="ltx_td ltx_align_center ltx_border_t">Target</th>
<th class="ltx_td ltx_align_left ltx_border_t">Task</th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_typewriter">FVEC</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_typewriter">STRUCT</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span class="ltx_text ltx_font_typewriter">AUTO</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span class="ltx_text ltx_font_typewriter">TABLETS</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">Sent</td>
<td class="ltx_td ltx_align_center ltx_border_t">66.1</td>
<td class="ltx_td ltx_align_center ltx_border_t">66.6</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Type</td>
<td class="ltx_td ltx_align_center">59.9</td>
<td class="ltx_td ltx_align_center">64.1<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m1" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Full</td>
<td class="ltx_td ltx_align_center">35.6</td>
<td class="ltx_td ltx_align_center">38.3<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m2" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="3"><span class="ltx_text ltx_font_typewriter">TABLETS</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" rowspan="3"><span class="ltx_text ltx_font_typewriter">AUTO</span></td>
<td class="ltx_td ltx_align_left ltx_border_t">Sent</td>
<td class="ltx_td ltx_align_center ltx_border_t">60.4</td>
<td class="ltx_td ltx_align_center ltx_border_t">61.9<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m3" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Type</td>
<td class="ltx_td ltx_align_center">54.2</td>
<td class="ltx_td ltx_align_center">55.6<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m4" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_b">Full</td>
<td class="ltx_td ltx_align_center ltx_border_b">43.4</td>
<td class="ltx_td ltx_align_center ltx_border_b">44.7<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m5" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Cross-domain experiment. Accuracy using <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models when trained/tested in both directions, i.e. <span class="ltx_text ltx_font_typewriter">AUTO<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m9" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathvariant="normal">→</mo></math>TABLETS</span> and <span class="ltx_text ltx_font_typewriter">TABLETS<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m10" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathvariant="normal">→</mo></math>AUTO</span>. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T3.m11" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math> denotes results statistically significant at 95% level (via pairwise t-test).</div>
</div>
<div id="S5.F3" class="ltx_figure">
<table style="width:100%;">
<tr>
<td class="ltx_subfigure">
<div id="S5.F2.sf1" class="ltx_figure ltx_align_center"><img src="P14-1118/image003.png" id="S5.F2.sf1.g1" class="ltx_graphics" width="608" height="434" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Sentiment classification</div>
</div></td>
<td class="ltx_subfigure">
<div id="S5.F2.sf2" class="ltx_figure ltx_align_center"><img src="P14-1118/image004.png" id="S5.F2.sf2.g1" class="ltx_graphics" width="608" height="434" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Type classification</div>
</div></td></tr>
</table>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Learning curves for the cross-domain setting (<span class="ltx_text ltx_font_typewriter">AUTO<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.F3.m2" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathvariant="normal">→</mo></math>TABLETS</span>). Shaded area refers to adding a small portion of comments from the same domain as the target test data to the training.</div>
</div>
</div>
<div id="S5.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.3.3 </span>Cross-domain experiments</h4>

<div id="S5.SS3.SSS3.p1" class="ltx_para">
<p class="ltx_p">To understand the performance of our classifiers on other YouTube domains, we perform a set of cross-domain experiments by training on the data from one product category and testing on the other.</p>
</div>
<div id="S5.SS3.SSS3.p2" class="ltx_para">
<p class="ltx_p">Table <a href="#S5.T3" title="Table 3 ‣ 5.3.2 Learning curves ‣ 5.3 Results ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reports the accuracy for three tasks when we use all comments (TRAIN + TEST) from <span class="ltx_text ltx_font_typewriter">AUTO</span> to predict on the TEST from <span class="ltx_text ltx_font_typewriter">TABLETS</span> and in the opposite direction (<span class="ltx_text ltx_font_typewriter">TABLETS<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS3.SSS3.p2.m1" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathvariant="normal">→</mo></math>AUTO</span>). When using <span class="ltx_text ltx_font_typewriter">AUTO</span> as a source domain, <span class="ltx_text ltx_font_typewriter">STRUCT</span> model provides additional 1-3% of absolute improvement, except for the sentiment task.</p>
</div>
<div id="S5.SS3.SSS3.p3" class="ltx_para">
<p class="ltx_p">Similar to the in-domain experiments, we studied the effect of the source domain size on the target test performance. This is useful to assess the adaptability of features exploited by the <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models with the change in the number of labeled examples available for training. Additionally, we considered a setting including a small amount of training data from the target data (i.e., supervised domain adaptation).</p>
</div>
<div id="S5.SS3.SSS3.p4" class="ltx_para">
<p class="ltx_p">For this purpose, we drew the learning curves of the <span class="ltx_text ltx_font_typewriter">FVEC</span> and <span class="ltx_text ltx_font_typewriter">STRUCT</span> models applied to the <span class="ltx_text ltx_font_bold">sentiment</span> and <span class="ltx_text ltx_font_bold">type</span> tasks (Figure <a href="#S5.F3" title="Figure 3 ‣ 5.3.2 Learning curves ‣ 5.3 Results ‣ 5 Experiments ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>): <span class="ltx_text ltx_font_typewriter">AUTO</span> is used as the source domain to train models, which are tested on <span class="ltx_text ltx_font_typewriter">TABLETS</span>.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup>The results for the other direction (<span class="ltx_text ltx_font_typewriter">TABLETS<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS3.SSS3.p4.m1" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathvariant="normal">→</mo></math>AUTO</span>) show similar behavior.</span></span></span>
The plot shows that when little training data is available, the features generated by the <span class="ltx_text ltx_font_typewriter">STRUCT</span> model exhibit better adaptability (up to 10% of improvement over FVEC). The bag-of-words model seems to be affected by the data sparsity problem which becomes a crucial issue when only a small training set is available. This difference becomes smaller as we add data from the same domain. This is an important advantage of our structural approach, since we cannot realistically expect to obtain manual annotations for 10k+ comments for each (of many thousands) product domains present on YouTube.</p>
</div>
</div>
</div>
<div id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.4 </span>Discussion</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p class="ltx_p">Our <span class="ltx_text ltx_font_typewriter">STRUCT</span> model is more accurate since it is able to induce structural patterns of sentiment. Consider the following comment: <span class="ltx_text ltx_font_italic">optimus pad is better. this xoom is just to bulky but optimus pad offers better functionality</span>. The <span class="ltx_text ltx_font_typewriter">FVEC</span> bag-of-words model misclassifies it to be <span class="ltx_text ltx_font_typewriter">positive</span>, since it contains two positive expressions (<span class="ltx_text ltx_font_italic">better</span>, <span class="ltx_text ltx_font_italic">better functionality</span>) that outweigh a single negative expression (<span class="ltx_text ltx_font_italic">bulky</span>). The structural model, in contrast, is able to identify the product of interest (<span class="ltx_text ltx_font_italic">xoom</span>) and associate it with the negative expression through a structural feature and thus correctly classify the comment as <span class="ltx_text ltx_font_typewriter">negative</span>.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p class="ltx_p">Some issues remain problematic even for the structural model. The largest group of errors are implicit sentiments. Thus, some comments do not contain any explicit positive or negative opinions, but provide detailed and well-argumented criticism, for example, <span class="ltx_text ltx_font_italic">this phone is heavy</span>. Such comments might also include irony. To account for these cases, a deep understanding of the product domain is necessary.</p>
</div>
</div>
</div>
<div id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6 </span>Conclusions and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">We carried out a systematic study on OM from YouTube comments by training a set of supervised multi-class classifiers distinguishing between video and product related opinions.
We use standard feature vectors augmented by shallow syntactic trees enriched with additional conceptual information.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p">This paper makes several contributions: (i) it shows that effective OM can be carried out with supervised models trained on high quality annotations; (ii) it introduces a novel annotated corpus of YouTube comments, which we make available for the research community; (iii) it defines novel structural models and kernels, which can improve on feature vectors, e.g., up to 30% of relative improvement in type classification, when little data is available, and demonstrates that the structural model scales well to other domains.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p class="ltx_p">In the future, we plan to work on a joint model to classify all the comments of a given video, s.t. it is possible to exploit latent dependencies between entities and the sentiments of the comment thread. Additionally, we plan to experiment with hierarchical multi-label classifiers for the full task (in place of a flat multi-class learner).</p>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">The authors are supported by a Google Faculty Award 2011, the Google Europe Fellowship Award 2013 and the European Community’s Seventh Framework Programme (FP7/2007-2013) under the grant #288024: <span class="ltx_text ltx_font_smallcaps">LiMoSINe</span>.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib12" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Artstein and M. Poesio</span><span class="ltx_text ltx_bib_year">(2008-12)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Inter-coder agreement for computational linguistics</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Computational Linguistics</span> <span class="ltx_text ltx_bib_volume">34</span> (<span class="ltx_text ltx_bib_number">4</span>), <span class="ltx_text ltx_bib_pages"> pp. 555–596</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text issn ltx_bib_external">ISSN 0891-2017</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p7" title="4 YouTube comments corpus ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span></li>
<li id="bib.bib9" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Baldwin, P. Cook, M. Lui, A. MacKinlay and L. Wang</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">How noisy social media text, how diffrnt social media sources?</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib17" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Blitzer, M. Dredze and F. Pereira</span><span class="ltx_text ltx_bib_year">(2007)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Biographies, bollywood, boom-boxes and blenders: domain adaptation for sentiment classification</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S2.p4" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Daumé</span><span class="ltx_text ltx_bib_year">(2007)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Frustratingly easy domain adaptation</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">ACL</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib19" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan and N. A. Smith</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Part-of-speech tagging for Twitter: annotation, features, and experiments</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.p2" title="3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
</span></li>
<li id="bib.bib21" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Hu and B. Liu</span><span class="ltx_text ltx_bib_year">(2004)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Mining and summarizing customer reviews</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S3.SS1.p3" title="3.1 Feature Set ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
<li id="bib.bib49" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Joachims</span><span class="ltx_text ltx_bib_year">(2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Optimizing search engines using clickthrough data</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p1" title="3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.
</span></li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. S. Kessler, M. Eckert, L. Clark and N. Nicolov</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The 2010 ICWSM JDPA sentiment corpus for the automotive domain</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib13" class="ltx_bibitem ltx_bib_inbook"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Krippendorf</span><span class="ltx_text ltx_bib_year">(2004)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Content analysis: an introduction to its methodology, second edition</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p7" title="4 YouTube comments corpus ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span></li>
<li id="bib.bib42" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Moschitti</span><span class="ltx_text ltx_bib_year">(2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Efficient convolution kernels for dependency and constituent syntactic trees</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p7" title="1 Introduction ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S3.SS3.p1" title="3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>,
<a href="#S3.SS3.p6" title="3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.
</span></li>
<li id="bib.bib2" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Moschitti</span><span class="ltx_text ltx_bib_year">(2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Making tree kernels practical for natural language learning</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 113–120</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p6" title="3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.
</span></li>
<li id="bib.bib53" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Moschitti</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Kernel methods, syntax and semantics for relational text categorization</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">O. Owoputi, B. OâConnor, C. Dyer, K. Gimpel, N. Schneider and N. A. Smith</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Improved part-of-speech tagging for online conversational text with word clusters</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.p2" title="3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Pak and P. Paroubek</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Twitter as a corpus for sentiment analysis and opinion mining.</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Pang and L. Lee</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Opinion mining and sentiment analysis</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Foundations and trends in information retrieval</span> <span class="ltx_text ltx_bib_volume">2</span> (<span class="ltx_text ltx_bib_number">1-2</span>), <span class="ltx_text ltx_bib_pages"> pp. 1–135</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib3" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Petrov and R. McDonald</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Overview of the 2012 shared task on parsing the web</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib5" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Plank and A. Moschitti</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Embedding semantic similarity in tree kernels for domain adaptation of relation extraction</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib20" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Ritter, S. Clark, Mausam and O. Etzioni</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Named entity recognition in tweets: an experimental study</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.p2" title="3.2 Structural model ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
</span></li>
<li id="bib.bib54" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Severyn and A. Moschitti</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Structural relationships for large-scale learning of answer re-ranking</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib36" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Severyn and A. Moschitti</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Automatic feature engineering for answer selection and extraction</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib35" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Severyn, M. Nicosia and A. Moschitti</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Learning semantic textual similarity with structural representations</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib43" class="ltx_bibitem ltx_bib_book"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Shawe-Taylor and N. Cristianini</span><span class="ltx_text ltx_bib_year">(2004)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Kernel methods for pattern analysis</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">Cambridge University Press</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p5" title="3.3 Learning ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.
</span></li>
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Siersdorfer, S. Chelaru, W. Nejdl and J. San Pedro</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">How useful are your comments?: Analyzing and predicting YouTube comments and comment ratings</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.p2" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib24" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Socher, J. Pennington, E. H. Huang, A. Y. Ng and C. D. Manning</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Semi-supervised recursive autoencoders for predicting sentiment distributions</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p3" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib4" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Søgaard and A. Johannsen</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Robust learning in random subspaces: equipping nlp for oov effects.</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib25" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">O. Täckström and R. McDonald</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Semi-supervised latent variable models for sentence-level sentiment analysis</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p3" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">O. Uryupina, B. Plank, A. Severyn, A. Rotondi and A. Moschitti</span><span class="ltx_text ltx_bib_year">(2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">SenTube: a corpus for sentiment analysis on YouTube social media</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p7" title="4 YouTube comments corpus ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span></li>
<li id="bib.bib23" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Wang and C. Manning</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Baselines and bigrams: simple, good sentiment and topic classification</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p3" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib22" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Wilson, J. Wiebe and P. Hoffmann</span><span class="ltx_text ltx_bib_year">(2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Recognizing contextual polarity in phrase-level sentiment analysis</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S3.SS1.p3" title="3.1 Feature Set ‣ 3 Representations and models ‣ Opinion Mining on YouTube" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun 10 18:54:16 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
