<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Automation and Evaluation of the Keyword Method for Second Language Learning</title>
<!--Generated on Wed Jun 11 17:48:34 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
<link rel="stylesheet" href="ltx-ulem.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Automation and Evaluation of the Keyword Method 
<br class="ltx_break"/>for Second Language Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gözde Özbal
<br class="ltx_break"/>Trento RISE 
<br class="ltx_break"/>Trento, Italy 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">gozbalde@gmail.com</span> 
<br class="ltx_break"/>&amp;Daniele Pighin 
<br class="ltx_break"/>Google 
<br class="ltx_break"/>Zürich, Switzerland 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">biondo@google.com</span> 
<br class="ltx_break"/>&amp;Carlo Strapparava
<br class="ltx_break"/>FBK-irst 
<br class="ltx_break"/>Trento, Italy 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">strappa@fbk.eu</span> 
<br class="ltx_break"/>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">In this paper, we combine existing NLP techniques with minimal supervision to build memory tips according to the keyword method, a well established mnemonic device for second language learning. We present what we believe to be the first extrinsic evaluation of a creative sentence generator on a vocabulary learning task. The results demonstrate that NLP techniques can effectively support the development of resources for second language learning.</p>
</div><span class="ltx_ERROR undefined">\setlist</span>
<div id="p1" class="ltx_para">
<p class="ltx_p">[1]itemsep=-3pt</p>
</div><span class="ltx_ERROR undefined">\algrenewcommand</span><span class="ltx_ERROR undefined">\algorithmicindent</span>
<div id="p2" class="ltx_para">
<p class="ltx_p">0.8em<span class="ltx_ERROR undefined">\algtext</span>*EndIf<span class="ltx_ERROR undefined">\algtext</span>*EndFor<span class="ltx_ERROR undefined">\algtext</span>*EndWhile</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">The keyword method is a mnemonic device <cite class="ltx_cite">[]</cite> that is especially suitable for vocabulary acquisition in second language learning <cite class="ltx_cite">[]</cite>. In this method, a <em class="ltx_emph">target</em> word in a foreign language L2 can be learned by a native speaker of another language L1 in two main steps: 1) one or more L1 words, possibly referring to a concrete entity, are chosen based on orthographic or phonetic similarity with the
target word; 2) an L1 sentence is constructed in which an association between the translation of the target word and the keyword(s) is established,
so that the learner, when seeing or hearing the word, immediately recalls
the keyword(s).
To illustrate, for teaching the Italian word <span class="ltx_text ltx_font_italic">cuore</span> which means <span class="ltx_text ltx_font_italic">heart</span> in English, the learner might be asked to imagine <span class="ltx_text ltx_font_italic">“a lonely <em class="ltx_emph">heart</em> with a hard <em class="ltx_emph">core</em>”</span>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">The keyword method has already been proven to be a valuable teaching device. However, the preparation of the memorization tips for each new word is an activity that requires considerable time, linguistic competence and creativity.
To the best of our knowledge, there is only one study which attempts to automate the mechanism of the keyword method.
In <cite class="ltx_cite">[]</cite>, we proposed to automate the keyword method by retrieving sentences from the Web. However, we did not provide any evaluation to demonstrate the effectiveness of our approach in a real life scenario. In addition, we observed that retrieval poses severe limitations in terms of recall and sentence quality, and it might incur copyright violations.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">In this paper, we overcome these limitations by introducing a semi-automatic system implementing the keyword method that builds upon the keyword selection mechanism of <cite class="ltx_cite"/> and combines it with a state-of-the-art creative sentence generation framework <cite class="ltx_cite">[]</cite>.
We set up an experiment to simulate the situation in which a teacher needs to prepare material for a vocabulary teaching resource. According to our scenario, the teacher relies on automatic techniques to generate relatively few, high quality mnemonics in English to teach Italian vocabulary. She only applies a very light supervision in the last step of the process, in which the most suitable among the generated sentences are selected before being presented to the learners. In this stage, the teacher may want to consider factors which are not yet in reach of automatic linguistic processors, such as the evocativeness or the memorability of a sentence. We show that the automatically generated sentences help learners to establish memorable connections which augment their ability to assimilate new vocabulary. To the best of our knowledge, this work is the first documented extrinsic evaluation of a creative sentence generator on a real-world application.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">The effectiveness of the keyword method (KM) is a well-established fact <cite class="ltx_cite">[]</cite>.
<cite class="ltx_cite"/> found that using KM to teach French made learning easier and faster than conventional methods. <cite class="ltx_cite"/> compared the effectiveness of
three learning methods including the semantic mapping, rote memorization (i.e., memorization by pure repetition, with no mnemonic aid) and keyword on beginner learners of a second language.
Their results show that using KM
leads to better learning of second language vocabulary for beginners.
Similar results have been reported by <cite class="ltx_cite"/> and  <cite class="ltx_cite"/>.
Besides all the experimental results demonstrating the effectiveness of KM, it is worthwhile to mention about the computational efforts to automate the mechanism. In <cite class="ltx_cite">[]</cite> we proposed an automatic vocabulary teaching system which combines NLP and IR techniques to automatically generate memory tips for vocabulary acquisition. The system exploits orthographic and phonetic similarity metrics to find the best L2 keywords for each target L1 word.
Sentences containing the keywords and the translation of the target word are retrieved from the Web, but
we did not carry out an evaluation of the quality or the coverage of the retrieved sentences.
In <cite class="ltx_cite"/> we proposed an extensible framework for the generation of creative sentences in which users are able to force several words to appear in the sentences. While we had discussed the potentiality of creative sentence generation as a useful teaching device, we had not validated our claim experimentally yet. As a previous attempt at using NLP for education, <cite class="ltx_cite"/> employ a riddle generator to create a language playground for children with complex communication needs.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Memory tip generation</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">Preparing memory tips based on KM includes two main ingredients: one or more keywords which are orthographically or phonetically similar to the L2 word to be learned; and a sentence in which the keywords and the translation of the target L2 word are combined in a meaningful way. In this section, we detail the process that we employed to generate such memory tips semi-automatically.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Target word selection and keyword generation</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We started by compiling a collection of Italian nouns consisting of three syllables from various resources for vocabulary teaching including <a href="http://didattica.org/italiano.htm" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://didattica.org/italiano.htm</span></a> and <a href="http://ielanguages.com" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://ielanguages.com</span></a>, and produced a list of 185 target L2 words.
To generate the L1 keywords for each target word, we adopted a similar strategy to <cite class="ltx_cite"/>. For each L2 target word <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, the keyword selection module generates a list of possible keyword pairs, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m2" class="ltx_Math" alttext="K" display="inline"><mi>K</mi></math>. A keyword pair <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m3" class="ltx_Math" alttext="k\in K" display="inline"><mrow><mi>k</mi><mo>∈</mo><mi>K</mi></mrow></math> can either consist of two non-empty strings, i.e., <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m4" class="ltx_Math" alttext="k=[w_{0},w_{1}]" display="inline"><mrow><mi>k</mi><mo>=</mo><mrow><mo>[</mo><mrow><msub><mi>w</mi><mn>0</mn></msub><mo>,</mo><msub><mi>w</mi><mn>1</mn></msub></mrow><mo>]</mo></mrow></mrow></math>, or of one non-empty and one empty string, i.e., <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m5" class="ltx_Math" alttext="w_{1}=\epsilon" display="inline"><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>=</mo><mi>ϵ</mi></mrow></math>. Each keyword pair has the property that the concatenation of its elements is either orthographically or phonetically similar to the target word <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>. Orthographic and phonetic similarity are evaluated by means of the Levenshtein distance <cite class="ltx_cite">[]</cite>. For orthographic similarity, the distance is calculated over the characters in the words, while for phonetic similarity it is calculated over the phonetic representations of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m7" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m8" class="ltx_Math" alttext="w_{0}+w_{1}" display="inline"><mrow><msub><mi>w</mi><mn>0</mn></msub><mo>+</mo><msub><mi>w</mi><mn>1</mn></msub></mrow></math>. We use the CMU pronunciation dictionary<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><a href="http://www.speech.cs.cmu.edu/cgi-bin/cmudict" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://www.speech.cs.cmu.edu/cgi-bin/cmudict</span></a></span></span></span> to retrieve the phonetic representation of English words. For Italian words, instead, their phonetic representation is obtained from an unpublished phonetic lexicon developed at FBK-irst.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Keyword filtering and ranking</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">Unlike in  <cite class="ltx_cite">[]</cite>, where we did not enforce any constraints for selecting the keywords, in this case we applied a more sophisticated filtering and ranking strategy. We require at least one keyword in each pair to be a content word; then, we require that at least one keyword has length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m1" class="ltx_Math" alttext="\geq" display="inline"><mo>≥</mo></math> 3; finally, we discard pairs containing at least one proper noun.
We allowed the keyword generation module to consider all the entries in the CMU dictionary, and rank the keyword pairs based on the following criteria in decreasing order of precedence:
1) Keywords with a smaller orthographic/phonetic distance are preferred;
2) Keywords consisting of a single word are preferred over two words (e.g., for the target word <span class="ltx_text ltx_font_italic">lavagna</span>, which means <span class="ltx_text ltx_font_italic">blackboard</span>, <span class="ltx_text ltx_font_italic">lasagna</span> takes precedence over <span class="ltx_text ltx_font_italic">love</span> and <span class="ltx_text ltx_font_italic">onion</span>);
3) Keywords that do not contain stop words are preferred (e.g., for the target word <span class="ltx_text ltx_font_italic">pettine</span>, which means <span class="ltx_text ltx_font_italic">comb</span>, the keyword pair <span class="ltx_text ltx_font_italic">pet</span> and <span class="ltx_text ltx_font_italic">inn</span> is ranked higher than <span class="ltx_text ltx_font_italic">pet</span> and <span class="ltx_text ltx_font_italic">in</span>, since <span class="ltx_text ltx_font_italic">in</span> is a stop word);
4) Keyword pairs obtained with orthographic similarity are preferred over those obtained with phonetic similarity, as learners might be unfamiliar with the phonetic rules of the target language. For example, for the target word <span class="ltx_text ltx_font_italic">forbice</span>, which means <span class="ltx_text ltx_font_italic">scissors</span>, the keyword pair <span class="ltx_text ltx_font_italic">for</span> and <span class="ltx_text ltx_font_italic">bid</span> is preferred to <span class="ltx_text ltx_font_italic">for</span> and <em class="ltx_emph">beach</em>.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">We selected up to three of the highest ranked keyword pairs for each target word, obtaining 407 keyword combinations for the initial 185 Italian words, which we used as the input for the sentence generator.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Sentence generation</h3>

<div id="S3.T1" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:433.6pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_bottom">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_tt">Group</th>
<th class="ltx_td ltx_align_left ltx_border_tt">Target</th>
<th class="ltx_td ltx_align_left ltx_border_tt">Sentence</th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">A1</td>
<td class="ltx_td ltx_align_left ltx_border_t">campagna</td>
<td class="ltx_td ltx_align_left ltx_border_t">a <em class="ltx_emph">company</em> runs the <span class="ltx_text ltx_font_bold">country</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">isola</td>
<td class="ltx_td ltx_align_left">an <em class="ltx_emph">island</em> of remote <span class="ltx_text ltx_font_bold">isolated</span> communities</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">fabbrica</td>
<td class="ltx_td ltx_align_left">a fabric worker in a <span class="ltx_text ltx_font_bold">factory</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">bagnino</td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">lifeguard</span>s carry <em class="ltx_emph">no bag</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">inverno</td>
<td class="ltx_td ltx_align_left">the <em class="ltx_emph">inferno</em> started, <span class="ltx_text ltx_font_bold">winter</span> left</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">cielo</td>
<td class="ltx_td ltx_align_left">the <span class="ltx_text ltx_font_bold">sky</span> has no <em class="ltx_emph">ceiling</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">marrone</td>
<td class="ltx_td ltx_align_left">blood and <em class="ltx_emph">marrow</em> in a <span class="ltx_text ltx_font_bold">brown</span> water</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">cuore</td>
<td class="ltx_td ltx_align_left">the lonely <span class="ltx_text ltx_font_bold">heart</span> has hard <em class="ltx_emph">core</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">coperta</td>
<td class="ltx_td ltx_align_left">a piece of <em class="ltx_emph">copper</em> in the corner of a <span class="ltx_text ltx_font_bold">blanket</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A1</td>
<td class="ltx_td ltx_align_left">locanda</td>
<td class="ltx_td ltx_align_left">an <span class="ltx_text ltx_font_bold">inn</span> oak door with <em class="ltx_emph">lock and</em> key</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">piazza</td>
<td class="ltx_td ltx_align_left">a <span class="ltx_text ltx_font_bold">square</span> building serves a free <em class="ltx_emph">pizza</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">calzino</td>
<td class="ltx_td ltx_align_left">big bloke with <span class="ltx_text ltx_font_bold">sock</span> in the <em class="ltx_emph">casino</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">scatola</td>
<td class="ltx_td ltx_align_left">a cardboard <span class="ltx_text ltx_font_bold">box</span> sat in a <em class="ltx_emph">scuttle</em> of a house</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">ragazzo</td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">boy</span>s <em class="ltx_emph">also</em> have <em class="ltx_emph">rag</em> dolls</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">angolo</td>
<td class="ltx_td ltx_align_left">a <span class="ltx_text ltx_font_bold">corner</span> kick came at an <em class="ltx_emph">angle</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">cestino</td>
<td class="ltx_td ltx_align_left">a <em class="ltx_emph">teen</em> movie uses <span class="ltx_text ltx_font_bold">basket</span> to play the <em class="ltx_emph">chess</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">carbone</td>
<td class="ltx_td ltx_align_left">the <span class="ltx_text ltx_font_bold">coal</span> is the form of <em class="ltx_emph">carbon</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">cassetto</td>
<td class="ltx_td ltx_align_left">a blank <em class="ltx_emph">cassette</em> tape is in a <span class="ltx_text ltx_font_bold">drawer</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">farfalla</td>
<td class="ltx_td ltx_align_left">the <span class="ltx_text ltx_font_bold">butterflies</span> are <em class="ltx_emph">far</em> in the <em class="ltx_emph">fall</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">A2</td>
<td class="ltx_td ltx_align_left">tovaglia</td>
<td class="ltx_td ltx_align_left">a damp <span class="ltx_text ltx_font_bold">cloth</span> <em class="ltx_emph">towel</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">duomo</td>
<td class="ltx_td ltx_align_left">the old <span class="ltx_text ltx_font_bold">cathedral</span> has a <em class="ltx_emph">dome</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">aceto</td>
<td class="ltx_td ltx_align_left">a <span class="ltx_text ltx_font_bold">vinegar</span> sauce contains the <em class="ltx_emph">acid</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">nuvola</td>
<td class="ltx_td ltx_align_left">the sophisticated <em class="ltx_emph">novel</em> depicts the <span class="ltx_text ltx_font_bold">cloud</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">chiesa</td>
<td class="ltx_td ltx_align_left">the Catholic <span class="ltx_text ltx_font_bold">church</span> has Swiss <em class="ltx_emph">cheese</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">bacino</td>
<td class="ltx_td ltx_align_left">the explosion <em class="ltx_emph">in</em> the <em class="ltx_emph">back</em> broke the <em class="ltx_emph">pelvis</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">maiale</td>
<td class="ltx_td ltx_align_left">a <span class="ltx_text ltx_font_bold">pork</span> meat comes in the <em class="ltx_emph">mail</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">minestra</td>
<td class="ltx_td ltx_align_left">Chinese <em class="ltx_emph">ministries</em> have <span class="ltx_text ltx_font_bold">soup</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">estate</td>
<td class="ltx_td ltx_align_left">this <em class="ltx_emph">estate</em> is for <span class="ltx_text ltx_font_bold">summer</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">bozzolo</td>
<td class="ltx_td ltx_align_left">a <em class="ltx_emph">buzz</em> comes wrapped in the <span class="ltx_text ltx_font_bold">cocoon</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B1</td>
<td class="ltx_td ltx_align_left">arnese</td>
<td class="ltx_td ltx_align_left"><em class="ltx_emph">harness</em> a technology to develop a <span class="ltx_text ltx_font_bold">tool</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">asino</td>
<td class="ltx_td ltx_align_left">an <em class="ltx_emph">Asian</em> elephant is riding a <span class="ltx_text ltx_font_bold">donkey</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">miele</td>
<td class="ltx_td ltx_align_left">do not make <span class="ltx_text ltx_font_bold">honey</span> to walk a <em class="ltx_emph">mile</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">polmone</td>
<td class="ltx_td ltx_align_left">crowded <em class="ltx_emph">pullman</em>s stop the <span class="ltx_text ltx_font_bold">lung</span>s</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">fagiolo</td>
<td class="ltx_td ltx_align_left">a topical <em class="ltx_emph">facial</em> <span class="ltx_text ltx_font_bold">bean</span> cream</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">fiore</td>
<td class="ltx_td ltx_align_left">a <em class="ltx_emph">fire</em> in a <span class="ltx_text ltx_font_bold">flower</span> market</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">compressa</td>
<td class="ltx_td ltx_align_left">the clay <span class="ltx_text ltx_font_bold">tablet</span> is in the <em class="ltx_emph">compress</em>ed form</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">cavallo</td>
<td class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_bold">horse</span> running fast in <em class="ltx_emph">cavalry</em></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">fiume</td>
<td class="ltx_td ltx_align_left">the muddy <span class="ltx_text ltx_font_bold">river</span> has smoke and <em class="ltx_emph">fume</em>s</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">B2</td>
<td class="ltx_td ltx_align_left">pittore</td>
<td class="ltx_td ltx_align_left">a famous <span class="ltx_text ltx_font_bold">painter</span> has precious <em class="ltx_emph">picture</em>s</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">B2</td>
<td class="ltx_td ltx_align_left ltx_border_bb">manico</td>
<td class="ltx_td ltx_align_left ltx_border_bb"><em class="ltx_emph">manic</em> people have broken <span class="ltx_text ltx_font_bold">neck</span>s</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Sentences used in the vocabulary acquisition experiment.</div>
</div>
<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">In this step, our goal was to generate, for each Italian word, sentences containing its L1 translation and the set of orthographically (or phonetically) similar keywords that we previously selected.
For each keyword combination, starting from the top-ranked ones, we generated up to 10 sentences by allowing any known part-of-speech for the keywords. The sentences were produced by the state of the art sentence generator of <cite class="ltx_cite"/>. The system relies on two corpora of automatic parses as a repository of sentence templates and lexical statistics. As for the former, we combined two resources: a corpus of 16,000 proverbs <cite class="ltx_cite">[]</cite> and a collection of 5,000 image captions<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><a href="http://vision.cs.uiuc.edu/pascal-sentences/" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://vision.cs.uiuc.edu/pascal-sentences/</span></a></span></span></span> collected by <cite class="ltx_cite"/>. We chose these two collections since they offer a combination of catchy or simple sentences that we expect to be especially suitable for second language learning. As for the second corpus, we used LDC’s English GigaWord 5th Edition<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><a href="http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://www.ldc.upenn.edu/Catalog/catalogEntry.jsp?catalogId=LDC2011T07</span></a></span></span></span>.
Of the 12 feature functions described in <cite class="ltx_cite">[]</cite>, we only implemented the following scorers: Variety (to prevent duplicate words from appearing in the sentences); Semantic Cohesion (to enforce the generation of sentence as lexically related to the target words as possible); Alliteration, Rhyme and Plosive (to introduce hooks to echoic memory in the output); Dependency Operator and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="N" display="inline"><mi>N</mi></math>-gram (to enforce output grammaticality).</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p">We observed that the sentence generation module was not able to generate a sentence for 24% of the input configurations. For comparison, when we attempted to retrieve sentences from the Web as suggested in <cite class="ltx_cite"/>, we could collect an output for less than 10% of the input configurations. Besides, many of the retrieved sentences were exceedingly long and complex to be used in a second language learning experiment.</p>
</div>
</div>
<div id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.4 </span>Sentence selection</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p">For each L1 keyword pair obtained for each L2 target word, we allowed the system to output up to 10 sentences.
We manually assessed the quality of the generated sentences in terms of meaningfulness, evocativeness and grammaticality to select the most appropriate sentences to be used for the task.
In addition, for keyword pairs not containing the empty string, we prioritized the sentences in which the keywords were closer to each other. For example, let us assume that we have the keywords <span class="ltx_text ltx_font_italic">call</span> and <span class="ltx_text ltx_font_italic">in</span> for the target word <span class="ltx_text ltx_font_italic">collina</span>. Among the sentences “<span class="ltx_text ltx_font_italic">The girl received a call in the bathroom</span>” and “<span class="ltx_text ltx_font_italic">Call the blond girl in case you need</span>”, the first one is preferred, since the keywords are closer to each other. Furthermore, we gave priority to the sentences that included the keywords in the right order. To illustrate, for the same keywords and the target words, we would prefer the sentence “<span class="ltx_text ltx_font_italic">I called him in the morning yesterday</span>” over “<span class="ltx_text ltx_font_italic">You talk a lot in a call</span>”.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p class="ltx_p">Accordingly, for each target word in random order, we sequentially scanned the outputs generated for each keyword pair.
As soon as a sentence of adequate quality was found, we added it to our evaluation data and moved on to the next keyword. We continued this process until we selected a sentence for 40 distinct target words, which we set as the target size of the experiment. We had to inspect the outputs generated for 48 target words before we were able to select 40 good examples, meaning that for 17% of the target words the sentence generator could not produce a sentence of acceptable quality.</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Experiment setup</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">For our experiment, we drew inspiration from <cite class="ltx_cite"/>. We compared the retention error rate of learners who tried to memorize new words with or without the aid of the automatically generated sentences. Through academic channels, we recruited 20 native English speakers with no prior knowledge of Italian.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>We preferred to select the experiment subjects in person as opposed to crowdsourcing the evaluation to be able to verify the proficiency of the subjects in the two languages and to ensure the reliability of the outcome of the evaluation.</span></span></span></p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">After obtaining the sentences as explained in Section <a href="#S3" title="3 Memory tip generation ‣ Automation and Evaluation of the Keyword Method  for Second Language Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we shuffled and then divided the whole set including 40 target words together with their translation, the generated keywords and sentences into 2 batches (A, B) and further divided each batch into 2 groups consisting of 10 elements (A1, A2, B1 and B2). The set of sentences assigned to each group is listed in Table <a href="#S3.T1" title="Table 1 ‣ 3.3 Sentence generation ‣ 3 Memory tip generation ‣ Automation and Evaluation of the Keyword Method  for Second Language Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>: Column “<span class="ltx_text ltx_font_italic">Target</span>” reports the Italian target word being taught; Column “<span class="ltx_text ltx_font_italic">Sentence</span>” shows the automatically generated sentence, where the translation of the target word is shown in bold and the keyword(s) in italic.
For the experiments, we randomly assigned each subject to one of the batches (A or B). Then, each subject was asked to memorize all the word pairs in a batch, but they would see the memory tips only for one of the two groups, which was again randomly assigned. This approach resulted in 4 different memorization exercises, namely 1) A1 with tips and A2 without, 2) A2 with tips and A1 without, 3) B1 with tips and B2 without, 4) B2 with tips and B1 without.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">When memorizing the translations without the aid of memory tips, the subjects were instructed to focus only on the Italian word and its English translation and to repeat them over and over in their mind. Conversely, when relying on the automatic memory tips the subjects were shown the word, its translation and the generated sentence including the keywords. In this case, the subjects were instructed to read the sentence over and over trying to visualize it.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">After going through each set of slides, we distracted the subjects with a short video in order to reset their short term memory. After that, their retention was tested. For each Italian word in the exercise, they were asked to select the English translation among 5 alternatives, including the correct translation and 4 other words randomly selected from the same group. In this way, the subjects would always have to choose among the words that they encountered during the exercise.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>Otherwise, they could easily filter out the wrong answers just because they were not exposed to them recently.</span></span></span> We also added an extra option “<span class="ltx_text ltx_font_italic">I already knew this word</span>” that the subjects were instructed to select in case they already knew the Italian word prior to taking part in the experiment.</p>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Experiment results</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">Table <a href="#S5.T2" title="Table 2 ‣ 5 Experiment results ‣ Automation and Evaluation of the Keyword Method  for Second Language Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes the outcome of the experiment. The contribution of the automatically generated sentences to the learning task is assessed in terms of error rate-reduction, which we measure both within each group (rows 1-4) and on the whole evaluation set (rows 5-6). Due to the presence of the “<span class="ltx_text ltx_font_italic">I already knew this word</span>” option in the learning-assessment questionnaire, the number of the actual answers provided by each subject can be slightly different, hence the difference between macro- and micro-average.</p>
</div>
<div id="S5.T2" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:433.6pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span class="ltx_text ltx_font_footnote">Error rate (%)</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span class="ltx_text ltx_font_footnote">Reduction</span></td>
<td class="ltx_td ltx_border_tt"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_tt"><span class="ltx_text ltx_font_footnote">Group</span></th>
<td class="ltx_td ltx_align_right ltx_border_tt"><span class="ltx_text ltx_font_footnote">Rote</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><span class="ltx_text ltx_font_footnote">KW</span></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T2.m1" class="ltx_Math" alttext="\Delta_{e}" display="inline"><msub><mi mathvariant="normal">Δ</mi><mi>e</mi></msub></math></td>
<td class="ltx_td ltx_align_right ltx_border_tt"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T2.m2" class="ltx_Math" alttext="\%_{e}" display="inline"><msub><mi mathvariant="normal">%</mi><mi>e</mi></msub></math></td>
<td class="ltx_td ltx_border_tt"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_footnote">A1</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">4.08</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">3.39</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">0.69</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">16.95</span></td>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_footnote">A2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">12.07</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">10.42</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">1.65</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">13.69</span></td>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_footnote">B1</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">12.77</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">10.00</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">2.77</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">21.67</span></td>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left"><span class="ltx_text ltx_font_footnote">B2</span></th>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">22.50</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">12.50</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">10.00</span></td>
<td class="ltx_td ltx_align_right"><span class="ltx_text ltx_font_footnote">44.44</span></td>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t"><span class="ltx_text ltx_font_footnote">Macro-average</span></th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">12.85</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">9.08</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">3.78</span></td>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_footnote">29.39</span></td>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_bb"><span class="ltx_text ltx_font_footnote">Micro-average</span></th>
<td class="ltx_td ltx_align_right ltx_border_bb"><span class="ltx_text ltx_font_footnote">11.27</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb"><span class="ltx_text ltx_font_footnote">8.25</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb"><span class="ltx_text ltx_font_footnote">3.02</span></td>
<td class="ltx_td ltx_align_right ltx_border_bb"><span class="ltx_text ltx_font_footnote">26.76</span></td>
<td class="ltx_td ltx_border_bb"/></tr>
</tbody>
</table>
</span>
<div class="ltx_caption ltx_centering ltx_font_footnote"><span class="ltx_tag ltx_tag_table">Table 2: </span>Per-group and overall retention error rate when using rote or keyword-aided (KW) memorization.</div>
</div>
<div id="S5.p2" class="ltx_para">
<p class="ltx_p">The error rate for each memorization technique <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> (where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m2" class="ltx_Math" alttext="t=\mathrm{R}" display="inline"><mrow><mi>t</mi><mo>=</mo><mi mathvariant="normal">R</mi></mrow></math> for “Rote memorization” and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m3" class="ltx_Math" alttext="t=\mathrm{K}" display="inline"><mrow><mi>t</mi><mo>=</mo><mi mathvariant="normal">K</mi></mrow></math> for “keyword-aided memorization”) is calculated as:
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m4" class="ltx_Math" alttext="e_{t}=\frac{i_{t}}{c_{t}+i_{t}}" display="inline"><mrow><msub><mi>e</mi><mi>t</mi></msub><mo>=</mo><mfrac><msub><mi>i</mi><mi>t</mi></msub><mrow><msub><mi>c</mi><mi>t</mi></msub><mo>+</mo><msub><mi>i</mi><mi>t</mi></msub></mrow></mfrac></mrow></math>,
where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m5" class="ltx_Math" alttext="c_{t}" display="inline"><msub><mi>c</mi><mi>t</mi></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m6" class="ltx_Math" alttext="i_{t}" display="inline"><msub><mi>i</mi><mi>t</mi></msub></math> are the number of correct and incorrect answers provided by the subjects, respectively. The absolute error rate reduction <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m7" class="ltx_Math" alttext="\Delta e" display="inline"><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mi>e</mi></mrow></math> is calculated as the absolute difference in error rate between rote and keyword-aided memorization, i.e.:
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m8" class="ltx_Math" alttext="\Delta_{e}=e_{\mathrm{R}}-e_{\mathrm{K}}" display="inline"><mrow><msub><mi mathvariant="normal">Δ</mi><mi>e</mi></msub><mo>=</mo><mrow><msub><mi>e</mi><mi mathvariant="normal">R</mi></msub><mo>-</mo><msub><mi>e</mi><mi mathvariant="normal">K</mi></msub></mrow></mrow></math>.
Finally, the relative error rate reduction <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m9" class="ltx_Math" alttext="\%_{e}" display="inline"><msub><mi mathvariant="normal">%</mi><mi>e</mi></msub></math> is calculated as the the ratio between the absolute error rate reduction <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m10" class="ltx_Math" alttext="\Delta e" display="inline"><mrow><mi mathvariant="normal">Δ</mi><mo>⁢</mo><mi>e</mi></mrow></math> and the error rate of rote memorization <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m11" class="ltx_Math" alttext="e_{\mathrm{R}}" display="inline"><msub><mi>e</mi><mi mathvariant="normal">R</mi></msub></math>, i.e.,: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p2.m12" class="ltx_Math" alttext="\%_{e}=\frac{\Delta_{e}}{e_{\mathrm{R}}}=\frac{e_{\mathrm{R}}-e_{\mathrm{K}}}{%&#10;e_{\mathrm{R}}}" display="inline"><mrow><msub><mi mathvariant="normal">%</mi><mi>e</mi></msub><mo>=</mo><mfrac><msub><mi mathvariant="normal">Δ</mi><mi>e</mi></msub><msub><mi>e</mi><mi mathvariant="normal">R</mi></msub></mfrac><mo>=</mo><mfrac><mrow><msub><mi>e</mi><mi mathvariant="normal">R</mi></msub><mo>-</mo><msub><mi>e</mi><mi mathvariant="normal">K</mi></msub></mrow><msub><mi>e</mi><mi mathvariant="normal">R</mi></msub></mfrac></mrow></math>.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p class="ltx_p">The overall results (rows 5 and 6 in Table <a href="#S5.T2" title="Table 2 ‣ 5 Experiment results ‣ Automation and Evaluation of the Keyword Method  for Second Language Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>) show that vocabulary learning noticeably improves when supported by the generated sentences, with error rates dropping by almost 30% in terms of macro-average (almost 27% for micro-average). The breakdown of the error rate across the 4 groups shows a clear pattern. The results clearly indicate that one group (A1) by chance contained easier words to memorize as shown by the low error rate (between 3% and 4%) obtained with both methods. Similarly, groups A2 and B1 are of average difficulty, whereas group B2 appears to be the most difficult, with an error rate higher than 22% when using only rote memorization. Interestingly, there is a strong correlation (Pearson’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p3.m1" class="ltx_Math" alttext="r=0.85" display="inline"><mrow><mi>r</mi><mo>=</mo><mn>0.85</mn></mrow></math>) between the difficulty of the words in each group (measured as the error rate on rote memorization) and the positive contribution of the generated sentences to the learning process. In fact, we can see how the relative error rate reduction <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p3.m2" class="ltx_Math" alttext="\%_{e}" display="inline"><msub><mi mathvariant="normal">%</mi><mi>e</mi></msub></math> increases from <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.p3.m3" class="ltx_Math" alttext="\sim" display="inline"><mo>∼</mo></math>17% (group A1) to almost 45% (group B2).
Based on the results obtained by <cite class="ltx_cite"/>, who showed that the keyword method results in better long-term word retention than rote memorization, we would expect the error rate reduction to be even higher in a delayed post-test.
All in all, these findings clearly support the claim that a state-of-the-art sentence generator can be successfully employed to support keyword-based second language learning.
After completing their exercise, the subjects were asked to provide feedback about their experience as learners. We set up a 4-items Likert scale <cite class="ltx_cite">[]</cite> where each item consisted of a statement and a 5-point scale of values ranging from (1) [I strongly disagree] to (5) [I strongly agree].
The distribution of the answers to the questions is shown in Table <a href="#S5.T3" title="Table 3 ‣ 5 Experiment results ‣ Automation and Evaluation of the Keyword Method  for Second Language Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
60% of the subjects acknowledged that the memory tips helped them in the memorization process; 45% found that the sentences were overall correct; 65% confirmed that the sentences were catchy and easy to remember; and 50% found the sentences to be overall witty although the sentence generator does not include a mechanism to generate humor. Finally, it is worth mentioning that none of the subjects noticed that the sentences were machine generated, which we regard as a very positive assessment of the quality of the sentence generation framework. From their comments, it emerges that the subjects actually believed that they were just comparing two memorization techniques.</p>
</div>
<div id="S5.T3" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:433.6pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_tt"/>
<th class="ltx_td ltx_align_center ltx_border_tt" colspan="5">Rating (%)</th></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t">Question</th>
<th class="ltx_td ltx_align_right ltx_border_t">1</th>
<th class="ltx_td ltx_align_right ltx_border_t">2</th>
<th class="ltx_td ltx_align_right ltx_border_t">3</th>
<th class="ltx_td ltx_align_right ltx_border_t">4</th>
<th class="ltx_td ltx_align_right ltx_border_t">5</th></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t">Sentences helped</td>
<td class="ltx_td ltx_align_right ltx_border_t">5</td>
<td class="ltx_td ltx_align_right ltx_border_t">20</td>
<td class="ltx_td ltx_align_right ltx_border_t">15</td>
<td class="ltx_td ltx_align_right ltx_border_t">35</td>
<td class="ltx_td ltx_align_right ltx_border_t">25</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Sentences are grammatical</td>
<td class="ltx_td ltx_align_right">-</td>
<td class="ltx_td ltx_align_right">25</td>
<td class="ltx_td ltx_align_right">30</td>
<td class="ltx_td ltx_align_right">35</td>
<td class="ltx_td ltx_align_right">10</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">Sentences are catchy</td>
<td class="ltx_td ltx_align_right">-</td>
<td class="ltx_td ltx_align_right">25</td>
<td class="ltx_td ltx_align_right">10</td>
<td class="ltx_td ltx_align_right">50</td>
<td class="ltx_td ltx_align_right">15</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_bb">Sentences are witty</td>
<td class="ltx_td ltx_align_right ltx_border_bb">-</td>
<td class="ltx_td ltx_align_right ltx_border_bb">25</td>
<td class="ltx_td ltx_align_right ltx_border_bb">25</td>
<td class="ltx_td ltx_align_right ltx_border_bb">50</td>
<td class="ltx_td ltx_align_right ltx_border_bb">-</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Evaluation of the generated sentences on a 5-point Likert scale.</div>
</div>
</div>
<div id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6 </span>Conclusion and Future Work</h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">In this paper, we have presented a semi-automatic system for the automation of the keyword method and used it to teach 40 Italian words to 20 English native speakers.
We let the system select appropriate keywords and generate sentences automatically. For each Italian word, we selected the most suitable among the 10 highest ranked suggestions and used it for the evaluation.
The significant reduction in retention error rate (between 17% and 45% on different word groups) for the words learned with the aid of the automatically generated sentences shows that they are a viable low-effort alternative to human-constructed examples for vocabulary teaching.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p class="ltx_p">As future work, it would be interesting to involve learners in an interactive evaluation to understand the extent to which learners can benefit from <em class="ltx_emph">ad-hoc</em> personalization. Furthermore, it should be possible to use frameworks similar to the one that we presented to automate other teaching devices based on sentences conforming to specific requirements <cite class="ltx_cite">[]</cite>, such as <em class="ltx_emph">verbal chaining</em> and <em class="ltx_emph">acrostic</em>.</p>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">This work was partially supported by the PerTe project (Trento RISE).</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 17:48:34 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
