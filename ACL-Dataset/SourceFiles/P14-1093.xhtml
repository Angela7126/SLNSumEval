<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Toward Future Scenario Generation:
Extracting Event Causality Exploiting Semantic Relation, Context, and
Association Features</title>
<!--Generated on Tue Jun 10 18:25:22 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Toward Future Scenario Generation:
Extracting Event Causality Exploiting Semantic Relation, Context, and
Association Features</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Chikara Hashimoto<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  Kentaro Torisawa<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  Julien Kloetzer<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  Motoki Sano<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  
<br class="ltx_break"/><span class="ltx_text ltx_font_bold">István Varga<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  Jong-Hoon Oh<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  Yutaka Kidawara<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> 
<br class="ltx_break"/><span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  
<span class="ltx_inline-block ltx_transformed_outer" style="width:369.7pt;height:21.1111111111111px;vertical-align:-9.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-webkit-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-ms-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;">
<p class="ltx_p">National Institute of Information and Communications Technology,
Kyoto, 619-0289, Japan</p>
</span></span> 
<br class="ltx_break"/><span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_note_type">footnotemark: </span></span></span></span>  
<span class="ltx_inline-block ltx_transformed_outer" style="width:369.7pt;height:21.1111111111111px;vertical-align:-9.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-webkit-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-ms-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;">
<p class="ltx_p">NEC Knowledge Discovery Research Laboratories,
Nara, 630-0101, Japan</p>
</span></span> 
<br class="ltx_break"/>
<span class="ltx_inline-block ltx_transformed_outer" style="width:369.7pt;height:21.1111111111111px;vertical-align:-9.3pt;"><span class="ltx_transformed_inner" style="transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-webkit-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;-ms-transform:translate(-32.6pt,-1.3pt) scale(.85,.85) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_medium">{<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">footnotemark: </span></span></span></span><span class="ltx_text ltx_font_typewriter"> ch, <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> torisawa,
<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> julien, <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> msano,
<span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> rovellia, <span class="ltx_note ltx_role_footnotemark"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_note_type">footnotemark: </span></span></span></span> kidawara</span>}<span class="ltx_text ltx_font_typewriter">@nict.go.jp</span></span></p>
</span></span>
</span>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">We propose a supervised method
of extracting
event causalities like
<span class="ltx_text ltx_font_italic">conduct slash-and-burn agriculture<math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>exacerbate desertification</span>
from the web
using
semantic relation (between nouns), context, and association features.
Experiments show that our
method outperforms
baselines
that are
based on state-of-the-art methods.
We also propose methods
of generating
<em class="ltx_emph">future scenarios</em> like
<span class="ltx_text ltx_font_italic">conduct slash-and-burn agriculture<math xmlns="http://www.w3.org/1998/Math/MathML" id="m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>exacerbate desertification<math xmlns="http://www.w3.org/1998/Math/MathML" id="m3" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>increase Asian dust (from China)<math xmlns="http://www.w3.org/1998/Math/MathML" id="m4" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>asthma gets worse</span>.
Experiments
show that
we can generate
50,000 scenarios with 68% precision.
We also generated a scenario
<span class="ltx_text ltx_font_italic">deforestation continues<math xmlns="http://www.w3.org/1998/Math/MathML" id="m5" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>global warming worsens<math xmlns="http://www.w3.org/1998/Math/MathML" id="m6" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>sea temperatures rise<math xmlns="http://www.w3.org/1998/Math/MathML" id="m7" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>vibrio parahaemolyticus fouls (water)</span>, which is written in no document in our input web corpus crawled in
2007.
But the vibrio risk due to global warming was observed in <cite class="ltx_cite">Baker-Austin<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib3" title="Emerging vibrio risk at high latitudes in response to ocean warming" class="ltx_ref">2013</a>)</cite>.
Thus,
we “predicted” the future event sequence in a sense.</p>
</div><span class="ltx_ERROR undefined">\externaldocument</span>
<div id="p1" class="ltx_para">
<p class="ltx_p">[A-]acl2014-supplementary-cameraready</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction </h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">The world can be seen as a network of causality where people,
organizations, and other kinds of entities
causally
depend on each other.
This network is so huge and complex that it is almost
impossible for humans to exhaustively predict the consequences of a
given event.
Indeed,
after the Great East Japan Earthquake in 2011, few expected that
it would lead to an enormous trade deficit in Japan due to
a sharp increase in energy imports.
For effective decision making that carefully
considers any form of future risks and chances, we need a system that helps humans do <span class="ltx_text ltx_font_italic">scenario planning</span>
<cite class="ltx_cite">[<a href="#bib.bib14" title="The art of the long view" class="ltx_ref">23</a>]</cite>, which is a decision-making scheme that examines
possible future events and assesses their potential chances and
risks.
Our ultimate goal is to develop a system that supports scenario planning
through generating possible
future events using big data, which would contain what Donald Rumsfeld
called “unknown unknowns”<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>
<a href="http://youtu.be/GiPe1OiKQuk" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://youtu.be/GiPe1OiKQuk</span></a>
</span></span></span>
<cite class="ltx_cite">[<a href="#bib.bib33" title="Organizing the web’s information explosion to discover unknown unknowns" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">To this end,
we propose a supervised method of extracting such event
causality as
<span class="ltx_text ltx_font_italic">conduct slash-and-burn agriculture<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p2.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>exacerbate desertification</span>
and use its output to generate <em class="ltx_emph">future scenarios</em>
(<em class="ltx_emph">scenarios</em>),
which are
chains of causality
that have been or might be observed in this world like
<span class="ltx_text ltx_font_italic">conduct slash-and-burn agriculture<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p2.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>exacerbate desertification<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p2.m3" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>increase Asian dust (from China)<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p2.m4" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>asthma gets worse</span>.
Note that, in this paper,
<span class="ltx_text ltx_font_italic">A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p2.m5" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>B</span> denotes that <span class="ltx_text ltx_font_italic">A</span> causes <span class="ltx_text ltx_font_italic">B</span>, which
means that
“<em class="ltx_emph">if A happens, the probability of B increases</em>.”
Our notion of causality
should be interpreted probabilistically rather than logically.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">Our method extracts event causality
based on three assumptions that are embodied as features of our
classifier.
First, we assume that two nouns
(e.g. <span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span> and <span class="ltx_text ltx_font_italic">desertification</span>)
that take some specific binary semantic
relations (e.g. <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">causes</span> <span class="ltx_text ltx_font_italic">B</span>) tend to constitute event
causality if combined with two predicates
(e.g. <span class="ltx_text ltx_font_italic">conduct</span> and <span class="ltx_text ltx_font_italic">exacerbate</span>).
Note that semantic relations are not restricted to
those directly relevant to causality like
<span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">causes</span> <span class="ltx_text ltx_font_italic">B</span> but can be those that might seem irrelevant to
causality like <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">is an ingredient for</span> <span class="ltx_text ltx_font_italic">B</span>
(e.g. <span class="ltx_text ltx_font_italic">plutonium</span> and <span class="ltx_text ltx_font_italic">atomic bomb</span> as in
<span class="ltx_text ltx_font_italic">plutonium is stolen<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p3.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>atomic bomb is made</span>).
Our underlying intuition is the observation that
event causality tends to hold between two entities linked by
semantic relations which roughly entail that one entity strongly
affects the other.
Such semantic relations can be expressed by (otherwise unintuitive)
patterns like <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">is an ingredient for</span> <span class="ltx_text ltx_font_italic">B</span>.
As such, semantic relations like the <span class="ltx_text ltx_font_smallcaps">Material</span> relation can
also be useful.
(See Section <a href="#S3.SS2.SSS1" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a> for a more intuitive
explanation.)</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">Our second assumption is that there are grammatical
contexts in which event causality is more likely to appear.
We implement what we consider likely contexts for
event causality as context features.
For example, a likely context of event causality
(underlined) would be:
<span class="ltx_ERROR undefined">\Underline</span><span class="ltx_text ltx_font_italic">CO2 levels rose, so
<span class="ltx_ERROR undefined">\Underline</span>climatic anomalies were observed</span>,
while an unlikely context would be:
<span class="ltx_text ltx_font_italic">It remains uncertain whether if <span class="ltx_ERROR undefined">\Underline</span>the recession is bottomed
<span class="ltx_ERROR undefined">\Underline</span>the declining birth rate is halted</span>.
Useful context information includes the mood of the
sentences (e.g., the uncertainty mood expressed by <span class="ltx_text ltx_font_italic">uncertain</span>
above),
which is represented by lexical features
(Section <a href="#S3.SS2.SSS2" title="3.2.2 Context Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>).</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">The last assumption embodied in our association features
is that each word of the cause phrase must have
a strong association (i.e., PMI, for example)
with that of the effect phrase
as <span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span> and <span class="ltx_text ltx_font_italic">desertification</span>
in the above example,
as in <cite class="ltx_cite">Do<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">2011</a>)</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">Our method exploits these
features on top of our base features such as nouns and predicates.
Experiments using 600 million web pages <cite class="ltx_cite">[<a href="#bib.bib15" title="Organizing information on the web to support user judgments on information credibility" class="ltx_ref">2</a>]</cite>
show that
our method outperforms baselines based on state-of-the-art methods
<cite class="ltx_cite">[<a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">8</a>, <a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">12</a>]</cite>
by more than 19% of average precision.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">We require that event causality be
<em class="ltx_emph">self-contained</em>,
i.e., intelligible as causality without the
sentences from which it was extracted.
For example,
<span class="ltx_text ltx_font_italic">omit toothbrushing<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p7.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>get a cavity</span>
is self-contained, but
<span class="ltx_text ltx_font_italic">omit toothbrushing<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p7.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>get a girlfriend</span>
is not since this is not intelligible without a context:
<span class="ltx_text ltx_font_italic">He omitted toothbrushing every day and got a girlfriend
who was a dental assistant of dental clinic he went to for his cavity</span>.
This is important since
future scenarios, which are generated by chaining event causality
as described below, must be self-contained,
unlike <cite class="ltx_cite">Hashimoto<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">2012</a>)</cite>.
To make event causality self-contained, we
wrote guidelines for manually annotating
training/development/test data.
Annotators regarded as event
causality only phrase pairs that were interpretable as event causality
without contexts (i.e., self-contained).
From the training data,
our method seemed to successfully learn what self-contained event
causality is.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p class="ltx_p">Our scenario generation method
generates scenarios by chaining extracted event causality;
generating <span class="ltx_text ltx_font_italic">A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>B<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>C</span> from <span class="ltx_text ltx_font_italic">A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m3" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>B</span> and <span class="ltx_text ltx_font_italic">B<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m4" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>C</span>.
The challenge is that many acceptable scenarios are overlooked
if we require the joint part of the chain (<span class="ltx_text ltx_font_italic">B</span> above)
to be an exact match.
To increase the number of acceptable scenarios,
our method identifies compatibility w.r.t causality
between two phrases
by a recently proposed semantic polarity,
<em class="ltx_emph">excitation</em>
<cite class="ltx_cite">[<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">12</a>]</cite>,
which properly relaxes the chaining condition
(Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> describes it).
For example, our method can identify the compatibility between
<span class="ltx_text ltx_font_italic">sea temperatures are high</span> and
<span class="ltx_text ltx_font_italic">sea temperatures rise</span> to chain <span class="ltx_text ltx_font_italic">global warming worsens<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m5" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>sea temperatures are high</span>
and <span class="ltx_text ltx_font_italic">sea temperatures rise<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m6" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>vibrio parahaemolyticus<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>
A bacterium in the sea causing food-poisoning.
</span></span></span>
fouls (water)</span>. Accordingly,
we generated a scenario
<span class="ltx_text ltx_font_italic">deforestation continues<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m7" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>global warming worsens<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m8" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>sea temperatures rise<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m9" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>vibrio parahaemolyticus fouls (water)</span>, which is written in no document in our input web corpus that was crawled
in 2007,
but the vibrio risk due to global warming has actually been observed in
the Baltic sea and reported in
<cite class="ltx_cite">Baker-Austin<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib3" title="Emerging vibrio risk at high latitudes in response to ocean warming" class="ltx_ref">2013</a>)</cite>.
In a sense, we “predicted” the event sequence reported in 2013 by
documents written in 2007.
Our experiments
also show that we generated 50,000 scenarios with 68% precision,
which include
<span class="ltx_text ltx_font_italic">conduct terrorist operations<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m10" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>terrorist bombing occurs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m11" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>cause fatalities and injuries<math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p8.m12" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>cause economic losses</span> and the above
“<span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span>” scenario
(Section <a href="#S5.SS2" title="5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>).
Neither is written in any document in our input corpus.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p class="ltx_p">In this paper, our target language is Japanese.
However, we believe that our ideas and methods are applicable to many
languages.
Examples are translated into English for ease of explanation.
Supplementary notes of this paper are available at
<a href="http://khn.nict.go.jp/analysis/member/ch/acl2014-sup.pdf" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://khn.nict.go.jp/analysis/member/ch/acl2014-sup.pdf</span></a>.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">For <span class="ltx_text ltx_font_bold">event causality extraction</span>,
clues used by previous methods can roughly
be categorized as
lexico-syntactic patterns
<cite class="ltx_cite">[<a href="#bib.bib19" title="Two-phrased event relation acquisition: coupling the relation-oriented and argument-oriented approaches" class="ltx_ref">1</a>, <a href="#bib.bib12" title="Learning causality for news events prediction" class="ltx_ref">20</a>]</cite>,
words in context
<cite class="ltx_cite">[<a href="#bib.bib11" title="Why-question answering using intra- and inter-sentential causal relations" class="ltx_ref">19</a>]</cite>,
associations among words
<cite class="ltx_cite">[<a href="#bib.bib21" title="Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences" class="ltx_ref">28</a>, <a href="#bib.bib29" title="Another look at causality: discovering scenario-specific contingency relationships with no supervision" class="ltx_ref">22</a>, <a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">8</a>]</cite>, and
predicate semantics
<cite class="ltx_cite">[<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">12</a>]</cite>.
Besides
features similar to those described above,
we propose
semantic relation features<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>
<cite class="ltx_cite">Radinsky<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib12" title="Learning causality for news events prediction" class="ltx_ref">2012</a>)</cite>
and <cite class="ltx_cite">Tanaka<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib1" title="Acquiring and generalizing causal inference rules from deverbal noun constructions" class="ltx_ref">2012</a>)</cite>
used semantic relations to <em class="ltx_emph">generalize</em>
acquired causality instances.</span></span></span>
that include those that are not obviously related to
causality.
We show that such thorough exploitation of new and existing features leads to
high performance.
Other clues include shared arguments
<cite class="ltx_cite">[<a href="#bib.bib21" title="Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences" class="ltx_ref">28</a>, <a href="#bib.bib17" title="Unsupervised learning of narrative event chains" class="ltx_ref">4</a>, <a href="#bib.bib18" title="Unsupervised learning of narrative schemas and their participants" class="ltx_ref">5</a>]</cite>,
which we ignore since we target event causality about two
distinct entities.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">To the best of our knowledge,
<span class="ltx_text ltx_font_bold">future scenario generation</span> is a new task,
although previous works have addressed similar tasks
<cite class="ltx_cite">[<a href="#bib.bib12" title="Learning causality for news events prediction" class="ltx_ref">20</a>, <a href="#bib.bib13" title="Mining the web to predict future events" class="ltx_ref">21</a>]</cite>.
Neither involves chaining and restricts themselves to only one
event causality step.
Besides, the events they predict must be those for which
similar events have previously been observed, and their method only
applies to news domain.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">Some of the scenarios we generated are written on no page in our input
web corpus.
Similarly,
<cite class="ltx_cite">Tsuchida<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib27" title="Toward finding semantic relations not written in a single sentence: an inference method using auto-discovered rules" class="ltx_ref">2011</a>)</cite>
generated
semantic knowledge like causality that is written in no
sentence.
However, their method cannot combine more than two pieces of knowledge
unlike ours,
and their target knowledge consists of nouns, but ours consists of verb
phrases, which are more informative.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p"><cite class="ltx_cite">Tanaka<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib36" title="WISDOM2013: a large-scale web information analysis system" class="ltx_ref">2013</a>)</cite>’s
web information analysis system
provides a <em class="ltx_emph">what-happens-if QA</em> service, which is based on our
scenario generation method.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Event Causality Extraction Method
</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">This section describes our event causality extraction method.
Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> describes
how to extract event causality candidates, and
Section <a href="#S3.SS2" title="3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>
details our features.
Section <a href="#S3.SS3" title="3.3 Event Causality Scoring ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> shows how to rank event
causality candidates.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Event Causality Candidate Extraction
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We extract the event causality between two
events represented by two phrases from single sentences
that are dependency parsed.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>
We used a Japanese dependency parser called J.DepP
<cite class="ltx_cite">[<a href="#bib.bib30" title="Polynomial to linear: efficient classification with conjunctive features" class="ltx_ref">30</a>]</cite>, available at
<a href="http://www.tkl.iis.u-tokyo.ac.jp/~ynaga/jdepp/" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://www.tkl.iis.u-tokyo.ac.jp/~ynaga/jdepp/</span></a>.</span></span></span>
We obtained sentences from 600 million web pages.
Each phrase in the event causality must
consist of a predicate with an argument
position (<em class="ltx_emph">template</em>, hereafter) like
<span class="ltx_text ltx_font_italic">conduct X</span>
and a noun like
<span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span>
that completes <span class="ltx_text ltx_font_italic">X</span>.
We also require the predicate of the cause phrase to syntactically
depend on the effect phrase in the sentence from which the event
causality was extracted;
we guarantee this by verifying the dependencies of the original sentence.
In Japanese, since the temporal order between events is usually
determined by precedence in a sentence, we require the
cause phrase to precede the effect phrase.
For context feature extraction, the
event causality candidates are accompanied by the original sentences from
which they were extracted.</p>
</div>
<div id="S3.SS1.SSS0.P1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Excitation</h5>

<div id="S3.SS1.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">We only keep the event causality candidates each phrase of which
consists of <em class="ltx_emph">excitation templates</em>, which have been shown to be
effective for causality extraction
<cite class="ltx_cite">[<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">12</a>]</cite> and other
semantic NLP tasks
<cite class="ltx_cite">[<a href="#bib.bib11" title="Why-question answering using intra- and inter-sentential causal relations" class="ltx_ref">19</a>]</cite>.
Excitation is a semantic property of templates
that classifies them into <em class="ltx_emph">excitatory</em>, <em class="ltx_emph">inhibitory</em>,
and <em class="ltx_emph">neutral</em>.
Excitatory templates such as <span class="ltx_text ltx_font_italic">cause X</span> entail that the function, effect, purpose or
role of their argument’s referent is activated, enhanced, or manifested,
while inhibitory templates such as <span class="ltx_text ltx_font_italic">lower X</span> entail that it is
deactivated or suppressed.
Neutral ones like <span class="ltx_text ltx_font_italic">proportional to X</span> belong to neither of
them.
We collectively call both excitatory and inhibitory templates
excitation templates.
We acquired 43,697 excitation templates by Hashimoto et al.’s
method and the manual annotation of excitation
template candidates.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>
Hashimoto et al.’s method constructs a network of
templates based on their co-occurrence in web sentences with a small
number of polarity-assigned seed templates and infers the polarity of
all the templates in the network by a constraint solver based on
the spin model <cite class="ltx_cite">[<a href="#bib.bib31" title="Extracting semantic orientation of words using spin model" class="ltx_ref">24</a>]</cite>.</span></span></span>
We applied the excitation filter to
all 272,025,401 event causality candidates from the web
and 132,528,706 remained.</p>
</div>
<div id="S3.SS1.SSS0.P1.p2" class="ltx_para">
<p class="ltx_p">After
applying additional filters
(see Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:filtering-conditions</span> in
the supplementary notes)
including those based on a
stop-word list and a causal connective list
to remove unlikely event causality
candidates that are not removed by the above filter,
we finally acquired 2,451,254 event causality candidates.</p>
</div>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Features for Event Causality Classifier
</h3>

<div id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Semantic Relation Features
</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p class="ltx_p">We hypothesize that two nouns with some particular semantic relations
are more likely to constitute event causality.
Below we describe the semantic relations that we believe are likely
to constitute event causality.</p>
</div><span class="ltx_ERROR undefined">\Underline</span>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_smallcaps">Causation</span>
is the causal relation between two
entities and is expressed by binary patterns like
<span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">causes</span> <span class="ltx_text ltx_font_italic">B</span>.
<span class="ltx_text ltx_font_italic">Deforestation</span> and <span class="ltx_text ltx_font_italic">global warming</span>
might complete the <span class="ltx_text ltx_font_italic">A</span> and <span class="ltx_text ltx_font_italic">B</span> slots.
We manually collected
748 binary patterns for this relation.
(See Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:examples-of-binary-patterns</span> in
the supplementary notes for examples of our binary patterns.)</p>
</div><span class="ltx_ERROR undefined">\Underline</span>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_smallcaps">Material</span> is the relation between a material and
a product made of it (e.g. <span class="ltx_text ltx_font_italic">plutonium</span> and <span class="ltx_text ltx_font_italic">atomic bomb</span>)
and can be expressed by
<span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">is made of</span> <span class="ltx_text ltx_font_italic">B</span>.
Its relation to event causality might seem unclear, but
a material can be seen as a “cause” of a product.
Indeed materials can participate in event causality with the help of
such template pairs as <span class="ltx_text ltx_font_italic">A is stolen<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS1.p3.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>B is made</span>
as in <span class="ltx_text ltx_font_italic">plutonium is stolen<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS1.p3.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>atomic bomb is made</span>.
We manually collected 187 binary patterns for this relation.</p>
</div><span class="ltx_ERROR undefined">\Underline</span>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_smallcaps">Necessity</span>’s
patterns include <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">is necessary for</span> <span class="ltx_text ltx_font_italic">B</span>,
which can be filled with
<span class="ltx_text ltx_font_italic">verbal aptitude</span> and <span class="ltx_text ltx_font_italic">ability to think</span>. Noun pairs with this relation can constitute event causality when
combined with template pairs like
<span class="ltx_text ltx_font_italic">improve A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS1.p4.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>cultivate B</span>.
We collected 257 patterns for this relation.</p>
</div><span class="ltx_ERROR undefined">\Underline</span>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_smallcaps">Use</span> is the relation between means (or
instruments) and the purpose for using them.
<span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">is used for</span> <span class="ltx_text ltx_font_italic">B</span> is a pattern of
the relation, which can be filled with
<span class="ltx_text ltx_font_italic">e-mailer</span> and <span class="ltx_text ltx_font_italic">exchanges of e-mail messages</span>.
Note that means can be seen as “causing” or “realizing”
the purpose of using the means in this relation,
and actually event causality can be obtained by incorporating noun pairs of
this relation into template pairs like
<span class="ltx_text ltx_font_italic">activate A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS1.p5.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>conduct B</span>.
2,178 patterns were collected for this relation.</p>
</div><span class="ltx_ERROR undefined">\Underline</span>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_smallcaps">Prevention</span> is the relation expressed by
patterns like <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">prevents</span> <span class="ltx_text ltx_font_italic">B</span>,
which can be filled with <span class="ltx_text ltx_font_italic">toothbrushing</span> and
<span class="ltx_text ltx_font_italic">periodontal disease</span>.
This relation is, so to speak, “negative <span class="ltx_text ltx_font_smallcaps">Causation</span>”
since the entity denoted by the noun completing the <span class="ltx_text ltx_font_italic">A</span> slot
makes the entity denoted by the <span class="ltx_text ltx_font_italic">B</span> noun NOT realized.
Such noun pairs mean event causality by substituting them into
template pairs like <span class="ltx_text ltx_font_italic">omit A<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS1.p6.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>get B</span>.
The number of patterns is 490.</p>
</div>
<div id="S3.SS2.SSS1.p7" class="ltx_para">
<p class="ltx_p">The experiments
in Section <a href="#S5.SS1.SSS1" title="5.1.1 Ablation Tests ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.1</span></a>
show that
not only <span class="ltx_text ltx_font_smallcaps">Causation</span> and <span class="ltx_text ltx_font_smallcaps">Prevention</span>
(“negative <span class="ltx_text ltx_font_smallcaps">Causation</span>”)
but the other relations are also effective for event causality
extraction.</p>
</div>
<div id="S3.SS2.SSS1.p8" class="ltx_para">
<p class="ltx_p">In addition,
we invented the
<span class="ltx_ERROR undefined">\Underline</span><span class="ltx_text ltx_font_smallcaps">Excitation</span> relation that is expressed by
binary patterns made of excitatory and inhibitory templates
(Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
For instance, we make binary patterns
<span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">rises</span> <span class="ltx_text ltx_font_italic">B</span> and <span class="ltx_text ltx_font_italic">A</span> <span class="ltx_text ltx_font_smallcaps">lowers</span> <span class="ltx_text ltx_font_italic">B</span> from
excitatory template <span class="ltx_text ltx_font_italic">rise X</span> and inhibitory template
<span class="ltx_text ltx_font_italic">lower X</span> respectively.
The <span class="ltx_text ltx_font_smallcaps">Excitation</span> relation roughly means that
<span class="ltx_text ltx_font_italic">A</span> activates <span class="ltx_text ltx_font_italic">B</span> (excitatory) or suppresses it (inhibitory).
We simply add an additional argument position to each template in the 43,697 excitation templates
to make binary patterns.
We restricted the argument positions (represented by Japanese
postpositions) of the <span class="ltx_text ltx_font_italic">A</span> slot to either <span class="ltx_text ltx_font_italic">ha</span> (topic marker),
<span class="ltx_text ltx_font_italic">ga</span> (nominative), or <span class="ltx_text ltx_font_italic">de</span> (instrumental) and those of the
<span class="ltx_text ltx_font_italic">B</span> slot to either <span class="ltx_text ltx_font_italic">ha</span>, <span class="ltx_text ltx_font_italic">ga</span>, <span class="ltx_text ltx_font_italic">de</span>,
<span class="ltx_text ltx_font_italic">wo</span> (accusative), or <span class="ltx_text ltx_font_italic">ni</span> (dative),
and obtained 55,881 patterns.</p>
</div>
<div id="S3.SS2.SSS1.p9" class="ltx_para">
<p class="ltx_p">Moreover,
for broader coverage,
we acquired binary patterns that
entail or are entailed by one of the patterns of the above six semantic
relations.
Those patterns
were acquired from
our web corpus by
<cite class="ltx_cite">Kloetzer<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib7" title="Large-scale acquisition of entailment pattern pairs" class="ltx_ref">2013b</a>)</cite>’s
method,
which acquired 185 million entailment pairs with
80% precision from our web corpus and was used for contradiction
acquisition <cite class="ltx_cite">[<a href="#bib.bib8" title="Two-stage method for large-scale acquisition of contradiction pattern pairs using entailment" class="ltx_ref">14</a>]</cite>.
We acquired 335,837 patterns by this method.
They are <em class="ltx_emph">class-dependent patterns</em>,
which have semantic class restrictions on arguments.
The semantic classes
were obtained from our web corpus based on <cite class="ltx_cite">Kazama and Torisawa (<a href="#bib.bib6" title="Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations" class="ltx_ref">2008</a>)</cite>.
See <cite class="ltx_cite">De Saeger<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib34" title="Large scale relation acquisition using class dependent patterns" class="ltx_ref">2009</a>)</cite>,
<cite class="ltx_cite">De Saeger<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib35" title="Relation acquisition using word classes and partial patterns" class="ltx_ref">2011</a>)</cite> and
<cite class="ltx_cite">Kloetzer<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib8" title="Two-stage method for large-scale acquisition of contradiction pattern pairs using entailment" class="ltx_ref">2013a</a>)</cite>
for more on our patterns.
They collectively constitute
the <span class="ltx_ERROR undefined">\Underline</span><span class="ltx_text ltx_font_smallcaps">Entailment</span> relation.</p>
</div>
<div id="S3.SS2.SSS1.p10" class="ltx_para">
<p class="ltx_p">Table <a href="#S3.T1" title="Table 1 ‣ 3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a></p>
</div>
<div id="S3.T1" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:203.8pt;height:166.666666666667px;vertical-align:-57.2pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.5pt,-15.0pt) scale(.7999,.7999) ;-webkit-transform:translate(-25.5pt,-15.0pt) scale(.7999,.7999) ;-ms-transform:translate(-25.5pt,-15.0pt) scale(.7999,.7999) ;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:239.8pt;">
<dl id="I1" class="ltx_description">
<dt id="I1.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_description">SR1:</span></dt>
<dd class="ltx_item">
<div id="I1.ix1.p1" class="ltx_para">
<p class="ltx_p">Binary pattern of our semantic relations that
co-occurs with two nouns of an event causality candidate
in our web corpus.</p>
</div></dd>
<dt id="I1.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_description">SR2:</span></dt>
<dd class="ltx_item">
<div id="I1.ix2.p1" class="ltx_para">
<p class="ltx_p">Semantic relation types (e.g <span class="ltx_text ltx_font_smallcaps">Causation</span> and
<span class="ltx_text ltx_font_smallcaps">Entailment</span>)
of the binary pattern of SR1.
<span class="ltx_text ltx_font_smallcaps">Excitation</span> is divided into six sub types
based on the excitation polarity
of the binary patterns,
the argument positions,
and the existence of causative markers.
A <span class="ltx_text ltx_font_smallcaps">Causation</span> pattern, <span class="ltx_text ltx_font_italic">B</span> <span class="ltx_text ltx_font_smallcaps">by</span> <span class="ltx_text ltx_font_italic">A</span>,
constitutes an independent relation called
the <span class="ltx_text ltx_font_smallcaps">By</span> relation.</p>
</div></dd>
</dl>
</span>
</span></span>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Semantic relation features.</div>
</div>
<div id="S3.SS2.SSS1.p11" class="ltx_para">
<p class="ltx_p">shows our semantic relation features.
To use them, we first make a database that records
which noun pairs co-occur with each binary pattern. Then we check a noun pair (the nouns of the cause and
effect phrases) for each event causality candidate,
and give the candidate all the patterns in the database that
co-occur with the noun pair.</p>
</div>
</div>
<div id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Context Features </h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p class="ltx_p">We believe that contexts exist
where event causality candidates are more likely to appear, as
described in Section <a href="#S1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
We developed features that capture the characteristics of
likely contexts for Japanese event causality
(See Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:context-features</span> in the supplementary notes).
In a nutshell, they represent a connective
(<span class="ltx_text ltx_font_bold">C1</span> and <span class="ltx_text ltx_font_bold">C2</span> in
Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:context-features</span>),
the distance between the elements of event causality candidate
(<span class="ltx_text ltx_font_bold">C3</span> and <span class="ltx_text ltx_font_bold">C4</span>), words in context
(<span class="ltx_text ltx_font_bold">C5</span> to <span class="ltx_text ltx_font_bold">C8</span>),
the existence of adnominal modifier
(<span class="ltx_text ltx_font_bold">9</span> to <span class="ltx_text ltx_font_bold">C10</span>),
and
the existence of additional arguments of
cause and effect predicates (<span class="ltx_text ltx_font_bold">C13</span> to <span class="ltx_text ltx_font_bold">C20</span>),
among others.</p>
</div>
</div>
<div id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.2.3 </span>Association Features </h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p class="ltx_p">These features measure the association strength between
<span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span> and <span class="ltx_text ltx_font_italic">desertification</span>
in <span class="ltx_text ltx_font_italic">conduct slash-and-burn agriculture<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSS3.p1.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>exacerbate desertification</span>
for instance and consist of CEA-, Wikipedia-, definition-, and web-based features.
<span class="ltx_text ltx_font_bold">CEA-based features</span>
are based on the Cause Effect
Association (CEA) measure of <cite class="ltx_cite">Do<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">2011</a>)</cite>.
It consists of association measures like PMI between arguments (nouns), between
arguments and predicates, and between predicates
(Table <a href="#S3.T2" title="Table 2 ‣ 3.2.3 Association Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).
Do et al. used it (along with discourse relations) to extract event
causality.</p>
</div>
<div id="S3.T2" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:203.8pt;height:280.277777777778px;vertical-align:-98.1pt;"><span class="ltx_transformed_inner" style="transform:translate(-25.5pt,-25.2pt) scale(.7999,.7999) ;-webkit-transform:translate(-25.5pt,-25.2pt) scale(.7999,.7999) ;-ms-transform:translate(-25.5pt,-25.2pt) scale(.7999,.7999) ;">
<span class="ltx_inline-block ltx_minipage ltx_align_middle" style="width:239.8pt;">
<dl id="I2" class="ltx_description">
<dt id="I2.ix1" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC1:</span></dt>
<dd class="ltx_item">
<div id="I2.ix1.p1" class="ltx_para">
<p class="ltx_p">The CEA value, the sum of AC2, AC3, and AC4.</p>
</div></dd>
<dt id="I2.ix2" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC2:</span></dt>
<dd class="ltx_item">
<div id="I2.ix2.p1" class="ltx_para">
<p class="ltx_p">Do et al.’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix2.p1.m1" class="ltx_Math" alttext="S_{pp}" display="inline"><msub><mi>S</mi><mrow><mi>p</mi><mo>⁢</mo><mi>p</mi></mrow></msub></math>. This is the association measure between
predicates, which is the product of AC5, AC6 and AC7 below.
They are calculated from the 132,528,706 event causality
candidates in Section
<a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
We omit Do et al.’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix2.p1.m2" class="ltx_Math" alttext="Dist" display="inline"><mrow><mi>D</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>t</mi></mrow></math>, which is a constant
since we set our window size to one.</p>
</div></dd>
<dt id="I2.ix3" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC3:</span></dt>
<dd class="ltx_item">
<div id="I2.ix3.p1" class="ltx_para">
<p class="ltx_p">Do et al.’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix3.p1.m1" class="ltx_Math" alttext="S_{pa}" display="inline"><msub><mi>S</mi><mrow><mi>p</mi><mo>⁢</mo><mi>a</mi></mrow></msub></math>. This is the association measure
between arguments and
predicates, which is the sum of AC8 and AC9.
They are calculated from the 132,528,706 event causality
candidates.</p>
</div></dd>
<dt id="I2.ix4" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC4:</span></dt>
<dd class="ltx_item">
<div id="I2.ix4.p1" class="ltx_para">
<p class="ltx_p">Do et al.’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix4.p1.m1" class="ltx_Math" alttext="S_{aa}" display="inline"><msub><mi>S</mi><mrow><mi>a</mi><mo>⁢</mo><mi>a</mi></mrow></msub></math>, which is PMI between arguments.
We obtained it in the same way as Filter 5
in the supplementary notes.</p>
</div></dd>
<dt id="I2.ix5" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC5:</span></dt>
<dd class="ltx_item">
<div id="I2.ix5.p1" class="ltx_para">
<p class="ltx_p">PMI between predicates.</p>
</div></dd>
<dt id="I2.ix6" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC6 / AC7:</span></dt>
<dd class="ltx_item">
<div id="I2.ix6.p1" class="ltx_para">
<p class="ltx_p">Do et al.’s <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix6.p1.m1" class="ltx_Math" alttext="max" display="inline"><mrow><mi>m</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>x</mi></mrow></math> / <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.ix6.p1.m2" class="ltx_Math" alttext="IDF" display="inline"><mrow><mi>I</mi><mo>⁢</mo><mi>D</mi><mo>⁢</mo><mi>F</mi></mrow></math>.</p>
</div></dd>
<dt id="I2.ix7" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC8:</span></dt>
<dd class="ltx_item">
<div id="I2.ix7.p1" class="ltx_para">
<p class="ltx_p">PMI between a cause noun and an effect predicate.</p>
</div></dd>
<dt id="I2.ix8" class="ltx_item"><span class="ltx_tag ltx_tag_description">AC9:</span></dt>
<dd class="ltx_item">
<div id="I2.ix8.p1" class="ltx_para">
<p class="ltx_p">PMI between a cause predicate and an effect noun.</p>
</div></dd>
</dl>
</span>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>CEA-based association features.</div>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Wikipedia-based features</span>
are the co-occurrence counts and the PMI values between cause and effect
nouns calculated using Wikipedia
(as of 2013-Sep-19).
We also checked whether an Wikipedia article whose title
is a cause (effect) noun contains its effect (cause) noun, as
detailed in
Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:wikipedia-based-association-features</span>
in the supplementary notes.
<span class="ltx_text ltx_font_bold">Definition-based features</span>,
as detailed in
Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:definition-based-association-features</span>
in the supplementary notes,
resemble the Wikipedia-based features except that the
information source is the definition sentences automatically acquired
from our 600 million web pages using the method of
<cite class="ltx_cite">Hashimoto<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib28" title="Extracting paraphrases from definition sentences on the web" class="ltx_ref">2011</a>)</cite>.
<span class="ltx_text ltx_font_bold">Web-based features</span>
provide association measures between nouns using various window
sizes in the 600 million web pages.
See Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:web-based-association-features</span> for detail.
Web-based association measures were obtained from the same database as
<span class="ltx_text ltx_font_bold">AC4</span> in Table <a href="#S3.T2" title="Table 2 ‣ 3.2.3 Association Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</div>
<div id="S3.SS2.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">3.2.4 </span>Base Features </h4>

<div id="S3.SS2.SSS4.p1" class="ltx_para">
<p class="ltx_p">Base features represent the basic properties of event causality
like nouns, templates, and their excitation polarities
(See Section
<span class="ltx_ref ltx_ref_self">LABEL:A-sec:base-features</span> in the supplementary notes).
For <span class="ltx_text ltx_font_bold">B3</span> and <span class="ltx_text ltx_font_bold">B4</span>, 500 semantic classes
were obtained from our web corpus using the method of
<cite class="ltx_cite">Kazama and Torisawa (<a href="#bib.bib6" title="Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations" class="ltx_ref">2008</a>)</cite>.</p>
</div>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Event Causality Scoring </h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">Using the above features, a classifier<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup>
We used SVM<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="{}^{light}" display="inline"><msup><mi/><mrow><mi>l</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>g</mi><mo>⁢</mo><mi>h</mi><mo>⁢</mo><mi>t</mi></mrow></msup></math> with the polynominal kernel (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m2" class="ltx_Math" alttext="d=2" display="inline"><mrow><mi>d</mi><mo>=</mo><mn>2</mn></mrow></math>),
available at <a href="http://svmlight.joachims.org" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://svmlight.joachims.org</span></a>.
</span></span></span> classifies each event causality
candidate into causality and non-causality.
An event causality candidate is given a causality score
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m3" class="ltx_Math" alttext="CScore" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi></mrow></math>, which is the SVM score (distance from the hyperplane)
that is normalized to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m4" class="ltx_Math" alttext="[0,1]" display="inline"><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>]</mo></mrow></math> by the
sigmoid function <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m5" class="ltx_Math" alttext="\frac{1}{1+e^{-x}}" display="inline"><mfrac><mn>1</mn><mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi><mrow><mo>-</mo><mi>x</mi></mrow></msup></mrow></mfrac></math>.
Each
event causality candidate may be given multiple original
sentences, since a phrase pair can appear in multiple sentences,
in which case it is given more than one SVM score.
For such candidates, we give the largest score
and keep only one original sentence that
corresponds to the largest score.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup>
Future work will exploit other original sentences, as suggested by an
anonymous reviewer.
</span></span></span>
Original sentences are also used for scenario generation,
as described below.</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Future Scenario Generation Method
</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">Our future scenario
generation method creates scenarios by chaining
event causalities.
A naive approach chains two phrase pairs by
exact matching.
However, this approach would overlook many acceptable
scenarios
as discussed in
Section <a href="#S1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
For example,
<span class="ltx_text ltx_font_italic">global warming worsens<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p1.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>sea temperatures are high</span>
and <span class="ltx_text ltx_font_italic">sea temperatures rise<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p1.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>vibrio parahaemolyticus fouls (water)</span>
can be chained to constitute an acceptable scenario, but the joint part is
not the same string.
Note that the two phrases are not simply paraphrases;
temperatures may be rising but remain cold,
or they may be decreasing even though they remain high.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">What characterizes two phrases that can be the
joint part of acceptable scenarios?
Although we have no definite
answer yet, we <em class="ltx_emph">name</em> it the <em class="ltx_emph">causal-compatibility</em> of two
phrases and provide its preliminary characterization
based on the excitation polarity.
Remember that
excitatory templates like
<span class="ltx_text ltx_font_italic">cause X</span> entail that <span class="ltx_text ltx_font_italic">X</span>’s function or effect
is activated,
but inhibitory templates like <span class="ltx_text ltx_font_italic">lower X</span> entail that it is
suppressed
(Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
Two
phrases are <em class="ltx_emph">causally-compatible</em> if they mention
the same entity (typically described by a noun) that is predicated by
the templates of the <em class="ltx_emph">same excitation polarity</em>.
Indeed, both <span class="ltx_text ltx_font_italic">X rise</span> and <span class="ltx_text ltx_font_italic">X are high</span> are excitatory
and hence <span class="ltx_text ltx_font_italic">sea temperatures are high</span>
and <span class="ltx_text ltx_font_italic">sea temperatures rise</span> are causally-compatible.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup>
Using other knowledge like verb entailment
<cite class="ltx_cite">[<a href="#bib.bib32" title="Large-scale verb entailment acquisition from the web" class="ltx_ref">11</a>]</cite>
can be helpful too, which is further future work.</span></span></span></p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">Scenarios (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m1" class="ltx_Math" alttext="sc" display="inline"><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow></math>s) generated by chaining causally-compatible phrase pairs
are scored by <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m2" class="ltx_Math" alttext="Score(sc)" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow></math>, which embodies our assumption that an acceptable
scenario consists of plausible event causality pairs:</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S4.Ex1" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.Ex1.m1" class="ltx_Math" alttext="\displaystyle Score(sc)=\prod_{cs\in CAUS(sc)}CScore(cs)" display="inline"><mrow><mrow><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><munder><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mrow><mi>c</mi><mo>⁢</mo><mi>s</mi></mrow><mo>∈</mo><mrow><mi>C</mi><mo>⁢</mo><mi>A</mi><mo>⁢</mo><mi>U</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow></mrow></munder></mstyle><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>c</mi><mo>⁢</mo><mi>s</mi></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m3" class="ltx_Math" alttext="CAUS(sc)" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>A</mi><mo>⁢</mo><mi>U</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow></math> is a set of event causality pairs that constitutes
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m4" class="ltx_Math" alttext="sc" display="inline"><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow></math> and
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m5" class="ltx_Math" alttext="cs" display="inline"><mrow><mi>c</mi><mo>⁢</mo><mi>s</mi></mrow></math> is a member of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m6" class="ltx_Math" alttext="CAUS(sc)" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>A</mi><mo>⁢</mo><mi>U</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>s</mi><mo>⁢</mo><mi>c</mi></mrow><mo>)</mo></mrow></mrow></math>.
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m7" class="ltx_Math" alttext="CScore(cs)" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>c</mi><mo>⁢</mo><mi>s</mi></mrow><mo>)</mo></mrow></mrow></math>, which is <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m8" class="ltx_Math" alttext="cs" display="inline"><mrow><mi>c</mi><mo>⁢</mo><mi>s</mi></mrow></math>’s score, was described in
Section <a href="#S3.SS3" title="3.3 Event Causality Scoring ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">Our method optionally applies the following two
filters to scenarios for better precision:
An <span class="ltx_text ltx_font_bold">original sentence filter</span> removes a scenario if
two event causality pairs that are chained in it
are extracted from original sentences between which no word overlap
exists other than words constituting causality pairs.
In this case, the two event causality pairs tend to be about different
topics and constitute an incoherent scenario.
A <span class="ltx_text ltx_font_bold">common argument filter</span> removes a scenario if a
joint part consists of two templates that share no argument in
our <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m1" class="ltx_Math" alttext="\langle" display="inline"><mo>⟨</mo></math>argument, template<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m2" class="ltx_Math" alttext="\rangle" display="inline"><mo>⟩</mo></math> database,
which is compiled from the syntactic dependency data between arguments
and templates
extracted from our web corpus.
Such a scenario tends to be incoherent too.</p>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Experiments </h2>

<div id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.1 </span>Event Causality Extraction
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p class="ltx_p">Next we describe our experiments on event causality extraction
and show
<span class="ltx_text ltx_font_bold">(a)</span> that most of our features are effective
and
<span class="ltx_text ltx_font_bold">(b)</span> that our method outperforms the baselines
based on state-of-the-art methods
<cite class="ltx_cite">[<a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">8</a>, <a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">12</a>]</cite>.
Our method achieved 70% precision at 13%
recall;
we can extract about 69,700 event causality
pairs with 70% precision, as described below.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p class="ltx_p">For the <span class="ltx_text ltx_font_bold">test data</span>, we randomly sampled
23,650 examples of
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.p2.m1" class="ltx_Math" alttext="\langle" display="inline"><mo>⟨</mo></math>event causality candidate, original sentence<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.p2.m2" class="ltx_Math" alttext="\rangle" display="inline"><mo>⟩</mo></math>
among which 3,645 were positive
from 2,451,254 event causality candidates
extracted from our web corpus
(Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
For the <span class="ltx_text ltx_font_bold">development data</span>, we identically collected 11,711 examples among which
1,898 were positive.
These datasets were annotated by three annotators (not the authors),
who annotated the event causality candidates without looking at the original
sentences.
The final label
was determined by majority vote.
The <span class="ltx_text ltx_font_bold">training data</span> were created by the annotators through
our preliminary experiments and consists of
112,110 among which
9,657 were positive.
The Kappa <cite class="ltx_cite">[<a href="#bib.bib24" title="Measuring nominal scale agreement among many raters" class="ltx_ref">9</a>]</cite> of their judgments was
0.67 (substantial agreement <cite class="ltx_cite">[<a href="#bib.bib25" title="The measurement of observer agreement for categorical data" class="ltx_ref">16</a>]</cite>).
These three datasets have no overlap in terms of
phrase pairs.
About nine man-months were required to prepare the data.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p class="ltx_p">Our evaluation is based on <em class="ltx_emph">average precision</em>;<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup>
It is obtained by computing the precision for each point in the
ranked list where we find a positive sample and averaging all the
precision figures <cite class="ltx_cite">[<a href="#bib.bib4" title="Foundations of statistical natural language processing" class="ltx_ref">18</a>]</cite>.
</span></span></span>
we believe that it is important to <em class="ltx_emph">rank</em> the plausible
event causality candidates higher.</p>
</div>
<div id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.1.1 </span>Ablation Tests
</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p">We evaluated the features of our method by ablation tests.
Table <a href="#S5.T3" title="Table 3 ‣ 5.1.1 Ablation Tests ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the results
of removing the semantic relation, the context, and the association
features from our method.</p>
</div>
<div id="S5.T3" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:276.0pt;height:122.222222222222px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.5pt,-11.0pt) scale(.7999,.7999) ;-webkit-transform:translate(-34.5pt,-11.0pt) scale(.7999,.7999) ;-ms-transform:translate(-34.5pt,-11.0pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Method</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Ave.
prec. (%)</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Proposed</th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">46.27</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">w/o Context features</th>
<td class="ltx_td ltx_align_right">45.68</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">w/o Association features</th>
<td class="ltx_td ltx_align_right">45.66</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">w/o Semantic relation features</th>
<td class="ltx_td ltx_align_right">44.44</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">Base features only</th>
<td class="ltx_td ltx_align_right ltx_border_b">41.29</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Ablation tests.</div>
</div>
<div id="S5.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p">All the feature types are effective and
contribute to the performance gain that was about 5% higher than the
<span class="ltx_text ltx_font_bold">Base features only</span>.
<span class="ltx_text ltx_font_bold">Proposed</span> achieved 70% precision at 13%
recall.
We then estimated that, with the precision rate,
we can extract 69,700
event causality pairs from the 2,451,254 event causality
candidates, among which the estimated number of positive
examples is 377,794.</p>
</div>
<div id="S5.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p">Next we examined whether the semantic relations that do not seem directly
relevant to causality like <span class="ltx_text ltx_font_smallcaps">Material</span>
are effective.
Table <a href="#S5.T4" title="Table 4 ‣ 5.1.1 Ablation Tests ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows that</p>
</div>
<div id="S5.T4" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:318.0pt;height:102.222222222222px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-39.8pt,-9.2pt) scale(.7999,.7999) ;-webkit-transform:translate(-39.8pt,-9.2pt) scale(.7999,.7999) ;-ms-transform:translate(-39.8pt,-9.2pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Semantic relations</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Ave.
prec. (%)</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">All semantic relations (Proposed)</th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">46.27</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_smallcaps">Causation</span></th>
<td class="ltx_td ltx_align_right">45.86</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_smallcaps">Causation</span> and <span class="ltx_text ltx_font_smallcaps">Prevention</span></th>
<td class="ltx_td ltx_align_right">45.78</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">None (w/o Semantic relation features)</th>
<td class="ltx_td ltx_align_right ltx_border_b">44.44</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Ablation tests on semantic relations.</div>
</div>
<div id="S5.SS1.SSS1.p4" class="ltx_para">
<p class="ltx_p">the performance degraded (46.27 <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS1.p4.m1" class="ltx_Math" alttext="\to" display="inline"><mo>→</mo></math> 45.86)
when we only used the <span class="ltx_text ltx_font_smallcaps">Causation</span>
binary patterns and their entailing and entailed patterns
compared to <span class="ltx_text ltx_font_bold">Proposed</span>.
Even when adding the <span class="ltx_text ltx_font_smallcaps">Prevention</span>
(“negative <span class="ltx_text ltx_font_smallcaps">Causation</span>”) patterns and their entailing and
entailed patterns, the performance was still slightly worse than
<span class="ltx_text ltx_font_bold">Proposed</span>.
The performance was even worse when using no semantic relation
(“None” in Table <a href="#S5.T4" title="Table 4 ‣ 5.1.1 Ablation Tests ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>).
Consequently we conclude that not only semantic relations directly
relevant to causality like <span class="ltx_text ltx_font_smallcaps">Causation</span> but also those
that seem to lack direct relevance to causality like
<span class="ltx_text ltx_font_smallcaps">Material</span> are somewhat effective.</p>
</div>
<div id="S5.SS1.SSS1.p5" class="ltx_para">
<p class="ltx_p">Finally, Table <a href="#S5.T5" title="Table 5 ‣ 5.1.1 Ablation Tests ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the performance drop by
removing the Wikipedia-, definition-, web-, and CEA-based features.</p>
</div>
<div id="S5.T5" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:270.0pt;height:122.222222222222px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-33.8pt,-11.0pt) scale(.7999,.7999) ;-webkit-transform:translate(-33.8pt,-11.0pt) scale(.7999,.7999) ;-ms-transform:translate(-33.8pt,-11.0pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Method</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Ave.
prec. (%)</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">w/o Wikipedia-based features</th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">46.52</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">Proposed</th>
<td class="ltx_td ltx_align_right">46.27</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">w/o definition-based features</th>
<td class="ltx_td ltx_align_right">46.21</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">w/o Web-based features</th>
<td class="ltx_td ltx_align_right">46.15</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">w/o CEA-based features</th>
<td class="ltx_td ltx_align_right ltx_border_b">45.80</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Ablation tests on association features.</div>
</div>
<div id="S5.SS1.SSS1.p6" class="ltx_para">
<p class="ltx_p">The CEA-based features were the most effective, while
the Wikipedia-based ones slightly degraded the performance.</p>
</div>
</div>
<div id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">5.1.2 </span>Comparison to Baseline Methods
</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p">We compared our method and two baselines based on
<cite class="ltx_cite">Do<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib16" title="Minimally supervised event causality identification" class="ltx_ref">2011</a>)</cite>:
<span class="ltx_text ltx_font_bold">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p1.m1" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>n</mi><mo mathvariant="bold">⁢</mo><mi>s</mi></mrow></msub></math></span> is an unsupervised method that uses CEA to
rank event causality candidates, and
<span class="ltx_text ltx_font_bold">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p1.m2" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span> is a supervised method using SVM and the CEA
features, whose ranking is based on the SVM scores.
The baselines are not complete implementations of Do et al.’s method
which uses discourse relations identified based
on <cite class="ltx_cite">Lin<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib5" title="A pdtb-styled end-to-end discourse parser" class="ltx_ref">2010</a>)</cite> and exploits them with CEA within an
ILP framework.
Nonetheless, we believe that this comparison is informative
since CEA can be seen as the main component;
they achieved a F1 of 41.7% for extracting causal event relations, but
with only CEA they still achieved 38.6%.</p>
</div>
<div id="S5.SS1.SSS2.p2" class="ltx_para">
<p class="ltx_p">Table <a href="#S5.T6" title="Table 6 ‣ 5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the average precision of
the compared methods.</p>
</div>
<div id="S5.T6" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:168.0pt;height:104.027777777778px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-21.0pt,-9.4pt) scale(.7999,.7999) ;-webkit-transform:translate(-21.0pt,-9.4pt) scale(.7999,.7999) ;-ms-transform:translate(-21.0pt,-9.4pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Method</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Ave.
prec. (%)</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Proposed</th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">46.27</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">Proposed-CEA</th>
<td class="ltx_td ltx_align_right">45.80</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T6.m1" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo>⁢</mo><mi>u</mi><mo>⁢</mo><mi>p</mi></mrow></msub></math></th>
<td class="ltx_td ltx_align_right">21.77</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T6.m2" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></msub></math></th>
<td class="ltx_td ltx_align_right ltx_border_b">16.57</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Average precision of our proposed methods and baselines using CEA.</div>
</div>
<div id="S5.SS1.SSS2.p3" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed</span> is our proposed method.
<span class="ltx_text ltx_font_bold">Proposed-CEA</span> is <span class="ltx_text ltx_font_bold">Proposed</span> without the CEA-features
and shows their contribution.
<span class="ltx_text ltx_font_bold">Proposed</span> is the best and the CEA features
slightly contribute to the performance, as <span class="ltx_text ltx_font_bold">Proposed-CEA</span>
indicates.
We observed that <span class="ltx_text ltx_font_bold">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p3.m1" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span> and <span class="ltx_text ltx_font_bold">CEA<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p3.m2" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>n</mi><mo mathvariant="bold">⁢</mo><mi>s</mi></mrow></msub></math></span>
performed poorly and
tended to
favor event
causality candidates whose
phrase pairs were highly relevant to each other but described
the contrasts of events rather than event causality
(e.g. <span class="ltx_text ltx_font_italic">build a slow muscle</span> and <span class="ltx_text ltx_font_italic">build a fast muscle</span>)
probably because their main components are PMI values.
Figure <a href="#S5.F1" title="Figure 1 ‣ 5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows their
precision-recall curves.</p>
</div>
<div id="S5.F1" class="ltx_figure"><img src="P14-1093/image001.png" id="S5.F1.g1" class="ltx_graphics ltx_centering" width="227" height="160" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Precision-recall curves of proposed methods and baselines using
CEA.</div>
</div>
<div id="S5.SS1.SSS2.p4" class="ltx_para">
<p class="ltx_p">Next we compared our method with the baselines based on
<cite class="ltx_cite">Hashimoto<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">2012</a>)</cite>.
They developed an automatic excitation template
acquisition method
that assigns each template an <em class="ltx_emph">excitation value</em> in range <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m1" class="ltx_Math" alttext="[-1,1]" display="inline"><mrow><mo>[</mo><mrow><mrow><mo>-</mo><mn>1</mn></mrow><mo>,</mo><mn>1</mn></mrow><mo>]</mo></mrow></math>
that is positive if the template is excitatory and negative if it is
inhibitory.
They ranked event causality candidates by
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m2" class="ltx_Math" alttext="Cs(p_{1},p_{2})=|s_{1}|\times|s_{2}|" display="inline"><mrow><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>p</mi><mn>1</mn></msub><mo>,</mo><msub><mi>p</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mo fence="true">|</mo><msub><mi>s</mi><mn>1</mn></msub><mo fence="true">|</mo></mrow><mo>×</mo><mrow><mo fence="true">|</mo><msub><mi>s</mi><mn>2</mn></msub><mo fence="true">|</mo></mrow></mrow></mrow></math>, where
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m3" class="ltx_Math" alttext="p_{1}" display="inline"><msub><mi>p</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m4" class="ltx_Math" alttext="p_{2}" display="inline"><msub><mi>p</mi><mn>2</mn></msub></math> are the two phrases of event causality candidates, and
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m5" class="ltx_Math" alttext="|s_{1}|" display="inline"><mrow><mo fence="true">|</mo><msub><mi>s</mi><mn>1</mn></msub><mo fence="true">|</mo></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m6" class="ltx_Math" alttext="|s_{2}|" display="inline"><mrow><mo fence="true">|</mo><msub><mi>s</mi><mn>2</mn></msub><mo fence="true">|</mo></mrow></math> are the absolute excitation values
of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m7" class="ltx_Math" alttext="p_{1}" display="inline"><msub><mi>p</mi><mn>1</mn></msub></math>’s and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m8" class="ltx_Math" alttext="p_{2}" display="inline"><msub><mi>p</mi><mn>2</mn></msub></math>’s templates.
The baselines are as follows:
<span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m9" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>n</mi><mo mathvariant="bold">⁢</mo><mi>s</mi></mrow></msub></math></span> is an unsupervised method that uses <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m10" class="ltx_Math" alttext="Cs" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi></mrow></math>
for ranking, and
<span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m11" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span> is a supervised method using SVM with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m12" class="ltx_Math" alttext="Cs" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi></mrow></math>
as the only feature that uses SVM scores for ranking.
Note that some event causality candidates were not given excitation values for their templates,
since
some templates were acquired by manual
annotation without Hashimoto et al.’s method.
To favor the baselines for fairness,
the event causality candidates of the development and test data
were restricted to
those with excitation values.
Since <span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p4.m13" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span> performed slightly
better when using all of the
training data in our preliminary experiments, we used all of it.</p>
</div>
<div id="S5.SS1.SSS2.p5" class="ltx_para">
<p class="ltx_p">Table <a href="#S5.T7" title="Table 7 ‣ 5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows the average precision of
the compared methods.</p>
</div>
<div id="S5.T7" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:144.0pt;height:84.0277777777778px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-18.0pt,-7.6pt) scale(.7999,.7999) ;-webkit-transform:translate(-18.0pt,-7.6pt) scale(.7999,.7999) ;-ms-transform:translate(-18.0pt,-7.6pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Method</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Ave.
prec. (%)</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Proposed</th>
<td class="ltx_td ltx_align_right ltx_border_t"><span class="ltx_text ltx_font_bold">49.64</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T7.m1" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi></mrow></msub></math></th>
<td class="ltx_td ltx_align_right">30.38</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T7.m2" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo>⁢</mo><mi>u</mi><mo>⁢</mo><mi>p</mi></mrow></msub></math></th>
<td class="ltx_td ltx_align_right ltx_border_b">27.49</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Average precision of our proposed method and baselines using <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.T7.m4" class="ltx_Math" alttext="Cs" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi></mrow></math>.</div>
</div>
<div id="S5.SS1.SSS2.p6" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed</span> is our method.
Its average precision is different from that in
Table <a href="#S5.T6" title="Table 6 ‣ 5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> due to the difference in
test data described above.
<span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p6.m1" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>n</mi><mo mathvariant="bold">⁢</mo><mi>s</mi></mrow></msub></math></span> and <span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p6.m2" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span> did not perform well.
Many phrase pairs described two events that often happen in parallel but
are not event causality
(e.g. <span class="ltx_text ltx_font_italic">reduce the intake of energy</span> and
<span class="ltx_text ltx_font_italic">increase the energy consumption</span>)
in the highly ranked event causality candidates of <span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p6.m3" class="ltx_Math" alttext="{}_{uns}" display="inline"><msub><mi/><mrow><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>n</mi><mo mathvariant="bold">⁢</mo><mi>s</mi></mrow></msub></math></span>
and <span class="ltx_text ltx_font_bold">Cs<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p6.m4" class="ltx_Math" alttext="{}_{sup}" display="inline"><msub><mi/><mrow><mi>s</mi><mo mathvariant="bold">⁢</mo><mi>u</mi><mo mathvariant="bold">⁢</mo><mi>p</mi></mrow></msub></math></span>.
Figure <a href="#S5.F2" title="Figure 2 ‣ 5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows their precision-recall
curves.</p>
</div>
<div id="S5.F2" class="ltx_figure"><img src="P14-1093/image002.png" id="S5.F2.g1" class="ltx_graphics ltx_centering" width="217" height="151" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Precision-recall curves of proposed methods and baselines using
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.F2.m2" class="ltx_Math" alttext="Cs" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi></mrow></math>.</div>
</div>
<div id="S5.SS1.SSS2.p7" class="ltx_para">
<p class="ltx_p"><cite class="ltx_cite">Hashimoto<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib9" title="Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web" class="ltx_ref">2012</a>)</cite>
extracted 500,000 event causalities
with about 70% precision.
However, as described in Section <a href="#S1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
our event causality criteria are different;
since they regarded phrase pairs that were not
self-contained as event causality
(their annotators checked the original sentences of phrase
pairs to see if they were event causality),
their judgments tended to be more lenient than ours, which explains
the performance difference.</p>
</div>
<div id="S5.SS1.SSS2.p8" class="ltx_para">
<p class="ltx_p">In preliminary experiments, since our proposed method’s performance
degraded when <math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS1.SSS2.p8.m1" class="ltx_Math" alttext="Cs" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>s</mi></mrow></math> was incorporated, we did not use it in
our method.</p>
</div>
</div>
</div>
<div id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">5.2 </span>Future Scenario Generation
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p class="ltx_p">To show that our future scenario generation methods can generate many
acceptable scenarios with reasonable precision,
we experimentally
compared four methods: <span class="ltx_text ltx_font_bold">Proposed</span>, our scenario generation method
without the two filters,
<span class="ltx_text ltx_font_bold">Proposed+Orig</span>, our method with the original sentence filter,
<span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span>, our method with
the original sentence and common argument filters,
and <span class="ltx_text ltx_font_bold">Exact</span>, a method that chains event causality by exact
matching.</p>
</div>
<div id="S5.SS2.SSS2.P1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Beginning events</h5>

<div id="S5.SS2.SSS2.P1.p1" class="ltx_para">
<p class="ltx_p">As the beginning event of a scenario,
we extracted nouns that describe social problems
(<em class="ltx_emph">social problem nouns</em>, e.g. <span class="ltx_text ltx_font_italic">deforestation</span>) from
Wikipedia
to focus our evaluation on the ability to generate scenarios about them,
which is a realistic use-case of scenario generation.
We extracted 557 social problem nouns
and used the cause phrases of the event causality candidates
that consisted of one
of the social problem nouns as the scenario’s beginning event.</p>
</div>
</div>
<div id="S5.SS2.SSS2.P2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Event causality</h5>

<div id="S5.SS2.SSS2.P2.p1" class="ltx_para">
<p class="ltx_p">We applied our event causality extraction
method to 2,451,254 candidates
(Section <a href="#S3.SS1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>) and culled
the top 1,200,000 phrase pairs from them
(See Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:examples-of-event-causality</span> in the supplementary
notes for examples).
Some phrase pairs have the same noun pairs and the same template
polarity pairs
(e.g. <span class="ltx_text ltx_font_italic">omit toothbrushing<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P2.p1.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>get a cavity</span>
and <span class="ltx_text ltx_font_italic">neglect toothbrushing<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P2.p1.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>have a cavity</span>, where
<span class="ltx_text ltx_font_italic">omit X</span> and <span class="ltx_text ltx_font_italic">neglect X</span> are inhibitory and
<span class="ltx_text ltx_font_italic">get X</span> and <span class="ltx_text ltx_font_italic">have X</span> are excitatory).
We removed such phrase pairs except those with the highest
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P2.p1.m3" class="ltx_Math" alttext="CScore" display="inline"><mrow><mi>C</mi><mo>⁢</mo><mi>S</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi></mrow></math>,
and 960,561 phrase pairs remained,
from which we generated two- or three-step scenarios
that consisted of two or three phrase pairs.</p>
</div>
</div>
<div id="S5.SS2.SSS2.P3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation samples</h5>

<div id="S5.SS2.SSS2.P3.p1" class="ltx_para">
<p class="ltx_p">The numbers of two- and three-step scenarios generated by
<span class="ltx_text ltx_font_bold">Proposed</span> were 217,836 and 5,288,352,
while those of <span class="ltx_text ltx_font_bold">Exact</span> were 22,910 and 72,746.
We sampled 2,000 from <span class="ltx_text ltx_font_bold">Proposed</span>’s two- and three-step scenarios
and 1,000 from those of <span class="ltx_text ltx_font_bold">Exact</span>.
We applied the filters to the sampled scenarios of <span class="ltx_text ltx_font_bold">Proposed</span>,
and the results were regarded as the sample scenarios of
<span class="ltx_text ltx_font_bold">Proposed+Orig</span> and <span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span>.
Table <a href="#S5.T8" title="Table 8 ‣ Evaluation samples ‣ 5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the number and precision
of the samples.</p>
</div>
<div id="S5.T8" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:276.0pt;height:102.222222222222px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-34.5pt,-9.2pt) scale(.7999,.7999) ;-webkit-transform:translate(-34.5pt,-9.2pt) scale(.7999,.7999) ;-ms-transform:translate(-34.5pt,-9.2pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_r ltx_border_t"/>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Two-step</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Three-step</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span class="ltx_inline-block ltx_transformed_outer" style="width:37.5pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Exact</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t">1,000 (44.10)</td>
<td class="ltx_td ltx_align_right ltx_border_t">1,000 (23.50)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:60.0pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r">2,000 (32.25)</td>
<td class="ltx_td ltx_align_right">2,000 (12.55)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:97.5pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed+Orig</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r">995 (36.28)</td>
<td class="ltx_td ltx_align_right">602 (17.28)</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:135.0pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r">708 (38.70)</td>
<td class="ltx_td ltx_align_right ltx_border_b">339 (17.99)</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Number of scenario samples
and their precision (%) in parentheses.</div>
</div>
<div id="S5.SS2.SSS2.P3.p2" class="ltx_para">
<p class="ltx_p">Note that, for the diversity of the sampled scenarios,
our sampling proceeded as follows:
<span class="ltx_text ltx_font_bold">(i)</span> Randomly sample a beginning event phrase from
the generated scenarios.
<span class="ltx_text ltx_font_bold">(ii)</span> Randomly sample an effect phrase for the beginning event
phrase from the scenarios.
<span class="ltx_text ltx_font_bold">(iii)</span> Regarding the effect phrase as a cause phrase,
randomly sample an effect phrase for it,
and repeat (iii) up to the specified number of steps (2 or 3).
The samples were annotated by three annotators (not the authors), who
were instructed to regard a sample as acceptable if
each event causality that constitutes it is plausible and
the sample as a whole constitutes a single coherent story.
Final judgment was made by majority vote.
Fleiss’ kappa of their judgments was
0.53 (moderate agreement), which is lower than
the kappa for the causality judgment.
This is probably because
scenario judgment requires careful consideration about various
possible futures for which individual annotators tend to draw different
conclusions.</p>
</div>
</div>
<div id="S5.SS2.SSS2.P4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Result 1</h5>

<div id="S5.T9" class="ltx_table">
<span class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:228.0pt;height:102.222222222222px;vertical-align:-1.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-28.5pt,-9.2pt) scale(.7999,.7999) ;-webkit-transform:translate(-28.5pt,-9.2pt) scale(.7999,.7999) ;-ms-transform:translate(-28.5pt,-9.2pt) scale(.7999,.7999) ;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_r ltx_border_t"/>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Two-step</span></th>
<th class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_bold">Three-step</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<span class="ltx_inline-block ltx_transformed_outer" style="width:37.5pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Exact</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r ltx_border_t">2,085</td>
<td class="ltx_td ltx_align_right ltx_border_t">1,237</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:60.0pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r">5,773</td>
<td class="ltx_td ltx_align_right">0</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:97.5pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed+Orig</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_r">4,107</td>
<td class="ltx_td ltx_align_right">0</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b ltx_border_r">
<span class="ltx_inline-block ltx_transformed_outer" style="width:135.0pt;height:12.5px;vertical-align:-2.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;-webkit-transform:translate(0.0pt,0.0pt) scale(1,1) ;-ms-transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span></p>
</span></span></th>
<td class="ltx_td ltx_align_right ltx_border_b ltx_border_r">3,293</td>
<td class="ltx_td ltx_align_right ltx_border_b">21,153</td></tr>
</tbody>
</table>
</span></span>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Estimated number of acceptable scenarios
with a 70% precision rate.</div>
</div>
<div id="S5.SS2.SSS2.P4.p1" class="ltx_para">
<p class="ltx_p">Table <a href="#S5.T9" title="Table 9 ‣ Result 1 ‣ 5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows
the estimated number of acceptable scenarios
generated with 70% precision.
The estimated number
is calculated as the product of the recall at 70% precision and
the number of acceptable scenarios in all the generated scenarios, which
is estimated by the annotated samples.
Figures <a href="#S5.F3" title="Figure 3 ‣ Result 1 ‣ 5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a></p>
</div>
<div id="S5.F3" class="ltx_figure"><img src="P14-1093/image003.png" id="S5.F3.g1" class="ltx_graphics ltx_centering" width="232" height="163" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Precision-scenario curves (2-step).</div>
</div>
<div id="S5.SS2.SSS2.P4.p2" class="ltx_para">
<p class="ltx_p">and
<a href="#S5.F4" title="Figure 4 ‣ Result 1 ‣ 5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a></p>
</div>
<div id="S5.F4" class="ltx_figure"><img src="P14-1093/image004.png" id="S5.F4.g1" class="ltx_graphics ltx_centering" width="232" height="163" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Precision-scenario curves (3-step).</div>
</div>
<div id="S5.SS2.SSS2.P4.p3" class="ltx_para">
<p class="ltx_p">show the <em class="ltx_emph">precision-scenario curves</em>
for the two- and three-step scenarios,
which illustrate how many acceptable scenarios can be
generated with what precision.
The curve is drawn in the same way as the precision-recall curve except
that the X-axis indicates the estimated number of acceptable scenarios.
At 70% precision,
all of the proposed methods
outperformed <span class="ltx_text ltx_font_bold">Exact</span> in the two-step setting,
and <span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span> outperformed <span class="ltx_text ltx_font_bold">Exact</span> in the
three-step setting.</p>
</div>
</div>
<div id="S5.SS2.SSS2.P5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Result 2</h5>

<div id="S5.SS2.SSS2.P5.p1" class="ltx_para">
<p class="ltx_p">To evaluate the top-ranked scenarios of
<span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span> in the three-step setting with
more samples, the annotators labeled 500 samples from the top 50,000 of
its output.
341 (68.20%)
were acceptable, and
the estimated number of acceptable scenarios at a precision
rate of 70% and 80% are 26,700 and 5,200
(See
Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:precision-scenario-curve</span> in the
supplementary notes).
The “<span class="ltx_text ltx_font_italic">terrorist operations</span>” scenario and
the “<span class="ltx_text ltx_font_italic">slash-and-burn agriculture</span>” scenario in
Section <a href="#S1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> were ranked 16,386th and 21,968th.
Next we examined how many of the top 50,000 scenarios were acceptable and
<em class="ltx_emph">non-trivial</em>, i.e., found in no page in our
input web corpus, using the 341 acceptable samples.
A scenario was regarded as
non-trivial if its nouns co-occur in no page of the corpus.
22 among the 341 samples
were non-trivial.
Accordingly,
we estimate that we can generate
2,200 (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P5.p1.m1" class="ltx_Math" alttext="\frac{50,000\times{}22}{500}" display="inline"><mfrac><mrow><mn>50</mn><mo>,</mo><mrow><mn>000</mn><mo>×</mo><mn>22</mn></mrow></mrow><mn>500</mn></mfrac></math>)
acceptable and non-trivial scenarios
from the top 50,000.
(See Section <span class="ltx_ref ltx_ref_self">LABEL:A-sec:examples-of-future-scenarios</span> in the
supplementary notes for examples of the generated scenarios.)</p>
</div>
</div>
<div id="S5.SS2.SSS2.P6" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Discussion</h5>

<div id="S5.SS2.SSS2.P6.p1" class="ltx_para">
<p class="ltx_p">Scenario
<span class="ltx_text ltx_font_italic">deforestation continues<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P6.p1.m1" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>global warming worsens<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P6.p1.m2" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>sea temperatures rise<math xmlns="http://www.w3.org/1998/Math/MathML" id="S5.SS2.SSS2.P6.p1.m3" class="ltx_Math" alttext="\to" display="inline"><mo mathvariant="normal">→</mo></math>vibrio parahaemolyticus fouls (water)</span>
was generated by <span class="ltx_text ltx_font_bold">Proposed+Orig+Comm</span>.
It is written in no page in our input web corpus, which
was crawled in 2007.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup>
The corpus has pages where
<span class="ltx_text ltx_font_italic">global warming</span>, <span class="ltx_text ltx_font_italic">sea temperatures</span>, and
<span class="ltx_text ltx_font_italic">vibrio parahaemolyticus</span> happen to co-occur.
But they are either
diaries where the three words appear separately in different
topics or lists of arbitrary words.
</span></span></span>
But we did find a paper <cite class="ltx_cite">Baker-Austin<span class="ltx_text ltx_bib_etal"> et al.</span> (<a href="#bib.bib3" title="Emerging vibrio risk at high latitudes in response to ocean warming" class="ltx_ref">2013</a>)</cite> that
observed the emerging vibrio risk in the Baltic sea due to global
warming.
In a sense, we “predicted” an event observed in 2013 from
documents written in 2007, although the scenario was ranked as low as
240,738th.</p>
</div>
</div>
</div>
</div>
<div id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">6 </span>Conclusion </h2>

<div id="S6.p1" class="ltx_para">
<p class="ltx_p">We proposed a supervised method for event causality extraction
that exploits semantic relation, context, and association features.
We also proposed methods for our new task, future scenario generation.
The methods chain event causality by causal-compatibility.
We generated non-trivial scenarios
with reasonable precision,
and “predicted” future events from web documents.
Increasing their rank is future work.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib19" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Abe, K. Inui and Y. Matsumoto</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Two-phrased event relation acquisition: coupling the relation-oriented and argument-oriented approaches</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1–8</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib15" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Akamine, D. Kawahara, Y. Kato, T. Nakagawa, Y. I. Leon-Suematsu, T. Kawada, K. Inui, S. Kurohashi and Y. Kidawara</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Organizing information on the web to support user judgments on information credibility</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 122–129</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p6" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib3" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Baker-Austin, J. A. Trinanes, N. G. H. Taylor, R. Hartnell, A. Siitonen and J. Martinez-Urtaza</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Emerging vibrio risk at high latitudes in response to ocean warming</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Nature Climate Change</span> <span class="ltx_text ltx_bib_volume">3</span>, <span class="ltx_text ltx_bib_pages"> pp. 73–77</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://www.nature.com/nclimate/journal/v3/n1/full/nclimate1628.html" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <span class="ltx_ref ltx_ref_self"><span class="ltx_text ltx_ref_title">Toward Future Scenario Generation:
Extracting Event Causality Exploiting Semantic Relation, Context, and
Association Features</span></span>,
<a href="#S1.p8" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S5.SS2.SSS2.P6.p1" title="Discussion ‣ 5.2 Future Scenario Generation ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a>.
</span></li>
<li id="bib.bib17" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">N. Chambers and D. Jurafsky</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Unsupervised learning of narrative event chains</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 789–797</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib18" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">N. Chambers and D. Jurafsky</span><span class="ltx_text ltx_bib_year">(2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Unsupervised learning of narrative schemas and their participants</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 602–610</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib34" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. De Saeger, K. Torisawa, J. Kazama, K. Kuroda and M. Murata</span><span class="ltx_text ltx_bib_year">(2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Large scale relation acquisition using class dependent patterns</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 764–769</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS1.p9" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>.
</span></li>
<li id="bib.bib35" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. De Saeger, K. Torisawa, M. Tsuchida, J. Kazama, C. Hashimoto, I. Yamada, J. Oh, I. Varga and Y. Yan</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Relation acquisition using word classes and partial patterns</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 825–835</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS1.p9" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>.
</span></li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Q. X. Do, Y. S. Chan and D. Roth</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Minimally supervised event causality identification</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 294–303</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p5" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S1.p6" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S3.SS2.SSS3.p1" title="3.2.3 Association Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>,
<a href="#S5.SS1.SSS2.p1" title="5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.2</span></a>,
<a href="#S5.SS1.p1" title="5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
</span></li>
<li id="bib.bib24" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. L. Fleiss</span><span class="ltx_text ltx_bib_year">(1971)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Measuring nominal scale agreement among many raters</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Psychological Bulletin</span> <span class="ltx_text ltx_bib_volume">76</span> (<span class="ltx_text ltx_bib_number">5</span>), <span class="ltx_text ltx_bib_pages"> pp. 378–382</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.SS1.p2" title="5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
</span></li>
<li id="bib.bib28" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Hashimoto, K. Torisawa, S. De Saeger, J. Kazama and S. Kurohashi</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Extracting paraphrases from definition sentences on the web</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1087–1097</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS3.p2" title="3.2.3 Association Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>.
</span></li>
<li id="bib.bib32" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Hashimoto, K. Torisawa, K. Kuroda, M. Murata and J. Kazama</span><span class="ltx_text ltx_bib_year">(2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Large-scale verb entailment acquisition from the web</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1172–1181</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p2" title="4 Future Scenario Generation Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span></li>
<li id="bib.bib9" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Hashimoto, K. Torisawa, S. D. Saeger, J. Oh and J. Kazama</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Excitatory or inhibitory: a new semantic orientation extracts contradiction and causality from the web</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 619–630</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p6" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S1.p7" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S1.p8" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S3.SS1.SSS0.P1.p1" title="Excitation ‣ 3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>,
<a href="#S5.SS1.SSS2.p4" title="5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.2</span></a>,
<a href="#S5.SS1.SSS2.p7" title="5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.2</span></a>,
<a href="#S5.SS1.p1" title="5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
</span></li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Kazama and K. Torisawa</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 407–415</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS1.p9" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>,
<a href="#S3.SS2.SSS4.p1" title="3.2.4 Base Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.4</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Kloetzer, S. D. Saeger, K. Torisawa, C. Hashimoto, J. Oh and K. Ohtake</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Two-stage method for large-scale acquisition of contradiction pattern pairs using entailment</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 693–703</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS1.p9" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>.
</span></li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Kloetzer, K. Torisawa, S. D. Saeger, M. Sano, C. Hashimoto and J. Gotoh</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Large-scale acquisition of entailment pattern pairs</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://kansai.ipsj.or.jp/2013sibutaikai_kaisai/" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.SSS1.p9" title="3.2.1 Semantic Relation Features ‣ 3.2 Features for Event Causality Classifier ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>.
</span></li>
<li id="bib.bib25" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. R. Landis and G. G. Koch</span><span class="ltx_text ltx_bib_year">(1977)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The measurement of observer agreement for categorical data</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Biometrics</span> <span class="ltx_text ltx_bib_volume">33</span> (<span class="ltx_text ltx_bib_number">1</span>), <span class="ltx_text ltx_bib_pages"> pp. 159–174</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.SS1.p2" title="5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
</span></li>
<li id="bib.bib5" class="ltx_bibitem ltx_bib_report"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Z. Lin, H. T. Ng and M. Kan</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A pdtb-styled end-to-end discourse parser</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Technical report</span>
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">School of Computing, National University of Singapore</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.SS1.SSS2.p1" title="5.1.2 Comparison to Baseline Methods ‣ 5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1.2</span></a>.
</span></li>
<li id="bib.bib4" class="ltx_bibitem ltx_bib_book"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Manning and H. Schütze</span><span class="ltx_text ltx_bib_year">(1999)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Foundations of statistical natural language processing</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">MIT Press</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S5.SS1.p3" title="5.1 Event Causality Extraction ‣ 5 Experiments ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
</span></li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Oh, K. Torisawa, C. Hashimoto, M. Sano, S. D. Saeger and K. Ohtake</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Why-question answering using intra- and inter-sentential causal relations</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1733–1743</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S3.SS1.SSS0.P1.p1" title="Excitation ‣ 3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
<li id="bib.bib12" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Radinsky, S. Davidovich and S. Markovitch</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Learning causality for news events prediction</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 909–918</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>,
<a href="#S2.p2" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib13" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Radinsky and E. Horvitz</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Mining the web to predict future events</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 255–264</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p2" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib29" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Riaz and R. Girju</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Another look at causality: discovering scenario-specific contingency relationships with no supervision</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 361–368</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib14" class="ltx_bibitem ltx_bib_book"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Schwartz</span><span class="ltx_text ltx_bib_year">(1991)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The art of the long view</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">Doubleday</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib31" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Takamura, T. Inui and M. Okumura</span><span class="ltx_text ltx_bib_year">(2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Extracting semantic orientation of words using spin model</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 133–140</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.SSS0.P1.p1" title="Excitation ‣ 3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
<li id="bib.bib36" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Tanaka, S. De Saeger, K. Ohtake, C. Hashimoto, M. Hijiya, H. Fujii and K. Torisawa</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">WISDOM2013: a large-scale web information analysis system</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 45–48</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Tanaka, N. Okazaki and M. Ishizuka</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Acquiring and generalizing causal inference rules from deverbal noun constructions</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1209–1218</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib33" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Torisawa, S. de Saeger, J. Kazama, A. Sumida, D. Noguchi, Y. Kakizawa, M. Murata, K. Kuroda and I. Yamada</span><span class="ltx_text ltx_bib_year">(2010)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Organizing the web’s information explosion to discover unknown unknowns</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">New Generation Computing (Special Issue on Information Explosion)</span> <span class="ltx_text ltx_bib_volume">28</span> (<span class="ltx_text ltx_bib_number">3</span>), <span class="ltx_text ltx_bib_pages"> pp. 217–236</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib21" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Torisawa</span><span class="ltx_text ltx_bib_year">(2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Acquiring inference rules with temporal constraints by using japanese coordinated sentences and noun-verb co-occurrences</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 57–64</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib27" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Tsuchida, K. Torisawa, S. D. Saeger, J. H. Oh, J. Kazama, C. Hashimoto and H. Ohwada</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Toward finding semantic relations not written in a single sentence: an inference method using auto-discovered rules</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 902–910</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p3" title="2 Related Work ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
</span></li>
<li id="bib.bib30" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">N. Yoshinaga and M. Kitsuregawa</span><span class="ltx_text ltx_bib_year">(2009)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Polynomial to linear: efficient classification with conjunctive features</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 542–1551</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.p1" title="3.1 Event Causality Candidate Extraction ‣ 3 Event Causality Extraction Method ‣ Toward Future Scenario Generation:&#10;Extracting Event Causality Exploiting Semantic Relation, Context, and&#10;Association Features" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun 10 18:25:22 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
