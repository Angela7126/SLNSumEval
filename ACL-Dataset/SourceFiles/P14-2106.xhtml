<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>On WordNet Semantic Classes and Dependency Parsing</title>
<!--Generated on Wed Jun 11 18:18:39 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">On WordNet Semantic Classes and Dependency Parsing</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kepa Bengoetxea†, Eneko Agirre†, Joakim Nivre‡, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold">Yue Zhang*, Koldo Gojenola†
<br class="ltx_break"/></span>†University of the Basque Country UPV/EHU / IXA NLP Group 
<br class="ltx_break"/>‡Uppsala University / Department of Linguistics and Philology 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="\ast" display="inline"><mo>∗</mo></math> Singapore University of Technology and Design 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">kepa.bengoetxea@ehu.es, e.agirre@ehu.es, </span> 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">joakim.nivre@lingfil.uu.se, yue_zhang@sutd.edu.sg, </span> 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">koldo.gojenola@ehu.es</span> 
<br class="ltx_break"/>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">This paper presents experiments with WordNet semantic classes to improve dependency parsing. We study
the effect of semantic classes in three dependency parsers, using two types of constituency-to-dependency conversions of the English Penn Treebank. Overall, we can say that the improvements are small and not significant using automatic POS tags, contrary to previously published results using gold POS tags <cite class="ltx_cite">[]</cite>.
In addition, we explore parser combinations, showing that the semantically enhanced parsers yield a small significant gain only on the more semantically oriented LTH treebank conversion.</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">This work presents a set of experiments to investigate the use of lexical semantic information in dependency parsing of English. Whether semantics improve parsing is one interesting research topic
both on parsing and lexical semantics.
Broadly speaking, we can classify the methods to incorporate semantic information into parsers in two: systems using static lexical semantic repositories, such as WordNet or similar ontologies <cite class="ltx_cite">[]</cite>, and systems using dynamic semantic clusters automatically acquired from corpora <cite class="ltx_cite">[]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Our main objective will be to determine whether static semantic knowledge can help parsing. We will apply different types of semantic
information to three dependency parsers. Specifically, we will test the following questions:</p>
</div>
<div id="S1.p3" class="ltx_para">
<ul id="I1" class="ltx_itemize">
<li id="I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i1.p1" class="ltx_para">
<p class="ltx_p">Does semantic information in WordNet help dependency parsing? <cite class="ltx_cite"/> found improvements in dependency parsing using MaltParser on gold POS tags. In this work, we will investigate the effect of semantic information using predicted POS tags.</p>
</div></li>
<li id="I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i2.p1" class="ltx_para">
<p class="ltx_p">Is the type of semantic information related to the type of parser? We will test
three different parsers representative of successful paradigms in dependency parsing.</p>
</div></li>
<li id="I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i3.p1" class="ltx_para">
<p class="ltx_p">How does the semantic information relate to the style of dependency annotation? Most experiments for English were evaluated on the Penn2Malt conversion of the constituency-based Penn Treebank. We will also examine the LTH conversion, with richer structure and an extended set of dependency labels.</p>
</div></li>
<li id="I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i4.p1" class="ltx_para">
<p class="ltx_p">How does WordNet compare to automatically obtained information? For the sake of comparison, we will also perform the experiments using syntactic/semantic clusters automatically acquired from corpora.</p>
</div></li>
<li id="I1.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i5.p1" class="ltx_para">
<p class="ltx_p">Does parser combination benefit from semantic information?
Different parsers can use semantic information in diverse ways.
For example, while MaltParser can use the semantic information in local contexts, MST can incorporate them in global contexts. We will run parser combination experiments with and without semantic information, to determine whether it is useful in the combined parsers.</p>
</div></li>
</ul>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">After introducing related work in section <a href="#S2" title="2 Related work ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, section <a href="#S3" title="3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>
describes the treebank conversions, parsers and semantic features. Section <a href="#S4" title="4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents
the results and section <a href="#S5" title="5 Conclusions ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> draws the main conclusions.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Broadly speaking, we can classify the attempts to add external knowledge to a parser in two sets: using large semantic repositories such as WordNet and approaches that use information automatically acquired from corpora.
In the first group, <cite class="ltx_cite"/> trained two state-of-the-art constituency-based statistical parsers <cite class="ltx_cite">[]</cite> on semantically-enriched input, substituting content words with their semantic
classes, trying to overcome the limitations of lexicalized approaches to parsing <cite class="ltx_cite">[]</cite> where related words, like <em class="ltx_emph">scissors</em> and <em class="ltx_emph">knife</em>, cannot be generalized.
The results showed a signiï¬cant improvement, giving the first results over both WordNet and the Penn Treebank (PTB) to show that semantics helps parsing. Later, <cite class="ltx_cite"/> successfully introduced WordNet classes in a dependency parser, obtaining improvements on the full PTB using gold POS tags, trying different combinations of semantic classes.
<cite class="ltx_cite"/> investigate the addition of semantic
annotations in the form of word sense hypernyms,
in HPSG parse ranking,
reducing error rate in dependency F-score
by 1%, while some methods
produce substantial decreases in performance.
<cite class="ltx_cite"/>
showed that fully disambiguated sense-based features smoothed
using ontological information are effective for parse selection.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">On the second group, <cite class="ltx_cite"/> presented a semisupervised method for training dependency parsers, introducing features that incorporate word clusters automatically acquired from a large unannotated corpus. The clusters include strongly semantic associations like {apple, pear} or {Apple, IBM} and also syntactic clusters like {of, in}. They demonstrated its effectiveness in dependency parsing experiments on the PTB and the Prague Dependency Treebank.
<cite class="ltx_cite"/>, <cite class="ltx_cite"/> and <cite class="ltx_cite"/> also experiment with the same cluster method.
Recently, <cite class="ltx_cite"/> tested the incorporation of
cluster features from unlabeled corpora in a multilingual setting, giving an algorithm for inducing cross-lingual clusters.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Experimental Framework</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">In this section we will briefly describe the PTB-based datasets (subsection <a href="#S3.SS1" title="3.1 Treebank conversions ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>), followed by the data-driven parsers used for the experiments (subsection <a href="#S3.SS2" title="3.2 Parsers ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>). Finally, we will describe the different types of semantic representation that were used.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Treebank conversions</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">Penn2Malt</em><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>http://w3.msi.vxu.se/ nivre/research/Penn2Malt.html</span></span></span> performs a simple and direct conversion from the constituency-based PTB to a dependency treebank. It obtains projective trees and has been used in several works, which allows us to compare our results with related experiments <cite class="ltx_cite">[]</cite>. We extracted dependencies using standard head rules <cite class="ltx_cite">[]</cite>, and a reduced set of 12 general dependency tags.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">LTH</em><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>http://nlp.cs.lth.se/software/treebank_converter</span></span></span> <cite class="ltx_cite">[]</cite> presents a conversion better suited for semantic processing, with a richer structure and a more fine-grained set of dependency labels (42 different dependency labels), including links
to handle long-distance phenomena, giving a 6.17% of nonprojective sentences. The results from parsing the LTH output are lower than those for Penn2Malt conversions.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Parsers</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">We have made use of three parsers representative of successful paradigms in dependency parsing.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">MaltParser</em> <cite class="ltx_cite">[]</cite> is a deterministic transition-based dependency parser
that obtains a dependency tree in linear-time in a single pass over the input using a stack of partially analyzed items and the remaining input sequence,
by means of history-based feature models.
We added two features that inspect the semantic feature at the top of the stack and the next input token.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">MST</em><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>http://mstparser.sourceforge.net</span></span></span> represents global, exhaustive graph-based parsing <cite class="ltx_cite">[]</cite> that finds the highest scoring directed spanning tree in a graph.
The learning procedure is global since model parameters are set relative to classifying the entire dependency graph,
in contrast to the local but richer contexts used by transition-based parsers.
The system can be trained using first or second order models.
The second order projective algorithm performed best on both conversions, and we used it in the rest of the evaluations.
We modified the system in order to add semantic features, combining them with wordforms and POS tags, on the parent and child nodes of each arc.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">ZPar</em><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>www.sourceforge.net/projects/zpar</span></span></span> <cite class="ltx_cite">[]</cite> performs transition-based dependency parsing with a stack of partial analysis and a queue of remaining inputs. In contrast to MaltParser (local model and greedy deterministic search) ZPar applies global discriminative learning and beam search.
We extend the feature set of ZPar to include semantic features. Each set of semantic information is represented by two atomic feature templates, associated with the top of the stack and the head of the queue, respectively.
ZPar was directly trained on the Penn2Malt conversion, while we applied the pseudo-projective transformation <cite class="ltx_cite">[]</cite> on LTH, in order to deal with non-projective arcs.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Semantic information</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">Our aim was to experiment with different types of WordNet-related semantic information. For comparison with automatically acquired information, we will also experiment with bit clusters.</p>
</div>
<div id="S3.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_rr ltx_border_t"/>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Base</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">WordNet</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">WordNet</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Clusters</span></th></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_rr"/>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">line</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">SF</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">SS</span></th>
<th class="ltx_td ltx_border_rr"/></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">Malt</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">88.46</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">88.49 (+0.03)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">88.42 (-0.04)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">88.59 (+0.13)</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">MST</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">90.55</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">90.70 (+0.15)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">90.47 (-0.08)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">90.88 (+0.33)‡</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">ZPar</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">91.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">91.65 (+0.13)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">91.70 (+0.18)†</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">91.74 (+0.22)</span></td></tr>
</tbody>
</table>
<br class="ltx_break ltx_centering"/>
<div class="ltx_caption ltx_centering ltx_font_script"><span class="ltx_tag ltx_tag_table">Table 1: </span> LAS results with several parsing algorithms, Penn2Malt conversion (†: p &lt;0.05, ‡: p &lt;0.005). In parenthesis, difference with baseline.</div>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">WordNet</em>. We will experiment with the semantic representations used in <cite class="ltx_cite"/> and <cite class="ltx_cite"/>, based on WordNet 2.1. WordNet is organized into sets of synonyms, called synsets (SS). Each synset in turn belongs to a unique semantic file (SF). There are a total of 45 SFs (1 for adverbs, 3 for adjectives, 15 for verbs, and 26 for nouns), based on syntactic and semantic categories. For example, noun SFs differentiate nouns denoting acts or actions, and nouns denoting animals, among others. We experiment with both full SSs and SFs as instances of fine-grained and coarse-grained semantic representation, respectively. As an example, <em class="ltx_emph">knife</em> in its tool sense is in the EDGE TOOL USED AS A CUTTING INSTRUMENT singleton synset, and also in the ARTIFACT SF along with thousands of words including <em class="ltx_emph">cutter</em>. These are the two extremes of semantic granularity in WordNet.
For each semantic representation, we need to determine the semantics of each occurrence of a target word. <cite class="ltx_cite"/> used i) gold-standard annotations from SemCor, a subset of the PTB, to give an upper bound performance of the semantic representation, ii) first sense, where all instances of a word were tagged with their most frequent sense, and iii) automatic sense ranking, predicting the most frequent sense for each word <cite class="ltx_cite">[]</cite>.
As we will make use of the full PTB, we only have access to the first sense information.</p>
</div>
<div id="S3.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_rr ltx_border_t"/>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Base</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">WordNet</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">WordNet</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Clusters</span></th></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_rr"/>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">line</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">SF</span></th>
<th class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">SS</span></th>
<th class="ltx_td ltx_border_rr"/></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">Malt</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">84.95</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">85.12 (+0.17)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">85.08 (+0.16)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">85.13 (+0.18)</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">MST</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">85.06</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">85.35 (+0.29)‡</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">84.99 (-0.07)</span></td>
<td class="ltx_td ltx_align_left ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">86.18 (+1.12)‡</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">ZPar</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">89.15</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">89.33 (+0.18)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">89.19 (+0.04)</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">89.17 (+0.02)</span></td></tr>
</tbody>
</table>
<br class="ltx_break ltx_centering"/>
<div class="ltx_caption ltx_centering ltx_font_script"><span class="ltx_tag ltx_tag_table">Table 2: </span> LAS results with several parsing algorithms in the LTH conversion (†: p &lt;0.05, ‡: p &lt;0.005). In parenthesis, difference with baseline.</div>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">Clusters</em>.
<cite class="ltx_cite"/> describe a semi-supervised approach that makes use of cluster
features induced from unlabeled data, providing significant performance improvements
for supervised dependency parsers
on the Penn Treebank
for English and the Prague Dependency Treebank for Czech. The process defines a hierarchical clustering of the words, which can be
represented as a binary tree where each node is associated to a bit-string, from the more general (root of the tree) to the more specific (leaves). Using prefixes of various lengths, it can
produce clusterings of different granularities. It can be seen as a representation of syntactic-semantic information acquired from corpora. They use short strings of 4-6 bits to represent parts of speech and the full strings for wordforms.</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Results</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">In all the experiments we employed a baseline feature set using
word forms and parts of speech, and an enriched feature set (WordNet or clusters).
We firstly tested the addition of each individual semantic feature to each parser, evaluating its contribution to the parser’s performance. For the combinations, instead of feature-engineering each parser with the wide array of different possibilities for features, as in <cite class="ltx_cite"/>, we adopted the simpler approach of combining the outputs of the individual parsers by voting <cite class="ltx_cite">[]</cite>. We will use Labeled Attachment Score (LAS) as our main evaluation criteria.
As in previous work, we exclude punctuation marks. For all the tests, we used a perceptron POS-tagger <cite class="ltx_cite">[]</cite>, trained on WSJ sections 2–21, to assign POS tags automatically to both the training (using 10-way jackknifing) and test data, obtaining a POS tagging accuracy of 97.32% on the test data. We will make use of Bikel’s randomized parsing evaluation comparator to test the statistical signiï¬cance of the results. In all of the experiments the parsers were trained on sections 2-21 of the PTB and evaluated on the development set (section 22). Finally, the best performing system was evaluated on the test set (section 23).</p>
</div>
<div id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.1 </span>Single Parsers</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">We run a series of experiments testing each individual semantic feature, also trying different
learning configurations for each one. Regarding the WordNet information, there were 2 different features to experiment with (SF and SS). For the bit clusters, there are different possibilities, depending on the number of bits used. For Malt and MST, all the different lengths of bit strings were used. Given the computational requirements and the previous results on Malt and MST, we only tested all bits in ZPar.
Tables <a href="#S3.T1" title="Table 1 ‣ 3.3 Semantic information ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S3.T2" title="Table 2 ‣ 3.3 Semantic information ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> show the results.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">Penn2Malt</em>. Table <a href="#S3.T1" title="Table 1 ‣ 3.3 Semantic information ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows that the only significant increase over the baseline is for ZPar with SS and for MST with clusters.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">LTH</em>. Looking at table <a href="#S3.T2" title="Table 2 ‣ 3.3 Semantic information ‣ 3 Experimental Framework ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we can say that the differences in baseline parser performance are accentuated when using the LTH treebank conversion, as ZPar clearly outperforms the other two parsers by more than 4 absolute points. We can see that SF helps all parsers, although it is only significant for MST. Bit clusters improve significantly MST, with the highest increase across the table.</p>
</div>
<div id="S4.T3" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Parsers</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">LAS</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">UAS</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">Best baseline (ZPar)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">91.52</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">92.57</span></td>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best single parser (ZPar + Clusters)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.74 (+0.22)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">92.63</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination (3 baseline parsers)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.90 (+0.38)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">93.01</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 SF extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">91.93 (+0.41)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_script">92.95</span></td>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 SS extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">91.87 (+0.35)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_script">92.92</span></td>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 cluster extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_script">91.90 (+0.38)</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_script">92.90</span></td>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/></tr>
</tbody>
</table>
<br class="ltx_break ltx_centering"/>
<div class="ltx_caption ltx_centering ltx_font_script"><span class="ltx_tag ltx_tag_table">Table 3: </span> Parser combinations on Penn2Malt.</div>
</div>
<div id="S4.T4" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">Parsers</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">LAS</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">UAS</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">Best baseline (ZPar)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">89.15</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">91.81</span></td>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best single parser (ZPar + SF)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.33 (+0.15)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">92.01</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination (3 baseline parsers)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.15 (+0.00)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.81</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 SF extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">89.56 (+0.41)‡</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_script">92.23</span></td>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 SS extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">89.43 (+0.28)</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_script">93.12</span></td>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_script">3 baselines + 3 cluster extensions</span></td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_script">89.52 (+0.37)†</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_script">92.19</span></td>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/></tr>
</tbody>
</table>
<br class="ltx_break ltx_centering"/>
<div class="ltx_caption ltx_centering ltx_font_script"><span class="ltx_tag ltx_tag_table">Table 4: </span> Parser combinations on LTH (†: p &lt;0.05, ‡: p &lt;0.005).</div>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p class="ltx_p">Overall, we see that the small improvements do not confirm the previous results on Penn2Malt, MaltParser and gold POS tags.
We can also conclude that automatically acquired clusters are specially effective with the MST parser in both treebank conversions, which suggests that the type of semantic information has a direct relation to the parsing algorithm.
Section <a href="#S4.SS3" title="4.3 Analysis ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a> will look at the details by each knowledge type.</p>
</div>
<div id="S4.T5" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_l ltx_border_rr ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">LAS on sentences</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold ltx_font_script">LAS on sentences</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr"><span class="ltx_text ltx_font_bold ltx_font_script">POS tags</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_script">Parser</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_script">LAS test set</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_script">without POS errors</span></td>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_bold ltx_font_script">with POS errors</span></td>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_script">Gold</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">ZPar</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">90.45</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">91.68</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_script">89.14</span></td>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/>
<td class="ltx_td ltx_border_tt"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Automatic</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">ZPar</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.15</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.62</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">86.51</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Automatic</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.56 (+0.41)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.90 (+0.28)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">87.06 (+0.55)</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_l ltx_border_rr"/>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">3 baselines + 3 SF extensions</span></td>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Automatic</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.43 (+0.28)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.95 (+0.33)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">86.75 (+0.24)</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_l ltx_border_rr"/>
<td class="ltx_td ltx_align_left ltx_border_r"><span class="ltx_text ltx_font_script">3 baselines + 3 SS extensions</span></td>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/>
<td class="ltx_td"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_script">Automatic</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">Best combination of 3 parsers:</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">89.52 (+0.37)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">91.92 (+0.30)</span></td>
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_script">86.96 (+0.45)</span></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_border_t"/></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_b ltx_border_l ltx_border_rr"/>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_script">3 baselines + 3 cluster extensions</span></td>
<td class="ltx_td ltx_border_b ltx_border_r"/>
<td class="ltx_td ltx_border_b ltx_border_r"/>
<td class="ltx_td ltx_border_b ltx_border_r"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/>
<td class="ltx_td ltx_border_b"/></tr>
</tbody>
</table>
<br class="ltx_break ltx_centering"/>
<div class="ltx_caption ltx_centering ltx_font_script"><span class="ltx_tag ltx_tag_table">Table 5: </span> Differences in LAS (LTH) for baseline and extended parsers with sentences having correct/incorrect POS tags (the parentheses show the difference w.r.t ZPar with automatic POS tags).</div>
</div>
</div>
<div id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.2 </span>Combinations</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p class="ltx_p">Subsection <a href="#S4.SS1" title="4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> presented the results of the base algorithms and their extensions based on semantic features. <cite class="ltx_cite"/> report improvements over the best single
parser when combining three transition-based models and one graph-based model. The same
technique was also used by the winning team of the CoNLL 2007 Shared Task <cite class="ltx_cite">[]</cite>, combining
six transition-based parsers.
We used MaltBlender<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>http://w3.msi.vxu.se/users/jni/blend/</span></span></span>, a tool for merging the output
of several dependency parsers, using the Chu-Liu/Edmonds directed MST algorithm.
After several tests we noticed that weighted voting by each parser’s labeled accuracy gave good
results, using it in the rest of the experiments. We trained different types of combination:</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<ul id="I2" class="ltx_itemize">
<li id="I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I2.i1.p1" class="ltx_para">
<p class="ltx_p">Base algorithms. This set includes the 3 baseline algorithms, MaltParser, MST, and ZPar.</p>
</div></li>
<li id="I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I2.i2.p1" class="ltx_para">
<p class="ltx_p">Extended parsers, adding semantic information to the baselines. We include the
three base algorithms and their semantic extensions (SF, SS, and clusters).
It is known <cite class="ltx_cite">[]</cite> that adding more parsers to an ensemble usually
improves accuracy, as long as they add to the diversity (and almost regardless of their accuracy level). So, for
the comparison to be fair, we will compare ensembles of 3 parsers, taken from sets of 6
parsers (3 baselines + 3 SF, SS, and cluster extensions, respectively).</p>
</div></li>
</ul>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p class="ltx_p">In each experiment, we took the best combination of individual parsers on the
development set for the final test. Tables <a href="#S4.T3" title="Table 3 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#S4.T4" title="Table 4 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> show the results.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">Penn2Malt</em>. Table <a href="#S4.T3" title="Table 3 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows that the combination of the baselines, without any semantic information,
considerably improves the best baseline. Adding semantics does not give a noticeable increase with respect to
combining the baselines.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p class="ltx_p"><em class="ltx_emph">LTH</em> (table <a href="#S4.T4" title="Table 4 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). Combining the 3 baselines does not give an improvement over the best
baseline, as ZPar clearly outperforms the other parsers. However, adding the semantic parsers gives
an increase with respect to the best single parser (ZPar + SF), which is small but significant for
SF and clusters.</p>
</div>
</div>
<div id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.3 </span>Analysis</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p">In this section we analyze the data trying to understand where and how semantic information helps most.
One of the obstacles of automatic parsers is the presence of incorrect POS tags due to automatic
tagging. For example, ZPar’s LAS score on the LTH conversion drops from 90.45% with gold POS tags
to 89.12% with automatic POS tags. We will examine the influence of each type of semantic information
on sentences that contain or not POS errors, and this will clarify whether the increments obtained when
using semantic information are useful for correcting the negative influence of POS errors or they are
orthogonal and constitute a source of new information independent of POS tags.
With this objective in mind, we analyzed the performance on the subset of the test corpus containing
the sentences which had POS errors (1,025 sentences and 27,300 tokens) and the subset where the
sentences had (automatically assigned) correct POS tags (1,391 sentences and 29,386 tokens).</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> presents the results of the best single parser on the LTH conversion (ZPar) with
gold and automatic POS tags in the first two rows. The LAS scores are particularized for sentences
that contain or not POS errors. The following three rows present the enhanced (combined) parsers
that make use of semantic information. As the combination of the three baseline parsers did not
give any improvement over the best single parser (ZPar), we can hypothesize that the gain coming
from the parser combinations comes mostly from the addition of semantic information.
Table <a href="#S4.T5" title="Table 5 ‣ 4.1 Single Parsers ‣ 4 Results ‣ On WordNet Semantic Classes and Dependency Parsing" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> suggests that the improvements coming from WordNet’s semantic file (SF) are
unevenly distributed between the sentences that contain POS errors and those that
do not (an increase of 0.28 for sentences without POS errors and 0.55 for those with errors). This
could mean that a big part of the information contained in SF helps to alleviate the errors
performed by the automatic POS tagger. On the other hand, the increments are more evenly
distributed for SS and clusters, and this can be due to the fact that the semantic
information is orthogonal to the POS, giving similar improvements for sentences that
contain or not POS errors. We independently tested this fact for the individual parsers. For
example, with MST and SF the gains almost doubled for sentences with incorrect
POS tags (+0.37 with respect to +0.21 for sentences with correct POS tags) while
the gains of adding clusters’ information for sentences without and with POS errors
were similar (0.91 and 1.33, repectively). This aspect deserves further
investigation, as the improvements seem to be related to both the type of semantic
information and the parsing algorithm.We did an initial exploration but it did not give any clear indication of the types
of improvements that could be expected using each parser and semantic data.</p>
</div>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">This work has tried to shed light on the contribution of semantic information to
dependency parsing. The experiments were thorough, testing two treebank conversions and three
parsing paradigms on automatically predicted POS tags. Compared to <cite class="ltx_cite">[]</cite>,
which used MaltParser on the LTH conversion and gold POS tags, our
results can be seen as a negative outcome, as the improvements are very small and non-significant in most of
the cases. For parser combination, WordNet semantic file information does give a small significant increment
in the more fine-grained LTH representation. In addition we show that the improvement of automatic clusters
is also weak. For the future, we think tdifferent parsers, eitherhat a more elaborate scheme is needed for word classes, requiring
to explore different levels of generalization in the WordNet (or alternative) hierarchies.</p>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">This research was supported by the the Basque Government (IT344-
10, S PE11UN114), the University of the
Basque Country (GIU09/19) and the Spanish
Ministry of Science and Innovation (MICINN,
TIN2010-20218).</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 18:18:39 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
