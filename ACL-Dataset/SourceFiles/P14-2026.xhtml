<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Dependency-based Pre-ordering for Chinese-English Machine Translation</title>
<!--Generated on Wed Jun 11 17:40:21 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Dependency-based Pre-ordering for Chinese-English Machine Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jingsheng Cai<math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math>   Masao Utiyama<math xmlns="http://www.w3.org/1998/Math/MathML" id="m2" class="ltx_Math" alttext="{}^{{\ddagger}}" display="inline"><msup><mi/><mo>‡</mo></msup></math>  Eiichiro Sumita<math xmlns="http://www.w3.org/1998/Math/MathML" id="m3" class="ltx_Math" alttext="{}^{{\ddagger}}" display="inline"><msup><mi/><mo>‡</mo></msup></math>  Yujie Zhang<math xmlns="http://www.w3.org/1998/Math/MathML" id="m4" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math>
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m5" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math>School of Computer and Information Technology, Beijing Jiaotong University 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m6" class="ltx_Math" alttext="{}^{{\ddagger}}" display="inline"><msup><mi/><mo>‡</mo></msup></math>National Institute of Information and Communications Technology 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">joycetsai99@gmail.com</span> 
<br class="ltx_break"/>{<span class="ltx_text ltx_font_typewriter">mutiyama, eiichiro.sumita</span>}<span class="ltx_text ltx_font_typewriter">@nict.go.jp</span> 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">yjzhang@bjtu.edu.cn</span> 
<br class="ltx_break"/>
</span><span class="ltx_author_notes"><span>  This work was done when the first author was on an internship in NICT.</span></span></span></div>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">In statistical machine translation (SMT), syntax-based pre-ordering of the source language is an effective method for dealing with language pairs where there are great differences in their respective word orders. This paper introduces a novel pre-ordering approach based on dependency parsing for Chinese-English SMT. We present a set of dependency-based pre-ordering rules which improved the BLEU score by 1.61 on the NIST 2006 evaluation data. We also investigate the accuracy of the rule set by conducting human evaluations.</p>
</div><span class="ltx_ERROR undefined">{CJK*}</span>
<div id="p1" class="ltx_para">
<p class="ltx_p">UTF8gbsn</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">SMT systems have difficulties translating between distant language pairs such as Chinese and English. The reason for this is that there are great differences in their word orders. Reordering therefore becomes a key issue in SMT systems between distant language pairs.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Previous work has shown that the approaches tackling the problem by introducing a pre-ordering procedure into phrase-based SMT (PBSMT) were effective. These pre-ordering approaches first parse the source language sentences to create parse trees. Then, syntactic reordering rules are applied to these parse trees with the goal of reordering the source language sentences into the word order of the target language. Syntax-based pre-ordering by employing constituent parsing have demonstrated effectiveness in many language pairs, such as English-French <cite class="ltx_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">2004</a>]</cite>, German-English <cite class="ltx_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">2005</a>]</cite>, Chinese-English <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>, <a href="#bib.bibx20" title="" class="ltx_ref">2008</a>]</cite>, and English-Japanese <cite class="ltx_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">2010</a>]</cite>. As a kind of constituent structure, HPSG <cite class="ltx_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">1994</a>]</cite> parsing-based pre-ordering showed improvements in SVO-SOV translations, such as English-Japanese <cite class="ltx_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">2010</a>, <a href="#bib.bibx17" title="" class="ltx_ref">2011</a>]</cite> and Chinese-Japanese <cite class="ltx_cite">[<a href="#bib.bibx6" title="" class="ltx_ref">2012</a>]</cite>. Since dependency parsing is more concise than constituent parsing in describing sentences, some research has used dependency parsing in pre-ordering approaches for language pairs such as Arabic-English <cite class="ltx_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">2007</a>]</cite>, and English-SOV languages <cite class="ltx_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">2009</a>, <a href="#bib.bibx9" title="" class="ltx_ref">2011</a>]</cite>. The pre-ordering rules can be made manually <cite class="ltx_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">2005</a>, <a href="#bib.bibx16" title="" class="ltx_ref">2007</a>, <a href="#bib.bibx6" title="" class="ltx_ref">2012</a>]</cite> or extracted automatically from a parallel corpus <cite class="ltx_cite">[<a href="#bib.bibx18" title="" class="ltx_ref">2004</a>, <a href="#bib.bibx7" title="" class="ltx_ref">2007</a>, <a href="#bib.bibx21" title="" class="ltx_ref">2007</a>, <a href="#bib.bibx17" title="" class="ltx_ref">2011</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">The purpose of this paper is to introduce a novel dependency-based pre-ordering approach through creating a pre-ordering rule set and applying it to the Chinese-English PBSMT system. Experiment results showed that our pre-ordering rule set improved the BLEU score on the NIST 2006 evaluation data by 1.61. Moreover, this rule set substantially decreased the total times of rule application about 60%, compared with a constituent-based approach (Wang et al., 2007). We also conducted human evaluations in order to assess its accuracy. To our knowledge, our manually created pre-ordering rule set is the first Chinese-English dependency-based pre-ordering rule set.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">The most similar work to this paper is that of Wang et al. (2007). They created a set of pre-ordering rules for constituent parsers for Chinese-English PBSMT. In contrast, we propose a set of pre-ordering rules for dependency parsers. We argue that even though the rules by Wang et al. (2007) exist, it is almost impossible to automatically convert their rules into rules that are applicable to dependency parsers. In fact, we abandoned our initial attempts to automatically convert</p>
</div>
<div id="S1.F1" class="ltx_figure">
<table style="width:100%;">
<tr>
<td class="ltx_subfigure">
<div id="S1.F0.sf1" class="ltx_figure ltx_align_center"><img src="P14-2026/image001.png" id="S1.F0.sf1.g1" class="ltx_graphics" width="270" height="183" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>A constituent parse tree</div>
</div></td>
<td class="ltx_subfigure">
<div id="S1.F0.sf2" class="ltx_figure ltx_align_center"><img src="P14-2026/image002.png" id="S1.F0.sf2.g1" class="ltx_graphics" width="316" height="108" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Stanford typed dependency parse tree</div>
</div></td></tr>
</table>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>A constituent parse tree and its corresponding Stanford typed dependency parse tree for the same Chinese sentence.</div>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">their rules into rules for dependency parsers, and spent more than two months discovering the rules introduced in this paper. By applying our rules and Wang et al.’s rules, one can use both dependency and constituency parsers for pre-ordering in Chinese-English PBSMT.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">This is especially important on the point of the system combination of PBSMT systems, because the diversity of outputs from machine translation systems is important for system combination <cite class="ltx_cite">[<a href="#bib.bibx2" title="" class="ltx_ref">2013</a>]</cite>. By using both our rules and Wang et al.’s rules, one can obtain diverse machine translation results because the pre-ordering results of these two rule sets are generally different.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">Another similar work is that of <cite class="ltx_cite">[<a href="#bib.bibx19" title="" class="ltx_ref">2009</a>]</cite>. They created a pre-ordering rule set for dependency parsers from English to several SOV languages. In contrast, our rule set is for Chinese-English PBSMT. That is, the direction of translation is opposite. Because there are a lot of language specific decisions that reflect specific aspects of the source language and the language pair combination, our rule set provides a valuable resource for pre-ordering in Chinese-English PBSMT.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Dependency-based Pre-ordering Rule Set </h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Figure 1 shows a constituent parse tree and its</p>
</div>
<div id="S2.F2" class="ltx_figure"><img src="P14-2026/image003.png" id="S2.F2.g1" class="ltx_graphics ltx_centering" width="223" height="123" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An example of a preposition phrase with a plmod structure. The phrase translates into “in front of the US embassy”.</div>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">Stanford typed dependency parse tree for the same Chinese sentence. As shown in the figure, the number of nodes in the dependency parse tree (i.e. 9) is much fewer than that in its corresponding constituent parse tree (i.e. 17). Because dependency parse trees are generally more concise than the constituent ones, they can conduct long-distance reorderings in a finer way. Thus, we attempted to conduct pre-ordering based on dependency parsing. There are two widely-used dependency systems – Stanford typed dependencies and CoNLL typed dependencies. For Chinese, there are 45 types of grammatical relations for Stanford typed dependencies <cite class="ltx_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">2009</a>]</cite> and 25 for CoNLL typed dependencies. As we thought that Stanford typed dependencies could describe language phenomena more meticulously owing to more types of grammatical relations, we preferred to use it for searching candidate pre-ordering rules.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">We designed two types of formats in our dependency-based pre-ordering rules. They are:</p>
</div>
<div id="S2.p4" class="ltx_para">
<ul id="I1" class="ltx_itemize">
<li id="I1.ix1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"/> 
<div id="I1.ix1.p1" class="ltx_para">
<p class="ltx_p">Type-1: <span class="ltx_text ltx_font_italic">x</span> : <span class="ltx_text ltx_font_italic">y</span></p>
</div></li>
<li id="I1.ix2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"/> 
<div id="I1.ix2.p1" class="ltx_para">
<p class="ltx_p">Type-2: <span class="ltx_text ltx_font_italic">x</span> - <span class="ltx_text ltx_font_italic">y</span></p>
</div></li>
</ul>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p">Here, both <span class="ltx_text ltx_font_italic">x</span> and <span class="ltx_text ltx_font_italic">y</span> are <span class="ltx_text ltx_font_italic">dependency relations</span> (e.g., plmod or lobj in Figure 2). We define the <span class="ltx_text ltx_font_italic">dependency structure</span> of a dependency relation as the structure containing the dependent word (e.g., the word directly indicated by plmod, or “å” in Figure 2) and the whole subtree under the dependency relation (all of the words that directly or indirectly depend on the dependent word, or the words under “å” in Figure 2). Further, we define <span class="ltx_text ltx_font_italic">X</span> and <span class="ltx_text ltx_font_italic">Y</span> as the corresponding dependency structures of the dependency relations <span class="ltx_text ltx_font_italic">x</span> and <span class="ltx_text ltx_font_italic">y</span>, respectively. We define <span class="ltx_text ltx_font_italic">X<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p5.m1" class="ltx_Math" alttext="\backslash" display="inline"><mo mathvariant="normal">\</mo></math>Y</span> as structure <span class="ltx_text ltx_font_italic">X</span> except <span class="ltx_text ltx_font_italic">Y</span>. For example, in Figure 2, let <span class="ltx_text ltx_font_italic">x</span> and <span class="ltx_text ltx_font_italic">y</span> denote plmod and lobj dependency relations, then <span class="ltx_text ltx_font_italic">X</span> represents “å” and all words under “å”, <span class="ltx_text ltx_font_italic">Y</span> represents “å¤§ä½¿é¦” and all words under</p>
</div>
<div id="S2.F3" class="ltx_figure"><img src="P14-2026/image004.png" id="S2.F3.g1" class="ltx_graphics ltx_centering" width="301" height="132" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An example of rcmod structure within an nsubj structure. The phrase translates into “a senior official close to Sharon said”.</div>
</div>
<div id="S2.p6" class="ltx_para">
<p class="ltx_p">“å¤§ä½¿é¦”, and <span class="ltx_text ltx_font_italic">X<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p6.m1" class="ltx_Math" alttext="\backslash" display="inline"><mo mathvariant="normal">\</mo></math>Y</span> represents “å”. For Type-1, <span class="ltx_text ltx_font_italic">Y</span> is a sub-structure of <span class="ltx_text ltx_font_italic">X</span>. The rule repositions <span class="ltx_text ltx_font_italic">X<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p6.m2" class="ltx_Math" alttext="\backslash" display="inline"><mo mathvariant="normal">\</mo></math>Y</span> to the position before <span class="ltx_text ltx_font_italic">Y</span>. For Type-2, <span class="ltx_text ltx_font_italic">X</span> and <span class="ltx_text ltx_font_italic">Y</span> are ordered sibling structures under a same parent node. The rule repositions <span class="ltx_text ltx_font_italic">X</span> to the position after <span class="ltx_text ltx_font_italic">Y</span>.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p class="ltx_p">We obtained rules as the following steps:</p>
</div>
<div id="S2.p8" class="ltx_para">
<ul id="I2" class="ltx_itemize">
<li id="I2.ix1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_italic">1</span></span> 
<div id="I2.ix1.p1" class="ltx_para">
<p class="ltx_p">Search the Chinese dependency parse trees in the corpus and rank all of the structures matching the two types of rules respectively according to their frequencies. Note that while calculating the frequencies of Type-1 structures, we dismissed the structures in which <span class="ltx_text ltx_font_italic">X</span> occurred before <span class="ltx_text ltx_font_italic">Y</span> originally.</p>
</div></li>
<li id="I2.ix2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_italic">2</span></span> 
<div id="I2.ix2.p1" class="ltx_para">
<p class="ltx_p">Filtration. 1) Filter out the structures which occurred less than 5,000 times. 2) Filter out the structures from which it was almost impossible to derive candidate pre-ordering rules because <span class="ltx_text ltx_font_italic">x</span> or <span class="ltx_text ltx_font_italic">y</span> was an “irrespective” dependency relation, for example, root, conj, cc and so on.</p>
</div></li>
<li id="I2.ix3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_italic">3</span></span> 
<div id="I2.ix3.p1" class="ltx_para">
<p class="ltx_p">Investigate the remaining structures. For each kind of structure, we selected some of the sample dependency parse trees that contained it, tried to restructure the parse trees according to the matched rule and judged the reordered Chinese phrases. If the reordering produced a Chinese phrase that had a closer word order to that of the English one, this structure would be a candidate pre-ordering rule.</p>
</div></li>
<li id="I2.ix4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_italic">4</span></span> 
<div id="I2.ix4.p1" class="ltx_para">
<p class="ltx_p">Conduct primary experiments which used the same training set and development set as the experiments described in Section 3. In the primary experiments, we tested the effectiveness of the candidate rules and filtered the ones that did not work based on the BLEU scores on the development set.</p>
</div></li>
</ul>
</div>
<div id="S2.F4" class="ltx_figure"><img src="P14-2026/image005.png" id="S2.F4.g1" class="ltx_graphics ltx_centering" width="246" height="118" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An example of rcmod structure with a preposition modifier. The phrase translates into “a press conference held in Kabul”.</div>
</div>
<div id="S2.p9" class="ltx_para">
<p class="ltx_p">As a result, we obtained eight pre-ordering rules in total, which can be divided into three dependency relation categories. They are: plmod (localizer modifier of a preposition), rcmod (relative clause modifier) and prep (preposition modifer). Each of these categories are discussed in detail below.</p>
</div>
<div id="S2.p10" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">plmod</span> Figure 2 shows an example of a prepositional phrase with a plmod structure, which translates literally into “in the US embassy front”. In Chinese, the dependent word of a plmod relation (e.g., “å” in Figure 2) occurs in the last position of the prepositional phrase. However, in English, this kind of word (e.g., “front” in the caption of Figure 2) always occur directly after prepositions, which is to say, in the second position in a prepositional phrase. Therefore, we applied a rule <span class="ltx_text ltx_font_bold">plmod</span> : <span class="ltx_text ltx_font_bold">lobj</span> (localizer object) to reposition the dependent word of the plmod relation (e.g., “å” in Figure 2) to the position before the lobj structure (e.g., “ç¾å½ å¤§ä½¿é¦” in Figure 2). In this case, it also comes directly after the preposition. Similarly, we created a rule <span class="ltx_text ltx_font_bold">plmod</span> : <span class="ltx_text ltx_font_bold">lccomp</span> (clausal complement of a localizer).</p>
</div>
<div id="S2.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold">Type</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">System</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold">Parser</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold">BLEU</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Counts</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">#Sent.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">No pre-ordering</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">-</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">29.96</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">-</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Constituent</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">WR07</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Berkeley</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">31.45</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2,561,937</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">852,052</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t">Dependency</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">OUR DEP 1</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">Berkeley Const.</td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">31.54</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">   978,013</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">556,752</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_b ltx_border_l ltx_border_rr"/>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">OUR DEP 2</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">Mate</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr">31.57</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">   947,441</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">547,084</td></tr>
</tbody>
</table>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>The comparison of four systems, including the performance (BLEU) on the test set, the total count of each rule set and the number of sentences they were applied to on the training set.</div>
</div>
<div id="S2.p11" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">rcmod</span> Figure 3 shows an example of an rcmod structure under an nsubj (nominal subject) structure. Here “mw” means “measure word”. As shown in the figure, relative clause modifiers in Chinese (e.g., “æ¥è¿ å¤é ç” in Figure 3) occurs before the noun being modified, which is in contrast to English (e.g., “close to Sharon” in the caption of Figure 3), where they come after. Thus, we introduced a series of rules <span class="ltx_text ltx_font_bold">NOUN</span> : <span class="ltx_text ltx_font_bold">rcmod</span> to restructure rcmod structures so that the noun is moved to the head. In this example, with the application of an <span class="ltx_text ltx_font_bold">nsubj</span> : <span class="ltx_text ltx_font_bold">rcmod</span> rule, the phrase can be translated into “a senior official close to Sharon say”, which has a word order very close to English. Since a noun can be nsubj, dobj (direct object), pobj (prepositional object)</p>
</div>
<div id="S2.F5" class="ltx_figure"><img src="P14-2026/image006.png" id="S2.F5.g1" class="ltx_graphics ltx_centering" width="293" height="128" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example of verb phrase with a preposition modifier. The phrase translates into “Musharraf told reporters here”.</div>
</div>
<div id="S2.p12" class="ltx_para">
<p class="ltx_p">and lobj in Stanford typed dependencies, we created four rules from the NOUN pattern. Note that for some preposition modifiers, we needed a rule <span class="ltx_text ltx_font_bold">rcmod</span> : <span class="ltx_text ltx_font_bold">prep</span> to conduct the same work. For instance, the Chinese phrase in Figure 4 can be translated into “hold in Kabul press conference” with the application of this rule.</p>
</div>
<div id="S2.p13" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">prep</span> Within verb phrases, the positions of prep structures are quite different between Chinese and English. Figure 5 shows an example of a verb phrase with a preposition modifier (prep), which literally translates into “Musharraf at this place tell reporter”. Recognizing that prep structures occur before the verb in Chinese (e.g., “å¨ æ­¤ å°” in Figure 5) but after the verb in English (usually in the last position of a verb phrase, e.g., “here” in the caption of Figure 5), we applied a rule <span class="ltx_text ltx_font_bold">prep</span> - <span class="ltx_text ltx_font_bold">dobj</span> to reposition prep structures after their sibling dobj structures.</p>
</div>
<div id="S2.p14" class="ltx_para">
<p class="ltx_p">In summary, the dependency-based pre-ordering rule set has eight rules: plmod : lobj, plmod : lccomp, nsubj : rcmod, dobj : rcmod, pobj : rcmod, lobj : rcmod, rcmod : prep, and prep - dobj.</p>
</div>
<div id="S2.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_bold">Category</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">   Count</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">  Correct</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Incorrect</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold">Accuracy</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_tt">plmod</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">42</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">26</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">16</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">61.9%</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr">rcmod</td>
<td class="ltx_td ltx_align_center ltx_border_r">89</td>
<td class="ltx_td ltx_align_center ltx_border_r">49</td>
<td class="ltx_td ltx_align_center ltx_border_r">40</td>
<td class="ltx_td ltx_align_center ltx_border_r">55.1%</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr">prep</td>
<td class="ltx_td ltx_align_center ltx_border_r">54</td>
<td class="ltx_td ltx_align_center ltx_border_r">36</td>
<td class="ltx_td ltx_align_center ltx_border_r">18</td>
<td class="ltx_td ltx_align_center ltx_border_r">66.7%</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_rr ltx_border_t">All</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">185</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">111</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">74</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">60.0%</td></tr>
</tbody>
</table>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Accuracy of the dependency-based pre-ordering rules on a set of 200 sentences randomly selected from the development set.</div>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">We used the MOSES PBSMT system <cite class="ltx_cite">[<a href="#bib.bibx11" title="" class="ltx_ref">2007</a>]</cite> in our experiments. The training data, which included those data used in Wang et al. <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>]</cite>, contained 1 million pairs of sentences extracted from the Linguistic Data Consortium’s parallel news corpora. Our development set was the official NIST MT evaluation data from 2002 to 2005, consisting of 4476 Chinese-English sentences pairs. Our test set was the NIST 2006 MT evaluation data, consisting of 1664 sentence pairs. We employed the Stanford Segmenter<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>http://nlp.stanford.edu/software/segmenter.shtml</span></span></span> to segment all of the data sets. For evaluation, we used BLEU scores <cite class="ltx_cite">[<a href="#bib.bibx13" title="" class="ltx_ref">2002</a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">We implemented the constituent-based pre-ordering rule set in Wang et al. <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>]</cite> for comparison, which is called WR07 below. The Berkeley Parser <cite class="ltx_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">2006</a>]</cite> was employed for parsing the Chinese sentences. For training the Berkeley Parser, we used Chinese Treebank (CTB) 7.0.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">We conducted our dependency-based pre-ordering experiments on the Berkeley Parser and the Mate Parser <cite class="ltx_cite">[<a href="#bib.bibx1" title="" class="ltx_ref">2010</a>]</cite>, which were shown to be the two best parsers for Stanford typed dependencies <cite class="ltx_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">2012</a>]</cite>. First, we converted the constituent parse trees in the results of the Berkeley Parser into dependency parse trees by employing a tool in the Stanford Parser <cite class="ltx_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">2003</a>]</cite>. For the Mate Parser, POS tagged inputs are required both in training and in inference. Thus, we then extracted the POS information from the results of the Berkeley Parser and used these as the pre-specified POS tags for the Mate Parser. Finally, we applied our dependency-based pre-ordering rule set to the dependency parse trees created from the converted Berkeley Parser and the Mate Parser, respectively.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p class="ltx_p">Table 1 presents a comparison of the system without pre-ordering, the constituent system using WR07 and two dependency systems employing the converted Berkeley Parser and the Mate Parser, respectively. It shows the BLEU scores on the test set and the statistics of pre-ordering on the training set, which includes the total count of each rule set and the number of sentences they were applied to. Both of our dependency systems outperformed WR07 slightly but were not significant at p = 0.05. However, both of them substantially decreased the total times about 60% (or 1,600,000) for pre-ordering rule applications on the training set, compared with WR07. In our opinion, the reason for the great decrease was that the dependency parse trees were more concise than the constituent parse trees in describing sentences and they could also describe the reordering at the sentence level in a finer way. In contrast, the constituent parse trees were more redundant and they needed more nodes to conduct long-distance reordering. In this case, the affect of the performance of the constituent parsers on pre-ordering is larger than that of the dependency ones so that the constituent parsers are likely to bring about more incorrect pre-orderings.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p class="ltx_p">Similar to Wang et al. <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>]</cite>, we carried out human evaluations to assess the accuracy of our dependency-based pre-ordering rules by employing the system “OUR DEP 2” in Table 1. The evaluation set contained 200 sentences randomly selected from the development set. Among them, 107 sentences contained at least one rule and the rules were applied 185 times totally. Since the accuracy check for dependency parse trees took great deal of time, we did not try to select error free (100% accurately parsed) sentences. A bilingual speaker of Chinese and English looked at an original Chinese phrase and the pre-ordered one with their corresponding English phrase and judged whether the pre-ordering obtained a Chinese phrase that had a closer word order to the English one. Table 2 shows the accuracies of three categories of our dependency-based pre-ordering rules. The overall accuracy of this rule set is 60.0%, which is almost at the same level as the WR07 rule set (62.1%), according to the similar evaluation (200 sentences and one annotator) conducted in Wang et al. <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>]</cite>. Notice that some of the incorrect pre-orderings may be caused by erroneous parsing as also suggested by Wang et al. <cite class="ltx_cite">[<a href="#bib.bibx16" title="" class="ltx_ref">2007</a>]</cite>. Through human evaluations, we found that 19 out of the total 74 incorrect pre-orderings resulted from errors in parsing. Among them, 13 incorrect pre-orderings applied the rules of the rcmod category. The analysis suggests that we need to introduce constraints on the rule application of this category in the future.</p>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">In this paper, we introduced a novel pre-ordering approach based on dependency parsing for a Chinese-English PBSMT system. The results showed that our approach achieved a BLEU score gain of 1.61. Moreover, our dependency-based pre-ordering rule set substantially decreased the time for applying pre-ordering rules about 60% compared with WR07, on the training set of 1M sentences pairs. The overall accuracy of our rule set is 60.0%, which is almost at the same level as the WR07 rule set. These results indicated that dependency parsing is more effective for conducting pre-ordering for Chinese-English PBSMT. Although our work focused on Chinese, the ideas can also be applied to other languages.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">In the future, we attempt to create more efficient pre-ordering rules by exploiting the rich information in dependency structures.</p>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">We thank the anonymous reviewers for their valuable comments and suggestions. This work is supported in part by the International Science &amp; Technology Cooperation Program of China (Grant No. 2014DFA11350) and Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS, Beijing 100190, China.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2010</span>
<span class="ltx_bibblock">
Bernd Bohnet.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Very high accuracy and fast dependency parsing is not a contradiction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010)</span>.

</span></li>
<li id="bib.bibx2" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2013</span>
<span class="ltx_bibblock">
Daniel Cer, Christopher D. Manning, and Dan Jurafsky.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Positive Diversity Tuning for Machine Translation System Combination.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the Eighth Workshop on Statistical Machine Translation (WMT 2013)</span>.

</span></li>
<li id="bib.bibx3" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2009</span>
<span class="ltx_bibblock">
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christopher D. Manning.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">Discriminative reordering with Chinese grammatical relations features.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the HLT-NAACL Workshop on Syntax and Structure in Statistical Translation</span>, pages 51-59.

</span></li>
<li id="bib.bibx4" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2012</span>
<span class="ltx_bibblock">
Wanxiang Che, Valentin Spitkovsky, and Ting Liu.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">A comparison of Chinese parsers for Stanford dependencies.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics</span>, pages 11-16.

</span></li>
<li id="bib.bibx5" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2005</span>
<span class="ltx_bibblock">
Michael Collins, Philipp Koehn, and Ivona Kucerova.

</span>
<span class="ltx_bibblock">2005.

</span>
<span class="ltx_bibblock">Clause restructuring for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</span>, pages 531-540.

</span></li>
<li id="bib.bibx6" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2012</span>
<span class="ltx_bibblock">
Dan Han, Katsuhito Sudoh, Xianchao Wu, Kevin Duh, Hajime Tsukada, and Masaaki Nagata.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Head Finalization reordering for Chinese-to-Japanese machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of SSST-6, Sixth Workshop on Syntax, Semantics and Structure in Statistical Translation</span>, pages 57-66.

</span></li>
<li id="bib.bibx7" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2007</span>
<span class="ltx_bibblock">
Nizar Habash.

</span>
<span class="ltx_bibblock">2007.

</span>
<span class="ltx_bibblock">Syntactic preprocessing for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 11th Machine Translation Summit (MT-Summit)</span>.

</span></li>
<li id="bib.bibx8" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2010</span>
<span class="ltx_bibblock">
Hideki Isozaki, Katsuhito Sudoh, Hajime Tsukada, and Kevin Duh.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Head Finalization: A simple reordering rule for SOV languages.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR</span>, pages 250-257.

</span></li>
<li id="bib.bibx9" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2011</span>
<span class="ltx_bibblock">
Jason Katz-Brown, Slav Petrov, Ryan McDonald, Franz J. Och, David Talbot, Hiroshi Ichikawa, Masakazu Seno, and Hideto Kazawa.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Training a parser for machine translation reordering.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the Conference on Empirical Methods in Natural Language Processing</span>, pages 183-192.

</span></li>
<li id="bib.bibx10" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2003</span>
<span class="ltx_bibblock">
Dan Klein and Christopher D. Manning.

</span>
<span class="ltx_bibblock">2003.

</span>
<span class="ltx_bibblock">Accurate unlexicalized parsing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 41st Annual Meeting on Association for Computational Linguistics</span>, pages 423-430.

</span></li>
<li id="bib.bibx11" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2007</span>
<span class="ltx_bibblock">
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst.

</span>
<span class="ltx_bibblock">2007.

</span>
<span class="ltx_bibblock">Moses: Open source toolkit for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions</span>, pages 177-180.

</span></li>
<li id="bib.bibx12" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2010</span>
<span class="ltx_bibblock">
Young-Suk Lee, Bing Zhao, and Xiaoqian Luo.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Constituent reordering and syntax models for English-to-Japanese statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 23rd International of Conference on Computational Linguistics</span>, pages 626-634.

</span></li>
<li id="bib.bibx13" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2002</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu.

</span>
<span class="ltx_bibblock">2002.

</span>
<span class="ltx_bibblock">BLEU: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of 40th Annual Meeting of the Association for Computational Linguistics</span>, pages 311-318.

</span></li>
<li id="bib.bibx14" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2006</span>
<span class="ltx_bibblock">
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein.

</span>
<span class="ltx_bibblock">2006.

</span>
<span class="ltx_bibblock">Learning accurate, compact, and interpretable tree annotation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics</span>, pages 433-440.

</span></li>
<li id="bib.bibx15" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">1994</span>
<span class="ltx_bibblock">
Carl Pollard and Ivan A. Sag.

</span>
<span class="ltx_bibblock">1994.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Head-Driven Phrase Structure Grammar</span>.

</span>
<span class="ltx_bibblock">University of Chicago Press.

</span></li>
<li id="bib.bibx16" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2007</span>
<span class="ltx_bibblock">
Chao Wang, Michael Collins, and Philipp Koehn.

</span>
<span class="ltx_bibblock">2007.

</span>
<span class="ltx_bibblock">Chinese syntactic reordering for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</span>, pages 737-745.

</span></li>
<li id="bib.bibx17" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2011</span>
<span class="ltx_bibblock">
Xianchao Wu, Katsuhito Sudoh, Kevin Duh, Hajime Tsukada, and Masaaki Nagata.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Extracting preordering rules from predicate-argument structures.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of 5th International Joint Conference on Natural Language Processing</span>, pages 29-37.

</span></li>
<li id="bib.bibx18" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2004</span>
<span class="ltx_bibblock">
Fei Xia and Michael McCord.

</span>
<span class="ltx_bibblock">2004.

</span>
<span class="ltx_bibblock">Improving a statistical MT system with automatically learned rewrite patterns.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of Coling 2004</span>, pages 508-514.

</span></li>
<li id="bib.bibx19" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2009</span>
<span class="ltx_bibblock">
Peng Xu, Jaeho Kang, Michael Ringgaard, and Franz J. Och.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">Using a dependency parser to improve SMT for subject-object-verb languages.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of HLT-NAACL</span>, pages 245-253.

</span></li>
<li id="bib.bibx20" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2008</span>
<span class="ltx_bibblock">
Jiajun Zhang, Chengqing Zong, and Shoushan Li.

</span>
<span class="ltx_bibblock">2008.

</span>
<span class="ltx_bibblock">Sentence type based reordering model for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of the 22nd International Conference on Computational Linguistics</span>, pages 1089-1096.

</span></li>
<li id="bib.bibx21" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">2007</span>
<span class="ltx_bibblock">
Yuqi Zhang, Richard Zens, and Hermann Ney.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Chunk-level reordering of source language sentences with automatically learned rules for statistical machine translation.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">HLT-NAACL Workshop on Syntax and Structure in Statistical Translation</span>, pages 1-8.

</span></li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"/>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 17:40:21 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
