<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Simple Bayesian Modelling Approach to Event Extraction from Twitter</title>
<!--Generated on Wed Jun 11 18:23:13 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Simple Bayesian Modelling Approach to Event Extraction from Twitter</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Deyu Zhou<math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="{}^{{\dagger}{\ddagger}}" display="inline"><msup><mi/><mrow><mo>†</mo><mo>⁣</mo><mo>‡</mo></mrow></msup></math>    Liangyu Chen<math xmlns="http://www.w3.org/1998/Math/MathML" id="m2" class="ltx_Math" alttext="{}^{\dagger}" display="inline"><msup><mi/><mo>†</mo></msup></math>    Yulan He<math xmlns="http://www.w3.org/1998/Math/MathML" id="m3" class="ltx_Math" alttext="{}^{\S}" display="inline"><msup><mi/><mi mathvariant="normal">§</mi></msup></math> 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m4" class="ltx_Math" alttext="{}^{\dagger}" display="inline"><msup><mi/><mo>†</mo></msup></math> School of Computer Science and Engineering, Key Laboratory of Computer Network 
<br class="ltx_break"/>and Information Integration, Ministry of Education, Southeast University, China
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m5" class="ltx_Math" alttext="{}^{\ddagger}" display="inline"><msup><mi/><mo>‡</mo></msup></math> State Key Laboratory for Novel Software Technology, Nanjing University, China
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="m6" class="ltx_Math" alttext="{}^{\S}" display="inline"><msup><mi/><mi mathvariant="normal">§</mi></msup></math> School of Engineering and Applied Science, Aston University, UK
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">d.zhou@seu.edu.cn, cly1cn@126.com, y.he@cantab.net</span>

</span></span></div>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">With the proliferation of social media sites, social streams have proven to contain the most up-to-date information on current events. Therefore, it is crucial to extract events from the social streams such as tweets. However, it is not straightforward to adapt the existing event extraction systems since texts in social media are fragmented and noisy. In this paper we propose a simple and yet effective Bayesian model, called Latent Event Model (LEM), to extract structured representation of events from social media. LEM is fully unsupervised and does not require annotated data for training. We evaluate LEM on a Twitter corpus. Experimental results show that the proposed model achieves 83% in F-measure, and outperforms the state-of-the-art baseline by over 7%.</p>
</div><span class="ltx_ERROR undefined">\setlist</span>
<div id="p1" class="ltx_para">
<p class="ltx_p">[itemize]itemsep=0cm</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.F1" class="ltx_figure"><img src="P14-2114/image001.png" id="S1.F1.g1" class="ltx_graphics ltx_centering" width="676" height="956" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The proposed framework for event extraction from tweets.</div>
</div>
<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Event extraction is to automatically identify events from text with information about <em class="ltx_emph">what</em> happened, <em class="ltx_emph">when</em>, <em class="ltx_emph">where</em>, to <em class="ltx_emph">whom</em>, and <em class="ltx_emph">why</em>. Previous work in event extraction has focused largely on news articles, as the newswire texts have been the best source of information on current events <cite class="ltx_cite">[<a href="#bib.bib8" title="An overview of event extraction from text" class="ltx_ref">6</a>]</cite>. Approaches for event extraction include knowledge-based <cite class="ltx_cite">[<a href="#bib.bib16" title="Extracting violent events from on-line news for ontology population" class="ltx_ref">12</a>, <a href="#bib.bib17" title="Real-time news event extraction for global crisis monitoring" class="ltx_ref">15</a>]</cite>, data-driven <cite class="ltx_cite">[<a href="#bib.bib18" title="Cluster-centric approach to news event extraction" class="ltx_ref">11</a>]</cite> and a combination of the above two categories <cite class="ltx_cite">[<a href="#bib.bib19" title="Nyu’s english ace 2005 system description" class="ltx_ref">5</a>]</cite>. Knowledge-based approaches often rely on linguistic and lexicographic patterns which represent expert domain knowledge for particular event types. They lack the flexibility of porting to new domains since extraction patterns often need to be re-defined. Data-driven approaches require large annotated data to train statistical models that approximate linguistic phenomena. Nevertheless, it is expensive to obtain annotated data in practice.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">With the increasing popularity of social media, social networking sites such as Twitter have become an important source of event information. As reported in <cite class="ltx_cite">[<a href="#bib.bib22" title="Can twitter replace newswire for breaking news?" class="ltx_ref">10</a>]</cite>, even 1% of the public stream of Twitter contains around 95% of all the events reported in the newswire. Nevertheless, the social stream data such as Twitter data pose new challenges. Social media messages are often short and evolve rapidly over time. As such, it is not possible to know the event types a priori and hence violates the use of existing event extraction approaches.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">Approaches to event extraction from Twitter make use of a graphical model to extract canonical entertainment events from tweets by aggregating information across multiple messages <cite class="ltx_cite">[<a href="#bib.bib1" title="Event discovery in social media feeds" class="ltx_ref">1</a>]</cite>. In <cite class="ltx_cite">[<a href="#bib.bib7" title="Exacting social events for tweets using a factor graph" class="ltx_ref">7</a>]</cite>, social events involving two persons are extracted from multiple similar tweets using a factor graph by harvesting the redundancy in tweets. Ritter et al. <cite class="ltx_cite">[<a href="#bib.bib10" title="Open domain event extraction from twitter" class="ltx_ref">14</a>]</cite> presented a system called TwiCal which extracts an open-domain calendar of significant events represented by a 4-tuple set including a named entity, event phrase, calendar date, and event type from Twitter.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">In our work here, we notice a very important property in social media data that the same event could be referenced by high volume messages. This property allows us resort to statistical models that can group similar events based on the co-occurrence patterns of their event elements. Here, event elements include named entities such as person, company, organization, date/time, location, and the relations among them. We can treat an event as a latent variable and model the generation of an event as a joint distribution of its individual event elements. We thus propose a Latent Event Model (LEM) which can automatically detect events from social media without the use of labeled data.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">Our work is similar to TwiCal in the sense that we also focus on the extraction of structured representation of events from Twitter. However, TwiCal relies on a supervised sequence labeler trained on tweets annotated with event mentions for the identification of event-related phrases. We propose a simple Bayesian modelling approach which is able to directly extract event-related keywords from tweets without supervised learning. Also, TwiCal uses <math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p5.m1" class="ltx_Math" alttext="G^{2}" display="inline"><msup><mi>G</mi><mn>2</mn></msup></math> test to choose an entity <math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p5.m2" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math> with the strongest association with a date <math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p5.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> to form a binary tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p5.m4" class="ltx_Math" alttext="\langle y,d\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi></mrow><mo>⟩</mo></mrow></math> to represent an event. On the contrary, the structured representation of events can be directly extracted from the output of our LEM model. We have conducted experiments on a Twitter corpus and the results show that our proposed approach outperforms TwiCal, the state-of-the-art open event extraction system, by 7.7% in F-measure.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Methodology</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Events extracted in our proposed framework are represented as a 4-tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m1" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m2" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math> stands for a non-location named entity, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> for a date, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m4" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math> for a location, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m5" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> for an event-related keyword. Each event mentioned in tweets can be closely depicted by this representation. It should be noted that for some events, one or more elements in their corresponding tuples might be absent as their related information is not available in tweets. As illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, our proposed framework consists of three main steps, pre-processing, event extraction based on the LEM model and post-processing. The details of our proposed framework are described below.</p>
</div>
<div id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.1 </span>Pre-processing</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">Tweets are pre-processed by time expression recognition, named entity recognition, POS tagging and stemming.</p>
</div>
<div id="S2.SS1.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Time Expression Recognition.</h4>

<div id="S2.SS1.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">Twitter users might represent the same date in various forms. For example, “tomorrow”, “next Monday”, “ August 23th” in tweets might all refer to the same day, depending on the date that users wrote the tweets. To resolve the ambiguity of the time expressions, SUTime<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><a href="http://nlp.stanford.edu/software/sutime.shtml" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://nlp.stanford.edu/software/sutime.shtml</span></a></span></span></span> <cite class="ltx_cite">[<a href="#bib.bib24" title="SUTIME: a library for recognizing and normalizing time expressions" class="ltx_ref">2</a>]</cite> is employed, which takes text and a reference date as input and outputs a more accurate date which the time expression refers to.</p>
</div>
</div>
<div id="S2.SS1.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Named Entity Recognition.</h4>

<div id="S2.SS1.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">Named entity recognition (NER) is a crucial step since the results would directly impact the final extracted 4-tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p1.m1" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math>. It is not easy to accurately identify named entities in the Twitter data since tweets contain a lot of misspellings and abbreviations. However, it is often observed that events mentioned in tweets are also reported in news articles in the same period <cite class="ltx_cite">[<a href="#bib.bib22" title="Can twitter replace newswire for breaking news?" class="ltx_ref">10</a>]</cite>. Therefore, named entities mentioned in tweets are likely to appear in news articles as well. We thus perform named entity recognition in the following way. First, a traditional NER tool such as the Stanford Named Entity Recognizer<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><a href="http://nlp.stanford.edu/software/CRF-NER.shtml" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://nlp.stanford.edu/software/CRF-NER.shtml</span></a></span></span></span> is used to identify named entities from the news articles crawled from BBC and CNN during the same period that the tweets were published. The recognised named entities from news are then used to build a dictionary. Named entities from tweets are extracted by looking up the dictionary through fuzzy matching. We have also used a named entity tagger trained specifically on the Twitter data<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><a href="http://github.com/aritter/twitter-nlp" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://github.com/aritter/twitter-nlp</span></a></span></span></span> <cite class="ltx_cite">[<a href="#bib.bib26" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">13</a>]</cite> to directly extract named entities from tweets. However, as will be shown in Section <a href="#S3" title="3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> that using our constructed dictionary for named entity extraction gives better results. We distinguish between location entities, denoted as <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p1.m2" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math>, and non-location entities such as person or organization, denoted as <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p1.m3" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math>.</p>
</div>
<div id="S2.SS1.SSS0.P2.p2" class="ltx_para">
<p class="ltx_p">Finally, we use a POS tagger<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><a href="http://www.ark.cs.cmu.edu/TweetNLP" title="" class="ltx_ref ltx_url"><span class="ltx_text ltx_font_typewriter">http://www.ark.cs.cmu.edu/TweetNLP</span></a></span></span></span> trained on tweets <cite class="ltx_cite">[<a href="#bib.bib23" title="Part-of-speech tagging for twitter: annotation, features, and experiments" class="ltx_ref">3</a>]</cite> to perform POS tagging on the tweets data and apart from the previously recognised named entities, only words tagged with nouns, verbs or adjectives are kept. These remaining words are subsequently stemmed and words occurred less than 3 times are filtered.</p>
</div>
<div id="S2.SS1.SSS0.P2.p3" class="ltx_para">
<p class="ltx_p">After the pre-processing step, non-location entities <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p3.m1" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math>, locations <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p3.m2" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math>, dates <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.SSS0.P2.p3.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> and candidate keywords of the tweets are collected as the input to the LEM model for event extraction.</p>
</div>
</div>
</div>
<div id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.2 </span>Event Extraction using the Latent Event Model (LEM)</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p">We propose an unsupervised latent variable model, called the Latent
Event Model (LEM), to extract events from tweets. The graphical model of LEM is shown in Figure <a href="#S2.F2" title="Figure 2 ‣ 2.2 Event Extraction using the Latent Event Model (LEM) ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S2.F2" class="ltx_figure"><img src="P14-2114/image002.png" id="S2.F2.g1" class="ltx_graphics ltx_centering" width="203" height="287" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Laten Event Model (LEM).</div>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">In this model, we assume that each tweet message <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m1" class="ltx_Math" alttext="m\in\{1..M\}" display="inline"><mrow><mi>m</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mn>1..</mn><mo>⁢</mo><mi>M</mi></mrow><mo>}</mo></mrow></mrow></math> is assigned to one event instance <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m2" class="ltx_Math" alttext="e" display="inline"><mi>e</mi></math>, while <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m3" class="ltx_Math" alttext="e" display="inline"><mi>e</mi></math> is modeled as a joint distribution over
the named entities <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m4" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math>, the date/time <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m5" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> when the event occurred, the location <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m6" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math> where the event occurred and the event-related keywords <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m7" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math>. This assumption essentially encourages events that involve the same named entities, occur at the same time and in the same
location and have similar keyword to be assigned with the same event.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p class="ltx_p">The generative process of LEM is shown below.</p>
<ul id="I1" class="ltx_itemize">
<li id="I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i1.p1" class="ltx_para">
<p class="ltx_p">Draw the event distribution <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i1.p1.m1" class="ltx_Math" alttext="\bm{\pi}_{e}\sim\mathop{\hbox{Dirichlet}}\nolimits(\alpha)" display="inline"><mrow><msub><mi>𝝅</mi><mi>e</mi></msub><mo>∼</mo><mrow><mtext>Dirichlet</mtext><mrow><mo>(</mo><mi>α</mi><mo>)</mo></mrow></mrow></mrow></math></p>
</div></li>
<li id="I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i2.p1" class="ltx_para">
<p class="ltx_p">For each event <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i2.p1.m1" class="ltx_Math" alttext="e\in\{1..E\}" display="inline"><mrow><mi>e</mi><mo>∈</mo><mrow><mo>{</mo><mrow><mn>1..</mn><mo>⁢</mo><mi>E</mi></mrow><mo>}</mo></mrow></mrow></math>, draw multinomial distributions <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i2.p1.m2" class="ltx_Math" alttext="\bm{\theta}_{e}\sim\mathop{\hbox{Dirichlet}}\nolimits(\beta),\bm{\varphi}_{e}%&#10;\sim\mathop{\hbox{Dirichlet}}\nolimits(\gamma),\bm{\psi}_{e}\sim\mathop{\hbox{%&#10;Dirichlet}}\nolimits(\eta),\bm{\omega}_{e}\sim\mathop{\hbox{Dirichlet}}%&#10;\nolimits(\lambda)" display="inline"><mrow><mrow><msub><mi>𝜽</mi><mi>e</mi></msub><mo>∼</mo><mrow><mtext>Dirichlet</mtext><mrow><mo>(</mo><mi>β</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo><mrow><mrow><msub><mi>𝝋</mi><mi>e</mi></msub><mo>∼</mo><mrow><mtext>Dirichlet</mtext><mrow><mo>(</mo><mi>γ</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo><mrow><mrow><msub><mi>𝝍</mi><mi>e</mi></msub><mo>∼</mo><mrow><mtext>Dirichlet</mtext><mrow><mo>(</mo><mi>η</mi><mo>)</mo></mrow></mrow></mrow><mo>,</mo><mrow><msub><mi>𝝎</mi><mi>e</mi></msub><mo>∼</mo><mrow><mtext>Dirichlet</mtext><mrow><mo>(</mo><mi>λ</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow></mrow></math>.</p>
</div></li>
<li id="I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">•</span> 
<div id="I1.i3.p1" class="ltx_para">
<p class="ltx_p">For each tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i3.p1.m1" class="ltx_Math" alttext="\bm{w}" display="inline"><mi>𝒘</mi></math></p>
<ul id="I1.I1" class="ltx_itemize">
<li id="I1.I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_bold">–</span></span> 
<div id="I1.I1.i1.p1" class="ltx_para">
<p class="ltx_p">Choose an event <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i1.p1.m1" class="ltx_Math" alttext="e\sim\mathop{\hbox{Multinomial}}\nolimits(\bm{\pi})" display="inline"><mrow><mi>e</mi><mo>∼</mo><mrow><mtext>Multinomial</mtext><mrow><mo>(</mo><mi>𝝅</mi><mo>)</mo></mrow></mrow></mrow></math>,</p>
</div></li>
<li id="I1.I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_bold">–</span></span> 
<div id="I1.I1.i2.p1" class="ltx_para">
<p class="ltx_p">For each named entity occur in tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i2.p1.m1" class="ltx_Math" alttext="\bm{w}" display="inline"><mi>𝒘</mi></math>, choose a named entity <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i2.p1.m2" class="ltx_Math" alttext="y\sim\mathop{\hbox{Multinomial}}\nolimits(\bm{\theta}_{e})" display="inline"><mrow><mi>y</mi><mo>∼</mo><mrow><mtext>Multinomial</mtext><mrow><mo>(</mo><msub><mi>𝜽</mi><mi>e</mi></msub><mo>)</mo></mrow></mrow></mrow></math>,</p>
</div></li>
<li id="I1.I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_bold">–</span></span> 
<div id="I1.I1.i3.p1" class="ltx_para">
<p class="ltx_p">For each date occur in tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i3.p1.m1" class="ltx_Math" alttext="\bm{w}" display="inline"><mi>𝒘</mi></math>, choose a date <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i3.p1.m2" class="ltx_Math" alttext="d\sim\mathop{\hbox{Multinomial}}\nolimits(\bm{\varphi}_{e})" display="inline"><mrow><mi>d</mi><mo>∼</mo><mrow><mtext>Multinomial</mtext><mrow><mo>(</mo><msub><mi>𝝋</mi><mi>e</mi></msub><mo>)</mo></mrow></mrow></mrow></math>,</p>
</div></li>
<li id="I1.I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_bold">–</span></span> 
<div id="I1.I1.i4.p1" class="ltx_para">
<p class="ltx_p">For each location occur in tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i4.p1.m1" class="ltx_Math" alttext="\bm{w}" display="inline"><mi>𝒘</mi></math>, choose a location <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i4.p1.m2" class="ltx_Math" alttext="l\sim\mathop{\hbox{Multinomial}}\nolimits(\bm{\psi}_{e})" display="inline"><mrow><mi>l</mi><mo>∼</mo><mrow><mtext>Multinomial</mtext><mrow><mo>(</mo><msub><mi>𝝍</mi><mi>e</mi></msub><mo>)</mo></mrow></mrow></mrow></math>,</p>
</div></li>
<li id="I1.I1.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize"><span class="ltx_text ltx_font_bold">–</span></span> 
<div id="I1.I1.i5.p1" class="ltx_para">
<p class="ltx_p">For other words in tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i5.p1.m1" class="ltx_Math" alttext="\bm{w}" display="inline"><mi>𝒘</mi></math>, choose a word <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.I1.i5.p1.m2" class="ltx_Math" alttext="k\sim\mathop{\hbox{Multinomial}}\nolimits(\bm{\omega}_{e})" display="inline"><mrow><mi>k</mi><mo>∼</mo><mrow><mtext>Multinomial</mtext><mrow><mo>(</mo><msub><mi>𝝎</mi><mi>e</mi></msub><mo>)</mo></mrow></mrow></mrow></math>.</p>
</div></li>
</ul>
</div></li>
</ul>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p class="ltx_p">We use Collapsed Gibbs Sampling <cite class="ltx_cite">[<a href="#bib.bib25" title="Finding scientific topics" class="ltx_ref">4</a>]</cite> to infer the parameters of the model and the latent class assignments for events, given observed data <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p4.m1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><mi class="ltx_font_mathcaligraphic">𝒟</mi></math> and the total likelihood. Gibbs sampling allows us repeatedly sample from a Markov chain whose stationary distribution is the posterior of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p4.m2" class="ltx_Math" alttext="e_{m}" display="inline"><msub><mi>e</mi><mi>m</mi></msub></math> from the distribution over that variable given the current values of all other variables and the data. Such samples can be used to empirically estimate the target distribution. Letting the subscript <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p4.m3" class="ltx_Math" alttext="-m" display="inline"><mrow><mo>-</mo><mi>m</mi></mrow></math> denote a quantity that excludes data from <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p4.m4" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>th tweet , the conditional posterior for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p4.m5" class="ltx_Math" alttext="e_{m}" display="inline"><msub><mi>e</mi><mi>m</mi></msub></math> is:</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<table id="S2.E1" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.E1.m1" class="ltx_Math" alttext="P(e_{m}=t|\bm{e}_{-m},\bm{y},\bm{d},\bm{l},\bm{z},\Lambda)\propto\frac{n^{-m}_%&#10;{t}+\alpha}{M+E\alpha}\times\\&#10;\prod_{y=1}^{Y}\frac{\prod_{b=1}^{n_{t,y}^{(m)}}(n_{t,y}-b+\beta)}{\prod_{b=1}%&#10;^{n_{t}^{(m)}}(n_{t}-b+Y\beta)}\times\prod_{d=1}^{D}\frac{\prod_{b=1}^{n_{t,d}%&#10;^{(m)}}(n_{t,d}-b+\gamma)}{\prod_{b=1}^{n_{t}^{(m)}}(n_{t}-b+D\gamma)}\\&#10;\times\prod_{l=1}^{L}\frac{\prod_{b=1}^{n_{t,l}^{(m)}}(n_{t,l}-b+\eta)}{\prod_%&#10;{b=1}^{n_{t}^{(m)}}(n_{t}-b+L\eta)}\times\prod_{k=1}^{V}\frac{\prod_{b=1}^{n_{%&#10;t,k}^{(m)}}(n_{t,k}-b+\lambda)}{\prod_{b=1}^{n_{t}^{(m)}}(n_{t}-b+V\lambda)}" display="block"><mrow><mi>P</mi><mrow><mo>(</mo><msub><mi>e</mi><mi>m</mi></msub><mo>=</mo><mi>t</mi><mo>|</mo><msub><mi>𝒆</mi><mrow><mo>-</mo><mi>m</mi></mrow></msub><mo>,</mo><mi>𝒚</mi><mo>,</mo><mi>𝒅</mi><mo>,</mo><mi>𝒍</mi><mo>,</mo><mi>𝒛</mi><mo>,</mo><mi mathvariant="normal">Λ</mi><mo>)</mo></mrow><mo>∝</mo><mfrac><mrow><msubsup><mi>n</mi><mi>t</mi><mrow><mo>-</mo><mi>m</mi></mrow></msubsup><mo>+</mo><mi>α</mi></mrow><mrow><mi>M</mi><mo>+</mo><mrow><mi>E</mi><mo>⁢</mo><mi>α</mi></mrow></mrow></mfrac><mo>×</mo><munderover><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mi>y</mi><mo>=</mo><mn>1</mn></mrow><mi>Y</mi></munderover><mfrac><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>y</mi></mrow><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>y</mi></mrow></msub><mo>-</mo><mi>b</mi><mo>+</mo><mi>β</mi></mrow><mo>)</mo></mrow></mrow><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mi>t</mi></msub><mo>-</mo><mi>b</mi><mo>+</mo><mrow><mi>Y</mi><mo>⁢</mo><mi>β</mi></mrow></mrow><mo>)</mo></mrow></mrow></mfrac><mo>×</mo><munderover><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow><mi>D</mi></munderover><mfrac><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub><mo>-</mo><mi>b</mi><mo>+</mo><mi>γ</mi></mrow><mo>)</mo></mrow></mrow><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mi>t</mi></msub><mo>-</mo><mi>b</mi><mo>+</mo><mrow><mi>D</mi><mo>⁢</mo><mi>γ</mi></mrow></mrow><mo>)</mo></mrow></mrow></mfrac><mo>×</mo><munderover><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mi>l</mi><mo>=</mo><mn>1</mn></mrow><mi>L</mi></munderover><mfrac><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>l</mi></mrow><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>l</mi></mrow></msub><mo>-</mo><mi>b</mi><mo>+</mo><mi>η</mi></mrow><mo>)</mo></mrow></mrow><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mi>t</mi></msub><mo>-</mo><mi>b</mi><mo>+</mo><mrow><mi>L</mi><mo>⁢</mo><mi>η</mi></mrow></mrow><mo>)</mo></mrow></mrow></mfrac><mo>×</mo><munderover><mo largeop="true" movablelimits="false" symmetric="true">∏</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>V</mi></munderover><mfrac><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>k</mi></mrow><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>k</mi></mrow></msub><mo>-</mo><mi>b</mi><mo>+</mo><mi>λ</mi></mrow><mo>)</mo></mrow></mrow><mrow><msubsup><mo largeop="true" symmetric="true">∏</mo><mrow><mi>b</mi><mo>=</mo><mn>1</mn></mrow><msubsup><mi>n</mi><mi>t</mi><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msubsup></msubsup><mrow><mo>(</mo><mrow><msub><mi>n</mi><mi>t</mi></msub><mo>-</mo><mi>b</mi><mo>+</mo><mrow><mi>V</mi><mo>⁢</mo><mi>λ</mi></mrow></mrow><mo>)</mo></mrow></mrow></mfrac></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(1)</span></td></tr>
</table>
<br class="ltx_break"/>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m1" class="ltx_Math" alttext="n_{t}" display="inline"><msub><mi>n</mi><mi>t</mi></msub></math> is the number of tweets that have been assigned to the event <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m2" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m3" class="ltx_Math" alttext="M" display="inline"><mi>M</mi></math> is the total number of tweets, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m4" class="ltx_Math" alttext="n_{t,y}" display="inline"><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>y</mi></mrow></msub></math> is the number of times named entity <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m5" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math> has been associated with event <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m7" class="ltx_Math" alttext="n_{t,d}" display="inline"><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>d</mi></mrow></msub></math> is the number of times dates <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m8" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> has been associated with event <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m9" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m10" class="ltx_Math" alttext="n_{t,l}" display="inline"><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>l</mi></mrow></msub></math> is the number of times locations <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m11" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math> has been assigned with event <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m12" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m13" class="ltx_Math" alttext="n_{t,k}" display="inline"><msub><mi>n</mi><mrow><mi>t</mi><mo>,</mo><mi>k</mi></mrow></msub></math> is the number of times keyword <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m14" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> has associated with event <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m15" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, counts with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m16" class="ltx_Math" alttext="(m)" display="inline"><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></math> notation denote the counts relating to tweet <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m17" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> only. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m18" class="ltx_Math" alttext="Y,D,L,V" display="inline"><mrow><mi>Y</mi><mo>,</mo><mi>D</mi><mo>,</mo><mi>L</mi><mo>,</mo><mi>V</mi></mrow></math> are the total numbers of distinct named entities, dates, locations, and words appeared in the whole Twitter corpus respectively. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p5.m19" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> is the total number of events which needs to be set.</p>
</div>
<div id="S2.SS2.p6" class="ltx_para">
<p class="ltx_p">Once the class assignments for all events are known, we can easily
estimate the model parameters <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p6.m1" class="ltx_Math" alttext="\{\bm{\pi},\bm{\theta},\bm{\varphi},\bm{\psi},\bm{\omega}\}" display="inline"><mrow><mo>{</mo><mrow><mi>𝝅</mi><mo>,</mo><mi>𝜽</mi><mo>,</mo><mi>𝝋</mi><mo>,</mo><mi>𝝍</mi><mo>,</mo><mi>𝝎</mi></mrow><mo>}</mo></mrow></math>. We set the hyperparameters <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p6.m2" class="ltx_Math" alttext="\alpha=\beta=\gamma=\eta=\lambda=0.5" display="inline"><mrow><mi>α</mi><mo>=</mo><mi>β</mi><mo>=</mo><mi>γ</mi><mo>=</mo><mi>η</mi><mo>=</mo><mi>λ</mi><mo>=</mo><mn>0.5</mn></mrow></math> and run Gibbs sampler for
10,000 iterations and stop the iteration once the log-likelihood of
the training data converges under the learned model.
Finally we select an entity, a date, a location, and the top 2 keywords of the highest probability of every event to form a 4-tuple as the representation of that event.</p>
</div>
</div>
<div id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.3 </span>Post-processing</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p">To improve the precision of event extraction, we remove the least confident event element from the 4-tuples using the following rule. If <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p1.m1" class="ltx_Math" alttext="P(" display="inline"><mrow><mi>P</mi><mo>(</mo></mrow></math>element) is less than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p1.m2" class="ltx_Math" alttext="\frac{1}{\xi}P(S)" display="inline"><mrow><mfrac><mn>1</mn><mi>ξ</mi></mfrac><mo>⁢</mo><mi>P</mi><mo>⁢</mo><mrow><mo>(</mo><mi>S</mi><mo>)</mo></mrow></mrow></math>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p1.m3" class="ltx_Math" alttext="P(S)" display="inline"><mrow><mi>P</mi><mo>⁢</mo><mrow><mo>(</mo><mi>S</mi><mo>)</mo></mrow></mrow></math> is the sum of probabilities of the other three elements and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p1.m4" class="ltx_Math" alttext="\xi" display="inline"><mi>ξ</mi></math> is a threshold value and is set to 5 empirically, the element will be removed from the extracted results.</p>
</div>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">In this section, we first describe the Twitter corpus used in our experiments and then present how we build a baseline based on the previously proposed TwiCal system <cite class="ltx_cite">[<a href="#bib.bib10" title="Open domain event extraction from twitter" class="ltx_ref">14</a>]</cite>, the state-of-the-art open event extraction system on tweets. Finally, we present our experimental results.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Dataset</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We use the First Story Detection (FSD) dataset <cite class="ltx_cite">[<a href="#bib.bib22" title="Can twitter replace newswire for breaking news?" class="ltx_ref">10</a>]</cite> in our experiment. It consists of 2,499 tweets which are manually annotated with the corresponding event instances resulting in a total of 27 events. The tweets were published between 7th July and 12th September 2011. These events cover a range of categories, from celebrity news to accidents, and from natural disasters to science discoveries. It should be noted here that some event elements such as location is not always available in the tweets. Automatically inferring geolocation of the tweets is a challenging task and will be considered in our future work. For the tweets without time expressions, we used the tweets’ publication dates as a default.
The number of tweets for each event ranges from 2 to around 1000. We believe that in reality, events which are mentioned in very few tweets are less likely to be significant. Therefore, the dataset was filtered by removing the events which are mentioned in less than 10 tweets. This results in a final dataset containing 2468 tweets annotated with 21 events.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Baseline construction</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">The baseline we chose is TwiCal <cite class="ltx_cite">[<a href="#bib.bib10" title="Open domain event extraction from twitter" class="ltx_ref">14</a>]</cite>. The events extracted in the baseline are represented as a 3-tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m1" class="ltx_Math" alttext="\langle y,d,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math><span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>TwiCal also groups event instances into event types such as ”Sport” or ”Politics” using LinkLDA which is not considered here.</span></span></span>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m2" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math> stands for a non-location named entity, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> for a date and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m4" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> for an event phrase. We re-implemented the system and evaluate the performance of the baseline on the correctness of the exacted three elements excluding the location element.
In the baseline approach, the tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m5" class="ltx_Math" alttext="\langle y,d,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math> are extracted in the following ways.
Firstly, a named entity recognizer <cite class="ltx_cite">[<a href="#bib.bib26" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">13</a>]</cite> is employed to identify named entities. The TempEx <cite class="ltx_cite">[<a href="#bib.bib11" title="Robust temporal processing of news" class="ltx_ref">9</a>]</cite> is used to resolve temporal expressions. For each date, the baseline approach chose the entity <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m6" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math> with the strongest association with the date and form the binary tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m7" class="ltx_Math" alttext="\langle y,d\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi></mrow><mo>⟩</mo></mrow></math> to represent an event. An event phrase extractor trained on annotated tweets is required to extract event-related phrases. Due to the difficulties of re-implementing the sequence labeler without knowing the actual features set and the annotated training data, we assume all the event-related phrases are identified correctly and simply use the event trigger words annotated in the FSD corpus as <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m8" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> to form the event 3-tuples. It is worth noting that the F-measure reported for the event phrase extraction is only 64% in the baseline approach <cite class="ltx_cite">[<a href="#bib.bib10" title="Open domain event extraction from twitter" class="ltx_ref">14</a>]</cite>.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Metric</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">To evaluate the performance of the propose approach, we use <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="precison" display="inline"><mrow><mi>p</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>n</mi></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m2" class="ltx_Math" alttext="recall" display="inline"><mrow><mi>r</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>l</mi></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m3" class="ltx_Math" alttext="F-measure" display="inline"><mrow><mi>F</mi><mo>-</mo><mrow><mi>m</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>u</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>e</mi></mrow></mrow></math> as in general information extraction systems <cite class="ltx_cite">[<a href="#bib.bib27" title="Performance measures for information extraction" class="ltx_ref">8</a>]</cite>. For the 4-tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m4" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math>, the precision is calculated based on the following criteria:</p>
<ol id="I2" class="ltx_enumerate">
<li id="I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_enumerate">1.</span> 
<div id="I2.i1.p1" class="ltx_para">
<p class="ltx_p">Do the entity <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m1" class="ltx_Math" alttext="y" display="inline"><mi>y</mi></math>, location <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m2" class="ltx_Math" alttext="l" display="inline"><mi>l</mi></math> and date <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m3" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> that we have extracted refer to the same event?</p>
</div></li>
<li id="I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_enumerate">2.</span> 
<div id="I2.i2.p1" class="ltx_para">
<p class="ltx_p">Are the keywords <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i2.p1.m1" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> in accord with the event that other extracted elements <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i2.p1.m2" class="ltx_Math" alttext="y,l,d" display="inline"><mrow><mi>y</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>d</mi></mrow></math> refer to and are they informative enough to tell us what happened?</p>
</div></li>
</ol>
<p class="ltx_p">If the extracted representation does not contain keywords, its precision is calculated by checking the criteria 1. If the extracted representation contains keywords, its precision is calculated by checking both criteria 1 and 2.</p>
</div>
</div>
<div id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.4 </span>Experimental Results</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p">The number of events, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m1" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math>, in the LEM model is set to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m2" class="ltx_Math" alttext="25" display="inline"><mn>25</mn></math>. The performance of the proposed framework is presented in Table <a href="#S3.T1" title="Table 1 ‣ 3.4 Experimental Results ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The baseline re-implemented here can only output 3-tuples <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m3" class="ltx_Math" alttext="\langle y,d,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math> and we simply use the gold standard event trigger words to assign to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m4" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math>. Still, we observe that compared to the baseline approach, the performance of our proposed framework evaluated on the 4-tuple achieves nearly 17% improvement on precision. The overall improvement on F-measure is around 7.76%.</p>
</div>
<div id="S3.T1" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:216.8pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t">Method</th>
<th class="ltx_td ltx_align_center ltx_border_t">Tuple Evaluated</th>
<th class="ltx_td ltx_align_center ltx_border_t">Precision</th>
<th class="ltx_td ltx_align_center ltx_border_t">Recall</th>
<th class="ltx_td ltx_align_center ltx_border_t">F-measure</th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t">Baseline</th>
<th class="ltx_td ltx_align_center ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T1.m1" class="ltx_Math" alttext="\langle y,d,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center ltx_border_t">75%</td>
<td class="ltx_td ltx_align_center ltx_border_t">76.19%</td>
<td class="ltx_td ltx_align_center ltx_border_t">75.59%</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left">Proposed</th>
<th class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T1.m2" class="ltx_Math" alttext="\langle y,d,l\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center">96%</td>
<td class="ltx_td ltx_align_center">80.95%</td>
<td class="ltx_td ltx_align_center">87.83%</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b">Proposed</th>
<th class="ltx_td ltx_align_center ltx_border_b"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T1.m3" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center ltx_border_b">92%</td>
<td class="ltx_td ltx_align_center ltx_border_b">76.19%</td>
<td class="ltx_td ltx_align_center ltx_border_b">83.35%</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison of the performance of event extraction on the FSD dataset.</div>
</div>
</div>
<div id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.5 </span>Impact of Named Entity Recognition</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p class="ltx_p">We experimented with two approaches for named entity recognition (NER) in preprocessing. One is to use the NER tool trained specifically on the Twitter data <cite class="ltx_cite">[<a href="#bib.bib26" title="Named entity recognition in tweets: an experimental study" class="ltx_ref">13</a>]</cite>, denoted as “TW-NER” in Table <a href="#S3.T2" title="Table 2 ‣ 3.5 Impact of Named Entity Recognition ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The other uses the traditional Stanford NER to extract named entities from news articles published in the same period and then perform fuzzy matching to identify named entities from tweets. The latter method is denoted as “NW-NER” in Table <a href="#S3.T2" title="Table 2 ‣ 3.5 Impact of Named Entity Recognition ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. It can be observed from Table <a href="#S3.T2" title="Table 2 ‣ 3.5 Impact of Named Entity Recognition ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> that by using NW-NER, the performance of event extraction system is improved significantly by 7.5% and 3% respectively on F-measure when evaluated on 3-tuples (without keywords) or 4-tuples (with keywords).</p>
</div>
<div id="S3.T2" class="ltx_table">
<span class="ltx_inline-block ltx_align_center" style="width:216.8pt;height:0px;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t">Method</th>
<th class="ltx_td ltx_align_center ltx_border_t">Tuple Evaluated</th>
<th class="ltx_td ltx_align_center ltx_border_t">Precision</th>
<th class="ltx_td ltx_align_center ltx_border_t">Recall</th>
<th class="ltx_td ltx_align_center ltx_border_t">F-measure</th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_t">TW-NER</th>
<th class="ltx_td ltx_align_center ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m1" class="ltx_Math" alttext="\langle y,d,l\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center ltx_border_t">88%</td>
<td class="ltx_td ltx_align_center ltx_border_t">76.19%</td>
<td class="ltx_td ltx_align_center ltx_border_t">80.35%</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left">TW-NER</th>
<th class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m2" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center">84%</td>
<td class="ltx_td ltx_align_center">76.19%</td>
<td class="ltx_td ltx_align_center">79.90%</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left">NW-NER</th>
<th class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m3" class="ltx_Math" alttext="\langle y,d,l\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center">96%</td>
<td class="ltx_td ltx_align_center">80.95%</td>
<td class="ltx_td ltx_align_center">87.83%</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_left ltx_border_b">NW-NER</th>
<th class="ltx_td ltx_align_center ltx_border_b"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m4" class="ltx_Math" alttext="\langle y,d,l,k\rangle" display="inline"><mrow><mo>⟨</mo><mrow><mi>y</mi><mo>,</mo><mi>d</mi><mo>,</mo><mi>l</mi><mo>,</mo><mi>k</mi></mrow><mo>⟩</mo></mrow></math></th>
<td class="ltx_td ltx_align_center ltx_border_b">92%</td>
<td class="ltx_td ltx_align_center ltx_border_b">76.19%</td>
<td class="ltx_td ltx_align_center ltx_border_b">83.35%</td></tr>
</tbody>
</table>
</span>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Comparison of the performance of event extraction using different NER method.</div>
</div>
</div>
<div id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.6 </span>Impact of the Number of Events <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.m1" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math></h3>

<div id="S3.SS6.p1" class="ltx_para">
<p class="ltx_p">We need to set the number of events <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m1" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> in the LEM model. Figure <a href="#S3.F3" title="Figure 3 ‣ 3.6 Impact of the Number of Events E ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the performance of event extraction versus different value of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m2" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math>. It can be observed that the performance of the proposed framework improves with the increase of the value of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m3" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> until it reaches 25, which is close to the actual number of events in our data. If further increasing <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m4" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math>, we notice more balanced precision/recall values and a relatively stable F-measure. This shows that our LEM model is less sensitive to the number of events <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m5" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> so long as <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS6.p1.m6" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math> is set to a relatively larger value.</p>
</div>
<div id="S3.F3" class="ltx_figure"><img src="P14-2114/image003.png" id="S3.F3.g1" class="ltx_graphics ltx_centering" width="339" height="238" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>The performance of the proposed framework with different number of events <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.F3.m2" class="ltx_Math" alttext="E" display="inline"><mi>E</mi></math>.</div>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Conclusions and Future Work</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">In this paper we have proposed an unsupervised Bayesian model, called the Latent Event Model (LEM), to extract the structured representation of events from social media data. Instead of employing labeled corpora for training, the proposed model only requires the identification of named entities, locations and time expressions. After that, the model can automatically extract events which involving a named entity at certain time, location, and with event-related keywords based on the co-occurrence patterns of the event elements. Our proposed model has been evaluated on
the FSD corpus. Experimental results show our proposed framework outperforms the state-of-the-art baseline by over 7% in F-measure. In future work, we plan to investigate inferring geolocations automatically from tweets. We also intend to study a better method to infer date more accurately from tweets and explore efficient ranking strategies to rank evens extracted for a better presentation of results.</p>
</div>
</div>
<div id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p class="ltx_p">This work was funded by the National Natural Science Foundation of China (61103077), Ph.D. Programs Foundation of Ministry of Education of China for Young Faculties (20100092120031), Scientific Research Foundation for the Returned Overseas Chinese Scholars, State Education Ministry, the Fundamental Research Funds for the Central Universities, and the UK’s EPSRC grant EP/L010690/1.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">E. Benson, A. Haghighi and R. Barzilay</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Event discovery in social media feeds</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">HLT ’11</span>, <span class="ltx_text ltx_bib_place">Stroudsburg, PA, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 389–398</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-1-932432-87-9</span>,
<a href="http://dl.acm.org/citation.cfm?id=2002472.2002522" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib24" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. X. Chang and C. D. Manning</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">SUTIME: a library for recognizing and normalizing time expressions</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.SSS0.P1.p1" title="Time Expression Recognition. ‣ 2.1 Pre-processing ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
</span></li>
<li id="bib.bib23" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Gimpel, N. Schneider, B. O’Connor, D. Das, D. Mills, J. Eisenstein, M. Heilman, D. Yogatama, J. Flanigan and N. A. Smith</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Part-of-speech tagging for twitter: annotation, features, and experiments</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.SSS0.P2.p2" title="Named Entity Recognition. ‣ 2.1 Pre-processing ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>.
</span></li>
<li id="bib.bib25" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. L. Griffiths and M. Steyvers</span><span class="ltx_text ltx_bib_year">(2004)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Finding scientific topics</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 5228¨C5235</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.p4" title="2.2 Event Extraction using the Latent Event Model (LEM) ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span></li>
<li id="bib.bib19" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">R. Grishman, D. Westbrook and A. Meyers</span><span class="ltx_text ltx_bib_year">(2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Nyu’s english ace 2005 system description</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">F. Hogenboom, F. Frasincar, U. Kaymak and F. de Jong</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">An overview of event extraction from text</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 48–57</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">X. Liu, X. Zhou, Z. Fu, F. Wei and M. Zhou</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Exacting social events for tweets using a factor graph</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1692–1698</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib27" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Makhoul, F. Kubala, R. Schwartz and R. Weischedel</span><span class="ltx_text ltx_bib_year">(1999)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Performance measures for information extraction</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS3.p1" title="3.3 Evaluation Metric ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.
</span></li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">I. Mani and G. Wilson</span><span class="ltx_text ltx_bib_year">(2000)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Robust temporal processing of news</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">ACL ’00</span>, <span class="ltx_text ltx_bib_place">Stroudsburg, PA, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 69–76</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://dx.doi.org/10.3115/1075218.1075228" title="" class="ltx_ref ltx_bib_external">Link</a>,
<a href="http://dx.doi.org/10.3115/1075218.1075228" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.p1" title="3.2 Baseline construction ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
</span></li>
<li id="bib.bib22" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Petrovic, M. Osborne, R. McCreadie, C. Macdonald, I. Ounis and L. Shrimpton</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Can twitter replace newswire for breaking news?</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S2.SS1.SSS0.P2.p1" title="Named Entity Recognition. ‣ 2.1 Pre-processing ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>,
<a href="#S3.SS1.p1" title="3.1 Dataset ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
<li id="bib.bib18" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Piskorski, H. Tanev, M. Atkinson and E. Van Der Goot</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Cluster-centric approach to news event extraction</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 276–290</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Piskorski, H. Tanev and P. Oezden Wennerberg</span><span class="ltx_text ltx_bib_year">(2007)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Extracting violent events from on-line news for ontology population</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 287–300</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib26" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Ritter, S. Clark and O. Etzioni</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Named entity recognition in tweets: an experimental study</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1524–1534</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.SSS0.P2.p1" title="Named Entity Recognition. ‣ 2.1 Pre-processing ‣ 2 Methodology ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>,
<a href="#S3.SS2.p1" title="3.2 Baseline construction ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>,
<a href="#S3.SS5.p1" title="3.5 Impact of Named Entity Recognition ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.5</span></a>.
</span></li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Ritter, Mausam, O. Etzioni and S. Clark</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Open domain event extraction from twitter</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_series">KDD ’12</span>, <span class="ltx_text ltx_bib_place">New York, NY, USA</span>, <span class="ltx_text ltx_bib_pages"> pp. 1104–1112</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 978-1-4503-1462-6</span>,
<a href="http://doi.acm.org/10.1145/2339530.2339704" title="" class="ltx_ref ltx_bib_external">Link</a>,
<a href="http://dx.doi.org/10.1145/2339530.2339704" title="" class="ltx_ref doi ltx_bib_external">Document</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>,
<a href="#S3.SS2.p1" title="3.2 Baseline construction ‣ 3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>,
<a href="#S3.p1" title="3 Experiments ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
</span></li>
<li id="bib.bib17" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Tanev, J. Piskorski and M. Atkinson</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Real-time news event extraction for global crisis monitoring</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 207–218</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Simple Bayesian Modelling Approach to Event Extraction from Twitter" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 18:23:13 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
