<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>A Composite Kernel Approach for Dialog Topic Tracking withStructured Domain Knowledge from Wikipedia</title>
<!--Generated on Wed Jun 11 17:30:31 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">A Composite Kernel Approach for Dialog Topic Tracking with
<br class="ltx_break"/>Structured Domain Knowledge from Wikipedia</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Seokhwan Kim, Rafael E. Banchs, Haizhou Li
<br class="ltx_break"/>Human Language Technology Department
<br class="ltx_break"/>Institute for Infocomm Research
<br class="ltx_break"/>Singapore 138632
<br class="ltx_break"/>{<span class="ltx_text ltx_font_typewriter">kims,rembanchs,hli</span>}<span class="ltx_text ltx_font_typewriter">@i2r.a-star.edu.sg
<br class="ltx_break"/></span>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Dialog topic tracking aims at analyzing and maintaining topic transitions in on-going dialogs.
This paper proposes a composite kernel approach for dialog topic tracking to utilize various types of domain knowledge obtained from Wikipedia.
Two kernels are defined based on history sequences and context trees constructed based on the extracted features.
The experimental results show that our composite kernel approach can significantly improve the performances of topic tracking in mixed-initiative human-human dialogs.</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Human communications in real world situations interlace multiple topics which are related to each other in conversational contexts.
This fact suggests that a dialog system should be also capable of conducting multi-topic conversations with users to provide them a more natural interaction with the system.
However, the majority of previous work on dialog interfaces has focused on dealing with only a single target task.
Although some multi-task dialog systems have been proposed <cite class="ltx_cite">[<a href="#bib.bib2" title="A distributed architecture for cooperative spoken dialogue agents with coherent dialogue state and history" class="ltx_ref">10</a>, <a href="#bib.bib3" title="Extensibility verification of robust domain selection against out-of-grammar utterances in multi-domain spoken dialogue system." class="ltx_ref">6</a>, <a href="#bib.bib1" title="Approximate inference for domain detection in spoken language understanding." class="ltx_ref">4</a>]</cite>,
they have aimed at just choosing the most probable one for each input from the sub-systems, each of which is independently operated from others.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">To analyze and maintain dialog topics from a more systematic perspective in a given dialog flow, some researchers <cite class="ltx_cite">[<a href="#bib.bib6" title="Topic detection based on dialogue history" class="ltx_ref">12</a>, <a href="#bib.bib8" title="Topic identification in natural language dialogues using neural networks" class="ltx_ref">8</a>, <a href="#bib.bib7" title="Topic detection and extraction in chat" class="ltx_ref">1</a>]</cite> have considered this dialog topic identification as a separate sub-problem of dialog management and attempted to solve it with text categorization approaches for the recognized utterances in a given turn.
The major obstacle to the success of these approaches results from the differences between written texts and spoken utterances.
In most text categorization tasks, the proper category for each textual unit can be assigned based only on its own content.
However, the dialog topic at each turn can be determined not only by the user’s intentions captured from the given utterances, but also by the system’s decisions for dialog management purposes.
Thus, the text categorization approaches can only be effective for the user-initiative cases when users tend to mention the topic-related expressions explicitly in their utterances.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">The other direction of dialog topic tracking approaches made use of external knowledge sources including domain models <cite class="ltx_cite">[<a href="#bib.bib10" title="Automatic generation of domain models for call centers from noisy transcriptions" class="ltx_ref">13</a>]</cite>, heuristics <cite class="ltx_cite">[<a href="#bib.bib12" title="The hidden information state approach to dialog management" class="ltx_ref">15</a>]</cite>, and agendas <cite class="ltx_cite">[<a href="#bib.bib11" title="RavenClaw: dialog management using hierarchical task decomposition and an expectation agenda" class="ltx_ref">2</a>, <a href="#bib.bib13" title="Robust dialog management with n-best hypotheses using dialog examples and agenda." class="ltx_ref">9</a>]</cite>.
These knowledge-based methods have an advantage of dealing with system-initiative dialogs, because dialog flows can be controlled by the system based on given resources.
However, this aspect can limit the flexibility to handle the user’s responses which are contradictory to the system’s suggestions.
Moreover, these approaches face cost problems for building a sufficient amount of resources to cover broad states of complex dialogs, because these resources should be manually prepared by human experts for each specific domain.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">In this paper, we propose a composite kernel to explore various types of information obtained from Wikipedia for mixed-initiative dialog topic tracking without significant costs for building resources.
Composite kernels have been successfully applied to improve the performances in other NLP problems <cite class="ltx_cite">[<a href="#bib.bib23" title="Extracting relations with integrated information using kernel methods" class="ltx_ref">17</a>, <a href="#bib.bib24" title="A composite kernel to extract relations between entities with both flat and structured features" class="ltx_ref">16</a>]</cite> by integrating multiple individual kernels, which aim to overcome the errors occurring at one level by information from other levels.
Our composite kernel consists of a history sequence and a domain context tree kernels, both of which are composed based on similar textual units in Wikipedia articles to a given dialog context.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Dialog Topic Tracking</h2>

<div id="S2.F1" class="ltx_figure">
<table class="ltx_tabular ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math></th>
<th class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Speaker</span></th>
<th class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Utterance</span></th>
<th class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Topic Transition</span></th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_tiny">0</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify ltx_border_t" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">How can I help you?</span></td>
<td class="ltx_td ltx_align_center ltx_border_t"><span class="ltx_text ltx_font_tiny">NONE</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m2" class="ltx_Math" alttext="\rightarrow" display="inline"><mo>→</mo></math><span class="ltx_text ltx_font_tiny">NONE</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">1</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Can you recommend some good places to visit in Singapore?</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">NONE<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m3" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>ATTR</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Well if you like to visit an icon of Singapore, Merlion park will be a nice place to visit.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">2</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Merlion is a symbol for Singapore, right?</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">ATTR<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m4" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>ATTR</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Yes, we use that to symbolise Singapore.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">3</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Okay.</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">ATTR<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m5" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>ATTR</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">The lion head symbolised the founding of the island and the fish body just symbolised the humble fishing village.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">4</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">How can I get there from Orchard Road?</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">ATTR<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m6" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>TRSP</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">You can take the north-south line train from Orchard Road and stop at Raffles Place station.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">5</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Is this walking distance from the station to the destination?</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">TRSP<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m7" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>TRSP</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Yes, it’ll take only ten minutes on foot.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">6</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Alright.</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">TRSP<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m8" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>FOOD</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Well, you can also enjoy some seafoods at the riverside near the place.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
</span><span class="ltx_text ltx_font_tiny">7</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">What food do you have any recommendations to try there?</span></td>
<td class="ltx_td ltx_align_center" rowspan="2"><span class="ltx_text ltx_font_tiny">FOOD<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m9" class="ltx_Math" alttext="\rightarrow" display="inline"><mo mathsize="normal" stretchy="false">→</mo></math>FOOD</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Guide</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">If you like spicy foods, you must try chilli crab which is one of our favourite dishes here in Singapore.</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center"><span class="ltx_ERROR undefined">\hdashline</span><span class="ltx_text ltx_font_tiny">[.4pt/1pt]
8</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">Tourist</span></td>
<td class="ltx_td ltx_align_justify" style="width:113.8pt;" width="113.8pt"><span class="ltx_text ltx_font_tiny">Great! I’ll try that.</span></td>
<td class="ltx_td ltx_align_center"><span class="ltx_text ltx_font_tiny">FOOD</span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m10" class="ltx_Math" alttext="\rightarrow" display="inline"><mo>→</mo></math><span class="ltx_text ltx_font_tiny">FOOD</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_font_tiny"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Examples of dialog topic tracking on Singapore tour guide dialogs</div>
</div>
<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Dialog topic tracking can be considered as a classification problem to detect topic transitions.
The most probable pair of topics at just before and after each turn is predicted by the following classifier:
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m1" class="ltx_Math" alttext="f(x_{t})=(y_{t-1},y_{t})" display="inline"><mrow><mrow><mi>f</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mi>x</mi><mi>t</mi></msub><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>y</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub><mo>,</mo><msub><mi>y</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow></math>,
where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m2" class="ltx_Math" alttext="x_{t}" display="inline"><msub><mi>x</mi><mi>t</mi></msub></math> contains the input features obtained at a turn <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m3" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m4" class="ltx_Math" alttext="y_{t}\in C" display="inline"><mrow><msub><mi>y</mi><mi>t</mi></msub><mo>∈</mo><mi>C</mi></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m5" class="ltx_Math" alttext="C" display="inline"><mi>C</mi></math> is a closed set of topic categories.
If a topic transition occurs at <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m7" class="ltx_Math" alttext="y_{t}" display="inline"><msub><mi>y</mi><mi>t</mi></msub></math> should be different from <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m8" class="ltx_Math" alttext="y_{t-1}" display="inline"><msub><mi>y</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math>.
Otherwise, both <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m9" class="ltx_Math" alttext="y_{t}" display="inline"><msub><mi>y</mi><mi>t</mi></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m10" class="ltx_Math" alttext="y_{t-1}" display="inline"><msub><mi>y</mi><mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></math> have the same value.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example of dialog topic tracking in a given dialog fragment on Singapore tour guide domain between a tourist and a guide.
This conversation is divided into three segments, since <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p2.m1" class="ltx_Math" alttext="f" display="inline"><mi>f</mi></math> detects three topic transitions at <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p2.m2" class="ltx_Math" alttext="t_{1}" display="inline"><msub><mi>t</mi><mn>1</mn></msub></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p2.m3" class="ltx_Math" alttext="t_{4}" display="inline"><msub><mi>t</mi><mn>4</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p2.m4" class="ltx_Math" alttext="t_{6}" display="inline"><msub><mi>t</mi><mn>6</mn></msub></math>.
Then, a topic sequence of ‘Attraction’, ‘Transportation’, and ‘Food’ is obtained from the results.</p>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Wikipedia-based Composite Kernel for Dialog Topic Tracking</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">The classifier <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m1" class="ltx_Math" alttext="f" display="inline"><mi>f</mi></math> can be built on the training examples annotated with topic labels using supervised machine learning techniques.
Although some fundamental features extracted from the utterances mentioned at a given turn or in a certain number of previous turns can be used for training the model,
this information obtained solely from an ongoing dialog is not sufficient to identify not only user-initiative, but also system-initiative topic transitions.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">To overcome this limitation, we propose to leverage on Wikipedia as an external knowledge source that can be obtained without significant effort toward building resources for topic tracking.
Recently, some researchers <cite class="ltx_cite">[<a href="#bib.bib15" title="WikiTalk: a spoken wikipedia-based open-domain knowledge access system" class="ltx_ref">14</a>, <a href="#bib.bib16" title="Harvesting wikipedia knowledge to identify topics in ongoing natural language dialogs" class="ltx_ref">3</a>]</cite> have shown the feasibility of using Wikipedia knowledge to build dialog systems.
While each of these studies mainly focuses only on a single type of information including category relatedness or hyperlink connectedness,
this work aims at incorporating various knowledge obtained from Wikipedia into the model using a composite kernel method.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">Our composite kernel consists of two different kernels: a history sequence kernel and a domain context tree kernel.
Both represent the current dialog context at a given turn with a set of relevant Wikipedia paragraphs which are selected based on the cosine similarity between the term vectors of the recently mentioned utterances and each paragraph in the Wikipedia collection as follows:</p>
<table id="S3.Ex1" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex1.m1" class="ltx_Math" alttext="\text{sim}\left(x,p_{i}\right)=\frac{\phi(x)\cdot\phi(p_{i})}{|\phi(x)||\phi(p%&#10;_{i})|}," display="block"><mrow><mrow><mrow><mtext>sim</mtext><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>x</mi><mo>,</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mfrac><mrow><mrow><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mo>⋅</mo><mi>ϕ</mi></mrow><mo>⁢</mo><mrow><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mrow><mrow><mo fence="true">|</mo><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mo fence="true">|</mo></mrow><mo>⁢</mo><mrow><mo fence="true">|</mo><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mo fence="true">|</mo></mrow></mrow></mfrac></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m1" class="ltx_Math" alttext="x" display="inline"><mi>x</mi></math> is the input, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m2" class="ltx_Math" alttext="p_{i}" display="inline"><msub><mi>p</mi><mi>i</mi></msub></math> is the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m3" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>-th paragraph in the Wikipedia collection, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m4" class="ltx_Math" alttext="\phi(p_{i})" display="inline"><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><msub><mi>p</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></math> is the term vector extracted from <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m5" class="ltx_Math" alttext="p_{i}" display="inline"><msub><mi>p</mi><mi>i</mi></msub></math>.
The term vector for the input <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m6" class="ltx_Math" alttext="x" display="inline"><mi>x</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m7" class="ltx_Math" alttext="\phi(x)" display="inline"><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></math>, is computed by accumulating the weights in the previous turns as follows:</p>
<table id="S3.Ex2" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex2.m1" class="ltx_Math" alttext="\phi(x)=\left(\alpha_{1},\alpha_{2},\cdots,\alpha_{|W|}\right)\in R^{|W|}," display="block"><mrow><mrow><mrow><mi>ϕ</mi><mo>⁢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>α</mi><mn>1</mn></msub><mo>,</mo><msub><mi>α</mi><mn>2</mn></msub><mo>,</mo><mi mathvariant="normal">⋯</mi><mo>,</mo><msub><mi>α</mi><mrow><mo fence="true">|</mo><mi>W</mi><mo fence="true">|</mo></mrow></msub></mrow><mo>)</mo></mrow><mo>∈</mo><msup><mi>R</mi><mrow><mo fence="true">|</mo><mi>W</mi><mo fence="true">|</mo></mrow></msup></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m8" class="ltx_Math" alttext="\alpha_{i}=\sum_{j=0}^{h}\left(\lambda^{j}\cdot tfidf(w_{i},u_{(t-j)})\right)" display="inline"><mrow><msub><mi>α</mi><mi>i</mi></msub><mo>=</mo><mrow><msubsup><mo largeop="true" symmetric="true">∑</mo><mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow><mi>h</mi></msubsup><mrow><mo>(</mo><mrow><mrow><msup><mi>λ</mi><mi>j</mi></msup><mo>⋅</mo><mi>t</mi></mrow><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>d</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>,</mo><msub><mi>u</mi><mrow><mo>(</mo><mrow><mi>t</mi><mo>-</mo><mi>j</mi></mrow><mo>)</mo></mrow></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m9" class="ltx_Math" alttext="u_{t}" display="inline"><msub><mi>u</mi><mi>t</mi></msub></math> is the utterance mentioned in a turn <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m10" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m11" class="ltx_Math" alttext="tfidf(w_{i},u_{t})" display="inline"><mrow><mi>t</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mi>i</mi><mo>⁢</mo><mi>d</mi><mo>⁢</mo><mi>f</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>,</mo><msub><mi>u</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow></math> is the product of term frequency of a word <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m12" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m13" class="ltx_Math" alttext="u_{t}" display="inline"><msub><mi>u</mi><mi>t</mi></msub></math> and inverse document frequency of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m14" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m15" class="ltx_Math" alttext="\lambda" display="inline"><mi>λ</mi></math> is a decay factor for giving more importance to more recent turns, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m16" class="ltx_Math" alttext="|W|" display="inline"><mrow><mo fence="true">|</mo><mi>W</mi><mo fence="true">|</mo></mrow></math> is the size of word dictionary, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m17" class="ltx_Math" alttext="h" display="inline"><mi>h</mi></math> is the number of previous turns considered as dialog history features.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p class="ltx_p">After computing this relatedness between the current dialog context and every paragraph in the Wikipedia collection,
two kernel structures are constructed using the information obtained from the highly-ranked paragraphs in the Wikipedia.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>History Sequence Kernel</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">The first structure to be constructed for our composite kernel is a sequence of the most similar paragraph IDs of each turn from the beginning of the session to the current turn.
Formally, the sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m1" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> at a given turn <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m2" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> is defined as:</p>
<table id="S3.Ex3" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex3.m1" class="ltx_Math" alttext="S=(s_{0},\cdots,s_{t})," display="block"><mrow><mrow><mi>S</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>s</mi><mn>0</mn></msub><mo>,</mo><mi mathvariant="normal">⋯</mi><mo>,</mo><msub><mi>s</mi><mi>t</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m3" class="ltx_Math" alttext="s_{j}=\operatornamewithlimits{argmax}_{i}\left(\text{sim}\left(x_{j},p_{i}%&#10;\right)\right)" display="inline"><mrow><msub><mi>s</mi><mi>j</mi></msub><mo>=</mo><mrow><munder><mo movablelimits="false">argmax</mo><mi>i</mi></munder><mo>⁡</mo><mrow><mo>(</mo><mrow><mtext>sim</mtext><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mi>j</mi></msub><mo>,</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math>.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">Since our hypothesis is that the more similar the dialog histories of the two inputs are, the more similar aspects of topic transtions occur for them,
we propose a sub-sequence kernel <cite class="ltx_cite">[<a href="#bib.bib20" title="Text classification using string kernels" class="ltx_ref">11</a>]</cite> to map the data into a new feature space defined based on the similarity of each pair of history sequences as follows:</p>
<table id="S3.Ex4" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex4.m1" class="ltx_Math" alttext="K_{s}(S_{1},S_{2})=\sum_{u\in\mathcal{A}^{n}}\sum_{\mathbf{i}:u=S_{1}[\mathbf{%&#10;i}]}\sum_{\mathbf{j}:u=S_{2}[\mathbf{j}]}\lambda^{l(\mathbf{i})+l(\mathbf{j})}," display="block"><mrow><mrow><mrow><msub><mi>K</mi><mi>s</mi></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><msub><mi>S</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>u</mi><mo>∈</mo><msup><mi class="ltx_font_mathcaligraphic">𝒜</mi><mi>n</mi></msup></mrow></munder><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>𝐢</mi><mo>:</mo><mrow><mi>u</mi><mo>=</mo><mrow><msub><mi>S</mi><mn>1</mn></msub><mo>⁢</mo><mrow><mo>[</mo><mi>𝐢</mi><mo>]</mo></mrow></mrow></mrow></mrow></munder><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>𝐣</mi><mo>:</mo><mrow><mi>u</mi><mo>=</mo><mrow><msub><mi>S</mi><mn>2</mn></msub><mo>⁢</mo><mrow><mo>[</mo><mi>𝐣</mi><mo>]</mo></mrow></mrow></mrow></mrow></munder><msup><mi>λ</mi><mrow><mrow><mi>l</mi><mo>⁢</mo><mrow><mo>(</mo><mi>𝐢</mi><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>l</mi><mo>⁢</mo><mrow><mo>(</mo><mi>𝐣</mi><mo>)</mo></mrow></mrow></mrow></msup></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m1" class="ltx_Math" alttext="\mathcal{A}" display="inline"><mi class="ltx_font_mathcaligraphic">𝒜</mi></math> is a finite set of paragraph IDs, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m2" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math> is a finite sequence of paragraph IDs, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m3" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> is a subsequence of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m4" class="ltx_Math" alttext="S" display="inline"><mi>S</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m5" class="ltx_Math" alttext="S[\mathbf{j}]" display="inline"><mrow><mi>S</mi><mo>⁢</mo><mrow><mo>[</mo><mi>𝐣</mi><mo>]</mo></mrow></mrow></math> is the subsequence with the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m6" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>-th characters <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m7" class="ltx_Math" alttext="\forall i\in\mathbf{j}" display="inline"><mrow><mrow><mo>∀</mo><mi>i</mi></mrow><mo>∈</mo><mi>𝐣</mi></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m8" class="ltx_Math" alttext="l(\mathbf{i})" display="inline"><mrow><mi>l</mi><mo>⁢</mo><mrow><mo>(</mo><mi>𝐢</mi><mo>)</mo></mrow></mrow></math> is the length of the subsequence, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p2.m9" class="ltx_Math" alttext="\lambda\in(0,1)" display="inline"><mrow><mi>λ</mi><mo>∈</mo><mrow><mo>(</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>)</mo></mrow></mrow></math> is a decay factor.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Domain Context Tree Kernel</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">The other kernel incorporates more various types of domain knowledge obtained from Wikipedia into the feature space.
In this method, each instance is encoded in a tree structure constructed following the rules in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2 Domain Context Tree Kernel ‣ 3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
The root node of a tree has few children, each of which is a subtree rooted at each paragraph node in:</p>
<table id="S3.Ex5" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex5.m1" class="ltx_Math" alttext="\mathcal{P}_{t}=\{p_{i}|\text{sim}\left(x_{t},p_{i}\right)&gt;\theta\}," display="block"><mrow><mrow><msub><mi class="ltx_font_mathcaligraphic">𝒫</mi><mi>t</mi></msub><mo>=</mo><mrow><mo>{</mo><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo fence="true">|</mo><mrow><mtext>sim</mtext><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mi>t</mi></msub><mo>,</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><mo>)</mo></mrow></mrow><mo>&gt;</mo></mrow><mo>⁢</mo><mi>θ</mi></mrow><mo>}</mo></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m1" class="ltx_Math" alttext="\theta" display="inline"><mi>θ</mi></math> is a threshold value to select the relevant paragraphs.
Each subtree consists of a set of features from a given paragraph in the Wikipedia collection in a hierarchical structure.
Figure <a href="#S3.F3" title="Figure 3 ‣ 3.2 Domain Context Tree Kernel ‣ 3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows an example of a constructed tree.</p>
</div>
<div id="S3.F2" class="ltx_figure"><pre class="ltx_verbatim ltx_font_typewriter ltx_font_small">
&lt;TREE&gt;:=(ROOT &lt;PAR&gt;...&lt;PAR&gt;)
 &lt;PAR&gt;:=(PAR_ID &lt;PARENTS&gt;
             &lt;PREV_PAR&gt;&lt;NEXT_PAR&gt;&lt;LINKS&gt;)
  &lt;PARENTS&gt;:=(`PARENTS' &lt;ART&gt;&lt;SEC&gt;)
   &lt;ART&gt;:=(ART_ID &lt;ART_NAME&gt;&lt;CAT_LIST&gt;)
    &lt;ART_NAME&gt;:=(`ART_NAME' ART_NAME)
    &lt;CAT_LIST&gt;:=(`CAT' &lt;CAT&gt;...&lt;CAT&gt;)
     &lt;CAT&gt;:=(CAT_ID *)
   &lt;SEC&gt;:=(SEC_ID &lt;SEC_NAME&gt;&lt;PARENT_SEC&gt;
                  &lt;PREV_SEC&gt;&lt;NEXT_SEC&gt;)
    &lt;SEC_NAME&gt;:=(`SEC_NAME' SEC_NAME)
    &lt;PARENT_SEC&gt;:=(`PRN_SEC', PRN_SEC_ID)
    &lt;PREV_SEC&gt;:=(`PREV_SEC', PREV_SEC_NAME)
    &lt;NEXT_SEC&gt;:=(`NEXT_SEC', NEXT_SEC_NAME)
  &lt;PREV_PAR&gt;:=(`PREV_PAR', PREV_PAR_ID)
  &lt;NEXT_PAR&gt;:=(`NEXT_PAR', NEXT_PAR_ID)
  &lt;LINKS&gt;:=(`LINKS' &lt;LINK&gt;...&lt;LINK&gt;)
   &lt;LINK&gt;:=(LINK_NAME *)
</pre>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Rules for constructing a domain context tree from Wikipedia: PAR, ART, SEC, and CAT are acronyms for paragraph, article, section, and category, respectively</div>
</div>
<div id="S3.F3" class="ltx_figure"><img src="P14-2004/image001.png" id="S3.F3.g1" class="ltx_graphics" width="675" height="279" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An example of domain context tree</div>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">Since this constructed tree structure represents semantic, discourse, and structural information extracted from the similar Wikipedia paragraphs to each given instance,
we can explore these more enriched features to build the topic tracking model using a subset tree kernel <cite class="ltx_cite">[<a href="#bib.bib21" title="New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron" class="ltx_ref">5</a>]</cite> which computes the similarity between each pair of trees in the feature space as follows:</p>
<table id="S3.Ex6" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex6.m1" class="ltx_Math" alttext="K_{t}(T_{1},T_{2})=\sum_{n_{1}\in N_{T_{1}}}\sum_{n_{2}\in N_{T_{2}}}\triangle%&#10;\left(n_{1},n_{2}\right)," display="block"><mrow><mrow><mrow><msub><mi>K</mi><mi>t</mi></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>∈</mo><msub><mi>N</mi><msub><mi>T</mi><mn>1</mn></msub></msub></mrow></munder><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><msub><mi>n</mi><mn>2</mn></msub><mo>∈</mo><msub><mi>N</mi><msub><mi>T</mi><mn>2</mn></msub></msub></mrow></munder><mrow><mi mathvariant="normal">△</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m1" class="ltx_Math" alttext="N_{T}" display="inline"><msub><mi>N</mi><mi>T</mi></msub></math> is the set of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m2" class="ltx_Math" alttext="T" display="inline"><mi>T</mi></math>’s nodes, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m3" class="ltx_Math" alttext="\triangle\left(n_{1},n_{2}\right)=\sum_{i}I_{i}\left(n_{i}\right)\cdot I_{i}%&#10;\left(n_{2}\right)" display="inline"><mrow><mrow><mi mathvariant="normal">△</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>n</mi><mn>1</mn></msub><mo>,</mo><msub><mi>n</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mo largeop="true" symmetric="true">∑</mo><mi>i</mi></msub><mrow><mrow><mrow><msub><mi>I</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>n</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mo>⋅</mo><msub><mi>I</mi><mi>i</mi></msub></mrow><mo>⁢</mo><mrow><mo>(</mo><msub><mi>n</mi><mn>2</mn></msub><mo>)</mo></mrow></mrow></mrow></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m4" class="ltx_Math" alttext="I_{i}(n)" display="inline"><mrow><msub><mi>I</mi><mi>i</mi></msub><mo>⁢</mo><mrow><mo>(</mo><mi>n</mi><mo>)</mo></mrow></mrow></math> is a function that is 1 iff the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m5" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>-th tree fragment occurs with root at node <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m6" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math> and 0 otherwise.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Kernel Composition</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">In this work, a composite kernel is defined by combining the individual kernels including history sequence and domain context tree kernels, as well as the linear kernel between the vectors representing fundamental features extracted from the utterances themselves and the results of linguistic preprocessors.
The composition is performed by linear combination as follows:</p>
<table id="S5.EGx1" class="ltx_equationgroup ltx_eqn_align">

<tr id="S3.Ex7" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex7.m1" class="ltx_Math" alttext="\displaystyle K(x_{1},x_{2})=" display="inline"><mrow><mrow><mi>K</mi><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><msub><mi>x</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math></td>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex7.m2" class="ltx_Math" alttext="\displaystyle\alpha\cdot K_{l}(V_{1},V_{2})+\beta\cdot K_{s}(S_{1},S_{2})" display="inline"><mrow><mrow><mrow><mi>α</mi><mo>⋅</mo><msub><mi>K</mi><mi>l</mi></msub></mrow><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>V</mi><mn>1</mn></msub><mo>,</mo><msub><mi>V</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mrow><mi>β</mi><mo>⋅</mo><msub><mi>K</mi><mi>s</mi></msub></mrow><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>S</mi><mn>1</mn></msub><mo>,</mo><msub><mi>S</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S3.Ex8" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"/>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex8.m2" class="ltx_Math" alttext="\displaystyle+\gamma\cdot K_{t}(T_{1},T_{2})," display="inline"><mrow><mrow><mo>+</mo><mrow><mrow><mi>γ</mi><mo>⋅</mo><msub><mi>K</mi><mi>t</mi></msub></mrow><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>T</mi><mn>1</mn></msub><mo>,</mo><msub><mi>T</mi><mn>2</mn></msub></mrow><mo>)</mo></mrow></mrow></mrow><mo>,</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="V_{i}" display="inline"><msub><mi>V</mi><mi>i</mi></msub></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m2" class="ltx_Math" alttext="S_{i}" display="inline"><msub><mi>S</mi><mi>i</mi></msub></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m3" class="ltx_Math" alttext="T_{i}" display="inline"><msub><mi>T</mi><mi>i</mi></msub></math> are the feature vector, history sequence, and domain context tree of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m4" class="ltx_Math" alttext="x_{i}" display="inline"><msub><mi>x</mi><mi>i</mi></msub></math>, respectively, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m5" class="ltx_Math" alttext="K_{l}" display="inline"><msub><mi>K</mi><mi>l</mi></msub></math> is the linear kernel computed by inner product of the vectors, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m6" class="ltx_Math" alttext="\alpha" display="inline"><mi>α</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m7" class="ltx_Math" alttext="\beta" display="inline"><mi>β</mi></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m8" class="ltx_Math" alttext="\gamma" display="inline"><mi>γ</mi></math> are coefficients for linear combination of three kernels, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m9" class="ltx_Math" alttext="\alpha+\beta+\gamma=1" display="inline"><mrow><mrow><mi>α</mi><mo>+</mo><mi>β</mi><mo>+</mo><mi>γ</mi></mrow><mo>=</mo><mn>1</mn></mrow></math>.</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">To demonstrate the effectiveness of our proposed kernel method for dialog topic tracking, we performed experiments on the Singapore tour guide dialogs which consists of 35 dialog sessions collected from real human-human mixed initiative conversations related to Singapore between guides and tourists.
All the recorded dialogs with the total length of 21 hours were manually transcribed, then these transcribed dialogs with 19,651 utterances were manually annotated with the following nine topic categories: Opening, Closing, Itinerary, Accommodation, Attraction, Food, Transportation, Shopping, and Other.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">Since we aim at developing the system which acts as a guide communicating with tourist users,
an instance for both training and prediction of topic transition was created for each turn of tourists.
The annotation of an instance is a pair of previous and current topics, and the actual number of labels occurred in the dataset is 65.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">For each instance, the term vector was generated from the utterances in current user turn, previous system turn, and history turns within the window sizes <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p3.m1" class="ltx_Math" alttext="h=10" display="inline"><mrow><mi>h</mi><mo>=</mo><mn>10</mn></mrow></math>.
Then, the history sequence and tree context structures for our composite kernel were constructed based on 3,155 articles related to Singapore collected from Wikipedia database dump as of February 2013.
For the linear kernel baseline, we used the following features: n-gram words, previous system actions, and current user acts which were manually annotated.
Finally, 8,318 instances were used for training the model.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">We trained the SVM models using SVM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">light</span></sup> <span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>http://svmlight.joachims.org/</span></span></span> <cite class="ltx_cite">[<a href="#bib.bib22" title="Making large-scale SVM learning practical" class="ltx_ref">7</a>]</cite> with the following five different combinations of kernels: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m1" class="ltx_Math" alttext="K_{l}" display="inline"><msub><mi>K</mi><mi>l</mi></msub></math> only, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m2" class="ltx_Math" alttext="K_{l}" display="inline"><msub><mi>K</mi><mi>l</mi></msub></math> with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m3" class="ltx_Math" alttext="\mathcal{P}" display="inline"><mi class="ltx_font_mathcaligraphic">𝒫</mi></math> as features, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m4" class="ltx_Math" alttext="K_{l}+K_{s}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><msub><mi>K</mi><mi>s</mi></msub></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m5" class="ltx_Math" alttext="K_{l}+K_{t}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><msub><mi>K</mi><mi>t</mi></msub></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m6" class="ltx_Math" alttext="K_{l}+K_{s}+K_{t}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><msub><mi>K</mi><mi>s</mi></msub><mo>+</mo><msub><mi>K</mi><mi>t</mi></msub></mrow></math>.
The threshold value <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m7" class="ltx_Math" alttext="\theta" display="inline"><mi>θ</mi></math> for selecting <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m8" class="ltx_Math" alttext="\mathcal{P}" display="inline"><mi class="ltx_font_mathcaligraphic">𝒫</mi></math> was 0.5, and the combinations of kernels were performed with the same <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m9" class="ltx_Math" alttext="\alpha" display="inline"><mi>α</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m10" class="ltx_Math" alttext="\beta" display="inline"><mi>β</mi></math>, or <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.p4.m11" class="ltx_Math" alttext="\gamma" display="inline"><mi>γ</mi></math> coefficient values for all sub-kernels.
All the evaluations were done in five-fold cross validation to the manual annotations with two different metrics: one is accuracy of the predicted topic label for every turn, and the other is precision/recall/F-measure for each event of topic transition occurred either in the answer or the predicted result.</p>
</div>
<div id="S4.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td"/>
<th class="ltx_td ltx_align_center" colspan="3">Turn-level</th>
<th class="ltx_td ltx_align_center" colspan="3">Transition-level</th></tr>
<tr class="ltx_tr">
<td class="ltx_td"/>
<th class="ltx_td ltx_align_center" colspan="3">Accuracy</th>
<th class="ltx_td ltx_align_center">P</th>
<th class="ltx_td ltx_align_center">R</th>
<th class="ltx_td ltx_align_center">F</th></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m1" class="ltx_Math" alttext="K_{l}" display="inline"><msub><mi>K</mi><mi>l</mi></msub></math></td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_align_center ltx_border_t">62.45</td>
<td class="ltx_td ltx_border_t"/>
<td class="ltx_td ltx_align_center ltx_border_t">42.77</td>
<td class="ltx_td ltx_align_center ltx_border_t">24.77</td>
<td class="ltx_td ltx_align_center ltx_border_t">31.37</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m2" class="ltx_Math" alttext="K_{l}+\mathcal{P}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><mi class="ltx_font_mathcaligraphic">𝒫</mi></mrow></math></td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">62.44</td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">42.76</td>
<td class="ltx_td ltx_align_center">24.77</td>
<td class="ltx_td ltx_align_center">31.37</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m3" class="ltx_Math" alttext="K_{l}+K_{s}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><msub><mi>K</mi><mi>s</mi></msub></mrow></math></td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">67.19</td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">39.94</td>
<td class="ltx_td ltx_align_center">40.59</td>
<td class="ltx_td ltx_align_center">40.26</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m4" class="ltx_Math" alttext="K_{l}+K_{t}" display="inline"><mrow><msub><mi>K</mi><mi>l</mi></msub><mo>+</mo><msub><mi>K</mi><mi>t</mi></msub></mrow></math></td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">68.54</td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">45.55</td>
<td class="ltx_td ltx_align_center">35.69</td>
<td class="ltx_td ltx_align_center">40.02</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">All</td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">69.98</td>
<td class="ltx_td"/>
<td class="ltx_td ltx_align_center">44.82</td>
<td class="ltx_td ltx_align_center">39.83</td>
<td class="ltx_td ltx_align_center">42.18</td></tr>
</tbody>
</table>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Experimental Results</div>
</div>
<div id="S4.p5" class="ltx_para">
<p class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4 Evaluation ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> compares the performances of the five combinations of kernels.
When just the paragraph IDs were included as additional features, it failed to improve the performances from the baseline without any external features.
However, our proposed kernels using history sequences and domain context trees achieved significant performances improvements for both evaluation metrics.
While the history sequence kernel enhanced the coverage of the model to detect topic transitions, the domain context tree kernel contributed to produce more precise outputs.
Finally, the model combining all the kernels outperformed the baseline by 7.53% in turn-level accuracy and 10.81% in transition-level F-measure.</p>
</div>
<div id="S4.p6" class="ltx_para">
<p class="ltx_p">The error distributions in Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Evaluation ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> indicate that these performance improvements were achieved by resolving the errors not only on user-initiative topic transitions, but also on system-initiative cases, which implies the effectiveness of the structured knowledge from Wikipedia to track the topics in mixed-initiative dialogs.</p>
</div>
<div id="S4.F4" class="ltx_figure"><img src="P14-2004/image002.png" id="S4.F4.g1" class="ltx_graphics" width="676" height="474" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Error distibutions of topic transitions: FN and FP denotes false negative and false positive respectively. USR and SYS in the parentheses indicate the initiativity of the transitions.
</div>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">This paper presented a composite kernel approach for dialog topic tracking.
This approach aimed to represent various types of domain knowledge obtained from Wikipedia as two structures: history sequences and domain context trees;
then incorporate them into the model with kernel methods.
Experimental results show that the proposed approaches helped to improve the topic tracking performances in mixed-initiative human-human dialogs with respect to the baseline model.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. H. Adams and C. H. Martell</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Topic detection and extraction in chat</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 581–588</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">D. Bohus and A. Rudnicky</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">RavenClaw: dialog management using hierarchical task decomposition and an expectation agenda</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 597–600</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Breuing, U. Waltinger and I. Wachsmuth</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Harvesting wikipedia knowledge to identify topics in ongoing natural language dialogs</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 445–450</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.p2" title="3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
</span></li>
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Celikyilmaz, D. Hakkani-Tür and G. Tür</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Approximate inference for domain detection in spoken language understanding.</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 713–716</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib21" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Collins and N. Duffy</span><span class="ltx_text ltx_bib_year">(2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">New ranking algorithms for parsing and tagging: kernels over discrete structures, and the voted perceptron</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 263–270</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS2.p2" title="3.2 Domain Context Tree Kernel ‣ 3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>.
</span></li>
<li id="bib.bib3" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Ikeda, K. Komatani, T. Ogata, H. G. Okuno and H. G. Okuno</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Extensibility verification of robust domain selection against out-of-grammar utterances in multi-domain spoken dialogue system.</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 487–490</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib22" class="ltx_bibitem ltx_bib_incollection"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Joachims</span><span class="ltx_text ltx_bib_year">(1999)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Making large-scale SVM learning practical</span>.
</span>
<span class="ltx_bibblock">in <span class="ltx_text ltx_bib_editor">B. Schölkopf, C. Burges and A. Smola (Eds.)</span>, <span class="ltx_text ltx_bib_inbook">Advances in Kernel Methods - Support Vector
Learning</span>,
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 169–184</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.p4" title="4 Evaluation ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Lagus and J. Kuusisto</span><span class="ltx_text ltx_bib_year">(2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Topic identification in natural language dialogues using neural networks</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 95–102</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib13" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">C. Lee, S. Jung and G. G. Lee</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Robust dialog management with n-best hypotheses using dialog examples and agenda.</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 630–637</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib2" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Lin, H. Wang and L. Lee</span><span class="ltx_text ltx_bib_year">(1999)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A distributed architecture for cooperative spoken dialogue agents with coherent dialogue state and history</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib20" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Lodhi, C. Saunders, J. Shawe-Taylor, N. Cristianini and C. Watkins</span><span class="ltx_text ltx_bib_year">(2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Text classification using string kernels</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">The Journal of Machine Learning Research</span> <span class="ltx_text ltx_bib_volume">2</span>, <span class="ltx_text ltx_bib_pages"> pp. 419–444</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.p2" title="3.1 History Sequence Kernel ‣ 3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
</span></li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Nakata, S. Ando and A. Okumura</span><span class="ltx_text ltx_bib_year">(2002)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Topic detection based on dialogue history</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 1–7</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Roy and L. V. Subramaniam</span><span class="ltx_text ltx_bib_year">(2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Automatic generation of domain models for call centers from noisy transcriptions</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 737–744</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib15" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">G. Wilcock</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">WikiTalk: a spoken wikipedia-based open-domain knowledge access system</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 57â70</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.p2" title="3 Wikipedia-based Composite Kernel for Dialog Topic Tracking ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
</span></li>
<li id="bib.bib12" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Young, J. Schatzmann, K. Weilhammer and H. Ye</span><span class="ltx_text ltx_bib_year">(2007)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">The hidden information state approach to dialog management</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 149–152</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib24" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Zhang, J. Zhang, J. Su and G. Zhou</span><span class="ltx_text ltx_bib_year">(2006)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A composite kernel to extract relations between entities with both flat and structured features</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 825–832</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib23" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Zhao and R. Grishman</span><span class="ltx_text ltx_bib_year">(2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Extracting relations with integrated information using kernel methods</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 419–426</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ A Composite Kernel Approach for Dialog Topic Tracking with Structured Domain Knowledge from Wikipedia" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 17:30:31 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
