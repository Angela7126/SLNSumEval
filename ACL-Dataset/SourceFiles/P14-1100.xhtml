<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Spectral Unsupervised Parsing with Additive Tree Metrics</title>
<!--Generated on Tue Jun 10 18:28:07 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Spectral Unsupervised Parsing with Additive Tree Metrics</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ankur P. Parikh 
<br class="ltx_break"/>School of Computer Science 
<br class="ltx_break"/>Carnegie Mellon University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">apparikh@cs.cmu.edu</span> 
<br class="ltx_break"/>&amp;Shay B. Cohen 
<br class="ltx_break"/>School of Informatics 
<br class="ltx_break"/>University of Edinburgh 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">scohen@inf.ed.ac.uk</span> 
<br class="ltx_break"/>&amp;Eric P. Xing 
<br class="ltx_break"/>School of Computer Science 
<br class="ltx_break"/>Carnegie Mellon University 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">epxing@cs.cmu.edu
<br class="ltx_break"/></span>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">We propose a spectral approach for unsupervised constituent parsing that comes with theoretical guarantees on latent structure recovery. Our approach is grammarless â€“ we directly learn the bracketing structure of a given sentence without using a grammar model. The main algorithm is based on lifting the concept of additive tree metrics for structure learning of latent trees in the phylogenetic and machine learning communities to the case where the tree structure varies across examples. Although finding the â€œminimalâ€ latent tree is NP-hard in general, for the case of projective trees we find that it can be found using bilexical parsing algorithms. Empirically, our algorithm performs favorably compared to the constituent context model of Klein and Manning (2002) without the need for careful initialization.</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Solutions to the problem of grammar induction have been long sought after since the early days of computational linguistics and are interesting both from cognitive and engineering perspectives. Cognitively, it is more plausible to assume that children obtain only terminal strings of parse trees and not the actual parse trees. This means the unsupervised setting is a better model for studying language acquisition. From the engineering perspective, training data for unsupervised parsing exists in abundance (i.e. sentences and part-of-speech tags), and is much cheaper than the syntactically annotated data required for supervised training.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Most existing solutions treat the problem of unsupervised parsing by assuming a generative process over parse trees e.g. probabilistic context free grammarsÂ <cite class="ltx_cite">[<a href="#bib.bibx26" title="" class="ltx_ref">Jelinek et al.1992</a>]</cite>, and the constituent context modelÂ <cite class="ltx_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a>]</cite>. Learning then reduces to finding a set of parameters that are estimated by identifying a local maximum of an objective function such as the likelihoodÂ <cite class="ltx_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a>]</cite> or a variant of it <cite class="ltx_cite">[<a href="#bib.bibx36" title="" class="ltx_ref">Smith and Eisner2005</a>, <a href="#bib.bibx9" title="" class="ltx_ref">Cohen and Smith2009</a>, <a href="#bib.bibx22" title="" class="ltx_ref">Headden et al.2009</a>, <a href="#bib.bibx39" title="" class="ltx_ref">Spitkovsky et al.2010b</a>, <a href="#bib.bibx16" title="" class="ltx_ref">Gillenwater et al.2010</a>, <a href="#bib.bibx18" title="" class="ltx_ref">Golland et al.2012</a>]</cite>. Unfortunately, finding the global maximum for these objective functions is usually intractable <cite class="ltx_cite">[<a href="#bib.bibx10" title="" class="ltx_ref">Cohen and Smith2012</a>]</cite> which often leads to severe local optima problems (but see Gormley and Eisner, 2013<cite class="ltx_cite"/>). Thus, strong experimental results are often achieved by initialization techniquesÂ <cite class="ltx_cite">[<a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a>, <a href="#bib.bibx17" title="" class="ltx_ref">Gimpel and Smith2012</a>]</cite>, incremental dataset useÂ <cite class="ltx_cite">[<a href="#bib.bibx38" title="" class="ltx_ref">Spitkovsky et al.2010a</a>]</cite> and other specialized techniques to avoid local optima such as count transformsÂ <cite class="ltx_cite">[<a href="#bib.bibx40" title="" class="ltx_ref">Spitkovsky et al.2013</a>]</cite>. These approaches, while empirically promising, generally lack theoretical justification.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">On the other hand, recently proposed spectral methods approach the problem via restriction of the PCFG modelÂ <cite class="ltx_cite">[<a href="#bib.bibx24" title="" class="ltx_ref">Hsu et al.2012</a>]</cite> or matrix completionÂ <cite class="ltx_cite">[<a href="#bib.bibx3" title="" class="ltx_ref">Bailly et al.2013</a>]</cite>. These novel perspectives offer strong theoretical guarantees but are not designed to achieve competitive empirical results.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">In this paper, we suggest a different approach, to provide a first step to bridging this theory-experiment gap. More specifically, we approach unsupervised constituent parsing from the perspective of <span class="ltx_text ltx_font_italic">structure learning</span> as opposed to parameter learning. We associate each sentence with an undirected latent tree graphical model, which is a tree consisting of both observed variables (corresponding to the words in the sentence) and an additional set of latent variables that are unobserved in the data. This undirected latent tree is then directed via a <span class="ltx_text ltx_font_italic">direction mapping</span> to give the final constituent parse.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">In our framework, parsing reduces to finding the best latent structure for a given sentence. However, due to the presence of latent variables, structure learning of latent trees is substantially more complicated than in observed models. As before, one solution would be local search heuristics.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p class="ltx_p">Intuitively, however, latent tree models encode low rank dependencies among the observed variables permitting the development of â€œspectralâ€ methods that can lead to provably correct solutions. In particular we leverage the concept of additive tree metricsÂ <cite class="ltx_cite">[<a href="#bib.bibx5" title="" class="ltx_ref">Buneman1971</a>, <a href="#bib.bibx6" title="" class="ltx_ref">Buneman1974</a>]</cite> in phylogenetics and machine learning that can create a special distance metric among the observed variables as a function of the underlying spectral dependenciesÂ <cite class="ltx_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Choi et al.2011</a>, <a href="#bib.bibx37" title="" class="ltx_ref">Song et al.2011</a>, <a href="#bib.bibx1" title="" class="ltx_ref">Anandkumar et al.2011</a>, <a href="#bib.bibx25" title="" class="ltx_ref">Ishteva et al.2012</a>]</cite>. Additive tree metrics can be leveraged by â€œmeta-algorithmsâ€ such as neighbor-joiningÂ <cite class="ltx_cite">[<a href="#bib.bibx34" title="" class="ltx_ref">Saitou and Nei1987</a>]</cite> and recursive groupingÂ <cite class="ltx_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Choi et al.2011</a>]</cite> to provide consistent learning algorithms for latent trees.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p class="ltx_p">Moreover, we show that it is desirable to learn the â€œminimalâ€ latent tree based on the tree metric (â€œminimum evolutionâ€ in phylogenetics). While this criterion is in general NP-hardÂ <cite class="ltx_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Desper and Gascuel2005</a>]</cite>, for projective trees we find that a bilexical parsing algorithm can be used to find an exact solution efficiently <cite class="ltx_cite">[<a href="#bib.bibx14" title="" class="ltx_ref">Eisner and Satta1999</a>]</cite>.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p class="ltx_p">Unlike in phylogenetics and graphical models, where a single latent tree is constructed for all the data, in our case, each part of speech sequence is associated with its own parse tree. This leads to a severe data sparsity problem even for moderately long sentences. To handle this issue, we present a strategy that is inspired by ideas from kernel smoothing in the statistics communityÂ <cite class="ltx_cite">[<a href="#bib.bibx42" title="" class="ltx_ref">Zhou et al.2010</a>, <a href="#bib.bibx29" title="" class="ltx_ref">Kolar et al.2010b</a>, <a href="#bib.bibx28" title="" class="ltx_ref">Kolar et al.2010a</a>]</cite>. This allows principled sharing of samples from different but similar underlying distributions.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p class="ltx_p">We provide theoretical guarantees on the recovery of the correct underlying latent tree and characterize the associated sample complexity under our technique. Empirically we evaluate our method on data in English, German and Chinese. Our algorithm performs favorably to Klein and Manningâ€™s (2002) constituent-context model (CCM), without the need for careful initialization. In addition, we also analyze CCMâ€™s sensitivity to initialization, and compare our results to Seginerâ€™s algorithmÂ <cite class="ltx_cite">[<a href="#bib.bibx35" title="" class="ltx_ref">Seginer2007</a>]</cite>.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Learning Setting and Model</h2>

<div id="S2.F1" class="ltx_figure"><img src="P14-1100/image001.png" id="S2.F1.g1" class="ltx_graphics ltx_centering" width="415" height="140" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 1: </span>Example for the tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m3" class="ltx_Math" alttext="(\tt{DT},\tt{NN},\tt{VBD},\tt{DT},\tt{NN})" display="inline"><mrow><mo>(</mo><mrow><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi><mo>,</mo><mi>ğš…ğ™±ğ™³</mi><mo>,</mo><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi></mrow><mo>)</mo></mrow></math> showing the overview of our approach. We first learn a undirected latent tree for the sequence (left). We then apply a direction mapping <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F1.m4" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> to direct the latent tree (center). This can then easily be converted into a bracketing (right).</div>
</div>
<div id="S2.p1" class="ltx_para">
<p class="ltx_p">In this section, we detail the learning setting and a conditional tree model we learn the structure for.</p>
</div>
<div id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.1 </span>Learning Setting</h3>

<div id="S2.F2" class="ltx_figure"><img src="P14-1100/image002.png" id="S2.F2.g1" class="ltx_graphics ltx_centering" width="242" height="77" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 2: </span>Candidate constituent parses for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.F2.m2" class="ltx_Math" alttext="\bm{x}={\tt(VBD,DT,NN)}" display="inline"><mrow><mi>ğ’™</mi><mo>=</mo><mrow><mo>(</mo><mrow><mi>ğš…ğ™±ğ™³</mi><mo>,</mo><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi></mrow><mo>)</mo></mrow></mrow></math> (left-correct, right -incorrect)</div>
</div>
<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m1" class="ltx_Math" alttext="\bm{w}=(w_{1},...,w_{\ell})" display="inline"><mrow><mi>ğ’˜</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>w</mi><mi mathvariant="normal">â„“</mi></msub></mrow><mo>)</mo></mrow></mrow></math> be a vector of words corresponding to a sentence of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m2" class="ltx_Math" alttext="\ell" display="inline"><mi mathvariant="normal">â„“</mi></math>. Each <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m3" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> is represented by a vector in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m4" class="ltx_Math" alttext="\mathbb{R}^{p}" display="inline"><msup><mi>â„</mi><mi>p</mi></msup></math> for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m5" class="ltx_Math" alttext="p\in\mathbb{N}" display="inline"><mrow><mi>p</mi><mo>âˆˆ</mo><mi>â„•</mi></mrow></math>. The vector is an embedding of the word in some space, chosen from a fixed dictionary that maps word types to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m6" class="ltx_Math" alttext="\mathbb{R}^{p}" display="inline"><msup><mi>â„</mi><mi>p</mi></msup></math>.
In addition, let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m7" class="ltx_Math" alttext="\bm{x}=(x_{1},...,x_{\ell})" display="inline"><mrow><mi>ğ’™</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>x</mi><mi mathvariant="normal">â„“</mi></msub></mrow><mo>)</mo></mrow></mrow></math> be the associated vector of part-of-speech (POS) tags (i.e. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m8" class="ltx_Math" alttext="x_{i}" display="inline"><msub><mi>x</mi><mi>i</mi></msub></math> is the POS tag of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p1.m9" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math>).</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p class="ltx_p">In our learning algorithm, we assume that examples of the form <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p2.m1" class="ltx_Math" alttext="(\bm{w}^{(i)},\bm{x}^{(i)})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></math> for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p2.m2" class="ltx_Math" alttext="i\in[N]=\{1,\ldots,N\}" display="inline"><mrow><mi>i</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>N</mi></mrow><mo>}</mo></mrow></mrow></math> are given, and the goal is to predict
a bracketing parse tree for each of these examples. The word embeddings are used during the learning process, but the final decoder that the learning algorithm outputs
maps a POS tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p2.m3" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> to a parse tree. While ideally we would want to use the word information in decoding as well, much of the syntax of a sentence
is determined by the POS tags, and relatively high level of accuracy can be achieved by learning, for example, a supervised parser from POS tag sequences.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p class="ltx_p">Just like our decoder, our model assumes that the bracketing of a given sentence is a function of its POS tags. The POS tags are generated from some distribution,
followed by a deterministic generation of the bracketing parse tree. Then, latent states are generated for each bracket, and finally, the latent states at the yield of the bracketing
parse tree generate the words of the sentence (in the form of embeddings). The latent states are represented by vectors <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p3.m1" class="ltx_Math" alttext="z\in\mathbb{R}^{m}" display="inline"><mrow><mi>z</mi><mo>âˆˆ</mo><msup><mi>â„</mi><mi>m</mi></msup></mrow></math> where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS1.p3.m2" class="ltx_Math" alttext="m&lt;p" display="inline"><mrow><mi>m</mi><mo>&lt;</mo><mi>p</mi></mrow></math>.</p>
</div>
</div>
<div id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.2 </span>Intuition</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p">For intuition, consider the simple tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p1.m1" class="ltx_Math" alttext="\bm{x}=({\tt VBD},{\tt DT},{\tt NN})" display="inline"><mrow><mi>ğ’™</mi><mo>=</mo><mrow><mo>(</mo><mrow><mi>ğš…ğ™±ğ™³</mi><mo>,</mo><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi></mrow><mo>)</mo></mrow></mrow></math>.
Two candidate constituent parse structures are shown in FigureÂ <a href="#S2.F2" title="FigureÂ 2 â€£ 2.1 Learning Setting â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and the correct one is boxed in green (the other in red).
Recall that our training data contains word phrases that have the tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p1.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> e.g. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p1.m3" class="ltx_Math" alttext="\bm{w}^{(1)}={\tt{(hit,the,ball)}}" display="inline"><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mn>1</mn><mo>)</mo></mrow></msup><mo>=</mo><mrow><mo>(</mo><mrow><mi>ğš‘ğš’ğš</mi><mo>,</mo><mi>ğšğš‘ğš</mi><mo>,</mo><mi>ğš‹ğšŠğš•ğš•</mi></mrow><mo>)</mo></mrow></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p1.m4" class="ltx_Math" alttext="\bm{w}^{(2)}={\tt{(ate,an,apple)}}" display="inline"><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mn>2</mn><mo>)</mo></mrow></msup><mo>=</mo><mrow><mo>(</mo><mrow><mi>ğšŠğšğš</mi><mo>,</mo><mi>ğšŠğš—</mi><mo>,</mo><mi>ğšŠğš™ğš™ğš•ğš</mi></mrow><mo>)</mo></mrow></mrow></math>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">Intuitively, the words in the above phrases exhibit dependencies that can reveal the parse structure. The determiner (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m1" class="ltx_Math" alttext="w_{2}" display="inline"><msub><mi>w</mi><mn>2</mn></msub></math>) and the direct object (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m2" class="ltx_Math" alttext="w_{3}" display="inline"><msub><mi>w</mi><mn>3</mn></msub></math>) are correlated in that the choice of determiner depends on the plurality of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m3" class="ltx_Math" alttext="w_{3}" display="inline"><msub><mi>w</mi><mn>3</mn></msub></math>. However, the choice of verb (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m4" class="ltx_Math" alttext="w_{1}" display="inline"><msub><mi>w</mi><mn>1</mn></msub></math>) is mostly independent of the determiner. We could thus conclude that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m5" class="ltx_Math" alttext="w_{2}" display="inline"><msub><mi>w</mi><mn>2</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m6" class="ltx_Math" alttext="w_{3}" display="inline"><msub><mi>w</mi><mn>3</mn></msub></math> should be closer in the parse tree than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m7" class="ltx_Math" alttext="w_{1}" display="inline"><msub><mi>w</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m8" class="ltx_Math" alttext="w_{2}" display="inline"><msub><mi>w</mi><mn>2</mn></msub></math>, giving us the correct structure. Informally, the latent state <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m9" class="ltx_Math" alttext="z" display="inline"><mi>z</mi></math> corresponding to the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m10" class="ltx_Math" alttext="(w_{2},w_{3})" display="inline"><mrow><mo>(</mo><mrow><msub><mi>w</mi><mn>2</mn></msub><mo>,</mo><msub><mi>w</mi><mn>3</mn></msub></mrow><mo>)</mo></mrow></math> bracket would store information about the plurality of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m11" class="ltx_Math" alttext="z" display="inline"><mi>z</mi></math>, the key to the dependence between <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m12" class="ltx_Math" alttext="w_{2}" display="inline"><msub><mi>w</mi><mn>2</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m13" class="ltx_Math" alttext="w_{3}" display="inline"><msub><mi>w</mi><mn>3</mn></msub></math>. It would then be reasonable to assume that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m14" class="ltx_Math" alttext="w_{2}" display="inline"><msub><mi>w</mi><mn>2</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m15" class="ltx_Math" alttext="w_{3}" display="inline"><msub><mi>w</mi><mn>3</mn></msub></math> are independent given <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m16" class="ltx_Math" alttext="z" display="inline"><mi>z</mi></math>.</p>
</div>
</div>
<div id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.3 </span>A Conditional Latent Tree Model</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p class="ltx_p">Following this intuition, we propose to model the distribution over the latent bracketing states and words for each tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p1.m1" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> as a latent tree graphical model, which encodes conditional independences among the words given the latent states.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p class="ltx_p">Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p2.m1" class="ltx_Math" alttext="\mathcal{V}:=\{w_{1},...,w_{\ell},z_{1},...,z_{H}\}" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’±</mi><mo>:=</mo><mrow><mo>{</mo><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>w</mi><mi mathvariant="normal">â„“</mi></msub><mo>,</mo><msub><mi>z</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo>}</mo></mrow></mrow></math>, with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p2.m2" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> representing the word embeddings, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p2.m3" class="ltx_Math" alttext="z_{i}" display="inline"><msub><mi>z</mi><mi>i</mi></msub></math> representing
the latent states of the bracketings. Then, according to our base model it holds that:</p>
<table id="A0.EGx1" class="ltx_equationgroup ltx_eqn_align">

<tr id="S2.Ex1" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.Ex1.m1" class="ltx_Math" alttext="\displaystyle p(\bm{w},\bm{z}|\bm{x})" display="inline"><mrow><mi>p</mi><mrow><mo>(</mo><mi>ğ’˜</mi><mo>,</mo><mi>ğ’›</mi><mo>|</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math></td>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.Ex1.m2" class="ltx_Math" alttext="\displaystyle=\prod_{i=1}^{H}p(z_{i}|\pi_{\bm{x}}(z_{i}),\theta(\bm{x}))" display="inline"><mrow><mo>=</mo><mstyle displaystyle="true"><munderover><mo largeop="true" movablelimits="false" symmetric="true">âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>H</mi></munderover></mstyle><mi>p</mi><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>|</mo><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>,</mo><mi>Î¸</mi><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mo>)</mo></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S2.E1" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"/>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.E1.m2" class="ltx_Math" alttext="\displaystyle\times\prod_{i=1}^{\ell(\bm{x})}p(w_{i}|\pi_{\bm{x}}(w_{i}),%&#10;\theta(\bm{x}))" display="inline"><mrow><mo>Ã—</mo><mstyle displaystyle="true"><munderover><mo largeop="true" movablelimits="false" symmetric="true">âˆ</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></munderover></mstyle><mi>p</mi><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>|</mo><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>,</mo><mi>Î¸</mi><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mo>)</mo></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(1)</span></td></tr>
</table>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m1" class="ltx_Math" alttext="\pi_{\bm{x}}(\cdot)" display="inline"><mrow><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mo>â‹…</mo><mo>)</mo></mrow></mrow></math> returns the parent node index of the argument in the latent tree corresponding to tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math>.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup>At this point, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m3" class="ltx_Math" alttext="\pi" display="inline"><mi>Ï€</mi></math> refers to an arbitrary direction
of the undirected tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m4" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>.</span></span></span> If <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m5" class="ltx_Math" alttext="z" display="inline"><mi>z</mi></math> is the root, then <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m6" class="ltx_Math" alttext="\pi_{\bm{x}}(z)=\emptyset" display="inline"><mrow><mrow><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>z</mi><mo>)</mo></mrow></mrow><mo>=</mo><mi mathvariant="normal">âˆ…</mi></mrow></math>. All the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m7" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> are assumed to be leaves while all the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m8" class="ltx_Math" alttext="z_{i}" display="inline"><msub><mi>z</mi><mi>i</mi></msub></math> are internal (i.e. non-leaf) nodes.
The parameters <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m9" class="ltx_Math" alttext="\theta(\bm{x})" display="inline"><mrow><mi>Î¸</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> control the conditional probability tables. We do not commit to a certain parametric family, but see more about the assumptions we make about <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m10" class="ltx_Math" alttext="\theta" display="inline"><mi>Î¸</mi></math>
in Â§<a href="#S3.SS2" title="3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>. The parameter space is denoted <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p3.m11" class="ltx_Math" alttext="\Theta" display="inline"><mi mathvariant="normal">Î˜</mi></math>. The model assumes a factorization according to a latent-variable tree. The latent variables can incorporate
various linguistic properties, such as head information, valence of dependency being generated, and so on. This information is expected to be learned automatically from data.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p class="ltx_p">Our generative model deterministically maps a POS sequence to a bracketing via an undirected latent-variable tree.
The orientation of the tree is determined by a <span class="ltx_text ltx_font_italic"> direction mapping</span> <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p4.m1" class="ltx_Math" alttext="h_{\mathrm{dir}}(u)" display="inline"><mrow><msub><mi>h</mi><mi>dir</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math>, which is fixed during learning and decoding.
This means our decoder first identifies (given a POS sequence) an undirected tree, and then orients it by applying <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p4.m2" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> on the resulting tree (see below).</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p class="ltx_p">Define <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m1" class="ltx_Math" alttext="\mathcal{U}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’°</mi></math> to be the set of undirected latent trees where all internal nodes have degree exactly <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m2" class="ltx_Math" alttext="3" display="inline"><mn>3</mn></math> (i.e. they correspond to binary bracketing), and in addition
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m3" class="ltx_Math" alttext="h_{\mathrm{dir}}(u)" display="inline"><mrow><msub><mi>h</mi><mi>dir</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math> for any <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m4" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math> is projective (explained in the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m5" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> section). In addition, let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.p5.m6" class="ltx_Math" alttext="{\mathcal{T}}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’¯</mi></math> be the set of binary bracketings. The complete generative model that we follow is then:</p>
</div>
<div id="S2.SS3.p6" class="ltx_para">
<ul class="ltx_itemize">
<li id="I1.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i1.p1" class="ltx_para">
<p class="ltx_p">Generate a tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i1.p1.m1" class="ltx_Math" alttext="\bm{x}=(x_{1},\ldots,x_{\ell})" display="inline"><mrow><mi>ğ’™</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>x</mi><mi mathvariant="normal">â„“</mi></msub></mrow><mo>)</mo></mrow></mrow></math></p>
</div></li>
<li id="I1.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i2.p1" class="ltx_para">
<p class="ltx_p">Decide on <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i2.p1.m1" class="ltx_Math" alttext="u(\bm{x})\in\mathcal{U}" display="inline"><mrow><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math>, the undirected latent tree that <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i2.p1.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> maps to.</p>
</div></li>
<li id="I1.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i3.p1" class="ltx_para">
<p class="ltx_p">Set <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i3.p1.m1" class="ltx_Math" alttext="t\in{\mathcal{T}}" display="inline"><mrow><mi>t</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’¯</mi></mrow></math> by computing <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i3.p1.m2" class="ltx_Math" alttext="t=h_{\mathrm{dir}}(u)" display="inline"><mrow><mi>t</mi><mo>=</mo><mrow><msub><mi>h</mi><mi>dir</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></mrow></math>.</p>
</div></li>
<li id="I1.i4" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i4.p1" class="ltx_para">
<p class="ltx_p">Set <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i4.p1.m1" class="ltx_Math" alttext="\theta\in\Theta" display="inline"><mrow><mi>Î¸</mi><mo>âˆˆ</mo><mi mathvariant="normal">Î˜</mi></mrow></math> by computing <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i4.p1.m2" class="ltx_Math" alttext="\theta=\theta(\bm{x})" display="inline"><mrow><mi>Î¸</mi><mo>=</mo><mrow><mi>Î¸</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow></math>.</p>
</div></li>
<li id="I1.i5" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I1.i5.p1" class="ltx_para">
<p class="ltx_p">Generate a tuple <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i5.p1.m1" class="ltx_Math" alttext="\bm{v}=(w_{1},\ldots,w_{\ell},z_{1},...,z_{H})" display="inline"><mrow><mi>ğ’—</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>w</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>w</mi><mi mathvariant="normal">â„“</mi></msub><mo>,</mo><msub><mi>z</mi><mn>1</mn></msub><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><msub><mi>z</mi><mi>H</mi></msub></mrow><mo>)</mo></mrow></mrow></math> where <math xmlns="http://www.w3.org/1998/Math/MathML" id="I1.i5.p1.m2" class="ltx_Math" alttext="w_{i}\in\mathbb{R}^{p},z_{j}\in\mathbb{R}^{m}" display="inline"><mrow><mrow><msub><mi>w</mi><mi>i</mi></msub><mo>âˆˆ</mo><msup><mi>â„</mi><mi>p</mi></msup></mrow><mo>,</mo><mrow><msub><mi>z</mi><mi>j</mi></msub><mo>âˆˆ</mo><msup><mi>â„</mi><mi>m</mi></msup></mrow></mrow></math> according to Eq.Â <a href="#S2.E1" title="(1) â€£ 2.3 A Conditional Latent Tree Model â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div></li>
</ul>
<p class="ltx_p">See Figure 1 (left) for an example.</p>
</div>
<div id="S2.SS3.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">The Direction Mapping <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.m1" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>.</h4>

<div id="S2.SS3.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">Generating a bracketing via an undirected tree enables us to build on existing
methods for structure learning of latent-tree graphical models <cite class="ltx_cite">[<a href="#bib.bibx7" title="" class="ltx_ref">Choi et al.2011</a>, <a href="#bib.bibx1" title="" class="ltx_ref">Anandkumar et al.2011</a>]</cite>.
Our learning algorithm focuses on recovering the undirected tree based for the generative model that was described above. This undirected tree
is converted into a directed tree by applying <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p1.m1" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>. The mapping <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p1.m2" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> works in three steps:</p>
</div>
<div id="S2.SS3.SSS0.P1.p2" class="ltx_para">
<ul class="ltx_itemize">
<li id="I2.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I2.i1.p1" class="ltx_para">
<p class="ltx_p">It first chooses a top bracket <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m1" class="ltx_Math" alttext="([1,R-1],[R,\ell])" display="inline"><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mn>1</mn><mo>,</mo><mrow><mi>R</mi><mo>-</mo><mn>1</mn></mrow></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mi>R</mi><mo>,</mo><mi mathvariant="normal">â„“</mi></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow></math> where <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m2" class="ltx_Math" alttext="R" display="inline"><mi>R</mi></math> is the mid-point of the bracket and <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i1.p1.m3" class="ltx_Math" alttext="\ell" display="inline"><mi mathvariant="normal">â„“</mi></math> is the length of the sentence.</p>
</div></li>
<li id="I2.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I2.i2.p1" class="ltx_para">
<p class="ltx_p">It marks the edge <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i2.p1.m1" class="ltx_Math" alttext="e_{i,j}" display="inline"><msub><mi>e</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></math> that splits the tree according to the top bracket as the â€œroot edgeâ€ (marked in red in FigureÂ <a href="#S2.F1" title="FigureÂ 1 â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(center))</p>
</div></li>
<li id="I2.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I2.i3.p1" class="ltx_para">
<p class="ltx_p">It then creates <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i3.p1.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> from <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i3.p1.m2" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> by directing the tree outward from <math xmlns="http://www.w3.org/1998/Math/MathML" id="I2.i3.p1.m3" class="ltx_Math" alttext="e_{i,j}" display="inline"><msub><mi>e</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></math> as shown in FigureÂ <a href="#S2.F1" title="FigureÂ 1 â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>(center)</p>
</div></li>
</ul>
</div>
<div id="S2.SS3.SSS0.P1.p3" class="ltx_para">
<p class="ltx_p">The resulting <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m1" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> is a binary bracketing parse tree.
As implied by the above definition of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m2" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>, selecting which edge is the root can be interpreted as determining the top bracket of the constituent parse.
For example, in FigureÂ <a href="#S2.F1" title="FigureÂ 1 â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the top bracket is <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m3" class="ltx_Math" alttext="([1,2],[3,5])=([{\tt DT},{\tt NN}],[{\tt VBD},{\tt DT},{\tt NN}])" display="inline"><mrow><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mn>3</mn><mo>,</mo><mn>5</mn></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow><mo>=</mo><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mi>ğš…ğ™±ğ™³</mi><mo>,</mo><mi>ğ™³ğšƒ</mi><mo>,</mo><mi>ğ™½ğ™½</mi></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow></mrow></math>. Note that the â€œrootâ€ edge <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m4" class="ltx_Math" alttext="e_{z_{1},z_{2}}" display="inline"><msub><mi>e</mi><mrow><msub><mi>z</mi><mn>1</mn></msub><mo>,</mo><msub><mi>z</mi><mn>2</mn></msub></mrow></msub></math> partitions the leaves into precisely this bracketing. As indicated in the above section, we restrict the set of undirected trees to be those such that after applying <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m5" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> the resulting <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS3.SSS0.P1.p3.m6" class="ltx_Math" alttext="t" display="inline"><mi>t</mi></math> is projective i.e. there are no crossing brackets. In Â§<a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, we discuss an effective heuristic to find the top bracket without supervision.</p>
</div>
</div>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Spectral Learning Algorithm based on Additive Tree Metrics</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">Our goal is to recover <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m1" class="ltx_Math" alttext="t\in{\mathcal{T}}" display="inline"><mrow><mi>t</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’¯</mi></mrow></math> for tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> using the data <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m3" class="ltx_Math" alttext="\mathcal{D}=[(\bm{w}^{(i)},\bm{x}^{(i)})]_{i=1}^{N}" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>=</mo><msubsup><mrow><mo>[</mo><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow><mo>]</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup></mrow></math>. To get an intuition about the algorithm, consider a partition of the set of examples
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m4" class="ltx_Math" alttext="\mathcal{D}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></math> into <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m5" class="ltx_Math" alttext="\mathcal{D}(\bm{x})=\{(\bm{w}^{(i)},\bm{x}^{(i)})\in\mathcal{D}|\bm{x}^{(i)}=%&#10;\bm{x}\}" display="inline"><mrow><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mrow><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></mrow><mo separator="true">|</mo><mrow><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><mi>ğ’™</mi></mrow></mrow><mo>}</mo></mrow></mrow></math>, i.e. each section in the partition has an identical sequence of part of speech tags. Assume for this section <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p1.m6" class="ltx_Math" alttext="|\mathcal{D}(\bm{x})|" display="inline"><mrow><mo fence="true">|</mo><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo fence="true">|</mo></mrow></math> is large (we address the data sparsity issue in Â§<a href="#S3.SS4" title="3.4 Estimation of d from Sparse Data â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>).</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">We can then proceed by learning how to map a POS sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p2.m1" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> to a tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p2.m2" class="ltx_Math" alttext="t\in{\mathcal{T}}" display="inline"><mrow><mi>t</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’¯</mi></mrow></math> (through <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p2.m3" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math>) by focusing only on examples in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p2.m4" class="ltx_Math" alttext="\mathcal{D}(\bm{x})" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">Directly attempting to maximize the likelihood unfortunately results in an intractable optimization problem and greedy heuristics are often employedÂ <cite class="ltx_cite">[<a href="#bib.bibx20" title="" class="ltx_ref">Harmeling and Williams2011</a>]</cite>. Instead we propose a method that is provably consistent and returns a tree that can be mapped to a bracketing using <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p3.m1" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p class="ltx_p">If all the variables were observed, then the Chow-Liu algorithm <cite class="ltx_cite">[<a href="#bib.bibx8" title="" class="ltx_ref">Chow and Liu1968</a>]</cite> could be used to find the most likely tree structure <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p4.m1" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math>. The Chow-Liu algorithm essentially computes the distances among all pairs of variables (the negative of the mutual information) and then finds the minimum cost tree. However, the fact that the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.p4.m2" class="ltx_Math" alttext="z_{i}" display="inline"><msub><mi>z</mi><mi>i</mi></msub></math> are latent variables makes this strategy substantially more complicated. In particular, it becomes challenging to compute the distances among pairs of latent variables. What is needed is a â€œspecialâ€ distance function that allows us to reverse engineer the distances among the latent variables given the distances among the observed variables. This is the key idea behind additive tree metrics that are the basis of our approach.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p class="ltx_p">In the following sections, we describe the key steps to our method. Â§3.1 and Â§3.2 largely describe existing background on additive tree metrics and latent tree structure learning, while Â§3.3 and Â§3.4 discuss novel aspects that are unique to our problem.</p>
</div>
<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Additive Tree Metrics</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m1" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> be the true undirected tree of sentence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> and assume the nodes <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m3" class="ltx_Math" alttext="\mathcal{V}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’±</mi></math> to be indexed by <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m4" class="ltx_Math" alttext="[M]=\{1,\ldots,M\}" display="inline"><mrow><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow><mo>=</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mi>M</mi></mrow><mo>}</mo></mrow></mrow></math> such that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m5" class="ltx_Math" alttext="M=|\mathcal{V}|=H+\ell" display="inline"><mrow><mi>M</mi><mo>=</mo><mrow><mo fence="true">|</mo><mi class="ltx_font_mathcaligraphic">ğ’±</mi><mo fence="true">|</mo></mrow><mo>=</mo><mrow><mi>H</mi><mo>+</mo><mi mathvariant="normal">â„“</mi></mrow></mrow></math>. Furthermore, let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m6" class="ltx_Math" alttext="v\in\mathcal{V}" display="inline"><mrow><mi>v</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’±</mi></mrow></math> refer to a node in the undirected tree (either observed or latent). We assume the existence of a distance function that allows us to compute distances between pairs of nodes. For example, as we see in Â§<a href="#S3.SS2" title="3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a> we will define the distance <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m7" class="ltx_Math" alttext="d(i,j)" display="inline"><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> to be a function of the covariance matrix <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m8" class="ltx_Math" alttext="\mathbb{E}[v_{i}v_{j}^{\top}|u(\bm{x}),\theta(\bm{x})]" display="inline"><mrow><mi>ğ”¼</mi><mrow><mo>[</mo><msub><mi>v</mi><mi>i</mi></msub><msubsup><mi>v</mi><mi>j</mi><mo>âŠ¤</mo></msubsup><mo>|</mo><mi>u</mi><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mo>,</mo><mi>Î¸</mi><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mo>]</mo></mrow></mrow></math>. Thus if <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m9" class="ltx_Math" alttext="v_{i}" display="inline"><msub><mi>v</mi><mi>i</mi></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p1.m10" class="ltx_Math" alttext="v_{j}" display="inline"><msub><mi>v</mi><mi>j</mi></msub></math> are both observed variables, the distance can be directly computed from the data.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">Moreover, the metrics we construct are such that they are <span class="ltx_text ltx_font_italic">tree additive</span>, defined below:</p>
</div>
<div id="Thmdefinition1" class="ltx_theorem ltx_theorem_definition">
<h6 class="ltx_title ltx_runin ltx_font_bold ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem">Definition 1</span></h6>
<div id="Thmdefinition1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">A function <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m1" class="ltx_Math" alttext="d_{u(\bm{x})}:[M]\times[M]\rightarrow\mathbb{R}" display="inline"><mrow><msub><mi>d</mi><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></msub><mo mathvariant="normal">:</mo><mrow><mrow><mrow><mo mathvariant="italic">[</mo><mi>M</mi><mo mathvariant="italic">]</mo></mrow><mo mathvariant="normal">Ã—</mo><mrow><mo mathvariant="italic">[</mo><mi>M</mi><mo mathvariant="italic">]</mo></mrow></mrow><mo mathvariant="normal">â†’</mo><mi>â„</mi></mrow></mrow></math> is an <em class="ltx_emph">additive tree metric</em>Â <cite class="ltx_cite">[<a href="#bib.bibx15" title="" class="ltx_ref">ErdÃµs et al.1999</a>]</cite> for the undirected tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m2" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></math> if it is a distance metric,<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup>This means that it satisfies <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m3" class="ltx_Math" alttext="d(i,j)=0" display="inline"><mrow><mrow><mi>d</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mrow><mi>i</mi><mo mathvariant="italic">,</mo><mi>j</mi></mrow><mo mathvariant="italic">)</mo></mrow></mrow><mo mathvariant="normal">=</mo><mn mathvariant="normal">0</mn></mrow></math> if and only if <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m4" class="ltx_Math" alttext="i=j" display="inline"><mrow><mi>i</mi><mo mathvariant="normal">=</mo><mi>j</mi></mrow></math>, the triangle inequality and is also symmetric.</span></span></span> and furthermore, <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m5" class="ltx_Math" alttext="\forall i,j\in[M]" display="inline"><mrow><mrow><mrow><mo mathvariant="normal">âˆ€</mo><mi>i</mi></mrow><mo mathvariant="italic">,</mo><mi>j</mi></mrow><mo mathvariant="normal">âˆˆ</mo><mrow><mo mathvariant="italic">[</mo><mi>M</mi><mo mathvariant="italic">]</mo></mrow></mrow></math> the following relation holds:</span></p>
<table id="A0.EGx2" class="ltx_equationgroup ltx_eqn_align">

<tr id="S3.E2" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E2.m1" class="ltx_Math" alttext="\displaystyle d_{u(\bm{x})}(i,j)=\sum_{(a,b)\in\mathrm{path}_{u(\bm{x})}(i,j)}%&#10;d_{u(\bm{x})}(a,b)" display="inline"><mrow><mrow><msub><mi>d</mi><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><munder><mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo><mrow><mrow><mo>(</mo><mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow><mo>)</mo></mrow><mo>âˆˆ</mo><mrow><msub><mi>path</mi><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></mrow></munder></mstyle><mrow><msub><mi>d</mi><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>a</mi><mo>,</mo><mi>b</mi></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(2)</span></td></tr>
</table>
<p class="ltx_p"><span class="ltx_text ltx_font_italic">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m6" class="ltx_Math" alttext="\mathrm{path}_{u(\bm{x})}(i,j)" display="inline"><mrow><msub><mi mathvariant="normal">path</mi><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></msub><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mrow><mi>i</mi><mo mathvariant="italic">,</mo><mi>j</mi></mrow><mo mathvariant="italic">)</mo></mrow></mrow></math> is the set of all the edges in the (undirected) path from <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m7" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> to <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m8" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> in the tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmdefinition1.p1.m9" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></math>.</span></p>
</div>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">As we describe below, given the tree structure, the additive tree metric property allows us to compute â€œbackwardsâ€ the distances among the latent variables as a function of the distances among the observed variables.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p class="ltx_p">Define <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m1" class="ltx_Math" alttext="\bm{D}" display="inline"><mi>ğ‘«</mi></math> to be the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m2" class="ltx_Math" alttext="M\times M" display="inline"><mrow><mi>M</mi><mo>Ã—</mo><mi>M</mi></mrow></math> distance matrix among the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m3" class="ltx_Math" alttext="M" display="inline"><mi>M</mi></math> variables, i.e. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m4" class="ltx_Math" alttext="D_{ij}=d_{u(\bm{x})}(i,j)" display="inline"><mrow><msub><mi>D</mi><mrow><mi>i</mi><mo>â¢</mo><mi>j</mi></mrow></msub><mo>=</mo><mrow><msub><mi>d</mi><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></mrow></math>. Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m5" class="ltx_Math" alttext="\bm{D}_{WW}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>W</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m6" class="ltx_Math" alttext="\bm{D}_{ZW}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>Z</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math> (equal to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m7" class="ltx_Math" alttext="\bm{D}_{WZ}^{\top}" display="inline"><msubsup><mi>ğ‘«</mi><mrow><mi>W</mi><mo>â¢</mo><mi>Z</mi></mrow><mo>âŠ¤</mo></msubsup></math>), and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m8" class="ltx_Math" alttext="\bm{D}_{ZZ}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>Z</mi><mo>â¢</mo><mi>Z</mi></mrow></msub></math> indicate the word-word, latent-word and latent-latent sub-blocks of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m9" class="ltx_Math" alttext="\bm{D}" display="inline"><mi>ğ‘«</mi></math> respectively. In addition, since <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m10" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> is assumed to be known from context, we denote <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m11" class="ltx_Math" alttext="d_{u(\bm{x})}(i,j)" display="inline"><mrow><msub><mi>d</mi><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> just by <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p4.m12" class="ltx_Math" alttext="d(i,j)" display="inline"><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math>.</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p class="ltx_p">Given the fact that the distance between a pair of nodes is a function of the random variables they represent (according to the true model), only <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p5.m1" class="ltx_Math" alttext="\bm{D}_{WW}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>W</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math> can be empirically estimated
from data. However, if the underlying tree structure is known, then DefinitionÂ <a href="#A0.EGx2" title="Definition 1 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> can be leveraged to compute <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p5.m2" class="ltx_Math" alttext="\bm{D}_{ZZ}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>Z</mi><mo>â¢</mo><mi>Z</mi></mrow></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p5.m3" class="ltx_Math" alttext="\bm{D}_{ZW}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>Z</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math> as we show below.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p class="ltx_p">We first show how to compute <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m1" class="ltx_Math" alttext="d(i,j)" display="inline"><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> for all <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m2" class="ltx_Math" alttext="i,j" display="inline"><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></math> such that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m3" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m4" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> are adjacent to each other in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m5" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>, based only on observed nodes.
It then follows that the other elements of the distance matrix can be computed based on DefinitionÂ <a href="#A0.EGx2" title="Definition 1 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. To show how to compute distances
between adjacent nodes, consider the two cases: <span class="ltx_text ltx_font_bold">(1)</span> <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m6" class="ltx_Math" alttext="(i,j)" display="inline"><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></math> is a leaf edge; <span class="ltx_text ltx_font_bold">(2)</span> <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.p6.m7" class="ltx_Math" alttext="(i,j)" display="inline"><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></math> is an internal edge.</p>
</div>
<div id="S3.F3" class="ltx_figure">
<table style="width:100%;">
<tr>
<td class="ltx_subfigure">
<div id="S3.F3.fig1" class="ltx_figure ltx_align_center"><img src="P14-1100/image003.png" id="S3.F3.g1" class="ltx_graphics" width="101" height="106" alt=""/>
</div></td>
<td class="ltx_subfigure">
<div id="S3.F3.fig2" class="ltx_figure ltx_align_center"><img src="P14-1100/image004.png" id="S3.F3.g2" class="ltx_graphics" width="146" height="104" alt=""/>
</div></td></tr>
</table>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">FigureÂ 3: </span>Two types of edges in general undirected latent trees. (a) leaf edge, (b) internal edge</div>
</div>
<div id="S3.SS1.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Case 1 (leaf edge, figureÂ <a href="#S3.F3.fig1" title="FigureÂ 3 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)</h4>

<div id="S3.SS1.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">Assume without loss of generality that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m1" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> is the leaf and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m2" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> is an internal latent node.
Then <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m3" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> must have exactly two other neighbors <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m4" class="ltx_Math" alttext="a\in[M]" display="inline"><mrow><mi>a</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m5" class="ltx_Math" alttext="b\in[M]" display="inline"><mrow><mi>b</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math>. Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m6" class="ltx_Math" alttext="A" display="inline"><mi>A</mi></math> denote the set of nodes that are closer to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m7" class="ltx_Math" alttext="a" display="inline"><mi>a</mi></math> than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m8" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> and similarly let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m9" class="ltx_Math" alttext="B" display="inline"><mi>B</mi></math> denote the set of nodes that are closer to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m10" class="ltx_Math" alttext="b" display="inline"><mi>b</mi></math> than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m11" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>. Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m12" class="ltx_Math" alttext="A^{\ast}" display="inline"><msup><mi>A</mi><mo>âˆ—</mo></msup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m13" class="ltx_Math" alttext="B^{\ast}" display="inline"><msup><mi>B</mi><mo>âˆ—</mo></msup></math> denote all the leaves (word nodes) in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m14" class="ltx_Math" alttext="A" display="inline"><mi>A</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m15" class="ltx_Math" alttext="B" display="inline"><mi>B</mi></math> respectively. Then using path additivity (DefinitionÂ <a href="#A0.EGx2" title="Definition 1 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), it can be shown that for any <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P1.p1.m16" class="ltx_Math" alttext="a^{\ast}\in A^{\ast},b^{\ast}\in B^{\ast}" display="inline"><mrow><mrow><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>A</mi><mo>âˆ—</mo></msup></mrow><mo>,</mo><mrow><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>B</mi><mo>âˆ—</mo></msup></mrow></mrow></math> it holds that:</p>
<table id="A0.EGx3" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.E3" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E3.m1" class="ltx_Math" alttext="\displaystyle d(i,j)=\frac{1}{2}\left(d(j,a^{\ast})+d(j,b^{\ast})-d(a^{\ast},b%&#10;^{\ast})\right)" display="inline"><mrow><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mstyle displaystyle="true"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle><mo>â¢</mo><mrow><mo>(</mo><mrow><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><msup><mi>a</mi><mo>âˆ—</mo></msup></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><msup><mi>b</mi><mo>âˆ—</mo></msup></mrow><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>b</mi><mo>âˆ—</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(3)</span></td></tr>
</table>
</div>
<div id="S3.SS1.SSS0.P1.p2" class="ltx_para">
<p class="ltx_p">Note that the right-hand side only depends on distances between observed random variables.</p>
</div>
</div>
<div id="S3.SS1.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Case 2 (internal edge, figureÂ <a href="#S3.F3.fig2" title="FigureÂ 3 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>)</h4>

<div id="S3.SS1.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">Both <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m1" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m2" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> are internal nodes. In this case, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m3" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> has exactly two other neighbors <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m4" class="ltx_Math" alttext="a\in[M]" display="inline"><mrow><mi>a</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m5" class="ltx_Math" alttext="b\in[M]" display="inline"><mrow><mi>b</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math>, and similarly, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m6" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> has exactly other two neighbors <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m7" class="ltx_Math" alttext="g\in[M]" display="inline"><mrow><mi>g</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m8" class="ltx_Math" alttext="h\in[M]" display="inline"><mrow><mi>h</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>M</mi><mo>]</mo></mrow></mrow></math>. Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m9" class="ltx_Math" alttext="A" display="inline"><mi>A</mi></math> denote the set of nodes closer to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m10" class="ltx_Math" alttext="a" display="inline"><mi>a</mi></math> than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m11" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>, and analogously for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m12" class="ltx_Math" alttext="B" display="inline"><mi>B</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m13" class="ltx_Math" alttext="G" display="inline"><mi>G</mi></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m14" class="ltx_Math" alttext="H" display="inline"><mi>H</mi></math>.
Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m15" class="ltx_Math" alttext="A^{\ast}" display="inline"><msup><mi>A</mi><mo>âˆ—</mo></msup></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m16" class="ltx_Math" alttext="B^{\ast}" display="inline"><msup><mi>B</mi><mo>âˆ—</mo></msup></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m17" class="ltx_Math" alttext="G^{\ast}" display="inline"><msup><mi>G</mi><mo>âˆ—</mo></msup></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m18" class="ltx_Math" alttext="H^{\ast}" display="inline"><msup><mi>H</mi><mo>âˆ—</mo></msup></math> refer to the leaves in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m19" class="ltx_Math" alttext="A,B,G" display="inline"><mrow><mi>A</mi><mo>,</mo><mi>B</mi><mo>,</mo><mi>G</mi></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m20" class="ltx_Math" alttext="H" display="inline"><mi>H</mi></math> respectively. Then for any <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m21" class="ltx_Math" alttext="a^{\ast}\in A^{\ast}" display="inline"><mrow><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>A</mi><mo>âˆ—</mo></msup></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m22" class="ltx_Math" alttext="b^{\ast}\in B^{\ast}" display="inline"><mrow><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>B</mi><mo>âˆ—</mo></msup></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m23" class="ltx_Math" alttext="g^{\ast}\in G^{\ast}" display="inline"><mrow><msup><mi>g</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>G</mi><mo>âˆ—</mo></msup></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p1.m24" class="ltx_Math" alttext="h^{\ast}\in H^{\ast}" display="inline"><mrow><msup><mi>h</mi><mo>âˆ—</mo></msup><mo>âˆˆ</mo><msup><mi>H</mi><mo>âˆ—</mo></msup></mrow></math> it can be shown that:</p>
<table id="A0.EGx4" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex2" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex2.m2" class="ltx_Math" alttext="\displaystyle d(i,j)=\frac{1}{4}\bigg(d(a^{\ast},g^{\ast})+d(a^{\ast},h^{\ast}%&#10;)+d(b^{\ast},g^{\ast})" display="inline"><mrow><mi>d</mi><mrow><mo>(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>)</mo></mrow><mo>=</mo><mstyle displaystyle="true"><mfrac><mn>1</mn><mn>4</mn></mfrac></mstyle><mrow><mo mathsize="2.0em" stretchy="false">(</mo><mi>d</mi><mrow><mo>(</mo><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>g</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow><mo>+</mo><mi>d</mi><mrow><mo>(</mo><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>h</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow><mo>+</mo><mi>d</mi><mrow><mo>(</mo><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>g</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S3.E4" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E4.m2" class="ltx_Math" alttext="\displaystyle\quad\,\,+d(b^{\ast},h^{\ast})-2d(a^{\ast},b^{\ast})-2d(g^{\ast},%&#10;h^{\ast})\bigg)" display="inline"><mrow><mpadded width="+3.4pt"><mi mathvariant="normal">â€</mi></mpadded><mo>+</mo><mi>d</mi><mrow><mo>(</mo><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>h</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow><mo>-</mo><mn>2</mn><mi>d</mi><mrow><mo>(</mo><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow><mo>-</mo><mn>2</mn><mi>d</mi><mrow><mo>(</mo><msup><mi>g</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>h</mi><mo>âˆ—</mo></msup><mo>)</mo></mrow><mo mathsize="2.0em" stretchy="false">)</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(4)</span></td></tr>
</table>
</div>
<div id="S3.SS1.SSS0.P2.p2" class="ltx_para">
<p class="ltx_p">Empirically, one can obtain a more robust empirical estimate <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p2.m1" class="ltx_Math" alttext="\widehat{d}(i,j)" display="inline"><mrow><mover accent="true"><mi>d</mi><mo>^</mo></mover><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> by averaging over all valid choices of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p2.m2" class="ltx_Math" alttext="a^{\ast},b^{\ast}" display="inline"><mrow><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>b</mi><mo>âˆ—</mo></msup></mrow></math> in Eq.Â <a href="#S3.E3" title="(3) â€£ Case 1 (leaf edge, figureÂ ) â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and all valid choices of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS1.SSS0.P2.p2.m3" class="ltx_Math" alttext="a^{\ast},b^{\ast},g^{\ast},h^{\ast}" display="inline"><mrow><msup><mi>a</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>b</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>g</mi><mo>âˆ—</mo></msup><mo>,</mo><msup><mi>h</mi><mo>âˆ—</mo></msup></mrow></math> in Eq.Â <a href="#S3.E4" title="(4) â€£ Case 2 (internal edge, figureÂ ) â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>Â <cite class="ltx_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Desper and Gascuel2005</a>]</cite>.</p>
</div>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Constructing a Spectral Additive Metric</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">In constructing our distance metric, we begin with the following assumption on the distribution in Eq.Â <a href="#S2.E1" title="(1) â€£ 2.3 A Conditional Latent Tree Model â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> (analogous to the assumptions made in Anandkumar et al., 2011<cite class="ltx_cite"/>).</p>
</div>
<div id="Thmassumption1" class="ltx_theorem ltx_theorem_assumption">
<h6 class="ltx_title ltx_runin ltx_font_bold ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem">Assumption 1</span> (Linear, Rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.m1" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>, Means)</h6>
<div id="Thmassumption1.p1" class="ltx_para">
<table id="A0.EGx5" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex3" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex3.m1" class="ltx_Math" alttext="\displaystyle\mathbb{E}[z_{i}|\pi_{\bm{x}}(z_{i}),\bm{x}]=\bm{A}_{(z_{i}|z_{%&#10;\pi_{\bm{x}}(z_{i})},\bm{x})}\pi_{\bm{x}}(z_{i})\,\,\forall i\in[H]" display="inline"><mrow><mi>ğ”¼</mi><mrow><mo>[</mo><msub><mi>z</mi><mi>i</mi></msub><mo>|</mo><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>,</mo><mi>ğ’™</mi><mo>]</mo></mrow><mo>=</mo><msub><mi>ğ‘¨</mi><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>|</mo><msub><mi>z</mi><mrow><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></msub><mo>,</mo><mi>ğ’™</mi><mo>)</mo></mrow></msub><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>z</mi><mi>i</mi></msub><mo rspace="5.9pt">)</mo></mrow><mo>âˆ€</mo><mi>i</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>H</mi><mo>]</mo></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p"><span class="ltx_text ltx_font_italic">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p1.m1" class="ltx_Math" alttext="\bm{A}_{(z_{i}|\pi_{\bm{x}}(z_{i}),\bm{x})}\in\mathbb{R}^{m\times m}" display="inline"><mrow><msub><mi>ğ€</mi><mrow><mo mathvariant="normal">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo mathvariant="normal">|</mo><msub><mi>Ï€</mi><mi>ğ±</mi></msub><mrow><mo mathvariant="normal">(</mo><msub><mi>z</mi><mi>i</mi></msub><mo mathvariant="normal">)</mo></mrow><mo mathvariant="normal">,</mo><mi>ğ±</mi><mo mathvariant="normal">)</mo></mrow></msub><mo mathvariant="normal">âˆˆ</mo><msup><mi>â„</mi><mrow><mi>m</mi><mo mathvariant="normal">Ã—</mo><mi>m</mi></mrow></msup></mrow></math> has rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p1.m2" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>.</span></p>
<table id="A0.EGx6" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex4" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex4.m1" class="ltx_Math" alttext="\displaystyle\mathbb{E}[w_{i}|\pi_{\bm{x}}(w_{i}),\bm{x}]=\bm{C}_{(w_{i}|\pi_{%&#10;\bm{x}}(w_{i}),\bm{x})}\pi_{\bm{x}}(w_{i})\,\,\forall i\in[\ell(\bm{x})]" display="inline"><mrow><mi>ğ”¼</mi><mrow><mo>[</mo><msub><mi>w</mi><mi>i</mi></msub><mo>|</mo><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>,</mo><mi>ğ’™</mi><mo>]</mo></mrow><mo>=</mo><msub><mi>ğ‘ª</mi><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>|</mo><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo>)</mo></mrow><mo>,</mo><mi>ğ’™</mi><mo>)</mo></mrow></msub><msub><mi>Ï€</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><msub><mi>w</mi><mi>i</mi></msub><mo rspace="5.9pt">)</mo></mrow><mo>âˆ€</mo><mi>i</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi mathvariant="normal">â„“</mi><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mo>]</mo></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p"><span class="ltx_text ltx_font_italic">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p1.m3" class="ltx_Math" alttext="\bm{C}_{(w_{i}|\pi_{\bm{x}}(w_{i}),\bm{x})}\in\mathbb{R}^{p\times m}" display="inline"><mrow><msub><mi>ğ‚</mi><mrow><mo mathvariant="normal">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo mathvariant="normal">|</mo><msub><mi>Ï€</mi><mi>ğ±</mi></msub><mrow><mo mathvariant="normal">(</mo><msub><mi>w</mi><mi>i</mi></msub><mo mathvariant="normal">)</mo></mrow><mo mathvariant="normal">,</mo><mi>ğ±</mi><mo mathvariant="normal">)</mo></mrow></msub><mo mathvariant="normal">âˆˆ</mo><msup><mi>â„</mi><mrow><mi>p</mi><mo mathvariant="normal">Ã—</mo><mi>m</mi></mrow></msup></mrow></math> has rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p1.m4" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>.</span></p>
</div>
<div id="Thmassumption1.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Also assume that <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p2.m1" class="ltx_Math" alttext="\mathbb{E}[z_{i}z_{i}^{\top}|\bm{x}]" display="inline"><mrow><mi>ğ”¼</mi><mrow><mo mathvariant="normal">[</mo><msub><mi>z</mi><mi>i</mi></msub><msubsup><mi>z</mi><mi>i</mi><mo mathvariant="normal">âŠ¤</mo></msubsup><mo mathvariant="normal">|</mo><mi>ğ±</mi><mo mathvariant="normal">]</mo></mrow></mrow></math> has rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p2.m2" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmassumption1.p2.m3" class="ltx_Math" alttext="\forall i\in[H]" display="inline"><mrow><mrow><mo mathvariant="normal">âˆ€</mo><mi>i</mi></mrow><mo mathvariant="normal">âˆˆ</mo><mrow><mo mathvariant="italic">[</mo><mi>H</mi><mo mathvariant="italic">]</mo></mrow></mrow></math>.</span></p>
</div>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p class="ltx_p">Note that the matrices <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m1" class="ltx_Math" alttext="\bm{A}" display="inline"><mi>ğ‘¨</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m2" class="ltx_Math" alttext="\bm{C}" display="inline"><mi>ğ‘ª</mi></math> are a direct function of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m3" class="ltx_Math" alttext="\theta(\bm{x})" display="inline"><mrow><mi>Î¸</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>, but we do not specify a model family for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m4" class="ltx_Math" alttext="\theta(\bm{x})" display="inline"><mrow><mi>Î¸</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>. The only restriction
is in the form of the above assumption. If <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m5" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m6" class="ltx_Math" alttext="z_{i}" display="inline"><msub><mi>z</mi><mi>i</mi></msub></math> were discrete, represented as binary vectors, the above assumption would correspond to requiring all conditional probability tables in the latent tree to have rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m7" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>.
AssumptionÂ <a href="#Thmassumption1" title="Assumption 1 (Linear, Rank m, Means) â€£ 3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> allows for the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p2.m8" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> to be high dimensional features, as long as the expectation requirement above is satisfied.
Similar assumptions are made with spectral parameter learning methods e.g. <cite class="ltx_cite"><a href="#bib.bibx23" title="" class="ltx_ref">Hsu et al.2009</a></cite>, <cite class="ltx_cite"><a href="#bib.bibx2" title="" class="ltx_ref">Bailly et al.2009</a></cite>, <cite class="ltx_cite"><a href="#bib.bibx31" title="" class="ltx_ref">Parikh et al.2011</a></cite>, and <cite class="ltx_cite"><a href="#bib.bibx11" title="" class="ltx_ref">Cohen et al.2012</a></cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p class="ltx_p">Furthermore, AssumptionÂ <a href="#Thmassumption1" title="Assumption 1 (Linear, Rank m, Means) â€£ 3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> makes it explicit that regardless of the size of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p3.m1" class="ltx_Math" alttext="p" display="inline"><mi>p</mi></math>, the relationships among the variables in the latent tree are restricted to be of rank <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p3.m2" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math>, and are thus <span class="ltx_text ltx_font_italic">low rank</span> since <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p3.m3" class="ltx_Math" alttext="p&gt;m" display="inline"><mrow><mi>p</mi><mo>&gt;</mo><mi>m</mi></mrow></math>.
To leverage this low rank structure, we propose using the following additive metric, a normalized variant of that inÂ <cite class="ltx_cite"><a href="#bib.bibx1" title="" class="ltx_ref">Anandkumar et al.2011</a></cite>:</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<table id="A0.EGx7" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex5" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex5.m2" class="ltx_Math" alttext="\displaystyle d^{\mathrm{spectral}}(i,j)=-\log\Lambda_{m}(\bm{\Sigma}_{\bm{x}}%&#10;(i,j))" display="inline"><mrow><mrow><msup><mi>d</mi><mi>spectral</mi></msup><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>-</mo><mrow><mrow><mi>log</mi><mo>â¡</mo><msub><mi mathvariant="normal">Î›</mi><mi>m</mi></msub></mrow><mo>â¢</mo><mrow><mo>(</mo><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S3.E5" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E5.m2" class="ltx_Math" alttext="\displaystyle+{\textstyle\frac{1}{2}}\log\Lambda_{m}(\bm{\Sigma}_{\bm{x}}(i,i)%&#10;)+{\textstyle\frac{1}{2}}\log\Lambda_{m}(\bm{\Sigma}_{\bm{x}}(j,j))" display="inline"><mrow><mo>+</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>â¢</mo><mrow><mi>log</mi><mo>â¡</mo><msub><mi mathvariant="normal">Î›</mi><mi>m</mi></msub></mrow><mo>â¢</mo><mrow><mo>(</mo><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>i</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>+</mo><mrow><mfrac><mn>1</mn><mn>2</mn></mfrac><mo>â¢</mo><mrow><mi>log</mi><mo>â¡</mo><msub><mi mathvariant="normal">Î›</mi><mi>m</mi></msub></mrow><mo>â¢</mo><mrow><mo>(</mo><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(5)</span></td></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p4.m1" class="ltx_Math" alttext="\Lambda_{m}(\bm{A})" display="inline"><mrow><msub><mi mathvariant="normal">Î›</mi><mi>m</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>ğ‘¨</mi><mo>)</mo></mrow></mrow></math> denotes the product of the top <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p4.m2" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> singular values of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p4.m3" class="ltx_Math" alttext="\bm{A}" display="inline"><mi>ğ‘¨</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p4.m4" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(i,j):=\mathbb{E}[v_{i}v_{j}^{\top}|\bm{x}]" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mrow><mo>(</mo><mi>i</mi><mo>,</mo><mi>j</mi><mo>)</mo></mrow><mo>:=</mo><mi>ğ”¼</mi><mrow><mo>[</mo><msub><mi>v</mi><mi>i</mi></msub><msubsup><mi>v</mi><mi>j</mi><mo>âŠ¤</mo></msubsup><mo>|</mo><mi>ğ’™</mi><mo>]</mo></mrow></mrow></math>, i.e. the uncentered cross-covariance matrix.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p class="ltx_p">We can then show that this metric is additive:</p>
</div>
<div id="Thmlemma1" class="ltx_theorem ltx_theorem_lemma">
<h6 class="ltx_title ltx_runin ltx_font_bold ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem">Lemma 1</span></h6>
<div id="Thmlemma1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">If AssumptionÂ <a href="#Thmassumption1" title="Assumption 1 (Linear, Rank m, Means) â€£ 3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> holds then, <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmlemma1.p1.m1" class="ltx_Math" alttext="d^{\mathrm{spectral}}" display="inline"><msup><mi>d</mi><mi mathvariant="normal">spectral</mi></msup></math> is an additive tree metric (DefinitionÂ <a href="#A0.EGx2" title="Definition 1 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).</span></p>
</div>
</div>
<div id="S3.SS2.p6" class="ltx_para">
<p class="ltx_p">A proof is in the supplementary for completeness.
From here, we use <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p6.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> to denote <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p6.m2" class="ltx_Math" alttext="d^{\mathrm{spectral}}" display="inline"><msup><mi>d</mi><mi>spectral</mi></msup></math>, since that is the metric
we use for our learning algorithm.</p>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Recovering the Minimal Projective Latent Tree</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">It has been shown <cite class="ltx_cite">[<a href="#bib.bibx33" title="" class="ltx_ref">Rzhetsky and Nei1993</a>]</cite> that for any additive tree metric, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> can be recovered by solving
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m2" class="ltx_Math" alttext="\arg\min_{u\in\mathcal{U}}c(u)" display="inline"><mrow><mi>arg</mi><mo>â¢</mo><mrow><msub><mo>min</mo><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></msub><mo>â¡</mo><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></mrow></mrow></math> for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m3" class="ltx_Math" alttext="c(u)" display="inline"><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math>:</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<table id="S3.E6" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.E6.m1" class="ltx_Math" alttext="c(u)=\sum_{(i,j)\in\mathcal{E}_{u}}d(i,j)." display="block"><mrow><mrow><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><munder><mo largeop="true" movablelimits="false" symmetric="true">âˆ‘</mo><mrow><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow><mo>âˆˆ</mo><msub><mi class="ltx_font_mathcaligraphic">â„°</mi><mi>u</mi></msub></mrow></munder><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></mrow></mrow><mo>.</mo></mrow></math></td>
<td class="ltx_eqn_center_padright"/>
<td rowspan="1" class="ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation">(6)</span></td></tr>
</table>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m1" class="ltx_Math" alttext="\mathcal{E}_{u}" display="inline"><msub><mi class="ltx_font_mathcaligraphic">â„°</mi><mi>u</mi></msub></math> is the set of pairs of nodes which are adjacent to each other in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m2" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p3.m3" class="ltx_Math" alttext="d(i,j)" display="inline"><mrow><mi>d</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> is computed using Eq.Â <a href="#S3.E3" title="(3) â€£ Case 1 (leaf edge, figureÂ ) â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and Eq.Â <a href="#S3.E4" title="(4) â€£ Case 2 (internal edge, figureÂ ) â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p class="ltx_p">Note that the metric <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> we use in defining <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m2" class="ltx_Math" alttext="c(u)" display="inline"><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math> is based on the expectations from the true distribution. In practice, the true distribution is unknown, and therefore we use an approximation for the distance metric <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m3" class="ltx_Math" alttext="\hat{d}" display="inline"><mover accent="true"><mi>d</mi><mo stretchy="false">^</mo></mover></math>. As we discussed in Â§<a href="#S3.SS1" title="3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1</span></a> all elements of the distance matrix are functions of observable quantities if the underlying tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m4" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> is known. However, only the word-word sub-block <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p4.m5" class="ltx_Math" alttext="\bm{D}_{WW}" display="inline"><msub><mi>ğ‘«</mi><mrow><mi>W</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math> can be directly estimated from the data without knowledge of the tree structure.</p>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p class="ltx_p">This subtlety makes solving the minimization problem in Eq.Â <a href="#S3.E6" title="(6) â€£ 3.3 Recovering the Minimal Projective Latent Tree â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> NP-hard <cite class="ltx_cite">[<a href="#bib.bibx12" title="" class="ltx_ref">Desper and Gascuel2005</a>]</cite>
if <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m1" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> is allowed to be an arbitrary undirected tree. However, if we restrict <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m2" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> to
be in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m3" class="ltx_Math" alttext="\mathcal{U}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’°</mi></math>, as we do in the above, then maximizing <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m4" class="ltx_Math" alttext="\hat{c}(u)" display="inline"><mrow><mover accent="true"><mi>c</mi><mo stretchy="false">^</mo></mover><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math> over <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m5" class="ltx_Math" alttext="\mathcal{U}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’°</mi></math> can be solved
using the bilexical parsing algorithm from <cite class="ltx_cite"><a href="#bib.bibx14" title="" class="ltx_ref">Eisner and Satta1999</a></cite>. This is because the computation of the other sub-blocks of the distance matrix only depend on the partitions of the nodes shown in FigureÂ <a href="#S3.F3" title="FigureÂ 3 â€£ 3.1 Additive Tree Metrics â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> into <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m6" class="ltx_Math" alttext="A" display="inline"><mi>A</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m7" class="ltx_Math" alttext="B" display="inline"><mi>B</mi></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m8" class="ltx_Math" alttext="G" display="inline"><mi>G</mi></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p5.m9" class="ltx_Math" alttext="H" display="inline"><mi>H</mi></math>, and not on the entire tree structure.</p>
</div>
<div id="S3.SS3.p6" class="ltx_para">
<p class="ltx_p">Therefore, the procedure to find a bracketing for a given POS tag <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m1" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> is to first estimate the distance matrix sub-block <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m2" class="ltx_Math" alttext="\widehat{\bm{D}}_{WW}" display="inline"><msub><mover accent="true"><mi>ğ‘«</mi><mo>^</mo></mover><mrow><mi>W</mi><mo>â¢</mo><mi>W</mi></mrow></msub></math> from raw text data (see Â§<a href="#S3.SS4" title="3.4 Estimation of d from Sparse Data â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.4</span></a>),
and then solve the optimization problem <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m3" class="ltx_Math" alttext="\arg\min_{u\in\mathcal{U}}\hat{c}(u)" display="inline"><mrow><mi>arg</mi><mo>â¢</mo><mrow><msub><mo>min</mo><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></msub><mo>â¡</mo><mrow><mover accent="true"><mi>c</mi><mo stretchy="false">^</mo></mover><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></mrow></mrow></math> using a variant of the Eisner-Satta algorithm where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m4" class="ltx_Math" alttext="\hat{c}(u)" display="inline"><mrow><mover accent="true"><mi>c</mi><mo stretchy="false">^</mo></mover><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math> is identical to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m5" class="ltx_Math" alttext="c(u)" display="inline"><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math> in Eq.Â <a href="#S3.E6" title="(6) â€£ 3.3 Recovering the Minimal Projective Latent Tree â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m6" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> replaced with <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p6.m7" class="ltx_Math" alttext="\hat{d}" display="inline"><mover accent="true"><mi>d</mi><mo stretchy="false">^</mo></mover></math>.</p>
</div><span class="ltx_ERROR undefined">{algorithm}</span>
<div id="S3.SS3.p7" class="ltx_para">
<p class="ltx_p">[t!]<span class="ltx_text ltx_font_bold">Inputs:</span> Set of examples <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p7.m1" class="ltx_Math" alttext="(\bm{w}^{(i)},\bm{x}^{(i)})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></math> for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p7.m2" class="ltx_Math" alttext="i\in[N]" display="inline"><mrow><mi>i</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow></mrow></math>, a kernel <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p7.m3" class="ltx_Math" alttext="K_{\gamma}(j,k,j^{\prime},k^{\prime}|\bm{x},\bm{x}^{\prime})" display="inline"><mrow><msub><mi>K</mi><mi>Î³</mi></msub><mrow><mo>(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><mi>ğ’™</mi><mo>,</mo><msup><mi>ğ’™</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow></math>, an integer <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p7.m4" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math></p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Data structures:</span>
For each <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p8.m1" class="ltx_Math" alttext="i\in[N],j,k\in\ell(\bm{x}^{(i)})" display="inline"><mrow><mrow><mi>i</mi><mo>âˆˆ</mo><mrow><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow><mo>,</mo><mi>j</mi></mrow></mrow><mo>,</mo><mrow><mi>k</mi><mo>âˆˆ</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow></mrow></mrow></mrow></math> there is a (uncentered) covariance matrix <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p8.m2" class="ltx_Math" alttext="\widehat{\bm{\Sigma}}_{\bm{x}^{(i)}}(j,k)\in\mathbb{R}^{p\times p}" display="inline"><mrow><mrow><msub><mover accent="true"><mi>ğšº</mi><mo>^</mo></mover><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow><mo>âˆˆ</mo><msup><mi>â„</mi><mrow><mi>p</mi><mo>Ã—</mo><mi>p</mi></mrow></msup></mrow></math>,
and a distance <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p8.m3" class="ltx_Math" alttext="\hat{d}^{\mathrm{spectral}}(j,k)" display="inline"><mrow><msup><mover accent="true"><mi>d</mi><mo stretchy="false">^</mo></mover><mi>spectral</mi></msup><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow></math>.</p>
</div>
<div id="S3.SS3.p9" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Algorithm:</span></p>
</div>
<div id="S3.SS3.p10" class="ltx_para">
<p class="ltx_p">(Covariance estimation)
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p10.m1" class="ltx_Math" alttext="\forall i\in[N],j,k\in\ell(\bm{x}^{(i)})\;\;" display="inline"><mrow><mrow><mrow><mo>âˆ€</mo><mi>i</mi></mrow><mo>âˆˆ</mo><mrow><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow><mo>,</mo><mi>j</mi></mrow></mrow><mo>,</mo><mrow><mi>k</mi><mo>âˆˆ</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mpadded width="+5.6pt"><mrow><mo>(</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow></mpadded></mrow></mrow></mrow></math></p>
</div>
<div id="S3.SS3.p11" class="ltx_para">
<ul class="ltx_itemize">
<li id="I3.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I3.i1.p1" class="ltx_para">
<p class="ltx_p">Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="I3.i1.p1.m1" class="ltx_Math" alttext="C_{j^{\prime},k^{\prime}|i^{\prime}}=w_{j^{\prime}}^{(i^{\prime})}(w_{k^{%&#10;\prime}}^{(i^{\prime})})^{\top}" display="inline"><mrow><msub><mi>C</mi><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><msup><mi>i</mi><mo>â€²</mo></msup></mrow></msub><mo>=</mo><mrow><msubsup><mi>w</mi><msup><mi>j</mi><mo>â€²</mo></msup><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msubsup><mo>â¢</mo><msup><mrow><mo>(</mo><msubsup><mi>w</mi><msup><mi>k</mi><mo>â€²</mo></msup><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msubsup><mo>)</mo></mrow><mo>âŠ¤</mo></msup></mrow></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="I3.i1.p1.m2" class="ltx_Math" alttext="k_{j,k,j^{\prime},k^{\prime},i,i^{\prime}}=K_{\gamma}(j,k,j^{\prime},k^{\prime%&#10;}|\bm{x}^{(i)},\bm{x}^{(i^{\prime})})" display="inline"><mrow><msub><mi>k</mi><mrow><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>,</mo><mi>i</mi><mo>,</mo><msup><mi>i</mi><mo>â€²</mo></msup></mrow></msub><mo>=</mo><msub><mi>K</mi><mi>Î³</mi></msub><mrow><mo>(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup><mo>)</mo></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="I3.i1.p1.m3" class="ltx_Math" alttext="\ell_{i^{\prime}}=\ell(\bm{x}^{(i^{\prime})})" display="inline"><mrow><msub><mi mathvariant="normal">â„“</mi><msup><mi>i</mi><mo>â€²</mo></msup></msub><mo>=</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup><mo>)</mo></mrow></mrow></mrow></math>, and estimate each <math xmlns="http://www.w3.org/1998/Math/MathML" id="I3.i1.p1.m4" class="ltx_Math" alttext="p\times p" display="inline"><mrow><mi>p</mi><mo>Ã—</mo><mi>p</mi></mrow></math> covariance matrix as:</p>
<table id="A0.EGx8" class="ltx_equationgroup ltx_eqn_align">

<tr id="S3.Ex6" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex6.m1" class="ltx_Math" alttext="\displaystyle\widehat{\bm{\Sigma}}_{\bm{x}}(j,k)=" display="inline"><mrow><mrow><msub><mover accent="true"><mi>ğšº</mi><mo>^</mo></mover><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mi/></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S3.Ex7" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"/>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex7.m2" class="ltx_Math" alttext="\displaystyle\frac{\sum_{i^{\prime}=1}^{N}\sum_{j^{\prime}=1}^{\ell_{i^{\prime%&#10;}}}\sum_{k^{\prime}=1}^{\ell_{i^{\prime}}}k_{j,k,j^{\prime},k^{\prime},i,i^{%&#10;\prime}}C_{j^{\prime},k^{\prime}|i^{\prime}}}{\sum_{i^{\prime}=1}^{N}\sum_{j^{%&#10;\prime}=1}^{\ell_{i^{\prime}}}\sum_{k^{\prime}=1}^{\ell_{i^{\prime}}}k_{j,k,j^%&#10;{\prime},k^{\prime},i,i^{\prime}}}" display="inline"><mstyle displaystyle="true"><mfrac><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>i</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><msub><mi mathvariant="normal">â„“</mi><msup><mi>i</mi><mo>â€²</mo></msup></msub></msubsup><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>k</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><msub><mi mathvariant="normal">â„“</mi><msup><mi>i</mi><mo>â€²</mo></msup></msub></msubsup><mrow><msub><mi>k</mi><mrow><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>,</mo><mi>i</mi><mo>,</mo><msup><mi>i</mi><mo>â€²</mo></msup></mrow></msub><mo>â¢</mo><msub><mi>C</mi><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><msup><mi>i</mi><mo>â€²</mo></msup></mrow></msub></mrow></mrow></mrow></mrow><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>i</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><msub><mi mathvariant="normal">â„“</mi><msup><mi>i</mi><mo>â€²</mo></msup></msub></msubsup><mrow><msubsup><mo largeop="true" symmetric="true">âˆ‘</mo><mrow><msup><mi>k</mi><mo>â€²</mo></msup><mo>=</mo><mn>1</mn></mrow><msub><mi mathvariant="normal">â„“</mi><msup><mi>i</mi><mo>â€²</mo></msup></msub></msubsup><msub><mi>k</mi><mrow><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>,</mo><mi>i</mi><mo>,</mo><msup><mi>i</mi><mo>â€²</mo></msup></mrow></msub></mrow></mrow></mrow></mfrac></mstyle></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
</div></li>
<li id="I3.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I3.i2.p1" class="ltx_para">
<p class="ltx_p">Compute <math xmlns="http://www.w3.org/1998/Math/MathML" id="I3.i2.p1.m1" class="ltx_Math" alttext="\hat{d}^{\mathrm{spectral}}(j,k)\,\,\forall j,k\in\ell(\bm{x}^{(i)})" display="inline"><mrow><mrow><mrow><msup><mover accent="true"><mi>d</mi><mo stretchy="false">^</mo></mover><mi>spectral</mi></msup><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow><mo>â¢</mo><mrow><mo>âˆ€</mo><mi>j</mi></mrow></mrow><mo>,</mo><mi>k</mi></mrow><mo>âˆˆ</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow></mrow></mrow></math> using Eq.Â <a href="#S3.E5" title="(5) â€£ 3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div></li>
</ul>
</div>
<div id="S3.SS3.p12" class="ltx_para">
<p class="ltx_p">(Uncover structure)
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p12.m1" class="ltx_Math" alttext="\forall i\in[N]\;\;" display="inline"><mrow><mrow><mo>âˆ€</mo><mi>i</mi></mrow><mo>âˆˆ</mo><mpadded width="+5.6pt"><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow></mpadded></mrow></math></p>
</div>
<div id="S3.SS3.p13" class="ltx_para">
<ul class="ltx_itemize">
<li id="I4.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I4.i1.p1" class="ltx_para">
<p class="ltx_p">Find <math xmlns="http://www.w3.org/1998/Math/MathML" id="I4.i1.p1.m1" class="ltx_Math" alttext="\hat{u}^{(i)}=\arg\min_{u\in\mathcal{U}}\hat{c}(u)" display="inline"><mrow><msup><mover accent="true"><mi>u</mi><mo stretchy="false">^</mo></mover><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>=</mo><mrow><mi>arg</mi><mo>â¢</mo><mrow><msub><mo>min</mo><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></msub><mo>â¡</mo><mrow><mover accent="true"><mi>c</mi><mo stretchy="false">^</mo></mover><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></mrow></mrow></mrow></math>, and for the <math xmlns="http://www.w3.org/1998/Math/MathML" id="I4.i1.p1.m2" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>th example, return the structure <math xmlns="http://www.w3.org/1998/Math/MathML" id="I4.i1.p1.m3" class="ltx_Math" alttext="h_{\mathrm{dir}}(\hat{u}^{(i)})" display="inline"><mrow><msub><mi>h</mi><mi>dir</mi></msub><mo>â¢</mo><mrow><mo>(</mo><msup><mover accent="true"><mi>u</mi><mo stretchy="false">^</mo></mover><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>)</mo></mrow></mrow></math>.</p>
</div></li>
</ul>
</div>
<div id="S3.SS3.p14" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_caption">The learning algorithm for finding the latent structure from a set of examples <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p14.m1" class="ltx_Math" alttext="(\bm{w}^{(i)},\bm{x}^{(i)})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p14.m2" class="ltx_Math" alttext="i\in[N]" display="inline"><mrow><mi>i</mi><mo>âˆˆ</mo><mrow><mo>[</mo><mi>N</mi><mo>]</mo></mrow></mrow></math>.</span></p>
</div>
<div id="S3.SS3.p15" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Summary.</span> We first defined a generative model that describes how a sentence, its sequence of POS tags, and its bracketing is generated (Â§<a href="#S2.SS3" title="2.3 A Conditional Latent Tree Model â€£ 2 Learning Setting and Model â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>).
First an undirected <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m1" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math> is generated (only as a function of the POS tags), and then <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m2" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> is mapped to a bracketing using a direction mapping <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m3" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>. We then showed that we can define a distance metric between nodes in the undirected tree, such that minimizing
it leads to a recovery of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m4" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math>. This distance metric can be computed based only on the text, without needing to identify the latent information (Â§<a href="#S3.SS2" title="3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
If the true distance metric is known, with respect to the true distribution that generates the words in a sentence, then <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m5" class="ltx_Math" alttext="u" display="inline"><mi>u</mi></math> can be fully recovered
by optimizing the cost function <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p15.m6" class="ltx_Math" alttext="c(u)" display="inline"><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mi>u</mi><mo>)</mo></mrow></mrow></math>. However, in practice the distance metric must be estimated from data, as discussed below.</p>
</div>
</div>
<div id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.4 </span>Estimation of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> from Sparse Data</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p">We now address the data sparsity problem, in particular that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m1" class="ltx_Math" alttext="\mathcal{D}(\bm{x})" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> can be very small, and therefore estimating <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m2" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> for each POS sequence separately can be problematic.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup>This data sparsity problem is quite severe â€“ for example, the Penn treebank <cite class="ltx_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">Marcus et al.1993</a>]</cite> has a total number of 43,498 sentences, with 42,246 <span class="ltx_text ltx_font_italic">unique</span> POS tag sequences, averaging <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p1.m3" class="ltx_Math" alttext="|\mathcal{D}(\bm{x})|" display="inline"><mrow><mo fence="true">|</mo><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo fence="true">|</mo></mrow></math> to be 1.04.</span></span></span></p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p class="ltx_p">In order to estimate <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p2.m1" class="ltx_Math" alttext="d" display="inline"><mi>d</mi></math> from data, we need to estimate the covariance matrices <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p2.m2" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(i,j)" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>)</mo></mrow></mrow></math> (for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p2.m3" class="ltx_Math" alttext="i,j\in\{1,\ldots,\ell(\bm{x})\}" display="inline"><mrow><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow><mo>âˆˆ</mo><mrow><mo>{</mo><mrow><mn>1</mn><mo>,</mo><mi mathvariant="normal">â€¦</mi><mo>,</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow><mo>}</mo></mrow></mrow></math>) from Eq.Â <a href="#S3.E5" title="(5) â€£ 3.2 Constructing a Spectral Additive Metric â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S3.SS4.p3" class="ltx_para">
<p class="ltx_p">To give some motivation to our solution, consider estimating the covariance matrix <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m1" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(1,2)" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math> for the tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m2" class="ltx_Math" alttext="\bm{x}=(\tt{DT_{1}},\tt{NN_{2}},\tt{VBD_{3}},\tt{DT_{4}},\tt{NN_{5}})" display="inline"><mrow><mi>ğ’™</mi><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>ğ™³ğšƒ</mi><mn>ğŸ·</mn></msub><mo>,</mo><msub><mi>ğ™½ğ™½</mi><mn>ğŸ¸</mn></msub><mo>,</mo><msub><mi>ğš…ğ™±ğ™³</mi><mn>ğŸ¹</mn></msub><mo>,</mo><msub><mi>ğ™³ğšƒ</mi><mn>ğŸº</mn></msub><mo>,</mo><msub><mi>ğ™½ğ™½</mi><mn>ğŸ»</mn></msub></mrow><mo>)</mo></mrow></mrow></math>. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m3" class="ltx_Math" alttext="\mathcal{D}(\bm{x})" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math> may be insufficient for an accurate empirical estimate. However, consider another sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m4" class="ltx_Math" alttext="\bm{x}^{\prime}=(\tt{RB_{1}},\tt{DT_{2}},\tt{NN_{3}},\tt{VBD_{4}},\tt{DT_{5}},%&#10;\tt{ADJ_{6}},\tt{NN_{7}})" display="inline"><mrow><msup><mi>ğ’™</mi><mo>â€²</mo></msup><mo>=</mo><mrow><mo>(</mo><mrow><msub><mi>ğšğ™±</mi><mn>ğŸ·</mn></msub><mo>,</mo><msub><mi>ğ™³ğšƒ</mi><mn>ğŸ¸</mn></msub><mo>,</mo><msub><mi>ğ™½ğ™½</mi><mn>ğŸ¹</mn></msub><mo>,</mo><msub><mi>ğš…ğ™±ğ™³</mi><mn>ğŸº</mn></msub><mo>,</mo><msub><mi>ğ™³ğšƒ</mi><mn>ğŸ»</mn></msub><mo>,</mo><msub><mi>ğ™°ğ™³ğ™¹</mi><mn>ğŸ¼</mn></msub><mo>,</mo><msub><mi>ğ™½ğ™½</mi><mn>ğŸ½</mn></msub></mrow><mo>)</mo></mrow></mrow></math>. Although <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m5" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m6" class="ltx_Math" alttext="\bm{x}^{\prime}" display="inline"><msup><mi>ğ’™</mi><mo>â€²</mo></msup></math> are not identical, it is likely that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m7" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}^{\prime}}(2,3)" display="inline"><mrow><msub><mi>ğšº</mi><msup><mi>ğ’™</mi><mo>â€²</mo></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>2</mn><mo>,</mo><mn>3</mn></mrow><mo>)</mo></mrow></mrow></math> is similar to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m8" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(1,2)" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math> because the determiner and the noun appear in similar syntactic context. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m9" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}^{\prime}}(5,7)" display="inline"><mrow><msub><mi>ğšº</mi><msup><mi>ğ’™</mi><mo>â€²</mo></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>5</mn><mo>,</mo><mn>7</mn></mrow><mo>)</mo></mrow></mrow></math> also may be somewhat similar,
but <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m10" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}^{\prime}}(2,7)" display="inline"><mrow><msub><mi>ğšº</mi><msup><mi>ğ’™</mi><mo>â€²</mo></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>2</mn><mo>,</mo><mn>7</mn></mrow><mo>)</mo></mrow></mrow></math> should not be very similar to <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p3.m11" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(1,2)" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mn>1</mn><mo>,</mo><mn>2</mn></mrow><mo>)</mo></mrow></mrow></math> because the noun and the determiner appear in a different syntactic context.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p class="ltx_p">The observation that the covariance matrices depend on local syntactic context is the main driving force behind our solution. The local syntactic context acts as an â€œanchor,â€ which
enhances or replaces a word index in a sentence with local syntactic context.
More formally, an anchor is a function <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m1" class="ltx_Math" alttext="G" display="inline"><mi>G</mi></math> that maps a word index <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m2" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> and a sequence of POS tags <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m3" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> to a local context <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m4" class="ltx_Math" alttext="G(j,\bm{x})" display="inline"><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>ğ’™</mi></mrow><mo>)</mo></mrow></mrow></math>. The anchor we use
is <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m5" class="ltx_Math" alttext="G(j,\bm{x})=(j,x_{j})" display="inline"><mrow><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>ğ’™</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><msub><mi>x</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math>. Then, the covariance matrices <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m6" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}" display="inline"><msub><mi>ğšº</mi><mi>ğ’™</mi></msub></math> are estimated using kernel smoothing <cite class="ltx_cite">[<a href="#bib.bibx21" title="" class="ltx_ref">Hastie et al.2009</a>]</cite>, where the smoother
tests similarity between the different anchors <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p4.m7" class="ltx_Math" alttext="G(j,\bm{x})" display="inline"><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>ğ’™</mi></mrow><mo>)</mo></mrow></mrow></math>.</p>
</div>
<div id="S3.SS4.p5" class="ltx_para">
<p class="ltx_p">The full learning algorithm is given in FigureÂ <a href="#S3.SS3" title="3.3 Recovering the Minimal Projective Latent Tree â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>. The first step in the algorithm is to estimate the covariance matrix block <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m1" class="ltx_Math" alttext="\widehat{\bm{\Sigma}}_{\bm{x}^{(i)}}(j,k)" display="inline"><mrow><msub><mover accent="true"><mi>ğšº</mi><mo>^</mo></mover><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow></math> for each
training example <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m2" class="ltx_Math" alttext="\bm{x}^{(i)}" display="inline"><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math> and each pair of preterminal positions <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m3" class="ltx_Math" alttext="(j,k)" display="inline"><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m4" class="ltx_Math" alttext="\bm{x}^{(i)}" display="inline"><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math>. Instead of computing this block by computing the empirical covariance matrix for positions <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m5" class="ltx_Math" alttext="(j,k)" display="inline"><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></math> in
the data <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m6" class="ltx_Math" alttext="\mathcal{D}(\bm{x})" display="inline"><mrow><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>, the algorithm uses all of the pairs <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m7" class="ltx_Math" alttext="(j^{\prime},k^{\prime})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo>)</mo></mrow></math> from all of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m8" class="ltx_Math" alttext="N" display="inline"><mi>N</mi></math> training examples. It averages the empirical covariance matrices from these contexts using a kernel
weight, which gives a similarity measure for the position <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m9" class="ltx_Math" alttext="(j,k)" display="inline"><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m10" class="ltx_Math" alttext="\bm{x}^{(i)}" display="inline"><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m11" class="ltx_Math" alttext="(j^{\prime},k^{\prime})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo>)</mo></mrow></math> in another example <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m12" class="ltx_Math" alttext="\bm{x}^{(i^{\prime})}" display="inline"><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup></math>. <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m13" class="ltx_Math" alttext="\gamma" display="inline"><mi>Î³</mi></math> is the kernel â€œbandwidthâ€, a user-specified parameter that controls how inclusive the kernel will be with respect to examples in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m14" class="ltx_Math" alttext="\mathcal{D}" display="inline"><mi class="ltx_font_mathcaligraphic">ğ’Ÿ</mi></math> (see Â§Â <a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a> for a concrete example). Note that the learning algorithm is such that it ensures that <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m15" class="ltx_Math" alttext="\widehat{\bm{\Sigma}}_{\bm{x}^{(i)}}(j,k)=\widehat{\bm{\Sigma}}_{\bm{x}^{(i^{%&#10;\prime})}}(j^{\prime},k^{\prime})" display="inline"><mrow><mrow><msub><mover accent="true"><mi>ğšº</mi><mo>^</mo></mover><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><msub><mover accent="true"><mi>ğšº</mi><mo>^</mo></mover><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow></math> if <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m16" class="ltx_Math" alttext="G(j,\bm{x}^{(i)})=G(j^{\prime},\bm{x}^{(i^{\prime})})" display="inline"><mrow><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></mrow></mrow></math>
and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS4.p5.m17" class="ltx_Math" alttext="G(k,\bm{x}^{(i)})=G(k^{\prime},\bm{x}^{(i^{\prime})})" display="inline"><mrow><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>k</mi><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>G</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><msup><mi>k</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><msup><mi>i</mi><mo>â€²</mo></msup><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></mrow></mrow></math>.</p>
</div>
<div id="S3.SS4.p6" class="ltx_para">
<p class="ltx_p">Once the empirical estimates for the covariance matrices are obtained, a variant of the Eisner-Satta algorithm is used, as mentioned in Â§<a href="#S3.SS3" title="3.3 Recovering the Minimal Projective Latent Tree â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
</div>
<div id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.5 </span>Theoretical Guarantees</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p class="ltx_p">Our main theoretical guarantee is that Algorithm 1 will recover the correct tree <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p1.m1" class="ltx_Math" alttext="u\in\mathcal{U}" display="inline"><mrow><mi>u</mi><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow></math> with high probability, if the given top bracket is correct and if we obtain enough examples <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p1.m2" class="ltx_Math" alttext="(\bm{w}^{(i)},\bm{x}^{(i)})" display="inline"><mrow><mo>(</mo><mrow><msup><mi>ğ’˜</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup><mo>,</mo><msup><mi>ğ’™</mi><mrow><mo>(</mo><mi>i</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></math> from the model in Â§2. We give the theorem statement below. The constants lurking in the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p1.m3" class="ltx_Math" alttext="O" display="inline"><mi>O</mi></math>-notation and the full proof are in the supplementary.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p class="ltx_p">Denote <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p2.m1" class="ltx_Math" alttext="\sigma_{\bm{x}}(j,k)^{(r)}" display="inline"><mrow><msub><mi>Ïƒ</mi><mi>ğ’™</mi></msub><mo>â¢</mo><msup><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mi>r</mi><mo>)</mo></mrow></msup></mrow></math> as the <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p2.m2" class="ltx_Math" alttext="r^{th}" display="inline"><msup><mi>r</mi><mrow><mi>t</mi><mo>â¢</mo><mi>h</mi></mrow></msup></math> singular value of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p2.m3" class="ltx_Math" alttext="\bm{\Sigma}_{\bm{x}}(j,k)" display="inline"><mrow><msub><mi>ğšº</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow></math>. Let <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p2.m4" class="ltx_Math" alttext="\sigma^{\ast}(x):=\min_{j,k\in\ell(\bm{x})}\min\left(\sigma_{\bm{x}}(j,k)^{(m)%&#10;}\right)" display="inline"><mrow><mrow><msup><mi>Ïƒ</mi><mo>âˆ—</mo></msup><mo>â¢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow><mo>:=</mo><mrow><msub><mo>min</mo><mrow><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>âˆˆ</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow></msub><mo>â¡</mo><mrow><mo>min</mo><mo>â¡</mo><mrow><mo>(</mo><mrow><msub><mi>Ïƒ</mi><mi>ğ’™</mi></msub><mo>â¢</mo><msup><mrow><mo>(</mo><mrow><mi>j</mi><mo>,</mo><mi>k</mi></mrow><mo>)</mo></mrow><mrow><mo>(</mo><mi>m</mi><mo>)</mo></mrow></msup></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math>.</p>
</div>
<div id="Thmtheorem1" class="ltx_theorem ltx_theorem_theorem">
<h6 class="ltx_title ltx_runin ltx_font_bold ltx_title_theorem"><span class="ltx_tag ltx_tag_theorem">Theorem 1</span></h6>
<div id="Thmtheorem1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Define <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmtheorem1.p1.m1" class="ltx_Math" alttext="\hat{u}" display="inline"><mover accent="true"><mi>u</mi><mo mathvariant="normal" stretchy="false">^</mo></mover></math> as the estimated tree for tag sequence <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmtheorem1.p1.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ±</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmtheorem1.p1.m3" class="ltx_Math" alttext="u(\bm{x})" display="inline"><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></math> as the correct tree. Let</span></p>
<table id="A0.EGx9" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex8" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex8.m1" class="ltx_Math" alttext="\displaystyle\triangle(\bm{x}):=\min_{u^{\prime}\in\mathcal{U}:u^{\prime}\neq u%&#10;(\bm{x})}(c(u(\bm{x}))-c(u^{\prime}))/(8|\ell(\bm{x})|)" display="inline"><mrow><mrow><mi mathvariant="normal">â–³</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo>:=</mo><mrow><munder><mo movablelimits="false">min</mo><mrow><mrow><msup><mi>u</mi><mo>â€²</mo></msup><mo>âˆˆ</mo><mi class="ltx_font_mathcaligraphic">ğ’°</mi></mrow><mo>:</mo><mrow><msup><mi>u</mi><mo>â€²</mo></msup><mo>â‰ </mo><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow></mrow></munder><mo>â¡</mo><mrow><mrow><mo>(</mo><mrow><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>u</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow><mo>-</mo><mrow><mi>c</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>u</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow><mo>/</mo><mrow><mo>(</mo><mrow><mn>8</mn><mo>â¢</mo><mrow><mo fence="true">|</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow><mo fence="true">|</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
</div>
<div id="Thmtheorem1.p2" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Assume that</span></p>
<table id="A0.EGx10" class="ltx_equationgroup ltx_eqn_eqnarray">

<tr id="S3.Ex9" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex9.m1" class="ltx_Math" alttext="\displaystyle N\geq\mathcal{O}\left(\frac{m^{2}\log\left(\frac{p^{2}\ell(\bm{x%&#10;})^{2}}{\delta}\right)}{\min(\sigma^{\ast}(\bm{x})^{2}\triangle(\bm{x})^{2},%&#10;\sigma^{\ast}(\bm{x})^{2})\nu_{\bm{x}}(\gamma)^{2}}\right)" display="inline"><mrow><mi>N</mi><mo>â‰¥</mo><mrow><mi class="ltx_font_mathcaligraphic">ğ’ª</mi><mo>â¢</mo><mrow><mo>(</mo><mstyle displaystyle="true"><mfrac><mrow><msup><mi>m</mi><mn>2</mn></msup><mo>â¢</mo><mrow><mi>log</mi><mo>â¡</mo><mrow><mo>(</mo><mfrac><mrow><msup><mi>p</mi><mn>2</mn></msup><mo>â¢</mo><mi mathvariant="normal">â„“</mi><mo>â¢</mo><msup><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow><mi>Î´</mi></mfrac><mo>)</mo></mrow></mrow></mrow><mrow><mo>min</mo><mo>â¡</mo><mrow><mrow><mo>(</mo><mrow><mrow><msup><mi>Ïƒ</mi><mo>âˆ—</mo></msup><mo>â¢</mo><msup><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mn>2</mn></msup><mo>â¢</mo><mi mathvariant="normal">â–³</mi><mo>â¢</mo><msup><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow><mo>,</mo><mrow><msup><mi>Ïƒ</mi><mo>âˆ—</mo></msup><mo>â¢</mo><msup><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow><mo>)</mo></mrow><mo>â¢</mo><msub><mi>Î½</mi><mi>ğ’™</mi></msub><mo>â¢</mo><msup><mrow><mo>(</mo><mi>Î³</mi><mo>)</mo></mrow><mn>2</mn></msup></mrow></mrow></mfrac></mstyle><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Then with probability <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmtheorem1.p2.m1" class="ltx_Math" alttext="1-\delta" display="inline"><mrow><mn mathvariant="normal">1</mn><mo mathvariant="normal">-</mo><mi>Î´</mi></mrow></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="Thmtheorem1.p2.m2" class="ltx_Math" alttext="\hat{u}=u(\bm{x})" display="inline"><mrow><mover accent="true"><mi>u</mi><mo mathvariant="normal" stretchy="false">^</mo></mover><mo mathvariant="normal">=</mo><mrow><mi>u</mi><mo mathvariant="italic">â¢</mo><mrow><mo mathvariant="italic">(</mo><mi>ğ±</mi><mo mathvariant="italic">)</mo></mrow></mrow></mrow></math>.</span></p>
</div>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p3.m1" class="ltx_Math" alttext="\nu_{\bm{x}}(\gamma)" display="inline"><mrow><msub><mi>Î½</mi><mi>ğ’™</mi></msub><mo>â¢</mo><mrow><mo>(</mo><mi>Î³</mi><mo>)</mo></mrow></mrow></math>, defined in the supplementary, is a function of the underlying distribution over the tag sequences <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p3.m2" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> and the kernel bandwidth <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p3.m3" class="ltx_Math" alttext="\gamma" display="inline"><mi>Î³</mi></math>.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p class="ltx_p">Thus, the sample complexity of our approach depends on the dimensionality of the latent and observed states (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p4.m1" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p4.m2" class="ltx_Math" alttext="p" display="inline"><mi>p</mi></math>), the underlying singular values of the cross-covariance matrices (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p4.m3" class="ltx_Math" alttext="\sigma^{\ast}(\bm{x})" display="inline"><mrow><msup><mi>Ïƒ</mi><mo>âˆ—</mo></msup><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>) and the difference in the cost of the true tree compared to the cost of the incorrect trees (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS5.p4.m4" class="ltx_Math" alttext="\triangle(\bm{x})" display="inline"><mrow><mi mathvariant="normal">â–³</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></math>).</p>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">We report results on three different languages: English, German, and Chinese. For English we use the Penn treebank <cite class="ltx_cite">[<a href="#bib.bibx30" title="" class="ltx_ref">Marcus et al.1993</a>]</cite>, with sections 2â€“21 for training and section 23 for final testing. For German and Chinese we use the Negra treebank and the Chinese treebank respectively and the first 80% of the sentences are used for training and the last 20% for testing. All punctuation from the data is removed.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup>We make brief use of punctuation for our top bracket heuristic detailed below before removing it.</span></span></span></p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">We primarily compare our method to the constituent-context model (CCM) of <cite class="ltx_cite"><a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a></cite>. We also compare our method to the algorithm of <cite class="ltx_cite"><a href="#bib.bibx35" title="" class="ltx_ref">Seginer2007</a></cite>.</p>
</div>
<div id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Settings</h3>

<div id="S4.SS1.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Top bracket heuristic</h4>

<div id="S4.SS1.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">Our algorithm requires the top bracket in order to direct the latent tree. In practice, we employ the following heuristic to find the bracket using the following three steps:</p>
<ul class="ltx_itemize">
<li id="I5.i1" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I5.i1.p1" class="ltx_para">
<p class="ltx_p">If there exists a comma/semicolon/colon at index <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i1.p1.m1" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> that has at least a verb before <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i1.p1.m2" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math> and both a noun followed by a verb after <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i1.p1.m3" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>, then return <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i1.p1.m4" class="ltx_Math" alttext="([0,i-1],[i,\ell(x)])" display="inline"><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mi>i</mi><mo>,</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow></math> as the top bracket. (Pick the rightmost comma/semicolon/colon if multiple satisfy the criterion).</p>
</div></li>
<li id="I5.i2" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I5.i2.p1" class="ltx_para">
<p class="ltx_p">Otherwise find the first non-participle verb (say at index <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i2.p1.m1" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math>) and return <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i2.p1.m2" class="ltx_Math" alttext="([0,j-1],[j,\ell(\bm{x})])" display="inline"><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mrow><mi>j</mi><mo>-</mo><mn>1</mn></mrow></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mi>j</mi><mo>,</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow></math>.</p>
</div></li>
<li id="I5.i3" class="ltx_item" style="list-style-type:none;"><span class="ltx_tag ltx_tag_itemize">â€¢</span> 
<div id="I5.i3.p1" class="ltx_para">
<p class="ltx_p">If no verb exists, return <math xmlns="http://www.w3.org/1998/Math/MathML" id="I5.i3.p1.m1" class="ltx_Math" alttext="([0,1],[1,\ell(\bm{x})])" display="inline"><mrow><mo>(</mo><mrow><mrow><mo>[</mo><mrow><mn>0</mn><mo>,</mo><mn>1</mn></mrow><mo>]</mo></mrow><mo>,</mo><mrow><mo>[</mo><mrow><mn>1</mn><mo>,</mo><mrow><mi mathvariant="normal">â„“</mi><mo>â¢</mo><mrow><mo>(</mo><mi>ğ’™</mi><mo>)</mo></mrow></mrow></mrow><mo>]</mo></mrow></mrow><mo>)</mo></mrow></math>.</p>
</div></li>
</ul>
</div>
</div>
<div id="S4.SS1.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Word embeddings</h4>

<div id="S4.SS1.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">As mentioned earlier, each <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P2.p1.m1" class="ltx_Math" alttext="w_{i}" display="inline"><msub><mi>w</mi><mi>i</mi></msub></math> can be an arbitrary feature vector. For all languages we use Brown clustering <cite class="ltx_cite">[<a href="#bib.bibx4" title="" class="ltx_ref">Brown et al.1992</a>]</cite> to construct a <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P2.p1.m2" class="ltx_Math" alttext="\log(C)+C" display="inline"><mrow><mrow><mi>log</mi><mo>â¡</mo><mrow><mo>(</mo><mi>C</mi><mo>)</mo></mrow></mrow><mo>+</mo><mi>C</mi></mrow></math> feature vector where the first <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P2.p1.m3" class="ltx_Math" alttext="\log(C)" display="inline"><mrow><mi>log</mi><mo>â¡</mo><mrow><mo>(</mo><mi>C</mi><mo>)</mo></mrow></mrow></math> elements indicate which mergable cluster the word belongs to, and the last <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P2.p1.m4" class="ltx_Math" alttext="C" display="inline"><mi>C</mi></math> elements indicate the cluster identity. For English, more sophisticated word embeddings are easily obtainable, and we experiment with neural word embeddingsÂ <cite class="ltx_cite"><a href="#bib.bibx41" title="" class="ltx_ref">Turian et al.2010</a></cite> of length 50. We also explored two types of CCA embeddings: OSCCA and TSCCA, given inÂ <cite class="ltx_cite"><a href="#bib.bibx13" title="" class="ltx_ref">Dhillon et al.2012</a></cite>. The OSCCA embeddings behaved better, so we only report its results.</p>
</div>
</div>
<div id="S4.SS1.SSS0.P3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Choice of kernel</h4>

<div id="S4.SS1.SSS0.P3.p1" class="ltx_para">
<p class="ltx_p">For our experiments, we use the kernel</p>
<table id="A0.EGx11" class="ltx_equationgroup ltx_eqn_align">

<tr id="S4.Ex10" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"/>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.Ex10.m2" class="ltx_Math" alttext="\displaystyle K_{\gamma}(j,k,j^{\prime},k^{\prime}|\bm{x},\bm{x}^{\prime})" display="inline"><mrow><msub><mi>K</mi><mi>Î³</mi></msub><mrow><mo>(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><mi>ğ’™</mi><mo>,</mo><msup><mi>ğ’™</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
<tr id="S4.Ex11" class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_td ltx_align_right"/>
<td class="ltx_td ltx_align_left"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.Ex11.m2" class="ltx_Math" alttext="\displaystyle=\max\left\{0,1-\displaystyle\frac{\kappa(j,k,j^{\prime},k^{%&#10;\prime}|\bm{x},\bm{x}^{\prime})}{\gamma}\right\}" display="inline"><mrow><mi/><mo>=</mo><mrow><mo movablelimits="false">max</mo><mo>â¡</mo><mrow><mo>{</mo><mrow><mn>0</mn><mo>,</mo><mrow><mn>1</mn><mo>-</mo><mstyle displaystyle="true"><mfrac><mrow><mi>Îº</mi><mrow><mo>(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><mi>ğ’™</mi><mo>,</mo><msup><mi>ğ’™</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow><mi>Î³</mi></mfrac></mstyle></mrow></mrow><mo>}</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m1" class="ltx_Math" alttext="\gamma" display="inline"><mi>Î³</mi></math> denotes the user-specified bandwidth, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m2" class="ltx_Math" alttext="\kappa(j,k,j^{\prime},k^{\prime}|\bm{x},\bm{x}^{\prime})=\displaystyle\frac{|j%&#10;-k|-|j^{\prime}-k^{\prime}|}{|j-k|+|j^{\prime}-k^{\prime}|}" display="inline"><mrow><mi>Îº</mi><mrow><mo>(</mo><mi>j</mi><mo>,</mo><mi>k</mi><mo>,</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>,</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>|</mo><mi>ğ’™</mi><mo>,</mo><msup><mi>ğ’™</mi><mo>â€²</mo></msup><mo>)</mo></mrow><mo>=</mo><mstyle displaystyle="true"><mfrac><mrow><mrow><mo fence="true">|</mo><mrow><mi>j</mi><mo>-</mo><mi>k</mi></mrow><mo fence="true">|</mo></mrow><mo>-</mo><mrow><mo fence="true">|</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>-</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo fence="true">|</mo></mrow></mrow><mrow><mrow><mo fence="true">|</mo><mrow><mi>j</mi><mo>-</mo><mi>k</mi></mrow><mo fence="true">|</mo></mrow><mo>+</mo><mrow><mo fence="true">|</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>-</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo fence="true">|</mo></mrow></mrow></mfrac></mstyle></mrow></math> if <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m3" class="ltx_Math" alttext="\bm{x}(j)=\bm{x}(j^{\prime})" display="inline"><mrow><mrow><mi>ğ’™</mi><mo>â¢</mo><mrow><mo>(</mo><mi>j</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>ğ’™</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>j</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow></mrow></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m4" class="ltx_Math" alttext="\bm{x}(k^{\prime})=\bm{x}(k)" display="inline"><mrow><mrow><mi>ğ’™</mi><mo>â¢</mo><mrow><mo>(</mo><msup><mi>k</mi><mo>â€²</mo></msup><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mi>ğ’™</mi><mo>â¢</mo><mrow><mo>(</mo><mi>k</mi><mo>)</mo></mrow></mrow></mrow></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m5" class="ltx_Math" alttext="\textrm{sign}(j-k)=\textrm{sign}(j^{\prime}-k^{\prime})" display="inline"><mrow><mrow><mtext>sign</mtext><mo>â¢</mo><mrow><mo>(</mo><mrow><mi>j</mi><mo>-</mo><mi>k</mi></mrow><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mtext>sign</mtext><mo>â¢</mo><mrow><mo>(</mo><mrow><msup><mi>j</mi><mo>â€²</mo></msup><mo>-</mo><msup><mi>k</mi><mo>â€²</mo></msup></mrow><mo>)</mo></mrow></mrow></mrow></math> (and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p1.m6" class="ltx_Math" alttext="\infty" display="inline"><mi mathvariant="normal">âˆ</mi></math> otherwise).</p>
</div>
<div id="S4.SS1.SSS0.P3.p2" class="ltx_para">
<p class="ltx_p">The kernel is non-zero if and only if the tags at position <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m1" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m2" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m3" class="ltx_Math" alttext="\bm{x}" display="inline"><mi>ğ’™</mi></math> are identical to the ones in position <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m4" class="ltx_Math" alttext="j^{\prime}" display="inline"><msup><mi>j</mi><mo>â€²</mo></msup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m5" class="ltx_Math" alttext="k^{\prime}" display="inline"><msup><mi>k</mi><mo>â€²</mo></msup></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m6" class="ltx_Math" alttext="\bm{x}^{\prime}" display="inline"><msup><mi>ğ’™</mi><mo>â€²</mo></msup></math>, and if the direction between <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m7" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math>
and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m8" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> is identical to the one between <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m9" class="ltx_Math" alttext="j^{\prime}" display="inline"><msup><mi>j</mi><mo>â€²</mo></msup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m10" class="ltx_Math" alttext="k^{\prime}" display="inline"><msup><mi>k</mi><mo>â€²</mo></msup></math>. Note that the kernel is not binary, as opposed to the theoretical kernel in the supplementary material.
Our experiments show that using a non-zero value different than 1 that is a function of the distance between <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m11" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m12" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> compared to the distance between <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m13" class="ltx_Math" alttext="j^{\prime}" display="inline"><msup><mi>j</mi><mo>â€²</mo></msup></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P3.p2.m14" class="ltx_Math" alttext="k^{\prime}" display="inline"><msup><mi>k</mi><mo>â€²</mo></msup></math> does better in practice.</p>
</div>
<div id="S4.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">Length</span></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">CCM</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">CCM-U</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">CCM-OB</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">CCM-UB</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m1" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">72.5</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">57.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">58.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">62.9</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m2" class="ltx_Math" alttext="\leq 15" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>15</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">54.1</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">36</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">24</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">23.7</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m3" class="ltx_Math" alttext="\leq 20" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>20</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">50</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">34.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">19.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">19.1</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m4" class="ltx_Math" alttext="\leq 25" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>25</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">47.2</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">30.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">16.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">16.6</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m5" class="ltx_Math" alttext="\leq 30" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>30</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">44.8</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">29.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">15.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">15.2</span></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T1.m6" class="ltx_Math" alttext="\leq 40" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>40</mn></mrow></math></th>
<th class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">26.3</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">13.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">13.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">13.8</span></td></tr>
</tbody>
</table>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">TableÂ 1: </span>Comparison of different CCM variants on English (training). U stands for universal POS tagset, OB stands for conjoining original POS tags with Brown clusters and UB stands for
conjoining universal POS tags with Brown clusters. The best setting is just the vanilla setting, CCM.</div>
</div>
<div id="S4.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r ltx_border_t"/>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m1" class="ltx_Math" alttext="\ell" display="inline"><mi mathvariant="normal">â„“</mi></math></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" colspan="7"><span class="ltx_text ltx_font_small">English</span></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_rr ltx_border_t" colspan="3"><span class="ltx_text ltx_font_small">German</span></td>
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span class="ltx_text ltx_font_small">Chinese</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_border_r"/>
<td class="ltx_td ltx_border_rr"/>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">NN-O</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">NN</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">CC-O</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">CC</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC-O</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">CCM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC-O</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">CCM</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC-O</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">BC</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">CCM</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span class="ltx_text ltx_font_small">
<span class="ltx_inline-block ltx_transformed_outer" style="width:8.1pt;height:46.8055555555556px;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:33.7pt;transform:translate(-12.82pt,12.82pt) rotate(-90deg) ;-webkit-transform:translate(-12.82pt,12.82pt) rotate(-90deg) ;-ms-transform:translate(-12.82pt,12.82pt) rotate(-90deg) ;">
<p class="ltx_p">train</p>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m2" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">70.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">69.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">70.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">68.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">71.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">69.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">72.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">64.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">59.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span class="ltx_text ltx_font_small">62.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">64.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">57.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_small">46.1</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m3" class="ltx_Math" alttext="\leq 20" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>20</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">55.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">53.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">53.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">51.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">53.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">51.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">50</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">52.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">47.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">51.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">22.4</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m4" class="ltx_Math" alttext="\leq 40" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>40</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">44.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">43.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">41.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">43.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">41.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">26.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">43.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">19.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">42.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">15</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_tt" rowspan="6"><span class="ltx_text ltx_font_small">
<span class="ltx_inline-block ltx_transformed_outer" style="width:8.1pt;height:37.5px;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:27.0pt;transform:translate(-9.45pt,9.45pt) rotate(-90deg) ;-webkit-transform:translate(-9.45pt,9.45pt) rotate(-90deg) ;-ms-transform:translate(-9.45pt,9.45pt) rotate(-90deg) ;">
<p class="ltx_p">test</p>
</span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m5" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">69.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">66.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">68.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">65.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">68.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">66.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_small">70.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">66.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">61.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span class="ltx_text ltx_font_small">64.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">58.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">53.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span class="ltx_text ltx_font_small">40.7</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m6" class="ltx_Math" alttext="\leq 15" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>15</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">60.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">58.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">58.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">56.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">58.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">56.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">53.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">57.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">53.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">49.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">54.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">49.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">35.9</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m7" class="ltx_Math" alttext="\leq 20" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>20</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">54.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">52.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">52.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">50.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">51.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">50.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">50.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">52.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">49.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">48.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">49.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">45.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">20.1</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m8" class="ltx_Math" alttext="\leq 25" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>25</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">50.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">49.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">47.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">50.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">45.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">42.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">17.8</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m9" class="ltx_Math" alttext="\leq 30" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>30</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">46.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">45.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">43.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">45.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">43.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">44.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">48.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">45.4</span></td>
<td class="ltx_td ltx_align_center ltx_border_rr"><span class="ltx_text ltx_font_small">21.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">44.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">40.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_small">16.1</span></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m10" class="ltx_Math" alttext="\leq 40" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>40</mn></mrow></math></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">45.5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">43.8</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">43.0</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">41.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">42.7</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">41.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span class="ltx_text ltx_font_small">26.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">46.9</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">44.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_rr"><span class="ltx_text ltx_font_small">20.1</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">42.2</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">38.6</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_small">14.3</span></td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_font_small"><span class="ltx_tag ltx_tag_table">TableÂ 2: </span><math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m14" class="ltx_Math" alttext="F_{1}" display="inline"><msub><mi mathsize="normal" stretchy="false">F</mi><mn mathsize="normal" stretchy="false">1</mn></msub></math> bracketing measure for the test sets and train sets in three languages. NN, CC, and BC indicate the performance of our method
for neural embeddings, CCA embeddings, and Brown clustering respectively, using the heuristic for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m15" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi mathsize="normal" stretchy="false">h</mi><mi mathsize="normal" stretchy="false">dir</mi></msub></math> described in Â§Â <a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. NN-O, CC-O, and BC-O indicate that the oracle (i.e. true top bracket) was used for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.T2.m16" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi mathsize="normal" stretchy="false">h</mi><mi mathsize="normal" stretchy="false">dir</mi></msub></math>.</div>
</div>
</div>
<div id="S4.SS1.SSS0.P4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Choice of data</h4>

<div id="S4.SS1.SSS0.P4.p1" class="ltx_para">
<p class="ltx_p">For CCM, we found that if the full dataset (all sentence lengths) is used in training, then performance degrades when evaluating on sentences of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P4.p1.m1" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math>. We therefore restrict the data used with CCM to sentences of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P4.p1.m2" class="ltx_Math" alttext="\leq\ell" display="inline"><mrow><mi/><mo>â‰¤</mo><mi mathvariant="normal">â„“</mi></mrow></math>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P4.p1.m3" class="ltx_Math" alttext="\ell" display="inline"><mi mathvariant="normal">â„“</mi></math> is the maximal sentence length being evaluated. This does not happen with our algorithm, which manages to leverage lexical information whenever more data is available. We therefore use the full data for our method for all lengths.</p>
</div>
<div id="S4.SS1.SSS0.P4.p2" class="ltx_para">
<p class="ltx_p">We also experimented with the original POS tags and the universal POS tags of <cite class="ltx_cite"><a href="#bib.bibx32" title="" class="ltx_ref">Petrov et al.2011</a></cite>. Here, we found out that our method does better with the universal part of speech tags. For CCM, we also experimented with the original parts of speech, universal tags (CCM-U), the cross-product of the original parts of speech with the Brown clusters (CCM-OB), and the cross-product of the universal tags with the Brown clusters (CCM-UB). The results in TableÂ <a href="#S4.T1" title="TableÂ 1 â€£ Choice of kernel â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> indicate that the vanilla setting is the best for CCM.</p>
</div>
<div id="S4.SS1.SSS0.P4.p3" class="ltx_para">
<p class="ltx_p">Thus, for all results, we use universal tags for our method and the original POS tags for CCM. We believe that our approach substitutes the need for fine-grained POS tags with the lexical information. CCM, on the other hand, is fully unlexicalized.</p>
</div>
</div>
<div id="S4.SS1.SSS0.P5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Parameter Selection</h4>

<div id="S4.SS1.SSS0.P5.p1" class="ltx_para">
<p class="ltx_p">Our method requires two parameters, the latent dimension <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m1" class="ltx_Math" alttext="m" display="inline"><mi>m</mi></math> and the bandwidth <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m2" class="ltx_Math" alttext="\gamma" display="inline"><mi>Î³</mi></math>.
CCM also has two parameters, the number of extra constituent/distituent counts used for smoothing. For both methods we chose the best parameters for sentences of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m3" class="ltx_Math" alttext="\ell\leq 10" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>10</mn></mrow></math> on the English Penn Treebank (training) and used this set for all other experiments.
This resulted in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m4" class="ltx_Math" alttext="m=7,\gamma=0.4" display="inline"><mrow><mrow><mi>m</mi><mo>=</mo><mn>7</mn></mrow><mo>,</mo><mrow><mi>Î³</mi><mo>=</mo><mn>0.4</mn></mrow></mrow></math> for our method and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m5" class="ltx_Math" alttext="2" display="inline"><mn>2</mn></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS1.SSS0.P5.p1.m6" class="ltx_Math" alttext="8" display="inline"><mn>8</mn></math> for CCMâ€™s extra constituent/distituent counts respectively. We also tried letting CCM choose different hyperparameters for different sentence lengths based on dev-set likelihood, but this gave worse results than holding them fixed.</p>
</div>
<div id="S4.F4" class="ltx_figure"><img src="P14-1100/image005.png" id="S4.F4.g1" class="ltx_graphics ltx_centering" width="539" height="314" alt=""/>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_figure">FigureÂ 4: </span> Histogram showing performance of CCM across 100 random restarts for sentences of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.F4.m2" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math>.</div>
</div>
</div>
</div>
<div id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">4.2 </span>Results</h3>

<div id="S4.SS2.SSS0.P1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Test I: Accuracy</h4>

<div id="S4.SS2.SSS0.P1.p1" class="ltx_para">
<p class="ltx_p">TableÂ <a href="#S4.T2" title="TableÂ 2 â€£ Choice of kernel â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> summarizes our results.
CCM is used with the initializer proposed in <cite class="ltx_cite"><a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a></cite>.<span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup>We used the implementation available at <span class="ltx_text ltx_font_sansserif">http://tinyurl.com/lhwk5n6</span>.</span></span></span> NN, CC, and BC indicate the performance of our method
for neural embeddings, CCA embeddings, and Brown clustering respectively, using the heuristic for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p1.m1" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math> described in Â§Â <a href="#S4.SS1" title="4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>. NN-O, CC-O, and BC-O indicate that the oracle (i.e. true top bracket) was used for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p1.m2" class="ltx_Math" alttext="h_{\mathrm{dir}}" display="inline"><msub><mi>h</mi><mi>dir</mi></msub></math>. For our method, test set results can be obtained by using AlgorithmÂ <a href="#S3.SS3" title="3.3 Recovering the Minimal Projective Latent Tree â€£ 3 Spectral Learning Algorithm based on Additive Tree Metrics â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3</span></a> (except the distances are computed using the training data).</p>
</div>
<div id="S4.SS2.SSS0.P1.p2" class="ltx_para">
<p class="ltx_p">For English, while CCM behaves better for short sentences (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p2.m1" class="ltx_Math" alttext="\ell\leq 10" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>10</mn></mrow></math>), our algorithm is more robust with longer sentences.
This is especially noticeable for length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p2.m2" class="ltx_Math" alttext="\leq 40" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>40</mn></mrow></math>,
where CCM breaks down and our algorithm is more stable.
We find that the neural embeddings modestly outperform the CCA and Brown cluster embeddings.</p>
</div>
<div id="S4.SS2.SSS0.P1.p3" class="ltx_para">
<p class="ltx_p">The results for German are similar, except CCM breaks down earlier at sentences of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p3.m1" class="ltx_Math" alttext="\ell\leq 30" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>30</mn></mrow></math>. For Chinese, our method substantially outperforms CCM for all lengths. Note that CCM performs very poorly, obtaining only around <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p3.m2" class="ltx_Math" alttext="20\%" display="inline"><mrow><mn>20</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> accuracy even for sentences of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P1.p3.m3" class="ltx_Math" alttext="\ell\leq 20" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>20</mn></mrow></math>. We didnâ€™t have neural embeddings for German and Chinese (which worked best for English) and thus only used Brown cluster embeddings.</p>
</div>
<div id="S4.SS2.SSS0.P1.p4" class="ltx_para">
<p class="ltx_p">For English, the disparity between NN-O (oracle top bracket) and NN (heuristic top bracket) is rather low suggesting that our top bracket heuristic is rather effective. However, for German and Chinese note that the â€œBC-Oâ€ performs substantially better, suggesting that if we had a better top bracket heuristic our performance would increase.</p>
</div>
</div>
<div id="S4.SS2.SSS0.P2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Test II: Sensitivity to initialization</h4>

<div id="S4.SS2.SSS0.P2.p1" class="ltx_para">
<p class="ltx_p">The EM algorithm with the CCM requires very careful initialization, which is described in <cite class="ltx_cite"><a href="#bib.bibx27" title="" class="ltx_ref">Klein and Manning2002</a></cite>. If, on the other hand, random initialization is used, the variance of the
performance of the CCM varies greatly. FigureÂ <a href="#S4.F4" title="FigureÂ 4 â€£ Parameter Selection â€£ 4.1 Experimental Settings â€£ 4 Experiments â€£ Spectral Unsupervised Parsing with Additive Tree Metrics" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows a histogram of the performance level for sentences of length <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P2.p1.m1" class="ltx_Math" alttext="\leq 10" display="inline"><mrow><mi/><mo>â‰¤</mo><mn>10</mn></mrow></math> for different random
initializers. As one can see, for some restarts, CCM obtains accuracies lower than <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P2.p1.m2" class="ltx_Math" alttext="30\%" display="inline"><mrow><mn>30</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> due to local optima.
Our method does not suffer from local optima and thus does not require careful initialization.</p>
</div>
</div>
<div id="S4.SS2.SSS0.P3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Test III: Comparison to Seginerâ€™s algorithm</h4>

<div id="S4.SS2.SSS0.P3.p1" class="ltx_para">
<p class="ltx_p">Our approach is not directly comparable to Seginerâ€™s because he uses punctuation, while we use POS tags. Using Seginerâ€™s parser we were able to get results on the training sets. On English: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m1" class="ltx_Math" alttext="75.2\%" display="inline"><mrow><mn>75.2</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m2" class="ltx_Math" alttext="\ell\leq 10" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>10</mn></mrow></math>), <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m3" class="ltx_Math" alttext="64.2\%" display="inline"><mrow><mn>64.2</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m4" class="ltx_Math" alttext="\ell\leq 20" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>20</mn></mrow></math>), <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m5" class="ltx_Math" alttext="56.7\%" display="inline"><mrow><mn>56.7</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m6" class="ltx_Math" alttext="\ell\leq 40" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>40</mn></mrow></math>). On German: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m7" class="ltx_Math" alttext="57.8\%" display="inline"><mrow><mn>57.8</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m8" class="ltx_Math" alttext="\ell\leq 10" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>10</mn></mrow></math>), <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m9" class="ltx_Math" alttext="45.0\%" display="inline"><mrow><mn>45.0</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m10" class="ltx_Math" alttext="\ell\leq 20" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>20</mn></mrow></math>), and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m11" class="ltx_Math" alttext="39.9\%" display="inline"><mrow><mn>39.9</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m12" class="ltx_Math" alttext="\ell\leq 40" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>40</mn></mrow></math>). On Chinese: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m13" class="ltx_Math" alttext="56.6\%" display="inline"><mrow><mn>56.6</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m14" class="ltx_Math" alttext="\ell\leq 10" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>10</mn></mrow></math>), <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m15" class="ltx_Math" alttext="45.1\%" display="inline"><mrow><mn>45.1</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m16" class="ltx_Math" alttext="\ell\leq 20" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>20</mn></mrow></math>), and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m17" class="ltx_Math" alttext="38.9\%" display="inline"><mrow><mn>38.9</mn><mo>â¢</mo><mi mathvariant="normal">%</mi></mrow></math> (<math xmlns="http://www.w3.org/1998/Math/MathML" id="S4.SS2.SSS0.P3.p1.m18" class="ltx_Math" alttext="\ell\leq 40" display="inline"><mrow><mi mathvariant="normal">â„“</mi><mo>â‰¤</mo><mn>40</mn></mrow></math>).</p>
</div>
<div id="S4.SS2.SSS0.P3.p2" class="ltx_para">
<p class="ltx_p">Thus, while Seginerâ€™s method performs better on English, our approach performs 2-3 points better on German, and both methods give similar performance on Chinese.</p>
</div>
</div>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">We described a spectral approach for unsupervised constituent parsing that comes with theoretical guarantees on latent structure recovery. Empirically, our algorithm performs favorably to the CCM of Klein and Manning (2002) without the need for careful initialization.

<br class="ltx_break"/>
<br class="ltx_break"/><span class="ltx_text ltx_font_bold">Acknowledgements</span>: This work is supported by NSF IIS1218282, NSF IIS1111142, NIH R01GM093156, and the NSF Graduate Research Fellowship Program under Grant No. 0946825 (NSF Fellowship to APP).</p>
</div>
<div class="ltx_pagination ltx_role_newpage"/>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bibx1" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Anandkumar et al.2011</span>
<span class="ltx_bibblock">
A.Â Anandkumar, K.Â Chaudhuri, D.Â Hsu, S.Â M. Kakade, L.Â Song, and T.Â Zhang.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Spectral methods for learning multivariate latent tree structure.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1107.1283</span>.

</span></li>
<li id="bib.bibx2" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Bailly et al.2009</span>
<span class="ltx_bibblock">
R.Â Bailly, F.Â Denis, and L.Â Ralaivola.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">Grammatical inference as a principal component analysis problem.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ICML</span>.

</span></li>
<li id="bib.bibx3" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Bailly et al.2013</span>
<span class="ltx_bibblock">
R.Â Bailly, X.Â Carreras, F.Â M. Luque, and A.Â Quattoni.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Unsupervised spectral learning of WCFG as low-rank matrix
completion.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of EMNLP</span>.

</span></li>
<li id="bib.bibx4" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Brown et al.1992</span>
<span class="ltx_bibblock">
P.Â F. Brown, P.V. Desouza, R.L. Mercer, V.J.D. Pietra, and J.C. Lai.

</span>
<span class="ltx_bibblock">1992.

</span>
<span class="ltx_bibblock">Class-based n-gram models of natural language.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Computational linguistics</span>, 18(4):467â€“479.

</span></li>
<li id="bib.bibx5" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Buneman1971</span>
<span class="ltx_bibblock">
O.Â P. Buneman.

</span>
<span class="ltx_bibblock">1971.

</span>
<span class="ltx_bibblock">The recovery of trees from measures of dissimilarity.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Mathematics in the archaeological and historical sciences</span>.

</span></li>
<li id="bib.bibx6" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Buneman1974</span>
<span class="ltx_bibblock">
P.Â Buneman.

</span>
<span class="ltx_bibblock">1974.

</span>
<span class="ltx_bibblock">A note on the metric properties of trees.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Journal of Combinatorial Theory, Series B</span>, 17(1):48â€“50.

</span></li>
<li id="bib.bibx7" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Choi et al.2011</span>
<span class="ltx_bibblock">
M.J. Choi, V.Â YF Tan, A.Â Anandkumar, and A.S. Willsky.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Learning latent tree graphical models.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The Journal of Machine Learning Research</span>, 12:1771â€“1812.

</span></li>
<li id="bib.bibx8" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Chow and Liu1968</span>
<span class="ltx_bibblock">
C.Â K. Chow and C.Â N. Liu.

</span>
<span class="ltx_bibblock">1968.

</span>
<span class="ltx_bibblock">Approximating Discrete Probability Distributions With Dependence
Trees.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">IEEE Transactions on Information Theory</span>, IT-14:462â€“467.

</span></li>
<li id="bib.bibx9" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Cohen and Smith2009</span>
<span class="ltx_bibblock">
S.Â B. Cohen and N.Â A. Smith.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">Shared logistic normal distributions for soft parameter tying in
unsupervised grammar induction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of HLT-NAACL</span>.

</span></li>
<li id="bib.bibx10" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Cohen and Smith2012</span>
<span class="ltx_bibblock">
S.Â B. Cohen and N.Â A. Smith.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Empirical risk minimization for probabilistic grammars: Sample
complexity and hardness of learning.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Computational Linguistics</span>, 38(3):479â€“526.

</span></li>
<li id="bib.bibx11" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Cohen et al.2012</span>
<span class="ltx_bibblock">
S.Â B. Cohen, K.Â Stratos, M.Â Collins, D.Â P. Foster, and L.Â Ungar.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Spectral learning of latent-variable PCFGs.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx12" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Desper and Gascuel2005</span>
<span class="ltx_bibblock">
R.Â Desper and O.Â Gascuel.

</span>
<span class="ltx_bibblock">2005.

</span>
<span class="ltx_bibblock">The minimum evolution distance-based approach to phylogenetic
inference.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Mathematics of evolution and phylogeny</span>, pages 1â€“32.

</span></li>
<li id="bib.bibx13" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Dhillon et al.2012</span>
<span class="ltx_bibblock">
P.Â S. Dhillon, J.Â Rodu, D.Â P. Foster, and L.Â H. Ungar.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Two step cca: A new spectral method for estimating vector models of
words.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ICML</span>.

</span></li>
<li id="bib.bibx14" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Eisner and Satta1999</span>
<span class="ltx_bibblock">
J.Â Eisner and G.Â Satta.

</span>
<span class="ltx_bibblock">1999.

</span>
<span class="ltx_bibblock">Efficient parsing for bilexical context-free grammars and head
automaton grammars.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx15" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">ErdÃµs et al.1999</span>
<span class="ltx_bibblock">
P.Â ErdÃµs, M.Â Steel, L.Â SzÃ©kely, and T.Â Warnow.

</span>
<span class="ltx_bibblock">1999.

</span>
<span class="ltx_bibblock">A few logs suffice to build (almost) all trees: Part ii.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Theoretical Computer Science</span>, 221(1):77â€“118.

</span></li>
<li id="bib.bibx16" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Gillenwater et al.2010</span>
<span class="ltx_bibblock">
J.Â Gillenwater, K.Â Ganchev, J.Â GraÃ§a, F.Â Pereira, and B.Â Taskar.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Sparsity in dependency grammar induction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx17" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Gimpel and Smith2012</span>
<span class="ltx_bibblock">
K.Â Gimpel and N.A. Smith.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Concavity and initialization for unsupervised dependency parsing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of NAACL</span>.

</span></li>
<li id="bib.bibx18" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Golland et al.2012</span>
<span class="ltx_bibblock">
D.Â Golland, J.Â DeNero, and J.Â Uszkoreit.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">A feature-rich constituent context model for grammar induction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx19" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Gormley and Eisner2013</span>
<span class="ltx_bibblock">
M.Â Gormley and J.Â Eisner.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Nonconvex global optimization for latent-variable models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx20" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Harmeling and Williams2011</span>
<span class="ltx_bibblock">
S.Â Harmeling and C.Â KI Williams.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Greedy learning of binary latent trees.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Pattern Analysis and Machine Intelligence, IEEE Transactions
on</span>, 33(6):1087â€“1097.

</span></li>
<li id="bib.bibx21" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Hastie et al.2009</span>
<span class="ltx_bibblock">
T.Â Hastie, R.Â Tibshirani, and J.Â Friedman.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The Elements of Statistical Learning: Data Mining, Inference,
and Prediction</span>.

</span>
<span class="ltx_bibblock">Springer Series in Statistics. Springer Verlag.

</span></li>
<li id="bib.bibx22" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Headden et al.2009</span>
<span class="ltx_bibblock">
W.Â P. Headden, M.Â Johnson, and D.Â McClosky.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">Improving unsupervised dependency parsing with richer contexts and
smoothing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of NAACL-HLT</span>.

</span></li>
<li id="bib.bibx23" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Hsu et al.2009</span>
<span class="ltx_bibblock">
D.Â Hsu, S.Â Kakade, and T.Â Zhang.

</span>
<span class="ltx_bibblock">2009.

</span>
<span class="ltx_bibblock">A spectral algorithm for learning hidden Markov models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of COLT</span>.

</span></li>
<li id="bib.bibx24" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Hsu et al.2012</span>
<span class="ltx_bibblock">
D.Â Hsu, S.Â M. Kakade, and P.Â Liang.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Identifiability and unmixing of latent parse trees.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1206.3137</span>.

</span></li>
<li id="bib.bibx25" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Ishteva et al.2012</span>
<span class="ltx_bibblock">
M.Â Ishteva, H.Â Park, and L.Â Song.

</span>
<span class="ltx_bibblock">2012.

</span>
<span class="ltx_bibblock">Unfolding latent tree structures using 4th order tensors.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">arXiv preprint arXiv:1210.1258</span>.

</span></li>
<li id="bib.bibx26" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Jelinek et al.1992</span>
<span class="ltx_bibblock">
F.Â Jelinek, J.Â D. Lafferty, and R.Â L. Mercer.

</span>
<span class="ltx_bibblock">1992.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Basic methods of probabilistic context free grammars</span>.

</span>
<span class="ltx_bibblock">Springer.

</span></li>
<li id="bib.bibx27" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Klein and Manning2002</span>
<span class="ltx_bibblock">
D.Â Klein and C.Â D. Manning.

</span>
<span class="ltx_bibblock">2002.

</span>
<span class="ltx_bibblock">A generative constituent-context model for improved grammar
induction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx28" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Kolar et al.2010a</span>
<span class="ltx_bibblock">
M.Â Kolar, A.Â P. Parikh, and E.Â P. Xing.

</span>
<span class="ltx_bibblock">2010a.

</span>
<span class="ltx_bibblock">On sparse nonparametric conditional covariance selection.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ICML</span>.

</span></li>
<li id="bib.bibx29" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Kolar et al.2010b</span>
<span class="ltx_bibblock">
M.Â Kolar, L.Â Song, A.Â Ahmed, and E.Â P. Xing.

</span>
<span class="ltx_bibblock">2010b.

</span>
<span class="ltx_bibblock">Estimating time-varying networks.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">The Annals of Applied Statistics</span>, 4(1):94â€“123.

</span></li>
<li id="bib.bibx30" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Marcus et al.1993</span>
<span class="ltx_bibblock">
M.Â P. Marcus, B.Â Santorini, and M.Â A. Marcinkiewicz.

</span>
<span class="ltx_bibblock">1993.

</span>
<span class="ltx_bibblock">Building a large annotated corpus of English: The Penn treebank.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Computational Linguistics</span>, 19:313â€“330.

</span></li>
<li id="bib.bibx31" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Parikh et al.2011</span>
<span class="ltx_bibblock">
A.P. Parikh, L.Â Song, and E.P. Xing.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">A spectral algorithm for latent tree graphical models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ICML</span>.

</span></li>
<li id="bib.bibx32" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Petrov et al.2011</span>
<span class="ltx_bibblock">
S.Â Petrov, D.Â Das, and R.Â McDonald.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">A universal part-of-speech tagset.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">ArXiv:1104.2086</span>.

</span></li>
<li id="bib.bibx33" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Rzhetsky and Nei1993</span>
<span class="ltx_bibblock">
A.Â Rzhetsky and M.Â Nei.

</span>
<span class="ltx_bibblock">1993.

</span>
<span class="ltx_bibblock">Theoretical foundation of the minimum-evolution method of
phylogenetic inference.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Molecular Biology and Evolution</span>, 10(5):1073â€“1095.

</span></li>
<li id="bib.bibx34" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Saitou and Nei1987</span>
<span class="ltx_bibblock">
N.Â Saitou and M.Â Nei.

</span>
<span class="ltx_bibblock">1987.

</span>
<span class="ltx_bibblock">The neighbor-joining method: a new method for reconstructing
phylogenetic trees.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Molecular biology and evolution</span>, 4(4):406â€“425.

</span></li>
<li id="bib.bibx35" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Seginer2007</span>
<span class="ltx_bibblock">
Y.Â Seginer.

</span>
<span class="ltx_bibblock">2007.

</span>
<span class="ltx_bibblock">Fast unsupervised incremental parsing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx36" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Smith and Eisner2005</span>
<span class="ltx_bibblock">
N.Â A. Smith and J.Â Eisner.

</span>
<span class="ltx_bibblock">2005.

</span>
<span class="ltx_bibblock">Contrastive estimation: Training log-linear models on unlabeled data.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx37" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Song et al.2011</span>
<span class="ltx_bibblock">
L.Â Song, A.P. Parikh, and E.P. Xing.

</span>
<span class="ltx_bibblock">2011.

</span>
<span class="ltx_bibblock">Kernel embeddings of latent tree graphical models.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of NIPS</span>.

</span></li>
<li id="bib.bibx38" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Spitkovsky et al.2010a</span>
<span class="ltx_bibblock">
V.Â I. Spitkovsky, H.Â Alshawi, and D.Â Jurafsky.

</span>
<span class="ltx_bibblock">2010a.

</span>
<span class="ltx_bibblock">From baby steps to leapfrog: how less is more in unsupervised
dependency parsing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of NAACL</span>.

</span></li>
<li id="bib.bibx39" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Spitkovsky et al.2010b</span>
<span class="ltx_bibblock">
V.Â I. Spitkovsky, H.Â Alshawi, D.Â Jurafsky, and C.Â D. Manning.

</span>
<span class="ltx_bibblock">2010b.

</span>
<span class="ltx_bibblock">Viterbi training improves unsupervised dependency parsing.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of CoNLL</span>.

</span></li>
<li id="bib.bibx40" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Spitkovsky et al.2013</span>
<span class="ltx_bibblock">
V.Â I. Spitkovsky, H.Â Alshawi, and D.Â Jurafsky.

</span>
<span class="ltx_bibblock">2013.

</span>
<span class="ltx_bibblock">Breaking out of local optima with count transforms and model
recombination: A study in grammar induction.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of EMNLP</span>.

</span></li>
<li id="bib.bibx41" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Turian et al.2010</span>
<span class="ltx_bibblock">
J.Â P. Turian, L.-A. Ratinov, and Y.Â Bengio.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Word representations: A simple and general method for semi-supervised
learning.

</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_font_italic">Proceedings of ACL</span>.

</span></li>
<li id="bib.bibx42" class="ltx_bibitem"><span class="ltx_bibtag ltx_role_refnum">Zhou et al.2010</span>
<span class="ltx_bibblock">
S.Â Zhou, J.Â Lafferty, and L.Â Wasserman.

</span>
<span class="ltx_bibblock">2010.

</span>
<span class="ltx_bibblock">Time varying undirected graphs.

</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_font_italic">Machine Learning</span>, 80(2-3):295â€“319.

</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Jun 10 18:28:07 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
