<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 plus MathML 2.0//EN" "http://www.w3.org/Math/DTD/mathml2/xhtml-math11-f.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<title>Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation</title>
<!--Generated on Wed Jun 11 18:10:59 2014 by LaTeXML (version 0.8.0) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on .-->

<meta http-equiv="Content-Type" content="application/xhtml+xml; charset=UTF-8"/>
<link rel="stylesheet" href="LaTeXML.css" type="text/css"/>
<link rel="stylesheet" href="ltx-article.css" type="text/css"/>
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<div class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yu-Chun Wang 
<br class="ltx_break"/>Department of CSIE
<br class="ltx_break"/>National Taiwan University
<br class="ltx_break"/>Taipei, Taiwan 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">d97023@csie.ntu.edu.tw</span> 
<br class="ltx_break"/>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Chun-Kai Wu 
<br class="ltx_break"/>Department of CSIE 
<br class="ltx_break"/>National Tsinghua University 
<br class="ltx_break"/>Hsinchu, Taiwan 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">s102065512@m102.</span> 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">nthu.edu.tw</span> 
<br class="ltx_break"/>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Richard Tzong-Han Tsai<math xmlns="http://www.w3.org/1998/Math/MathML" id="m1" class="ltx_Math" alttext="{}^{*}" display="inline"><msup><mi/><mo>*</mo></msup></math> 
<br class="ltx_break"/>Department of CSIE
<br class="ltx_break"/>National Central University
<br class="ltx_break"/>Chungli, Taiwan 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter">thtsai@csie.ncu.edu.tw</span> 
<br class="ltx_break"/>
</span></span></div>
<div class="ltx_date ltx_role_creation"/>

<div class="ltx_abstract"><h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Creating cross-language article links among different online encyclopedias is now an important task in the unification of multilingual knowledge bases.
In this paper, we propose a cross-language article linking method using a mixed-language topic model and hypernym translation features based on an SVM model to link English Wikipedia and Chinese Baidu Baike, the most widely used Wiki-like encyclopedia in China.
To evaluate our approach, we compile a data set from the top 500 Baidu Baike articles and their corresponding English Wiki articles.
The evaluation results show that our approach achieves 80.95% in MRR and 87.46% in recall.
Our method does not heavily depend on linguistic characteristics and can be easily extended to generate cross-language article links among different online encyclopedias in other languages.</p>
</div><span class="ltx_ERROR undefined">{CJK}</span>
<div id="p1" class="ltx_para">
<p class="ltx_p">UTF8nsung</p>
</div>
<div id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Online encyclopedias are among the most frequently used Internet services today. <span class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><math xmlns="http://www.w3.org/1998/Math/MathML" id="S1.p1.m1" class="ltx_Math" alttext="{}^{*}" display="inline"><msup><mi/><mo>*</mo></msup></math>corresponding author</span></span></span>
One of the largest and best known online encyclopedias is Wikipedia.
Wikipedia has many language versions, and articles in one language contain hyperlinks to corresponding pages in other languages.
However, the coverage of different language ver-sions of Wikipedia is very inconsistent.
Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the statistics of inter-language link pages in the English and Chinese editions in February 2014.
The total number of Chinese articles is about one-quarter of English ones, and only 2.3% of English articles have inter-language links to their Chinese versions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">However, there are alternatives to Wikipedia for some languages.
In China, for example Baidu Baike and Hudong are the largest encyclopedia sites, containing more than 6.2 and 7 million Chinese articles respectively.
Similarly, in Korea, Naver Knowledge Encyclopedia has a large presence.</p>
</div>
<div id="S1.T1" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_border_l ltx_border_r ltx_border_t"/>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Articles</th>
<th class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2">Inter-language Links</th>
<th class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ratio</th></tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">zh</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">755,628</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">zh2en</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">486,086</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">64.3%</td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">en</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">4,470,246</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">en2zh</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">106,729</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">2.3%</td></tr>
</tbody>
</table>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Inter-Language Links in Wikipedia</div>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">Since alternative encyclopedias like Baidu Baike are larger (by article count) and growing faster than the Chinese Wikipedia, it is worth-while to investigate creating cross-language links among different online encyclopedias.
Several works have focused on creating cross-language links between Wikipedia language versions <cite class="ltx_cite">[<a href="#bib.bib7" title="Enriching multilingual language resources by discovering missing cross-language links in wikipedia" class="ltx_ref">7</a>, <a href="#bib.bib9" title="Enriching the crosslingual link structure of wikipedia-a classification-based approach" class="ltx_ref">9</a>]</cite> or finding a cross-language link for each entity mention in a Wikipedia article, namely Cross-Language Link Discovery (CLLD) <cite class="ltx_cite">[<a href="#bib.bib10" title="Overview of the ntcir-10 cross-lingual link discovery task" class="ltx_ref">10</a>, <a href="#bib.bib5" title="Cross-language entity linking" class="ltx_ref">5</a>]</cite>.
These works were able to exploit the link structure and metadata common to all Wikipedia language versions.
However, when linking between different online encyclopedia platforms this is more difficult as many of these structural features are different or not shared.
To date, little research has been done into linking between encyclopedias on different platforms.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">Title translation is an effective and widely used method of creating cross-language links between encyclopedia articles. <cite class="ltx_cite">[<a href="#bib.bib11" title="Cross-lingual knowledge linking across wiki knowledge bases" class="ltx_ref">11</a>, <a href="#bib.bib1" title="Discovering missing links in wikipedia" class="ltx_ref">1</a>]</cite>
However, title translation alone is not always sufficient.
In some cases, for example, the titles of corresponding articles in different languages do not even match.
Other methods must be used along with title translation to create a more robust linking tool.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">In this paper, we propose a method comprising title and hypernym translation and mixed-language topic model methods to select and link related articles between the English Wikipedia and Baidu Baike online encyclopedias.
We also compile a suitable dataset from the above two encyclopedias to evaluate the linking accuracy of our method.</p>
</div>
</div>
<div id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">2 </span>Method</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Cross-language article linking between different encyclopedias can be formulated as follows:
For each encyclopedia <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m1" class="ltx_Math" alttext="K" display="inline"><mi>K</mi></math>, a collection of human-written articles, can be defined as <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m2" class="ltx_Math" alttext="K=\{a_{i}\}_{i=1}^{n}" display="inline"><mrow><mi>K</mi><mo>=</mo><msubsup><mrow><mo>{</mo><msub><mi>a</mi><mi>i</mi></msub><mo>}</mo></mrow><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></msubsup></mrow></math>, where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m3" class="ltx_Math" alttext="a_{i}" display="inline"><msub><mi>a</mi><mi>i</mi></msub></math> is an article in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m4" class="ltx_Math" alttext="K" display="inline"><mi>K</mi></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m5" class="ltx_Math" alttext="n" display="inline"><mi>n</mi></math> is the size of <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m6" class="ltx_Math" alttext="K" display="inline"><mi>K</mi></math>.
Article linking can then be defined as follows:
Given two encyclopedia <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m7" class="ltx_Math" alttext="K_{1}" display="inline"><msub><mi>K</mi><mn>1</mn></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m8" class="ltx_Math" alttext="K_{2}" display="inline"><msub><mi>K</mi><mn>2</mn></msub></math>, cross-language article linking is the task of finding the corresponding equivalent article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m9" class="ltx_Math" alttext="a_{j}" display="inline"><msub><mi>a</mi><mi>j</mi></msub></math> from encyclopedia <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m10" class="ltx_Math" alttext="K_{2}" display="inline"><msub><mi>K</mi><mn>2</mn></msub></math> for each article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m11" class="ltx_Math" alttext="a_{i}" display="inline"><msub><mi>a</mi><mi>i</mi></msub></math> from encyclopedia <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.p1.m12" class="ltx_Math" alttext="K_{1}" display="inline"><msub><mi>K</mi><mn>1</mn></msub></math>.
Equivalent articles are articles that describe the same topic in different languages.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">Our approach to cross-language article linking comprises two stages: candidate selection, which produces a list of candidate articles, and candidate ranking, which ranks that list.</p>
</div>
<div id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.1 </span>Candidate Selection</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p class="ltx_p">Since knowledge bases (KB) may contain millions of articles, comparison between all possible pairs in two knowledge bases is time-consuming and sometimes impractical.
To avoid brute-force comparison, we first select plausible candidate articles on which to focus our efforts.
To extract possible candidates, two similarity calculation methods are carried out: title matching and title similarity.</p>
</div>
<div id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">2.1.1 </span>Title Matching</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p class="ltx_p">In our title matching method, we formulate candidate selection as an English-Chinese cross-language information retrieval (CLIR) problem <cite class="ltx_cite">[<a href="#bib.bib8" title="Cross-language retrieval with wikipedia" class="ltx_ref">8</a>]</cite>, in which every English articleâs title is treated as a query and all the articles in the Chinese encyclopedia are treated as the documents.
We employ the two main CLIR methods: query translation and document translation.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p class="ltx_p">In query translation, we translate the title of every English article into Chinese and then use these translated titles as queries to retrieve articles from the Chinese encyclopedia.
In document translation, we translate the contents of the entire Chinese encyclopedia into English and then search them using the original English titles.
The top 100 results for the query-translation and the top 100 results for document-translation steps are unionized.
The resulting list contains our title-matching candidates.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p class="ltx_p">For the query- and document-translation steps, we use the Lucene search engine with similarity scores calculated by the Okapi BM25 ranking function <cite class="ltx_cite">[<a href="#bib.bib2" title="Okapi at TREC-5" class="ltx_ref">2</a>]</cite>.
We separate all words in the translated and original English article titles with the “OR” operator before submission to the search engine.
For all E-C and C-E translation tasks, we use Google Translate.</p>
</div>
</div>
<div id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection"><span class="ltx_tag ltx_tag_subsubsection">2.1.2 </span>Title Similarity</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p class="ltx_p">In the title similarity method, every Chinese article title is represented as a vector, and each distinct character in all these titles is a dimension of all vectors.
The title of each English article is translated into Chinese and represented as a vector.
Then, cosine similarity between this vector and the vector of each Chinese title is measured as title similarity.</p>
</div>
</div>
</div>
<div id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">2.2 </span>Candidate Ranking</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p class="ltx_p">The second stage of our approach is to score each viable candidate using a supervised learning method, and then sort all candidates in order of score from high to low as final output.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p class="ltx_p">Each article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m1" class="ltx_Math" alttext="x_{i}" display="inline"><msub><mi>x</mi><mi>i</mi></msub></math> in KB <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m2" class="ltx_Math" alttext="K_{1}" display="inline"><msub><mi>K</mi><mn>1</mn></msub></math> can be represented by a feature vector <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m3" class="ltx_Math" alttext="\mathbf{x}_{i}=(f_{1}(x_{i}),f_{2}(x_{i}),\ldots,f_{n}(x_{i}))" display="inline"><mrow><msub><mi>𝐱</mi><mi>i</mi></msub><mo>=</mo><mrow><mo>(</mo><mrow><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>f</mi><mn>2</mn></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mrow><msub><mi>f</mi><mi>n</mi></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>x</mi><mi>i</mi></msub><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></math>. Also, we have <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m4" class="ltx_Math" alttext="\mathbf{y}_{j}=(f_{1}(y_{j}),f_{2}(y_{j}),\ldots,f_{n}(y_{j}))" display="inline"><mrow><msub><mi>𝐲</mi><mi>j</mi></msub><mo>=</mo><mrow><mo>(</mo><mrow><mrow><msub><mi>f</mi><mn>1</mn></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>)</mo></mrow></mrow><mo>,</mo><mrow><msub><mi>f</mi><mn>2</mn></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>)</mo></mrow></mrow><mo>,</mo><mi mathvariant="normal">…</mi><mo>,</mo><mrow><msub><mi>f</mi><mi>n</mi></msub><mo>⁢</mo><mrow><mo>(</mo><msub><mi>y</mi><mi>j</mi></msub><mo>)</mo></mrow></mrow></mrow><mo>)</mo></mrow></mrow></math> for a candidate article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m5" class="ltx_Math" alttext="y_{j}" display="inline"><msub><mi>y</mi><mi>j</mi></msub></math> in KB <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m6" class="ltx_Math" alttext="K_{2}" display="inline"><msub><mi>K</mi><mn>2</mn></msub></math>.
Then, individual feature functions <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m7" class="ltx_Math" alttext="F_{k}(x_{i},y_{j})" display="inline"><mrow><msub><mi>F</mi><mi>k</mi></msub><mo>⁢</mo><mrow><mo>(</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>,</mo><msub><mi>y</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow></mrow></math> are based on the feature properties of both article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m8" class="ltx_Math" alttext="a_{i}" display="inline"><msub><mi>a</mi><mi>i</mi></msub></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m9" class="ltx_Math" alttext="a_{j}" display="inline"><msub><mi>a</mi><mi>j</mi></msub></math>.
The top predicted corresponding article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m10" class="ltx_Math" alttext="y_{j}" display="inline"><msub><mi>y</mi><mi>j</mi></msub></math> in the knowledge base <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m11" class="ltx_Math" alttext="K_{2}" display="inline"><msub><mi>K</mi><mn>2</mn></msub></math> for an input article <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m12" class="ltx_Math" alttext="x_{i}" display="inline"><msub><mi>x</mi><mi>i</mi></msub></math> in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m13" class="ltx_Math" alttext="K_{1}" display="inline"><msub><mi>K</mi><mn>1</mn></msub></math> should receive a higher score than any other entity in <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m14" class="ltx_Math" alttext="K_{2},a_{m}\in K_{2},m\neq j" display="inline"><mrow><mrow><mrow><msub><mi>K</mi><mn>2</mn></msub><mo>,</mo><msub><mi>a</mi><mi>m</mi></msub></mrow><mo>∈</mo><msub><mi>K</mi><mn>2</mn></msub></mrow><mo>,</mo><mrow><mi>m</mi><mo>≠</mo><mi>j</mi></mrow></mrow></math>.
We use the support vector machine (SVM) approach to determine the probability of each pair <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.p2.m15" class="ltx_Math" alttext="(\mathbf{x}_{i},\mathbf{y}_{j})" display="inline"><mrow><mo>(</mo><mrow><msub><mi>𝐱</mi><mi>i</mi></msub><mo>,</mo><msub><mi>𝐲</mi><mi>j</mi></msub></mrow><mo>)</mo></mrow></math> being equivalent.
Our SVM model’s features are described below.</p>
</div>
<div id="S2.SS2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Title Matching and Title Similarity Feature (Baseline)</h4>

<div id="S2.SS2.SSSx1.p1" class="ltx_para">
<p class="ltx_p">We use the results of title matching and title similarity from the candidate selection stage as two features for the candidate ranking stage.
The similarity values generated by title matching and title similarity are used directly as real value features in the SVM model.</p>
</div>
</div>
<div id="S2.SS2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Mixed-language Topic Model Feature (MTM)</h4>

<div id="S2.SS2.SSSx2.p1" class="ltx_para">
<p class="ltx_p">For a linked English-Chinese article pair, the distribution of words used in each usually shows some convergence.
The two semantically corresponding articles often have many related terms, which results in clusters of specific words.
If two articles do not describe the same topic, the distribution of terms is often scattered. <cite class="ltx_cite">[<a href="#bib.bib6" title="Using lda to detect semantically incoherent documents" class="ltx_ref">6</a>]</cite>
Thus, the distribution of terms is good measurement of article similarity.</p>
</div>
<div id="S2.SS2.SSSx2.p2" class="ltx_para">
<p class="ltx_p">Because the number of all possible words is too large, we adopt a topic model to gather the words into some latent topics.
For this feature, we use the Latent Dirichlet Allocation (LDA) <cite class="ltx_cite">[<a href="#bib.bib3" title="Latent dirichlet allocation" class="ltx_ref">3</a>]</cite>.
LDA can be seen as a typical probabilistic approach to latent topic computation.
Each topic is represented by a distribution of words, and each word has a probability score used to measure its contribution to the topic.
To train the LDA model, the pair English and Chinese articles are concatenated into a single document.
English and Chinese terms are all regarded as terms of the same language and the LDA topic model, namely mixed-language topic model, generates both English and Chinese terms for each latent topic.
Then, for each English article and Chinese candidate pair in testing, the LDA model provides the distribution of the latent topics.
Next, we can use entropy to measure the distribution of topics.
The entropy of the estimated topic distribution of a related article is expected to be lower than that of an unrelated article. We can calculate the entropy of the distribution as a value for SVM. The entropy is defined as follows:</p>
<table id="S2.Ex1" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.Ex1.m1" class="ltx_Math" alttext="H=-\sum_{j=1}^{T}\vec{\theta_{dj}}\log\vec{\theta_{dj}}" display="block"><mrow><mi>H</mi><mo>=</mo><mrow><mo>-</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>T</mi></munderover><mrow><mover accent="true"><msub><mi>θ</mi><mrow><mi>d</mi><mo>⁢</mo><mi>j</mi></mrow></msub><mo stretchy="false">→</mo></mover><mo>⁢</mo><mrow><mi>log</mi><mo>⁡</mo><mover accent="true"><msub><mi>θ</mi><mrow><mi>d</mi><mo>⁢</mo><mi>j</mi></mrow></msub><mo stretchy="false">→</mo></mover></mrow></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx2.p2.m1" class="ltx_Math" alttext="T" display="inline"><mi>T</mi></math> is the number of latent topics, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx2.p2.m2" class="ltx_Math" alttext="\theta_{dj}" display="inline"><msub><mi>θ</mi><mrow><mi>d</mi><mo>⁢</mo><mi>j</mi></mrow></msub></math> is the topic distribution of a given topic <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx2.p2.m3" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math>.</p>
</div>
</div>
<div id="S2.SS2.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Hypernym Translation Feature (HT)</h4>

<div id="S2.SS2.SSSx3.p1" class="ltx_para">
<p class="ltx_p">The first sentence of an encyclopedia article usually contains the title of the article.
It may also contain a hypernym that defines the category of the article.
For example, the first sentence of the “iPad” article in the English Wikipedia begins, “iPad is a line of tablet computers designed and marketed by Apple Inc<math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx3.p1.m1" class="ltx_Math" alttext="\ldots" display="inline"><mi mathvariant="normal">…</mi></math>”
In this sentence, the term “tablet computers” is the hypernym of iPad.
These extracted hypernyms can be treated as article categories.
Therefore, articles containing the same hypernym are likely to belong to the same category.</p>
</div>
<div id="S2.SS2.SSSx3.p2" class="ltx_para">
<p class="ltx_p">In this study, we only carry out title hypernym extraction on the first sentences of English articles due to the looser syntactic structure of Chinese.
To generate dependency parse trees for the sentences, we adopt the Stanford Dependency Parser.
Then, we manually designed seven patterns to extract hypernyms from the parse tree structures.
To demonstrate this idea, let us take the English article “The Hunger Games” for example.
The first sentence of this article is “The Hunger Games is a 2008 young adult novel by American writer Suzanne Collins.”
Since article titles may be named entities or compound nouns, the dependency parser may mislabel them and thus output an incorrect parse tree.
To avoid this problem, we first replace all instances of an article’s title in the first sentence with pronouns.
For example, the previous sentence is rewritten as “It is a 2008 young adult novel by American writer Suzanne Collins.”
Then, the dependency parser generates the following parse tree:</p><img src="P14-2096/image001.png" id="S2.SS2.SSSx3.p2.g1" class="ltx_graphics ltx_centering" width="298" height="223" alt=""/>
</div>
<div id="S2.SS2.SSSx3.p3" class="ltx_para">
<p class="ltx_p">Next, we apply our predefined syntactic patterns to extract the hypernym. <cite class="ltx_cite">[<a href="#bib.bib4" title="Automatic acquisition of hyponyms from large text corpora" class="ltx_ref">4</a>]</cite>
If any pattern matches the structure of the dependency parse tree, the hypernym can be extracted.
In the above example, the following pattern is matched:</p><img src="P14-2096/image002.png" id="S2.SS2.SSSx3.p3.g1" class="ltx_graphics ltx_centering" width="120" height="90" alt=""/>
</div>
<div id="S2.SS2.SSSx3.p4" class="ltx_para">
<p class="ltx_p">In this pattern, the rightmost leaf is the hypernym target.
Thus, we can extract the hypernym “novel” from the previous example.
The term “novel” is the extracted hypernym of the English article “The Hunger Games”.</p>
</div>
<div id="S2.SS2.SSSx3.p5" class="ltx_para">
<p class="ltx_p">After extracting the hypernym of the English article, the hypernym is translated into Chinese.
The value of this feature in the SVM model is calculated as follows:</p>
<table id="S2.Ex2" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.Ex2.m1" class="ltx_Math" alttext="F_{hypernym}(h)=\log count(translated(h))" display="block"><mrow><mrow><msub><mi>F</mi><mrow><mi>h</mi><mo>⁢</mo><mi>y</mi><mo>⁢</mo><mi>p</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>y</mi><mo>⁢</mo><mi>m</mi></mrow></msub><mo>⁢</mo><mrow><mo>(</mo><mi>h</mi><mo>)</mo></mrow></mrow><mo>=</mo><mrow><mrow><mi>log</mi><mo>⁡</mo><mrow><mi>c</mi><mo>⁢</mo><mi>o</mi><mo>⁢</mo><mi>u</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>t</mi></mrow></mrow><mo>⁢</mo><mrow><mo>(</mo><mrow><mi>t</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><mi>h</mi><mo>)</mo></mrow></mrow><mo>)</mo></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
<p class="ltx_p">where <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx3.p5.m1" class="ltx_Math" alttext="h" display="inline"><mi>h</mi></math> is the hypernym, <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx3.p5.m2" class="ltx_Math" alttext="translated(h)" display="inline"><mrow><mi>t</mi><mo>⁢</mo><mi>r</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>n</mi><mo>⁢</mo><mi>s</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>t</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>d</mi><mo>⁢</mo><mrow><mo>(</mo><mi>h</mi><mo>)</mo></mrow></mrow></math> is the Chinese translation of the term <math xmlns="http://www.w3.org/1998/Math/MathML" id="S2.SS2.SSSx3.p5.m3" class="ltx_Math" alttext="h" display="inline"><mi>h</mi></math>.</p>
</div>
</div>
<div id="S2.SS2.SSSx4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">English Title Occurrence Feature (ETO)</h4>

<div id="S2.SS2.SSSx4.p1" class="ltx_para">
<p class="ltx_p">In a Baidu Baike article, the first sentence may contain a parenthetical translation of the main title.
For example, the first sentence of the Chinese article on San Francisco is “æ§éå±±ï¼San Franciscoï¼ï¼åè¯âå£å¼æè¥¿æ¯ç§âãâä¸è©å¸âã”.
We regard the appearance of the English title in the first sentence of a Baidu Baike article as a binary feature:
If the English title appears in the first sentence, the value of this feature is 1; otherwise, the value is 0.</p>
</div>
</div>
</div>
</div>
<div id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">3 </span>Evalutaion</h2>

<div id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.1 </span>Evaluation Dataset</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">In order to evaluate the performance of cross-language article linking between English Wikiepdia and Chinese Baidu Baike, we compile an English-Chinese evaluation dataset from Wikipedia and Baidu Baike online encyclopedias.
First, our spider crawls the entire contents of English Wikipedia and Chinese Baidu Baike.
Since the two encyclopedias’ article formats differ, we copy the information in each article (title, content, category, etc.) into a standardized XML structure.
In order to generate the gold standard evaluation sets of correct English and Chinese article pairs, we automatically collect English-Chinese inter-language links from Wikipedia.
For pairs that have both English and Chinese articles, the Chinese article title is regarded as the translation of the English one.
Next, we check if there is a Chinese article in Baidu Baike with exactly the same title as the one in Chinese Wikipedia.
If so, the corresponding English Wikipedia article and the Baidu Baike article are paired in the gold standard.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">To evaluate the performance of our method on linking different types of encyclopedia articles, we compile a set containing the most popular articles.
We select the top 500 English-Chinese article pairs with the highest page view counts in Baidu Baike.
This set represents the articles people in China are most interested in.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p class="ltx_p">Because our approach uses an SVM model, the data set should be split into training and test sets.
For statistical generality, each data set is randomly split 4:1 (training:test) 30 times.
The final evaluation results are calculated as the mean of the average of these 30 evaluation sets.</p>
</div>
</div>
<div id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.2 </span>Evaluation Metrics</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">To measure the quality of cross-language entity linking, we use the following three metrics.
For each English article queries, ten output Baidu Baike candidates are generated in a ranked list.
To define the metrics, we use following notations: <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m1" class="ltx_Math" alttext="N" display="inline"><mi>N</mi></math> is the number of English query; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m2" class="ltx_Math" alttext="r_{i,j}" display="inline"><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></math> is <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m3" class="ltx_Math" alttext="j" display="inline"><mi>j</mi></math>-th correct Chinese article for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m4" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>-th English query; <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m5" class="ltx_Math" alttext="c_{i,k}" display="inline"><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub></math> is <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m6" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math>-th candiate the system output for <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.p1.m7" class="ltx_Math" alttext="i" display="inline"><mi>i</mi></math>-th English query.</p>
</div>
<div id="S3.SS2.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Top-<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSSx1.m1" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> Accuracy (ACC)</h4>

<div id="S3.SS2.SSSx1.p1" class="ltx_para">
<p class="ltx_p">ACC measures the correctness of the first candidate in the candidate list.
<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSSx1.p1.m1" class="ltx_Math" alttext="ACC=1" display="inline"><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>C</mi><mo>⁢</mo><mi>C</mi></mrow><mo>=</mo><mn>1</mn></mrow></math> means that all top candidates are correctly linked (i.e. they match one of the references), and <math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS2.SSSx1.p1.m2" class="ltx_Math" alttext="ACC=0" display="inline"><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>C</mi><mo>⁢</mo><mi>C</mi></mrow><mo>=</mo><mn>0</mn></mrow></math> means that none of the top candidates is correct.</p>
<table id="S3.Ex3" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex3.m1" class="ltx_Math" alttext="ACC=\frac{1}{N}\sum_{i=1}^{N}\left\{\begin{array}[]{ll}1&amp;\mbox{if $\exists r_{%&#10;i,j}:r_{i,j}=c_{i,k}$}\\&#10;0&amp;\mbox{otherwise}\end{array}\right\}" display="block"><mrow><mrow><mi>A</mi><mo>⁢</mo><mi>C</mi><mo>⁢</mo><mi>C</mi></mrow><mo>=</mo><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>⁢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mo>{</mo><mtable align="center" columnspacing="0.4em" rowspacing="0.2ex"><mtr><mtd columnalign="left"><mn>1</mn></mtd><mtd columnalign="left"><mrow><mtext>if </mtext><mrow><mrow><mo>∃</mo><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo>:</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn></mtd><mtd columnalign="left"><mtext>otherwise</mtext></mtd></mtr></mtable><mo>}</mo></mrow></mrow></mrow></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
</div>
</div>
<div id="S3.SS2.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Mean Reciprocal Rank (MRR)</h4>

<div id="S3.SS2.SSSx2.p1" class="ltx_para">
<p class="ltx_p">Traditional MRR measures any correct answer produced by the system from among the candidates.
1/MRR approximates the average rank of the correct transliteration.
An MRR closer to 1 implies that the correct answer usually appears close to the top of the n-best lists.</p>
<table id="S3.Ex4" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex4.m1" class="ltx_Math" alttext="\begin{array}[]{lcl}RR_{i}&amp;=&amp;\left\{\begin{array}[]{ll}\min_{j}\frac{1}{j}&amp;%&#10;\mbox{if $\exists r_{i,j},c_{i,k}:r_{i,j}=c_{i,k}$}\\&#10;0&amp;\mbox{otherwise}\end{array}\right\}\\&#10;MRR&amp;=&amp;\frac{1}{N}\sum_{i=1}^{N}RR_{i}\\&#10;\end{array}" display="block"><mtable align="center" columnspacing="0.4em" rowspacing="0.2ex"><mtr><mtd columnalign="left"><mrow><mi>R</mi><mo>⁢</mo><msub><mi>R</mi><mi>i</mi></msub></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><mo>{</mo><mtable align="center" columnspacing="0.4em" rowspacing="0.2ex"><mtr><mtd columnalign="left"><mrow><munder><mo movablelimits="false">min</mo><mi>j</mi></munder><mo>⁡</mo><mfrac><mn>1</mn><mi>j</mi></mfrac></mrow></mtd><mtd columnalign="left"><mrow><mtext>if </mtext><mrow><mrow><mrow><mo>∃</mo><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub></mrow><mo>,</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub></mrow><mo>:</mo><mrow><msub><mi>r</mi><mrow><mi>i</mi><mo>,</mo><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>c</mi><mrow><mi>i</mi><mo>,</mo><mi>k</mi></mrow></msub></mrow></mrow></mrow></mtd></mtr><mtr><mtd columnalign="left"><mn>0</mn></mtd><mtd columnalign="left"><mtext>otherwise</mtext></mtd></mtr></mtable><mo>}</mo></mrow></mtd></mtr><mtr><mtd columnalign="left"><mrow><mi>M</mi><mo>⁢</mo><mi>R</mi><mo>⁢</mo><mi>R</mi></mrow></mtd><mtd columnalign="center"><mo>=</mo></mtd><mtd columnalign="left"><mrow><mfrac><mn>1</mn><mi>N</mi></mfrac><mo>⁢</mo><mrow><munderover><mo largeop="true" movablelimits="false" symmetric="true">∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mrow><mi>R</mi><mo>⁢</mo><msub><mi>R</mi><mi>i</mi></msub></mrow></mrow></mrow></mtd></mtr></mtable></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
</div>
</div>
<div id="S3.SS2.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Recall</h4>

<div id="S3.SS2.SSSx3.p1" class="ltx_para">
<p class="ltx_p">Recall is the fraction of the retrieved articles that are relevant to the given query.
Recall is used to measure the performance of the candidate selection method.
If the candidate selection method can actually select the correct Chinese candidate, the recall will be high.</p>
<table id="S3.Ex5" class="ltx_equation">

<tr class="ltx_equation ltx_align_baseline">
<td class="ltx_eqn_center_padleft"/>
<td class="ltx_align_center"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.Ex5.m1" class="ltx_Math" alttext="Recall=\frac{|\mbox{relevant articles}|\cap|\mbox{retrieved articles}|}{|\mbox%&#10;{relevant articles}|}" display="block"><mrow><mrow><mi>R</mi><mo>⁢</mo><mi>e</mi><mo>⁢</mo><mi>c</mi><mo>⁢</mo><mi>a</mi><mo>⁢</mo><mi>l</mi><mo>⁢</mo><mi>l</mi></mrow><mo>=</mo><mfrac><mrow><mrow><mo fence="true">|</mo><mtext>relevant articles</mtext><mo fence="true">|</mo></mrow><mo>∩</mo><mrow><mo fence="true">|</mo><mtext>retrieved articles</mtext><mo fence="true">|</mo></mrow></mrow><mrow><mo fence="true">|</mo><mtext>relevant articles</mtext><mo fence="true">|</mo></mrow></mfrac></mrow></math></td>
<td class="ltx_eqn_center_padright"/></tr>
</table>
</div>
</div>
</div>
<div id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection"><span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation Results</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">The overall results of our method achieves 80.95% in MRR and 87.46% in recall.
Figure <a href="#S3.F1" title="Figure 1 ‣ 3.3 Evaluation Results ‣ 3 Evalutaion ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the top-<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.SS3.p1.m1" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> ACC from the top 1 to 5.
These results show that our method is very effective in linking articles in English Wikipedia to those in Baidu Baike.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p class="ltx_p">In order to show the benefits of each feature used in the SVM model, we conduct a experiment to test the performance of different feature combinations.
Because title similarity of the articles is a widely used method, we choose English and Chinese title similarity as the baseline.
Then, another feature is added to each configuration until all the features have been added. Table <a href="#S3.T2" title="Table 2 ‣ 3.3 Evaluation Results ‣ 3 Evalutaion ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the final results of different feature combinations.</p>
</div>
<div id="S3.F1" class="ltx_figure"><img src="P14-2096/image003.png" id="S3.F1.g1" class="ltx_graphics ltx_centering" width="312" height="188" alt=""/>
<div class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Top-<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.F1.m2" class="ltx_Math" alttext="k" display="inline"><mi>k</mi></math> Accuracy</div>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p class="ltx_p">In the results, we can observe that mix-language topic model, hypernym, and English title occurence features all noticeably improve the performance.
Combining two of these three feature has more improvement and the combination of all the features achieves the best.</p>
</div>
<div id="S3.T2" class="ltx_table">
<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_t">Level</th>
<td class="ltx_td ltx_align_left ltx_border_t">Configuration</td>
<td class="ltx_td ltx_align_left ltx_border_t">MRR</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_t">0</th>
<td class="ltx_td ltx_align_left ltx_border_t">Baseline (BL)</td>
<td class="ltx_td ltx_align_left ltx_border_t">0.6559</td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_t" rowspan="3">1</th>
<td class="ltx_td ltx_align_left ltx_border_t">BL + MTM<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m1" class="ltx_Math" alttext="{}^{*1}" display="inline"><msup><mi/><mrow><mi/><mo>*</mo><mn>1</mn></mrow></msup></math></td>
<td class="ltx_td ltx_align_left ltx_border_t">0.6967<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m2" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">BL + HT<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m3" class="ltx_Math" alttext="{}^{*2}" display="inline"><msup><mi/><mrow><mi/><mo>*</mo><mn>2</mn></mrow></msup></math></td>
<td class="ltx_td ltx_align_left">0.6975<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m4" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">BL + ETO<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m5" class="ltx_Math" alttext="{}^{*3}" display="inline"><msup><mi/><mrow><mi/><mo>*</mo><mn>3</mn></mrow></msup></math></td>
<td class="ltx_td ltx_align_left">0.6981<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m6" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_t" rowspan="3">2</th>
<td class="ltx_td ltx_align_left ltx_border_t">BL + MTM + HT</td>
<td class="ltx_td ltx_align_left ltx_border_t">0.7703<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m7" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">BL + MTM + ETO</td>
<td class="ltx_td ltx_align_left">0.7558<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m8" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_left">BL + HT + ETO</td>
<td class="ltx_td ltx_align_left">0.7682<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m9" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo>†</mo></msup></math></td></tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_border_b ltx_border_t">3</th>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t">BL + MTM + HT + ETO</td>
<td class="ltx_td ltx_align_left ltx_border_b ltx_border_t"><span class="ltx_text ltx_font_bold">0.8095<math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m10" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo mathvariant="normal">†</mo></msup></math></span></td></tr>
</tbody>
</table>
<p class="ltx_p"><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m11" class="ltx_Math" alttext="{}^{*1}" display="inline"><msup><mi/><mrow><mi/><mo>*</mo><mn>1</mn></mrow></msup></math><span class="ltx_text ltx_font_small">MTM: mix-language topic model 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m12" class="ltx_Math" alttext="{}^{*2}" display="inline"><msup><mi/><mrow><mi/><mo mathsize="normal" stretchy="false">*</mo><mn mathsize="normal" stretchy="false">2</mn></mrow></msup></math>HT: hypernym translation
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m13" class="ltx_Math" alttext="{}^{*3}" display="inline"><msup><mi/><mrow><mi/><mo mathsize="normal" stretchy="false">*</mo><mn mathsize="normal" stretchy="false">3</mn></mrow></msup></math>ETO: English title occurrence 
<br class="ltx_break"/><math xmlns="http://www.w3.org/1998/Math/MathML" id="S3.T2.m14" class="ltx_Math" alttext="{}^{{\dagger}}" display="inline"><msup><mi/><mo mathsize="normal" stretchy="false">†</mo></msup></math> This config. outperforms the best config. in last level with statistically significant difference.
</span></p>
<div class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>MRRs of Feature Combinations</div>
</div>
</div>
</div>
<div id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">4 </span>Discussion</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">Although our method can effectively generate cross-language links with high accuracy, some correct candidates are not ranked number one. After examining the results, we can divide errors into several categories:</p>
</div>
<div id="S4.p2" class="ltx_para">
<p class="ltx_p">The first kind of error is due to large literal differences between the English and Chinese titles.
For example, for the English article “Nero”, our approach ranks the Chinese candidate “å°¼ç¦ç” (“King Nero”) as number one, instead of the correct answer “å°¼ç¦Â·åå³çä¹æ¯Â·å¾·é²èæ¯Â·æ¥è³æ¼å°¼åºæ¯” (the number two candidate).
The title of the correct Chinese article is the full name of the Roman Emperor Nero (Nero Claudius Drusus Germanicus).
The false positive “å°¼ç¦ç” is a historical novel about the life of the Emperor Nero.
Because of the large difference in title lengths, the value of the title similarity feature between the English article “Nero” and the corresponding Chinese article is low. Such length differences may cause the SVM model to rank the correct answer lower when the difference of other features are not so significant because the contents of the Chinese candidates are similar.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p class="ltx_p">The second error type is caused by articles that have duplicates in Baidu Baike. For example, for the English article “Jensen Ackles”, our approach generates a link to the Chinese article “Jensen” in Baidu Baike.
However, there is another Baidu article “è©¹æ£®Â·é¿åæ¯” (“Jensen Ackles”).
These two articles both describe the actor Jensen Ackles.
In this case, our approach still generates a correct link, although it is not the one in the gold standard.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p class="ltx_p">The third error type is translation errors.
For example, the English article “Raccoon” is linked to the Baidu article “ç¸” (raccoon dog), though the correct one is âæµ£çâ (raccoon).
The reason is that Google Translate provides the translation “ç¸” instead of “æµ£ç”.</p>
</div>
</div>
<div id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section"><span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">Cross-language article linking is the task of creating links between online encyclopedia articles in different languages that describe the same content.
We propose a method based on article hypernym and topic model to link English Wikipedia articles to corresponding Chinese Baidu Baike articles.
Our method comprises two stages: candidate selection and candidate ranking.
We formulate candidate selection as a cross-language information retrieval task based on the title similarity between English and Chinese articles.
In candidate ranking, we employ several features of the articles in our SVM model.
To evaluate our method, we compile a dataset from English Wikipedia and Baidu Baike, containing the 500 most popular Baidu articles.
Evaluation results of our method show an MRR of up to 80.95% and a recall of 87.46%.
This shows that our method is effective in generating cross-language links between English Wikipedia and Baidu Baike with high accuracy.
Our method does not heavily depend on linguistic characteristics and can be easily extended to generate cross-language article links among different encyclopedias in other languages.</p>
</div>
</div>
<div id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul id="L1" class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. F. Adafre and M. de Rijke</span><span class="ltx_text ltx_bib_year">(2005)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Discovering missing links in wikipedia</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib2" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Beaulieu, M. Gatford, X. Huang, S. Robertson, S. Walker and P. Williams</span><span class="ltx_text ltx_bib_year">(1997)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Okapi at TREC-5</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 143–166</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.SSS1.p3" title="2.1.1 Title Matching ‣ 2.1 Candidate Selection ‣ 2 Method ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1.1</span></a>.
</span></li>
<li id="bib.bib3" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">D. M. Blei, A. Y. Ng and M. I. Jordan</span><span class="ltx_text ltx_bib_year">(2003)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Latent dirichlet allocation</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Journal of Machine Learning Research</span> <span class="ltx_text ltx_bib_volume">3</span> (<span class="ltx_text ltx_bib_number">4-5</span>), <span class="ltx_text ltx_bib_pages"> pp. 993–1022</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.SSSx2.p2" title="Mixed-language Topic Model Feature (MTM) ‣ 2.2 Candidate Ranking ‣ 2 Method ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span></li>
<li id="bib.bib4" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. A. Hearst</span><span class="ltx_text ltx_bib_year">(1992)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Automatic acquisition of hyponyms from large text corpora</span>.
</span>
<span class="ltx_bibblock">Vol. <span class="ltx_text ltx_bib_volume">2</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.SSSx3.p3" title="Hypernym Translation Feature (HT) ‣ 2.2 Candidate Ranking ‣ 2 Method ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span></li>
<li id="bib.bib5" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. McNamee, J. Mayfield, D. Lawrie, D. W. Oard and D. S. Doermann</span><span class="ltx_text ltx_bib_year">(2011)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Cross-language entity linking</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 255–263</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Misra, O. Cappe and F. Yvon</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Using lda to detect semantically incoherent documents</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS2.SSSx2.p1" title="Mixed-language Topic Model Feature (MTM) ‣ 2.2 Candidate Ranking ‣ 2 Method ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>.
</span></li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Oh, D. Kawahara, K. Uchimoto, J. Kazama and K. Torisawa</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Enriching multilingual language resources by discovering missing cross-language links in wikipedia</span>.
</span>
<span class="ltx_bibblock">Vol. <span class="ltx_text ltx_bib_volume">1</span>, <span class="ltx_text ltx_bib_pages"> pp. 322–328</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_article"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Schönhofen, A. Benczùr, I. Bìrò and K. Csalogàny</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Cross-language retrieval with wikipedia</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">Advances in Multilingual and Multimodal Information Retrieval, Lecture
Notes in Computer Science</span> <span class="ltx_text ltx_bib_volume">5152</span>, <span class="ltx_text ltx_bib_pages"> pp. 72–79</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS1.SSS1.p1" title="2.1.1 Title Matching ‣ 2.1 Candidate Selection ‣ 2 Method ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1.1</span></a>.
</span></li>
<li id="bib.bib9" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Sorg and P. Cimiano</span><span class="ltx_text ltx_bib_year">(2008)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Enriching the crosslingual link structure of wikipedia-a classification-based approach</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_pages"> pp. 49–54</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Tang, I. Kang, F. Kimura, Y. Lee, A. Trotman, S. Geva and Y. Xu</span><span class="ltx_text ltx_bib_year">(2013)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Overview of the ntcir-10 cross-lingual link discovery task</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p3" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings"><span class="ltx_bibtag ltx_bib_key ltx_role_refnum">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Z. Wang, J. Li, Z. Wang and J. Tang</span><span class="ltx_text ltx_bib_year">(2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Cross-lingual knowledge linking across wiki knowledge bases</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p4" title="1 Introduction ‣ Cross-language and Cross-encyclopedia Article Linking Using Mixed-language Topic Model and Hypernym Translation" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
</span></li>
</ul>
</div>
</div>
</div>
<div class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jun 11 18:10:59 2014 by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"/></a></div></div>
</div>
</body>
</html>
