<html>
 <head>
  <meta content="SENT_NUM: 6, WORD_NUM: 113" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   Prior research on language identification focused primarily on text and speech.
  </a>
  <a href="#1" id="1">
   In this paper, we focus on the visual modality and present a method for identifying sign languages solely from short video samples.
  </a>
  <a href="#2" id="2">
   The method is trained on unlabelled video data (unsupervised feature learning) and using these features, it is trained to discriminate between six sign languages (supervised learning.
  </a>
  <a href="#3" id="3">
   We ran experiments on short video samples involving 30 signers (about 6 hours in total.
  </a>
  <a href="#4" id="4">
   Using leave-one-signer-out cross-validation, our evaluation shows an average best accuracy of 84 %.
  </a>
  <a href="#5" id="5">
   Given that sign languages are under-resourced, unsupervised feature learning techniques are the right tools and our results indicate that this is realistic for sign language identification.
  </a>
 </body>
</html>