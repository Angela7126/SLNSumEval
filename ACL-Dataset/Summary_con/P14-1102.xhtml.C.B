<html>
 <head>
  <meta content="SENT_NUM:22, WORD_NUM:634" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   This paper has presented a simple cognitive model of filler-gap acquisition, which is able to capture several findings from developmental psychology.
  </a>
  <a href="#1" id="1">
   Training significantly improves role labelling in the case of object-extractions, which improves the overall accuracy of the model.
  </a>
  <a href="#2" id="2">
   This boost is accompanied by a slight decrease in labelling accuracy in subject-extraction settings.
  </a>
  <a href="#3" id="3">
   The asymmetric ease of subject versus object comprehension is well-documented in both children and adults [] , and while training improves the model u'\u2019' s ability to process object-extractions, there is still a gap between object-extraction and subject-extraction comprehension even after training.
  </a>
  <a href="#4" id="4">
   Further, the model exhibits better comprehension of wh -relatives than that -relatives similar to children [].
  </a>
  <a href="#5" id="5">
   This could also be an area where a lexicalized model could do better.
  </a>
  <a href="#6" id="6">
   As point out, whereas wh -relatives such as who or which always signify a filler-gap construction, that can occur for many different reasons (demonstrative, determiner, complementizer, etc) and so is a much weaker filler-gap cue.
  </a>
  <a href="#7" id="7">
   A lexical model could potentially pick up on clues which could indicate when that is a relativizer or simply improve on its comprehension of wh -relatives even more.
  </a>
  <a href="#8" id="8">
   It is interesting to note that the cuurent model does not make use of that as a cue at all and yet is still slower at acquiring that -relatives than wh -relatives.
  </a>
  <a href="#9" id="9">
   This fact suggests that the findings of may be partially explained by a frequency effect perhaps the input to children is simply biased such that wh -relatives are much more common than that -relatives (as shown in Table 5.
  </a>
  <a href="#10" id="10">
   This model also initially reflects the 1-1 role bias observed in children [] as well as previous models [] without sacrificing accuracy in canonical intransitive settings.
  </a>
  <a href="#11" id="11">
   Finally, this model is extremely robust to different initializations.
  </a>
  <a href="#12" id="12">
   The canonical Gaussian expectations can begin far from the verb ( 3 ) or close to the verb ( 0.1 ), and the standard deviations of the distributions and the skip-penalty can vary widely; the model always converges to give comparable results to those presented here.
  </a>
  <a href="#13" id="13">
   The only constraint on the initial parameters is that the probability of the extracted object occurring preverbally must exceed the skip-penalty (i.e., extraction must be possible.
  </a>
  <a href="#14" id="14">
   In short, this paper describes a simple, robust cognitive model of the development of a learner between 15 months until somewhere between 25- and 30-months old (since 1-1 role bias is no longer present but no more than two arguments are being generalized.
  </a>
  <a href="#15" id="15">
   In future, it would be interesting to incorporate lexicalization into the model presented in this paper, as this feature seems likely to bridge the gap between this model and BabySRL in transitive settings.
  </a>
  <a href="#16" id="16">
   Lexicalization should also help further distinguish modifiers from arguments and improve the overall accuracy of the model.
  </a>
  <a href="#17" id="17">
   It would also be interesting to investigate how well this model generalizes to languages besides English.
  </a>
  <a href="#18" id="18">
   Since the model is able to use the verb position as a semi-permeable boundary between canonical subjects and objects, it may not work as well in verb-final languages, and thus makes the prediction that filler-gap comprehension may be acquired later in development in such languages due to a greater reliance on hierarchical syntax.
  </a>
  <a href="#19" id="19">
   Ordering is one of the definining characteristics of a language that must be acquired by learners (e.g., SVO vs SOV), and this work shows that filler-gap comprehension can be acquired as a by-product of learning orderings rather than having to resort to higher-order syntax.
  </a>
  <a href="#20" id="20">
   Note that this model cannot capture the constraints on filler-gap usage which require a hierarchical grammar (e.g., subjacency), but such knowledge is really only needed for successful production of filler-gap constructions, which occurs much later (around 5 years; de Villiers and Roeper, 1995.
  </a>
  <a href="#21" id="21">
   Further, the kind of ordering system proposed in this paper may form an initial basis for learning such grammars [].
  </a>
 </body>
</html>