<html>
 <head>
  <meta content="SENT_NUM:8, WORD_NUM:150" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   In this paper, we propose a Recursive Recurrent Neural Network(R 2 NN) to combine the recurrent neural network and recursive neural network.
  </a>
  <a href="#1" id="1">
   Our proposed R 2 NN cannot only integrate global input information during each combination, but also can generate the tree structure in a recursive way.
  </a>
  <a href="#2" id="2">
   We apply our model to SMT decoding, and propose a three-step semi-supervised training method.
  </a>
  <a href="#3" id="3">
   In addition, we explore phrase pair embedding method, which models translation confidence directly.
  </a>
  <a href="#4" id="4">
   We conduct experiments on a Chinese-to-English translation task, and our method outperforms a state-of-the-art baseline about 1.5 points BLEU.
  </a>
  <a href="#5" id="5">
   From the experiments, we find that, phrase pair embedding is crucial to the performance of SMT.
  </a>
  <a href="#6" id="6">
   In the future, we will explore better methods for phrase pair embedding to model the translation equivalent between source and target phrases.
  </a>
  <a href="#7" id="7">
   We will apply our proposed R 2 NN to other tree structure learning tasks, such as natural language parsing.
  </a>
 </body>
</html>