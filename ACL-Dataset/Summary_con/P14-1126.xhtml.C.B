<html>
 <head>
  <meta content="SENT_NUM:3, WORD_NUM:76" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   In this paper, we propose an unsupervised projective dependency parsing approach for resource-poor languages, using existing resources from a resource-rich source language.
  </a>
  <a href="#1" id="1">
   By presenting a model training framework, our approach can utilize parallel text to estimate transferring distribution with the help of a well-developed resource-rich language dependency parser, and use unlabeled data as entropy regularization.
  </a>
  <a href="#2" id="2">
   The experimental results on three data sets across ten target languages show that our approach achieves significant improvement over previous studies.
  </a>
 </body>
</html>