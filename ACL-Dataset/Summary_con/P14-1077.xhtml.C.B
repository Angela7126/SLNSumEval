<html>
 <head>
  <meta content="SENT_NUM:7, WORD_NUM:150" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   In this paper, we make use of the global clues derived from KB to help resolve the disagreements among local relation predictions, thus reduce the incorrect predictions and improve the performance of relation extraction.
  </a>
  <a href="#1" id="1">
   Two kinds of clues, including implicit argument type information and argument cardinality information of relations are investigated.
  </a>
  <a href="#2" id="2">
   Our framework outperforms the state-of-the-art models if we can find such clues in the KB.
  </a>
  <a href="#3" id="3">
   Furthermore, our framework is scalable for other local sentence level extractors in addition to the MaxEnt model.
  </a>
  <a href="#4" id="4">
   Finally, we show that the clues can be learnt automatically from the KB, and lead to comparable performance to manually refined ones.
  </a>
  <a href="#5" id="5">
   For future work, we will investigate other kinds of clues and attempt a joint optimization framework that could host entity disambiguation, relation extraction and entity linking together.
  </a>
  <a href="#6" id="6">
   We will also adopt selection preference between entities and relations since sometimes we may not find useful clues.
  </a>
 </body>
</html>