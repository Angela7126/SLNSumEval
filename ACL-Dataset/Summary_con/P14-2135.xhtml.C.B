<html>
 <head>
  <meta content="SENT_NUM:9, WORD_NUM:204" name="TextLength"/>
 </head>
 <body bgcolor="white">
  <a href="#0" id="0">
   We presented a novel method, image dispersion-based filtering, that improves multi-modal representations by approximating conceptual concreteness from images and filtering model input.
  </a>
  <a href="#1" id="1">
   The results clearly show that including more perceptual input in multi-modal models is not always better.
  </a>
  <a href="#2" id="2">
   Motivated by this fact, our approach provides an intuitive and straightforward metric to determine whether or not to include such information.
  </a>
  <a href="#3" id="3">
   In addition to improving multi-modal representations, we have shown the applicability of the image dispersion metric to several other tasks.
  </a>
  <a href="#4" id="4">
   To our knowledge, our algorithm constitutes the first unsupervised method for quantifying conceptual concreteness as applied to NLP, although it does, of course, rely on the Google Images retrieval algorithm.
  </a>
  <a href="#5" id="5">
   Moreover, we presented a method to classify adjective-noun pairs according to modification type that exploits the link between image dispersion and concreteness.
  </a>
  <a href="#6" id="6">
   It is striking that this apparently linguistic problem can be addressed solely using the raw data encoded in images.
  </a>
  <a href="#7" id="7">
   In future work, we will investigate the precise quantity of perceptual information to be included for best performance, as well as the optimal filtering threshold.
  </a>
  <a href="#8" id="8">
   In addition, we will explore whether the application of image data, and the interaction between images and language, can yield improvements on other tasks in semantic processing and representation.
  </a>
 </body>
</html>