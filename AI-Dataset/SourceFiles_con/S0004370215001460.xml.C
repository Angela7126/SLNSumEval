<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Semi-supervised combination of experts for aerosol optical depth estimation.
   </title>
   <abstract>
    Aerosols are small airborne particles produced by natural and man-made sources. Aerosol Optical Depth (AOD), recognized as one of the most important quantities in understanding and predicting the Earth's climate, is estimated daily on a global scale by several Earth-observing satellite instruments. Each instrument has different coverage and sensitivity to atmospheric and surface conditions, and, as a result, the quality of AOD estimated by different instruments varies across the globe. We present a semi-supervised method for learning how to aggregate estimations from multiple satellite instruments into a more accurate estimate, where labels come from a small number of accurate and expensive ground-based instruments. The method also accounts for the problem of missing experts, an issue inherent to the AOD estimation task. By assuming a context-dependent prior, the model is capable of incorporating additional information and providing estimates even when there are no available experts. Moreover, the proposed method uses a latent variable to partition the data, so that in each partition the expert AOD estimations are aggregated in a different, optimal way. We applied the method to combine global AOD estimations from 5 instruments aboard 4 satellites, and the results indicate it can successfully exploit labeled and unlabeled data to produce accurate aggregated AOD estimations.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Aerosols are small airborne particles produced by natural and man-made sources that both reflect and absorb incoming Solar radiation. Depending on their distribution and composition, aerosols can result either in cooling or warming of the atmosphere, thus having a major role in regulating the climate system. Distribution of aerosols is measured by Aerosol Optical Depth (AOD or τ), a quantitative measure of the extinction of Solar radiation by scattering and absorption between the top of the atmosphere and the surface. Aerosols have been recognized among the most important quantities in understanding and predicting the Earth's climate by the Intergovernmental Panel on Climate Change (IPCC) [2], and have been a focal point of a number of scientific studies due to their importance and large impact on our atmosphere [3], [4], [5]. AOD is an important input to climate models, and it can significantly impact predictions of future climate changes [6]. Considering that climate predictions influence decisions of policy makers, accurate AOD estimation is a task of global significance. Moreover, in addition to its impact on large-scale terrestrial climate studies, AOD is an important quantity in estimation of air pollution that affects the well-being and quality of life of us all. For example, it was shown by [7] that AOD is an accurate predictor of {a mathematical formula}PM2.5, the concentration of particulate matter with aerodynamic diameters {a mathematical formula}≤2.5μm, which poses a serious health hazard to the population [8].
     </paragraph>
     <paragraph>
      Currently, a number of instruments aboard several Earth-observing satellites report their AOD estimates, such as MODIS instrument aboard Terra and Aqua satellites [9], MISR aboard Terra [10], OMI aboard Aura [11], SeaWiFS aboard SeaStar [12], Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) aboard CALIPSO [13], and others. All these instruments have a capability of providing global estimates of AOD distribution with a fine spatial (few kilometers) and temporal (few days) resolution. Each instrument has different properties and estimates AOD using a different algorithm developed by domain scientists. Coverage and quality of satellite measurements can differ from instrument to instrument for a number of reasons. As illustrated in Fig. 1, width of the field of view of MODIS instrument is {a mathematical formula}2,330km, allowing MODIS to observe the entire Earth every day, as opposed to {a mathematical formula}360km width of MISR instrument, which requires 9 days for global coverage. The quality of AOD estimates from different instruments varies with atmospheric and surface conditions [14]. For example, 9 cameras observing Earth at 9 different angles used by MISR allow it to be more accurate than MODIS when clouds are present, over bright surfaces, or for some types of aerosol compositions. In addition to satellite-borne sensors, AOD is also measured by a network of ground-based sensors from AERONET [15], placed at several hundred unevenly distributed locations across the globe, see Fig. 2. AERONET AOD measurements are considered a ground-truth, as they are several times more accurate than the best available satellite AOD estimations. The drawback of AERONET is that it has a very limited spatial coverage, and that it cannot be used to provide global estimation of AOD distribution required for climate models.
     </paragraph>
     <paragraph>
      Different spatial and temporal coverage, design, and specific mission objectives of various satellite-borne instruments mean that they observe and measure different, possibly complementary aspects of the same phenomenon. Thus, instead of considering AOD estimates of individual instruments in isolation, combining measurements from different sources into an aggregated estimate may prove to be the best path towards obtaining a higher-quality, global estimation of aerosol distribution. A recent study by [14] confirmed this hypothesis by illustrating that even a simple average of collocated Terra MODIS and MISR AOD estimations resulted in an improved accuracy.
     </paragraph>
     <paragraph>
      Apart from AOD studies, researchers have explored aggregation of measurements in other areas of Earth science as well, including work on climate change [16], [17], carbon dioxide distribution [18], and sea surface height [19]. Moreover, the combination of experts that ultimately yields an estimate that is more accurate than any of the individual forecasts is a well-researched topic in many other scientific areas, such as risk analysis [20], information retrieval [21], or artificial intelligence [22]. More recently, researchers have proposed a number of state-of-the-art methods that address the problem of aggregation of discrete predictions [23], [24], [25]. However, less progress has been made to address the problem when experts provide real-valued predictions. Assuming the Gaussian distribution of prediction errors and no missing experts, in the seminal works [26] and [27] the authors described a method for learning the optimal combination of experts from labeled data. If data set is unlabeled, in [28] the authors proposed how to learn a combination of experts by extending a classification method from [29]. The approach assumed that the experts are independent and that all experts are always available for aggregation, which may be an unrealistic assumption for the considered task of aerosol estimation.
     </paragraph>
     <paragraph>
      In this paper we propose a novel method suitable for finding a linear combination of AOD estimations from multiple instruments. There are several interesting challenges specific to the aerosol domain that had to be addressed. (1) As quality of different instruments varies with atmospheric and surface conditions, it is not likely that the same linear combination would work equally well at different locations, for example, in North America and Africa [30]. Therefore, it might be needed to develop specialized combinations for different regions around the globe. (2) Number of labeled data points is relatively small. For example, in North America, thanks to a relative abundance of AERONET sites, the number of labeled data points can exceed a thousand every year, while in Africa and parts of Asia there are very few AERONET sites, and the number of labeled data points could be measured in tens every year. In addition to their small number, labeled data points might cover only a limited set of conditions observable at AERONET locations. On the other hand, the number of unlabeled data points is orders of magnitudes larger. An open question in AOD estimation is how to exploit labeled and unlabeled data. (3) As shown in Fig. 1, which illustrates daily coverage of different sensors over the USA, for most of the labeled (e.g., points A and B) and unlabeled (e.g., points C and D) data points, AOD estimations from some of the instruments are missing. For example, points A and C have AOD estimate from all 3 satellite instruments, while points B and D are just outside of MISR's field of view and do not have its AOD estimate. Moreover, even when a particular location is covered by a satellite instrument (i.e., location is within satellite's field of view), it does not mean that the instrument necessarily provides a prediction, further exacerbating the problem of missing data. Typical reasons for missing predictions are cloud contamination, sunglint, or sensor maintenance and repair. Similar holds for ground-based AERONET instrument, which does not provide a complete temporal coverage as it is strongly affected by local weather conditions and other technical issues. This opens a question of learning from data with significant amounts of missing AOD estimations.
     </paragraph>
     <paragraph>
      To address the many issues plaguing remote sensing of aerosols, we assume that AOD estimation errors of satellite instruments follow multivariate Gaussian distribution, and propose a semi-supervised method that can handle missing data while being able to partition the data into homogeneous subsets on which specialized aggregators are learned. Our method can be seen as a significant generalization of the traditional supervised method for combination of experts introduced by [26] and [27], as well as of recently proposed unsupervised method for averaging of experts in regression by [28].
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Methodology
     </section-title>
     <paragraph>
      In this section we describe the details of the proposed semi-supervised aggregation algorithm. We will see that the model is very suitable for aggregation of aerosol predictions, as it accounts for missing satellite predictions, correlated experts, as well as for unlabeled data for which AERONET failed to provide a ground-truth. In addition, by assuming a context-dependent prior, it is capable of incorporating prior knowledge and additional data sources, as well as providing predictions even when there are no available satellite predictors.
     </paragraph>
     <section label="2.1">
      <section-title>
       Problem setup and assumptions
      </section-title>
      <paragraph>
       Let us assume we are given a training set {a mathematical formula}D={xi,{yˆik}k=1,…,K,yi}i=1,…,N, where target value {a mathematical formula}yi for the ith data point is predicted by K experts, with the kth expert providing an opinion in a form of prediction {a mathematical formula}yˆik, and {a mathematical formula}xi∈RD is a column-vector of explanatory features for the ith data point. For example, in the aerosol domain that we study, the experts are satellite instruments and the predictions are their individual AOD estimates, while explanatory variables can be longitude, latitude, temperature, or any other information we have readily available for the ith data point. We arrange the data set such that the first {a mathematical formula}Nu data points are unlabeled, while the last {a mathematical formula}Nl data points are labeled, i.e., we have a ground truth only for data points indexed by {a mathematical formula}i=(Nu+1),…,N, with {a mathematical formula}N=(Nu+Nl). In the remainder of the paper we use 1 to denote a column-vector of all ones of an appropriate length, 0 to denote a matrix of all zeros, and {a mathematical formula}yˆiK=[yˆi1,…,yˆiK]T to denote a column-vector of expert predictions for the ith data point.
      </paragraph>
      <paragraph>
       We assume a linear model for the generation of true AOD values, corrupted by a stochastic process as{a mathematical formula} where {a mathematical formula}w∈RD is a weight vector, and {a mathematical formula}εi is a regression error due to zero-mean Gaussian noise with variance {a mathematical formula}σ2. Then, we can say that the target values {a mathematical formula}yi are sampled from the following Gaussian distribution,{a mathematical formula} Further, we assume that data points are independent and identically distributed (IID), and that expert predictions for the ith data point are sampled from a multivariate Gaussian distribution as{a mathematical formula} This assumption allows the experts to be correlated (i.e., {a mathematical formula}ΣK is non-diagonal), as is the case in practice in the aerosol domain. We will first consider a case where all experts are available, and then extend the methodology to account for missing experts. Given {a mathematical formula}D, the objective is to learn {a mathematical formula}ΣK, w, and {a mathematical formula}σ2. For conciseness, in the following by {a mathematical formula}Θ={ΣK,w,σ2} we denote a set of parameters to be learned in a training phase.
      </paragraph>
      <paragraph>
       Once Θ is learned, and given expert predictions {a mathematical formula}yˆi, aggregated prediction {a mathematical formula}yi for the ith data point can be found as a mean of the posterior distribution {a mathematical formula}yi|xi,yˆiK∼N(y‾i,(1TΣ−11)−1), where mean {a mathematical formula}y‾i is computed as{a mathematical formula} with {a mathematical formula}yˆi=[(yˆiK)T,μi]T, and Σ is a {a mathematical formula}(K+1)×(K+1) block matrix equal to{a mathematical formula} Interestingly, we can see that the prior mean {a mathematical formula}μi can be viewed as an additional expert with variance {a mathematical formula}σ2, which is independent from the original K experts. Thus, to simplify the presentation, in the following we consider the prior mean as the {a mathematical formula}(K+1)th expert that is always available to the aggregation algorithm (i.e., it can never be missing).
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Semi-supervised combination of experts
      </section-title>
      <paragraph>
       Given the model parameters Θ, probability of observing the data set {a mathematical formula}D can be written as{a mathematical formula} where subscripts u and l denote unlabeled and labeled parts of the data set, respectively. Let us first consider {a mathematical formula}P(Du|Θ). As the data points are sampled IID, the probability factorizes over individual data points, and we can write{a mathematical formula} As both probabilities under the integral are assumed Gaussian, due to (2) and (3), their product is also Gaussian. Then, by solving the integral, we obtain{a mathematical formula} Moreover, likelihood of the labeled part can be written as follows,{a mathematical formula} which, following equations (2) and (3), is a product of {a mathematical formula}Nl multivariate Gaussians with covariance matrix Σ. Then, combining equations (6), (8), and (9), we can compute likelihood of the data set {a mathematical formula}D for any given set of parameters Θ.
      </paragraph>
      <paragraph>
       We employ the maximum likelihood principle to find the model parameters. After finding derivative of the log-likelihood with respect to {a mathematical formula}Σ−1 and equating the resulting expression with zero, we obtain the following expression for Σ matrix,{a mathematical formula} where ⊙ denotes element-wise matrix multiplication operator, {a mathematical formula}1 is a {a mathematical formula}K×K matrix of all ones, {a mathematical formula}Yˆu and {a mathematical formula}Yˆl are {a mathematical formula}Nu×(K+1) and {a mathematical formula}Nl×(K+1) matrices of expert predictions for unlabeled and labeled data, respectively, with each row corresponding to a single data point, and {a mathematical formula}yl is an {a mathematical formula}Nl×1 column-vector of ground-truth values. Equation (10) yields an iterative procedure for learning Σ, where Σ on the l.h.s. is a new value, and Σ on the r.h.s. is an old value.
      </paragraph>
      <paragraph>
       Next, we maximize the log-likelihood of data set {a mathematical formula}D with respect to w. The log-likelihood, after removing all elements not dependent on w from equations (8) and (9), is equal to{a mathematical formula} We can see from (11) that, in order to maximize {a mathematical formula}L with respect to w, we need to solve linear regression where for unlabeled points we use an estimate of a ground truth equal to {a mathematical formula}y‾i. A closed-form solution for w can be found using the familiar equations for solving linear regression, computed as{a mathematical formula} where X is an {a mathematical formula}N×D matrix of explanatory features with each row corresponding to a single data point, and y is an N-dimensional vector with the first {a mathematical formula}Nu elements equal to {a mathematical formula}y‾i,i=1,…,Nu, and the remaining {a mathematical formula}Nl elements equal to {a mathematical formula}yi,i=Nu+1,…,N.
      </paragraph>
     </section>
     <section label="2.3">
      <section-title>
       Missing experts
      </section-title>
      <paragraph>
       Let us now consider the case where some experts are missing. For example, let us assume that the ith data point has q missing predictions. Then, we reorganize vector {a mathematical formula}yˆi in such a way so that the first {a mathematical formula}a=(K+1−q) elements are available predictions, while the last q elements are missing predictions, i.e., {a mathematical formula}yˆi=[yˆaiT,yˆqiT]T. Similarly, we reorganize {a mathematical formula}Σ−1 matrix so that the first a rows/columns correspond to available predictions, while the remaining q rows/columns correspond to missing predictions, or{a mathematical formula} where {a mathematical formula}Πi is a permutation function used to reorder both rows and columns of {a mathematical formula}Σ−1 according to the ith data point, and U is an {a mathematical formula}a×a matrix. Given the covariance matrix Σ and a vector of expert predictions {a mathematical formula}yˆai for the ith data point, the aggregated prediction {a mathematical formula}yi can be found as a mean of the posterior distribution {a mathematical formula}yi|yˆai∼N(y‾i,(1TUi′1)−1), where we introduced {a mathematical formula}U′=U−VQ−1VT to simplify the notation, and{a mathematical formula} Note that we appended subscript i to indicate that the size of a matrix {a mathematical formula}Ui′ depends on the number of available experts for the ith data point.
      </paragraph>
      <paragraph>
       In the following, we derive the update equation for Σ. The probability of observing the ith unlabeled point is equal to{a mathematical formula} Solving the equation (15) we obtain{a mathematical formula} In a very similar manner we can find the probability of observing the ith labeled data point. It follows{a mathematical formula} which, after solving the integral, results in{a mathematical formula}
      </paragraph>
      <paragraph>
       By combining equations (6), (16), and (18), we can find the likelihood of the data set {a mathematical formula}D. After finding derivative of the log-likelihood with respect to {a mathematical formula}Σ−1[31] and equating the resulting expression with zero, we obtain the following expression for computing the Σ matrix,{a mathematical formula} where {a mathematical formula}Πi−1 is an inverse permutation function that reorders rows and columns of the matrix back to the original order of experts, symmetric {a mathematical formula}(K+1)×(K+1) matrix {a mathematical formula}Ψi is equal to{a mathematical formula} and {a mathematical formula}〚Ai〛 for some symmetric {a mathematical formula}a×a matrix {a mathematical formula}Ai denotes the following symmetric {a mathematical formula}(K+1)×(K+1) matrix,{a mathematical formula} Lastly, after finding a derivative of the log-likelihood function with respect to w, parameter vector of the prior model can be found as in (12).
      </paragraph>
     </section>
     <section label="2.4">
      Incorporating prior probability {a mathematical formula}P(Θ)
      <paragraph>
       Let us consider the case where we have some prior, expert knowledge about the underlining data-generation model, and would like to include this knowledge into the aggregation model. First, we write the joint probability of the data and the model as follows,{a mathematical formula} Note that we defined prior {a mathematical formula}P(Σ−1) in terms of an inverse of the covariance matrix (i.e., in terms of a precision matrix). For the prior over the Θ parameters we choose a normal-Wishart distribution {a mathematical formula}NW(0,λ−1,S,n), a conjugate prior for multivariate Gaussian distribution, with given λ prior variance parameter, {a mathematical formula}(K+1)×(K+1) scale matrix S, and {a mathematical formula}n&gt;K degrees of freedom, resulting in{a mathematical formula} where {a mathematical formula}ΓK+1 is the multivariate gamma function, and I is a {a mathematical formula}(K+1)×(K+1) identity matrix. After setting {a mathematical formula}n=(K+3) and finding the derivative of the log-likelihood with respect to {a mathematical formula}Σ−1, we obtain the following update equation for the covariance matrix Σ,{a mathematical formula} Similarly, after finding the derivative of the log-likelihood with respect to weight vector, w can be found using the closed-form solution for regularized linear regression, with regularization parameter equal to {a mathematical formula}λσ2,{a mathematical formula}
      </paragraph>
     </section>
     <section label="2.5">
      <section-title>
       Data partitioning using a latent variable
      </section-title>
      <paragraph>
       It is an inherent property of the experts in the aerosol domain that they do not maintain the same quality of predictions across all observed conditions. To address this characteristic of the aggregation problem, we consider partitioning the data points into several groups, called the regimes, where each regime is governed by a different prior from (2) and multivariate Gaussian from (3). In the following we assume there are R regimes, and that we have available a feature vector {a mathematical formula}x˜i∈RD˜ for the ith data point that could be used to assign it to an appropriate regime [32]. Note that we denoted feature vector {a mathematical formula}x˜i used for partitioning and feature vector {a mathematical formula}xi used in the prior from equation (1) differently, to emphasize that they do not necessarily need to be identical.
      </paragraph>
      <paragraph>
       Assuming a mixture of R regimes, probability of observing expert predictions {a mathematical formula}yˆai for the ith labeled data point can be written as follows,{a mathematical formula} where {a mathematical formula}Pr(yˆai|yi)=P(yˆai|regimer,x˜i,yi,Θ), {a mathematical formula}πir(x˜i)=P(regimer|x˜i,Θ), and where appended subscript r denotes the rth regime. Similarly, we can write probability of observing expert predictions {a mathematical formula}yˆai for the ith unlabeled data point as{a mathematical formula} Probability of observing the ith unlabeled or labeled data point given that it was generated by the rth regime, {a mathematical formula}Pr(yˆai) or {a mathematical formula}Pr(yˆai|yi), respectively, can be computed by considering equations (16) and (18), respectively. Before computing the aggregated prediction, we first find the prior mean as{a mathematical formula} which acts as the {a mathematical formula}(K+1)st expert, and the aggregated prediction {a mathematical formula}y‾i can then be found using the following expression,{a mathematical formula}
      </paragraph>
      <paragraph>
       To facilitate model optimization, we consider regime assignments as unobserved data, and introduce a latent indicator variable {a mathematical formula}zir such that the following holds,{a mathematical formula} Further, by introducing {a mathematical formula}zi=[zi1,…,ziR]T, we can write the complete-data likelihood for the ith labeled data point as{a mathematical formula} Note that, for conciseness, in equations (31), (32), and (34), we only give expressions for labeled data. However, when dealing with the ith unlabeled data point we simply need to replace {a mathematical formula}Pr(yˆai|yi) by {a mathematical formula}Pr(yˆai). Then, the complete-data log-likelihood {a mathematical formula}L is equal to{a mathematical formula} Expectation–Maximization (EM) algorithm [33] can be used to find the parameters Θ that maximize {a mathematical formula}L from (32).
      </paragraph>
      <section label="2.5.1">
       <section-title>
        EM algorithm for semi-supervised aggregation
       </section-title>
       <paragraph>
        Before moving on, we need to decide on the parameterization of the prior probability {a mathematical formula}πir. We define this probability using a softmax function,{a mathematical formula} where we defined a prototype vector {a mathematical formula}qr∈RD˜ and a {a mathematical formula}D˜×D˜ feature scaling matrix {a mathematical formula}Λr for each regime, to be found during optimization, resulting in {a mathematical formula}Θ={Σr,qr,Λr}r=1,…,R.
       </paragraph>
       <paragraph>
        In the E-step, we compute the current expectation of posterior probability {a mathematical formula}hir that the rth regime is “responsible” for generating expert predictions for the ith labeled point as{a mathematical formula}
       </paragraph>
       <paragraph>
        In the M-step, we fix values of {a mathematical formula}hir for all data points and regimes, and optimize {a mathematical formula}L with respect to covariance matrices {a mathematical formula}Σr, weight vectors {a mathematical formula}wr, as well as prototype vectors {a mathematical formula}qr and scaling matrices {a mathematical formula}Λr,r=1,…,R. Note that the derivatives of {a mathematical formula}L with respect to these two sets of variables are independent from each other, and the optimization of {a mathematical formula}Σr and {a mathematical formula}wr on one side, and {a mathematical formula}qr and {a mathematical formula}Λr on the other, can be easily parallelized. After derivation, the update equation for {a mathematical formula}Σr can be written as follows,{a mathematical formula} In order to find the weight vector {a mathematical formula}wr, let us first write out log-likelihood {a mathematical formula}Lr, pertaining to the rth regime. After removing all elements not dependent on {a mathematical formula}wr from equations (16) and (18), we obtain the following expression,{a mathematical formula} where the regularization term weighted by 0.5λ corresponds to an isotropic Gaussian prior over the weight vector {a mathematical formula}wr, introduced in Section 2.4. A closed-form solution for {a mathematical formula}wr can be found using the equation for weighted, regularized linear regression, equal to{a mathematical formula} where {a mathematical formula}Hr is a diagonal {a mathematical formula}N×N weight-matrix with the ith diagonal element equal to {a mathematical formula}hir.
       </paragraph>
       <paragraph>
        Lastly, prototype vector {a mathematical formula}qr and scaling matrix {a mathematical formula}Λr can be found through the gradient ascent optimization using the following update equations,{a mathematical formula} where η is an appropriately set learning rate.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="3">
     <section-title>
      Experiments
     </section-title>
     <paragraph>
      In this section, we first experimentally validate the semi-supervised aggregation on synthetic data, and then apply the method to AOD estimation using real-world aerosol data set. We used Root Mean Squared Error (RMSE) measure to report performance of various aggregation methods, commonly used in AOD research [34]. RMSE is defined as follows,{a mathematical formula} where the sum is over N labeled data points from the test set.
     </paragraph>
     <section label="3.1">
      <section-title>
       Validation on synthetic data
      </section-title>
      <paragraph>
       We started by evaluating our method on synthetic data generated as follows: for a given number of regimes R and experts K, we selected weight vector w, prototype q, and a covariance matrix for each regime Σ. Then, we assigned the ith data point uniformly at random with probability {a mathematical formula}1/R to a regime, say the lth regime, and obtained features {a mathematical formula}xi by sampling from multivariate Gaussian with mean {a mathematical formula}ql and covariance matrix {a mathematical formula}0.5I, where for simplicity we also set {a mathematical formula}x˜i=xi. We sampled {a mathematical formula}wr,r=1,…,R, from multivariate Gaussian with zero mean and unit variance. We sampled ground-truth value {a mathematical formula}yi from Gaussian with unit variance and mean computed using (1), then sampled K expert predictions from a Gaussian {a mathematical formula}N(yi1,Σl). Finally, we removed each expert's prediction with probability 0.5 to simulate missing experts. In all experiments we set {a mathematical formula}S=I, and used 15 EM iterations. Learning rate η was set through cross-validation, and reported results averaged over 100 experiments. To better characterize the proposed model, in the first set of experiments we assumed uninformative prior (i.e., we set {a mathematical formula}σ→∞ and did not learn {a mathematical formula}wr vectors), and evaluated benefits of the informative, context-dependent prior at the end of the section.
      </paragraph>
      <paragraph>
       In order to evaluate the semi-supervised method without clustering, we set {a mathematical formula}K=5, {a mathematical formula}R=1, {a mathematical formula}D=D˜=2, and {a mathematical formula}Σ1=diag([0.1,0.2,0.3,0.4,0.5]). We compared our learning method to a baseline method that averages all available experts, as well as to the optimal predictor that computes the prediction (29) using the true {a mathematical formula}Σ1. We increased the number of training points N from 10 to 100 in increments of 10, and for each N we experimented with percentage of labeled data points equal to 0%, 20%, 40%, and 100% (shown as four solid lines in Fig. 3).
      </paragraph>
      <paragraph>
       The results in terms of RMSE, evaluated on {a mathematical formula}1,000 testing points generated in the same way as the training set, are shown in Fig. 3a. We can see that the performance of the fully unsupervised approach, given by the top-most full line, is already better than simple averaging, which further improves as the number of unlabeled data grows. Moreover, as we increase the number of labeled points, the semi-supervised method further improves the accuracy, approaching the lower bound on RMSE achieved by the optimal combination of experts.
      </paragraph>
      <paragraph>
       Next, we generated the data using two regimes by setting {a mathematical formula}q1=[1,1], {a mathematical formula}q2=[−1,−1], {a mathematical formula}Σ1=diag([0.1,0.2,0.3,0.4,0.5]), {a mathematical formula}Σ2=diag([0.5,0.4,0.3,0.2,0.1]), and we set {a mathematical formula}R=2. The results in terms of RMSE are given in Fig. 3b, where we also show accuracy of the proposed method which used only labeled data, but assumed only one cluster. The RMSE of supervised method that assumed only a single cluster is worse than simple averaging, and approached it as the data size increased. Unsupervised method using two clusters achieved better accuracy than simple averaging, and RMSE further decreased with larger data sizes. Introduction of labeled data points further decreased the RMSE.
      </paragraph>
      <paragraph>
       In the following set of experiments we evaluated the benefits of the prior model introduced in (1), and learned both the feature vectors {a mathematical formula}wr and variances {a mathematical formula}σr, {a mathematical formula}r=1,…,R. We set the number of training data points to 100, and experimented with percentage of labeled data points from 0% to 100%, with 10% increments. We set {a mathematical formula}λ=10, and run experiments for {a mathematical formula}R=1 and {a mathematical formula}R=2. The results in terms of RMSE are illustrated in Fig. 4. We can see that the introduction of prior model resulted in significant decrease in the RMSE measure. It is important to note that baseline linear regression alone, trained on labeled data points only, would have RMSE of around 1, much worse than any of the experts. Interestingly, for purely unlabeled data set, the method with informative prior obtained slightly worse result than the method without, which is due to overfitting to the estimated ground-truth values for unlabeled data points (i.e., the prior model learns to predict other experts' predictions), and can be mitigated with stronger regularization when number of labeled data points is small or by increasing size of the training set. However, for both {a mathematical formula}R=1 and {a mathematical formula}R=2, the method with context-dependent prior outperformed the aggregation method with uninformative prior even for small number of available ground-truth labels. Moreover, the performance gap quickly grew as we increased the fraction of labeled data, eventually reaching better RMSE than the optimal method from Fig. 3.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Validation on aerosol data
      </section-title>
      <paragraph>
       In this section we present the results of the experiments on real-world, global aerosol data set. We first describe how the data set was generated, before moving on to the discussion of the performance results.
      </paragraph>
      <section label="3.2.1">
       <section-title>
        The data set
       </section-title>
       <paragraph>
        We used ground-based AERONET data [15] and global data from 5 satellite instruments spanning 5 years, from 2006 to 2010. For the ground-based AERONET sensors we downloaded data for all sites from AERONET website.{sup:1} To obtain the target AOD values we used only Level 2.0 AOD data, the highest-quality data, as it is pre- and post-field calibrated, automatically cloud-cleared and manually inspected, and take a measurement at {a mathematical formula}10:30am as a ground-truth AOD value. Furthermore, to obtain feature vectors {a mathematical formula}xi we used the 2nd-generation NOAA Global Ensemble Forecast System Reforecast (GEFS/R) data,{sup:2} and considered longitude and latitude of the location, as well as the following measurements: wind mixing energy, skin temperature, resulting in dimensionality {a mathematical formula}D=4. To obtain partition feature vectors {a mathematical formula}x˜i we considered longitude and latitude of the location, resulting in dimensionality {a mathematical formula}D˜=2.
       </paragraph>
       <paragraph>
        For the satellite sensors we used Multi-sensor Aerosol Products Sampling System [35],{sup:3} which provides satellite data only when they are collocated with AERONET locations. We used only research-quality AOD estimates, recommended by the teams responsible for the prediction algorithm of each sensor. The following satellite instruments were considered:
       </paragraph>
       <list>
        <list-item label="•">
         MODIS We used Daily Level 2 aerosol product, collection 5.1 (MOD04_L2 and MYD04_L2, for Terra and Aqua, respectively). For this study we only used predictions with Quality Assurance (QA) flag equal to 3, and considered the following Scientific Data Set (SDS): Corrected_Optical_Depth_Land. The product was available at around {a mathematical formula}10:30am and {a mathematical formula}1:30pm local time, at the overpass times of Terra and Aqua satellites, respectively.
        </list-item>
        <list-item label="•">
         MISR We used MIL2ASAE data product, a MISR Level 2 aerosol product. For this study we only used predictions with the Quality Assurance (QAb) flags equal to 0 and 1, and considered the following SDS: RegBestEstimateSpectralOptDepth. The product was available at around {a mathematical formula}10:30am local time, at the overpass time of Terra satellite.
        </list-item>
        <list-item label="•">
         OMI We used OMAERUV, a Level-2 near-UV aerosol absorption and extinction optical depth and single scattering albedo OMI data product. For this study we only used predictions with the Quality assurance for final algorithm flag (Qafaf) equal to 0, and considered the following SDS: FinalAerosolOpticalDepth. The product was available at around {a mathematical formula}1:30pm local time, at the overpass time of Aura satellite.
        </list-item>
        <list-item label="•">
         SeaWiFS We used SWDB_L2, Deep Blue Aerosol Optical Depth Daily Level 2 data product. For this study we only used predictions with Quality Assurance (QA) flag equal to 3, and considered the following SDS: aerosol_optical_thickness_ 550_ land. The product was available at around {a mathematical formula}12:20pm local time, at the overpass time of SeaStar.
        </list-item>
       </list>
       <paragraph>
        We note that we also considered the CALIOP data product. However, due to a very small number of collocated data points that were available, we did not include it in this study.
       </paragraph>
       <paragraph>
        We considered AOD at {a mathematical formula}550nm wavelength. If an instrument did not provide AOD at this wavelength, we performed linear interpolation or extrapolation in the log-scale of predictions at two closest wavelengths to {a mathematical formula}550nm[36]. In particular, if {a mathematical formula}τa and {a mathematical formula}τb are available, where {a mathematical formula}τx denotes AOD reported at wavelength x, {a mathematical formula}τ550 is calculated as follows,{a mathematical formula} We used 5 years of data from 2006 to 2010, where there were, on average, 199 working AERONET sites each year. After removing AERONET sites with too few observations, there remained 86 sites in the data set, with locations shown in Fig. 5. This resulted in a labeled data set with {a mathematical formula}N=23,119 data points, where 67% of expert predictions were missing. Both {a mathematical formula}xi and {a mathematical formula}x˜i vectors were always available for all data points. We used this data set for three sets of experiments: (1) evaluating usefulness of unlabeled data; (2) evaluating usefulness of partitioning; and (3) evaluating usefulness of context-dependent prior over AOD values. In all sets of experiments we performed leave-one-site-out cross-validation.
       </paragraph>
      </section>
      <section label="3.2.2">
       <section-title>
        Results
       </section-title>
       <paragraph>
        In the first set of experiments, we manually split the data into 5 per-continent subsets (2 Australian sites were assigned to Asian cluster), and then trained a separate aggregation model for each partition. We first randomly selected 2 training AERONET sites and took 50 labeled data points from each of them. Then, we selected 50 unlabeled data points from the remaining training AERONET sites, and sampled 50 labeled data points from the left-out site for validation. We trained one model which used only labeled data, and one that used both labeled and unlabeled data. We used {a mathematical formula}R=1 clusters in both cases, and assumed {a mathematical formula}σ→∞, resulting in an uninformative prior over the AOD values. We compared the performance to a baseline method that takes a simple average of available expert predictions. The results in terms of RMSE are given in Table 1, clearly indicating that the proposed method successfully exploited large amounts of readily available unlabeled data. This is particularly important for the largest continents of Asia and Africa, where the density of AERONET sites is very low and labeled data are extremely scarce. As seen in Table 1, the average improvement of semi-supervised approach over the baseline was over 10%, and around 5% over the purely supervised method.
       </paragraph>
       <paragraph>
        In the second set of experiments we evaluated the benefits of data partitioning using the EM algorithm. We randomly sampled from each training site 50 labeled and 50 unlabeled data points, and from the left-out site sampled 50 labeled data points used for validation, assuming {a mathematical formula}σ→∞. We used our proposed method with {a mathematical formula}R∈{1,2,3,4,5}, repeating the experiments 5 times. RMSE is reported in the middle of Table 2, where at the top we also report the RMSE of the semi-supervised method using the per-continent partition considered earlier.
       </paragraph>
       <paragraph>
        We can see that semi-supervised aggregation with partitioning using latent variables had significantly lower RMSE than the baseline where we manually split the data into per-continent subsets using domain knowledge. By increasing the number of clusters from 1 (i.e., without partitioning) to 5 we observed a drop in RMSE of around 6% over the baseline, achieving the best performance for {a mathematical formula}R=3 clusters. In Fig. 5 we color-code the AERONET sites according to their cluster assignments for this case. Interestingly, the shown partition roughly corresponds to clustering found by earlier studies that considered aerosol properties [30], where south-western cluster contains sites with mostly absorbing aerosols, south-eastern cluster sites with mostly non-absorbing aerosols, and northern cluster contains sites with mixed moderately absorbing and non-absorbing aerosols. Given predictions of all the experts, for the northern cluster the weights of linear combination assigned to MISR, Terra MODIS, Aqua MODIS, OMI, and SeaWiFS instruments were {a mathematical formula}[0.37,0.19,0.19,0.13,0.12], for the south-eastern cluster they were {a mathematical formula}[0.46,0.18,0.18,0.05,0.13], for the south-western cluster they were {a mathematical formula}[0.44,0.15,0.15,0.10,0.16], respectively. In concordance with the domain knowledge, MISR obtained the largest weights, while other instruments were given similar weights, with the exception of OMI which consistently had the lowest weight in all clusters.
       </paragraph>
       <paragraph>
        Lastly, we evaluated the benefits of the linear regression prior over the AOD values, introduced in equation (1). Here we dropped the assumption that {a mathematical formula}σ→∞, set {a mathematical formula}R=3 due to the results shown in the middle part of Table 2, and during training learned both weight vectors {a mathematical formula}wr and prior variances {a mathematical formula}σr, {a mathematical formula}r={1,2,3}. In order to partition the data set we used longitude and latitude of the AERONET sites as in the previous experiment, while for explanatory features {a mathematical formula}xi from (1) we used 4 ground measurements discussed in Section 3.2.1. The RMSE performance of the final model is given at the bottom of Table 2, where we can see further improvements over the methods that assumed uninformative prior. In particular, compared to the best previous model, RMSE dropped by around 3.2%, and it is interesting to note that the learned weight of the linear combination for the prior model was roughly similar to the weights of Terra MODIS and Aqua MODIS. An additional benefit of the assumed prior is the ability to provide AOD estimates even when there are no available satellite experts, by using the available non-AOD ground-based measurements through equation (1). We can conclude that the results presented in this section confirm the validity of the proposed semi-supervised method for aggregation of experts, which is able to account for missing experts, find a partition of data into clusters, exploit additional available information through the prior model, and construct specialized aggregators on each cluster.
       </paragraph>
      </section>
     </section>
    </section>
   </content>
  </root>
 </body>
</html>