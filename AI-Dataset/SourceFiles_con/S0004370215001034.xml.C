<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Inducing semantic relations from conceptual spaces: A data-driven approach to plausible reasoning.
   </title>
   <abstract>
    Commonsense reasoning patterns such as interpolation and a fortiori inference have proven useful for dealing with gaps in structured knowledge bases. An important difficulty in applying these reasoning patterns in practice is that they rely on fine-grained knowledge of how different concepts and entities are semantically related. In this paper, we show how the required semantic relations can be learned from a large collection of text documents. To this end, we first induce a conceptual space from the text documents, using multi-dimensional scaling. We then rely on the key insight that the required semantic relations correspond to qualitative spatial relations in this conceptual space. Among others, in an entirely unsupervised way, we identify salient directions in the conceptual space which correspond to interpretable relative properties such as ‘more fruity than’ (in a space of wines), resulting in a symbolic and interpretable representation of the conceptual space. To evaluate the quality of our semantic relations, we show how they can be exploited by a number of commonsense reasoning based classifiers. We experimentally show that these classifiers can outperform standard approaches, while being able to provide intuitive explanations of classification decisions. A number of crowdsourcing experiments provide further insights into the nature of the extracted semantic relations.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      if we know that buying beer is illegal under the age of 18 in the UK, we can plausibly derive that buying whiskey is also illegal under the age of 18, since whiskey is stronger than beer. Unfortunately, the semantic relations that are needed to automate these forms of commonsense reasoning are not commonly available. Large-scale semantic knowledge bases such as DBpedia, YAGO and Freebase mainly encode attributional knowledge such as “Chianti is made from the Sangiovese grape”, while we need relational knowledge such as “Chianti is generally less tannic than Cabernet Sauvignon”. Lexical resources such as WordNet{sup:5} and ConceptNet do contain relational information, but they are limited to a small set of predefined relations (e.g. synonyms and is-a relations).
     </paragraph>
     <paragraph>
      In this paper, we will show how the required semantic relations can be obtained by interpreting them as qualitative spatial relations in a particular kind of distributional model. Specifically, we will obtain semantic relations from conceptual spaces that have been induced from text corpora. Conceptual spaces [9] are metric spaces which are used to encode the meaning of natural language concepts and properties. In most applications, conceptual spaces are assumed to be Euclidean. They are typically high-dimensional, with each dimension corresponding to a primitive cognitive feature. Specific entities then correspond to points in the conceptual space, while natural concepts and properties are posited to correspond to convex regions [9]. Fig. 1 shows a simple example of a two-dimensional conceptual space of vehicles, although it should be noted that most conceptual spaces will have a considerably higher number of dimensions. An important observation is that many types of semantic relations between vehicles correspond to qualitative spatial relations in this conceptual space. For example, the semantic is-a relationship corresponds to a spatial part-of relationship (e.g. the region for bicycle is included in the region for vehicle, because every bicycle is also a vehicle). Furthermore, we can identify conceptual betweenness with geometric betweenness (e.g. the region for motorbike is geometrically between the regions for bicycle and car, and accordingly the properties of a motorbike can be thought of as being intermediate between those of a bicycle and those of a car). Vagueness can be modelled by modelling concepts as fuzzy sets, or more simply, as nested sets of convex regions (e.g. elevators can be considered as borderline cases of vehicles). Finally, relative properties such as “more technologically advanced” correspond to direction relations: the more a vehicle is located to the right, the more it is technologically advanced.
     </paragraph>
     <paragraph>
      The aim of this paper is to investigate (i) how suitable conceptual spaces can be induced from large text corpora, (ii) how interpretable semantic relations can be derived from these conceptual spaces, and (iii) how these relations can be used to learn categorization rules based on the aforementioned commonsense reasoning patterns. Compared to standard machine learning approaches, these categorization rules will have the advantage that they allow us to produce intuitive justifications for inferred facts, which we believe is paramount in applications that rely on imperfect reasoning. Many current recommender systems, for example, essentially use some form of similarity based reasoning, which allows them to provide explanations of the form “we think that you will like X because you have previously expressed an interest in Y and Z”. Similarly, we could imagine a wine recommendation engine to provide suggestions such as “while beef dishes are often paired with Cabernet Sauvignon, we recommend a medium-bodied wine such as Chianti for beef carpaccio, because uncooked meat is usually paired with lighter wines than grilled meat”, if it has no specific knowledge on what wines to pair with beef carpaccio. As another example, consider the problem of automatically extending knowledge bases such as Freebase. Several methods for automatically extending such knowledge bases have already been proposed [4], [10], [11], [3], which could be useful, among others, for developing semantic search systems on the web of data that go beyond fact retrieval. However, given that no method can provide perfect accuracy, in such applications it becomes crucial to explain to users why a particular answer is believed, allowing them to assess the credibility of inferred facts.
     </paragraph>
     <paragraph>
      Beyond commonsense reasoning, inducing semantic relations is also useful for applications such as critique based recommendation and search [12]. The idea of critique based systems is to enable the user to find an item of interest through an interactive process. First, a list of options is displayed, based on an initial query (e.g. hotels in Cardiff). Then the user can critique these options, specifying how the desired item differs from a suggested item (e.g. “like this hotel, but cheaper”). Most existing work is limited to domains where the relevant attributes are clearly defined, and the corresponding values are explicitly provided. One exception is [13], which proposes a critique based movie recommender. Using a supervised method, their system allows users to specify, for instance, that they want “a film like this one, but grittier”. Similarly, [14] proposes a critique based image search engine, based on a supervised method that learns the degree to which visual attributes apply to images, e.g. “I want to buy shoes like these, but shinier”. Clearly, such supervised methods are difficult to scale beyond specific domains. In contrast, the methods we develop in this paper are unsupervised, and could thus enable critique based search in a much broader set of domains.
     </paragraph>
     <paragraph>
      The remainder of this paper is structured as follows. After reviewing related work in Section 2, Section 3 explains how we use multi-dimensional scaling to derive conceptual spaces from text corpora. Then, in Section 4 we show how interpretable semantic relations can be induced from these conceptual spaces in an entirely unsupervised way. Subsequently, Section 5 discusses how these (mostly qualitative) semantic relations can be used in categorization problems. Finally, experimental results are presented in Section 6. This paper significantly extends our work in [15] and [16].
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Related work
     </section-title>
     <section label="2.1">
      <section-title>
       Formalizing commonsense reasoning
      </section-title>
      <paragraph>
       Similarity based reasoning, i.e. the view that similar concepts tend to have similar properties, has been widely studied. In cognition, it lies at the heart of the prototype and exemplar based models of categorization [17], [18], [19]. In machine learning, it forms the basis of the k-nearest neighbour method [20]. Similarity based reasoning has also been studied in logic. For example, [21] uses a connectionist approach for modelling similarity, and proposes an inference mechanism that combines rule based and similarity based reasoning. Several other approaches to similarity based reasoning rely on fuzzy logic for encoding numerical similarity degrees in a logical framework [22], [23].
      </paragraph>
      <paragraph>
       One of the challenges in developing a logic based encoding of similarity based reasoning is that similarity degrees tend to be subjective and context-dependent. Moreover, it is unclear how similar two concepts need to be before plausible conclusions can be obtained, which makes it difficult to automate similarity based reasoning in a principled way. Interpolation avoids these issues by taking the qualitative notion of conceptual betweenness as primitive. Interpolative reasoning has been investigated as a technique for completing fuzzy logic rule bases [24]. Recently, a propositional logic that supports interpolation as a form of commonsense reasoning has been proposed in [25]. The idea of interpolation is also similar in spirit to the approach from [26], where similarity degrees are avoided by introducing a ternary modality encoding comparative similarity. Unlike betweenness, however, comparative similarity is not invariant under linear transformations. Rescaling the dimensions of a conceptual space (which is a linear transformation) is a common method for modelling changes in context, which suggests that comparative similarity may be more context-dependent than betweenness. Another approach to avoid similarity degrees is the idea of statistical predicate invention proposed in [27]. Essentially this approach is based on clustering, where a clustering can be seen as a binary similarity relation (i.e. two elements are considered similar iff they belong to the same cluster) and the idea is that entities from the same cluster tend to have the same properties. However, rather than using a single clustering, the approach from [27] relies on multiple clusterings, each reflecting different aspects of the domain. A method is then proposed to learn which types of properties can be induced from which clusterings.
      </paragraph>
      <paragraph>
       A fortiori reasoning assumes that concepts and properties can be ordered in a natural way and that these orderings are co-monotone. In the example in the introduction, alcoholic drinks are ordered according to strength and it is assumed that this ordering is co-monotone with the legal drinking age, which allows us to draw conclusions about the legal drinking age for whiskey from knowledge about the legal drinking age for beer. This form of inference has been analysed in [28], where it is proposed as the basis of a method for deriving plausible values for missing features, given a collection of feature vectors. The method proposed in [28] is based on the idea of inducing a partial order from a set of feature vectors, and choosing the missing value such that the resulting partial order is maximally regular in some sense.
      </paragraph>
      <paragraph>
       Analogical reasoning can be seen as a generalization of a fortiori reasoning, where the ordering on concepts and properties is not explicitly given, but is rather encoded implicitly in the form of examples. Instead of assuming that the natural ordering of concepts and properties is co-monotone, we then assume that concepts which differ in analogous ways have properties which differ in analogous ways. Several authors have studied analogical proportions, i.e. statements of the form “salmon tartare is to grilled salmon what beef carpaccio is to grilled steak”, and their use in classification in recent years [29], [30], [31], [32]. Most of these approaches are restricted to binary or nominal attributes, although recently some promising results have been obtained for numerical attributes as well [32]. The use of analogical-proportion based reasoning in logic has been considered in the approach from [25], where the more general notion of extrapolative reasoning was studied. Note that while analogical reasoning is a broad area of study, we will not be concerned with approaches that aim to transfer knowledge from one domain to another [33].
      </paragraph>
      <paragraph>
       It should be noted that existing approaches to commonsense reasoning typically require that objects are described using well-defined attributes, encoded as binary or real-valued features. In contrast, we consider scenarios where we only have access to text documents describing the entities of interest. Moreover, we are not only interested in identifying that e.g. beer relates to wine like wine relates to whiskey, but also in naming this relationship, i.e. wine is stronger than beer, and whiskey is stronger than wine.
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Acquiring semantic relations
      </section-title>
      <paragraph>
       It is convenient to represent the meaning of terms or documents as points, vectors or regions in a Euclidean space. Such representations are known as vector-space models, conceptual spaces, or semantic spaces, and are popular in areas such as cognition [34], computational linguistics [35], [36], [37], information retrieval [38], [39] and knowledge representation [9], [4]. In information retrieval, it is common to represent documents as vectors with one component for every term occurring in the corpus. In many other applications (and sometimes in information retrieval) some form of dimensionality reduction is typically used to obtain vectors whose components correspond to concepts. One of the most popular techniques, called latent semantic analysis (LSA [39]), uses singular value decomposition (SVD) to this end. Multi-dimensional scaling (MDS [40]) is another popular method for dimensionality reduction, which builds a vector-space representation from pairwise similarity judgements. It is popular, among others, in cognitive science to interpret pairwise similarity judgements obtained from human assessors.
      </paragraph>
      <paragraph>
       Most approaches represent natural language terms as points or vectors. One notable exception is the work of Gärdenfors on conceptual spaces [9], where properties and concepts are represented using convex regions, while specific instances of a concept are represented as points. This has a number of important advantages. First, it allows us to distinguish borderline instances of a concept from more prototypical instances, by taking the view that instances which are closer to the center of a region are more typical [9]. A second advantage is that using regions makes it clear whether one concept subsumes another (e.g. every pizzeria is a restaurant), whether two concepts are mutually exclusive (e.g. no restaurant can also be a beach), or whether they are overlapping (e.g. some bars serve wine but not all, some establishments which serve wine are bars but not all). Region based models have been shown to outperform point based models in some natural language processing tasks [41]. On the other hand, using regions is computationally more demanding, and learning accurate region boundaries for a given concept would require a prohibitive amount of data. In this paper, we essentially view point based representations as coarse-grained approximations of conceptual spaces, where points correspond to fine-grained categories instead of specific instances, while convex regions are used to model higher-level categories.
      </paragraph>
      <paragraph>
       To date, vector-space representations have almost exclusively been used to estimate the similarity between terms (or documents), e.g. to find documents that match a given query in information retrieval, or to find synonyms in computational linguistics. The use of similarity degrees from vector-space models for logical reasoning has been explored in [6]. In particular, the authors extend a Markov logic theory with rules that essentially encode that similar concepts are likely to have the same properties. It is shown that implementing this form of similarity based reasoning improves a system for recognizing textual entailment. In [7], distributional similarity is used to improve reasoning about commonsense knowledge bases such as ConceptNet. Other authors use similarity based reasoning in a more implicit way for automatically extending (light-weight) knowledge bases. For example, [4] represents ConceptNet as a matrix, with rows corresponding to concepts and columns corresponding to properties, and then applies singular value decomposition on that matrix to identify plausible properties that are missing from ConceptNet. Along similar lines, [10] represents YAGO as a tensor and uses a tensor decomposition method to find plausible properties that are missing from YAGO. Even though these methods do not explicitly use a similarity measure, the assumption underlying the use of dimensionality reduction methods is that similar concepts are likely to have similar properties.
      </paragraph>
      <paragraph>
       Beyond similarity, a few authors have looked at learning analogical proportions {a mathematical formula}a:b::c:d from data. If the analogical proportion {a mathematical formula}a:b::c:d holds, the pairs {a mathematical formula}(a,b) and {a mathematical formula}(c,d) are called relationally similar [42]. To learn relationally similar pairs from a text corpus, in [42] a matrix is compiled with rows corresponding to pairs of words {a mathematical formula}(a,b) and columns corresponding to phrases P. The matrix itself encodes whether the corpus contains sentences in which the phrase P connects the words a and b. For example, in a sentence such as “a kitten is a young cat” the words kitten and cat are connected by the phrase “X is a young Y”. Singular value decomposition is then applied to the matrix, after which relationally similar pairs of words can be identified. The method is thus able to learn that e.g. (kitten, cat) is relationally similar to (puppy, dog) by observing that both pairs of terms tend to be connected by similar phrases (e.g. “X is a young Y”). While showing promising results, this approach has the drawback of being computationally demanding. Moreover, it can only discover relational similarity between pairs of words that are mentioned in the same sentence sufficiently often. An alternative method, which does not suffer from these drawbacks, has been proposed in [43]. This method learns two semantic spaces, based on two different notions of similarity, referring respectively to functional role and the domain of terms. In this way, the approach can discover that (carpenter, wood) and (mason, stone) are relationally similar, because: (i) carpenter and wood are terms from the same domain, (ii) mason and stone are from the same domain, (iii) carpenter and mason have a similar function, and (iv) wood and stone have a similar function. However, this approach is not suitable for identifying semantic relations among entities of the same type (e.g. between pairs of movies), which is what we focus on in this paper. A few approaches have tried to learn analogical proportions by identifying (approximate) parallelograms in a learned semantic space, including the approach based on multi-dimensional scaling from [44] and the neural network based approach from [45]. Note that the aforementioned approaches essentially use a geometric representation of the domain of interest to discover analogical proportions. In [46] the opposite problem is discussed: given a set of analogical proportions that are known to hold, it is studied how can we learn a better geometric representation (in the context of visual object categorization).
      </paragraph>
      <paragraph>
       A rather different line of work uses relation extraction methods to extract semantic relations from natural language sentences. For example, NELL{sup:6}[47] extends and populates an ontology by continuously reading web documents, relying only on minimal human supervision. Along similar lines, the Open Information Extraction project{sup:7}[48] aims to extract semantic relations without specifying the types of semantic relations in advance, again by analysing natural language sentences. SOFIE [49] also extracts semantic relations from natural language, but focuses on extending an existing ontology such as YAGO. Relation extraction from natural language is clearly a promising method to identify properties of entities (e.g. the fact that the Shining movie was released in 1980). However, it is less clear to what extent relation extraction can successfully identify semantic relations between entities of the same type, such as “the Shining is (generally considered) more terrifying than the Hunger games”. Indeed, there are few sentences on the web that explicitly compare two movies in such a way{sup:8} (unless in particular cases, such as when a sequel is compared to the original movie).
      </paragraph>
     </section>
    </section>
    <section label="3">
     <section-title>
      Inducing conceptual spaces from data
     </section-title>
     <paragraph>
      In Section 4, we will discuss how semantic relations between entities of the same kind can be induced from conceptual spaces. These relations will then be used in Section 5 as the basis for commonsense reasoning based classifiers. In this section, we first focus on data acquisition, and in particular on how we have induced the conceptual spaces that will be used throughout the paper. We will focus on conceptual spaces in three domains: place types, movies, and wines. Sections 3.1 Acquiring data about place types, 3.2 Acquiring data about movies, 3.3 Acquiring data about wines explain how we have compiled a text corpus about entities in these domains. Section 3.4 then explains how we use multi-dimensional scaling to obtain a conceptual space.
     </paragraph>
     <section label="3.1">
      <section-title>
       Acquiring data about place types
      </section-title>
      <paragraph>
       The set {a mathematical formula}Eplace of place types that we have considered are those from the following place type taxonomies: GeoNames{sup:9} organises 667 place types in 9 categories, encompassing both man-made and natural features.Foursquare{sup:10} also uses 9 top-level categories, but focuses mainly on urban man-made places such as restaurants, bars and shops. Although a few of these categories include sub-categories, the taxonomy is mostly flat, and we will only consider the top-level categories in this paper. In total, the Foursquare taxonomy contains 435 place types.OpenCYC{sup:11} is a common-sense knowledge base, containing a large open-domain taxonomy. To derive a suitable place type taxonomy from OpenCYC, we considered all refinements of the category Site, leading to a total of 3388 place types, organised in directed acyclic graph. We have used Flickr,{sup:12} a photo-sharing website, to derive textual information about each of the place types. Users on Flickr can assign tags (i.e. short textual descriptions) to their photos. Our assumption is that photos which are tagged with a given place type (e.g. restaurant) will often contain other tags that relate to that place type (e.g. food, waiter, dessert). The distribution of tags that co-occur with a given place type on Flickr may thus provide us with meaningful information about the meaning of that place type.
      </paragraph>
      <paragraph>
       We have used the Flickr API to collect a large number of photos which are tagged with one of the considered place types. For composite names such as “football stadium”, photos with both of the tags football and stadium were accepted, in addition to those including the concatenation of the whole name, footballstadium. In total we collected 22 816 139 photos in April 2014. Place types with fewer than 1000 associated photos on Flickr have been removed from the set {a mathematical formula}Eplace of considered entities. Sufficient numbers of photos were found for 391 place types from Foursquare, 403 place types from GeoNames, and 923 place types from OpenCYC. For each of the remaining entities e, we define the associated text document {a mathematical formula}De as the bag-of-words containing all tags that co-occur with e in the collected sample of Flickr photos.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Acquiring data about movies
      </section-title>
      <paragraph>
       Initially, we considered the 50 000 movies with the highest number of votes on IMDB.{sup:13} For each of these movies, in October 2013 we collected reviews from the following sources: IMDB,{sup:14} Rotten Tomatoes,{sup:15} SNAP project's Amazon reviews [50],{sup:16} and the data set from [51].{sup:17} To link reviews across these sources, we assume that movies with the same title and release year are identical; Rotten Tomatoes was linked with IMDB by using the IMDB IDs that are provided by the Rotten Tomatoes API. We then selected the 15 000 movies whose associated reviews contained the highest number of words as the set {a mathematical formula}Emovie of considered movies. Similarly as in Section 3.1, we associated with each movie e from {a mathematical formula}Emovie a bag-of-words {a mathematical formula}De, now consisting of the terms from the reviews rather than tags of associated Flickr photos. We have removed words from a standard list of stop words,{sup:18} converted all words to lower case, and removed diacritics and punctuation.
      </paragraph>
     </section>
     <section label="3.3">
      <section-title>
       Acquiring data about wines
      </section-title>
      <paragraph>
       For wines, we used the corpus of wine reviews from the SNAP Project.{sup:19} This corpus contains 2 025 995 reviews of 485 179 different wines. For each of these wines, the name of the corresponding wine variant is also provided, e.g. the wine 2001 Thierry Allemand Cornas Reynard is of variant Syrah. The entities we will consider in this paper are these wine variants, rather than the specific wines (since too little information is available about most of the specific wines). In particular, the set {a mathematical formula}Ewine contains the 330 wine varieties for which the available reviews together contained at least 1000 words. The bag-of-words representation {a mathematical formula}De for each of these wine varieties e was obtained as for the movie data.
      </paragraph>
     </section>
     <section label="3.4">
      <section-title>
       Dimensionality reduction
      </section-title>
      <paragraph>
       The process explained in Sections 3.1 Acquiring data about place types, 3.2 Acquiring data about movies, 3.3 Acquiring data about wines results in a set of entities E from a given domain and for each entity {a mathematical formula}e∈E a document {a mathematical formula}De, represented as a bag of words. To obtain a vector-space representation of these documents, we need to quantify for each term occurring in the corpus {a mathematical formula}{De|e∈E} how strongly it is associated with e. Following [52], we use the Positive Pointwise Mutual Information (PPMI) measure to this end. In particular, let {a mathematical formula}c(e,t) be the number of times term t occurs in the document {a mathematical formula}De. Then the weight {a mathematical formula}ppmi(e,t) for term t in the vector representing e is given by {a mathematical formula}max⁡(0,log⁡(petpe⁎⋅p⁎t)) where{a mathematical formula} Like the popular TF-IDF measure, PPMI will favor terms which are frequently associated with the entity e while being relatively infrequent in the corpus overall. Let us use {a mathematical formula}ve to denote the resulting vector representation of entity e, i.e. if the considered terms are {a mathematical formula}t1,…,tk then {a mathematical formula}ve=(ppmi(e,t1),…,ppmi(e,tk)). There are two reasons why we cannot use these vector representations directly. First, these representations are too sparse: often {a mathematical formula}ppmi(e,t)=0 will hold even if t is relevant to the entity e, because t has not been mentioned in the document {a mathematical formula}De. Second, as will become clear in Section 4, we need a geometric representation in which entities correspond to points and in which Euclidean distance is a meaningful measure of dissimilarity (which implies that spatial relations such as betweenness and parallelism are also meaningful).
      </paragraph>
      <paragraph>
       To address both issues we use multi-dimensional scaling (MDS). MDS takes as input a dissimilarity matrix and a number of dimensions n. To measure the dissimilarity between two entities {a mathematical formula}ei and {a mathematical formula}ej we use the normalized angular difference:{a mathematical formula} Given these dissimilarities, MDS generates an n-dimensional Euclidean space, in which each entity {a mathematical formula}ei is associated with a point {a mathematical formula}pi such that the Euclidean distance {a mathematical formula}d(pi,pj) approximates the dissimilarity {a mathematical formula}ang(ei,ej). We will consider Euclidean spaces of dimensions 20, 50, 100 and 200. In general, using a small value for n leads to representations which mainly capture high-level properties of the entities, and thus a better generalization of specific representations. On the other hand, by using a larger value of n, the representations preserve more specific details, at the cost of being more noisy. The number of dimensions n thus reflects a trade-off. We have used the implementation of classical multidimensional scaling from the MDSJ java library.{sup:20}
      </paragraph>
      <paragraph>
       Several authors have already proposed the use of dimensionality reduction for commonsense reasoning. For example, [4] uses Singular Value Decomposition (SVD) to find missing properties in ConceptNet. However, SVD produces a representation in which entities correspond to vectors, which should be compared in terms of cosine similarity rather than Euclidean distance. In applications which only rely on similarity, this poses no problems. However, we can expect that spatial relations such as betweenness and parallelism (which we will need) are not meaningful in the representations derived from SVD. This has been confirmed by experiments in [15], where we compared the representations resulting from MDS, SVD, and Isomap [53]. While it may be possible to find alternative measures of betweenness and parallelism that make sense for vectors, the use of point representations is more intuitive and will allow us to use off-the-shelf SVM classifiers for identifying salient directions in Section 4.2.2, among others.
      </paragraph>
      <paragraph>
       In the following, we will refer to {a mathematical formula}Splace, {a mathematical formula}Smovie and {a mathematical formula}Swine to denote the Euclidean spaces that were obtained using this process (assuming the number of dimensions is clear from the context, or irrelevant for the discussion). We will refer to these spaces as conceptual spaces. Sometimes we will write {a mathematical formula}S to denote a generic conceptual space. The point in {a mathematical formula}S corresponding to an entity e will be denoted by {a mathematical formula}pe. However, when there is no cause for confusion, we will often use the notation e to refer both to the entity and the corresponding point in {a mathematical formula}S. We have made all conceptual space representations, as well as the initial PPMI weighted vectors, available online.{sup:21}
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Deriving semantic relations from conceptual spaces
     </section-title>
     <paragraph>
      It is well-known that Euclidean distance in {a mathematical formula}S can be used to define a measure of semantic similarity, e.g. {a mathematical formula}sim(a,b)=e−λ⋅d(a,b) for {a mathematical formula}a,b∈E and some fixed {a mathematical formula}λ&gt;0. This particular similarity measure is often used in the field of cognition and has proven useful in models of human categorization [54], [55]. Beyond similarity, few authors have looked at modelling semantic relatedness using spatial relations (apart from the preliminary work in [44]). To characterise additional forms of semantic relatedness, we will consider spatial relations in {a mathematical formula}S that relate to betweenness and direction, which will allow us to implement classifiers based on interpolative and a fortiori reasoning.
     </paragraph>
     <section label="4.1">
      <section-title>
       Betweenness
      </section-title>
      <paragraph>
       We say that an entity b is conceptually between entities a and c if b has all the natural properties that a and c have in common. Geometrically, we say that the point {a mathematical formula}pb is between points {a mathematical formula}pa and {a mathematical formula}pc if {a mathematical formula}cos⁡(papb→,pbpc→)=1, where we write {a mathematical formula}cos⁡(x,y) for vectors x and y to denote the cosine of the angle between x and y. Both notions of betweenness can be linked to each other, by considering that natural properties tend to correspond to convex regions in conceptual spaces [9]. Indeed, {a mathematical formula}pb is geometrically between {a mathematical formula}pa and {a mathematical formula}pc iff all convex regions that contain {a mathematical formula}pa and {a mathematical formula}pc also contain {a mathematical formula}pb. This suggests that we can identify geometric betweenness in {a mathematical formula}S with conceptual betweenness.
      </paragraph>
      <paragraph>
       Since it is unlikely that a point b will be perfectly between two other points a and c in {a mathematical formula}S, we need to measure degrees of betweenness. First we define a degree of collinearity as follows:{a mathematical formula} where p is the orthogonal projection of b on the line connecting a and c, as illustrated in Fig. 2(a). To measure betweenness, we additionally check whether p is between a and c:{a mathematical formula} noting that {a mathematical formula}cos⁡(ac→,ab→)≥0 and {a mathematical formula}cos⁡(ca→,cb→)≥0 iff p lies on the line segment between a and c. If {a mathematical formula}BtwA(a,b,c)=0 then b is perfectly between a and c, with higher scores corresponding to weaker betweenness relations. The measures Col and {a mathematical formula}BtwA are illustrated in Figs. 2(a) and 2(b).
      </paragraph>
      <paragraph>
       We also consider a second betweenness measure, based on the observation that {a mathematical formula}‖ac→‖≤‖ab→‖+‖bc→‖ (by the triangle inequality), and {a mathematical formula}‖ac→‖=‖ab→‖+‖bc→‖ iff b is exactly between a and c:{a mathematical formula} In contrast to {a mathematical formula}BtwA, higher values for {a mathematical formula}BtwB represent a stronger betweenness relation, with a score of 1 denoting perfect betweenness. With this alternative definition, illustrated in Fig. 2(c), points near a or b will get some degree of betweenness, even if their projection p is not between a and b.
      </paragraph>
      <paragraph>
       Table 1 shows for a number of place types b which pair of place types {a mathematical formula}(a,c) minimizes {a mathematical formula}BtwA(a,b,c). Most of these triples indeed intuitively correspond to conceptual betweenness. For example, properties which hold for convenience stores and farmers markets (e.g. selling fruit) also tend to hold for grocery stores. In addition to these examples, we have also found several triples {a mathematical formula}(a,b,c) with a low score for {a mathematical formula}BtwA(a,b,c) where a, b and c are highly similar, but none of the place types is clearly between the other two (not shown in the table). Examples include:{a mathematical formula}{a mathematical formula}{a mathematical formula} It is indeed easy to see that if a, b and c are close to each other in {a mathematical formula}S, at least one of {a mathematical formula}BtwA(a,b,c), {a mathematical formula}BtwA(b,a,c) and {a mathematical formula}BtwA(a,c,b) will be low. While such triples do not always correspond to our intuition of betweenness, they tend to be useful for implementing interpolative reasoning, as we will see in Section 6. We also found some triples {a mathematical formula}(a,b,c) in which one of the place types is a generalization of the other(s). Examples include:{a mathematical formula}{a mathematical formula}{a mathematical formula} To more accurately model the relationship between place types at different levels of granularity, we could represent place types as regions, instead of points, and identify approximate betweenness, overlap, and part-of relations between these regions. Such representations can be obtained by clustering the text documents associated with each entity, representing each such cluster as a point in {a mathematical formula}S and then identifying the entity e.g. with the convex hull of these points (possibly after removing outliers). Initial experiments, reported in [15], have revealed that such a region based representation did not consistently improve the performance of a betweenness based classifier, while being computationally much more expensive. Therefore, we have not considered region based representations in this paper. An alternative would be to define betweenness relative to a taxonomy of place types, and only consider triples between place types that are at the same level of the taxonomy.
      </paragraph>
      <paragraph>
       Table 2, Table 3 provide examples of betweenness for movies and wine varieties. The examples for movies closely correspond to an intuitive notion of conceptual betweenness. For wines, however, we mainly seem to find triples {a mathematical formula}(a,b,c) where b is either highly similar to a or to c.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Interpretable directions
      </section-title>
      <paragraph>
       It is tempting to think of the dimensions of the space {a mathematical formula}S as primitive features from the domain of interest. Unfortunately, however, the dimensions that we obtain from MDS tend not to have an intuitive meaning. Most existing work on learning spaces with interpretable dimensions has focused on non-negative matrix factorization (NMF [56]). The advantage of NMF stems from the fact that each dimension in the learned space corresponds to a linear combination of features from the original space (i.e. natural language terms in our context) which uses positive weights only. The positive nature of the weights means that dimensions can be seen as (weighted) clusters of terms. Moreover, some approaches to NMF explicitly enforce sparsity to obtain dimensions which correspond to linear combinations of just a few terms, and thus further improve the interpretability of the learned dimensions [57]. As is the case for SVD, however, Euclidean distance is not necessarily meaningful as a measure of dissimilarity in the space obtained by NMF.
      </paragraph>
      <paragraph>
       Since Euclidean distance plays a key role in our approach (e.g. given its relationship to the notion of betweenness), instead of using NMF, we will show how we can identify (in an unsupervised) way interpretable directions in the space {a mathematical formula}S, corresponding to the most salient properties of the domain of interest (but typically not orthogonal to each other). For example, in a space of movies there could be a direction pointing towards more violent movies. Each of the identified directions will yield a ranking of the considered entities, according to how much they have the corresponding property, e.g. by identifying the direction modelling ‘more violent than’ in a conceptual space of movies, we can obtain a ranking of movies according to their level of violence. These rankings provide a purely qualitative representation of the conceptual space {a mathematical formula}S, capturing semantic relations which are not yet included in existing knowledge bases such as Freebase and YAGO.
      </paragraph>
      <paragraph>
       In Section 4.2.1 we explain how we can identify directions that correspond to interpretable properties, while in Section 4.2.2 we discuss how these directions can be used to make explicit how one entity is semantically related to another. Section 4.2.3 then focuses on selecting those directions that correspond to the most salient properties.
      </paragraph>
      <section label="4.2.1">
       <section-title>
        Interpreting semantic relations as directions
       </section-title>
       <paragraph>
        Interpretable directions should correspond to natural language terms. It is moreover natural to assume that such directions will correspond to terms that occur in the text corpus from which the space {a mathematical formula}S was induced.{sup:22} As a first step, we therefore compile a set T of all terms that are sufficiently frequent in this text corpus. Let {a mathematical formula}Tplace, {a mathematical formula}Tmovie and {a mathematical formula}Twine (defined as follows) be the set of terms that are considered for {a mathematical formula}Splace, {a mathematical formula}Smovie and {a mathematical formula}Swine respectively. In the case of {a mathematical formula}Splace, where the text corpus consists of Flickr tags, {a mathematical formula}Tplace was chosen as the set of all tags that co-occur with at least 50 different place types in our Flickr corpus (out of the 1383 considered place types). This resulted in a total of {a mathematical formula}|Tplace|=21833 candidate terms. In the case of {a mathematical formula}Smovie, we considered adjectives, nouns, adjective phrases and noun phrases that appear in the corpus of reviews. The underlying assumption is that there will be meaningful directions of two types. Some dimensions will correspond to gradual properties (e.g. violent, funny, creepy), which are most likely to correspond to an adjective or adjective phrase. Other dimensions will correspond to topics, which may relate to the genre, theme or other aspects of the movie that are likely to correspond to a noun or noun phrase. To select adjectives, nouns, and adjective/noun phrases from the reviews, we used the part-of-speech tagger and chunker from the Open NLP Project.{sup:23} We only considered words and phrases which appear in the reviews of at least 100 movies (out of the 15 000 considered movies), resulting in a total of 22 903 candidate terms. The thresholds of 50 in the case of {a mathematical formula}Tplace and 100 in the case of {a mathematical formula}Tmovie were chosen such that the total number of candidate terms is approximately equal, i.e. {a mathematical formula}Tplace≈Tmovie. Finally, in the case of {a mathematical formula}Swine we again extracted adjectives, nouns and adjective/noun phrases from the reviews and considered all terms which appear in the reviews of at least 50 different wine varieties (out of the 330 considered varieties), leading to {a mathematical formula}|Twine|=6385 candidate terms.
       </paragraph>
       <paragraph>
        We then assign a direction in {a mathematical formula}S to each term t from T. To this end, we first train a (linear) SVM to find the hyperplane {a mathematical formula}Ht in {a mathematical formula}S that best separates the entities to which t applies from the others, where we say that t applies to an entity if at least one of its associated text documents contains t. The perpendicular vector {a mathematical formula}vt→ of {a mathematical formula}Ht is then considered to define the direction associated with t. We used LibSVM{sup:24} with a linear kernel and the standard values for all parameters, but we adapted the costs of the training instances to deal with class imbalance (using the ratio between entities with/without the term as cost). Only some of the terms in T correspond to properties of the considered entities. Accordingly only some of the terms in T can be faithfully modelled as a direction in {a mathematical formula}S. Therefore, as a last step, we estimate to what extent {a mathematical formula}vt→ is indeed a meaningful representation of the term t. Here we use the assumption that the better {a mathematical formula}Ht separates entities to which t applies from the others in {a mathematical formula}S, the better {a mathematical formula}vt→ models the term t. To quantify the performance of the SVM model, we used Cohen's Kappa measure [58], due to its tolerance to class imbalance. We also considered several alternative metrics, including Spearman's and Kendall's correlation coefficients to measure the correlation between the ranking induced by {a mathematical formula}vt→ and the number of times t appears in the documents associated with each entity. As the results from these alternative metrics were less promising in initial experiments, we have not considered them further. The higher the Kappa score of a term t, the more we consider {a mathematical formula}vt→ to be a faithful representation of the term t. We write {a mathematical formula}Tλ for the set of terms from T whose Kappa measure is at least λ.
       </paragraph>
      </section>
      <section label="4.2.2">
       <section-title>
        Describing the semantic relation between two entities
       </section-title>
       <paragraph>
        For two entities {a mathematical formula}e1 and {a mathematical formula}e2, represented as points in {a mathematical formula}S, we can compare the vector {a mathematical formula}e1e2→ with the vectors {a mathematical formula}vt→ of interpretable terms t ({a mathematical formula}t∈Tλ for a given value of {a mathematical formula}λ&gt;0). This leads to the following measure {a mathematical formula}diffA of how well term t describes how entity {a mathematical formula}e2 differs from entity {a mathematical formula}e1.{a mathematical formula} As a baseline method, we can also look at how frequently t is used in the text documents associated with {a mathematical formula}e1 and {a mathematical formula}e2. As before, let {a mathematical formula}ppmi(e,t) be the PPMI-value of term t in the document associated with entity e. We define:{a mathematical formula} Note that {a mathematical formula}diffB is only defined for unigrams, in contrast to {a mathematical formula}diffA.
       </paragraph>
       <paragraph>
        Table 4, Table 5, Table 6 illustrate the kind of results that both measures can achieve (using {a mathematical formula}λ=0.1 and a 100-dimensional space), while a more formal evaluation based on a crowdsourcing experiment will be presented in Section 6.2.1. The examples in Table 4 show that {a mathematical formula}diffA can indeed find meaningful labels to describe how two place types differ. As the example for cupcake shop illustrates, the terms which are selected also depend on the choice of {a mathematical formula}e1: a cupcake shop mainly differs from a hobby shop in the fact that it sells confections, leading to terms such as icing and dessert. On the other hand, cupcake shop mainly differs from a bagel shop in the kind of confections that are sold, leading rather to terms such as gift and handmade. The baseline measure {a mathematical formula}diffB tends to select terms which are too specific (e.g. motoq9c), although some highly relevant terms are identified as well (e.g. caribbeanfood, pescatarian, medicaleducation). In Table 5, the use of phrases has the advantage that terms such as science fiction can be recognized. On the other hand, it also leads to the occurrence of phrases such as your spine (from the idiom “sending shivers down your spine”) which are less suitable as descriptions. The results for wines in Table 6 are mixed. While {a mathematical formula}diffA is able to identify reasonable terms when the two wines are very different (e.g. chardonnay and merlot), for wines that are more similar (e.g. pinot gris and pinot blanc), no terms are found which achieve a high value for {a mathematical formula}diffA(e1,e2;t), resulting in some generic terms being identified among the top terms (e.g. a tasting note). This may be explained by the fact that the wine space contains only 330 entities (making the problem of inducing a 100-dimensional conceptual space under-constrained), the fact that {a mathematical formula}Twine contains fewer candidate terms than {a mathematical formula}Tplace and {a mathematical formula}Tmovie (potentially leading to fewer interpretable directions in the space), and the fact that we have less text, on average, per wine than per film of place type. Moreover, wines from the same variety can be very different, which further complicates the problem of deriving meaningful conceptual space representations.
       </paragraph>
      </section>
      <section label="4.2.3">
       <section-title>
        Selecting the most salient directions
       </section-title>
       <paragraph>
        Much of human reasoning relies (only) on our ability to rank entities or concepts according to a particular feature [59]. A central problem is thus to identify the most salient properties of a given domain. In our setting, this boils down to selecting the most salient directions in {a mathematical formula}S. We can intuitively think of these directions as a non-orthogonal basis for the space {a mathematical formula}S, where dimensions now correspond interpretable properties.
       </paragraph>
       <paragraph>
        To select interpretable directions, we will only consider the terms in {a mathematical formula}T0.5, as a Kappa score of 0.5 was found in initial experiments to offer a good balance between keeping a sufficient number of terms and ensuring that the terms are modelled adequately as directions in {a mathematical formula}S. To select the most salient directions, we first select the term with the highest Kappa score overall. Then we repeatedly apply the following process: as the ith term, we select the term t minimising {a mathematical formula}maxj&lt;i⁡cos⁡(vtj→,vt→). In other words, we repeatedly select the term which is least similar to the terms that have already been selected. One possibility would be to choose as many terms as there are dimensions in {a mathematical formula}S. However, because we have no guarantees that all terms will be linearly independent from the others, we allow for some redundancy, and select 2n terms for an n-dimensional space.
       </paragraph>
       <paragraph>
        Let {a mathematical formula}d1,…,d2n be the terms that have been selected. We then associate with each term {a mathematical formula}di a cluster {a mathematical formula}Ci containing all terms from {a mathematical formula}T0.1 which are more similar to {a mathematical formula}di than to any of the other directions {a mathematical formula}dj. The cluster {a mathematical formula}Ci in turn defines a direction {a mathematical formula}vi⁎→=1|Ci|∑t∈Civt→, which we will consider as the direction corresponding to term {a mathematical formula}di. Note that in principle, we could now reassign the terms in {a mathematical formula}T0.1 to the closest direction {a mathematical formula}vi⁎, as in the k-means algorithm, but initial experiments with this approach did not yield any clear improvements.
       </paragraph>
       <paragraph>
        Each of these salient directions {a mathematical formula}vi⁎→ naturally induces a ranking. In particular, for a given {a mathematical formula}Ci, let {a mathematical formula}Li={o+λ⋅vi⁎→|λ∈R} be the corresponding line, where o represents the origin of {a mathematical formula}S. For each entity {a mathematical formula}e∈E, let {a mathematical formula}qei be the orthogonal projection of {a mathematical formula}pe on the line {a mathematical formula}Li. Then {a mathematical formula}qei is of the form {a mathematical formula}qei=o+λei⋅vi⁎→. The associated ranking {a mathematical formula}&lt;i is defined as follows: {a mathematical formula}e&lt;if iff {a mathematical formula}λei&lt;λfi. We write {a mathematical formula}ri(e) for the rank of entity e in this ranking, i.e. {a mathematical formula}ri(e)=|{f|f∈E,f&lt;ie}|. The complete list of clusters and the corresponding directions, for each of the conceptual spaces has been made available on the online companion website.{sup:25} Moreover, we have also made available for each entity e the feature vector {a mathematical formula}(λe1,…,λe2n) (from which the rankings {a mathematical formula}&lt;i can readily be obtained). Examples of the selected salient directions and the correspond clusters are show in Table 7 for place types, Table 8 for movies and Table 9 for wines. Many of the directions in Table 7 encode properties of place types. Examples include nature, bahnhof, pub and tapas. Other clusters correspond to geographic areas, e.g. chicago, malaysia and uk. Given that {a mathematical formula}Splace has been derived from Flickr, it is not surprising to see some clusters related to photography, such as light. The directions about movies in Table 8 are different in a number of aspects. Being derived from full text documents instead of tags, the table contains individual terms as well as phrases. More importantly, the fact that adjectives are now also considered seems to lead to a higher number of directions which describe properties of movies, e.g. touching, clever, romantic, eerie, etc. In addition, we also find directions corresponding to movie themes, e.g. horror movies, supernatural or political. Some of the other directions include budget (referring to the production value), directions grouping phrases that start with her and his (referring to whether the lead actor is male or female), vhs (referring to older films, which were initially released on e.g. VHS or LaserDisc), era (referring to films which are set in the past) and sequel (referring to films which are part of a series). The directions in Table 9 mainly correspond to different flavours found in wine, which is unsurprising since reviews from which the conceptual space {a mathematical formula}Swine was induced are essentially tasting notes. In contrast to the case of place types and movies, for wines we find several clusters which are quite similar. For example, the cluster for light food mentions salad whereas the cluster for grass mentions salads. Conversely, some clusters should ideally be split into two or more separate clusters (e.g. in the cluster grape juice, the terms terrible and a very good price correspond to different properties). Most importantly, some natural properties of wines are lacking. Ideally there would be directions ordering wines according to their amount of tannins, the heaviness of their body, and their acidity. None of the identified directions exactly models these properties, although some directions are highly correlated with them (e.g. dark fruits for the amount of tannins).
       </paragraph>
      </section>
     </section>
     <section label="4.3">
      <section-title>
       Parallelism
      </section-title>
      <paragraph>
       As we discussed in Section 4.2, the vector {a mathematical formula}ab→ defined by two entities a and b encodes how these entities differ from each other. Given four entities a, b, c and d, we can thus naturally model the relational similarity between {a mathematical formula}(a,b) and {a mathematical formula}(c,d) by comparing the vectors {a mathematical formula}ab→ and {a mathematical formula}cd→. In [29] the following measure of analogical dissimilarity is proposed:{a mathematical formula} This measure evaluates to 0 if the points a, b, c, d define a parallelogram. We can think of the direction of {a mathematical formula}ab→ as encoding in which aspects a differs from b (e.g. ‘b is more violent than a’) while {a mathematical formula}‖ab→‖ measures the amount of difference (e.g. how much more violent b is). This means that (1) not only requires that {a mathematical formula}(a,b) and {a mathematical formula}(c,d) are related in similar ways, but also that the amount of change is similar. Since often only the former is relevant, we will also consider the following measure, which disregards the amount of change:{a mathematical formula} Note that {a mathematical formula}simB measures relational similarity, whereas {a mathematical formula}dissA measures dissimilarity. In the following, we will mainly be interested in finding the points c and d in the training data that minimize {a mathematical formula}dissA(a,b,c,d) or maximize {a mathematical formula}simB(a,b,c,d), given a and b. In other words, we will only use the measures {a mathematical formula}dissA and {a mathematical formula}simB to rank pairs of objects {a mathematical formula}(c,d). It is easy to show that {a mathematical formula}simB corresponds to a normalized version of {a mathematical formula}dissA, in the sense that {a mathematical formula}simB(a,b,c,d)≤simB(a,b,e,f) iff {a mathematical formula}dissA(a‖ab→‖,b‖ab→‖,c‖cd→‖,d‖cd→‖)≥dissA(a‖ab→‖,b‖ab→‖,e‖ef→‖,f‖ef→‖).
      </paragraph>
      <paragraph>
       Note that {a mathematical formula}simB was also used in [45] for learning analogical relations, although for vector representations instead of point based representations. In particular, to complete the analogical proportion {a mathematical formula}a:b::c:x, given a, b and c, they propose selecting the vector {a mathematical formula}vx→ which maximizes {a mathematical formula}cos⁡(vx→,vb→−va→+vc→) (where {a mathematical formula}va→ is the vector representation of a, and similar for {a mathematical formula}b,c,x). Since {a mathematical formula}cos⁡(vx→,vb→−va→+vc→)=cos⁡(vx→−vc→,vb→−va→), this corresponds to applying {a mathematical formula}simB to vector representations. There are, however, a number of differences between the aims of [45] and our aims in this paper. For example, due to the way in which the vector representations from [45] have been learned, their approach is able to recognize syntactic regularities in language, such as {a mathematical formula}better:best::rougher:roughest. They also identify semantic relations between common words, such as {a mathematical formula}man:woman::king:queen. In contrast, we focus on learning fine-grained relations between entities of the same type.
      </paragraph>
      <paragraph>
       Table 10, Table 11, Table 12 contain examples of analogical pairs of place types, movies, and wines. In particular, each line in these tables corresponds to a tuple {a mathematical formula}(a,b,c,d) for which {a mathematical formula}simB(a,b,c,d) is close to 1. Some of these tuples are such that a and c are very similar and b and d are very similar. For example, in Table 10, the tuple {a mathematical formula}(baseball diamond,college science building,stadium,college campus) does not intuitively correspond to an analogy. It is found because baseball diamond and stadium are located close to each other in {a mathematical formula}Splace, as are college science building and college campus. As a result, the vectors {a mathematical formula}ab→ and {a mathematical formula}cd→ are nearly identical, resulting in a high score for both {a mathematical formula}dissA and {a mathematical formula}simB. Despite not intuitively corresponding to analogies, such tuples will still be useful in an analogical classifier, as we will see further. To obtain tuples which intuitively do correspond to analogical proportions, we need to additionally require that a and c are sufficiently far apart (which also means that b and d will be far apart). An example of such a tuple is shown on the first line of Table 10: prisons are used for holding people while sheep folds are used for holding animals; hospital rooms are used for healing people, while veterinarians heal animals. Similarly, in Table 11, the movies million dollar baby and rocky are about boxing, while requiem for a dream and trainspotting are about drug abuse. On the other hand, million dollar baby and requiem for a dream have in common that they are much darker than rocky and trainspotting. In Table 12, for example, the tuple {a mathematical formula}(barbaresco,valpolicella,dolcetto,bardolino) reflects that barbaresco is more tannic than valpolicella while dolcetto is typically more tannic than bardolino. On the other hand, barbaresco and dolcetto are both from the Piedmont region, while valpolicella and bardolino are from the Verona region.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Commonsense reasoning based classifiers
     </section-title>
     <paragraph>
      To evaluate the practical usefulness of the considered semantic relations, we will focus on their use in commonsense reasoning based classifiers, i.e. classifiers which are based on inference patterns such as interpolation and a fortiori inference. One of the main advantages of such classifiers is that we can easily generate explanations for the decisions they make.
     </paragraph>
     <paragraph>
      Let {a mathematical formula}C1,…,Cm be disjoint categories and let {a mathematical formula}Oi be a set of entities that are known to belong to category {a mathematical formula}Ci (i.e. {a mathematical formula}O=⋃iOi is the available training data). We consider the problem of deciding which category is most likely to contain an unlabelled entity x. In this context, using similarity based reasoning corresponds to k-NN classification [20], i.e. we use {a mathematical formula}S to find the k entities {a mathematical formula}y1,…,yk from O which are most similar to x and then assign x to the category to which most of the entities {a mathematical formula}yi belong. We now discuss a number of classifiers which are based on other commonsense reasoning patterns.
     </paragraph>
     <section label="5.1">
      <section-title>
       Betweenness based classification
      </section-title>
      <paragraph>
       Betweenness can be used to classify objects similarly to how k-NN uses similarity. Instead of looking for entities y that are similar to x, we then look for pairs of entities {a mathematical formula}(y,z) from the same category {a mathematical formula}Ci such that x is approximately between y and z. The main underlying assumption is that the categories {a mathematical formula}C1,…,Cm correspond to convex regions in {a mathematical formula}S, in accordance with the theory of conceptual spaces [9]. Using this assumption, we can conclude that x belongs to the category {a mathematical formula}Ci from the knowledge that (i) y and z belong to {a mathematical formula}Ci and (ii) x is located between y and z. In practice, perfect betweenness is rare, which leads us to consider the pairs {a mathematical formula}(y,z) which maximize the value of {a mathematical formula}Btw(y,x,z), where e.g. {a mathematical formula}Btw=BtwA or {a mathematical formula}Btw=BtwB. More generally, we could also consider the top k such pairs. To classify the entity x, we then first identify the pairs {a mathematical formula}(y1,z1),…,(yk,zk) that maximize {a mathematical formula}Btw(yi,x,zi) such that {a mathematical formula}yi and {a mathematical formula}zi belong to the same category. Each of the pairs {a mathematical formula}(yi,zi) suggests a category for the test instance. The final decision is then based by a majority vote from the k best pairs.
      </paragraph>
      <paragraph>
       In the case where {a mathematical formula}k=1, this betweenness classifier can be generalized to a convex hull based classifier [60]. In a convex hull based classifier, every category {a mathematical formula}Ci is represented geometrically as the convex hull of the points (i.e. entities) that are known to belong to {a mathematical formula}Ci. The test item x is then assigned to the category whose convex hull is closest. However, evaluating the distance between a point and a convex hull requires solving a quadratic optimization problem, which is computationally expensive in high-dimensional spaces. Moreover, while we have introduced Col mainly to define the measure {a mathematical formula}BtwA, as will become clear in the experiments in Section 6, using Col instead of {a mathematical formula}BtwA or {a mathematical formula}BtwB can also be useful in a classification setting. Such a classifier is similar in spirit to so-called affine hull based classifiers [61], [62], but is again computationally much less demanding.
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       Classification based on relational similarity
      </section-title>
      <paragraph>
       While several authors have proposed analogical proportion based classifiers, most work to date has focused on binary or nominal attributes. One exception is [29], where analogical dissimilarity between pairs of entities with continuous attributes is defined in terms of how close the feature vectors of the four entities are to defining a parallelogram, although no experimental results were provided on the use of this measure in a classifier. In [30] a definition of graded analogical proportion was given, based on fuzzy logic connectives. A corresponding classifier was moreover proposed, based on the idea that the more the attributes of 4 entities are in an analogical proportion, the more we can expect the class labels to be in an analogical proportion as well. However, while promising, the results that were obtained are not competitive with standard methods such as k-NN and SVM. Recently, somewhat better results have been reported in [32], although only datasets with clearly defined and relatively few attributes have been considered (the largest considered dataset has 36 attributes).
      </paragraph>
      <paragraph>
       To assess to what extent such methods can be successful in our context, where entities are represented as points in a relatively high-dimensional Euclidean space, we will consider classifiers that use the measures {a mathematical formula}dissA and {a mathematical formula}simB from Section 4.3. We will consider binary (i.e. two-class) classification problems only, even though the approach can naturally be extended to problems with a larger number of linearly ordered classes (and even more generally, to problems where relational similarity between pairs of class labels can be measured). For {a mathematical formula}x,y,z,u∈{0,1}, analogical proportions are defined as follows [63]:{a mathematical formula} Note that there are six tuples {a mathematical formula}(x,y,u,v) in {a mathematical formula}{0,1}4 that form an analogical proportion: {a mathematical formula}(0:0::0:0), {a mathematical formula}(1:1::1:1), {a mathematical formula}(0:0::1:1), {a mathematical formula}(1:1::0:0), {a mathematical formula}(1:0::1:0) and {a mathematical formula}(0:1::0:1). When the feature vectors of four objects are in an (approximate) analogical proportion, analogical classifiers consider that their class labels should also be in an analogical proportion. Let {a mathematical formula}cl(a)∈{0,1} be the class label of object a, where 0 and 1 are interpreted as the logical constants false and true to evaluate (3). Let a be an entity whose class label is unknown. The approach from [29] then consists of the following steps:
      </paragraph>
      <list>
       <list-item label="•">
        Find the triples {a mathematical formula}(b,c,d) in the training set for which there exists a value {a mathematical formula}x∈{0,1} that makes {a mathematical formula}x:cl(b)::cl(c):cl(d) an analogical proportion. Among these triples, find the one {a mathematical formula}(b⁎,c⁎,d⁎) that minimizes {a mathematical formula}dissA(a,b⁎,c⁎,d⁎).
       </list-item>
       <list-item label="•">
        Choose the class label of a as the unique value {a mathematical formula}x∈{0,1} that makes {a mathematical formula}x:cl(b⁎)::cl(c⁎):cl(d⁎) an analogical proportion.
       </list-item>
      </list>
      <paragraph>
       We will refer to this approach as {a mathematical formula}analogA. We will also consider the alternative {a mathematical formula}analogB where in the first step, the triple {a mathematical formula}(b⁎,c⁎,d⁎) is chosen that minimizes {a mathematical formula}simB(a,b⁎,c⁎,d⁎).
      </paragraph>
      <paragraph>
       Note that the only two cases where the triple {a mathematical formula}(cl(b),cl(c),cl(d)) cannot be extended to an analogical proportion are when {a mathematical formula}(cl(b),cl(c),cl(d))=(0,0,1) and {a mathematical formula}(cl(b),cl(c),cl(d))=(1,1,0). As we explain next, these two cases give rise to a different type of classifier, whose intuition is based on the idea of a fortiori reasoning. In particular, when {a mathematical formula}(cl(b),cl(c),cl(d))=(0,0,1), we can think of {a mathematical formula}dc→ as defining a direction from membership to non-membership of the considered class. Since b does not belong to the class, if {a mathematical formula}ab→ is approximately parallel to {a mathematical formula}cd→, we would expect that a would definitely not belong to the category, since it is obtained from b by following a direction that is associated with non-membership. Similarly, when {a mathematical formula}(cl(b),cl(c),cl(d))=(1,1,0), the direction {a mathematical formula}dc→ is associated with membership, hence we can expect a to belong to the category if {a mathematical formula}cl(b)=1 and {a mathematical formula}ab→ is approximately parallel to {a mathematical formula}cd→. This leads us to the following procedure:
      </paragraph>
      <list>
       <list-item label="•">
        Find the triples {a mathematical formula}(b,c,d) of entities in the training set such that {a mathematical formula}(cl(b),cl(c),cl(d))=(0,0,1) or {a mathematical formula}(cl(b),cl(c),cl(d))=(1,1,0). Among these triples, find the one {a mathematical formula}(b⁎,c⁎,d⁎) that maximizes {a mathematical formula}simB(a,b⁎,c⁎,d⁎).
       </list-item>
       <list-item label="•">
        If {a mathematical formula}(cl(b⁎),cl(c⁎),cl(d⁎))=(0,0,1), we choose {a mathematical formula}cl(x)=0. If {a mathematical formula}(cl(b⁎),cl(c⁎),cl(d⁎))=(1,1,0), we choose {a mathematical formula}cl(x)=1.
       </list-item>
      </list>
      <paragraph>
       We will refer to this approach as {a mathematical formula}analogC. Since the intuition here is purely based on the direction of change, we only consider {a mathematical formula}simB. This idea of specifically looking at types of change that affect the class label is somewhat reminiscent of the approach proposed in [64], which is based on learning change patterns between binary feature vectors that affect the class label. Note that we will refer to {a mathematical formula}analogA, {a mathematical formula}analogB and {a mathematical formula}analogC as analogical classifiers, for the ease of presentation, even though {a mathematical formula}analogC is more related to a fortiori reasoning than to existing analogical proportion based classifiers.
      </paragraph>
      <paragraph>
       To avoid the cubic time complexity of a naive implementation, in variants using {a mathematical formula}dissA, we maintain three KD trees {a mathematical formula}T&gt;, {a mathematical formula}T&lt; and {a mathematical formula}T=storing respectively the vectors ab→, with a and b entities from the training data, for which {a mathematical formula}class(a)&gt;class(b), {a mathematical formula}class(a)&lt;class(b) and {a mathematical formula}class(a)=class(b). In variants using {a mathematical formula}simB we instead store the normalised vectors {a mathematical formula}ab→‖ab→‖ In this way, the average-case time complexity of the analogical classifiers is reduced from {a mathematical formula}O(n3) to {a mathematical formula}O(n2⋅log⁡(n)). A different approach to avoid a cubic time complexity is proposed in [29]. This latter approach, called FADANA, is based on precomputing the analogical dissimilarity for a subset of the training data, and relying on the fact that {a mathematical formula}dissA satisfies the triangle inequality. Our proposed approach is conceptually simpler, however, as we can rely on off-the-shelf implementations of KD trees, and we do not need to tweak the number of instances for which to precompute the analogical dissimilarity.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Classification based on salient properties
      </section-title>
      <paragraph>
       The classifiers from Section 5.2 use the assumption that directions can be identified in {a mathematical formula}S that point towards class membership, which is what we need for implementing a fortiori reasoning. In practice, however, many of the dimensions of {a mathematical formula}S will be irrelevant, i.e. ideally we want to look at directions in a relevant subspace of {a mathematical formula}S. The following classification rule, for instance, looks at direction in a one-dimensional subspace of {a mathematical formula}S: Ifx is more scary than most horror films thenx is a horror film. We will also consider rules with more than one condition, e.g.: Ifx is less sweet and less fruity than most wines thenx is a savory red wine. To implement a classifier that uses such rules, we need to identify for each class which are the most appropriate directions and how we should interpret ‘most’. As candidate directions, we consider the 2n salient directions that were selected in Section 4.2.3. Initially, we will interpret ‘most’ in a strict way. In particular, we will learn rules with conditions of the form {a mathematical formula}x0&lt;iy and {a mathematical formula}x0&gt;iy, where y is the item to be classified and {a mathematical formula}x0 is another (possibly unlabelled) entity. For example, rather than learning the first rule above, we would learn a rule such as Ifx is more scary than the shiningthenx is a horror film. After these rules have been learned, we will soften our interpretation of ‘most’ to reflect that the more a movie is scary, the more likely it is a horror film. We will again focus on binary classification problems only, but the method can be straightforwardly extended to multi-class problems.
      </paragraph>
      <paragraph>
       To learn the rules, we use a variant of the well-known FOIL algorithm [65]. Crucially, we assume that only the rankings {a mathematical formula}&lt;i (induced by the 2n selected salient directions) are available, i.e. we make no use of the actual conceptual space representation of the films. As in the original version of FOIL, our method generates one rule at a time. Each time a rule is created, the positive examples covered by that rule are deleted from the training data. Following this procedure, new rules are incrementally added until 95% of the positive examples have been covered. Then the algorithm is run a second time, generating rules for the negatives examples, in the same way.
      </paragraph>
      <paragraph>
       Rules are generated by incrementally adding conditions of the form {a mathematical formula}x0&lt;iy or {a mathematical formula}x0&gt;iy. In particular, starting with an empty list of conditions (“if true then y belongs to class X”), at each step, we choose the condition that maximizes the weighted information gain:{a mathematical formula} where pos and neg are the number of positive and negative examples which are covered by the rule that has been constructed so far, while {a mathematical formula}posC and {a mathematical formula}posC are the number of positive and negative examples which are still covered after the condition C is added to that rule ({a mathematical formula}posC≤pos and {a mathematical formula}negC≤neg). Rules are considered complete when no improvement in terms of information gain can be made anymore, or when the length of the rule reaches a predefined size; we used a maximum of 5 conditions. The accuracy of each rule is then estimated according to its Laplace accuracy (see [65]), defined as {a mathematical formula}pos+1pos+neg+2, where pos and neg are again the number of positive and negative examples that are covered by the rule.
      </paragraph>
      <paragraph>
       The result of this training step is a set of rules that derive conclusions of the form {a mathematical formula}y∈X and a set of rules that derive conclusions of the form {a mathematical formula}y∉X. When rules of both types apply to a given test instance y, FOIL uses a weighted majority process, in which rules are weighted based on their Laplace accuracy. Here, we add a second factor, to encode the principle that a rule with condition {a mathematical formula}x0&lt;iy should receive a greater support if {a mathematical formula}ri(y)−ri(x0) is large, and to avoid discarding the rule completely if the condition is violated but {a mathematical formula}ri(x0) is close to {a mathematical formula}ri(y). In other words, we interpret a condition such as {a mathematical formula}x0&lt;iy as a soft constraint. Specifically, we measure the degree to which the condition {a mathematical formula}y&gt;ix0 is satisfied as follows:{a mathematical formula} where B is a parameter that controls how strict the condition {a mathematical formula}y&gt;ix0 is to be interpreted. We will refer to {a mathematical formula}FOILi to denote the version of our algorithm that uses {a mathematical formula}B=Ni. Initially, we considered the values {a mathematical formula}N1=100, {a mathematical formula}N2=500 and {a mathematical formula}N3=2500 for the conceptual space of movies. By choosing a range of values we will be able to analyze how sensitive the results are to the choice of B. Since the value of {a mathematical formula}Ni relates to the number of entities, for the remaining problem domains, we have chosen values that reflect a similar proportion of the total number of considered entities. For classification experiments with places, we will consider GeoNames, Foursquare and OpenCYC separately. Since our conceptual space of places contains 403 entities from GeoNames, we choose {a mathematical formula}N1=2.5 because {a mathematical formula}10015000≈2.5403≈0.006 and similarly for the other values and other place type taxonomies. For the classification experiments with wines, we will consider 120 wines only as not all of the 330 wines in {a mathematical formula}Ewine appear in the taxonomy that we will use. As a result we choose {a mathematical formula}N1=0.8 since {a mathematical formula}0.8120≈0.006. The values {a mathematical formula}Ni that we will consider are summarized in Table 13. In addition, we will use {a mathematical formula}FOIL0 to denote the version of our classifier in which {a mathematical formula}lt(x0,y,i) is replaced by the crisp constraint {a mathematical formula}y&gt;ix0.
      </paragraph>
      <paragraph>
       The scores for conditions of the form {a mathematical formula}x0&gt;iy are computed in a similar way. The degree to which a rule is satisfied is defined as the minimum of the degrees to which its conditions are satisfied. When categorising a test instance, each rule receives a score which is the product of its Laplace accuracy and the degree to which it is satisfied for that instance. For rules predicting non-membership, this score is multiplied by −1. To make the final decision, we then assume that the test item belongs to the class iff the sum of the scores of the 5 most accurate rules is positive.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Experimental results
     </section-title>
     <paragraph>
      Our evaluation consists of two parts. First, in Section 6.1 we will evaluate whether the derived semantic relations are sufficiently accurate to be useful in a classification setting. Then in Section 6.2, we will discuss the outcome of a number of crowdsourcing experiments which aim at evaluating more subjective aspects, such as whether the semantic relations can provide useful explanations. All data needed to replicate the experiments has been made available on a companion website,{sup:26} including the PPMI weighted vectors, the MDS representations, the directions interpreting each of the terms, the chosen salient properties and the corresponding clusters of terms.
     </paragraph>
     <section label="6.1">
      <section-title>
       Evaluation of classifier performance
      </section-title>
      <paragraph>
       The baseline classifiers which we will consider are as follows: k-NNis a standard k-NN classifier (using majority voting if {a mathematical formula}k&gt;1).{a mathematical formula}SVMMDSis an SVM classifier with a Gaussian kernel, where the feature vector of each item is given by its coordinate in {a mathematical formula}S. We have used the LIBSVM{sup:27} implementation. Because default values of the parameters yielded very poor results, we have used a grid search procedure to find the optimal value of the C parameter for every class. To this end, the training data for each class was split into 2/3 training and 1/3 validation. Moreover, to address class imbalance we under-sampled negative training examples, such that the ratio between positive and negative training examples was at least 1/2.{a mathematical formula}SVMBoWis an SVM classifier where the feature vector of each item contains the PPMI values for every term t from the considered text corpus. Apart from this, we used the same configuration as for {a mathematical formula}SVMMDS.{a mathematical formula}C4.5MDSis a standard C4.5 classifier, where the feature vector of each item is given by its coordinate in {a mathematical formula}S. We have used the implementation from the KEEL project,{sup:28} using standard values for all parameters.{a mathematical formula}C4.5diris a C4.5 classifier, where the feature vector of an entity e contains the values {a mathematical formula}λei, corresponding to the orthogonal projections of e onto the salient directions (cf. Section 4.2.3).
      </paragraph>
      <section label="6.1.1">
       <section-title>
        Results for place types
       </section-title>
       <paragraph>
        To evaluate the classifiers in the domain of place types, we generated a number of classification experiments from the Foursquare, GeoNames and OpenCYC taxonomies. For each of the 9 top-level categories that were used by Foursquare in September 2013,{sup:29} we considered the corresponding binary classification problem. In the case of GeoNames, we only used 7 of the 9 categories,{sup:30} as for 2 categories too few place types were retained in {a mathematical formula}Eplace. Finally, from the OpenCYC taxonomy, we derived 93 binary classification problems, corresponding to categories at different levels of the hierarchy.{sup:31} We used 5-fold cross-validation in all experiments.
       </paragraph>
       <paragraph>
        The results are summarized in Table 14, where we consider conceptual spaces of dimensions 20, 50, 100 and 200. A first important observation is that the results are quite robust w.r.t. the chosen number of dimensions: similar results are obtained for 50, 100 and 200 dimensions, although 20 dimensions is too few for most classifiers. Second, as the classification problems are heavily imbalanced, most methods are able to achieve a similar accuracy score. Differences between the F1 score, on the other hand, are more pronounced. Overall, the best results are obtained by Col, {a mathematical formula}BtwA and {a mathematical formula}AnalogC. These methods consistently improve 1-NN, which is the best-performing baseline method. Even though the differences with 1-NN are relatively small, they are statistically significant in the case of OpenCYC. Specifically, for OpenCYC we found
       </paragraph>
       <list>
        <list-item label="•">
         The accuracy of 1-NN in 50D is significantly improved by Col ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwA ({a mathematical formula}p-value&lt;0.0001) and {a mathematical formula}BtwB ({a mathematical formula}p-value&lt;0.0001); the F1 score of 1-NN in 50D is significantly improved by {a mathematical formula}AnalogC ({a mathematical formula}p-value=0.0178).
        </list-item>
        <list-item label="•">
         The accuracy of 1-NN in 100D is significantly improved by Col ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwA ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwB ({a mathematical formula}p-value&lt;0.0001) and {a mathematical formula}AnalogB ({a mathematical formula}p-value&lt;0.0001); the F1 score of 1-NN in 100D is significantly improved by Col ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwA ({a mathematical formula}p-value=0.0008), {a mathematical formula}AnalogA ({a mathematical formula}p-value=0.0018), {a mathematical formula}AnalogB ({a mathematical formula}p-value=0.0033) and {a mathematical formula}AnalogC ({a mathematical formula}p-value&lt;0.0001).
        </list-item>
        <list-item label="•">
         The accuracy of 1-NN in 200D is significantly improved by Col ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwA ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwB ({a mathematical formula}p-value&lt;0.0001) and {a mathematical formula}AnalogC ({a mathematical formula}p-value&lt;0.0001); the F1 score of 1-NN in 200D is significantly improved by Col ({a mathematical formula}p-value&lt;0.0001), {a mathematical formula}BtwA ({a mathematical formula}p-value=0.0007), {a mathematical formula}AnalogB ({a mathematical formula}p-value=0.0036) and {a mathematical formula}AnalogC ({a mathematical formula}p-value&lt;0.0001).
        </list-item>
       </list>
       <paragraph>
        All p-values have been obtained using a two-tailed Wilcoxon signed-rank test. For Foursquare and GeoNames, the number of classification problems (9 and 7 respectively) was not sufficient to achieve statistical significance.
       </paragraph>
       <paragraph>
        Looking more closely at the results in Table 14, we find that {a mathematical formula}BtwA outperforms {a mathematical formula}BtwB. Surprisingly, we also find that Col usually performs as good as or better than {a mathematical formula}BtwA, despite only checking for collinearity. For the analogical classifiers, we find that {a mathematical formula}AnalogC performs better than {a mathematical formula}AnalogA and {a mathematical formula}AnalogB, suggesting that a fortiori inference is more reliable for continuous representations than looking for analogical proportions. The FOIL, C4.5 and SVM classifiers are not competitive. However, we do find that {a mathematical formula}SVMMDS outperforms {a mathematical formula}SVMBoW, which suggests that using a conceptual space representation is useful even for standard classifiers. For k-NN and the betweenness classifier, we found {a mathematical formula}k=1 to be a good choice overall. Fig. 3 shows how the results are affected by the choice of k. Note that the betweenness classifiers are clearly less sensitive to the choice of k. This suggests that while there may often only be a few sufficiently similar entities that can be exploited by a k-NN classifier, there tend to be many more relevant betweenness triples. In the remainder of this paper, we will only consider the case {a mathematical formula}k=1.
       </paragraph>
       <paragraph>
        To better understand why the betweenness classifier is able to outperform k-NN, Table 15 gives examples of places which were classified correctly by {a mathematical formula}BtwA but incorrectly by 1-NN. In many of these examples, the misclassification by 1-NN is because the nearest neighbour is not similar in some important aspect. For example, while music school is related to jazz club (both being music related venues), these place types have rather different functions (being education and entertainment respectively), which leads 1-NN to misclassify music school as an Arts &amp; Entertainment venue. Betweenness, on the other hand, is more demanding, e.g. while music school is both similar to jazz club and to piano bar, music school is not located between these places. Other examples of misclassifications of this kind include bike shop (vs. bike rental) and medical center (vs. medical school). Misclassifications by 1-NN also happen because none of the place types in the training data is sufficiently similar. For example, the place type closest to veterinarian is photography lab which results in the misclassification of veterinarian as a Shops &amp; Services venue. In contrast, betweenness does not require any of the place types to be similar. Because veterinarian was identified as being between animal shelter and emergency room, the betweenness classifier has correctly classified it as belonging to Professional &amp; Other places.
       </paragraph>
      </section>
      <section label="6.1.2">
       <section-title>
        Results for movies
       </section-title>
       <paragraph>
        We have evaluated the classifiers in the movies domain on three different types of classes: genres, rating certificates, and plot keywords. Movie genres have been taken from IMDB.{sup:32} We have only considered those 23 genres which have been assigned to at least 100 movies from our data set. Given that multiple genres may be assigned to the same movie, we have considered 23 binary classification problems instead of a single multi-class problem. Second, we considered the task of predicting the rating certificate of movies, focusing on the BBFC{sup:33} certificates and their US equivalent. The ground truth was again obtained from IMDB.{sup:34} The UK ratings can be ranked as follows: {a mathematical formula}U&lt;PG&lt;12/12A&lt;15&lt;18/R18. To interpret rating prediction as a classification problem, we considered the classes “PG or more restrictive”, “{a mathematical formula}12/12A or more restrictive”, “15 or more restrictive” and “{a mathematical formula}18/R18”. The US ratings can be ranked as {a mathematical formula}G&lt;PG&lt;PG−13&lt;R/NC−17, similarly leading to 3 additional classification problems. Finally, we used IMDB plot keywords,{sup:35} which are user-defined free text descriptions of movies. We chose the 100 keywords which were most commonly assigned to movies in {a mathematical formula}Emovie to define an additional 100 binary classification problems. Note that these genres, ratings and keywords were not considered in the BoW representation of the movies, to allow for a fair evaluation. In practice, however, it would make sense to add the genre labels and keywords to the BoW representation with a high weight, since they tend to be very descriptive.
       </paragraph>
       <paragraph>
        The results are summarized in Table 16. We have not considered the betweenness and analogical classifiers here, as they do not scale to the 15000 movies in {a mathematical formula}Emovie, due to their quadratic time complexity. Again we find that the results are not very sensitive to the chosen number of dimensions. In contrast to the results for place types, here the SVM classifiers achieve the best performance, followed by the FOIL based methods. The performance of 1-NN and the C4.5 classifiers is not competitive, despite 1-NN being one of the best methods for place types. Nonetheless, it is interesting to see that {a mathematical formula}C4.5dir generally outperforms {a mathematical formula}C4.5MDS suggesting that the interpretable directions may be useful for rule based learners in general. Since the FOIL based methods rely on the most salient properties only, they are most useful for learning common categories such as genres. In Table 16, we indeed find that the difference between {a mathematical formula}SVMMDS and the FOIL based methods is most pronounced for the keywords, which tend to refer to very specific properties. Closer inspection of the results revealed that the relative performance of {a mathematical formula}FOIL1, compared to {a mathematical formula}SVMMDS, is best for keywords that refer to common movie themes (e.g. murder, police, hero) and worst for keywords that refer to more specific properties (e.g. new-york-city, beach, drunkenness).
       </paragraph>
      </section>
      <section label="6.1.3">
       <section-title>
        Results for wines
       </section-title>
       <paragraph>
        To obtain classification problems in the wine domain, we used the taxonomy from http://winefolly.com/review/different-types-of-wine/. In total, 122 of the 330 wines in {a mathematical formula}Ewine could be matched to wines from that taxonomy. To generate classification problems, we considered the following 14 categories: Fruity Red, Savory Red, Dry White, Red, White, Sparkling, Tannic, Round, Spicy/Juicy, Blueberry/BlackBerry, Black Pepper Gravel, Smoke Tobacco Leather, Light Citrus Lemon, Medium Perfume Floral. The remaining categories contained too few wines from {a mathematical formula}Ewine to be useful. Note that the selected categories are taken from different levels of the taxonomy (e.g. Tannic is a sub-category of Red).
       </paragraph>
       <paragraph>
        The results, summarized in Table 17, are again not very sensitive to the chosen number of dimensions, but results for 200 dimensions are clearly worse. In contrast, the results for 20 dimensions are close to optimal, whereas 20 dimensions did not lead to competitive results for the place type and movie domaines. Overall, we find that {a mathematical formula}AnalogC achieves the best results, followed by {a mathematical formula}Col/BtwA, and then 1-NN. In particular {a mathematical formula}AnalogC achieves a higher F1 score than {a mathematical formula}Col/BtwA while achieving a similar accuracy (especially in 20D and 50D). On the other hand, {a mathematical formula}Col/BtwA achieves a higher accuracy than 1-NN while achieving a similar F1 score (especially in 100D and 200D). The FOIL based classifiers, C4.5 and SVM are not competitive. Interestingly, however, we again find that {a mathematical formula}C4.5dir outperforms {a mathematical formula}C4.5MDS, providing further support for the usefulness of the selected salient dimensions.
       </paragraph>
      </section>
     </section>
     <section label="6.2">
      <section-title>
       Crowdsourcing evaluation of semantic relations
      </section-title>
      <paragraph>
       Where Section 6.1 used classification problems to objectively assess the usefulness of the semantic relations, here we look at some subjective aspects, which we have evaluated using CrowdFlower,{sup:36} a crowdsourcing platform which has integrated mechanisms for quality control. Our aim was to better understand to what extent the interpretable directions can be used to describe the difference between two entities (Section 6.2.1) and to what extent conceptual betweenness can be used to provide useful explanations of classification decisions (Section 6.2.2). Finally, in Section 6.2.3 we look at how some of the methods compare against human performance, given that some parts of the taxonomies we used are subjective (e.g. ice cream shops are classified as restaurants on TripAdvisor but as shops in OpenCYC).
      </paragraph>
      <section label="6.2.1">
       <section-title>
        Identifying terms to compare two movies
       </section-title>
       <paragraph>
        In a first experiment, we compared our descriptions of how movies are semantically related with the supervised method from [13]. The latter method, called the Tag Genome, is based on keywords that users have explicitly assigned to movies, together with a supervised learning process aimed at reducing the sparsity of these assignments and to learn a degree of relevance for terms (rather than just having binary assignments). For movie m and tag t, we will write {a mathematical formula}TG(m,t) for the degree of relevance term t has for movie m according to the Tag Genome. We considered the following four methods to generate descriptions of the form “{a mathematical formula}movie1 is more related to t than {a mathematical formula}movie2”: MDS-allselects the term t maximizing {a mathematical formula}diffA(movie2,movie1;t), as explained in Section 4.2.2 (using the 100-dimensional space).MDS-salientselects the most similar direction among the 200 salient directions in {a mathematical formula}Smovie that were identified in Section 4.2.3 (using the 100-dimensional space). Once the direction is identified, we choose the term t from the corresponding cluster which has the highest Kappa score among all terms that occur at least once in a review of movie 1.Tag Genomeselects the term t that maximizes {a mathematical formula}TG(movie1,t)−TG(movie2,t).PPMIselects the term t maximizing {a mathematical formula}diffB(movie2,movie1;t). In the experiment, users were asked which of the four resulting statements they thought best described how {a mathematical formula}movie1 differs from {a mathematical formula}movie2. They were also given the option to respond with “I don't know” or “None of the statements applies”. To limit the number of unfamiliar movie pairs, we only considered the top 50 most popular movies (in terms of the number of users who have rated the movie on IMDB), resulting in {a mathematical formula}50⋅49=2450 movie pairs. Each of these pairs was assessed by at least 5 annotators. The total number of (trusted{sup:37}) annotations was 16170. In 3025 cases, the annotator chose the “I don't know” option. We obtained 2339 annotations in favor of MDS-all, 2393 annotations in favor of MDS-salient, 6563 annotations in favor of Tag Genome, and 789 annotations in favor of PPMI. In the remaining 1060 cases, the annotator indicated that “None of the statements applies”.
       </paragraph>
       <paragraph>
        MDS-all and MDS-salient clearly outperform PPMI, although both methods are outperformed by the Tag Genome. This is unsurprising, given that the Tag Genome consists of terms that have been manually assigned to movies by users (with weights that have been learned in a supervised way, based on feedback from users). To illustrate the difference between the four methods, Table 18, Table 19, Table 20, Table 21 respectively show pairs of movies for which all annotators preferred MDS-all, for which all annotators preferred MDS-salient, for which all annotators preferred Tag Genome, and for which all annotators preferred PPMI. As can be seen from these tables, the tags provided by the Tag Genome are always relevant, although they do not always reflect the most salient properties. For example, the term ‘70 mm’ to describe Die Hard (Table 21, third row) correctly describes one aspect in which Die Hard differs from Django Unchained (since Die Hard has been released on 70 mm film), but few people will consider this the most important property in which the two movies differ. MDS-all and MDS-salient often succeed in finding the most important property, but sometimes fail to identify a good label to describe that property. For example, the salient direction containing ‘second viewing’ (Table 18, fourth row) also contains terms such as ‘intriguing’, ‘enigmatic’ and ‘a puzzle’, presumably because many reviews suggest that some aspects of the plot may only become clear after a second viewing. This direction thus captures one of the main properties of the movie ‘Inception’, although the label ‘second viewing’ is not adequate. Similarly, the salient direction corresponding to ‘couple’ (Table 18, third row) also contains terms such as ‘marriage’ and ‘affair’, which captures one of the main themes of Titanic. As expected, MDS-all typically chooses more specific terms (e.g. dinosaurs), while MDS-salient tries to identify more abstract properties (e.g. tragedy). In the few cases where PPMI was preferred by all annotators, the term that was identified tends to correspond to the name of a character, actor or director.
       </paragraph>
       <paragraph>
        For the majority of movie pairs (1544/2450), at least one assessor preferred the term from the Tag Genome and at least one other assessor preferred MDS-all or MDS-salient, which suggests that these three methods all tend to identify reasonable properties. However, MDS-all and MDS-salient do not always find an intuitive label to associate with that property: there are 578 movie pairs for which all assessors preferred the Tag Genome term. This problem could be alleviated by incorporating better heuristics (e.g. choosing the term from the selected salient direction that has the highest PPMI value for the target movie) or by using automated cluster labelling based on external sources such as Wikipedia [66], but is unlikely to be avoided entirely due to the unsupervised nature of the process. Hybrid methods may be able to combine the best of both worlds, e.g. based on learning directions in the conceptual space {a mathematical formula}S for keywords that have been associated with films on IMDB or from the terms in the Tag Genome.
       </paragraph>
      </section>
      <section label="6.2.2">
       <section-title>
        Assessing the usefulness of explanations
       </section-title>
       <paragraph>
        In a second crowdsourcing experiment, we have looked at whether explanations help users to assess the reliability of a classification. Again using CrowdFlower, we presented users with arguments of the following form: Knowing: X is somewhat between a paintball field and a ski areaWe conclude: X belongs to the category of Parks &amp; Outdoor places where categories were taken from the Foursquare taxonomy. To generate such explanations, we have used the betweenness based classifier and k-NN. In the latter case, explanations were of the form (for {a mathematical formula}k=2): Knowing: X is similar to a paintball field and a ski areaWe conclude: X belongs to the category of Parks &amp; Outdoor places Note that in each case, users were not shown which place type was being classified (i.e. we always write ‘X’). They were only shown the explanation and the classification decision. Users were given four options: (i) based on the given knowledge, I am confident that the conclusion is correct; (ii) based on the given knowledge, I think the conclusion is more or less plausible; (iii) the given knowledge does not support the conclusion; (iv) I don't know.
       </paragraph>
       <paragraph>
        In total, for each of the considered classifiers, users were shown 391 statements (i.e. one statement for each of the place types in the Foursquare taxonomy). The statements were obtained by using the same configuration of the classifiers as in Section 6.1, using 5-fold cross validation to select the training data. Each statement, for each classifier, was annotated by at least 5 users. We can then rank the classification decisions for a given classifier according to the percentage of human annotators who indicated that they were confident that the conclusion is correct. More precisely, we rank each classification decision according to the value{sup:38}{a mathematical formula}pospos+borderline+neg, where pos, borderline and neg are the number of annotators who chose the first, second, and third option respectively. The results are summarised in Fig. 4, showing the precision-recall trade-off for different cut-offs of the value {a mathematical formula}pospos+borderline+neg. Since all three graphs are decreasing, we find that 1-NN, 2-NN and the betweenness classifier (based on the {a mathematical formula}BtwA measure) indeed generate explanations that help users spot incorrect classifications.
       </paragraph>
       <paragraph>
        Interestingly, 2-NN yields more convincing explanations than 1-NN, despite generating the same classification decisions, i.e. presenting the two most similar place types helps users to better identify misclassifications and borderline cases. Despite having a better classification accuracy overall, the betweenness classifier apparently produces explanations which are slightly less helpful than those provided by 2-NN. This seems related to the fact that the betweenness classifier sometimes makes decisions based on place types which are not similar.
       </paragraph>
      </section>
      <section label="6.2.3">
       <section-title>
        Comparison with human performance
       </section-title>
       <paragraph>
        Place type taxonomies are to some extent arbitrary. For example, in the Foursquare taxonomy, ‘butcher’, ‘candy store’, ‘cheese shop’, ‘farmers market’, ‘fish market’, ‘food court’, ‘gourmet store’ and ‘wine shop’ are classified under shops &amp; services while ‘bagel shop’, ‘bakery’, ‘cupcake shop’,‘dessert shop’, ‘donut shop’, ‘ice cream shop’ and ‘juice bar’ are classified under the disjoint category food. Partly this is because the foursquare categories are disjoint (i.e. the taxonomy is a tree). However, in the OpenCYC taxonomy (where categories are not required to be disjoint), we still find arbitrary classifications. For example, ‘control tower’, ‘grain elevator’, ‘radar station’ and ‘stable’ are classified as buildings, but ‘aqueduct’, ‘radio station’ and ‘vacant house’ are not; ‘dockyard’, ‘bus stop’ and ‘ski area’ are classified as outdoor locations, but ‘snowfield’ and ‘beach’ are not. This complicates the interpretation of the experiments in Section 6.1. To better understand how well the classifiers are performing, in a final crowdsourcing experiment we have shown annotators statements of the following form: church is a kind of building Annotators were given the following four options: (i) the statement is correct; (ii) he statement is partially correct; (iii) the statement is incorrect; (iv) I don't know. Assessments where the annotator chose option 4 have been discarded and are not used in the following analysis. Let us write {a mathematical formula}pos(c,t), {a mathematical formula}borderline(c,t) and {a mathematical formula}neg(c,t) for the number of annotators who have respectively chosen option 1, 2 and 3 for an OpenCYC category c and place type t. We have collected judgements for the OpenCYC categories outdoor location, building, transport facility, tower, home, business location, tourist attraction, large building, landmark and public place. The place types we have considered are those that belong to the aforementioned categories in OpenCYC, as well as all place types from the Foursquare taxonomy (1230 place types in total). The pairs {a mathematical formula}(c,t) we considered are (i) all pairs where t is a place type from the Foursquare taxonomy, (ii) all pairs where t is a place type from the OpenCYC taxonomy and either t belongs to category c or one of the considered classifiers incorrectly assigned t to category c. This led to a total of 4450 pairs, each of which was assessed by at least 5 annotators.
       </paragraph>
       <paragraph>
        Table 22 compares the betweenness classifier and 1-NN with human performance on the task of deciding which (category, place type) pairs are correct, where only place types from the OpenCYC taxonomy are considered since there is no ground truth for the place types from Foursquare. The results for {a mathematical formula}BtwA and 1-NN are based on a 5-fold cross validation. To measure human performance, we have considered three alternatives: Human strictshows the average performance if for each pair {a mathematical formula}(c,t), we select the response of one of the annotators, and accept the pair as being correct if that annotator has chosen option 1.Human lenientshows the average performance if we instead accept the pair {a mathematical formula}(c,t) as being correct if that annotator has chosen option 1 or 2.Human majorityshows the performance if we accept all pairs {a mathematical formula}(c,t) for which {a mathematical formula}pos(c,t)&gt;neg(c,t). The results show that the betweenness classifier is competitive with human strict and human lenient in terms of accuracy, and even outperforms human strict and human lenient in terms of precision. However, human performance is much stronger in terms of recall and (as a result) F1. Interestingly, we observe a wisdom-of-the-crowds effect: the consensus approach used by Human majority outperforms the expected performance of a single annotator.
       </paragraph>
       <paragraph>
        One of the possible applications of the betweenness classifier is to merge different taxonomies. In particular, we have considered the task of assigning place types from Foursquare to the 10 categories from the CYC taxonomy that were used before. Given that the betweenness classifier rivals human performance in terms of precision, we could expect that the places it assigns to these categories would be mostly meaningful. To test this hypothesis, we have used the betweenness classifier and 1-NN to assign places from the Foursquare taxonomy to the 10 considered categories from OpenCYC. For this experiment, the entire OpenCYC taxonomy was used as training data. Given the lack of ground truth, Table 23 compares the results to the human assessments. In particular, the table reports how many place types from Foursquare have been assigned to the CYC categories and what was the precision of these assignments, considering three measures of precision:
       </paragraph>
       <list>
        <list-item>
         each of the human assessors considered the assignment correct.
        </list-item>
        <list-item>
         at least one of the human assessors considered the assignment correct.
        </list-item>
        <list-item>
         the majority of the human assessors considered the assignment correct, i.e. {a mathematical formula}pos(c,t)&gt;neg(c,t).
        </list-item>
       </list>
       <paragraph>
        We find that {a mathematical formula}BtwA outperforms 1-NN for all precision measures, although 1-NN assigns slightly more place types, i.e. {a mathematical formula}BtwA is slightly more cautious in assigning place types to the CYC categories.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="7">
     <section-title>
      Discussion
     </section-title>
     <paragraph>
      The results for place types and, to a lesser extent, wines clearly demonstrate the potential of betweenness and analogical classifiers to avoid some systematic errors that are made by k-NN classifiers, and to come up with reasonable decisions when there are no similar entities that can be exploited. However, when sufficient training data is available, as in the movies domain, SVMs substantially outperform the betweenness and analogical classifiers (as well as k-NN), at least when the C parameter is carefully optimized and class imbalance is addressed (SVMs were uncompetitive when default configurations were used). In such domains, the FOIL based classifiers also perform quite well. The poor performance of FOIL in the place type and movie domains suggests that this method requires a sufficiently high number of training items. The relatively small number of place types and wine varieties makes it harder to learn reliable interpretable directions, and to choose the most salient ones. This is most obvious in the wine domain, where directions in spaces of up to 200 dimensions had to be learned from 330 instances.
     </paragraph>
     <paragraph>
      Despite being outperformed by SVM classifiers, the FOIL based classifiers have a number of significant advantages. Firstly, we can readily derive intuitive explanations from the decisions made by the FOIL classifier, which can help users assess whether they can trust a classification decision. A second advantage of the FOIL based methods is that we can combine them with other sources of structured information in a natural way (e.g. information about the director and actors associated with a film, extracted from natural language or from linked data). Training the FOIL based classifiers is also computationally more efficient than training the SVM classifiers, given that the latter require a grid search for optimizing the C parameter. Finally, the fact that our FOIL classifiers only rely on symbolic, relational information (i.e. rankings of entities) means that we may be able to make reasonable classification decisions, even if no conceptual space representation for the test item can be obtained. Suppose, for example, that we have some information about an upcoming movie, e.g. that it will be “even scarier than the Shining”. From this information alone, the FOIL based classifiers could predict that the movie will likely belong to the horror genre. In contrast, an SVM classifier would not be able to make any predictions before we have a conceptual space representation (i.e. after the movie has been released and enough reviews have become available). This possibility of using qualitative information derived in other ways (e.g. relation extraction from natural language) could prove particularly important for estimating the properties of rare entities, for which we may have insufficient textual information to induce a reliable conceptual space representation. This also relates to a proposal in [67], where a classifier is learned from natural language instructions and a small number of training examples, and to the idea of zero-shot learning, where no training examples are used at all (see e.g. [14]). For example, Wikipedia defines legal thriller as{sup:39} “A suspense film in which the major characters are lawyers and their employees”. Given that we know how to interpret properties such as suspense and keywords such as lawyer as directions in the conceptual space of movies, reasonable classification rules for legal thriller could be obtained from its natural language definition and the classification rules we already have for thriller.
     </paragraph>
     <paragraph>
      In future work, we will study how the semantic relations could be used to implement more robust forms of logical inference, using the logic from [25] as a starting point. In this way, we can obtain a purely data-driven way to deal with gaps in a knowledge base, which can be effective even when the number of formulas is relatively small, unlike methods which are based on deriving statistical regularities from the knowledge base itself [3], [4], [68]. On the other hand, such an approach is only suitable when the predicates from the knowledge base can be identified with natural language terms.
     </paragraph>
    </section>
   </content>
  </root>
 </body>
</html>