<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Robust planning with incomplete domain models.
   </title>
   <abstract>
    Most current planners assume complete domain models and focus on generating correct plans. Unfortunately, domain modeling is a laborious and error-prone task, thus real world agents have to plan with incomplete domain models. While domain experts cannot guarantee completeness, often they are able to circumscribe the incompleteness of the model by providing annotations as to which parts of the domain model may be incomplete. In this paper, we study planning problems with incomplete domain models where the annotations specify possible preconditions and effects of actions. We show that the problem of assessing the quality of a plan, or its plan robustness, is #P-complete, establishing its equivalence with the weighted model counting problems. We present two approaches to synthesizing robust plans. While the method based on the compilation to conformant probabilistic planning is much intuitive, its performance appears to be limited to only small problem instances. Our second approach based on stochastic heuristic search works well for much larger problems. It aims to use the robustness measure directly for estimating heuristic distance, which is then used to guide the search. Our planning system, PISA, outperforms a state-of-the-art planner handling incomplete domain models in most of the tested domains, both in terms of plan quality and planning time. Finally, we also present an extension of PISA called CPISA that is able to exploit the available of past successful plan traces to both improve the robustness of the synthesized plans and reduce the domain modeling burden.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      In the past several years, significant strides have been made in scaling up plan synthesis techniques. We now have technology to routinely generate plans with hundreds of actions. All this work, however, makes a crucial assumption—that the action models of an agent are completely known in advance. While there are domains where knowledge-engineering such detailed models is necessary and feasible (e.g., mission planning domains in NASA and factory-floor planning), it is increasingly recognized (cf. Kambhampati [18]) that there are also many scenarios where insistence on correct and complete models renders the current planning technology unusable. The incompleteness in such cases arises because domain writers do not have the full knowledge of the domain physics, or when the planner is embedded into an integrated architecture where the domain model is being learned incrementally.
     </paragraph>
     <paragraph>
      One tempting idea is to wait until the models become complete, either by manual revision or by machine learning. Alas, the users often do not have the luxury of delaying their decision making. For example, while existing domain modeling tools [27], [19] can make significant efforts to correct any detectable omissions in the specified models by alerting the domain writers, elicitation of complete models is impossible when the writers themselves do not know the full dynamics. Similarly, although there exist efforts [1], [34], [37], [4] that attempt to either learn models from scratch or revise existing ones, their operation is contingent on the availability of successful plan traces or access to execution experience. There is thus a critical need for planning technology that can get by with partially specified domain models, and yet generate plans that are “robust” in the sense that they are likely to execute successfully in the real world.
     </paragraph>
     <paragraph>
      Although the domain modelers cannot provide complete models, often they are able to provide “annotations” on the partial model circumscribing the places where it is incomplete. In automated planning, Garland and Lesh [11] was the first, to the best of our knowledge, to allow annotations on the specification of incomplete actions; these annotations specify parts of the domains not affecting or being affected by the corresponding actions. The notion of plan quality in their work is defined in terms of four different types of “risks”, which however has tenuous heuristic connections with the likelihood of successful execution of plans.
     </paragraph>
     <paragraph>
      In this research, annotations on the incompleteness of the domains specify possible preconditions and effects of actions. (It should be straightforward to extend the existing model acquisition tools to support acquisition of incompleteness annotations.) These annotations facilitate, though only conceptually, the enumeration of all “candidate” complete models, and thus the counting of models under which a plan succeeds. The corresponding robustness measure for plans, therefore, captures exactly the probability of success for plans given such an incompleteness language. Given an incompletely specified domain model, an action of a plan might fail to apply during the execution of the plan. Depending on the planning scenario, a user might want to terminate the current plan (and triggering replanning process) or continue its execution after an action failure. This work considers two different semantics for plan execution. In the Generous Execution semantics, the failure to execute of an action does not automatically cause plan failure. Thus additional actions could be inserted into an existing plan for robustifying against potential action failures. The STRIPS Execution semantics, on the other hand, follows STRIPS-style planning [9] preventing a plan from continuing its execution when one of its actions fails to apply. The problem of assessing robustness of a given plan under the two execution semantics is studied using model counting techniques, and its complexity is also established.
     </paragraph>
     <paragraph>
      Two approaches are proposed for synthesizing robust plans. The first one translates this problem into a conformant probabilistic planning problem [8]. While perhaps the most intuitive approach, this compilation method appears to work only for small planning instances given the state-of-the-art conformant probabilistic planner, Probabilistic-FF [8]. We present the details of the compilation under the Generous Execution semantics and briefly discuss the approach for the STRIPS Execution semantics.
     </paragraph>
     <paragraph>
      The second approach is a heuristic search method that works well in much larger problem instances. It aims to use the robustness measure directly for estimating heuristic distance, which is then used to guide the search. In the current work, we fully investigate the heuristic approach under the STRIPS Execution semantics. The novel idea is to overcome the complexity of computing the exact robustness measure by exploiting the structures of the correctness constraints for plans. This results in the lower and upper bounds for the robustness measure that can be incorporated in the extraction of robust relaxed plans and guiding the search for robust plans. The experiments show that the resulting planner, PISA (Planning with Incomplete STRIPS Actions), outperforms DeFault, a planner that can handle incomplete STRIPS models [31], in most of the tested domain both in terms of plan robustness and in planning time.
     </paragraph>
     <paragraph>
      We also present a novel extension of PISA called {a mathematical formula}CPISA that is able to exploit past successful plan traces to both improve the robustness of the synthesized plans and reduce the domain modeling burden. As we shall see, {a mathematical formula}CPISA can be viewed as a bayesian learning extension to PISA that starts with a distribution over domain models (that are consistent with the annotated STRIPS model), and learning from past successful plan cases to compute a new posterior distribution over the domain models, which it then uses to compute robust plans for new problems. We will present empirical results demonstrating the effectiveness of {a mathematical formula}CPISA. We will also compare {a mathematical formula}CPISA to RIM [36], an existing system that starts with a single (incorrect) domain model and modifies it in light of available successful plan traces.
     </paragraph>
     <paragraph>
      This journal article is a unification of two prior conference publications, [21] and [20], with several significant extensions. The most important extension is the introduction of {a mathematical formula}CPISA, and its evaluation comparing to RIM. In addition to this, an approach to assessing plan robustness with the Generous Execution semantics is presented, and an approximate, fast to compute, transition function is introduced for the STRIPS Execution semantics and used during the forward heuristic search.
     </paragraph>
     <paragraph>
      The rest of the paper is organized as follows. We start with a discussion of related work in Section 2. Section 3 formulates the planning problems with incomplete domain models. Section 4 formalizes the robustness measure for plans under incomplete domain models. Section 5 presents a spectrum of problems given an incomplete domain model. Section 6 shows a method to assess the plan robustness measure for the two execution semantics using weighted model counting, and then establishes the complexity of the plan robustness assessment problem. Section 7 presents a compilation approach to synthesizing robust plans under the Generous Execution semantics. Section 8 presents a heuristic approach to synthesizing robust plans given incomplete STRIPS domain models, which includes a method to approximate plan robustness and a procedure for extracting robust relaxed plans. Section 9 shows how the approach can exploit successful plan traces to improve the robustness of the plans it generates. The contributions of this work are summarized in Section 10.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      As mentioned earlier, Garland and Lesh [11] share the same objective with us on generating robust plans under incomplete domain models. However, their notion of robustness, which is defined in terms of four different types of risks, only has tenuous heuristic connections with the likelihood of successful execution of plans. Robertson and Bryce [24] focus on the plan generation in Garland and Lesh model, but their approach still relies on the same unsatisfactory formulation of robustness. Weber and Bryce [31] use the same formulation with Nguyen et al. [22] and propose a heuristic approach to search for plans minimizing their risks, which is essentially one minus plan robustness. Their planner, DeFault, employs a systematic search guided by an FF-like heuristic, breaking ties on a so called “prime implicant” heuristic. It however does not directly estimate the risk or robustness measures that are supposed to be optimized, but rather uses them indirectly to break ties over the standard FF heuristic. Using this tie breaking heuristic as the main guidance for the search, as observed by Weber and Bryce, does not result in an informative heuristic for generating low risk plans. Zhuo et al. [35], [36] consider planning under incomplete domain models, where instead of possible precondition/effect annotations, the incomplete model is augmented with a set of successful plan traces. Unlike PISA these approaches cannot provide a priori guarantees on the robustness of the plan they generate. In Section 9, we discuss an extension of PISA (called {a mathematical formula}CPISA), that is able to leverage the availability of successful plan traces, while still keeping robustness guarantees.
     </paragraph>
     <paragraph>
      The work by Fox et al. [10] also explores robustness of plans, but their focus is on temporal plans under unforeseen execution-time variations rather than on incompletely specified domain models. Although there has been some work on reducing the “faults” in plan execution, e.g., the work on k-fault plans for non-deterministic planning [17], it is based in the context of stochastic/non-deterministic actions rather than incompletely specified ones. The semantics of the possible preconditions/effects in the incomplete domain models of this work differs fundamentally from non-deterministic and stochastic effects. Executing different instances of the same pick-up action in the Gripper example above would either all fail or all succeed, since there is no uncertainty but the information is unknown at the time the model is built. In contrast, if the pick-up action's effects are stochastic, then trying the same picking action multiple times increases the chances of success.
     </paragraph>
     <paragraph>
      Our approaches to assessing plan robustness and synthesizing robust plans share the same spirit with the Probabilistic-FF planner [8] in utilizing the correctness constraints of a plan or a plan prefix, but are different in how they reflect the incompleteness semantics in deterministic domains. The constraints in our methods involve a unique set of boolean variables representing the realization of possible preconditions and effects of deterministic albeit incomplete actions, which can then be re-used across multiple steps of an action sequence. On the other hand, unknown effects in non-deterministic or stochastic domains are naturally much more costly to model; among other sets of boolean variables, the Probabilistic-FF planner introduces different variables for a same effect in different time steps. The encodings we construct, especially under the SE semantics where action failure implies plan failure, are therefore significantly more compact. Our heuristic search, described in Section 8, exploits certain structures of these compact encoding to approximate plan robustness, resulting in more efficient approach for plan synthesis under the SE semantics.
     </paragraph>
     <paragraph>
      The possible precondition/effects to formalize domain model incompleteness has interesting applications in adapting planning technology to penetration testing in cybersecurity. In particular, as pointed out in Hoffmann [14], from a planning point of view, a realistic model involves assuming deterministic exploits whose exact preconditions and effects are none-the-less not completely known. Such a situation can be naturally modeled in terms of possible preconditions and effects. Interestingly, Hoffmann [14] proposes handling this situation in terms of stochastic actions. As discussed in the context of k-fault planning above, this will lead to the problematic semantics allowing for the action outcomes to change when it is executed repeatedly. Not surprisingly, the approach in Hoffmann [14] involves adding constraints to prohibit multiple executions of any single action. The robust planning framework based on possible precondition/effect annotations are, in our view, a more natural formulation.
     </paragraph>
     <paragraph>
      In the context of decision-theoretic planning, a domain model is defined with a transition function mapping each pair of current state and action to a probability distribution of successor states. Much work has also been done for “uncertainty incompleteness”, in particular with imprecise parameters representing incomplete transition probabilities. In Satia and Lave Jr [26], incomplete transition probabilities are modeled for each vector of probabilities representing a transition function from each pair of current state and action to a next state. They can be modeled either by a set (described with lower and upper bounds on component probabilities of the vector), or a prior distribution of probability values. For each of which, different optimal criteria were considered for quality of policies. Similar set-based representation and more efficient algorithm for computing max-min policy can also be found in White III and Eldeib [33]. With similar incompleteness representation, Givan et al. [12] considered bounded parameter Markov Decision Process (MDP) and propose a new value function representing values of states using closed real value intervals. The authors also devise algorithms for evaluating policies and computing optimal policies in this setting. Delgado et al. [6] introduce factored MDPs with similar incompleteness representation and propose efficient dynamic programming exploiting their structures.
     </paragraph>
     <paragraph>
      While the focus of this paper is on planning with incomplete domain models, a closely related issue is learning to improve the completeness of the domain models. Reinforcement learning, and in particular the variant called bayesian reinforcement learning [5], [28] aims to learn a posterior over the domain models, and plan (determine behavior) using this distribution over the models. This second phase bears several relations to planning with incomplete STRIPS models that we address in this paper (since, as we shall see, an incomplete annotated STRIPS model is a distribution over complete domain models). Although we do not address integration of learning and acting that traditional reinforcement learning does, we do address some aspects of learning. In particular, {a mathematical formula}CPISA, described in Section 9 can be viewed as starting with a distribution over domain models, and learning from past successful plan cases to compute a new posterior distribution over the domain models, which it then uses to compute robust plans for new problems. In contrast, RIM [36] is a competing approach that starts with a single domain model, and given successful plan cases, refines its initial model into a single new model. The comparison between RIM and {a mathematical formula}CPISA, presented in Section 9.4, bears some relation to the advantages of normal vs. bayesian reinforcement learning.
     </paragraph>
     <paragraph>
      This work can also be categorized as one particular instance of the general model-lite planning problem, as defined in Kambhampati [18], in which the author points out a large class of applications where handling incomplete models is unavoidable due to the difficulty in getting a complete model.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Problem formulation
     </section-title>
     <paragraph>
      We define an incomplete action model {a mathematical formula}D˜ as {a mathematical formula}D˜=〈R,O〉, where {a mathematical formula}R is a set of predicates with typed variables, {a mathematical formula}O is a set of operators, each might be incompletely specified. In particular, in addition to the sets of known preconditions {a mathematical formula}Pre(o)⊆R, add effects {a mathematical formula}Add(o)⊆R and delete effects {a mathematical formula}Del(o)⊆R, each operator {a mathematical formula}o∈O also contains:
     </paragraph>
     <list>
      <list-item label="•">
       possible precondition set {a mathematical formula}Pre˜(o)⊆R that operator o might need as its preconditions;
      </list-item>
      <list-item label="•">
       possible add (delete) effect set {a mathematical formula}Add˜(o)⊆R ({a mathematical formula}Del˜(o)⊆R) that o might add (delete, respectively) during execution.
      </list-item>
     </list>
     <paragraph>
      In addition, each possible precondition, add and delete effect {a mathematical formula}r∈R of an operator o is (optionally) associated with a “weight”, or subjective probability, {a mathematical formula}wopre(r), {a mathematical formula}woadd(r) and {a mathematical formula}wodel(r) ({a mathematical formula}0&lt;wopre(r), {a mathematical formula}woadd(r), {a mathematical formula}wodel(r)&lt;1) representing the domain modeler's assessment of the likelihood that r will actually be realized as a precondition, add and delete effect of o, respectively.{sup:1} We assume that the “annotations” on possible preconditions and effects are uncorrelated, thus can be realized independently (both within each operator and across different ones).{sup:2}
     </paragraph>
     <paragraph>
      Given an incomplete domain model {a mathematical formula}D˜, we define its completion set{a mathematical formula}《D˜》 as the set of complete domain models whose operators have all the known and “realized” preconditions and effects. Since any subset of {a mathematical formula}Pre˜(o), {a mathematical formula}Add˜(o) and {a mathematical formula}Del˜(o) can be realized as preconditions and effects of o, there are {a mathematical formula}2K possible complete domain models in {a mathematical formula}《D˜》, where {a mathematical formula}K=∑o∈O(|Pre˜(o)|+|Add˜(o)|+|Del˜(o)|). There is exactly one (unknown) complete model, denoted by {a mathematical formula}D⁎, that is the ground truth. For each complete model {a mathematical formula}D, we denote the complete sets of preconditions and effects for each operator o as {a mathematical formula}PreD(o), {a mathematical formula}AddD(o) and {a mathematical formula}DelD(o).
     </paragraph>
     <paragraph>
      A planning problem {a mathematical formula}P˜ with respect to an incomplete domain model {a mathematical formula}D˜ and a set of typed objects O is defined as {a mathematical formula}P˜=〈F,A,I,G〉 where F is the set of propositions instantiated from predicates {a mathematical formula}R and objects O, A is the set of actions instantiated from {a mathematical formula}O and O, {a mathematical formula}I⊆F is the initial state, and {a mathematical formula}G⊆F is the set of goal propositions. In a specific complete model {a mathematical formula}D, actions instantiated from one operator have the same realized preconditions and effects. The complete sets of preconditions and effects for action {a mathematical formula}a∈A in complete model {a mathematical formula}D are denoted by {a mathematical formula}PreD(a), {a mathematical formula}AddD(a) and {a mathematical formula}DelD(a).
     </paragraph>
     <paragraph>
      A state is defined as either a set of propositions {a mathematical formula}s⊆F that are true (T), and all the remaining are false (F), or a special state {a mathematical formula}s⊥={⊥} where {a mathematical formula}⊥∉F is a proposition used exclusively to define this “dead end” state. Since {a mathematical formula}s⊥⊈F, {a mathematical formula}PreD(a)⊈s⊥, ({a mathematical formula}∀a∈A,D∈《D˜》), and {a mathematical formula}s⊥⊭G.
     </paragraph>
     <paragraph>
      The resulting state after executing a sequence of actions π in a state s under a complete model {a mathematical formula}D∈《D˜》 is denoted by {a mathematical formula}γD(π,s). The projection of π in s with respect to the incomplete model {a mathematical formula}D˜, {a mathematical formula}γ(π,s), is defined as the union of all projection of π from s with respect to each and every complete models in {a mathematical formula}《D˜》:{a mathematical formula}
     </paragraph>
     <paragraph>
      The transition function {a mathematical formula}γD(π,s) with respect to a complete model {a mathematical formula}D∈《D˜》 is defined recursively as follows:{a mathematical formula} In order to complete the definition of {a mathematical formula}γ(s,π), it is necessary to define {a mathematical formula}γD(〈a〉,s), the resulting state after applying action a in state s with respect to a complete model {a mathematical formula}D. Given that the domain model {a mathematical formula}D˜ used during planning is incomplete, it is quite expected that some action of a synthesized plan might fail to be applied during execution. We consider two execution semantics with different ways in defining resulting states after executing an “inapplicable” action. In the first one, called Generous execution (GE) semantics, executing an action with unsatisfied preconditions does not change the world state. The transition function following this semantics is denoted with {a mathematical formula}γGE, and the resulting state {a mathematical formula}γGED(〈a〉,s) is defined as follows:{a mathematical formula}
     </paragraph>
     <paragraph>
      The STRIPS execution (SE) semantics follows the definition in STRIPS-style planning [9], making the resulting state “undefined” if action a is not executable in state s—the plan is considered failed with respect to the complete model {a mathematical formula}D. The transition function {a mathematical formula}γSED for a single action sequence with respect to a complete model {a mathematical formula}D is defined for action {a mathematical formula}a∈A and state {a mathematical formula}s∈2F∪{s⊥} as follows:{a mathematical formula}
     </paragraph>
     <paragraph>
      The definition of {a mathematical formula}γ(π,s) in Eq. (1) is now complete with the definitions of {a mathematical formula}γD(〈a〉,s) for the two semantics, {a mathematical formula}γGED(〈a〉,s) and {a mathematical formula}γSED(〈a〉,s). In the following, we use {a mathematical formula}γ(π,s), {a mathematical formula}γD(π,s) in the discussion that applies for both semantics, and the notation with subscripts {a mathematical formula}γGE(π,s), {a mathematical formula}γGED(π,s), {a mathematical formula}γSE(π,s), {a mathematical formula}γSED(π,s) when the discussion limits to a particular execution semantics.
     </paragraph>
     <paragraph>
      Given the transition function {a mathematical formula}γ(π,s), a sequence of actions π is a valid plan for {a mathematical formula}P˜ if, after executing in the state I, it achieves the goals G with respect to at least one complete model: {a mathematical formula}∃D∈《D˜》γD(π,I)⊨G. Given that {a mathematical formula}《D˜》 can be exponentially large in terms of possible preconditions and effects, validity is too weak to guarantee on the quality of plans. The quality of a plan, therefore, will be measured with its robustness value, which will be presented in the next section.
     </paragraph>
     <paragraph label="Example">
      Fig. 1 shows the description of incomplete action pick-up(?b – ball,?r – room) as described above. In addition to the possible precondition (light ?b) on the weight of the ball ?b, we also assume that since the modeler is unsure if the gripper has been cleaned or not, she models it with a possible add effect (dirty ?b) indicating that the action might make the ball dirty. Those two possible preconditions and effects can be realized independently, resulting in four possible candidate complete domain models (assuming all other action schemes in the domain model are completely described).
     </paragraph>
    </section>
    <section label="4">
     <section-title>
      A robustness measure for plans
     </section-title>
     <paragraph>
      The robustness of a plan π for the problem {a mathematical formula}P˜ is defined as the probability mass of the completions of {a mathematical formula}D˜ under which π succeeds (in achieving the goals). More formally, let {a mathematical formula}Pr(D) be the modeler's estimate of the probability that a given model {a mathematical formula}D in {a mathematical formula}《D˜》 is the real model of the world ({a mathematical formula}0&lt;Pr(D)&lt;1,∀D∈《D˜》; {a mathematical formula}∑D∈《D˜》Pr(D)=1). The robustness of π is defined as follows:{a mathematical formula}
     </paragraph>
     <paragraph>
      Note that given the uncorrelated incompleteness assumption, the probability {a mathematical formula}Pr(D) for a model {a mathematical formula}D∈《D˜》 can be computed as the product of the weights {a mathematical formula}wopre(r), {a mathematical formula}woadd(r), and {a mathematical formula}wodel(r) for all {a mathematical formula}o∈O and its possible preconditions/effects r if r is realized as a precondition, add and delete effect of the operator in {a mathematical formula}D (or the product of their “complement” {a mathematical formula}1−wopre(r), {a mathematical formula}1−woadd(r), and {a mathematical formula}1−wodel(r) if r is not realized).
     </paragraph>
     <paragraph>
      It is easy to see that if {a mathematical formula}R(π)&gt;0, then π is a valid plan for {a mathematical formula}P˜. The definition of plan robustness introduced here applies for both two execution semantics. The robustness of a given plan under the SE semantics is no greater than it is under the GE semantics—any plan that succeeds under SE semantics does so under the GE semantics.
     </paragraph>
     <paragraph label="Example">
      Fig. 2 shows an example with an incomplete domain model {a mathematical formula}D˜=〈R≡F,O≡A〉 with {a mathematical formula}F={p1,p2,p3} and {a mathematical formula}A={a1,a2} and a solution plan {a mathematical formula}π=〈a1,a2〉 for the problem {a mathematical formula}P˜=〈F,A,I={p2},G={p3}〉. The incomplete model is: {a mathematical formula}Pre(a1)=∅, {a mathematical formula}Pre˜(a1)={p1}, {a mathematical formula}Add(a1)={p2,p3}, {a mathematical formula}Add˜(a1)=∅, {a mathematical formula}Del(a1)=∅, {a mathematical formula}Del˜(a1)=∅; {a mathematical formula}Pre(a2)={p2}, {a mathematical formula}Pre˜(a2)=∅, {a mathematical formula}Add(a2)=∅, {a mathematical formula}Add˜(a2)={p3}, {a mathematical formula}Del(a2)=∅, {a mathematical formula}Del˜(a2)={p1}. Given that the total number of possible preconditions and effects is 3, the total number of completions ({a mathematical formula}|《D˜》|) is {a mathematical formula}23=8, for each of which the plan π may succeed or fail to achieve G, as shown in the table. In the fifth candidate model, for instance, {a mathematical formula}p1 and {a mathematical formula}p3 are realized as precondition and add effect of {a mathematical formula}a1 and {a mathematical formula}a2, whereas {a mathematical formula}p1 is not a delete effect of action {a mathematical formula}a2. Even though {a mathematical formula}a1 could not execute (and thus {a mathematical formula}p3 remains false in the second state), the goal eventually is achieved according to the GE semantics by action {a mathematical formula}a2 with respects to this candidate model. Overall, with the GE semantics there are two of eight candidate models where π fails and six for which it succeeds. The robustness value of the plan is {a mathematical formula}R(π)=34 if {a mathematical formula}Pr(Di) is uniform. However, if the domain writer thinks that {a mathematical formula}p1 is very likely to be a precondition of {a mathematical formula}a1 and provides {a mathematical formula}wa1pre(p1)=0.9, the robustness of π decreases to {a mathematical formula}R(π)=2×(0.9×0.5×0.5)+4×(0.1×0.5×0.5)=0.55 (as intuitively, the last four models with which π succeeds are very unlikely to be the real one). Note that according to the SE semantics, the plan π would be considered failing to achieve G in the first four complete models since {a mathematical formula}a1 fails to apply (and thus {a mathematical formula}a2 is prevented from execution).
     </paragraph>
    </section>
    <section label="5">
     <section-title>
      A spectrum of robust planning problems
     </section-title>
     <paragraph>
      Given this set up, we can now talk about a spectrum of problems related to planning under incomplete domain models: Robustness Assessment (RA):Given a plan π for the problem {a mathematical formula}P˜, assess the robustness of π.Maximally Robust Plan Generation (RG{sup:⁎}):Given a problem {a mathematical formula}P˜, generate the maximally robust plan {a mathematical formula}π⁎.Generating Plan with Desired Level of Robustness ({a mathematical formula}RGρ):Given a problem {a mathematical formula}P˜ and a robustness threshold ρ ({a mathematical formula}0&lt;ρ≤1), generate a plan π with robustness greater than or equal to ρ.Cost-sensitive Robust Plan Generation ({a mathematical formula}RGc⁎):Given a problem {a mathematical formula}P˜ and a cost bound c, generate a plan π of maximal robustness subject to cost bound c (where the cost of a plan π is defined as the cumulative costs of the actions in π).Incremental Robustification ({a mathematical formula}RIc):Given a plan π for the problem {a mathematical formula}P˜, improve the robustness of π, subject to a cost budget c. The problem of assessing robustness of plans, RA, can be tackled by compiling it into a weighted model-counting problem. We will also show in Section 6 that RA with uniform distribution of candidate complete models is complete for #P complexity class [29], and thus the robustness assessment problem is at least as hard as NP-complete.
     </paragraph>
     <paragraph>
      For plan synthesis problems, we can talk about either generating a maximally robust plan, RG{sup:⁎}, or finding a plan with a robustness value above the given threshold, {a mathematical formula}RGρ. A related issue is that of the interaction between plan cost and robustness. Increasing robustness might involve using additional or costlier actions to support the desired goals, and thus comes at the expense of increased plan cost. We can also talk about cost-constrained robust plan generation, {a mathematical formula}RGc⁎. Finally, in practice, we are often interested in increasing the robustness of a given plan (either during iterative search, or during mixed-initiative planning). We thus also have the incremental variant {a mathematical formula}RIc. In the next sections, we will focus on the problems of assessing plan robustness and synthesizing robust plans, ignoring plan cost.
     </paragraph>
    </section>
    <section label="6">
     <section-title>
      Assessing plan robustness
     </section-title>
     <paragraph>
      Given an incomplete domain model {a mathematical formula}D˜, problem {a mathematical formula}P˜ and plan {a mathematical formula}π=〈a1,...,an〉, a naive approach to compute the robustness of π is to enumerate all domain models {a mathematical formula}D∈《D˜》 and check for the success of π with respect to {a mathematical formula}D. This is prohibitively expensive when the number of possible preconditions and effects is large. In this section, we show that the problem of assessing plan robustness can be reduced to the weighted model counting problem (cf. Sang et al. [25]) in which a set of logical constraints {a mathematical formula}Σπ is constructed such that there is a one-to-one mapping between each of its models and a candidate domain model under which the plan succeeds. In the rest of this section, we assume {a mathematical formula}a0≡aI and {a mathematical formula}an+1≡aG for any sequence π of length n, where {a mathematical formula}aI and {a mathematical formula}aG are two dummy complete actions representing the initial and goal state: {a mathematical formula}Pre(aI)=∅, {a mathematical formula}Add(aI)=I, {a mathematical formula}Pre(aG)=G, {a mathematical formula}Add(aG)={⊤} , where {a mathematical formula}⊤∉F denotes a dummy proposition representing goal achievement (those precondition and effect sets not specified are empty). We also denote {a mathematical formula}〈s0≡I,s1,...,sn,sn+1≡{⊤}〉 as the sequence of states generated from the execution of π.
     </paragraph>
     <section label="6.1">
      <section-title>
       GE semantics
      </section-title>
      <paragraph>
       Boolean variables: First, we create variables representing whether a possible precondition or effect of an operator {a mathematical formula}o∈O is realized: {a mathematical formula}ropre, {a mathematical formula}roadd and {a mathematical formula}rodel with the associated weights {a mathematical formula}wopre(r), {a mathematical formula}woadd(r) and {a mathematical formula}wodel(r) for each predicate r respectively in {a mathematical formula}Pre˜(o), {a mathematical formula}Add˜(o) and {a mathematical formula}Del˜(o). Abusing notation, we often write {a mathematical formula}papre and {a mathematical formula}wapre(p) for action {a mathematical formula}a∈A, {a mathematical formula}p∈Pre˜(a), and similarly for {a mathematical formula}p∈Add˜(a) or {a mathematical formula}Del˜(a), to refer to the boolean variables and weights defined for the unique predicate and operator from which they are instantiated. We denote {a mathematical formula}Z˜ as the set of those boolean variables.
      </paragraph>
      <paragraph>
       Second, for each action instance {a mathematical formula}ai in the solution plan π we create one variable with weight {a mathematical formula}12 representing whether the action can execute or not. Abusing notation, we denote this boolean variable {a mathematical formula}ai.
      </paragraph>
      <paragraph>
       Finally, for each proposition {a mathematical formula}p∈F and state index {a mathematical formula}i∈{0,1,...,n}, we create a boolean variable {a mathematical formula}pi with weight {a mathematical formula}12.
      </paragraph>
      <paragraph>
       We denote Z as the set of all boolean variables defined; thus {a mathematical formula}Z∖Z˜ is the set of those representing action instances {a mathematical formula}ai's and propositions {a mathematical formula}pi's over time steps.
      </paragraph>
      <paragraph>
       Constraints:
      </paragraph>
      <paragraph>
       Initial and goal states constraints: for each proposition p that presents in the initial state, we set {a mathematical formula}p0=T; otherwise, {a mathematical formula}p0=F. Similarly, if {a mathematical formula}p∈G then {a mathematical formula}pn=T.
      </paragraph>
      <paragraph>
       Action execution constraints: for each action {a mathematical formula}ai ({a mathematical formula}1≤i≤n+1), we create a constraint:{a mathematical formula} specifying the necessary and sufficient conditions under which the action can and will execute:{a mathematical formula}
      </paragraph>
      <paragraph>
       We note that, slightly different from a state-based encoding for plan synthesis (cf., Rintanen et al. [23]), we need {a mathematical formula}ai⇐exe(ai) to correctly capture our semantics of action execution: when an action is executable (i.e., when all of its preconditions, including realized ones, are satisfied), its effects will take place in the successor state.
      </paragraph>
      <paragraph>
       Effect constraints: we create constraints specifying that if action {a mathematical formula}ai executes, then its effects are true in the next state:{a mathematical formula}
      </paragraph>
      <paragraph>
       State change constraints: for every proposition {a mathematical formula}p∈F, we add constraints specifying conditions under which the value of p being changed in two consecutive time steps {a mathematical formula}(i−1)-th and i-th ({a mathematical formula}1≤i≤n). For the changes from F to T:{a mathematical formula} in which {a mathematical formula}ϕi is defined as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       The constraints for changing from T to F are defined similarly.
      </paragraph>
      <paragraph>
       Let {a mathematical formula}Σπ be the set of all constraints above. For each assignment σ for variables Z, we denote {a mathematical formula}Dσ∈《D˜》 as the candidate domain model in which the realization of possible preconditions and effects is determined by the truth assignment for variables {a mathematical formula}Z˜ in σ. Let {a mathematical formula}M(Σπ) be the set of all models satisfying {a mathematical formula}Σπ.
      </paragraph>
      <paragraph label="Theorem 1">
       For each{a mathematical formula}σ∈M(Σπ),{a mathematical formula}γGEDσ(π,I)⊨G.
      </paragraph>
      <paragraph label="Proof">
       Each model {a mathematical formula}σ∈M(Σπ) assigns truth values to variables {a mathematical formula}Z˜. With those truth values, all constraints in which variables in {a mathematical formula}Z˜ are involved are similar to those for synthesizing plans with SAT-based approach (for instance, in Rintanen et al. [23]), except that there is only one action instance of π at each time step. Following the correctness of encoding for those SAT-based approaches, π must achieve G with respect to the model σ.  □
      </paragraph>
      <paragraph>
       The following theorem establishes the connection between the robustness of π with the weighted model count of {a mathematical formula}Σπ.
      </paragraph>
      <paragraph label="Proof">
       The robustness of π in the GE semantics is{a mathematical formula}where{a mathematical formula}WMC(Σπ)is the weighted model count of{a mathematical formula}Σπ.Let {a mathematical formula}w(σ) be the weight of an assignment σ. We have:{a mathematical formula} By definition:{a mathematical formula} The last equality is due to both Theorem 1 and the definition of plan robustness.  □
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       SE semantics
      </section-title>
      <paragraph>
       Variables: The variables are the same as those in the set of variables {a mathematical formula}Z˜ used in the correctness constraints under the GE semantics.
      </paragraph>
      <paragraph>
       Constraints: Given that all actions must be executable, and that the initial state at the first step is complete, the truth value of any proposition p at level i ({a mathematical formula}1&lt;i≤n+1) can only be affected by actions at steps {a mathematical formula}k∈{Cpi,...,i−1}. Here, {a mathematical formula}Cpi∈{1,...,i−1} is the latest level before i at which the truth value of p at {a mathematical formula}Cpi is completely “confirmed” by the success of either action {a mathematical formula}aCpi or {a mathematical formula}aCpi−1. Specifically, it is confirmed T if {a mathematical formula}p∈Pre(aCpi) or {a mathematical formula}p∈Add(aCpi−1); and confirmed F if {a mathematical formula}p∈Del(aCpi−1).
      </paragraph>
      <paragraph>
       Precondition establishment and protection: for each {a mathematical formula}p∈Pre(ai) ({a mathematical formula}1≤i≤n+1), we create constraints establishing and protecting the T value of this precondition. If {a mathematical formula}p=F at level {a mathematical formula}Cpi, we add the following constraints to ensure that it is supported before level i:{a mathematical formula}
      </paragraph>
      <paragraph>
       Note that there exists at least one such action {a mathematical formula}ak for {a mathematical formula}ai to be executable. If there exists actions {a mathematical formula}am ({a mathematical formula}Cpi≤m≤i−1) that possibly deletes p, we protect its value with the constraints:{a mathematical formula} or {a mathematical formula}¬pamdel if there is no such action {a mathematical formula}ak possibly support p. Note that the constraints for known preconditions of {a mathematical formula}an+1 ensure that goals G are achieved after the plan execution.
      </paragraph>
      <paragraph>
       Possible precondition establishment and protection: when a possible precondition p of action {a mathematical formula}ai ({a mathematical formula}1≤i≤n) is realized, its value also needs to be established to T and protected. Specifically, for {a mathematical formula}p=F at level {a mathematical formula}Cpi, we add the constraints:{a mathematical formula}
      </paragraph>
      <paragraph>
       Finally, with actions {a mathematical formula}am ({a mathematical formula}Cpi≤m≤i−1) having p as a possible delete effect, we must ensure that:{a mathematical formula}
      </paragraph>
      <paragraph>
       We again denote the set of constraints (11)–(14) established for π as {a mathematical formula}Σπ. It can be shown that any assignment to Boolean variables {a mathematical formula}papre, {a mathematical formula}paadd and {a mathematical formula}padel satisfying all constraints above corresponds to a complete domain model {a mathematical formula}D∈《D˜》 under which all actions {a mathematical formula}a1, ..., {a mathematical formula}an and {a mathematical formula}an+1 succeeds to execute. The weighted model count of {a mathematical formula}Σπ is thus the robustness of the plan. We will therefore use {a mathematical formula}R(π) and {a mathematical formula}WMC(Σπ) interchangeably under the SE semantics.
      </paragraph>
     </section>
     <section label="6.3">
      <section-title>
       Computational complexity
      </section-title>
      <paragraph>
       The fact that weighted model counting can be used to compute plan robustness does not immediately mean that assessing plan robustness is hard. We now show that it is indeed #P-complete, the same complexity of model counting problems.
      </paragraph>
      <paragraph label="Theorem 3">
       Given an incomplete model{a mathematical formula}D˜=〈R,O〉with annotations of weights{a mathematical formula}12, a planning problem{a mathematical formula}P˜=〈F,A,I,G〉and a plan π. The problem of computing{a mathematical formula}R(π)is #P-complete, and this holds for both GE and SE semantics.
      </paragraph>
      <paragraph label="Proof">
       The following proof applies for both two semantics. The membership can be seen by having a Counting Turing Machine [29] nondeterministically guess a complete model, and check the correctness of the plan. The number of accepting branches output is the number of complete models under which the plan succeeds.To prove the hardness, we show that there is a polynomial-time reduction from an instance {a mathematical formula}〈X,Σ〉 of MONOTONE 2-SAT, a #P-complete problem [30], to an instance {a mathematical formula}〈D˜,P˜,π〉 such that {a mathematical formula}R(π)=|M(Σ)|2n. The input of the MONOTONE 2-SAT counting problem is a set of n Boolean variables {a mathematical formula}X={x1,...,xn}, a monotone CNF formulae {a mathematical formula}Σ={c1,c2,...,cm} with m clauses {a mathematical formula}cj=xj1∨xj2, where {a mathematical formula}xj1,xj2∈X. The required output is {a mathematical formula}|M(Σ)|, the number of assignments of X satisfying Σ.Let {a mathematical formula}G=〈V,E〉 be the constraint graph of the clause set Σ, where {a mathematical formula}V=X and {a mathematical formula}(xi,xj)∈E if {a mathematical formula}xi∨xj∈Σ. We partition this graph into connected components (or subgraph) {a mathematical formula}G1,...,Gl. Our set of propositions F then includes propositions {a mathematical formula}pk for each subgraph {a mathematical formula}Gk ({a mathematical formula}1≤k≤l) and propositions {a mathematical formula}gj for each clause {a mathematical formula}cj ({a mathematical formula}1≤j≤m): {a mathematical formula}F={p1,...,pl,g1,...,gm}. We denote {a mathematical formula}k(xi) and {a mathematical formula}k(cj) as the indices of the subgraphs containing {a mathematical formula}xi and the edge {a mathematical formula}(xj1,xj2). The set of actions A consists of {a mathematical formula}n+m actions {a mathematical formula}axi and {a mathematical formula}bgj, respectively defined for each variable {a mathematical formula}xi and proposition {a mathematical formula}gj. Action {a mathematical formula}axi has {a mathematical formula}Add˜(axi)={pk(xi)} and the other components are empty. Action {a mathematical formula}bgj is complete and defined with {a mathematical formula}Pre(bgj)=Del(bgj)={pk(cj)}, {a mathematical formula}Add(bgj)={gj}. Given {a mathematical formula}D˜=〈F,A〉,{sup:3} we define a planning problem {a mathematical formula}P˜ with {a mathematical formula}I=∅, {a mathematical formula}G={g1,...,gm} and a plan π that is the concatenation of m “subplans”: {a mathematical formula}π=π1∘...∘πm. Each subplan is {a mathematical formula}πj=〈axj1,axj2,bgj〉 ({a mathematical formula}1≤j≤m) such that {a mathematical formula}cj=xj1∨xj2 is the clause corresponding to {a mathematical formula}gj.From the reduction, there is a one-to-one mapping between the assignments of X to {a mathematical formula}《D˜》: {a mathematical formula}xi=T if and only if {a mathematical formula}axi has {a mathematical formula}pk(xi) as its add effect. The relation {a mathematical formula}R(π)=|M(Σ)|2n can be established by verifying that an assignment σ satisfies Σ if and only if π succeeds under the corresponding complete model {a mathematical formula}Dσ.Consider an assignment σ satisfying Σ, and the corresponding complete model {a mathematical formula}Dσ∈《D˜》. For each clause {a mathematical formula}cj=xj1∨xj2, at least one of the variables {a mathematical formula}xj1 and {a mathematical formula}xj2 must be T, implying that one of the two actions {a mathematical formula}axj1 and {a mathematical formula}axj2 will support {a mathematical formula}pk(cj) under {a mathematical formula}Dσ. Action {a mathematical formula}bgj is therefore executable in π, achieving {a mathematical formula}gj. As a result, π succeeds in achieving G under {a mathematical formula}Dσ. Vice versa, assuming that π succeeds under {a mathematical formula}Dσ. Since each {a mathematical formula}gj can only be supported by the corresponding {a mathematical formula}bgj, these actions must be executable. Therefore, {a mathematical formula}pk(cj) must be realized as an add effect of either {a mathematical formula}axj1 or {a mathematical formula}axj2, implying that {a mathematical formula}cj=xj1∨xj2 is satisfiable. The set of clauses Σ must then be satisfiable with respect to σ. The relation {a mathematical formula}R(π)=|M(Σ)|2n can now be established.  □
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Synthesizing robust plans with a compilation approach
     </section-title>
     <paragraph>
      In this section we will show that the problem of generating plans with at least ρ robustness value can be compiled into a conformant probabilistic planning problem [8]. We focus the details only on the GE semantics in this section and then present our experimental results using Probabilistic-FF, a state-of-the-art planner created by Domshlak and Hoffmann [8]. We briefly discuss how to adapt the compilation presented for the SE semantics.
     </paragraph>
     <section label="7.1">
      <section-title>
       Conformant probabilistic planning
      </section-title>
      <paragraph>
       Following the formalism used by Domshlak and Hoffmann [8], a domain model in conformant probabilistic planning (CPP) is a tuple {a mathematical formula}D′=〈F′,A′〉, where {a mathematical formula}F′ and {a mathematical formula}A′ are the sets of propositions and probabilistic actions, respectively. A belief state {a mathematical formula}b:2F′→[0,1] is a distribution of states {a mathematical formula}s⊆F′ (we denote {a mathematical formula}s∈b if {a mathematical formula}b(s)&gt;0). Each action {a mathematical formula}a′∈A′ is specified by a set of preconditions {a mathematical formula}Pre(a′)⊆F′ and conditional effects {a mathematical formula}E(a′). For each {a mathematical formula}e=(cons(e),O(e))∈E(a′), {a mathematical formula}cons(e)⊆F′ is the condition set and {a mathematical formula}O(e) determines the set of outcomes {a mathematical formula}ε=(Pr(ε),add(ε),del(ε)) that will add and delete proposition sets {a mathematical formula}add(ε), {a mathematical formula}del(ε) into and from the resulting state with the probability {a mathematical formula}Pr(ε) ({a mathematical formula}0≤Pr(ε)≤1 , {a mathematical formula}∑ε∈O(e)Pr(ε)=1). All condition sets of the effects in {a mathematical formula}E(a′) are assumed to be mutually exclusive and exhaustive. The action {a mathematical formula}a′ is applicable in a belief state b if {a mathematical formula}Pre(a′)⊆s for all {a mathematical formula}s∈b, and the probability of a state {a mathematical formula}s′ in the resulting belief state is {a mathematical formula}ba′(s′)=∑s⊇Pre(a′)b(s)∑ε∈O′(e)Pr(ε), where {a mathematical formula}e∈E(a′) is the conditional effect such that {a mathematical formula}cons(e)⊆s, and {a mathematical formula}O′(e)⊆O(e) is the set of outcomes ε such that {a mathematical formula}s′=s∪add(ε)∖del(ε).
      </paragraph>
      <paragraph>
       Given the domain model {a mathematical formula}D′, a problem {a mathematical formula}P′ is a quadruple {a mathematical formula}P′=〈D′,bI,G′,ρ′〉, where {a mathematical formula}bI is an initial belief state, {a mathematical formula}G′ is a set of goal propositions and {a mathematical formula}ρ′ is the acceptable goal satisfaction probability. A sequence of actions {a mathematical formula}π′=〈a1′,...,an′〉 is a solution plan for {a mathematical formula}P′ if {a mathematical formula}ai′ is applicable in the belief state {a mathematical formula}bi (assuming {a mathematical formula}b1≡bI), which results in {a mathematical formula}bi+1 ({a mathematical formula}1≤i≤n), and it achieves all goal propositions with at least {a mathematical formula}ρ′ probability.
      </paragraph>
     </section>
     <section label="7.2">
      <section-title>
       Compilation
      </section-title>
      <paragraph>
       Given an incomplete domain model {a mathematical formula}D˜=〈R,O〉 and a planning problem {a mathematical formula}P˜=〈F,A,I,G〉, we now describe a compilation that translates the problem of synthesizing a solution plan π for {a mathematical formula}P˜ such that {a mathematical formula}R(π)≥ρ to a CPP problem {a mathematical formula}P′. At a high level, the realization of possible preconditions {a mathematical formula}p∈Pre˜(a) and effects {a mathematical formula}q∈Add˜(a), {a mathematical formula}r∈Del˜(a) of an action {a mathematical formula}a∈A can be understood as being determined by the truth values of hidden propositions {a mathematical formula}papre, {a mathematical formula}qaadd and {a mathematical formula}radel that are certain (i.e. unchanged in any world state) but unknown. (These propositions play the same role with variables {a mathematical formula}Z˜ in Section 6.1.) Specifically, the applicability of the action in a state {a mathematical formula}s⊆F depends on possible preconditions p that are realized (i.e. {a mathematical formula}papre=T), and their truth values in s. Similarly, the values of q and r are affected by a in the resulting state only if they are realized as add and delete effects of the action (i.e., {a mathematical formula}qaadd=T, {a mathematical formula}radel=T). There are totally {a mathematical formula}2|Pre˜(a)|+|Add˜(a)|+|Del˜(a)| realizations of the action a, and all of them should be considered simultaneously in checking the applicability of the action and in defining corresponding resulting states.
      </paragraph>
      <paragraph>
       With those observations, we use multiple conditional effects to compile away incomplete knowledge on preconditions and effects of the action a. Each conditional effect corresponds to one realization of the action, and can be fired only if {a mathematical formula}p=T whenever {a mathematical formula}papre=T, and adding (removing) an effect q (r) into (from) the resulting state depending on the values of {a mathematical formula}qaadd ({a mathematical formula}radel, respectively) in the realization.
      </paragraph>
      <paragraph>
       While the partial knowledge can be removed, the hidden propositions introduce uncertainty into the initial state, and therefore making it a belief state. Since the action a may be applicable in some but rarely all states of a belief state, certain preconditions {a mathematical formula}Pre(a) should be modeled as conditions of all conditional effects. We are now ready to formally specify the resulting domain model {a mathematical formula}D′ and problem {a mathematical formula}P′.
      </paragraph>
      <paragraph>
       For each action {a mathematical formula}a∈A, we introduce new propositions {a mathematical formula}papre, {a mathematical formula}qaadd, {a mathematical formula}radel and their negations {a mathematical formula}npapre, {a mathematical formula}nqaadd, {a mathematical formula}nradel for each {a mathematical formula}p∈Pre˜(a), {a mathematical formula}q∈Add˜(a) and {a mathematical formula}r∈Del˜(a) to determine whether they are realized as preconditions and effects of a in the real domain model.{sup:4} Let {a mathematical formula}Fnew be the set of those new propositions, then {a mathematical formula}F′=F∪Fnew is the proposition set of {a mathematical formula}D′.
      </paragraph>
      <paragraph>
       Each action {a mathematical formula}a′∈A′ is made from one action {a mathematical formula}a∈A such that {a mathematical formula}Pre(a′)=∅, and {a mathematical formula}E(a′) consists of {a mathematical formula}2|Pre˜(a)|+|Add˜(a)|+|Del˜(a)| conditional effects e. For each conditional effect e:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}cons(e) is the union of the following sets:
       </list-item>
       <list-item label="•">
        the single outcome ε of e is defined as {a mathematical formula}add(ε)=Add(a)∪Add‾(a), {a mathematical formula}del(ε)=Del(a)∪Del‾(a), and {a mathematical formula}Pr(ε)=1,
       </list-item>
      </list>
      <paragraph>
       where {a mathematical formula}Pre‾(a)⊆Pre˜(a), {a mathematical formula}Add‾(a)⊆Add˜(a) and {a mathematical formula}Del‾(a)⊆Del˜(a) represent the sets of realized preconditions and effects of the action. In other words, we create a conditional effect for each subset of the union of the possible precondition and effect sets of the action a. Note that the inclusion of new propositions derived from {a mathematical formula}Pre‾(a), {a mathematical formula}Add‾(a), {a mathematical formula}Del‾(a) and their “complement” sets {a mathematical formula}Pre˜(a)∖Pre‾(a), {a mathematical formula}Add˜(a)∖Add‾(a), {a mathematical formula}Del˜(a)∖Del‾(a) makes all condition sets of the action {a mathematical formula}a′ mutually exclusive. As for other cases (including those in which some precondition in {a mathematical formula}Pre(a) is excluded), the action has no effect on the resulting state, they can be ignored. The condition sets, therefore, are also exhaustive.
      </paragraph>
      <paragraph>
       The initial belief state {a mathematical formula}bI consists of {a mathematical formula}2|Fnew| states {a mathematical formula}s′⊆F′ such that {a mathematical formula}p∈s′ iff {a mathematical formula}p∈I ({a mathematical formula}∀p∈F), each represents a complete domain model {a mathematical formula}Di∈《D˜》 and with the probability {a mathematical formula}Pr(Di). The goal is {a mathematical formula}G′=G, and the acceptable goal satisfaction probability is {a mathematical formula}ρ′=ρ.
      </paragraph>
      <paragraph label="Theorem 4">
       Given a plan{a mathematical formula}π=〈a1,...,an〉for the problem{a mathematical formula}P˜, and{a mathematical formula}π′=(a1′,...,an′)where{a mathematical formula}ak′is the compiled version of{a mathematical formula}ak({a mathematical formula}1≤k≤n) in{a mathematical formula}P′. Then{a mathematical formula}R(π)≥ρiff{a mathematical formula}π′achieves all goals with at least ρ probability in{a mathematical formula}P′.
      </paragraph>
      <paragraph label="Proof">
       According to the compilation, there is one-to-one mapping between each complete model {a mathematical formula}Di∈《D˜》 in {a mathematical formula}P˜ and a (complete) state {a mathematical formula}si0′∈bI in {a mathematical formula}P′. Moreover, if {a mathematical formula}Di has a probability of {a mathematical formula}Pr(Di) to be the real model, then {a mathematical formula}si0′ also has a probability of {a mathematical formula}Pr(Di) in the belief state {a mathematical formula}bI of {a mathematical formula}P′.Given the projection over complete model {a mathematical formula}Di, executing π from the state I with respect to {a mathematical formula}Di results in a sequence of complete states {a mathematical formula}〈si1,...,si(n+1)〉. On the other hand, executing {a mathematical formula}π′ from {a mathematical formula}{si0′} in {a mathematical formula}P′ results in a sequence of belief states {a mathematical formula}({si1′},...,{si(n+1)′}). Since {a mathematical formula}p∈si0′ iff {a mathematical formula}p∈I ({a mathematical formula}∀p∈F), by induction it can be shown that {a mathematical formula}p∈sij′ iff {a mathematical formula}p∈sij ({a mathematical formula}∀j∈{1,...,n+1},p∈F). Therefore, {a mathematical formula}si(n+1)⊨G iff {a mathematical formula}si(n+1)′⊨G=G′.Since all actions {a mathematical formula}ai′ are deterministic and {a mathematical formula}si0′ has a probability of {a mathematical formula}Pr(Di) in the belief state {a mathematical formula}bI of {a mathematical formula}P′, the probability that {a mathematical formula}π′ achieves {a mathematical formula}G′ is {a mathematical formula}∑si(n+1)′⊨GPr(Di), which is equal to {a mathematical formula}R(π) as defined in Equation (5). This proves the theorem.  □
      </paragraph>
      <paragraph label="Example">
       Consider the action pick-up(?b – ball,?r – room) in the Gripper domain as described above. In addition to the possible precondition (light ?b) on the weight of the ball ?b, we also assume that since the modeler is unsure if the gripper has been cleaned or not, she models it with a possible add effect (dirty ?b) indicating that the action might make the ball dirty. Fig. 3 shows both the original and the compiled specification of the action.
      </paragraph>
     </section>
     <section label="7.3">
      <section-title>
       Experimental results
      </section-title>
      <paragraph>
       We tested the compilation with Probabilistic-FF (PFF), a state-of-the-art planner, on a range of domains in the International Planning Competition.We first discuss the results on the variants of the Logistics and Satellite domains, where domain incompleteness is deliberately modeled on the preconditions and effects of actions (respectively). Our purpose here is to observe how generated plans are robustified to satisfy a given robustness threshold, and how the amount of incompleteness in the domains affects the plan generation phase. We then describe the second experimental setting in which we randomly introduce incompleteness into IPC domains, and discuss the feasibility of our approach in this setting.{sup:5}
      </paragraph>
      <paragraph>
       Domains with deliberate incompleteness
      </paragraph>
      <paragraph>
       Logistics: In this domain, each of the two cities {a mathematical formula}C1 and {a mathematical formula}C2 has an airport and a downtown area. The transportation between the two distant cities can only be done by two airplanes {a mathematical formula}A1 and {a mathematical formula}A2. In the downtown area of {a mathematical formula}Ci ({a mathematical formula}i∈{1,2}), there are three heavy containers {a mathematical formula}Pi1,...,Pi3 that can be moved to the airport by a truck {a mathematical formula}Ti. Loading those containers onto the truck in the city {a mathematical formula}Ci, however, requires moving a team of m robots {a mathematical formula}Ri1,...,Rim ({a mathematical formula}m≥1), initially located in the airport, to the downtown area. The source of incompleteness in this domain model comes from the assumption that each pair of robots {a mathematical formula}R1j and {a mathematical formula}R2j ({a mathematical formula}1≤j≤m) are made by the same manufacturer {a mathematical formula}Mj, both therefore might fail to load a heavy container.{sup:6} The actions loading containers onto trucks using robots made by a particular manufacturer (e.g., the action schema load-truck-with-robots-of-M1 using robots of manufacturer {a mathematical formula}M1), therefore, have a possible precondition requiring that containers should not be heavy. To simplify discussion (see below), we assume that robots of different manufacturers may fail to load heavy containers, though independently, with the same probability of 0.7. The goal is to transport all three containers in the city {a mathematical formula}C1 to {a mathematical formula}C2, and vice versa. For this domain model, a plan to ship a container to another city involves a step of loading it onto the truck, which can be done by a robot (after moving it from the airport to the downtown). Plans can be made more robust by using additional robots of different manufacturer after moving them into the downtown areas, with the cost of increasing plan length.
      </paragraph>
      <paragraph>
       Satellite: In this domain, there are two satellites {a mathematical formula}S1 and {a mathematical formula}S2 orbiting the planet Earth, on each of which there are m instruments {a mathematical formula}Li1,...,Lim ({a mathematical formula}i∈{1,2}, {a mathematical formula}m≥1) used to take images of interested modes at some direction in the space. For each {a mathematical formula}j∈{1,...,m}, the lenses of instruments {a mathematical formula}Lij's were made from a type of material {a mathematical formula}Mj, which might have an error affecting the quality of images that they take. If the material {a mathematical formula}Mj actually has error, all instruments {a mathematical formula}Lij's produce mangled images. The knowledge of this incompleteness is modeled as a possible add effect of the action taking images using instruments made from {a mathematical formula}Mj (for instance, the action schema take-image-with-instruments-M1 using instruments of type {a mathematical formula}M1) with a probability of {a mathematical formula}pj, asserting that images taken might be in a bad condition. A typical plan to take an image using an instrument, e.g. {a mathematical formula}L14 of type {a mathematical formula}M4 on the satellite {a mathematical formula}S1, is first to switch on {a mathematical formula}L14, turning the satellite {a mathematical formula}S1 to a ground direction from which {a mathematical formula}L14 can be calibrated, and then taking image. Plans can be made more robust by using additional instruments, which might be on a different satellite, but should be of different type of materials and can also take an image of the interested mode at the same direction.
      </paragraph>
      <paragraph>
       Table 1, Table 2 show respectively the results in the Logistics and Satellite domains with {a mathematical formula}m={1,2,...,5} and {a mathematical formula}ρ∈{0.1,0.2,...,0.9}. The number of complete domain models in the two domains is {a mathematical formula}2m. For Satellite domain, the probabilities {a mathematical formula}pj's range from 0.25, 0.3,... to 0.45 when m increases from 1, 2, ... to 5. For each specific value of ρ and m, we report {a mathematical formula}l/t where l is the length of plan and t is the running time (in seconds). Cases in which no plan is found within the time limit are denoted by “–”, and those where it is provable that no plan with the desired robustness exists are denoted by “⊥”.
      </paragraph>
      <paragraph>
       Observations on fixed value of m: In both domains, for a fixed value of m we observe that the solution plans tend to be longer with higher robustness threshold ρ, and the time to synthesize plans is also larger. For instance, in Logistics with {a mathematical formula}m=5, the plan returned has 48 actions if {a mathematical formula}ρ=0.3, whereas 66-length plan is needed if ρ increases to 0.4. Since loading containers using the same robot multiple times does not increase the chance of success, more robots of different manufacturers need to move into the downtown area for loading containers, which causes an increase in plan length. In the Satellite domain with {a mathematical formula}m=3, similarly, the returned plan has 37 actions when {a mathematical formula}ρ=0.5, but requires 53 actions if {a mathematical formula}ρ=0.6—more actions need to calibrate an instrument of different material types in order to increase the chance of having a good image of interested mode at the same direction.
      </paragraph>
      <paragraph>
       Since the cost of actions is currently ignored in the compilation approach, we also observe that more than the needed number of actions have been used in many solution plans. In the Logistics domain, specifically, it is easy to see that the probability of successfully loading a container onto a truck using robots of k ({a mathematical formula}1≤k≤m) different manufacturers is {a mathematical formula}(1−0.7k). As an example, however, robots of all five manufacturers are used in a plan when {a mathematical formula}ρ=0.4, whereas using those of three manufacturers is enough.
      </paragraph>
      <paragraph>
       Observations on fixed value of ρ: In both domains, we observe that the maximal robustness value of plans that can be returned increases with higher number of manufacturers (though the higher the value of m is, the higher number of complete models is). For instance, when {a mathematical formula}m=2 there is not any plan returned with at least {a mathematical formula}ρ=0.6 in the Logistics domain, and with {a mathematical formula}ρ=0.4 in the Satellite domain. Intuitively, more robots of different manufacturers offer higher probability of successfully loading a container in the Logistics domain (and similarly for instruments of different materials in the Satellite domain).
      </paragraph>
      <paragraph>
       Finally, it may take longer time to synthesize plans with the same length when m is higher—in other words, the increasing amount of incompleteness of the domain makes the plan generation phase harder. As an example, in the Satellite domain, with {a mathematical formula}ρ=0.6 it takes 216.7 seconds to synthesize a 37-length plan when there are {a mathematical formula}m=5 possible add effects at the schema level of the domain, whereas the search time is only 94.1 seconds when {a mathematical formula}m=4. With {a mathematical formula}ρ=0.7, no plan is found within the time limit when {a mathematical formula}m=5, although a plan with robustness of 0.7075 exists in the solution space. It is the increase of the branching factors and the time spent on satisfiability test and weighted model-counting used inside the planner that affect the search efficiency.
      </paragraph>
      <paragraph>
       Domains with random incompleteness: We built a program to generate an incomplete domain model from a deterministic one by introducing M new propositions into each domain model (all are initially T). Some of those new propositions were randomly added into the sets of possible preconditions/effects of actions. Some of them were also randomly made certain add/delete effects of actions. With this strategy, each solution plan in an original deterministic domain model is also a valid plan, as defined earlier, in the corresponding incomplete domain model. Our experiments with the Depots, Driverlog, Satellite and Zenotravel domains indicate that because the annotations are random, there are often fewer opportunities for the PFF planner to increase the robustness of a plan prefix during the search. This makes it hard to generate plans with a desired level of robustness under given time constraint.
      </paragraph>
      <paragraph>
       Discussion: The techniques presented in this section for the GE semantics can be adapted for the compilation approach under the SE semantics. The compiled actions must have additional conditional effects to capture execution scenarios where either a known precondition or a possible precondition being realized is not satisfied in the current state. The effects in those cases must result in ⊥, thus leading the system to the dead end state {a mathematical formula}s⊥. We however note that the requirement for mutually exclusive and exhaustive conditions in each conditional effect of the CPP formulation can significantly increase the number of conditional effects in the compiled actions.
      </paragraph>
     </section>
    </section>
    <section label="8">
     <section-title>
      Synthesizing robust plans with heuristic search
     </section-title>
     <paragraph>
      We now present an anytime forward search approach to synthesizing robust plans under the STRIPS execution semantics. Although the solution space is more limited than that of the GE semantics, the proposed approach is much more scalable than the compilation approach in the previous section. At a high level, in each iteration it searches for a plan π with the robustness {a mathematical formula}R(π) greater than a threshold δ, which is set to zero initially. The threshold is then updated with {a mathematical formula}R(π), preparing for the next iteration. The last plan produced is the most robust plan. We will briefly discuss a similar idea for the Generous Execution semantics at the end of this section.
     </paragraph>
     <paragraph>
      The main technical part of our approach is a procedure to extract a relaxed plan {a mathematical formula}π˜, given the current plan prefix {a mathematical formula}πk of k actions and threshold δ, such that {a mathematical formula}WMC(Σπk∧Σπ˜)&gt;δ. (The sets of constraints {a mathematical formula}Σπ, {a mathematical formula}Σπk and {a mathematical formula}Σπ˜ used in this approach for the SE semantics are presented in Section 6.2.) The length of {a mathematical formula}π˜ estimates the additional search cost {a mathematical formula}h(πk,δ) to reach goals G, starting from {a mathematical formula}πk, with more than δ probability of success. Since {a mathematical formula}WMC(⋅) is costly to compute, we approximate it with a lower bound {a mathematical formula}l(⋅) and upper bound {a mathematical formula}u(⋅), which will then be used during the relaxed plan extraction. In particular, we look for the relaxed plan {a mathematical formula}π˜ satisfying {a mathematical formula}l(Σπk∧Σπ˜)&gt;δ, and compute the exact robustness of a candidate plan π only if {a mathematical formula}u(Σπ)&gt;δ.
     </paragraph>
     <paragraph>
      In this section, we first introduce an approximate transition function {a mathematical formula}γ˜SE(π,s) that will be used during the forward search. It defines a set of propositions that might be T during the execution phase, thus helps the search in quickly defining applicable actions and checking potential goal satisfaction at each search step. The set will also be used as the first propositional layer of the relaxed planning graphs for extracting relaxed plans. We then describe our lower and upper bound for {a mathematical formula}WMC(Σ) of a clause set Σ, presents our procedure for extracting relaxed plan, and then discuss our choice for the underlying search algorithm.
     </paragraph>
     <section label="8.1">
      <section-title>
       An approximate transition function
      </section-title>
      <paragraph>
       In our approximate transition function, the resulting state from applying action a in state s is defined as follows:{a mathematical formula} The projection of an action sequence π from a state s is defined as {a mathematical formula}γ˜SE(π,s)=s if {a mathematical formula}π=〈〉, and {a mathematical formula}γ˜SE(π,s)=γ˜SE(〈a〉,γ˜SE(π′,s)) if {a mathematical formula}π=π′∘〈a〉. The sequence π is a valid plan for a planning problem {a mathematical formula}P˜ under the approximate transition function if {a mathematical formula}γ˜SE(π,I)⊇G.
      </paragraph>
      <paragraph label="Proposition 1">
       For any complete model{a mathematical formula}D∈《D˜》, action sequence π and state s such that{a mathematical formula}γSED(π,s)≠s⊥,{a mathematical formula}γSED(π,s)⊆γ˜SE(π,s).
      </paragraph>
      <paragraph label="Proof">
       We prove the theorem by induction on the length of π. For the base case when {a mathematical formula}π=〈〉, {a mathematical formula}γSED(〈〉,s)=γ˜SE(〈〉,s)=s for any complete model {a mathematical formula}D and state s. Assuming that the theorem holds for any action sequences π of length k ({a mathematical formula}k≥0), complete model {a mathematical formula}D and state s such that {a mathematical formula}γSED(π,s)≠s⊥. Consider a complete model {a mathematical formula}D, state {a mathematical formula}s≠s⊥ and a sequence {a mathematical formula}π=π′∘〈a〉 of {a mathematical formula}k+1 actions such that {a mathematical formula}γSED(π,s)≠s⊥. Let {a mathematical formula}sπ′D=γSED(π′,s), {a mathematical formula}s˜π′D=γ˜SE(π′,s). It must hold that {a mathematical formula}sπ′D≠s⊥ and {a mathematical formula}Pre(a)⊆γSED(π′,s), because otherwise {a mathematical formula}γSED(π,s)=s⊥. Thus,{a mathematical formula} From the inductive hypothesis: {a mathematical formula}sπ′D⊆s˜π′D, and since {a mathematical formula}Pre(a)⊆γSED(π′,s) we have {a mathematical formula}Pre(a)⊆γ˜SE(π′,s). Therefore,{a mathematical formula} Since {a mathematical formula}sπ′D⊆s˜π′D, {a mathematical formula}DelD(a)⊇Del(a), {a mathematical formula}AddD(a)⊆Add(a)∪Add˜(a), from Eq. (16) and (17) we have {a mathematical formula}γSED(π,s)⊆γ˜SE(π,s). The theorem thus holds with sequences of {a mathematical formula}k+1 actions.  □
      </paragraph>
      <paragraph label="Theorem 5">
       A sequence of actions π is a valid plan under{a mathematical formula}γSEif and only if it is a valid plan under{a mathematical formula}γ˜SE.
      </paragraph>
      <paragraph label="Proof">
       If: Given that {a mathematical formula}γ˜SE(π,I)⊨G, π is a plan under the complete model {a mathematical formula}D0 in which {a mathematical formula}PreD0(a)=Pre(a), {a mathematical formula}AddD0(a)=Add(a)∪Add˜(a) and {a mathematical formula}DelD0(a)=Del(a) for all actions {a mathematical formula}a∈A. Thus π is a valid plan under {a mathematical formula}γSE.Only if: Assuming that π is a valid plan under {a mathematical formula}γSE. Let {a mathematical formula}D∈《D˜》 such that {a mathematical formula}γSED(π,I)⊨G. From Proposition 1, {a mathematical formula}γSED(π,I)⊆γ˜SE(π,I). Thus, {a mathematical formula}γ˜SE(π,I)⊨G, or π is a valid plan under {a mathematical formula}γ˜SE.  □
      </paragraph>
      <paragraph>
       Theorem 5 above implies that using the approximate transition function ensures the completeness property (that is, any plan achieving goals G in the ground truth model {a mathematical formula}D⁎ is not excluded from the search space), and the soundness property (in the sense that any valid plan for {a mathematical formula}P˜ is a plan achieving G in at least one complete model {a mathematical formula}D∈《D˜》). The approximate transition function {a mathematical formula}γ˜SE will therefore be used together with other components presented below for synthesizing robust plans.
      </paragraph>
     </section>
     <section label="8.2">
      <section-title>
       Approximating weighted model count
      </section-title>
      <paragraph>
       Our approach for generating robust plans requires the computation for weighted model counts of clause sets during the search and robust relaxed plan extraction. Given that such a computation has been proved to be hard, we introduce the lower bound and upper bound for the exact weighted model count {a mathematical formula}WMC(Σ) of clause set Σ, which can be computed in polynomial time.
      </paragraph>
      <paragraph>
       Lower bound: We observe that the set of constraints Σ, constructed as in (11)–(14), can be converted into a set of clauses containing only positive literals (or monotone clauses). In particular, the variables {a mathematical formula}paadd only appear in positive form in the resulting clauses. Variables {a mathematical formula}papre and {a mathematical formula}padel, however, are all in negation form, thus can be replaced with {a mathematical formula}npapre and {a mathematical formula}npadel having the corresponding weights {a mathematical formula}1−wapre(p) and {a mathematical formula}1−wadel(p). As a result, the following theorem shows that the quantity {a mathematical formula}lΣ=∏ciPr(ci) can be used as a lower bound for {a mathematical formula}WMC(Σ), where {a mathematical formula}Pr(ci) is the probability of {a mathematical formula}ci=T. (Recall that for a monotone clause {a mathematical formula}c=⋁ixi, {a mathematical formula}Pr(c)=1−∏i(1−wi), where {a mathematical formula}wi is the probability of {a mathematical formula}xi=T.)
      </paragraph>
      <paragraph label="Theorem 6">
       Given a set of monotone clauses{a mathematical formula}Σ={c1,...,ck},{a mathematical formula}lΣ=∏ci∈ΣPr(ci)≤WMC(Σ).
      </paragraph>
      <paragraph label="Proof (sketch)">
       For any two monotone clauses c and {a mathematical formula}c′, we can show that {a mathematical formula}Pr(c|c′)≥Pr(c) holds. (As an intuition, since c and {a mathematical formula}c′ have “positive interaction” only, observing one of the literals in {a mathematical formula}c′ cannot reduce belief that c is T.) More generally, {a mathematical formula}Pr(c|c1′∧...∧ct′)≥Pr(c) holds for monotone clauses c, {a mathematical formula}c1′, ..., {a mathematical formula}ct′. Therefore, {a mathematical formula}WMC(Σ)=Pr(Σ)=Pr(c1)Pr(c2|c1)...Pr(ck|c1∧...∧ck−1)≥∏ciPr(ci). □
      </paragraph>
      <paragraph>
       Upper bound: One trivial upper bound for {a mathematical formula}Pr(Σ) is {a mathematical formula}minci⁡Pr(ci). We can however derive a much tighter bound for {a mathematical formula}WMC(Σ) by observing that literals representing the realization of preconditions and effects on different predicates would not be present together in one clause. This suggests that the set of clauses Σ is essentially decomposable into independent sets of clauses, each contains literals on one specific predicate. Clauses related to the same predicate, furthermore, can also be partitioned into smaller sets. Thus, to derive a better upper bound for {a mathematical formula}Pr(Σ), we first divide it into independent clause sets {a mathematical formula}Σ1,...,Σm, and compute an upper bound {a mathematical formula}uΣ as follows: {a mathematical formula}uΣ=∏Σiminc∈Σi⁡Pr(c).
      </paragraph>
     </section>
     <section label="8.3">
      <section-title>
       Extracting robust relaxed plan
      </section-title>
      <paragraph>
       We now introduce our procedure to extract a relaxed plan {a mathematical formula}π˜ such that {a mathematical formula}l(Σπk∧Σπ˜)&gt;δ, where {a mathematical formula}Σπk and {a mathematical formula}Σπ˜ are the sets of constraints for the executability of actions in {a mathematical formula}πk and {a mathematical formula}π˜; note that {a mathematical formula}Σπ˜ also includes constraints for {a mathematical formula}aG, thus for the achievement of G. Our procedure employs an extension of the common relaxation technique (cf., Bonet and Geffner [2]) by ignoring both the known and possible delete effects of actions in constructing {a mathematical formula}π˜.{sup:7}
      </paragraph>
      <paragraph>
       Relaxed planning graph construction
      </paragraph>
      <paragraph>
       We construct the relaxed planning graph {a mathematical formula}G=〈L1,A1,...,LT−1,AT−1,LT〉 for the plan prefix {a mathematical formula}πk, in which each proposition p and action a at layer t is associated with clause sets {a mathematical formula}Σp(t) and {a mathematical formula}Σa(t).
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}L1≡sk+1, where {a mathematical formula}sk+1=γ˜SE(πk,I). The clause set {a mathematical formula}Σp(1) for each {a mathematical formula}p∈L1, constructed with Constraints (11) and (12), represents the constraints on actions of {a mathematical formula}πk under which {a mathematical formula}p=T at the first layer.
       </list-item>
       <list-item label="•">
        Given proposition layer {a mathematical formula}Lt, {a mathematical formula}At contains all actions a whose known preconditions appear in {a mathematical formula}Lt (i.e., {a mathematical formula}Pre(a)⊆Lt), and a complete action, {a mathematical formula}noopp, for each {a mathematical formula}p∈Lt: {a mathematical formula}Pre(noopp)=Add(noopp)={p}, {a mathematical formula}Del(noopp)=∅. The constraints for the non-noop actions:{a mathematical formula} All actions noop have the same constraints with their corresponding propositions.
       </list-item>
       <list-item label="•">
        Given action layer {a mathematical formula}At, the resulting proposition layer {a mathematical formula}Lt+1 contains all known and possible add effects of actions in {a mathematical formula}At. The clause set of p at layer {a mathematical formula}t+1 will be constructed by considering clause sets of all actions supporting and possibly supporting it at the previous layer, taking into account correctness constraints for the current plan prefix, i.e., {a mathematical formula}Σπk. In particular:{a mathematical formula} where {a mathematical formula}S1={Σa(t)|p∈Add(a)} and {a mathematical formula}S2={pa′add∧Σa′(t)|p∈Add˜(a′)}.{sup:8}
       </list-item>
      </list>
      <paragraph>
       We stop expanding the relaxed planning graph at layer {a mathematical formula}LT satisfying: (1) {a mathematical formula}G⊆LT, (2) the two layers {a mathematical formula}LT−1 and {a mathematical formula}LT, which include the set of propositions and their associated clause sets, are exactly the same. If the second condition is met, but not the first, then the relaxed plan extraction fails. We also recognize an early stopping condition at which (1) {a mathematical formula}G⊆LT and (2) {a mathematical formula}l(ΣG)&gt;δ, where {a mathematical formula}ΣG is the conjunction of clauses attached to goals {a mathematical formula}g∈G at layer T.
      </paragraph>
      <paragraph>
       Relaxed plan extraction
      </paragraph>
      <paragraph>
       We now extract actions from {a mathematical formula}G, forming a relaxed plan {a mathematical formula}π˜ such that {a mathematical formula}l(Σπk∧Σπ˜)&gt;δ. At a high level, our procedure at each step will pop a subgoal for being potentially supported. Each subgoal g is either a known or a possible precondition of an action a that has been inserted into the relaxed plan. The decision as to whether a subgoal should be supported depends on many factors (see below), all of which reflect our strategy that a new action is inserted only if the insertion increases the robustness of the current relaxed plan. If a new action is inserted, all of its known and possible preconditions will be pushed into the subgoal queue. Our procedure will stop as soon as it reaches a complete relaxed plan (see below) and its approximated robustness, specifically the value {a mathematical formula}l(Σπk∧Σπ˜), exceeds the current threshold δ (stop with success), or the subgoal queue is empty (stop with failure).
      </paragraph>
      <paragraph>
       The relaxed plan while being constructed might contain actions a with unsupported known preconditions p, for which the supporting and protecting constraints cannot be defined. The constraints defining the (potential) executability of actions in such an incomplete relaxed plan, therefore, are not well-defined.{sup:9} This is when the clause sets propagated in the relaxed planning graph play their role. In particular, we reuse the clause sets {a mathematical formula}Σp(t) associated with unsupported known preconditions p at the same layer t with a in the relaxed planning graph. We combine them with the constraints generated from Constraints (11)–(14) for (possibly) supported known and possible preconditions, resulting in constraints {a mathematical formula}Σπ˜. Together with {a mathematical formula}Σπk, it is used to define the robustness of the relaxed plan being constructed.
      </paragraph>
      <paragraph>
       The use of propagated clause sets in the relaxed planning graph reflects our intuition as to what the resulting relaxed plan should be. Given that each proposition p at layer t has a corresponding “best supporting action” at layer {a mathematical formula}t−1, defined from Equation (19), whose known and possible preconditions in turn have their best supporting actions, there exists a set of actions, denoted by {a mathematical formula}Sup(p,t), that can be selected at all layers {a mathematical formula}t′∈{1,...,t−1} to support p at layer t. Taking {a mathematical formula}Σp(t) into defining the robustness of an incomplete relaxed plan therefore implies that, in the worst case, we will have to include all actions in {a mathematical formula}Sup(p,t) into the resulting relaxed plan. Our procedure however will stop as soon as the relaxed plan is complete (i.e., all known preconditions and goals G are supported) and its lower bound for the robustness exceeds the threshold.
      </paragraph>
      <paragraph>
       Algorithm 1 shows the details of our relaxed plan extraction procedure. We initialize the relaxed plan {a mathematical formula}π˜ with {a mathematical formula}〈aG〉, the relaxed plan state{a mathematical formula}s→aG before {a mathematical formula}aG and the set of propositions {a mathematical formula}s→aG+ known to be T (Line 4). The set {a mathematical formula}sk+1+ contains propositions p known to be T after executing all actions in {a mathematical formula}πk—they are confirmed to be T at some step {a mathematical formula}Cpk+1&lt;k+1, and not being possibly deleted by any other actions at steps after {a mathematical formula}Cpk+1. Line 5–7 checks if {a mathematical formula}πk is actually a plan with the robustness exceeding δ. This procedure, presented in Algorithm 2, uses the bound {a mathematical formula}u(Σπk∧Σπ˜) to prevent the exact weighted model counting from being called unnecessarily.
      </paragraph>
      <paragraph>
       Line 8 initializes the constraints {a mathematical formula}Σπ˜ and the queue Q of subgoals.{sup:10} This procedure, presented in Algorithm 3, uses the constraints caused by actions of {a mathematical formula}πk for goals g that are (possibly) supported by {a mathematical formula}πk (Line 6-9), and the clause sets in {a mathematical formula}G for those that are not (Line 11).
      </paragraph>
      <paragraph>
       Line 10–37 of Algorithm 1 is our greedy process for building the relaxed plan. It first pops a triple {a mathematical formula}〈p,a,t〉 from Q to consider for supporting, then checks some conditions under which this subgoal can simply be skipped. Specifically, if {a mathematical formula}p∉Lt (Line 11), which also implies that it is a possible precondition of a (otherwise, a cannot be included into {a mathematical formula}At), then there are not any actions in the layer {a mathematical formula}At−1 that can (possibly) support p. Line 13–15 includes the other two conditions: {a mathematical formula}abest is in fact the last action in {a mathematical formula}πk, or it has already been inserted into {a mathematical formula}π˜. Here, {a mathematical formula}abest is the best non-noop supporting action for p at layer {a mathematical formula}lbest of {a mathematical formula}G (retrieved from Equation (19) and possibly a backward traversal over noop actions).
      </paragraph>
      <paragraph>
       Line 16–18 handles a situation where the current relaxed plan {a mathematical formula}π˜ is actually incomplete—it includes actions having a known precondition p not (possibly) supported; thus {a mathematical formula}πk∘π˜ would have (exact) zero robustness. It is therefore reasonable to immediately insert {a mathematical formula}abest into the current relaxed plan to support p. Note that this insertion means that {a mathematical formula}abest is put right after all actions at layers before {a mathematical formula}lbest that have been inserted into {a mathematical formula}π˜, maintaining the total-order of actions in {a mathematical formula}π˜.
      </paragraph>
      <paragraph>
       In other scenarios (Line 19–24), i.e., {a mathematical formula}p∈Pre(a)∩s→a or {a mathematical formula}p∈Pre˜(a), from the plan validity perspective we do not need to add new action (possibly) supporting this subgoal. However, since valid relaxed plan might not be robust enough (w.r.t. the current threshold δ), a new supporting action might be needed. Here, we employ a greedy approach: Line 20 evaluates the approximate robustness {a mathematical formula}r′ of the relaxed plan if {a mathematical formula}abest at layer {a mathematical formula}lbest is inserted. If inserting this action increases the current approximate robustness of the relaxed plan, i.e., {a mathematical formula}r′&gt;r, then the insertion will take place.
      </paragraph>
      <paragraph>
       Line 25–36 are works to be done after a new action is inserted into the relaxed plan. They include the updating of relaxed plan states and set of propositions known to be T (Line 26),{sup:11} the constraints {a mathematical formula}Σπ˜ (Line 27) and the lower bound on the robustness of the relaxed plan (Line 28). The new approximate robustness will then be checked against the threshold, and returns the relaxed plan with success if the conditions meet (Line 29–32). We note that in addition to the condition that the new approximate robustness exceeds δ, the relaxed plan must also satisfy the validity condition: all known preconditions of actions must be (possibly) supported. This ensures that all constraints in {a mathematical formula}Σπ˜ come from actions in {a mathematical formula}π˜, not from the clause set propagated in {a mathematical formula}G. In case the new relaxed plan is not robust enough, we push known and possible preconditions of the newly inserted action into the subgoal queue Q, ignoring those known to be T (Line 33–35), and repeat the process. Finally, we again check if the approximate robustness exceeds δ (Line 38) to return the relaxed plan length with its approximate robustness; otherwise, our procedure fails (Line 39).
      </paragraph>
     </section>
     <section label="8.4">
      <section-title>
       Search
      </section-title>
      <paragraph>
       We now discuss our choice for the underlying search algorithm. We note that the search for our problem, in essence, is performed over a space of belief states—in fact, our usage of the plan prefix {a mathematical formula}πk, the state {a mathematical formula}sk+1=γ˜SE(πk,I) and the set of known propositions {a mathematical formula}sk+1+ in the relaxed plan extraction makes the representation of belief state in our approach implicit, as in Conformant-FF [15] and Probabilistic-FF [7]. Checking duplicate belief states, if needed during the search, is expensive; to do this, for instance, Probabilistic-FF invokes satisfiability tests for certain propositions at a state just to check for a sufficient condition.
      </paragraph>
      <paragraph>
       To avoid such an expensive cost, in searching for a plan π with {a mathematical formula}R(π)&gt;δ we incorporate our relaxed plan extraction into an extension of the stochastic local search with failed-bounded restarts (Algorithm 4) proposed by Coles et al. [3]. Given a plan prefix {a mathematical formula}πk (initially empty) and its heuristic estimation {a mathematical formula}h(πk,δ), we look for a sequence of actions {a mathematical formula}π′ such that the new sequence {a mathematical formula}πk∘π′ has a better heuristic estimation: {a mathematical formula}h(πk∘π′,δ)&lt;h(πk,δ). This is done by performing multiple probes [3] starting from {a mathematical formula}sk+1=γ˜SE(πk,I); the resulting sequence π is a plan with {a mathematical formula}R(π)&gt;δ if {a mathematical formula}h(π,δ)=0. Since actions are stochastically sampled during the search, there is no need to perform belief state duplication detection.
      </paragraph>
     </section>
     <section label="8.5">
      <section-title>
       Experimental results
      </section-title>
      <paragraph>
       We test our planner, PISA, with incomplete domain models generated from IPC domains: Depots, Driverlog, Freecell, Rover, Satellite and Zenotravel. For each of these IPC domains, we make them incomplete with {a mathematical formula}np possible preconditions, {a mathematical formula}na possible add and {a mathematical formula}nd possible delete effects. We make possible lists using the following ways: (1) randomly “moving” some known preconditions and effects into the possible lists, (2) delete effects that are not preconditions are randomly made to be possible preconditions of the corresponding operators, (3) predicates whose parameters fit into the operator signatures, which however are not parts of the operator, are randomly added into possible lists. For these experiments, we vary {a mathematical formula}np, {a mathematical formula}na and {a mathematical formula}nd in {a mathematical formula}{0,1,...,5}, resulting in {a mathematical formula}63−1=215 incomplete domain models for each IPC domain mentioned above. We test our planner with the first 10 planning problems in each domain model, thus 2150 instances (i.e., a pair of incomplete domain model and planning problem). In addition, we also test with the Parcprinter incomplete domain available to us from the distribution of DeFault planner, which contains 300 instances. We restrict our experiments to incomplete domain models with only annotations of weights {a mathematical formula}12; this is also the only setting that DeFault can accept. We run them on a cluster of computing nodes, each possesses multiple Intel(R) Xeon(R) CPU E5440 @ 2.83 GHz. For exact model counting, we use Cachet model counting software ([25]). For the search in PISA we use the similar configuration in Coles et al. [3], except for the size of the neighborhood being 5—our experiments on small set of instances suggest this is probably the best. All experiments were limited to the 15 minutes time bound.
      </paragraph>
      <paragraph>
       Comparing to DeFault: We present our comparison between PISA and DeFault on five domains: Freecell, Parcprinter, Rover, Satellite and Zenotravel; DeFault cannot parse the other domains. We note that, although DeFault reads domain files describing operators with annotations, it assumes all annotations are specified at the grounded (or instantiated) level. Thus, we follow the same treatment by assuming possible preconditions and effects of grounded actions are all independent; the incompleteness amount can go up to, for instance in the Freecell domain, {a mathematical formula}K=73034 annotations (many of them however might be irrelevant to the actions in a resulting plan). We use the best configuration of DeFault: prime implicant heuristics with size {a mathematical formula}k=2 and 2 GB RAM as suggested, running it in the anytime mode.
      </paragraph>
      <paragraph>
       Fig. 4 shows the number of instances for which PISA generates plans having better, equal and worse robustness values compared to DeFault.{sup:12} Since the planners run in their anytime mode, returning plans with increasing plan robustness, we use the last plans produced by them in this comparison. Out of five domains, PISA generates better plans than DeFault in more instances of the four domains Freecell, Parcprinter, Satellite, Zenotravel, and a bit less in the Rover domain. More specifically, the percentage of instances for which PISA returns plans with equal or better robustness are always more than 50% in all domains: 61% in Freecell, 65% in Parcprinter, 53% in Rover, 60% in Satellite and 78.5% in Zenotravel. The percentages of instances with strictly better robustness in these domains respectively are 55.8%, 61.1%, 45.8%, 46.1% and 56.4%.
      </paragraph>
      <paragraph>
       Robustness ratio: Regarding the robustness value, we calculate the ratio of best robustness values of plans returned by PISA to those by DeFault. Note that in this comparison, we consider only instances for which both planners return valid plans. These ratios are: 8069.65 in Freecell, 166.36 in Parcprinter, 1.78 in Rover, 135.97 in Satellite and 898.66 in Zenotravel. Thus, on average, PISA produces plans with significantly higher robustness than DeFault.
      </paragraph>
      <paragraph>
       Planning time: Not only does PISA produce higher quality for plans, it also takes much less planning time.{sup:13} To demonstrate this, we first consider instances for which the two approaches return best plans with the same robustness values. Fig. 5 shows the total time taken by PISA and DeFault in these instances. We observe that in 95 instances of Freecell domain that the two approaches produce equally robust plans, PISA is faster in 72 instances, and slower in the remaining 23 instances—thus, it wins in 75.8% of instances. Comparing the ratio of planning times, PISA is actually 654.7× faster, on average, than DeFault in these 95 instances. These faster vs. slower instances and the planning time ratio are 8 vs. 2 (80.0%) and 29.6× for Parcprinter, 103 vs. 10 (91.1%) and 1665× for Rover, 281 vs. 28 (90.9%) and 562.7× for Satellite, 329 vs. 86 (79.3%) and 482.9× for Zenotravel.
      </paragraph>
      <paragraph>
       What is more interesting, in many cases, PISA is faster than Default, even when it produces significantly more robust plans. To show this, we again considered the last plan returned by each planner within the time bound, and the time when it was returned. Even for instances where the plan returned by PISA has strictly better robustness than that returned by DeFault, PISA often managed to return its plan significantly earlier. For example, in 65.4% of such instances in Freecell domain (315 out of 482), the planning time of PISA is also faster. These percentages of instances in Parcprinter, Rover, Satellite and Zenotravel are 52.8% (28 out of 53), 87.8% (144 out of 164), 55.9% (555 out of 992) and 46.5% (491 out of 1057) respectively. We also notice that PISA is faster than DeFault in synthesizing the first valid plans (that is, plans π such that {a mathematical formula}γ˜SE(π,I)⊇G) for most of the instances in all domains: 84.9% (960 out of 1130) instances in Freecell domain, 94% (141 out of 150) in Parcprinter, 98.1% (789 vs. 804) in Rover, 93.4% (1999 out of 2140) in Satellite and 92.4% (1821 out of 1971) in Zenotravel. We think that both the search and the fact that our heuristic is sensitive to the robustness threshold, so that it can perform pruning during search, contribute to the performance of PISA in planning time.
      </paragraph>
      <paragraph>
       Comparing with baseline approaches: We also compare PISA with an approach in which the relaxed plans are extracted in the similar way used in the FF planner [16]. In this approach, all annotations on possible preconditions and effects are ignored during the relaxed plan extraction. Note that all the other designs in PISA (such as checking {a mathematical formula}l(Σπk∧Σπ˜) against δ and the search algorithm) still remain the same. Unlike the earlier comparison with DeFault, incompleteness annotations are now applied at the operator level. PISA outperforms this FF-like heuristic approach in five domains: in particular, it produces better plans in 72.9% and worse in 8.3% instances of the Depots domain; similarly, 75.3% and 4.2% instances of Driverlog, 70.2% and 2.9% for Rover, 84.1% and 1.8% for Satellite, 61% and 8.3% in Zenotravel. PISA however is not as good as this baseline approach in the other two domains: it returns worse plans in 53.1% and only better in 12.4% instances of Freecell; the corresponding percentages in Parcprinter are 50.5% and 13.1%.
      </paragraph>
      <paragraph>
       In the second baseline approach, we use exact model counting {a mathematical formula}WMC(Σ) during the extraction of relaxed plans, replacing the approximation {a mathematical formula}l(Σ). This approach, as anticipated, spends most of the running time for the exact model counting. The results are discouraging, thus we will not go into the details.
      </paragraph>
      <paragraph>
       Discussion: The high level ideas of the heuristic approach presented in this section might also be useful for a similar approach under the GE semantics, however with additional challenges. In particular, the special property used for approximating plan robustness under the SE semantic no longer holds for GE semantics, thus the proposed lower and upper bounds are inapplicable. One might attempt to investigate the application of the work on approximate model counting, cf. [32], [13], for the encoding for plan correctness under the GE semantics in Section 6.1.
      </paragraph>
     </section>
    </section>
    <section label="9">
     <section-title>
      Using successful plan traces to improve plan robustness
     </section-title>
     <paragraph>
      PISA shows that in planning scenarios with incomplete domain models, the knowledge about the incompleteness such as the annotations considered in our setting greatly helps with defining the quality of plans and in synthesizing robust plans. In this section we extend our PISA approach to exploit a different source of information, the observation of past successful plans. These plan traces reveal information about the true domain model in an indirect way. In particular, any candidate domain model where the traces are not “correct” (i.e., do not successfully execute) cannot be true domain models, and thus can be eliminated. In other words, successful plan traces prune the candidate set of feasible domain models, and PISA needs only to synthesize a plan that is robust with respect to the remaining candidate domain models.
     </paragraph>
     <paragraph>
      In our extended approach, called {a mathematical formula}CPISA, this is accomplished by modifying the robustness assessment phase such that in addition to the constraints ensuring the correctness of the plan under development, we also add constraints ensuring that the provided plan traces are indeed correct. These latter constraints effectively put additional restrictions on which possible preconditions and possible effects are realized in the true domain model. In particular, the plan traces can either eliminate, force or correlate the realization of possible preconditions, possible adds and possible deletes of any of the actions in the domain model.
     </paragraph>
     <paragraph>
      As an example, consider a successful plan trace {a mathematical formula}〈ai,aj〉 for a problem with initial state I and goals G. Suppose {a mathematical formula}aj has a possible precondition p, which doesn't occur in I or anywhere in the definite or possible effects of {a mathematical formula}ai. In such a case, we can infer that in the true model, p cannot be a precondition of {a mathematical formula}aj (because otherwise, the plan couldn't be a successful trace). Thus, p is effectively eliminated as a “possible” precondition of {a mathematical formula}aj. This in turn halves the number of candidate domain models.
     </paragraph>
     <paragraph>
      For the case above, the possible precondition establishment and protection constraints (see Equation (13)) will add the constraint{a mathematical formula} (since there are no {a mathematical formula}ak that can possibly support p, the right hand side disjunction in Equation (13) becomes empty). On the other hand if {a mathematical formula}ai, in fact, had a possible add effect that could have turned p true, {a mathematical formula}CPISA would have included the constraint{a mathematical formula} It is important to note that the trace does not force the possible add for the action {a mathematical formula}ai to be true, rather it correlates it to the possible precondition of {a mathematical formula}aj. Specifically, if {a mathematical formula}aj does wind up having p as a precondition in the real model, then {a mathematical formula}ai must have p as an effect in the real model.
     </paragraph>
     <section label="9.1">
      <section-title>
       Posterior robustness measure
      </section-title>
      <paragraph>
       It is worth noting that since robustness measures the fraction of the candidate domain models in which the plan under development correctly executes, the estimate naturally changes when the planner has access to more successful traces. This is because the successful traces eliminate some of the candidate models, changing the base set of models over which we evaluate the correctness of the plan. Since PISA can be seen as a special case of {a mathematical formula}CPISA with no knowledge of successful traces, a given plan π can be seen to have different robustness according to PISA and {a mathematical formula}CPISA. The robustness estimated by PISA can be seen as a ‘prior’ estimate (with no additional knowledge of plan traces), while that estimated by {a mathematical formula}CPISA is a ‘posterior’ estimate (that takes into account the knowledge of the plan traces).
      </paragraph>
      <paragraph>
       Consider a set of plan traces {a mathematical formula}T that succeeded in achieving their goals under the (unknown) ground truth model {a mathematical formula}D⁎. Recall that the robustness of a plan π for the problem {a mathematical formula}P˜, as defined in Eq. (5), is the cumulative probability mass of the completions of {a mathematical formula}D˜ under which π succeeds (in achieving the goals). In the presence of plan traces {a mathematical formula}T, the extended robustness measure, denoted by {a mathematical formula}R(π|T), naturally is revised to be the probability that π succeeds given that all plans in {a mathematical formula}T succeed:{a mathematical formula}
      </paragraph>
      <paragraph>
       We denote {a mathematical formula}Pr(T) as the probability that all the plans in {a mathematical formula}T succeed, and similarly {a mathematical formula}Pr(π∧T) the probability that π and all plans in {a mathematical formula}T succeed. The robustness {a mathematical formula}R(π|T) above is equivalent to{a mathematical formula} where {a mathematical formula}ΣT=⋃πi∈TΣπi, i.e., the set of correctness constraints, as defined in Equations (11)–(14), for all plan traces.
      </paragraph>
      <paragraph>
       In extending PISA to take plan traces {a mathematical formula}T into account, we create the set of constraints {a mathematical formula}ΣT up front and then use them at every step of the search. In particular, the quality of a relaxed plan {a mathematical formula}π˜ constructed during the search for the plan prefix {a mathematical formula}πk is evaluated with the quantity{a mathematical formula}
      </paragraph>
      <paragraph>
       While the denominator is computed once, the numerator of the above quantity is approximated during the search. We use the same approximations presented earlier for the weighted model counting.
      </paragraph>
     </section>
     <section label="9.2">
      Experiments comparing {a mathematical formula}CPISA and PISA
      <paragraph>
       We ran {a mathematical formula}CPISA against two domains Zenotravel and Rover to demonstrate its utility. Both of these domains were used in evaluating the original approach. As before, we start from the correct domain models, and annotating a random set of preconditions and effects as possible preconditions and effects. In addition to making definite preconditions/effects into possible preconditions/effects, we also add additional domain conditions as possible preconditions and effects. This is to account for the fact that the domain writers may not necessarily know, at the time of annotation, which conditions are actually present in the true model. While adding these new predicates, we make sure that the parameter list of each new predicate was compatible with the signature of the operator. Next we created a set of random problems of varying sizes for each original complete domain model (using standard problem generators), which we then solved with respect to the actual domain model using an off-the-shelf planner. The solutions to these problems formed our case library.
      </paragraph>
      <paragraph>
       Some of these cases might implicitly eliminate some domain models from consideration. For example, in the case of Zenotravel, let us assume we have an operator ‘board’ with the following definition
      </paragraph>
      <list>
       <list-item>
        (:actionboard(?p-person?a-aircraft?c-city):precondition(and(at?a?c)(at?p?c)):poss-precondition():effect(and(in?p?a)):poss-effect(and(not(at?a?c))).
       </list-item>
      </list>
      <paragraph>
       As shown in its definition, the operator board has a possible effect (not (at ?a ?c)), which means that after boarding the plane will no longer be in that city. Next let us consider a plan trace containing the following actions
      </paragraph>
      <list>
       <list-item>
        (boardperson1plane3city4)(flyplane3city4city5fl4fl3)
       </list-item>
      </list>
      <paragraph>
       This plan trace tells us that after person1 boarded plane3 in city city4, the plane flew from city4 to city5 thereby reducing its fuel level from fl4 to fl3. If we knew that the operator fly had a known precondition that the plane should be in the source city, this plan trace would end up eliminating all domain models where the operator board has an effect
      </paragraph>
      <list>
       <list-item>
        (not(at?a?c))
       </list-item>
      </list>
      <paragraph>
       In the case of Zenotravel domain, we created an incomplete domain model by introducing five possible preconditions, five possible add effects and nine possible delete effects. Out of these possible predicates, nine of them are part of the actual base domain model, and ten of them were incorrect predicates added randomly. We created 15 case files by solving random problems using the base domain model. The 19 possible predicates represent 524,288 possible number of domains, of which only 1024 domains can support the execution of all the provided cases.
      </paragraph>
      <paragraph>
       We chose to test this domain on 15 problems of varying sizes and we ran the same problems using the original PISA system and with differing number of cases. Each system was run with a 15 minutes time limit per problem. Once we had the resulting plans for all the problems, we collected the best plan for each problem as produced by the respective approaches. Since both approaches rely on stochastic search, each planning instance was run multiple times to ensure that the search were not getting stuck on undesirable search paths. The result of the comparison is given in Fig. 6, Fig. 7.
      </paragraph>
      <paragraph>
       The results in Fig. 6, Fig. 7 illustrate that, the plans produced in the presence of full case library are consistently more robust. In Fig. 6 we see that {a mathematical formula}CPISA running with full case library was able to outperform the original approach (which is same as running {a mathematical formula}CPISA in the absence of any case files) in 9/15 problems. It is interesting to note that PISA in fact twice chose plans which ended up having zero robustness in the reduced domain space. In Fig. 7, we compare the outputs of {a mathematical formula}CPISA running with full case library against {a mathematical formula}CPISA running on a subset of the total cases. Again we see that even though the full set only had five additional cases, it was still able to produce better plans in many problems.
      </paragraph>
      <paragraph>
       Next for the Rover domain, we created an incomplete domain similar to Zenotravel. Our incomplete domain had 21 possible effect predicates and four possible precondition predicates. This includes a combination of existing predicates moved to possible section and new predicates. In total this represents 33,554,432 possible domains. Next we created four cases for the base domain, such that the four cases reduced the possible number of domains down to 65,535.
      </paragraph>
      <paragraph>
       We tested the domain using ten problems of different sizes. Similar to Zenotravel, each problem in Rover domain was tested with the original approach and then tested with our extension for varying sizes of case library. The best plan produced by each variation of the approach is evaluated in the reduced domain space to obtain the best possible approximation of the robustness. Similar to Zenotravel each problem was run multiple times. The result of the experiment is shown in Fig. 8 and Fig. 9.
      </paragraph>
      <paragraph>
       As is evident from the above results, {a mathematical formula}CPISA was able to produce plans with better robustness for the majority of the problems.{sup:14} One interesting point we noticed was that, the plans with better estimates of prior robustness (as measured by PISA) may actually have significantly worse posterior robustness estimate. This makes sense as the plan might have been working in models that are eliminated by the successful cases.
      </paragraph>
     </section>
     <section label="9.3">
      {a mathematical formula}CPISA as a way to further reduce domain-modeling burden
      <paragraph>
       Although our study focused on how {a mathematical formula}CPISA can exploit knowledge about past successful cases, the same mechanism also allows a way out of a more fundamental dilemma about the operation of PISA. Specifically, one might question whether a domain-writer not willing to write down the complete domain theory can be expected to mark possible preconditions and effects. After all, it would be more natural to expect that the domain writer provides an incomplete model, with no special indications on possible preconditions/effects. {a mathematical formula}CPISA suggests a satisfactory solution to this dilemma: we can start by assuming that for each action, any condition that is not already mentioned in its preconditions or effects list is a possible precondition or effect (respectively). While this exponentially increases the number of possible complete models that are consistent with the resultant incomplete model, the availability of the successful cases can help {a mathematical formula}CPISA filter out many of these possible complete models. In particular, any complete model that does't ensure successful execution of every one of the cases will in effect be pruned from consideration.
      </paragraph>
     </section>
     <section label="9.4">
      Comparing {a mathematical formula}CPISA to RIM
      <paragraph>
       {a mathematical formula}CPISA can be viewed as starting with a distribution over domain models (that are consistent with the annotated STRIPS model), and learning from past successful plan cases to compute a new posterior distribution over the domain models, which it then uses to compute robust plans for new problems. In contrast, RIM [36] is a competing approach that starts with a single domain model, and given successful plan cases, modifies its initial model into a single new model. This modified model not only captures additional precondition/effect knowledge about the given actions, but also “macro actions”. RIM uses a MAX-SAT framework for learning, where the constraints are derived from the executability of the given plan traces, as well as the preconditions/effects of the given incomplete model. Unlike traditional macro-action learners which use macros to increase the efficiency of planning (in the context of a complete model), RIM's motivation for learning macros is to increase the accuracy (robustness) of the plans generated with the modified model. It thus provides an interesting counter-point to the {a mathematical formula}CPISA approach.
      </paragraph>
      <paragraph>
       We compare the performance of {a mathematical formula}CPISA and RIM in three domains: Zenotravel, Blocksworld and Driverlog. For each domain, as before, a random set of preconditions and effects are removed from the domain file. This truncated domain model is given as the initial model for RIM. For {a mathematical formula}CPISA, while we could simply annotate the removed preconditions/effects as possible preconditions/effects (as was done in our earlier evaluations), we decided not to do that as RIM cannot use the knowledge about possible preconditions/effects. Instead, we made {a mathematical formula}CPISA make its own annotations in the manner described in Section 9.3. Specifically, {a mathematical formula}CPISA creates its own annotated model by adding all possible predicates that are not already part of the precondition and effects of each operator (provided the operator parameters matches the predicate parameter types). Note that this approach considerably increases the complexity of the problem faced by {a mathematical formula}CPISA, and can be seen as putting it at an unnecessary disadvantage in cases where annotated models are readily available.
      </paragraph>
      <paragraph>
       Once the initial models are fixed, {a mathematical formula}CPISA and RIM are both given the same set of successful cases, as well as a set of test problems. The plans produced by each of the systems for the test problems are evaluated in terms of the estimate of their posterior robustness. Note that while {a mathematical formula}CPISA is starting with an incomplete domain model (which specifies a distribution over the complete candidate models, one of which is guaranteed to be the real model), RIM's initial model is a single model that is incorrect. While {a mathematical formula}CPISA uses the successful cases to modify the “distribution” of the domain models (while retaining the correct model in the distribution), RIM uses the cases to modify the initial model into another (single) new model. The modified model may still be incorrect: it may produce incorrect plan or even no plan for a given problem.
      </paragraph>
      <paragraph>
       In Zenotravel, we created an incomplete domain with 10 missing predicates by randomly removing 6 preconditions and 4 effects from the ground truth. This is converted to an annotated PDDL model with 56 annotations (20 possible preconditions and 36 possible effects), which is equivalent to {a mathematical formula}246=7.03×1013 possible domains. We start with eight cases that were randomly generated, and then we make use of various subsets of this case library. In particular, we use a set of two cases which halves the total number of possible domains, a set of four cases which further cuts it down to {a mathematical formula}1.28×1010, and the complete set which represents a set of {a mathematical formula}3.2×109 domains. We test with 18 planning problems, with each plan generated by {a mathematical formula}CPISA and RIM compared in terms of their posterior robustness estimate.
      </paragraph>
      <paragraph>
       As shown in Fig. 10, Fig. 11, {a mathematical formula}CPISA clearly does better than RIM for smaller number of cases. This is because in the presence of a small number of cases (which means large number of candidate domain models), the probability that the single domain produced by RIM is the ground truth is quite unlikely. In contrast, {a mathematical formula}CPISA, which reasons with the full distribution of candidate domain models, is able to produce plans with high robustness. As the number cases increase however, the case constraints that {a mathematical formula}CPISA has to reason with increases, thereby increasing the computational cost of the robustness estimation it uses during the plan generation. Because of this, in Fig. 12 we see that RIM starts doing better as it is able to access more cases.
      </paragraph>
      <paragraph>
       For Blocksworld, we chose to compare the two approaches using a domain model with 5 missing preconditions and 10 missing effects. The incomplete model was converted to an annotated model with 19 possible preconditions and 32 possible effects (a total of {a mathematical formula}2.2×1015 possible domains) We evaluated both approaches by solving 15 random problems using a set of 5 and 15 randomly produced cases (representing approximately {a mathematical formula}5.1×108 and {a mathematical formula}4.0×107 domains respectively). While {a mathematical formula}CPISA was able to solve all 15 problems (Fig. 13, Fig. 14), we found that the domain produced by RIM was not able to solve any of the given problems. In particular, the modified model learned by RIM is still incorrect, and happened to be incorrect in such a way that all test case problems were unsolvable in that domain.{sup:15}
      </paragraph>
      <paragraph>
       For the Driverlog domain, we created an incomplete model with 8 missing preconditions and two missing effects. This maps into an annotated domain with 21 possible preconditions and 28 possible effects ({a mathematical formula}5.6×1014 possible complete domains). We tested our approach using 10 cases against 10 random problems, with both approaches trying to solve each problem using the first 5 cases (that are consistent with approximately {a mathematical formula}1.6×108 domains) and then using the entire set (approximately {a mathematical formula}4.9×107 possible domains). As seen from Fig. 15, Fig. 16, RIM generally outperforms {a mathematical formula}CPISA for this particular domain.
      </paragraph>
      <paragraph>
       The experiments reported above suggest that {a mathematical formula}CPISA is able to perform better for domains with higher incompleteness and with a lower number of cases (at times even producing plans with robustness value of 1, while RIM failed to produce plans). But we see that RIM starts to perform much better as we are provided more cases. We believe that in general, the RIM approach will start performing better as more cases are provided to it, as RIM is able to learn more and more macro operators. As macro operators are action sequences that were already seen in the plan traces, using these sequences will not add any new constraints and will not reduce the robustness of a plan.
      </paragraph>
      <paragraph>
       Given that the relation between {a mathematical formula}CPISA and RIM is similar to some extent to that between bayesian vs. traditional (maximum likelihood) reinforcement learning, this performance is expected to a certain extent.
      </paragraph>
     </section>
    </section>
   </content>
  </root>
 </body>
</html>