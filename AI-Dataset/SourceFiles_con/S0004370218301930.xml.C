<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Incentive-based search for efficient equilibria of the public goods game.
   </title>
   <abstract>
    The “best-shot” public goods game is a network game, defined on a social network. The simple version of the public goods game (PGG) has a fixed utility for a player who has at least a single neighbor buying the good. Players in the general version of PGG have additional utility when multiple neighbors purchase the good. The general version of the public goods game is shown to be a potential game, establishing the convergence to a stable state (i.e., a pure Nash equilibrium – PNE) by best-response dynamics. One can think of best-response dynamics as a distributed algorithm that runs in a fixed order of players/agents and is guaranteed to converge to a PNE. A new distributed algorithm is proposed for finding PNEs with improved efficiency by the use of transfer of payoffs among players. For the simple version of PGG, it is shown that the proposed algorithm can stabilize an outcome that maximizes social welfare. For the general version of the game, the proposed procedure transforms any initial outcome into a stable solution at least as efficient as the initial outcome by using transfers. An extensive experimental evaluation on randomly generated PGGs demonstrates that whereas pure best-response dynamics converges on stable states that have lower efficiency than the initial outcome, the proposed procedure finds PNEs of higher efficiency.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      In graphical games [1], played on a social network, the utilities of players depend both on their own actions and on the actions taken by their neighbors in the network. A well known example of network games are “best-shot” public goods games (PGGs) [2], [3], in which players share common goods. Each player chooses whether to take some action or avoid it. The action is associated with an investment in some local public good. The action might be in the form of performing some computational effort, where computation results can be easily shared locally. It can also be the buying of a book or some other product that is easily lent from one player to another. Each player wants to have at least one player in her neighborhood taking the action, including herself. However, there is a cost associated with taking the action, so if some of the player's neighbors take the action then the player would prefer to avoid it [4].
     </paragraph>
     <paragraph>
      There are several versions to the public goods game. The simplest and most common one has a fixed price across all players for the buying of the good and a fixed utility for a player who has at least a single neighbor buying the good [2], [3]. More complex versions have different costs of buying the good for different players and an increasing utility for players with more than a single neighbor that buy the good [5]. One may interpret this increasing utility as a shorter waiting time for using the good by the player, when a larger number of its neighbors buy the good (cf. [3]). Most former studies address the simple version of the PGG, where finding efficient equilibria is equivalent to finding a maximal independent set of vertices in the network [6]. Consequently, the finding of a Pure-strategy Nash Equilibrium (PNE) in the simple version is well studied.
     </paragraph>
     <paragraph>
      However, when one moves to the general version of PGG, which is at the focus of the present study, equilibria are no longer correlated with the independent sets of the network. The multiplicity of PNEs in a PGG drove the study of Galeoti et al. [7] to consider Bayesian NEs, instead of PNEs. Alternatively, the present paper focuses on distributed search algorithms for improved-efficiency PNEs of the general version of the PGG.
     </paragraph>
     <paragraph>
      The present article has evolved from a paper that was published in the WI-IAT conference [8], which focused only on the simple version of the PGG. For the simple version it was shown that the game is an ordinal potential game, and that every PNE is Pareto optimal [8]. On a different theme, it has been shown in [8] that the optimal state of the simple version of the PGG (e.g., with the largest social welfare) can be stabilized by the use of transfer of payoffs. The present article deals with the general version of the PGG, and among other contributions, provides a distributed algorithm for finding improved-efficiency PNEs that did not appear in [8].
     </paragraph>
     <paragraph>
      The present study proves that all versions of the public goods game are potential games, by constructing a non-trivial potential function for the general version of the PGG (see Section 3.1). It follows that the best-response dynamics is guaranteed to converge to a PNE (cf. [9], [10]). For the general version of the PGG it is shown that convergence of best-response dynamics is guaranteed in up to {a mathematical formula}2⋅K⋅n2 steps, where n is the number of agents in the PGG network and {a mathematical formula}K is the largest number of neighbors from which a player can benefit in the general version of PGG (see Sections 2 and 3). This forms a non trivial extension to the results for the simple version of PGG in [8].
     </paragraph>
     <paragraph>
      Typically, there are many PNEs in a public goods game [5], [11]. This has lead former studies to consider networks with a very specific utility function that entails a unique PNE [5]. Or, on a different theme, consider probabilistic stable states (i.e., Bayesian NE) on networks with partial information for players [7]. Equilibria of PGG with a certain form of achieving higher social welfare have been also found to be stable to perturbations [12]. Interestingly, experimental studies demonstrate that people playing these games seem to favor equilibria of high social welfare [11].
     </paragraph>
     <paragraph>
      On the theme of real world versions of the public goods game on a network, Boncinelli et al. [12] propose a typical problem of car pool grouping on a social network. Similarly to many PGGs, the game incorporates multiple Nash equilibria that correspond to different stable car-pools on the social network. True to a real world example, the efficiencies of the different equilibria differ widely and the resulting pollution depends on the structure and graph of the social network. The present paper shows (in Section 3) that by using a simple distributed search algorithm like best response, the car pool grouping seekers on a social network can within a bounded number of rounds find a stable solution to the problem. The proposed new algorithm is shown (in Section 6) to guarantee an equilibrium of higher social welfare to the problem of car pool grouping on a social network (that, say, minimizes pollution) by using the mechanism of side-payments.
     </paragraph>
     <paragraph>
      PNEs with high social welfare are commonly considered to be efficient, but finding a PNE with a maximal social welfare (SW) is computationally intensive [3]. Since general PGGs are potential games, one can achieve stability by using best-response dynamics as a distributed search algorithm performed by all agents in a fixed order, which is guaranteed to converge to a stable outcome. The natural next step is at the focus of the present study – to design a distributed algorithm for PGG players that converges to an efficient PNE (of high social welfare). Since efficient outcomes of PGG are not necessarily stable, the tradeoff between efficiency and stability motivates the use of an incentive mechanism to promote stability in efficient states (see Section 4).
     </paragraph>
     <paragraph>
      A possible approach for incentivizing unsatisfied players to agree on some preferred outcomes is to use transfers of payoffs among the players. Transfers of payoffs (e.g., money) take place between players, such that players who gain from some outcome may want to pay others that are unsatisfied by it. Transfers of payoffs can help promote efficiency by providing incentives to some players for seeing more fully the impact of their actions [13]. This is an important result of Jackson and Wilkie [13] who studied the efficiency of equilibria that are achieved by using side payments among the players. The present study continues this line of research by exploiting the machinery of transfer functions (side payments) and combining it with a search algorithm, in order to find efficient equilibria for the public goods game.
     </paragraph>
     <paragraph>
      For the simple version of PGG, where a single copy of the public good produces the maximal utility for all neighbors, a distributed iterative procedure is proposed for finding efficient PNEs. The proposed procedure works on any initial arbitrary outcome, not necessarily stable. Transfers of payoffs are used in order to ensure stability. The resulting outcome is ensured to be at least as efficient as the original outcome and it is shown that the proposed procedure can stabilize the optimal outcome of a PGG (i.e., of highest social welfare). This is in contrast to the work of DallAsta et al. [14], that use simulated annealing to search for an optimal outcome but does not guarantee finding it in finite time. In the second stage of the proposed procedure the new outcome is transformed into a PNE by applying the transfers of payoffs among the players. All transfers are contracted by the agents during the run of the iterative improvement procedure in the first stage of the algorithm. In this respect the proposed distributed algorithms represent a multi-agents (multi-players) procedure that can be embarked upon in a distributed manner and produce a not-worse outcome for all participants.
     </paragraph>
     <paragraph>
      For the general version of PGG an analogous distributed iterative procedure is proposed in Section 5. It uses transfers of payoffs to ensure stability and is guaranteed to converge to a PNE, but not necessarily of improved efficiency. The proposed algorithm is guaranteed to converge to a PNE within {a mathematical formula}2⋅K⋅n2 steps at most, where n is the number of agents and {a mathematical formula}K is the maximal number of accessible public goods from which an agent can benefit (see Section 2). An extensive empirical evaluation on randomly generated general PGGs demonstrates that while best-response dynamics converge to PNEs of lower efficiency than the original outcome, the proposed iterative improvement algorithm, which uses transfers of payoffs, converges to PNEs of improved efficiency.
     </paragraph>
     <paragraph>
      The plan of the paper is as follows. In Section 2 all versions of the public goods game are defined formally. Section 3 proves the first main contribution of the paper – that the general version of the PGG is a potential game, implying the convergence of best-response dynamics to a PNE. The efficiency of PNEs of public goods games is presented and discussed in Section 4. In order to find efficient PNEs for the public goods game, Section 5 presents the mechanism of transfer functions and Section 6 proposes the second main contribution of the paper – an innovative iterative improvement algorithm for finding PNEs of improved efficiency, which uses transfers of payoffs. The algorithm for the simple version of PGGs is proven to secure improved-efficiency equilibria. An extensive experimental evaluation and discussion are given in Section 7 and demonstrate the improved efficiency of PNEs resulting from the proposed algorithm, over those achieved by best-response dynamics. Section 8 summarizes our conclusions.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      The game model
     </section-title>
     <paragraph>
      A common and compact representation for network games is the graphical model proposed by Kearns et al. [1]. This model assumes that each player interacts with only a limited number of players (her neighbors). It is natural to think that a network game is based on some underlying graph describing the players' interactions network.
     </paragraph>
     <paragraph>
      The present study focuses on the “best-shot” public goods game [7], [14], [15], which is a well known example of a network game. A PGG is composed of a finite set of players {a mathematical formula}N={1,…,n} that are connected by a network {a mathematical formula}G={N,E}. Each vertex in G represents a player, and the edges E represent the interaction structure of the game. Given a player {a mathematical formula}i∈N, the set of i's neighbors is denoted by {a mathematical formula}Ni; these are the players whose actions impact i's payoff. The neighborhood of i is the set {a mathematical formula}{i}∪Ni.
     </paragraph>
     <paragraph>
      In the “best-shot” public goods game each player chooses an action {a mathematical formula}vi∈Vi where the set of possible actions is {a mathematical formula}Vi={T,F}. The choice {a mathematical formula}vi=T denotes taking the action (i.e., investment in some local public good), whereas the choice {a mathematical formula}vi=F represents avoiding action. An outcome, {a mathematical formula}v=(v1,…,vn)∈V1×…×Vn, is a collection of choices, one for each player.
     </paragraph>
     <paragraph>
      Taking the action by player i comes with a cost {a mathematical formula}0&lt;Ci&lt;1. Therefore, player i will try to avoid taking the action if possible. Obtaining the use of the local public good is essential for each player in the “best-shot” public goods game. Specifically, each player wants that either one of her neighbors will invest in a local public good or that she will take the action herself. In both cases the player obtains access to the public good.
     </paragraph>
     <paragraph>
      It is convenient to define distinct states of a player {a mathematical formula}i∈N (at outcome v). These states are defined as follows:{a mathematical formula} where l denotes the number of neighbors that choose to invest in the local public good (i.e., the number of {a mathematical formula}k∈Ni,vk=T). The state {a mathematical formula}Fl (of player i) denotes that the player avoids taking the action ({a mathematical formula}vi=F) and has exactly l neighbors that take the action. If the player is taking the action and has exactly l neighbors that also invest in the local public good, then the player's state is {a mathematical formula}Tl.
     </paragraph>
     <paragraph>
      Given the definition of players' states, the utility of player i for outcome v is defined as follows:{a mathematical formula} Here, {a mathematical formula}K defines the maximal number of players in i's neighborhood which can affect player i's utility. In other words, the player's utility grows with the number of players in her neighborhood that take the action, up to a limit of {a mathematical formula}K. Consequently, the tuple {a mathematical formula}〈G,K,C1,…,Cn〉 defines a “best-shot” public goods game where G is an underlying interactions network, {a mathematical formula}K is the maximal number of public goods that can affect i's utility and {a mathematical formula}C1,…,Cn are the costs for each player for taking the action.
     </paragraph>
     <paragraph>
      Most previous studies of equilibria of the PGG [7], [14], [15], [8] dealt with the simplified version of the “best-shot” public goods game. In the simplified version the costs for taking the action are equal for all players (i.e., {a mathematical formula}∀i∈N,Ci=C) and the number of public goods that each player can benefit from accessing to is limited to 1 (i.e., {a mathematical formula}K=1). In such a case, the utility of player i for some outcome {a mathematical formula}v∈V1×…×Vn can be simplified to:{a mathematical formula}
     </paragraph>
     <paragraph>
      The next section shows that the general version of the public goods game is an ordinal potential game. This implies the use of better-response dynamic for reaching a stable (equilibrium) state (Section 3). When addressing the efficiency of equilibria, an innovative procedure for finding efficient pure Nash equilibria (PNE) in the public goods game is described in Section 5.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Stability of the public goods game
     </section-title>
     <paragraph>
      The Pure Nash Equilibrium (PNE) is a central concept in game theory. An outcome is a PNE, if every player does not prefer to change her strategy, given the strategies of all other players in this outcome. Formally, an outcome v is a PNE if the following holds:{a mathematical formula} where {a mathematical formula}v−i is the standard notation for the combined strategies of all players except i. It is easy to see that the states {a mathematical formula}Tl&lt;K and {a mathematical formula}Fl≥K are stable. A player in one of these states has no incentive to change her strategy unilaterally. The states {a mathematical formula}Tl≥K and {a mathematical formula}Fl&lt;K are not stable. A player in state {a mathematical formula}Fl&lt;K would prefer to change her strategy to T, whereas a player in state {a mathematical formula}Tl≥K would prefer to change her strategy to F.
     </paragraph>
     <paragraph>
      In the next subsection it is shown that the general version of the public goods game is an ordinal potential game [9], [10]. This implies that a best-response procedure converges to a PNE.
     </paragraph>
     <section label="3.1">
      <section-title>
       A potential game perspective
      </section-title>
      <paragraph>
       The concept of a potential game is used to define games in which the change in players' utilities corresponds to the change in some global potential function[9], [10]. Since the incentives of all players are mapped into a global potential function, it can be a useful tool to analyze the attributes of equilibria states of the game, as will be demonstrated below.
      </paragraph>
      <paragraph>
       A game is an ordinal potential game if there exists a (potential) function {a mathematical formula}Φ:V1×...×Vn→R such that {a mathematical formula}∀v∈V1×...×Vn,∀vi′∈Vi it holds that{a mathematical formula} Namely, in (ordinal) potential games the sign of the difference of individual payoffs for each player that arises from individually changing one's strategy (ceteris paribus) has the same sign as the difference in values of these states in the potential function.
      </paragraph>
      <paragraph>
       In order to show that PGG is an ordinal potential game, one must provide a global potential function and then prove that the properties of the global potential function (as given in Equation (5)) hold. We term such a potential function as viable. Consider a global function of the form{a mathematical formula} where {a mathematical formula}φi(v) denotes the share of player i in the global potential function in outcome v. An intuitive and simple version of {a mathematical formula}φi(v) was proposed for the simplified version of the “best-shot” public goods game in a former paper [8]:{a mathematical formula}
      </paragraph>
      <paragraph>
       Equations (6) and (7) have been proven to form a potential function for the case of {a mathematical formula}K=1[8]. Consider a naive generalization of Equation (7) for {a mathematical formula}K≥2:{a mathematical formula}
      </paragraph>
      <paragraph>
       Let us see why Equations (6) and (8) no longer form a viable potential function, even for the case of {a mathematical formula}K=2. Consider the case were agent i is in state {a mathematical formula}statei(v)=Fl, having a single neighbor j in state {a mathematical formula}statej(v)=T1. Agent i's strategy change from {a mathematical formula}vi=F to {a mathematical formula}vi=T results in an increment of {a mathematical formula}1−C in its utility, but has a negative effect on the global potential. The change in agent i's potential share is {a mathematical formula}1−C, while the change in j's potential share is -1. Consequently, the total change in the global potential equals {a mathematical formula}−C which contradicts Equation (5).
      </paragraph>
      <paragraph>
       Since the potential function of Equation (7) cannot be naturally extended to fit the requirements for the general version of PGG, the new definition of the potential share is presented below together with an intuition regarding its correctness. The revised definition of the function {a mathematical formula}φi(v) is the following:{a mathematical formula} where {a mathematical formula}a,b and Δ are positive constants. Let us examine Figs. 1a, 1b and 1c that represent all possible state transitions of players in a PGG with {a mathematical formula}K=2. The purpose of these figures is to generate some intuition for the reasons of Equations (6) and (9) and the values of the constants {a mathematical formula}a,b and Δ to form a viable global potential function.
      </paragraph>
      <paragraph>
       Recall that transitions of state occur when a player chooses to change her strategy, given the choices of her neighbors. The set of the possible state transitions corresponds to the maximal number of neighbors of the player. Figs. 1a, 1b and 1c present all possible transitions for a player in games with at most {a mathematical formula}1,2 or 3 neighbors respectively (i.e., the maximal degree of nodes in the underlying graph is 1, 2, or 3).
      </paragraph>
      <paragraph>
       The states in Fig. 1 follow the notation in Equation (1). The edges (arrows) represent transitions among the states. Green arrows represent the change in the state of a player whose utility improved due to a change of her own strategy. All other edges represent state changes of a player due to a change of strategy by one of their neighbors. Only state transitions that change the share of a player in the global potential function (i.e., green/red/blue edges) are considered.{sup:1}
      </paragraph>
      <paragraph>
       Consider Fig. 1a, which consists of only two possible strategy changes made by a player i that improve the player's own utility (i.e., from {a mathematical formula}F0 to {a mathematical formula}T0 and from {a mathematical formula}F1 to {a mathematical formula}T1). The change in the global potential due to the transition from state {a mathematical formula}F0 to {a mathematical formula}T0 equals {a mathematical formula}b−a. This stems from the fact that i's share of potential at state {a mathematical formula}T0 equals b and the share of the potential at state {a mathematical formula}F0 equals a. Since player i (which performs the change) has no other player in her neighborhood performing actions, this is the only change to the global potential. Therefore, in order to fulfill the requirements of the global potential function (Equation (5)) it must have {a mathematical formula}b−a&gt;0, i.e., {a mathematical formula}b&gt;a.
      </paragraph>
      <paragraph>
       The other state transition that improves the utility of a player, from {a mathematical formula}F1 to {a mathematical formula}T1; results in a change of {a mathematical formula}b−Δ−a to the potential share of player i that changed her strategy. Player i has exactly one neighbor that performs the action, therefore player i's change of strategy changes the neighbor's share in the global potential by exactly −Δ. Combined with the incurred change of {a mathematical formula}b−Δ−a to the share of player i, the total change to the global potential is exactly {a mathematical formula}b−Δ−a−Δ, which in turn must be greater than 0 in order to satisfy the requirements of the global potential function. To summarize, it must hold that {a mathematical formula}b&gt;a and {a mathematical formula}Δ&lt;b−a2.
      </paragraph>
      <paragraph>
       By observing the state transitions for graphs with a maximal vertex degree of 2 (Fig. 1b), it is easy to see that both of the previous constraints (i.e., {a mathematical formula}b&gt;a and {a mathematical formula}Δ&lt;b−a2) must hold, for the same reasons. An additional strategy change that improves the player's utility is from {a mathematical formula}T2 to {a mathematical formula}F2. The dashed line represents the border above which improving strategy changes are from {a mathematical formula}T to {a mathematical formula}F. Such a transition results in a change to the global potential of {a mathematical formula}a−b+2⋅Δ+2⋅Δ. This follows from the fact that the change to the potential share the player i that changed her strategy is {a mathematical formula}a−b+2⋅Δ and the player has exactly two neighbors performing action, each of which adds Δ to her share in the global potential. Therefore, in order to satisfy the requirements of the global potential function, the inequality {a mathematical formula}a−b+4⋅Δ&gt;0 (i.e., {a mathematical formula}Δ&gt;b−a2) must hold.
      </paragraph>
      <paragraph>
       Fig. 1c adds a single strategy change that improves the player's utility, to those of Fig. 1b. As a result, all previously defined constraints must still hold. The additional strategy change, from {a mathematical formula}T3 to {a mathematical formula}F3, leads to an additional inequality {a mathematical formula}a−b+6⋅Δ&gt;0. This constraint is satisfied by all the values of a, b and Δ, which satisfy the inequality {a mathematical formula}Δ&gt;b−a4, due to the fact that {a mathematical formula}Δ&gt;0 and {a mathematical formula}b&gt;a. Consequently, for graphs with maximal vertex degree of 3, the inequalities {a mathematical formula}a&lt;b and {a mathematical formula}b−a4&lt;Δ&lt;b−a2 must hold in order to satisfy the requirements of the global potential function.
      </paragraph>
      <paragraph label="Proof">
       For any values of{a mathematical formula}a,band Δ for which it holds that{a mathematical formula}a&lt;band{a mathematical formula}b−a2⋅K&lt;Δ&lt;b−a2⋅(K−1), the function{a mathematical formula}Φ(v)(define by Equation(6)) is a global potential function.{sup:2}First, assume that {a mathematical formula}ui(vi′,v−i)−ui(vi,v−i)&gt;0 i.e., player i performs an improving step (moves from {a mathematical formula}vi to {a mathematical formula}vi′). An improving step can occur if either the player's state before performing the step is {a mathematical formula}Fl&lt;K or that the player's state is {a mathematical formula}Tl≥K.If the initial state of the player performing an improving step is {a mathematical formula}Fl, it means she has exactly l neighbors performing the action and therefore the change to the player's share in the global potential is {a mathematical formula}b−l⋅Δ−a, whereas the change to the global potential resulting from her neighbors' shares is {a mathematical formula}−l⋅Δ. Consequently, {a mathematical formula}b−2⋅l⋅Δ−a must be greater than 0. Specifically, if l equals 0, then the inequality {a mathematical formula}b&gt;a must hold. Otherwise, Δ must be less than {a mathematical formula}b−a2⋅l. Since inequality {a mathematical formula}Δ&lt;b−a2⋅l should hold for every {a mathematical formula}l&lt;K, one can conclude that {a mathematical formula}Δ&lt;b−a2⋅(K−1). Note that in case {a mathematical formula}K=1 the only possible value of {a mathematical formula}l&lt;K is {a mathematical formula}l=0, thus only the inequality {a mathematical formula}b&gt;a is relevant.The other improving step is from state {a mathematical formula}Tl. The transition from state {a mathematical formula}Tl to {a mathematical formula}Fl causes a change of {a mathematical formula}a−b+l⋅Δ to the player's own share in the global potential. The change to the global potential that arises from her neighbors' shares equals {a mathematical formula}l⋅Δ, since the player has exactly l neighbors performing the action. To conclude, Δ must be greater than {a mathematical formula}b−a2⋅l. Since this inequality must hold for every {a mathematical formula}l≥K, one can conclude that {a mathematical formula}Δ&gt;b−a2⋅K.For the opposite direction, assume {a mathematical formula}ui(vi′,v−i)−ui(vi,v−i)≤0 and show that {a mathematical formula}Φ(vi′,v−i)−Φ(vi,v−i)≤0 similarly to the first direction. □
      </paragraph>
      <paragraph>
       The above potential function has an interesting feature: its global maximum is not only a PNE (as every local maximum of the potential function), but it is also the PNE with the lowest social welfare of all PNEs. To see this feature, observe first that in any optimum of the potential function players can only be in state {a mathematical formula}Tl&lt;K or in state {a mathematical formula}Fl≥K. Consider the inequality of Proposition 1{a mathematical formula} Combining this inequality with the fact that players in local maxima of the potential function (i.e., PNEs) are in state {a mathematical formula}Tl&lt;K, one can conclude that each player in state {a mathematical formula}Tl contributes more to the potential than a player in state {a mathematical formula}Fl (i.e., {a mathematical formula}b−l⋅Δ&gt;a). This in turn implies that the global maximum of the potential function occurs for a state with the maximal number of players performing the action, out of all stable states of the game. However, this is the state with the lowest social welfare out of all PNEs, because in the stable state the utility of a player in state {a mathematical formula}Tl is lower than the utility of a player in state {a mathematical formula}Fl.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Complexity of better response dynamics
      </section-title>
      <paragraph>
       The fact that the “Best-shot” public goods game is a potential game results in convergence of the better-response dynamics. In the general case the convergence of better-response dynamics is computationally intractable [16], but there are several specific cases for which the convergence to a stable point is polynomial in the number of players [17]. Therefore, it is interesting to bound the run-time of better response in the “Best-shot” public goods games. This can actually be done in a straightforward way because the difference between the maximal and minimal values of the potential function can be easily bounded and so can the size of the change in the potential function value at each better response step.
      </paragraph>
      <paragraph label="Proof">
       The difference between the maximal and minimal values of the potential function, which was defined by Equations(6)and(9), is bounded by{a mathematical formula}n2⋅(b−a).The share of a player i in the global potential function depends on the player's state and equals a if her state is {a mathematical formula}Fl or {a mathematical formula}b−l⋅Δ otherwise. Consequently, the maximal value of such a share is {a mathematical formula}max⁡(a,b−l⋅Δ), whereas the minimal value is {a mathematical formula}min⁡(a,b−l⋅Δ). One can easily observe that the inequation {a mathematical formula}b−l⋅Δ≤b holds since {a mathematical formula}l≥0 and {a mathematical formula}Δ&gt;0; such an observation, together with the fact that {a mathematical formula}a&lt;b (Proposition 1), leads to:{a mathematical formula} Namely, the upper bound on a share of a single player in the global potential function is b.The lower bound of the player's share {a mathematical formula}min⁡(a,b−l⋅Δ) in the global potential function can be evaluated by the help of the following inequation:{a mathematical formula}Given the previous observations, one can evaluate the upper bound of the global potential function by the following equation:{a mathematical formula} whereas the lower bound can be evaluated as follows:{a mathematical formula} Consequently, the difference between the maximal and minimal values of the global potential function is:{a mathematical formula} □
      </paragraph>
      <paragraph label="Proof">
       The minimal improvement in the global potential, resulting from a better response step, is{a mathematical formula}b−a2⋅K.There are two types of improving steps when applying better-response dynamics to a PGG – from F to T if player i's state is {a mathematical formula}Fl&lt;K and from T to F if {a mathematical formula}statei(v)=Tl≥K. For the sake of clarity we will first consider the case {a mathematical formula}K≥2 and refer to the adjustments for the {a mathematical formula}K=1 case subsequently. In case {a mathematical formula}K≥2, Proposition 1 restricts the value of Δ to be in the range {a mathematical formula}b−a2⋅K&lt;Δ&lt;b−a2⋅(K−1). Let us fix the value of Δ to be {a mathematical formula}(b−a)⋅2⋅K−14⋅(K−1)⋅K, which is the center of the restricted range.Consider the case that the player's state, before changing her strategy, is {a mathematical formula}Fl&lt;K. In such a case, the change in the global potential, is {a mathematical formula}b−a−2⋅l⋅Δ. Since the upper bound of l is {a mathematical formula}K−1 and Δ is positive, the following inequality holds:{a mathematical formula}A change to the global potential of {a mathematical formula}a−b+2⋅l⋅Δ will occur if the player's state before the strategy update is {a mathematical formula}Tl≥K. Such a change results in the following inequality:{a mathematical formula}Consequently, the minimal improvement to the global potential, as a result of a better-response step, is {a mathematical formula}b−a2⋅K when {a mathematical formula}K≥2.In case {a mathematical formula}K=1 the only possible value of l is zero when the player's state is {a mathematical formula}Fl&lt;K, which makes Equation (14) trivial. If the player's state before the strategy update is {a mathematical formula}Tl≥K, the value {a mathematical formula}Δ=b−a can be used to obtain the lower bound of {a mathematical formula}b−a2⋅K. □
      </paragraph>
      <paragraph label="Corollary 4">
       Better-response dynamics for the “best-shot” public goods game converges in at most{a mathematical formula}2⋅K⋅n2improvement steps.
      </paragraph>
      <paragraph>
       The maximal number of improvement steps can be computed by dividing the maximal difference of the values of the potential function (i.e., {a mathematical formula}n2⋅(b−a)) by the minimal improvement in the potential from any improvement step (i.e., {a mathematical formula}b−a2⋅K). Therefore, the correctness of Corollary 4 is a direct result of Proposition 2, Proposition 3.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Equilibrium efficiency vs. stability
     </section-title>
     <paragraph>
      The fact that the general version of the “best-shot” public goods game is a potential game guarantees the existence of at least one PNE for each game. However, it is possible that a game will have multiple equilibria. Consider the example of a PGG that is based on the underlying graph depicted in Fig. 2, where {a mathematical formula}K=3 and the costs of performing the action are equal for all players (i.e., {a mathematical formula}∀i∈N,Ci=C). The underlying graph consists of a clique, involving exactly {a mathematical formula}K=3central players (represented by solid nodes), and a set of eight peripheral players (represented by dashed nodes), each of which is connected to all the nodes of the clique.
     </paragraph>
     <paragraph>
      It is easy to see that the above PGG has exactly two equilibria states. In one stable state all central players choose T as their strategy, while all peripheral players choose F. In the other stable state all central players choose F, while all others choose T. The social welfare of the first PNE is {a mathematical formula}3⋅(3−C)+8⋅3=33−3⋅C, whereas the second PNE has a social welfare of {a mathematical formula}3⋅3+8⋅(3−C)=33−8⋅C. From a global perspective, the network as a whole is better off in the first outcome, which maximizes social welfare (SW). We relate to such an outcome as an efficient one.
     </paragraph>
     <paragraph>
      Naturally, one would like to address the question of the efficiency of the outcomes that are produced by better-response dynamics. In particular, it is interesting to compare their efficiency to that of the stable outcome that maximizes social welfare. This relates closely to the concept of Price of Anarchy (PoA)[18]. The price of anarchy measures the bound on the degradation of the efficiency of a system due to the selfish behavior of its agents. It is defined to be the ratio between the optimal solution (i.e., of maximal SW) and the worst equilibrium:{a mathematical formula} The PoA of the above example of a PGG is{a mathematical formula} following directly from the fact that {a mathematical formula}0&lt;C&lt;1. It is easy to see that the first equilibrium above is the most efficient outcome of the game. Given the configuration of Fig. 2 with an unboundedly large number of peripheral players, the limit of the PoA is {a mathematical formula}K(K−1), and can be unboundedly large for {a mathematical formula}K=1.
     </paragraph>
     <paragraph>
      Another interesting concept regarding the relationship between efficiency and stability is that of the Price of Stability (PoS)[18]. The price of stability measures the ratio between the optimal solution and the best equilibrium:{a mathematical formula} PoS conveys the efficiency gap between the globally most efficient outcome and the most efficient stable outcome.
     </paragraph>
     <paragraph>
      To get some intuition about the price of stability of a PGG one can use the graph depicted in Fig. 3 and assume that the costs of all actions are equal {a mathematical formula}∀i∈N,Ci=C. The players participating in the game can be split into two distinct groups {a mathematical formula}N1 and {a mathematical formula}N2 of equal size so that {a mathematical formula}N1∪N2=N, {a mathematical formula}N1∩N2=∅ and {a mathematical formula}|N1|−|N2|≤1. For each group one can create a graph like Fig. 2 where an edge exists between every two central players of both groups. The overall graph in Fig. 3 depicts the case with {a mathematical formula}|N|=22 and {a mathematical formula}K=3. For this case the optimal outcome has a social welfare of {a mathematical formula}2⋅K⋅(K−C)+(|N|−2⋅K)⋅K. Clearly, this outcome is not stable, as any of the central players could improve her utility by not performing the action. When considering any stable outcomes, the social welfare of the most efficient PNE is {a mathematical formula}K⋅(K−C)+(|N|2−K)⋅K+(|N|2−K)⋅(K−C)+K⋅K. The most efficient PNE has one group in which the central players take the action and let all their peripheral players gain the most, and another group in which only the peripheral players take the action and let the central players gain the most. The price of stability in this case is therefore:{a mathematical formula}
     </paragraph>
     <paragraph>
      It is easy to see from Equation (19) that if the number of the participating agents {a mathematical formula}|N| is unboundedly large, then the limit of the PoS is {a mathematical formula}1+C2⋅K−C&lt;32. Both of the above examples serve to demonstrate that there is still a wide efficiency gap (up to 50% in the last example) between the globally most efficient outcome and the most efficient stable outcome. This gap can be thought of as the tradeoff between efficiency and stability. Nevertheless, this gap can be bridged by the algorithm proposed in the next sections.
     </paragraph>
    </section>
    <section label="5">
     <section-title>
      Finding efficient equilibria – preliminaries
     </section-title>
     <paragraph>
      Despite the efficiency gap that was described in the previous section one may be able to find efficient equilibria in the “best-shot” public goods game by using an extended version of better-response dynamics. In the extended scenario each player is endowed with the ability to propose a payoff transfer at each step, in response to a neighbor's proposal of her better response. For the simple version of the PGG where {a mathematical formula}K=1, it is shown next that the players' ability to propose payoff transfers enables the extended version of better-response dynamics to converge to a stable state of greater (or equal) efficiency than that of the initial, not necessarily stable, outcome. When the extended better-response dynamics is applied to the general version of PGG ({a mathematical formula}K≥2), there is no such theoretical guarantee for the efficiency. Nevertheless, our experimental evaluation in Section 7 demonstrates that in practice the efficiency is improved for all the evaluated game instances.
     </paragraph>
     <paragraph>
      The following subsection describes the mechanism of transfers of payoffs among players, which is a key element in the stability enforcing algorithm that is presented in Section 6. Next, a novel stability enforcing procedure that relies on transfers of payoffs is proposed. Finally, it is shown how this procedure may be complemented by existing heuristics that find initial outcomes of high efficiency. These components form the complete procedure for finding efficient PNEs in the “best-shot” public goods game.
     </paragraph>
     <section label="5.1">
      <section-title>
       Transfers of payoffs
      </section-title>
      <paragraph>
       Transfers of payoffs enable “best-shot” public goods games to be transformed from the inside, by endowing players with the possibility of sacrificing part of their payoff in order to convince other players to play a certain strategy. The transfer function between players enables each player to pay (or receive payment from) each one of its neighbors [13].
      </paragraph>
      <paragraph>
       Given a “best-shot” public goods game with an underlying interactions network {a mathematical formula}G={N,E}, let us define the transfer function {a mathematical formula}τ:N×N×V1×…×Vn⟶R+ so that {a mathematical formula}τi,j(v) denotes the payment being transferred from player i to player j if outcome v is played. In order to take the transfer of payoffs into consideration while deciding on the action to take, a player's utility must also reflect the change in her payoff caused by the transfers. The net loss that is incurred on player i in outcome v when using the transfer function τ is defined as follows:{a mathematical formula} We restrict our attention to transfer functions from neighbors, that is, if {a mathematical formula}j∉Ni then {a mathematical formula}∀v∈V1,…,Vn:τi,j(v)=0.
      </paragraph>
      <paragraph>
       The introduction of transfers of payoffs leads to an updated definition of the utility that player i obtains from outcome v (given a transfer function τ):{a mathematical formula}
      </paragraph>
      <paragraph>
       Since the use of transfers of payoffs is motivated by the attempt to secure a stable state (PNE) with certain properties, it is required to differentiate between outcomes that can be transformed into a PNE by the use of transfers of payoffs from those that can not.
      </paragraph>
      <paragraph label="Definition 1">
       An outcome v is side-payments enforceable (SPE) if there exists a transfer function τ, such that:{a mathematical formula}
      </paragraph>
      <paragraph>
       Let us explain the intuition behind the ability of transfers of payoffs to obtain efficient outcomes: A player can offer a neighboring player compensation, which relies on the second player's action, such that the compensation effectively reflects any impact that the second player's action has on the first (paying) player's utility. Take for example the following case, in which the benefit to player i is x if player j takes action {a mathematical formula}vj′ rather than action {a mathematical formula}vj (i.e., {a mathematical formula}ui(vj′,v−j)−ui(vj,v−j)=x). Assume also that the cost to player j for taking action {a mathematical formula}vj′ rather than {a mathematical formula}vj is only y (i.e., {a mathematical formula}uj(vj,v−j)−uj(vj′,v−j)=y) where {a mathematical formula}x&gt;y. Consider a transfer of payoff z, where {a mathematical formula}x≥z≥y, by player i to player j in case player j plays {a mathematical formula}vj′ instead of {a mathematical formula}vj (i.e., {a mathematical formula}τi,j(vj′,v−j)=z). Any z such that {a mathematical formula}x≥z≥y will provide a sufficient incentive for player j to take the action {a mathematical formula}vj′, because{a mathematical formula} Additionally, player i has a sufficient incentive to secure the transfer of payoff z to player j due to the fact that{a mathematical formula}
      </paragraph>
      <paragraph>
       In a “best-shot” public goods game a player i has an incentive to compensate its neighbor j only in case player j benefits from deviation from its strategy T. In this case j's deviation (from strategy T to F) affects i's utility, and the payoff loss incurred to player i is 1 (according to Equation (2)). Therefore, the utility loss of player i, termed {a mathematical formula}ℓi, which can be thought of as the maximal payment (i.e., transfer of payoff) that player i may be willing to sacrifice in order to convince player j to stay with strategy T is defined as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       In the case of {a mathematical formula}statei(v)=Tl&lt;K the change of j's strategy from T to F will decrease i's payoff by 1. This arises from the fact that before player j changes its strategy the utility of player i is {a mathematical formula}ui(v)=l+1−Ci, while after j's change of strategy it will be decreased to {a mathematical formula}ui(vj=F,v−j)=l−Ci. Therefore, player i is willing to secure a payoff of at most 1 to player j. Similarly to the previous case, if {a mathematical formula}statei(v)=Fl&lt;K, player i's utility will be also decreased by 1, which results in i's willingness to propose a payoff of at most 1 to player j in order to convince player j to stay with its choice T. When {a mathematical formula}statei(v)=FK, j's change of strategy from T to F will decrease i's payoff to {a mathematical formula}K−1. But i's utility may be increased to {a mathematical formula}K−Ci by its own unilateral deviation to T, in a following step. Therefore, the maximal payoff that player i will be willing to secure for player j is {a mathematical formula}Ci.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Stability enforcing algorithm
     </section-title>
     <paragraph>
      The stability enforcing algorithm is composed of two consecutive stages. Starting from an initial outcome v, the first stage finds an improved outcome {a mathematical formula}v⁎ that is guaranteed to be SPE. In other words, {a mathematical formula}v⁎ is an outcome for which there exists a transfer function τ that transforms it into a stable state. Such a transfer function can be efficiently found by the algorithm. In the second stage the computed transfers to {a mathematical formula}v⁎ are applied and the improved outcome is transformed into a stable state (i.e., a PNE).
     </paragraph>
     <section label="6.1">
      <section-title>
       The simple version of PGG
      </section-title>
      <paragraph>
       Algorithm 1 conducts the first stage for the simple version of PGG, where {a mathematical formula}K=1. Similarly to standard better response, it is assumed that the players of the game play in some fixed and predefined order. Each player in its turn executes the {a mathematical formula}onStrategySelect() procedure that deals with unstable states ({a mathematical formula}F0 and {a mathematical formula}Tl≥1). The procedure ensures that each player i in state {a mathematical formula}Tl≥1 will change its strategy to F, except in cases where other players have incentive and sufficient funds to convince player i to remain with its current strategy T. This is done by player i sending a message strategy-change to all of its neighbors (line 4), which in turn may propose a compensation (i.e., payoff transfer {a mathematical formula}τj,i(v)) so as to convince player i to stay with choice T (lines 8–9). This method enables to compensate player i by transfer of payoffs and in this way to enforce stability. In addition, the function {a mathematical formula}onStrategySelect() ensures that no player will stay in state {a mathematical formula}F0, by changing the choice of each player in this state from F to T (line 2). Algorithm 1 terminates when a pass through all the players of the game will not yield any change in the players' strategies.
      </paragraph>
      <paragraph>
       According to Equation (22), only players in state {a mathematical formula}F1 can propose payoff transfers to players in state {a mathematical formula}Tl≥1. If the payoffs from such players ({a mathematical formula}τj,i(v)) sums up to a value equal to or greater than {a mathematical formula}Ci, then the overall compensation to player i is sufficient and she will remain with strategy T. Otherwise (lines 6–7) she will update her strategy to F.
      </paragraph>
      <paragraph>
       Note that the transfers of payoff do not affect the social welfare of outcomes. Therefore, one can omit the payoff transfers (i.e., take into consideration only the “original” utilities of the players) when reasoning about the social welfare. However, it is essential to take the payoff transfers into consideration when reasoning about the stability of an outcome.
      </paragraph>
      <paragraph label="Proof">
       For every initial outcome{a mathematical formula}v∈V, the social welfare of{a mathematical formula}v⁎, which is the end result of runningAlgorithm 1on v, is greater than or equal to the social welfare of v.In order to prove that the social welfare of {a mathematical formula}v⁎ is not lower than that of v one can show that each change of strategy, resulting from the execution of function {a mathematical formula}onStrategySelect(), has two possible consequences. Either it immediately improves the social welfare, or it will eventually improve the social welfare before Algorithm 1 terminates. According to Algorithm 1 a player i will change its strategy if either {a mathematical formula}statei(v)=F0 or {a mathematical formula}statei(v)=Tl≥1∧Ci&gt;−τi(v) (lines 2 and 7 respectively). Therefore, only these cases will be considered.Suppose that player i's state is {a mathematical formula}F0. This means that i's choice is to avoid action (F) and the number of its neighbors performing the action is zero. In such a case, i's utility is 0, and can be improved to {a mathematical formula}1−Ci if player i changes its strategy to T. Such a change cannot decrease the utility of any other player, and therefore, the change in social welfare will be at least {a mathematical formula}1−Ci−0, which is positive since {a mathematical formula}0&lt;Ci&lt;1.In the case that player i's state is {a mathematical formula}Tl≥1, it would benefit from changing its strategy to F. Player i will deviate from its strategy T to F only in case {a mathematical formula}Ci&gt;−τi(v), which means that {a mathematical formula}Ci&gt;∑j∈Nj|statej(v)=F1Cj. Such a change in i's strategy will result in an increment of {a mathematical formula}Ci in its utility, but may decrease the utility of i's neighbors. The utility of each player {a mathematical formula}j∈Ni, which stands to lose from the change of i's strategy, will be decreased by 1 (according to Equation (2)). Therefore, the change in social welfare resulting from i's deviation, will be {a mathematical formula}Ci−∑j∈Ni|statej(v)=F11. Since the updated state of i's neighbors affected by this deviation is {a mathematical formula}F0, Algorithm 1 will not terminate until their utility will be improved (either by self deviation or by a neighbor's deviation to T). In the case where j's utility is increased by its own deviation (from F to T) the increment to the social welfare will be at least {a mathematical formula}1−Cj (as in the previous case {a mathematical formula}F0). Otherwise, one of j's neighbors will change its strategy from F to T, which will in turn increase the social welfare by at least 1. Combining both cases, the social welfare will increase by at least {a mathematical formula}1−Cj. Consequently, Algorithm 1 will not terminate until the social welfare will be improved by at least {a mathematical formula}Ci−∑j∈Ni|statej(v)=F11+∑j∈Ni|statej(v)=F1(1−Cj)=Ci−∑j∈Ni|statej(v)=F1Cj&gt;0. Therefore, if player i that is currently in state {a mathematical formula}T1, deviates from F to T, then eventually the social welfare will increase. □
      </paragraph>
      <paragraph label="Corollary 6">
       Algorithm 1converges in at most{a mathematical formula}2⋅K⋅n2improvement steps.
      </paragraph>
      <paragraph>
       Algorithm 1 allows only a subset of the strategy changes that can be done by better-response dynamics. Therefore, each strategy change that is the result of running Algorithm 1 increases the value of the potential function defined by Equation (6) and (9). Consequently, the correctness of Corollary 6 follows directly from Corollary 4.
      </paragraph>
      <paragraph label="Proof">
       An outcome{a mathematical formula}v⁎, yielded byAlgorithm 1, is side-payments enforceable.Algorithm 1 will terminate when a pass through all the players of the game will not yield changes in the players' strategies. Therefore, the state of the players at {a mathematical formula}v⁎ will be either {a mathematical formula}Fl≥1 or {a mathematical formula}Tl≥0. Consequently, in order to show that {a mathematical formula}v⁎ is side-payments enforceable, one needs to prove that no player will benefit from a unilateral deviation, given the payoff transfer function τ. The payoff transfer function, computed during the run of Algorithm 1, will be used for this purpose.Consider the case {a mathematical formula}statei(v⁎)=F1. This means that {a mathematical formula}ui(v⁎)=1 and consequently {a mathematical formula}uiτ(v⁎)=1−τi(v⁎). In this case player i has exactly one neighbor j s.t. {a mathematical formula}statej(v⁎)=Tl≥0 and the maximal payoff transfer, secured by player i for player j, is {a mathematical formula}τi,j(v⁎)=Ci. This results in i's net loss of {a mathematical formula}τi(v⁎)=Ci. Therefore, {a mathematical formula}uiτ(v⁎)≥1−Ci=ui(vi=T,v−i⁎), which means that player i cannot benefit from unilateral deviation.Now consider the case {a mathematical formula}statei(v⁎)=Fl&gt;1. In this case player i does not secure a payoff transfer for any of its neighbors (according to Equation (22)). Therefore, {a mathematical formula}uiτ(v⁎)=ui(v⁎)=1, which means that {a mathematical formula}uiτ(v⁎)&gt;1−Ci=ui(vi=T,v⁎−i). Similarly, when {a mathematical formula}statei(v⁎)=T0, player i's net loss is zero ({a mathematical formula}τi(v⁎)=0) and it will not benefit from unilateral deviation.Finally, if {a mathematical formula}statei(v⁎)=Tl≥1 then after the termination of Algorithm 1 it must hold that {a mathematical formula}−τi(v)≥Ci. Therefore, {a mathematical formula}uiτ(v⁎)=1−Ci−τi(v⁎)≥1=ui(vi=F,v−i⁎) which means that player i cannot benefit from unilateral deviation also in this case. Having considered all possible states of player i in outcome {a mathematical formula}v⁎, it holds that {a mathematical formula}v⁎ is side-payments enforceable. □
      </paragraph>
      <paragraph label="Observation 8">
       An outcome v that maximizes social welfare is side payments enforceable.
      </paragraph>
      <paragraph>
       Following Proposition 5, it is clear that applying Algorithm 1 to an outcome v that maximizes social welfare returns the exact same outcome {a mathematical formula}v⁎=v. Therefore, this outcome is SPE as shown by Proposition 7.
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       The general version of PGG
      </section-title>
      <paragraph>
       Algorithm 2, below, is an extended version of Algorithm 1 that handles the general version of the “best-shot” public goods game. The main difference between the algorithms is that for the general version of PGG there is no guarantee regarding the improvement of the social welfare. Nevertheless, the experimental evaluation of Section 7 demonstrates that in practice Algorithm 2 yields stable outcomes of greater efficiency than that of the initial outcome. The lack of theoretical guarantees regarding the efficiency of the outcomes stems from the fact that according to Algorithm 1 each player may secure a transfer of payoffs to at most one of its neighbors. This observation does not hold in the general case when {a mathematical formula}K&gt;1. Similarly to the simple version, Algorithm 2 terminates when a pass through all the players of the game does not yield any changes to the players' strategies.
      </paragraph>
      <paragraph>
       The function {a mathematical formula}onStrategySelect() of Algorithm 2 is executed by each player according to some fixed predefined order. After the execution of the function by player i, the player will not benefit from unilateral deviation. This property is achieved either by the change of i's strategy or by promised compensation to player i by its neighbors. In order to ensure that the outcome, yielded by Algorithm 2, is indeed SPE we restrict our attention only to admissible payoff transfer functions according to the following definition.
      </paragraph>
      <paragraph label="Definition 2">
       Given an outcome v of a “best-shot” public goods game, the payoff transfer function τ is admissible if for every player i the following conditions hold:
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}∀i∈N,j∈Ni,τi,j(v)≤ℓi(v)
       </list-item>
       <list-item label="2.">
        if {a mathematical formula}statei(v)=FK then {a mathematical formula}τi(v)≤Ci
       </list-item>
      </list>
      <paragraph label="Corollary 9">
       Algorithm 2converges in at most{a mathematical formula}2⋅K⋅n2improvement steps.
      </paragraph>
      <paragraph>
       Algorithm 2 allows only a subset of strategy changes out of those that can occur during the run of better-response dynamics (similarly to Algorithm 1). Consequently, the correctness of Corollary 9 follows directly from Corollary 4 that relates to the simple PGG case.
      </paragraph>
      <paragraph>
       In order to get some intuition about the expected improvement in social welfare of the resulting outcome, consider the following example:
      </paragraph>
      <paragraph label="Example 1">
       Consider an example PGG with 8 agents connected by the network depicted in Fig. 4a, where {a mathematical formula}K=2, and equal costs for all players (i.e., {a mathematical formula}∀i∈N,Ci=C). Fig. 4a also presents a specific initial outcome of the game (i.e., {a mathematical formula}v1=T,v2=T,v3=T,v4=F,v5=T,v6=T,v7=T and {a mathematical formula}v8=F). In this example, Algorithm 2 traverses the players in the order of their indexes. Additionally, the use of an admissible payoff transfer function is assumed.The first player that invokes function {a mathematical formula}onStrategySelect() is player 1. The state of the player is {a mathematical formula}T2, because exactly two of its neighbors chose T as their action. Therefore, player 1 sends a strategy-change message to all of its neighbors (i.e., players 2 and 3). Since {a mathematical formula}state2(v)=state3(v)=T3, {a mathematical formula}ℓ2(v)=0 and {a mathematical formula}ℓ3(v)=0, both neighbors reply with zero. Thus, player 1 changes her strategy from T to F.The next player in order is 2; the state of player 2 at this stage is {a mathematical formula}T2 and therefore she sends a strategy-change message to players {a mathematical formula}1,3,4 and 7. The replies of both players 3 and 7 are zero ({a mathematical formula}state3(v)=T2 and {a mathematical formula}state7(v)=T3). Consider now the replies of players 1 and 4, which are both at state {a mathematical formula}F2 at this stage. This means that {a mathematical formula}ℓ1=ℓ4=C, and therefore the sum of the replies of players 1 and 4 should be at least {a mathematical formula}C (say, {a mathematical formula}τ1,2(v)=τ4,2(v)=C2). According to these replies, the net gain of player 2 is greater/equal to {a mathematical formula}C (i.e., {a mathematical formula}−τ2(v)≥C). Therefore, player 2 remains with her choice T.The result of the execution of function {a mathematical formula}onStrategySelect() by player 3 is similar to that of player 2. The state of player 3 is {a mathematical formula}T2 which leads to four messages strategy-change to be sent to players {a mathematical formula}1,2,4 and 6. The sum of non-zero messages (from players 1 and 4) can be larger than {a mathematical formula}C (e.g., rationally preferable by 1 and 4), which will prevent player 3 from changing her strategy.Player 4 does not change its strategy since {a mathematical formula}state4(v)=F2 and the net loss of player 4 at this stage is {a mathematical formula}τ4(v)≤C. The results of the subsequent invocations of function {a mathematical formula}onStrategySelect() are as follows: player 5 changes her strategy to F for the same reasons of player 1, whereas players {a mathematical formula}6,7 and 8 will remain with their choices for the same reasons of players {a mathematical formula}2,3 and 4, respectively. An additional run over all players, traversed again according their indexes, does not yield any changes in their strategies, which leads to the termination of Algorithm 2 (see Fig. 4b).Note that the social welfare of the initial outcome is {a mathematical formula}8⋅2−6⋅C; this is due to the fact that each player has at least two neighbors taking the action and there are six players with strategy {a mathematical formula}vi=T. The social welfare of the outcome yielded by Algorithm 2 is {a mathematical formula}8⋅2−4⋅C, which is higher. Additionally, it is easy to see that the resulting outcome is side payments enforceable (SPE). Namely, the outcome {a mathematical formula}v=(F,T,T,F,F,T,T,F) can be stabilized by using the payoff transfers that were contracted (i.e., offered and accepted) during the run of Algorithm 2.
      </paragraph>
      <paragraph>
       Next, the stability of the outcome yielded by Algorithm 2 is investigated, followed by an example of an admissible payoff transfer function.
      </paragraph>
      <paragraph label="Proof">
       The use of an admissible payoff transfer function during the run ofAlgorithm 2ensures that the resulting outcome{a mathematical formula}v⁎, is SPE.The correctness of Proposition 10 follows directly from the termination condition of Algorithm 2. First, one can observe that after the algorithm terminates there are no players in states {a mathematical formula}Fl&lt;K. Consequently, the only players that may want to change their strategy are players that are in states {a mathematical formula}FK, {a mathematical formula}Fl&gt;K, {a mathematical formula}Tl&lt;K or {a mathematical formula}Tl≥K.Consider the case {a mathematical formula}statei(v⁎)=FK, which means that {a mathematical formula}ui(v⁎)=K. Therefore, {a mathematical formula}uiτ(v⁎)=K−τi(v⁎). A unilateral deviation of player i will result in outcome {a mathematical formula}v′=(vi=T,v−i⁎), in which i's utility will be {a mathematical formula}ui(v′)=K−Ci. According to the definition of an admissible payoff transfer function, if {a mathematical formula}statei(v)=FK then i's net loss ({a mathematical formula}τi(v)) must be at most {a mathematical formula}Ci. Therefore, {a mathematical formula}uiτ(v⁎)=K−τi(v⁎)≥K−Ci=ui(v′), which means that player i will not benefit from unilateral deviation (from F to T).Now consider the case {a mathematical formula}statei(v⁎)=Fl&gt;K. According to the definition of admissible payoff transfer functions, i's net loss is zero ({a mathematical formula}τi(v⁎)=0), since {a mathematical formula}ℓi(v)=0. Therefore, {a mathematical formula}uiτ(v⁎)=ui(v⁎)=K&gt;K−Ci=ui(vi=T,v−i⁎). Clearly, player i has no incentive to change her strategy. Similar reasoning settles the case of {a mathematical formula}statei(v)=Tl&lt;K.Finally, {a mathematical formula}statei(v⁎)=Tl≥K can exist for some player i after the termination of Algorithm 2 only if {a mathematical formula}Ci≤−τi(v⁎). Consequently, {a mathematical formula}uiτ(v⁎)=K−Ci−τi(v)≥K=ui(vi=T,v−i⁎), which essentially means that player i can be convinced to remain with its choice T. □
      </paragraph>
      <paragraph>
       Next, an example of an admissible payoff transfer function is presented. Note that according to Algorithm 2, transfers of payoffs should only be proposed to players with {a mathematical formula}statei(v)=Tl≥K. Additionally, note that only the player's state and its cost for taking the action limit the value of the payoff. As a result, a player j may decide on the following payoff transfer without consulting other players:{a mathematical formula} In other words, each player will secure the maximal payoff allowed according to the admissibility restriction (Definition 2). Let us proceed to see how an SPE outcome can be stabilized using the payoff transfers of Equation (23).
      </paragraph>
      <paragraph label="Example 2">
       Reconsider the outcome {a mathematical formula}v⁎ of Example 1 as yielded by Algorithm 2 (Fig. 4b). One can easily see that only players {a mathematical formula}2,3,6 and 7 should be incentivized in order to stabilize outcome {a mathematical formula}v⁎. According to Equation (23) player 1 can secure a payoff of {a mathematical formula}C to player 2 ({a mathematical formula}τ1,2=C) in order to convince her to remain with her choice T. At this stage {a mathematical formula}τ1(v⁎)=C. Subsequently the maximal payoff transfer that player 1 may secure to player 3 is zero (since {a mathematical formula}state1(v⁎)=F2 and {a mathematical formula}max⁡(ℓ1(v⁎)−τ1(v⁎),0)=max⁡(C−C,0)=0). Nevertheless, player 4 may secure a transfer of {a mathematical formula}C to player 3 ({a mathematical formula}τ4,3=C) and as a result player 3 will not benefit from unilateral deviation to strategy F. Similar payoff transfers are proposed by the respective players on the right-hand side of the graph (players 5–8). One can observe that the payoff transfers {a mathematical formula}τ1,2=C,τ4,3=C,τ5,6=C and {a mathematical formula}τ8,7=C will indeed stabilize outcome {a mathematical formula}v⁎.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Experimental evaluation
     </section-title>
     <paragraph>
      The proposed stability enforcing algorithm of Section 6 was proven to ensure stability (Proposition 7, Proposition 10). The objective of this experimental evaluation is to empirically demonstrate the efficiency of the resulting stable states. A theoretical guarantee regarding the efficiency of Algorithm 1 (i.e., {a mathematical formula}K=1) was given in Proposition 5. Nevertheless, in all the conducted experiments, the efficiency of the outcomes ({a mathematical formula}v⁎) yielded by Algorithm 2 (with various values of {a mathematical formula}K) was always greater than the efficiency of the original outcomes (v). One way to demonstrate the efficiency of the method is to compare it to that of best-response dynamics. Despite the conceptual differences between the two methods, both of them ultimately converge to a stable point – best-response dynamics to a PNE and the proposed procedure to an SPE.
     </paragraph>
     <paragraph>
      The first set of experiments considers the efficiency of the resulting stable outcomes of both methods keeping in mind the PoA and PoS of the games (see Section 4). For this purpose the PNEs that maximize and minimize the social welfare are considered, these PNEs were found by exhaustive search. The second set of experiments studies how do the parameters of the problem (i.e., the number of players N, the value of {a mathematical formula}K and the average number of neighbors m) influence the performance of the two methods. The third set of experiments studies the impact of the order of the players on the resulting outcome. The use of fixed orders of players is reminiscent of “serial dictatorship” procedures, which are notorious for their possibly “unfair” results. Therefore, studying the fairness of both methods is important.
     </paragraph>
     <section label="7.1">
      <section-title>
       Problem generation
      </section-title>
      <paragraph>
       In order to generate various PGG instances for the experimental evaluation, we use two types of underlying social networks:
      </paragraph>
      <list>
       <list-item label="1.">
        Random networks – a random graph is obtained by starting with a set of n isolated nodes and adding successive edges between them at random. In our experiments the model of Erdős and Rényi [19] was used to generate random networks. Instances of these networks were constructed by generating n vertices, and for each pair of vertices {a mathematical formula}i,j the edge {a mathematical formula}{i,j} was added with a probability p.{sup:3}
       </list-item>
       <list-item label="2.">
        Scale-free networks – in a scale-free graph, the distribution of node degrees follows a power law (at least asymptotically), {a mathematical formula}nd∝d−γ, where {a mathematical formula}Nd is the number of nodes of degree d and {a mathematical formula}γ&gt;0 is a constant (typically {a mathematical formula}2&lt;γ&lt;3). The model of Barabási and Albert [20] was used to generate random scale-free networks. The network begins with an initial connected network of {a mathematical formula}m0=3 nodes. New nodes are added to the network one at a time. Each new node is connected to m existing nodes with a probability that is proportional to the number of links that the existing nodes already have.
       </list-item>
      </list>
      <paragraph>
       While the construction processes of these networks are quite different from each other, they both share two important parameters – the number of nodes in the network (n) and the average number of neighbors (edges) for each node (m). For each instance a random problem was generated. First, a random social network was generated using each of the above models. Next, a “best-shot” public goods game was constructed according to the rules described in Section 2, where the cost of assigning T was drawn uniformly from the range {a mathematical formula}[0,1). Finally, an initial outcome and the order over the players were randomly chosen from a uniform distribution. Both of the evaluated methods – the stability enforcing algorithm (Section 6) and better-response dynamics (Section 3.1) – were applied to this outcome in order to achieve a stable solution.
      </paragraph>
     </section>
     <section label="7.2">
      <section-title>
       Metrics for evaluation
      </section-title>
      <paragraph>
       The performance of the two methods was evaluated by three metrics:
      </paragraph>
      <list>
       <list-item label="1.">
        Social welfare – the utilitarian sum (the efficiency of the outcome){a mathematical formula}
       </list-item>
       <list-item label="2.">
        Gini coefficient – a measure of inequality among players' utilities (the fairness of the solution){a mathematical formula}
       </list-item>
       <list-item label="3.">
        Number of improvement steps – the number of times a strategy of one of the players was changed. This measures the speed of convergence and serves to also assess the scalability of the method.
       </list-item>
      </list>
     </section>
     <section label="7.3">
      <section-title>
       Experimental results
      </section-title>
      <paragraph>
       The first set of experiments evaluates the difference between the social welfare yielded by the two methods – the stability enforcing algorithm and better-response dynamics – in comparison to the PNE that maximizes social welfare and the PNE that minimizes social welfare. For these experiments the average number of neighbors is fixed to {a mathematical formula}m=4, for {a mathematical formula}K=1, and {a mathematical formula}m=5 when {a mathematical formula}K is 3. Due to the small size of these networks we were able to compute the best and worst PNEs by exhaustive search, i.e., by enumerating all possible outcomes. Fig. 5, Fig. 6 depict the improvement in social welfare and in the Gini index respectively. The baseline for improvement in social welfare is the social welfare of the initial (random) outcome.
      </paragraph>
      <paragraph>
       It is easy to see that the average efficiency of the outcomes obtained by the proposed method is higher than those obtained by better-response dynamics (Fig. 5) for both cases ({a mathematical formula}K=1 and {a mathematical formula}K=3). For the simple version, where {a mathematical formula}K=1, the improvement in SW of Algorithm 1 is relatively small (Fig. 5a). However, for general PGGs with {a mathematical formula}K=3 the improvement in social welfare obtained by Algorithm 2 is quite close to that of the best PNEs (Fig. 5b). In contrast, the efficiency of the outcomes obtained by better-response dynamics is only slightly higher than that of the worst PNEs. This observation emphasizes the motivation for the use of payoff transfers when searching for efficient stable solutions of “best-shot” public goods games.
      </paragraph>
      <paragraph>
       The Gini index of the best PNEs is better (lower) than that of the worst PNEs (Figs. 6a and 6b). This relates to the fact that in order to maximize social welfare one needs to minimize the number of players that choose to take the action. In such a case the number of players that suffer a cost of {a mathematical formula}Ci is minimal, which in turn maximizes the fairness of the solution.
      </paragraph>
      <paragraph>
       The picture changes when one examines the Gini coefficient of the outcomes yielded by the proposed method; while in the case of {a mathematical formula}K=1 the fairness of outcomes is similar to those of better-response dynamics, the results for {a mathematical formula}K=3 are of higher Gini coefficient, even higher than that of the worst PNEs. This phenomenon may stem from the fact that players do not cooperate while reasoning about the payoff transfers. Namely, multiple players may secure a payoff to the same player i which results in the net gain of player i ({a mathematical formula}τi(v⁎)) being much higher than its cost for taking the action ({a mathematical formula}Ci) leading to a deterioration in the fairness of the solution.
      </paragraph>
      <paragraph>
       The next set of experiments studies the influence of the parameters of the “best-shot” public goods games on the performance of the methods. First, the effect of the size of the underlying network on the efficiency of the resulting outcomes. For these experiments the number of players is varied in the range {a mathematical formula}{100,…,1000}. Next, the value of m is varied in the range {a mathematical formula}{3,…,10}, for a fixed number of players ({a mathematical formula}n=1000). Studied finally is the impact of the value of {a mathematical formula}K on the results of the methods. This set of experiments empirically evaluates the efficiency and the fairness of stable solutions of PGGs on large random and scale-free networks. These networks are much larger than those used in the first set of experiments, and therefore results of the best and worst PNEs are not provided here, since these are intractable.
      </paragraph>
      <paragraph>
       Fig. 7 depicts the improvement in social welfare of the outcomes yielded by both methods on large random networks. When {a mathematical formula}K=1, the proposed method produces outcomes which about 5% higher social welfare improvement than those provided by better-response dynamics (Fig. 7a), which is consistent with the results of the first set of experiments (Fig. 5a). When {a mathematical formula}K=3, the results of the proposed method are approximately 16% more efficient than those of better-response dynamics (Fig. 5b). Note that in this case better-response dynamics yields outcomes that are {a mathematical formula}≈1%−2% less efficient than the initial outcome. This deterioration in the social welfare can be explained by the properties of the potential function described in Section 3.1 (i.e., the maximal value of the potential function represents a PNE of minimal social welfare).
      </paragraph>
      <paragraph>
       Fig. 8 presents the improvement in social welfare on large scale-free networks. It is easy to see that the type of underlying network has almost no impact on the ability of the proposed method to improve the social welfare in both cases ({a mathematical formula}K=1 and {a mathematical formula}K=3). Moreover, it provides an additional incentive to use payoff transfers when {a mathematical formula}K=3 since the decrease in social welfare of better-response dynamics is over 15%.
      </paragraph>
      <paragraph>
       Fig. 9 presents a measure of the fairness of the resulting outcomes of the two methods on both types of underlying networks with {a mathematical formula}K=3. The results for {a mathematical formula}K=1 are very similar to the respective results of the first set of the experiments (Fig. 6a), and are thus omitted. Fig. 9 clearly shows that the ability of the proposed method to provide outcomes of higher efficiency than those of better-response dynamics comes at the expense of fairness.
      </paragraph>
      <paragraph>
       A major factor regarding the applicability of each of the evaluated methods is their run-time performance. Fig. 10 shows that the average number of improvement steps is linear in the number of players for both methods ({a mathematical formula}K=3). These empirical results are in sync with Corollary 4, Corollary 9, which provide polynomial upper-bounds on the number of improvement steps until convergence of both methods. Additionally, note that the proposed method performs approximately half the number of the improvement steps of better-response dynamics until convergence. This comes as no surprise since the proposed method performs only a subset of the strategy changes that are allowed by better-response dynamics.
      </paragraph>
      <paragraph>
       The average number of neighbors seems to play a critical role in the ability to improve social welfare. Fig. 11 shows that the increase in social welfare reduces as the average number of neighbors grows in both types of underlying networks. Nevertheless, while better-response dynamics yields outcomes of lower efficiency than the initial (random) outcomes, the proposed method manages to improve the efficiency of the outcomes even for larger numbers of neighbors.
      </paragraph>
      <paragraph>
       Interestingly, the fairness of the outcomes increases as the average number of neighbors grows (Fig. 12). This may be because larger neighborhoods require less players to acquire the goods in a stable solution. Still, the solutions yielded by the proposed method are of higher Gini coefficient than those obtained by better-response dynamics, similarly to the previous cases.
      </paragraph>
      <paragraph>
       One can clearly observe that the average number of improvement steps increases as the average number of neighbors grows (Fig. 13). This observation correlates with Equation (13) which plays a crucial role in the theoretical bound on the number of improvement steps to convergence. As expected, the proposed method performs less improvement steps than better-response dynamics for all the evaluated values of m.
      </paragraph>
      <paragraph>
       The ability to improve the efficiency of the initial outcome depends also on the value of {a mathematical formula}K (Fig. 14). The proposed method outperforms better-response dynamics, in terms of efficiency, for all the evaluated values of {a mathematical formula}K in both types of the underlying networks. Additionally, the application of Algorithm 2 always produces a positive improvement in the social welfare. The proposed improvement procedure can provide outcomes with up to 20% higher efficiency than those of better-response.
      </paragraph>
      <paragraph>
       The fairness of the solutions provided by better-response dynamics is almost not affected by the value of {a mathematical formula}K (Fig. 15). In contrast, the Gini coefficient of the outcomes provided by the proposed method increases with the value of {a mathematical formula}K. A possible reason for this can be the fact that large values of {a mathematical formula}K increase the probability of a player i to receive a payoff compensation ({a mathematical formula}statei(v⁎)=Tl≥K) from its neighbors. Since players do not cooperate during the decision process regarding the payoff transfer, the fairness may deteriorate with each additional player that receives a compensation.
      </paragraph>
      <paragraph>
       Corollary 4, Corollary 6, Corollary 9 state that the number of improvement steps until convergence is linear in the value of {a mathematical formula}K. However, Fig. 16 shows that the average number of improvement steps can be almost unaffected by the value of {a mathematical formula}K (better-response dynamics on random networks) or even drop down with increase of {a mathematical formula}K (proposed method for {a mathematical formula}K≤5). This behavior may stem from the fact that only a small fraction of the players in the initial (random) outcomes can benefit from unilateral deviation.
      </paragraph>
      <paragraph>
       The final set of experiments studies the impact of the traversal order over the players for both methods. In these experiments three different orders are used – a random order, an ascending order of costs and a descending order of costs. The influence of the different orders on the performance of the methods for {a mathematical formula}K&gt;1 was insignificant, therefore the reported results are only for {a mathematical formula}K=1.
      </paragraph>
      <paragraph>
       Fig. 17a presents the change in social welfare for random underlying networks. It is easy to see that the descending order of costs provides the most significant improvement in social welfare for both proposed method and better-response dynamics, while ascending order of costs results in the minimal change of social welfare. This results from the fact that the majority of improvement steps performed by players, were from strategy T to strategy F. Fig. 17b provides similar results for better-response dynamics. The changes in the improvement in social welfare, made by the proposed method ({a mathematical formula}K=1), are less significant and almost negligible.
      </paragraph>
      <paragraph>
       The fairness of the solutions, yielded by both methods, is maximal when descending order of costs is used. This result resembles the previous observations – outcomes that maximize social welfare are of higher fairness than those of lower efficiency. Additionally, outcomes of better-response dynamics are of lower Gini index than the stable solutions yielded by the proposed method. See Fig. 18.
      </paragraph>
     </section>
    </section>
   </content>
  </root>
 </body>
</html>