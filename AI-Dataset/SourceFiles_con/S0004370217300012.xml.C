<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    The virtues of idleness: A decidable fragment of resource agent logic.
   </title>
   <abstract>
    Alternating Time Temporal Logic (ATL) is widely used for the verification of multi-agent systems. We consider Resource Agent Logic ( RAL), which extends ATL to allow the verification of properties of systems where agents act under resource constraints. The model checking problem for RAL with unbounded production and consumption of resources is known to be undecidable. We review existing (un)decidability results for fragments of RAL, tighten some existing undecidability results, and identify several aspects which affect decidability of model checking. One of these aspects is the availability of a ‘do nothing’, or idle action, which does not produce or consume resources. Analysis of undecidability results allows us to identify a significant new fragment of RAL for which model checking is decidable.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Many problems in AI and multi-agent systems research are most naturally formulated in terms of the abilities of a group or coalition of agents. For example, a group of agents may be able to cooperate to achieve an outcome which cannot be achieved by any agent in the group acting individually. In many cases, whether the outcome can be achieved depends critically on the resources available to the agents. Money is an obvious example, but there are many kinds of resources that may be produced or consumed by the actions of agents. For example, whether a team of agents can cooperate to extinguish a fire may depend on the amount of fuel and water they have available. Several logics for reasoning about coalitional ability under resource bounds have been proposed in the literature [1], [2], [3], [4], [5], [6], [7]. These resource logics allow us to express properties such as: ‘a coalition of agents A has a strategy (a choice of actions) requiring no more than b resources, such that whatever the actions by the agents outside the coalition, any evolution of the system generated by the strategy satisfies some temporal property’. Using model checking techniques we can then verify that a given coalition has a strategy requiring less than b resources to enforce an outcome, whatever the other agents in the system (or the environment) do. The ability to verify such properties can be useful when designing or developing a resource-constrained multi-agent system.
     </paragraph>
     <paragraph>
      Unfortunately, the model checking problem for many resource logics where actions can produce resources is undecidable [2], [5]. Recently, however, it was shown that some resource logics where actions can produce resources have a decidable model checking problem [6], [7], [8].{sup:1} In this paper, we investigate the reasons for the decidability or undecidability of the model checking problem for resource logics. Different syntactic and semantic choices give different variants of resource logics. Some of these choices are known to affect the decidability of the model checking problem. In particular, the decidability result in [6] was proven in the presence of two major restrictions, called, in the terminology of [2], resource flat and proponent restricted. The former assumes that agents are always re-equipped with fresh resources when they reconsider their strategies; the latter assumes that only the proponents act under resource bounds (i.e., agents outside the coalition are not resource bounded). In addition to these restrictions, another choice in the semantics is relevant for the decidability result in [6]. This choice, which is also related to the finitary and infinitary semantics of [2], stipulates that, in every model, agents always have a choice of doing nothing (executing an idle action) that produces and consumes no resources. Having an idle action makes model checking easier: intuitively, its availability ensures that in order to determine whether a coalition can enforce a ϕ-state after finitely many steps and within a given resource bound, we only need to find a finite strategy to enforce ϕ under the given resource bound, and after ϕ is achieved, the agents can always choose the idle action forever, which does not increase the ‘cost’ of the strategy. The presence of an idle action in the logic also guarantees some attractive formal properties. For example, as stated in [3], it ensures coalition monotonicity: if a coalition A can ensure a property under resource bound b, then any larger coalition can also ensure this property under the same resource bound (intuitively, the extra agents can always perform idle).
     </paragraph>
     <paragraph>
      In this paper, we investigate the effects of various semantic choices, such as the availability of an idle action, on the decidability of the model checking problem for resource logics. First we show that both the resource-flat and the proponent-restricted fragments of resource agent logic remain undecidable in the presence of idle actions. We then identify and motivate a significant, non-resource-flat fragment that has a decidable model checking property in the presence of idle actions, and is not decidable otherwise. It follows that idle actions can make a difference for the decidability of model checking with respect to the semantics we consider.
     </paragraph>
     <paragraph>
      The new fragment, which we call {a mathematical formula}pprRAL, allows us to express statements about the existence of nested strategies for a coalition of agents given some initial allocation of resources. Unlike the resource-flat fragment considered in [6], where for each new strategy agents are re-equipped with a fresh set of resources, {a mathematical formula}pprRAL allows us to express properties such as ‘given their initial battery charge, rescue robots A can safely get to a position from which they can perform rescue while in visual contact with the base’. There are two nested strategies implicit in this property: first, the robots should be able to reach some position (not necessarily maintaining visual contact with the base), and second, from this position, the agents should be able to perform rescue while in visual contact with the base. The first strategy (getting into position) will require certain resources (in this case battery charge), and the amount of resources required will depend on the environment. Then, with whatever resources are left, the agents need a strategy to perform the rescue. In this example, the model checking problem essentially corresponds to finding two nested conditional resource-constrained plans, see e.g., [10]. The plans are nested because it is impossible to decouple the second plan (for rescue) from the results of the first plan (getting into position), since we do not know the resource availability for the initial state of the second plan; the resource availability in that state is determined by resource consumption of the first plan. Compared to conditional planning with resources, resource logics provide an easy way to talk not just about reachability, but also about invariants and nested goals/strategies achieved by (potentially different) coalitions.
     </paragraph>
     <paragraph>
      This paper extends results presented in [7] in several respects, including: a more general definition of a decidable fragment, more elaborated intuitions regarding the (un)decidability results, detailed proofs of all theorems, and tighter undecidability results (in terms of the number of agents and resource types required for undecidability). The remainder of the paper is organised as follows. In Section 2 we briefly survey related work. In Section 3 we introduce resource agent logic, its models and the semantics. In Section 4, we review known decidability results for resource agent logic, and investigate the reasons for (un)decidability. We present new undecidability results for systems with a single resource type, and, based on these results, we motivate and introduce a new non-resource flat fragment of {a mathematical formula}RAL, {a mathematical formula}pprRAL. In Section 5, we present our second main technical result: a decidability result for {a mathematical formula}pprRAL. We conclude in Section 6.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      Early work on resource logics considered only the consumption of resources (i.e., no action produces resources), and initial results on the complexity of model checking were encouraging. One of the first logics capable of expressing resource requirements of agents was a version of Coalition Logic (CL){sup:2} called Resource-Bounded Coalition Logic (RBCL), where actions only consume (and do not produce) resources. It was introduced in [1] with the primary motivation of modelling systems of resource-bounded reasoners; however the framework is sufficiently general to model any type of action. The model checking problem for RBCL was shown to be decidable in time polynomial in the size of the transition system and of the property, and exponential in the number of resource types in [12]. A resource-bounded version of ATL, RB-ATL, where again actions only consume (and do not produce) resources was introduced in [3]. The model checking problem for this logic is also decidable in time polynomial in the size of the transition system and of the property, and exponential in the number of resource types [3]. (For a single resource type, e.g., energy, the model checking problem is no harder than for ATL.) Practical work on model checking many standard computer science transition systems (not multi-agent systems) with resources also falls in the category of consumption-only systems. For example, probabilistic model checking of systems with numerical resources as in the PRISM model checker [13] assumes that costs increase monotonically with time.
     </paragraph>
     <paragraph>
      However, when resource production is considered in addition to consumption, the situation changes. In a separate strand of work, a range of different formalisms for reasoning about resources was introduced in [14], [2], including Resource Agent Logic {a mathematical formula}RAL which is the main focus of this paper. In these formalisms, both consumption and production of resources was considered. In [2], it was shown that the model checking problem for most variants and fragments of {a mathematical formula}RAL is undecidable. The only decidable cases considered in [2] (and the related [14]) are an extension of Computation Tree Logic (CTL) with resources (essentially one-agent ATL), and a version where on every path only a fixed finite amount of resources can be produced. The models satisfying this property were referred to as bounded in [2]. It was pointed out in [2] that RBCL and RB-ATL are logics over a special kind of bounded models (where no resources are produced at all). Other decidability results for bounded resource logics have also been reported in the literature. For example, in [15] a decidable logic, PRB-ATL (Priced Resource-Bounded ATL) is defined, where the total amount of resources in the system has a fixed bound. The model checking algorithm for PRB-ATL requires time polynomial in the size of the transition system, and exponential in the number of resource types and the resource bound on the system. In [4] an EXPTIME lower bound in the number of resource types for the PRB-ATL model checking problem is shown. In [16], an extension of PRB-ATL to μ-calculus is also shown to have a decidable model checking problem.
     </paragraph>
     <paragraph>
      A general logic over systems with numerical constraints, Quantitative ATL (QATL{sup:⁎}), was introduced in [5], and undecidability results for the model checking problem for QATL{sup:⁎} and some of its fragments were shown. For example, QATL is undecidable even if no nestings of cooperation modalities are allowed. The main proposals for restoring decidability to the model checking problem for QATL in [5] are removing negative payoffs (similar to removing resource production), and introducing memoryless strategies (the latter idea is not pursued in any detail).
     </paragraph>
     <paragraph>
      This brief survey of work suggests that the boundary between decidability and undecidability for the model checking problem of resource logics is very subtle. No systematic study of the reasons for decidability and undecidability of this problem has been undertaken to date, and with this paper we aim to address this task. We believe a better understanding of the boundary between decidability and undecidability will be useful in developing new decidable fragments of resource logics.
     </paragraph>
     <paragraph>
      Of course, searching for decidable fragments is not the only way of addressing the undecidability of model checking for temporal logics with infinite-state transition systems ({a mathematical formula}RAL can be seen as a special case of such logics). Another approach is to design algorithms which return definite answers where possible, and ‘unknown’ otherwise (see, e.g., [17], [18], [19], [20], [21]). A promising direction of future research would be to explore connections between the two approaches. Our work connects to many other areas of computer science, such as planning [10] and the verification of autonomous systems [22], [23]. The model checking problem can essentially be seen as an approach to computing a robust plan for a set of autonomous agents, such as robots. Techniques used in our work are related to many subfields of theoretical computer science. In particular, techniques developed for Petri nets, vector addition systems and model checking over pushdown systems (see, e.g., [24], [25]), are closely connected to the techniques we use in establishing our decidability and undecidability results. The existing, deep theoretical results in these areas also provide a starting point for establishing complexity bounds for our model checking algorithms, and ideas for restrictions that give fragments with good computational properties. Finally, another branch of work on reasoning about resources is based on linear logic [26], [27], and related logics such as the logic of bunched implication [28], [29], [30], [31]. In the future, it would be interesting to explore deeper connections between the resource logics considered in this paper, and reasoning about resources using linear logic techniques.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Resource agent logic
     </section-title>
     <paragraph>
      In this section we define resource agent logic ({a mathematical formula}RAL) and resource-bounded models ({a mathematical formula}RBMs). We essentially follow [2], combined with aspects from [6]. We summarise the similarities and differences between {a mathematical formula}RAL and the resource logics considered in [2], [6] in more detail in Section 3.5.
     </paragraph>
     <section label="3.1">
      Syntax of {a mathematical formula}RAL
      <paragraph>
       The logic is defined over a set of agents {a mathematical formula}Agt, a set of resources types Res, and a set of propositional symbols Π. We denote the set of natural numbers by {a mathematical formula}N, the set of natural numbers with zero by {a mathematical formula}N0, the set of natural numbers with infinity by {a mathematical formula}N∞, and the set of natural numbers with zero and infinity by {a mathematical formula}N0∞. An endowment (function){a mathematical formula}η:Agt×Res→N0∞ assigns resources to agents; {a mathematical formula}ηa(r)=η(a,r) is the number of resources agent a has of resource type r. {a mathematical formula}En denotes the set of all possible endowments. Resource types can represent, for example, money, fuel, battery power, etc. Special minimal and maximal endowment functions are denoted by {a mathematical formula}0¯ and {a mathematical formula}∞¯, respectively. The former expresses that there are no resources at all, whereas the latter equips all agents with an infinite amount of each resource type. (In what follows, for readability we will talk about amounts of some resource, rather than of some resource type.) The logic {a mathematical formula}RAL is defined according to the grammar of {a mathematical formula}ATL[32]. {a mathematical formula}RAL-formulae are defined by:{a mathematical formula} where {a mathematical formula}p∈Π is a proposition, {a mathematical formula}A,B⊆Agt are sets of agents, and η is an endowment. We also define {a mathematical formula}《A》↓ and {a mathematical formula}《A》η as abbreviations for {a mathematical formula}《A》A↓ and {a mathematical formula}《A》Aη, respectively. The operators X, U, and G denote the standard temporal operators expressing that some property holds in the next point in time, until some other property holds, and now and always in the future, respectively. There are two types of cooperation modalities, {a mathematical formula}《A》B↓ and {a mathematical formula}《A》Bη. In both types of cooperation modality, the actions performed by agents in {a mathematical formula}A∪B consume and produce resources (actions by agents in {a mathematical formula}Agt∖(A∪B) do not change their resource endowment). The reading of {a mathematical formula}《A》Bηφ is that when agents{a mathematical formula}A∪Bhave a resource endowment η, agents A have a strategy compatible with this endowment to enforce φ (whatever the agents in{a mathematical formula}Agt∖Ado, compatible with their resource constraints, if any). The evaluation of a modality {a mathematical formula}《A》Bη (re-)equips all agents with a fresh amount of resources: the current resource endowment is overwritten by endowment η. The formula {a mathematical formula}《A》B↓φ reads similarly but the strategy must be compatible with the resources currently available to the agents. In both cases compatible means that the strategy can be executed given the agents' resources. For both modalities it is therefore necessary to keep track of resource production and consumption during the execution of a strategy.
      </paragraph>
     </section>
     <section label="3.2">
      Semantics of {a mathematical formula}RAL
      <paragraph>
       We define the models of {a mathematical formula}RAL as in [2]. Following [6] we also define a special case of these models in which all agents have an idle action in their repertoire which neither consumes nor produces resources.
      </paragraph>
      <paragraph label="Definition 1">
       {a mathematical formula}RBM,iRBMA resource-bounded model (RBM) is given by {a mathematical formula}M=(Agt,Q,Π,π,Act,d,o,Res,t) where
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}Agt={1,…,k} is a non-empty set of agents;
       </list-item>
       <list-item label="•">
        Q is a non-empty set of states;
       </list-item>
       <list-item label="•">
        {a mathematical formula}π:Q→℘(Π) is a valuation of propositions;
       </list-item>
       <list-item label="•">
        Act is a finite non-empty set of actions;
       </list-item>
       <list-item label="•">
        {a mathematical formula}d:Agt×Q→℘(Act)\{∅} indicates the actions available to agent {a mathematical formula}a∈Agt in state {a mathematical formula}q∈Q;
       </list-item>
       <list-item label="•">
        o maps each state {a mathematical formula}q∈Q and action profile {a mathematical formula}α=(σ1,…,σk) such that {a mathematical formula}σa∈d(a,q) for each {a mathematical formula}a∈{1,…,k}, to another state {a mathematical formula}q′=o(q,α);
       </list-item>
       <list-item label="•">
        {a mathematical formula}t:Act×Res→Z models the resources consumed and produced by actions; if {a mathematical formula}t(σ,r) is positive resource r is produced by σ, if {a mathematical formula}t(σ,r) is negative resource r is consumed by σ.
       </list-item>
      </list>
      <paragraph>
       We will write {a mathematical formula}da(q) instead of {a mathematical formula}d(a,q), and use {a mathematical formula}d(q) to denote the set {a mathematical formula}d1(q)×…×dk(q) of action profiles in state q. Similarly, {a mathematical formula}dA(q) denotes the action tuples available to {a mathematical formula}A⊆Agt in q. For {a mathematical formula}α=(σ1,…,σk), we use {a mathematical formula}αA to denote the sub-tuple consisting of the actions of agents {a mathematical formula}A⊆Agt; moreover, we write {a mathematical formula}αa to refer to {a mathematical formula}σa for {a mathematical formula}a∈Agt. {a mathematical formula}ActA is a set of tuples of actions by agents in A. We define {a mathematical formula}prod(σ,r):=max⁡{0,t(σ,r)} (resp. {a mathematical formula}cons(σ,r):=|min⁡{0,t(σ,r)}|) as the amount of resource r produced (resp. consumed) by action σ. Note that {a mathematical formula}cons(σ,r) is a non-negative number, and for any action σ and a resource type r it is not possible that both {a mathematical formula}prod(σ,r) and {a mathematical formula}cons(σ,r) are greater than 0.
      </paragraph>
      <paragraph>
       In what follows, {a mathematical formula}Qω denotes the set of all infinite sequences of elements from Q, and {a mathematical formula}Q+ denotes the set of all finite sequences. A path{a mathematical formula}λ∈Qω is an infinite sequence of states such that there is a transition between two adjacent states. A finite path is a finite segment of a path. We define {a mathematical formula}λ[i] to be the {a mathematical formula}(i+1)-th state of λ, and {a mathematical formula}λ[i,∞] to be the suffix {a mathematical formula}λ[i]λ[i+1]…. We denote a finite sequence λ extended by q by λq. A resource-extended path {a mathematical formula}λ∈(Q×En)ω is an infinite sequence over {a mathematical formula}Q×En such that the restriction to states (the first component), denoted by {a mathematical formula}λ|Q, is a path in the underlying model. The projection of λ to the second component of each element in the sequence is denoted by {a mathematical formula}λ|En. We call any initial (finite) suffix of a resource-extended path a finite resource extended path.
      </paragraph>
      <paragraph>
       A strategy for a coalition {a mathematical formula}A⊆Agt is a function {a mathematical formula}sA:Q+→ActA such that {a mathematical formula}sA(λq)∈dA(q) for {a mathematical formula}λq∈Q+. Such a strategy gives rise to a set of (resource-extended) paths. A {a mathematical formula}(η,sA,B)-path is a resource-extended path λ where for all {a mathematical formula}i=0,1,… with {a mathematical formula}λ[i]:=(qi,ηi) there is an action profile {a mathematical formula}α∈d(λ|Q[i]) such that:
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}η0=η (η describes the initial resource distribution);
       </list-item>
       <list-item label="2.">
        {a mathematical formula}sA(λ|Q[0,i])=αA (A follow their strategy);
       </list-item>
       <list-item label="3.">
        {a mathematical formula}λ|Q[i+1]=o(λ|Q[i],α) (transition according to α);
       </list-item>
       <list-item label="4.">
        for all {a mathematical formula}a∈A∪B and {a mathematical formula}r∈Res: {a mathematical formula}ηai(r)≥cons(αa,r) (each agent has enough resources to perform its action);
       </list-item>
       <list-item label="5.">
        for all {a mathematical formula}a∈A∪B and {a mathematical formula}r∈Res: {a mathematical formula}ηai+1(r)=ηai(r)+t(αa,r) (resources are updated);
       </list-item>
       <list-item label="6.">
        for all {a mathematical formula}a∈Agt∖(A∪B) and {a mathematical formula}r∈Res: {a mathematical formula}ηai+1(r)=ηai(r) (the resources of agents not in {a mathematical formula}A∪B do not change).
       </list-item>
      </list>
      <paragraph>
       The {a mathematical formula}(η,B)-outcome of a strategy {a mathematical formula}sA in q, {a mathematical formula}out(q,η,sA,B) is defined as the set of all {a mathematical formula}(η,sA,B)-paths starting in q. Truth is defined over an RBM{a mathematical formula}M, a state {a mathematical formula}q∈QM, and an endowment η.
      </paragraph>
      <paragraph>
       The semantics is given by the satisfaction relation ⊨ where the cases for propositions, negation and conjunction are standard and omitted: {a mathematical formula}M,q,η⊨《A》B↓φiff there is a strategy {a mathematical formula}sA for A such that for all {a mathematical formula}λ∈out(q,η,sA,B), {a mathematical formula}M,λ,η⊨φ{a mathematical formula}M,q,η⊨《A》Bζφiff there is a strategy {a mathematical formula}sA for A such that for all {a mathematical formula}λ∈out(q,ζ,sA,B), {a mathematical formula}M,λ,ζ⊨φ{a mathematical formula}M,λ,η⊨Xφiff {a mathematical formula}M,λ|Q[1],λ|En[1]⊨φ{a mathematical formula}M,λ,η⊨φUψiff there exists i with {a mathematical formula}i≥0 and {a mathematical formula}M,λ|Q[i],λ|En[i]⊨ψ and for all j with {a mathematical formula}0≤j&lt;i, {a mathematical formula}M,λ|Q[j],λ|En[j]⊨φ{a mathematical formula}M,λ,η⊨Gφiff for all {a mathematical formula}i≥0, {a mathematical formula}M,λ|Q[i],λ|En[i]⊨φ The model checking problem for {a mathematical formula}RAL is stated as follows: does {a mathematical formula}M,q,η⊨φ hold? When the context is clear, we simply write {a mathematical formula}q,η⊨φ; if φ is only a propositional formula, we sometimes also omit η.
      </paragraph>
      <paragraph>
       Observe that the standard ATL modalities {a mathematical formula}《A》 can be defined as {a mathematical formula}《A》Agt∞¯, so the logic is a proper extension of ATL.
      </paragraph>
      <paragraph label="Remark 1">
       Infinitary and finitary semanticsWe refer to the semantics introduced above as infinitary semantics. In [2] the main semantics also allows for finite (maximal) paths. We refer to that semantics as finitary semantics. We note that both semantics coincide over iRBMs, as it is always possible to extend a path using idle actions.
      </paragraph>
     </section>
     <section label="3.3">
      The syntactic fragments {a mathematical formula}rfRAL, {a mathematical formula}prRAL and {a mathematical formula}rfprRAL
      <paragraph>
       Following [2] we define three fragments of {a mathematical formula}RAL. The resource-flat fragment, {a mathematical formula}rfRAL, only allows cooperation modalities of type {a mathematical formula}《A》Bη: agents are always (re-)equipped with a fresh set of resources whenever they re-consider their strategies. The proponent-restricted fragment, {a mathematical formula}prRAL, only allows cooperation modalities of types {a mathematical formula}《A》↓ and {a mathematical formula}《A》η: only the proponents are resource bounded. The fragment combining both restrictions (resource-flat and proponent-restricted) is denoted by {a mathematical formula}rfprRAL.
      </paragraph>
     </section>
     <section label="3.4">
      <section-title>
       Running example
      </section-title>
      <paragraph>
       We introduce a simple running example to illustrate the syntax and semantics of {a mathematical formula}RAL and its fragments. The example represents interactions between two agents: a robot (agent 1) and its environment (agent 2). We consider only one resource type, energy. The robot needs to move into a position where it is capable of sending information to the base regularly and is also able to charge its battery. Both moving and the communication action require energy, and the charging action produces energy. We denote ‘being in a suitable position to send information to the base’ by p. The environment can make moving more or less difficult for the agent. We model this by giving the environment an ‘obstruct’ action which has the effect of requiring the agent to execute two move actions instead of one (and hence to spend more energy) in order to get into position; for the sake of the example, obstructing requires energy. The initial state is {a mathematical formula}q0 where the agent can move and the environment can obstruct, and both also can do nothing. If the agent moves and the environment idles, then the system reaches a state {a mathematical formula}q1 where p holds and the agent can loop forever between {a mathematical formula}q1 and {a mathematical formula}q3 (which also satisfies p) sending data and charging. If the agent does nothing upon reaching the position, it returns to the initial state (under the influence of gravity, for example). If in {a mathematical formula}q0 the environment obstructs the agent, the systems reaches a state {a mathematical formula}q2 where the agent can execute the move action again to reach {a mathematical formula}q1. To keep the example simple, we assume that in all states apart from {a mathematical formula}q0 the environment can only idle.
      </paragraph>
      <paragraph>
       Formally, we have a resource-bounded model {a mathematical formula}M=(Agt,Q,Π,π,Act,d,o,Res,t) where
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}Agt={1,2}
       </list-item>
       <list-item label="•">
        {a mathematical formula}Q={q0,q1,q2,q3}
       </list-item>
       <list-item label="•">
        {a mathematical formula}Π={p}
       </list-item>
       <list-item label="•">
        {a mathematical formula}π(q0)=π(q2)=∅, {a mathematical formula}π(q1)=π(q3)={p}
       </list-item>
       <list-item label="•">
        {a mathematical formula}Act={idle,move,send,charge,obstruct}
       </list-item>
       <list-item label="•">
        Actions available to the robot: {a mathematical formula}d(1,q0)={idle,move}, {a mathematical formula}d(1,q1)={idle,send}, {a mathematical formula}d(1,q2)={idle,move}, {a mathematical formula}d(1,q3)={idle,charge}. Actions available to the environment: {a mathematical formula}d(2,q0)={idle,obstruct}, {a mathematical formula}d(2,q1)=d(2,q2)=d(2,q3)={idle}.
       </list-item>
       <list-item label="•">
        The transition function is as follows:{a mathematical formula}
       </list-item>
       <list-item label="•">
        {a mathematical formula}Res={energy}
       </list-item>
       <list-item label="•">
        {a mathematical formula}t(idle,energy)=0, {a mathematical formula}t(move,energy)=−2, {a mathematical formula}t(send,energy)=−1, {a mathematical formula}t(charge,energy)=1, {a mathematical formula}t(obstruct,energy)=−1.
       </list-item>
      </list>
      <paragraph>
       The model is shown in Fig. 1.
      </paragraph>
      <paragraph>
       Here are some example {a mathematical formula}RAL properties which hold in the model:
      </paragraph>
      <list>
       <list-item label="•">
        If both agents are resource-bounded, and the initial allocation of resources is 3 units of energy for the robot and 0 units for the environment, then the robot has a strategy to reach a state from where with the remaining resources it can maintain the invariant p. We represent an endowment η that assigns 3 units of energy to agent 1 and 0 units to agent 2 by {a mathematical formula}1:3,2:0:{a mathematical formula} In fact, with environment unable to obstruct, the robot is guaranteed to reach {a mathematical formula}q1 in one step:{a mathematical formula} This property belongs to full {a mathematical formula}RAL: it is not in {a mathematical formula}rfRAL since it uses ↓ in {a mathematical formula}《1》{1,2}↓G, nor in {a mathematical formula}prRAL since it restricts the resources of the opponent agent 2.
       </list-item>
       <list-item label="•">
        When both agents are resource bounded, and the environment is restricted to 0 units of energy, then with 2 units of energy, the agent can reach the state where it can maintain the invariant with 1 unit of energy:{a mathematical formula} This property belongs to the resource-flat fragment, since the second strategy for the invariant uses a fresh resource allocation.
       </list-item>
       <list-item label="•">
        If only the robot is resource-bounded, and the initial allocation of resources is 5 units of energy for the robot and 0 units for the environment, then the robot has a strategy to reach a state from where with the remaining resources it can maintain the invariant p. The strategy is to execute the move action until the state {a mathematical formula}q1 is reached; in the worst case this would require 4 units of energy (since the environment is not resource-bounded, its initial allocation does not matter and it can perform the obstruct action). Then with at least one unit of energy remaining, the agent can enter the loop between {a mathematical formula}q1 and {a mathematical formula}q3:{a mathematical formula} This property does not belong to {a mathematical formula}rfRAL but it does belong to {a mathematical formula}prRAL. It can be written without the argument for the set of resource-bounded agents:{a mathematical formula} In fact, this property belongs to the fragment with a decidable model checking problem, {a mathematical formula}pprRAL (positive fragment of {a mathematical formula}prRAL).
       </list-item>
       <list-item label="•">
        If only the robot is resource-bounded, then with initial allocation of 4 units of energy, it can reach a state where with one unit of energy it can maintain the invariant:{a mathematical formula} This property belongs to {a mathematical formula}rfprRAL.
       </list-item>
      </list>
     </section>
     <section label="3.5">
      <section-title>
       Similarities and differences
      </section-title>
      <paragraph>
       We conclude this section with a discussion of similarities and differences between the variant of {a mathematical formula}RAL presented here and the original resource agent logics of [2] and the logic of [6]. In the interests of readability, we refer to the setting of [2] by {a mathematical formula}S1, and to that of [6] by {a mathematical formula}S2.
      </paragraph>
      <paragraph>
       The language of {a mathematical formula}RAL as given above is almost identical to the setting of {a mathematical formula}S1, except that we do not allow the release operator.{sup:3} Setting {a mathematical formula}S2 essentially corresponds to the resource-flat and proponent-restricted fragment of {a mathematical formula}RAL. RBMs serve as models of {a mathematical formula}S1, where {a mathematical formula}S2 uses iRBMs. There are also differences in how the production and consumption of resources are handled. In {a mathematical formula}S2 the resources of a coalition of agents are combined before the resource requirements of actions are evaluated. A shortage of resources of one agent can thus be balanced by surplus resources of another agent in the coalition. The implicit assumption is that agents in the proponent coalition share their resources. It is not necessary to decide how to divide any resources produced, as the coalition sticks together throughout the relevant part of the evaluation of the current formula. When a new cooperation modality is encountered, all agents are re-equipped with a new endowment. This is a property of the resource-flat and proponent restricted fragment of the logic. This approach cannot be used if the restriction of resource-flatness or proponent restrictiveness is dropped. First, a coalition may split-up in a nested modality in which agents are not re-equipped with new resources. In this case it is important to know how many resources each individual agent has. A similar difficulty arises if an agent in the proponent coalition becomes an opponent in a nested cooperation modality. If the logic is not proponent restricted it is necessary to know how many resources this agent possesses. In {a mathematical formula}S1 this issue is addressed by introducing shares. A share models how many resources an individual agents contributes to the pool of resources needed to execute the joint action, and also the amount of resources each agent receives when resources are produced. This can be seen as a binding agreement about the resource distribution. Again, the underlying assumption is that agents in the proponent and opponent coalitions share their resources within the coalition.
      </paragraph>
      <paragraph>
       As we consider a non-resource-flat variant of {a mathematical formula}RAL here, the approach of {a mathematical formula}S2 is not sufficient, whereas the approach of {a mathematical formula}S1 complicates the presentation. We therefore adopt a less involved formalisation for ease of readability: resources cannot be shared within a coalition and each agent is entirely responsible for its own resource balance. Thus, at each moment agents have a clearly defined resource endowment. Finally, most results of {a mathematical formula}S1 are given in terms of the finitary semantics whereas we require that paths are always infinite (cf. Remark 1).
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      The quest for decidability
     </section-title>
     <paragraph>
      If unbounded production of resources is allowed, the model checking problem for many resource logics is undecidable. In particular, most fragments of the resource agent logic considered in [2], [5] are undecidable. The case of the resource-flat, proponent-restricted fragment remained open in [2], but was shown to be decidable in [6], [8] (see also [9]):
     </paragraph>
     <paragraph label="Observation 1">
      {a mathematical formula}rfprRALis decidable overiRBMs.
     </paragraph>
     <paragraph>
      A natural question arises: can we extend decidability to more expressive fragments? Which restrictions are essential for decidability, and which can be relaxed?
     </paragraph>
     <paragraph>
      The result above relies on three restrictions on {a mathematical formula}RAL: (1) the availability of an idle action; (2) resource flatness, that is, each nested quantifier has a fresh endowment; and (3) proponent restriction, that is, there are no resource bounds on the opponents. It turns out that all three restrictions are essential for the decidability of {a mathematical formula}rfprRAL, as we explain below.
     </paragraph>
     <paragraph>
      It follows from [2] that the availability of an idle action is essential for the decidability of {a mathematical formula}rfprRAL:
     </paragraph>
     <paragraph label="Observation 2">
      {a mathematical formula}rfprRALis undecidable overRBMs.
     </paragraph>
     <paragraph>
      However, the availability of an idle action on its own is not sufficient for decidability. Replacing RBMs with iRBMs does not always make the model checking problem decidable.
     </paragraph>
     <paragraph>
      In this section we present the main idea underlying the undecidability proofs of model checking {a mathematical formula}RAL from [2] and investigate the reasons for the (un)decidability. We show that the model checking problem for {a mathematical formula}RAL, i.e., the logic without any additional restrictions, remains undecidable over iRBMs (see Theorem 1 below). This result also holds for both the proponent-restricted fragment and the resource-flat fragment. For these fragments we also investigate the effect of the number of agents and resource types on the undecidability. The results of [2], [7] depend on the availability of two resource types. Here we show that undecidability holds even if each agent has only a single resource type available. In this case, however, additional agents are required for undecidability; more precisely, one or two additional agents are required depending on the setting. We also show that in the case of {a mathematical formula}prRAL over iRBMs, although the model checking problem remains undecidable, the formula expressing an undecidable problem in the logic is more complex than the formula required for {a mathematical formula}rfRAL. This suggests the idea of a syntactic restriction of {a mathematical formula}prRAL which does not allow expression of the undecidable property. We end this section by motivating a new fragment of {a mathematical formula}RAL, the positive proponent restricted fragment, {a mathematical formula}pprRAL. This fragment is more expressive than that introduced in [7], in that the formula {a mathematical formula}φ1 on the left-hand-side of {a mathematical formula}φ1Uφ2 is not constrained to be purely propositional. In Section 5 we show that the model checking problem for {a mathematical formula}pprRAL is decidable over iRBMs.
     </paragraph>
     <paragraph>
      For all the results below, the undecidability of the model checking problem is shown by a reduction of the halting problem for two-counter machines (also called Minsky machines, see [33] for details). A two-counter machine (TCM) is essentially a pushdown automaton with two stacks. The stacks are represented as two counters over natural numbers. Each of the counters (1 and 2) can be incremented, decremented (if non-zero), and tested for zero. In [33] it is shown that these machines are expressively equivalent to Turing machines. As a consequence the halting problem of two-counter machines is undecidable as well. For this paper we only need to consider TCMs with empty inputs; therefore, we only introduce this special type of TCMs.
     </paragraph>
     <paragraph label="Definition 2">
      Empty-band two-counter machine (cf. [33]), empty-bandAn empty band TCM {a mathematical formula}A is given by {a mathematical formula}(S,sinit,Sf,Δ) where S is a finite set of states, {a mathematical formula}sinit∈S is the initial state, {a mathematical formula}Sf⊆S is a set of final states, and {a mathematical formula}Δ⊆(S×{0,1}2)×(S×{−1,0,1}2) is the transition relation such that if {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ and {a mathematical formula}Ei=0 then {a mathematical formula}Ci≠−1 for {a mathematical formula}i=1,2 (to ensure that an empty counter is not decremented). In the following we sometimes use infix notation and write {a mathematical formula}(s,E1,E2)Δ(s′,C1,C2) instead of {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ. We call {a mathematical formula}((s,E1,E2),(s′,C1,C2)) a transition if {a mathematical formula}(s,E1,E2)Δ(s′,C1,C2) and denote a typical transition by τ.
     </paragraph>
     <paragraph>
      As we focus on empty-band TCMs, we often simply say automaton or machine to refer to such a TCM. A TCM can be considered as a transition system equipped with two counters that influence the transitions. Each transition step of the automaton depends on whether the counters are zero or non-zero, and in each step the counters can be incremented or decremented. It is important to emphasise that a TCM cannot access the specific value of the counters. In the following let {a mathematical formula}τ=((s,E1,E2),(s′,C1,C2)) be a transition. Here, {a mathematical formula}Ei=1 (resp. =0) represents that counter i is non-zero (resp. zero), and {a mathematical formula}Ck=1 (resp. =−1) denotes that counter i is incremented (resp. decremented) by 1. A value {a mathematical formula}Ck=0 indicates that counter k is left unchanged. The transition encodes that in state s the automaton can change its state to {a mathematical formula}s′ provided that the first (resp. second) counter meets condition {a mathematical formula}E1 (resp. {a mathematical formula}E2). The value of counter k changes according to {a mathematical formula}Ck for {a mathematical formula}k=1,2. For example, the transition {a mathematical formula}((s,1,0),(s′,−1,1)) is enabled if the current state is s, counter 1 is non-zero, and counter 2 is zero. If the transition is enabled and taken, the state changes to {a mathematical formula}s′, counter 1 is decremented and counter 2 is incremented by 1.
     </paragraph>
     <paragraph>
      The general mode of operation is as for pushdown automata. In particular, a configuration is a triple {a mathematical formula}(s,v1,v2)∈S×N02 describing the current state (s), the value of counter 1 ({a mathematical formula}v1) and of counter 2 ({a mathematical formula}v2). An {a mathematical formula}A-computation ρ (or simply computation if the two-counter machine is clear from context) is a sequence of subsequent configurations resulting from transitions according to Δ, such that the first state is {a mathematical formula}sinit. An accepting computation is a finite computation {a mathematical formula}ρ=(si,v1i,v2i)i=1,…,l where the last state {a mathematical formula}sl∈Sf is a final state. We use {a mathematical formula}ρi=((si,E1i,E2i),(si+1,C1i,C2i)) to denote the transition that leads from the ith configuration {a mathematical formula}(si,v1i,v2i) to the {a mathematical formula}(i+1)th configuration {a mathematical formula}(si+1,v1i+1,v2i+1) for {a mathematical formula}i&lt;l. Note that we have that {a mathematical formula}vki+1=vki+Cki for {a mathematical formula}k=1,2.
     </paragraph>
     <paragraph>
      Finally, we say that a transition {a mathematical formula}τ=((s,E1,E2),(s′,C1,C2)) is enabled in a configuration {a mathematical formula}(s,v1,v2) if the value {a mathematical formula}vk of counter k satisfies condition {a mathematical formula}Ek∈{0,1} for {a mathematical formula}k∈{1,2} (with the obvious meaning of being zero or non-zero), i.e. {a mathematical formula}vk&gt;0 iff {a mathematical formula}Ek=1. If an enabled transition τ is taken the automaton changes its control state from s to {a mathematical formula}s′, and counter i is updated by adding {a mathematical formula}Ci∈{−1,0,+1}. The automaton halts on empty input iff there is an accepting computation.{sup:4}
     </paragraph>
     <section label="4.1">
      Undecidability of {a mathematical formula}rfRAL and {a mathematical formula}prRAL with two resources types over iRBMs
      <paragraph>
       In this section we essentially extend the undecidability results of [2] to iRBMs. We first give a generic construction of an iRBM{a mathematical formula}M1A for a two-counter machine {a mathematical formula}A which is used to show that model checking {a mathematical formula}rfRAL and {a mathematical formula}prRAL are undecidable over iRBMs (Theorem 1, Theorem 2). The key is provided by the Simulation Lemma 1.
      </paragraph>
      <section label="4.1.1">
       <section-title>
        Encoding of two-counter machines
       </section-title>
       <paragraph>
        In [2] it was shown that model checking formulae of the form {a mathematical formula}《1》Agt0¯Fhalt is undecidable over RBMs, where {a mathematical formula}halt is an arbitrary proposition encoding that the TCM halts. In the following we show that this result carries over to iRBMs. Before we give the formal definitions and proof we present the basic idea underlying the reductions of [2] regarding RBMs.{sup:5} The key idea is to encode the transition table of the automaton as an RBM, where the two counters are simulated by two resource types {a mathematical formula}R1 and {a mathematical formula}R2. We give a reduction for both one and two agents. First, we describe the variant with two agents. In this variant, agent 1 is the simulator and agent 2 is the spoiler. Essentially, the role of agent 1 is to select transitions τ of the automaton, while the role of agent 2 is to ensure that only enabled transitions are selected by agent 1. As an illustration, let us consider a single transition {a mathematical formula}τ=((s,E1,E2),(s′,C1,C2)). The model has different types of states, including automaton states S. In states {a mathematical formula}s∈S the simulator agent 1 can execute an action {a mathematical formula}E1E2 followed by an action {a mathematical formula}sE1E2′C1C2. Both actions together simulate the selection of τ. The first action, {a mathematical formula}E1E2, is used to select and to (partially) check whether a transition of the TCM is enabled. That is, if {a mathematical formula}Ei=1, agent 1 must have a resource of type {a mathematical formula}Ri to execute the action. After executing {a mathematical formula}E1E2 the model enters a test state{a mathematical formula}sE1E2. The purpose of the test state is to check whether a transition with {a mathematical formula}Ei=0 was selected by agent 1 only if counter i was indeed zero. That is, the test state ensures that the simulation is sound. Note that, in general, nothing prevents agent 1 from executing such an action if it has resources available. The problem is that it is not possible to test for zero directly in the model.{sup:6} The workaround proposed in [2] is to use the spoiler agent 2 to encode the “zero test”. In a test state {a mathematical formula}sE1E2, agent 2 must not be able to reach the fail state{a mathematical formula}qf. Reaching the fail state is only possible if resources are available in cases where there should not be any. This is encoded in the model by test actions {a mathematical formula}testi with {a mathematical formula}i∈{1,2}. For example, if counter 1 should be empty, {a mathematical formula}E1=0, the action {a mathematical formula}test1 can only be executed if resources of type 1 are available. That is, the executability of the action indicates a flawed simulation. To work correctly, this requires that agent 2 correctly mirrors agent 1's resource balance, i.e. agent 2 also simulates the counter values. This is achieved by essentially making the model turn-based, in the sense that agent 2 frequently has no alternatives: once agent 1 has executed an action {a mathematical formula}sE1E2′C1C2 to update the counter values, an intermediate state {a mathematical formula}s′C1C2_ is introduced in which agent 2 has a single choice with the same effect on its resource balance as agent 1's previous action.{sup:7} Based on this idea, it is shown in [2] (using the finitary semantics) that the TCM {a mathematical formula}A halts on the empty input if, and only if, the formula {a mathematical formula}《1》{1,2}0¯Fhalt holds in the corresponding model. The state corresponding to the automaton's accepting state is labelled {a mathematical formula}halt.
       </paragraph>
       <paragraph>
        In extending the reduction to iRBMs, the main difficulty is correctly mirroring agent 1's resources by agent 2 in the presence of idle actions. It is no longer possible to give agent 2 only a single action to execute; an action with no costs must also be available. We extend the construction outlined above accordingly. The key idea is that executing the idle action does not help agent 2 spoil the execution. The next definition formalises an appropriate encoding to work over iRBMs.
       </paragraph>
       <paragraph label="Definition 3">
        {a mathematical formula}M1ALet {a mathematical formula}A=(S,sinit,Sf,Δ) be an empty-band TCM. From {a mathematical formula}A we construct the iRBM{a mathematical formula}M1A=({1,2},Q,Π,π,Act,d,o,{R1,R2},t) with
       </paragraph>
       <list>
        <list-item label="1.">
         {a mathematical formula}Q=S∪Q1∪Q2∪{qf,qh,q⥁} where {a mathematical formula}Q1={sE1E2|s∈S,E1,E2∈{0,1}} and {a mathematical formula}Q2={sC1C2_|s∈S,C1,C2∈{−1,0,1}}. State {a mathematical formula}qf (resp. {a mathematical formula}qh and {a mathematical formula}q⥁) is called a fail state (resp. auxiliary halting state and loop state).
        </list-item>
        <list-item label="2.">
         The set Act of actions is defined as follows. For each transition {a mathematical formula}((s,E1,E2),(s′,C1,C2)) of {a mathematical formula}A the set contains actions {a mathematical formula}E1E2, {a mathematical formula}sE1E2′C1C2, and {a mathematical formula}s′C1C2. Additionally, there are the idle action idle and test actions {a mathematical formula}testi for {a mathematical formula}i∈{1,2}.
        </list-item>
        <list-item label="3.">
         The action availability is defined according to Δ. For agent 1 we have:{a mathematical formula} and for agent 2:{a mathematical formula}
        </list-item>
        <list-item label="4.">
         The set of propositions is defined by {a mathematical formula}Π={halt,fail}. All states in {a mathematical formula}{qh}∪Sf are labelled with {a mathematical formula}halt and {a mathematical formula}qf is labelled with {a mathematical formula}fail.
        </list-item>
        <list-item label="5.">
         The transition function is defined as follows:{a mathematical formula} where ⋆ represents any action available to the respective agent in that state.
        </list-item>
        <list-item label="6.">
         The actions' resource consumption/production is defined by function t where {a mathematical formula}i,r∈{1,2}:{a mathematical formula}
        </list-item>
       </list>
       <paragraph>
        Let us consider a TCM {a mathematical formula}A=(S,sinit,Sf,Δ). The construction of the model {a mathematical formula}M1A is sketched in Fig. 2 (left), and the encoding of a single transition {a mathematical formula}τ=((s,E1,E2),(s′,C1,C2)) is illustrated in Fig. 2 (right). As explained above, the action {a mathematical formula}E1E2 consumes {a mathematical formula}−Er resources of {a mathematical formula}Rr for {a mathematical formula}r=1,2. This simulates that only enabled transitions τ can be taken. If {a mathematical formula}Er=1 then the action {a mathematical formula}E1E2 can only be taken if resources {a mathematical formula}Rr≥1. Actions of type {a mathematical formula}sE1E2C1C2 consume/produce {a mathematical formula}Cr+Er units of resource {a mathematical formula}Rr, {a mathematical formula}r=1,2. The component {a mathematical formula}Cr simulates the decrement and increment of counter r where {a mathematical formula}Er corrects the possible (temporary) subtraction from the previous action {a mathematical formula}E1E2. The necessary information to select the correct action is stored in the state {a mathematical formula}sE1E2. Clearly, actions can only be performed if sufficient resources are available. The difficulty is to ensure that actions {a mathematical formula}E1E2 with some {a mathematical formula}Er=0 are only performed if the counter r is actually 0; that is, if no resources of type {a mathematical formula}Rr are available. For this purpose, test actions{a mathematical formula}testr that cost −1 units of resource {a mathematical formula}Rr for {a mathematical formula}r∈{1,2}, are introduced. Such an action {a mathematical formula}testr can only be performed in states {a mathematical formula}sE1E2 if {a mathematical formula}Er=0, and it always leads to the fail state {a mathematical formula}qf. Now, in a state {a mathematical formula}sE1E2 with some element equal to 0, say {a mathematical formula}E1=0, {a mathematical formula}E2=1, (representing that counter 1 should be zero and 2 should be non-zero) the action {a mathematical formula}test1 can be used to verify whether the currently available resources model the counter correctly: if {a mathematical formula}qf is reachable, resources of type {a mathematical formula}R1 are available, although this should not be the case according to {a mathematical formula}E1.
       </paragraph>
      </section>
      <section label="4.1.2">
       <section-title>
        Properties of the encoding: the simulation lemma
       </section-title>
       <paragraph>
        In the following, we state properties of the encoding, and prove a simulation lemma which relates runs of the two-counter machine with paths in the model. First, we make a straightforward observation:
       </paragraph>
       <paragraph label="Observation 3">
        The model{a mathematical formula}M1Ais aniRBM.
       </paragraph>
       <paragraph>
        We define the concept of a computation pre-encoding. This is a finite path in the model which will later be shown to encode a partial computation of the automaton.
       </paragraph>
       <paragraph label="Definition 4">
        Computation pre-encoding of {a mathematical formula}M1ALet {a mathematical formula}A be an empty-band TCM. A finite resource-extended path {a mathematical formula}λ∈(Q×En)+ in {a mathematical formula}M1A is called an {a mathematical formula}A-computation pre-encoding of{a mathematical formula}M1A if it satisfies the following properties:
       </paragraph>
       <list>
        <list-item label="1.">
         {a mathematical formula}η(1,Rr)=η(2,Rr) where {a mathematical formula}λ[0]=(q,η) for {a mathematical formula}r∈{1,2}; and
        </list-item>
        <list-item label="2.">
         {a mathematical formula}λ|Q=(si(siE1iE2i)(si+1C1iC2i_))i=1,…,ksk+1 or {a mathematical formula}λ|Q=s1.
        </list-item>
       </list>
       <paragraph>
        The first requirement states that the endowments of both agents must be the same in the initial state. The second requirement expresses that a fail, auxiliary halting, or loop state must never be visited, and the path ends in a state that is also a state of {a mathematical formula}A; moreover, it specifies the order in which states in the model are visited. The latter is inherent in the construction of the model. The next proposition states that, on a computation pre-encoding, agent 2 correctly mirrors the resources of agent 1 whenever a state in the model, representing a state of the TCM, is visited.
       </paragraph>
       <paragraph label="Proposition 1">
        Let{a mathematical formula}Abe an empty-band TCM and{a mathematical formula}λ=(qi,ηi)i=1,…,3(k−1)+1be an{a mathematical formula}A-computation pre-encoding.
       </paragraph>
       <list>
        <list-item>
         We have that{a mathematical formula}η3(k−1)+1(1,Rr)=η3(k−1)+1(2,Rr)for{a mathematical formula}r=1,2.
        </list-item>
        <list-item>
         If{a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′)is a partial resource-extended path, then{a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′)(s′,η″)is a partial resource-extended path with a uniquely defined endowment{a mathematical formula}η″.
        </list-item>
        <list-item>
         If{a mathematical formula}λ[i]=(qi,ηi)=(sE1E2,ηi)with{a mathematical formula}Er=0, then ({a mathematical formula}ηi(1,Rr)=0if, and only if,{a mathematical formula}ηi(2,Rr)=0), where{a mathematical formula}r∈{1,2}.
        </list-item>
       </list>
       <paragraph>
        The proof is given in Appendix A.1. Part (a) expresses that the resource endowments of agents 1 and 2 are identical whenever a state q corresponding to an automaton state s is reached. Part (b) says that agent 2 always has enough resources in states of type {a mathematical formula}s′C1C2_ to mirror the action executed by agent 1 one step before. Finally, in (c) the crucial observation is made that in the test states {a mathematical formula}sE1E2 with {a mathematical formula}Er=0 for {a mathematical formula}r∈{1,2}, both agents both have either no resources of {a mathematical formula}Rr available, or they both have resources of {a mathematical formula}Rr available. This ensures that the test actions are correctly executed.
       </paragraph>
       <paragraph>
        The next definition relates a computation pre-encoding to the computations of the automaton it simulates. This means that essentially the same automaton states are visited, and the resources of agent 1 correctly simulate the counter values.
       </paragraph>
       <paragraph label="Definition 5">
        Simulation, {a mathematical formula}A-computation encodingWe say that the {a mathematical formula}A-computation pre-encoding {a mathematical formula}λ=(qi,ηi)i=1,…,3(k−1)+1, {a mathematical formula}k∈N, simulates the computation ρ iff the following holds:
       </paragraph>
       <list>
        <list-item label="1.">
         ρ has length k;
        </list-item>
        <list-item label="2.">
         for every {a mathematical formula}i∈{1,…,k} if {a mathematical formula}ρ[i]=(s,v1,v2) then {a mathematical formula}λ[3(i−1)+1]=(s,η) with {a mathematical formula}η(1,Rr)=vr for {a mathematical formula}r∈{1,2}; and
        </list-item>
        <list-item label="3.">
         for any configuration {a mathematical formula}λ[i]=(sE1E2,η) on λ with {a mathematical formula}Er=0, {a mathematical formula}r∈{1,2}, it holds that {a mathematical formula}η(1,Rr)=0.
        </list-item>
       </list>
       <paragraph>
        The following lemma is the key step in our reduction. It specifies that the computation pre-encodings do exactly characterise the computations of the automaton. In other words, the behaviour of the automaton is exactly captured by the computation pre-encoding in the constructed iRBM. This lemma concludes the construction of {a mathematical formula}M1A and the analysis of its structural properties.
       </paragraph>
       <paragraph label="Lemma 1">
        Simulation Lemma for {a mathematical formula}M1AThere is a bijection{a mathematical formula}fAbetween computations of{a mathematical formula}Aand{a mathematical formula}A-computation encodings of{a mathematical formula}M1Asuch that{a mathematical formula}fA(ρ)simulates the computation ρ. In particular, if ρ is an accepting computation then{a mathematical formula}fA(ρ)is also accepting.
       </paragraph>
       <paragraph>
        The proof is given in Appendix A.1.
       </paragraph>
      </section>
      <section label="4.1.3">
       <section-title>
        Resource-flat fragment with two resource types
       </section-title>
       <paragraph>
        We first show that proponent restrictedness is essential for decidability over iRBMs, by showing that resource flatness is not sufficient, and {a mathematical formula}rfRAL is undecidable over iRBMs. In [2] it was shown that model checking formulae of type {a mathematical formula}《1》Agt0¯Fhalt is undecidable over RBMs. The decidability of this fragment was open over iRBMs. In Theorem 1, we show that undecidability continues to hold. The proof adapts the approach of [2] to work over iRBMs.
       </paragraph>
       <paragraph>
        As in [2] we show that the empty-band TCM {a mathematical formula}A halts iff {a mathematical formula}M1A,qinit,0¯⊨《1》{1,2}0¯Fhalt. By Lemma 1 this is equivalent to showing that there is an accepting {a mathematical formula}A-computation encoding iff {a mathematical formula}M1A,qinit,0¯⊨《1》{1,2}0¯Fhalt.
       </paragraph>
       <paragraph>
        Consider the encoding of {a mathematical formula}(s,E1,E2)Δ(s′,C1,C2) shown in Fig. 2. First, we observe that executing an idle action is not helpful for agent 1 in states s and {a mathematical formula}sE1E2; neither is it helpful for agent 2 to idle in a state {a mathematical formula}s′C1C2_. If agent 1 executes idle in states s or {a mathematical formula}sE1E2, this would yield the state {a mathematical formula}qf or {a mathematical formula}q⥁ which cannot help to make the formula true; on the contrary, if the formula is not already true, these states make it false. Similarly, if agent 2 executes idle in {a mathematical formula}s′C1C2, the formula would be true when state {a mathematical formula}qh is reached. As we are looking for a winning strategy for agent 1 against all strategies of agent 2, we can neglect the cases where either agent executes an idle action in the aforementioned states. As a result, we only need to consider paths that have the structure of {a mathematical formula}A-computation pre-encodings. The second agent is needed to ensure that agent 1 chooses actions that yield an {a mathematical formula}A-computation encoding, i.e. that the selection of actions simulates a possible behaviour of the automaton. By construction, agent 2 only has a choice in states {a mathematical formula}sE1E2 and {a mathematical formula}s′C1C2. In the former state the agent can execute a test action if sufficient resources are available. In the latter, it could idle—as discussed above, an action the agent should not execute. As a consequence, in states of type {a mathematical formula}s′C1C2, agent 2 should essentially only perform the action {a mathematical formula}s′C1C2 ensuring that the agent's resources mirror agent 1's resources (cf. Proposition 1). This essentially ensures condition 3 of Definition 5 (simulation). Formally, we have:
       </paragraph>
       <paragraph label="Lemma 2">
        The empty-band TCM{a mathematical formula}Ahalts iff{a mathematical formula}M1A,sinit,0¯⊨《1》{1,2}0¯Fhalt.
       </paragraph>
       <paragraph>
        We briefly sketch the main idea of the proof below; the full proof is given in Appendix A.1:
       </paragraph>
       <list>
        <list-item label="•">
         Suppose that {a mathematical formula}A halts. Then, agent 1 simulates the transitions of the machine's accepting run. Due to the simulation, agent 2 will never be able to enforce the fail state {a mathematical formula}qf. Moreover, either agent 2's resources correctly mirror agent 1's resources, or agent 2 performs the idle action. In both cases, either an accepting state or the auxiliary halting state {a mathematical formula}qh, both labelled {a mathematical formula}halt, are reached. The formula is true.
        </list-item>
        <list-item label="•">
         Let the formula be true. Agent 1 must have a strategy that guarantees reaching a state labelled {a mathematical formula}halt against all strategies of agent 2, including agent 2's strategy in which agent 2 never performs the idle action. This strategy of agent 2 correctly mirrors agent 1's resources and ensures that agent 1's strategy only selects enabled transitions. Thus, the strategy of agent 1 yields a {a mathematical formula}A-computation encoding.
        </list-item>
       </list>
       <paragraph>
        The previous lemma immediately yields the following theorem which concludes our study of {a mathematical formula}rfRAL with two resource types.
       </paragraph>
       <paragraph label="Theorem 1">
        Model checking{a mathematical formula}rfRALover the class ofiRBMs is undecidable, even for two agents and two resource types.
       </paragraph>
      </section>
      <section label="4.1.4">
       <section-title>
        The proponent restricted fragment with two resource types
       </section-title>
       <paragraph>
        Theorem 1 shows that the restriction of resource-flatness is not enough to obtain a decidable model checking property. In this section, we consider the proponent-restricted fragment. We show that proponent-restrictedness on its own is also not sufficient for decidability, and {a mathematical formula}prRAL is undecidable over iRBMs. We do this by adapting the undecidability proof of [2] for {a mathematical formula}prRAL to work over iRBMs. This is a negative result. However, in contrast to Theorem 1, the formula used in the reduction is more complex. This leaves room for restrictions on the temporal structure of {a mathematical formula}prRAL. Indeed, this is the motivation for the decidable fragment of {a mathematical formula}prRAL that we introduce in Section 4.3.
       </paragraph>
       <paragraph label="Lemma 3">
        The proof of the undecidability result for {a mathematical formula}prRAL over RBMs of [2] essentially follows an encoding similar to the one shown in Fig. 3. However, in contrast to the previous encoding, the second agent is removed, and agent 1 itself is used to perform the zero test. This requires a slightly more sophisticated formula. First, we show a reduction with respect to our original, two-player model {a mathematical formula}M1A: the automaton {a mathematical formula}A halts if, and only if, {a mathematical formula}M1A,qinit,0¯⊨《1,2》0¯((¬《1,2》↓Xfail)Uhalt). The main idea is that in test state {a mathematical formula}sE1E2, agents {a mathematical formula}{1,2} must not be able to reach the fail state{a mathematical formula}qf, which is expressed by {a mathematical formula}¬《{1,2}》↓Xfail. The next lemma follows essentially as a Corollary of [2], by adding idle loops to the construction. However, for uniformity, we base the proof on the model {a mathematical formula}M1A. The empty-band TCM{a mathematical formula}Ahalts iff{a mathematical formula}M1A,qinit,0¯⊨《1,2》0¯((¬《1,2》↓Xfail)Uhalt).
       </paragraph>
       <paragraph label="Proof">
        The proof is analogous to the one given for Lemma 2. For the direction “⇒” it is sufficient to observe that the only states from which the fail state {a mathematical formula}qf can be reached within one step are of the form {a mathematical formula}sE1E2 with {a mathematical formula}Er=0 for {a mathematical formula}r∈{1,2}. Thus, the strategy profile {a mathematical formula}(s1,s2), where {a mathematical formula}s1 is the strategy of agent 1 as defined in Lemma 2 and {a mathematical formula}s2 is an arbitrary strategy for agent 2, witnesses the truth of the formula. The other direction is done analogously to Lemma 2. □
       </paragraph>
       <paragraph>
        In the formula used in the reduction of Lemma 3, {a mathematical formula}《1,2》0¯((¬《1,2》↓Xfail)Uhalt), the two agents 1 and 2 always act as a team; there is no opponent. Thus, the two agents can be merged into a single agent. The next result makes this observation precise.
       </paragraph>
       <paragraph label="Proof">
        Model checking{a mathematical formula}prRALover the class ofiRBMs is undecidable, even in the case of a single agent and two resource types.We modify the model {a mathematical formula}M1A=({1,2},Q,Π,π,Act,d,o,{R1,R2},t) to a model {a mathematical formula}Mˆ1A=({1},Q\{qh},Π,πˆ,Actˆ,dˆ,oˆ,{R1,R2},tˆ). We remove the auxiliary halting state as it must not be reached by the proponent agent 1. Essentially, we merge the two agents into one. The encoding of a single automaton transition is shown in Fig. 3. We define {a mathematical formula}dˆ1(q) as {a mathematical formula}d1(q) where we additionally require that {a mathematical formula}testi∈dˆ1(sE1E2) iff Ei=0; agent 1 can now make all decisions. The action set {a mathematical formula}Actˆ equals Act but all actions of type {a mathematical formula}sC1C2 are removed. The transition function {a mathematical formula}oˆ is obtained from o:{a mathematical formula} The cost function {a mathematical formula}tˆ and the labelling function {a mathematical formula}πˆ are defined as before restricted to the new action set.Now, it is easy to see that each resource-extended path {a mathematical formula}λ=(qi,ηi)i∈N in {a mathematical formula}M1A that does not visit state {a mathematical formula}qh corresponds to a path {a mathematical formula}λ=(qi,ηˆi)i∈N in {a mathematical formula}Mˆ1A with {a mathematical formula}ηˆi(1,Rr)=ηi(1,Rr). By Proposition 1(c), the zero-test in the test states can equivalently be defined with respect to agent 1's resource endowment. It is immediate that {a mathematical formula}M1A,qinit,0¯⊨《1,2》0¯((¬《1,2》↓Xfail)Uhalt) if, and only if, {a mathematical formula}Mˆ1A,qinit,0¯⊨《1》0¯((¬《1》↓Xfail)Uhalt). □
       </paragraph>
       <paragraph label="Remark 2">
        We note that we can further simplify model {a mathematical formula}Mˆ1A. For example, states of type {a mathematical formula}s′C1C2_ are not needed. Keeping them, however, allows us to reuse the previous notation and thus simplifies the presentation.
       </paragraph>
      </section>
     </section>
     <section label="4.2">
      Undecidability of {a mathematical formula}prRAL and {a mathematical formula}rfRAL with one resource type over iRBMs
      <paragraph>
       The reductions presented in the previous section use two resource types to simulate the two counters of the two-counter machine. In this section we show that the model checking problem for {a mathematical formula}prRAL and {a mathematical formula}rfRAL remain undecidable even if each agent has only one resource type available. This shows that proponent restriction and resource flatness are essential even with one resource type. Settings restricted to a single resource type are an important special case, as having only one resource type available might be expected to make model checking less complex. For example, with one resource type, the complexity of RB±ATL goes from EXPSPACE-hard to PSPACE-complete [8], [9]. The reductions in the case of one resource type are more complex. Specifically, the number of agents doubles: instead of one agent in the proponent-restricted setting, we need two; and instead of two agents in the resource-flat setting, we need four.
      </paragraph>
      <section label="4.2.1">
       <section-title>
        Encoding two-counter machines
       </section-title>
       <paragraph>
        The encoding of the TCM is very similar to the encoding presented in Section 4.1.1. The key difference is that we can no longer use a single action to update both resource types at the same time. The actions must be split into two. Instead of an action {a mathematical formula}E1E2, we introduce two actions {a mathematical formula}E_1E2 and {a mathematical formula}E1E_2, where the first and second action are controlled by the first and second agent, respectively, and change the agent's single resource type according to {a mathematical formula}E1 and {a mathematical formula}E2, respectively. Similarly, actions of type {a mathematical formula}sC1C2E1E2 are split into {a mathematical formula}sC_1C2E_1E2 and {a mathematical formula}sC1C_2E1E_2. The underscore indicates which parts of the action should be used to update the resources of the agent executing the action.
       </paragraph>
       <paragraph>
        The technical presentation requires a little more notation. The decomposition ensures that the agents coordinate their actions so that the action tuples consisting of the actions of the first and second agent have a counterpart in the TCM. This is best illustrated by an example. Suppose the automaton contains the transitions {a mathematical formula}((s,0,1),(s′,1,1)) and {a mathematical formula}((s,1,0),(s′,1,1)), and that these are the only two transitions which should be enabled in state s. In the new encoding, agent 1 would have the actions {a mathematical formula}0_1, {a mathematical formula}1_0, and idle in its repertoire at state s. Similarly, agent 2 has actions {a mathematical formula}01_, {a mathematical formula}10_, and idle available at state s. As both agents are autonomous decision makers they are free to choose actions independently. Hence, the action profile {a mathematical formula}(0_1,10_) may result from their action selection. Clearly, this is an undesirable action tuple, as it does not correspond to any transition of the automaton. We need to ensure that such action profiles never yield a behaviour which encodes an accepting run of the automaton. Therefore, the model is constructed in such a way that invalid action profiles result in the loop state {a mathematical formula}q⥁.
       </paragraph>
       <paragraph>
        With this change, the other parts of the previous encoding can be used with only minor modifications. Agents {a mathematical formula}{1,2} are used to simulate the behaviour of the automaton, and agents {a mathematical formula}{3,4} play the role of the spoiler agents who ensure that the simulation is sound. Thus, the coalition {a mathematical formula}{3,4} is used to encode the zero-test. This requires that agent 3 mirrors the resources of agent 1, and agent 4 the resources of agent 2. The new encoding of a transition is illustrated in Fig. 4, and the formal definition of the model is given in Appendix A.2 (Definition 7).
       </paragraph>
      </section>
      <section label="4.2.2">
       <section-title>
        Properties of the encoding: the simulation lemma
       </section-title>
       <paragraph>
        Analogously to Section 4.1.2, we present a simulation lemma. We also need to introduce computation pre-encodings etc. with respect to {a mathematical formula}M2A. For the sake of readability, we mostly refrain from giving formal definitions, and focus on the key modifications. An {a mathematical formula}A-computation pre-encoding of{a mathematical formula}M2A is defined as for {a mathematical formula}M1A, but the initial condition is changed to {a mathematical formula}η(a,R)=η(b,R) for agents {a mathematical formula}(a,b)∈{(1,3),(2,4)} where R refers to the single resource type. (In the following we use a and b to denote the agents, where b simulates the resources of a.) That is, the initial endowment for agents 1 and 3, as well as for agents 2 and 4 must be identical. With this notion we can also prove basic properties analogously to Proposition 1. The new version of Proposition 1 reads as follows:
       </paragraph>
       <list>
        <list-item label="(a)">
         We have that {a mathematical formula}η3(k−1)+1(a,R)=η3(k−1)+1(b,R) for {a mathematical formula}(a,b)∈{(1,3),(2,4)}.
        </list-item>
        <list-item label="(b)">
         If {a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′) is a resource-extended path, then {a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′)(s′,η″) is a resource-extended path with a uniquely defined endowment {a mathematical formula}η″.
        </list-item>
        <list-item label="(c)">
         If {a mathematical formula}λ[i]=(qi,ηi)=(sE1E2,ηi) with {a mathematical formula}Ea=0, then ({a mathematical formula}ηi(a,R)=0 if and only if {a mathematical formula}ηi(b,R)=0), where {a mathematical formula}(a,b)∈{(1,3),(2,4)}.
        </list-item>
       </list>
       <paragraph>
        (b) remains unchanged, and expresses that agents 3 and 4 correctly mirror the resources of agents 1 and 2, respectively. We introduce the revised notion of simulation. We say that the {a mathematical formula}A-computation pre-encoding {a mathematical formula}λ=(qi,ηi)i∈{1,…,3(k−1)+1} of {a mathematical formula}M2A, {a mathematical formula}k∈N, simulates the{a mathematical formula}A-computation ρ (wrt. {a mathematical formula}M2A) if the following holds:
       </paragraph>
       <list>
        <list-item label="1.">
         ρ has length k;
        </list-item>
        <list-item label="2.">
         for every {a mathematical formula}i∈{1,…,k} if {a mathematical formula}ρ[i]=(s,v1,v2) then {a mathematical formula}λ[3(i−1)+1]=(s,η) with {a mathematical formula}η(1,R)=v1 and {a mathematical formula}η(2,R)=v2; and
        </list-item>
        <list-item label="3.">
         for any configuration {a mathematical formula}λ[i]=(sE1E2,η) on λ with {a mathematical formula}Er=0, {a mathematical formula}r∈{1,2}, it holds that {a mathematical formula}η(r,R)=0.
        </list-item>
       </list>
       <paragraph>
        Note that counters now refer to the unique resource type of different agents, rather than to different resource types of a single agent.
       </paragraph>
       <paragraph>
        Analogously to Lemma 1 we can prove the following adapted simulation lemma.
       </paragraph>
       <paragraph label="Lemma 4">
        Simulation Lemma for {a mathematical formula}M2AThere is a bijection{a mathematical formula}fAbetween computations of{a mathematical formula}Aand{a mathematical formula}A-computation encodings of{a mathematical formula}M2Asuch that{a mathematical formula}fA(ρ)simulates the computation ρ. In particular, if ρ is an accepting computation then{a mathematical formula}fA(ρ)is also accepting.
       </paragraph>
      </section>
      <section label="4.2.3">
       <section-title>
        Resource-flat fragment with one resource type
       </section-title>
       <paragraph>
        In this section we prove undecidability of {a mathematical formula}rfRAL with only one resource type. We proceed analogously to Section 4.1.3. We show that the empty-band TCM {a mathematical formula}A halts if, and only if, {a mathematical formula}M2A,sinit,0¯⊨《1,2》{1,2,3,4}0¯Fhalt. Again, we observe that for any encoding of a transition {a mathematical formula}(s,E1,E2)Δ(s′,C1,C2) shown in Fig. 4, agents 1 and 2 (resp. 3 and 4) have no incentive to idle in states s and {a mathematical formula}sE1E2 (resp. in state {a mathematical formula}s′C1C2_). Instead of looking for a winning strategy for {1} we look for a winning strategy for {a mathematical formula}{1,2}. The key idea is that the coalition behaves in such a way that their combined action corresponds to the action selection of {1} in Section 4.1.3. Given the reformulation of properties above, we can make the following observations:
       </paragraph>
       <list>
        <list-item label="•">
         If {a mathematical formula}A halts, then coalition {a mathematical formula}{1,2} simulates the transitions of the machine's accepting run. Due to the simulation, coalition {a mathematical formula}{3,4} will never be able to enforce the fail state {a mathematical formula}qf. Moreover, either agent b's resources correctly mirror agent a's resources, or agent b performs the idle action for {a mathematical formula}(a,b)∈{(1,3),(2,4)}. In both cases, either an accepting state or the auxiliary halting state {a mathematical formula}qh, both labelled {a mathematical formula}halt, are reached. The formula is true.
        </list-item>
        <list-item label="•">
         Let the formula be true. Coalition {a mathematical formula}{1,2} must have a strategy that guarantees reaching a state labelled {a mathematical formula}halt against all strategies of {a mathematical formula}{3,4}, including the collective strategy of {a mathematical formula}{3,4} in which an idle action is never performed in states of type {a mathematical formula}s′C1C2_. This strategy of agent b correctly mirrors agent a's resources and ensures that agent a's strategy only selects enabled transitions, {a mathematical formula}(a,b)∈{(1,3),(2,4)}. Thus, the strategy of {a mathematical formula}{1,2} yields an {a mathematical formula}A-computation encoding. By Simulation Lemma 4 the TCM has an accepting run and halts.
        </list-item>
       </list>
       <paragraph>
        Formally, we capture the previous discussion in the following Lemma and Theorem.
       </paragraph>
       <paragraph label="Lemma 5">
        The empty-band TCM{a mathematical formula}Ahalts iff{a mathematical formula}M2A,sinit,0¯⊨《1,2》{1,2,3,4}0¯Fhalt.
       </paragraph>
       <paragraph label="Theorem 3">
        Model checking{a mathematical formula}rfRALover the class ofiRBMs is undecidable, even in the case of a single resource type and four agents.
       </paragraph>
       <paragraph>
        The proofs of Lemma 5 and Theorem 3 are analogous to those of Lemma 2 and Theorem 1, respectively.
       </paragraph>
      </section>
      <section label="4.2.4">
       <section-title>
        The proponent restricted fragment with one resource type
       </section-title>
       <paragraph>
        Finally, we consider the proponent-restricted fragment. Again, the line of argument is analogous to the one followed in Section 4.1.4, but there is one caveat when it comes to merging the agents. We first state the analogue of Lemma 3.
       </paragraph>
       <paragraph label="Lemma 6">
        The empty-band TCM{a mathematical formula}Ahalts iff{a mathematical formula}M2A,qinit,0¯⊨《1,2,3,4》0¯((¬《1,2,3,4》↓Xfail)Uhalt). Next, we observe that the agents {a mathematical formula}{1,2,3,4} act as a team. Thus, we can consider their decision making as the decision making of a single “merged” agent. However, in contrast to the setting of Section 4.1.4, we cannot explicitly model this by a single agent as there is only one resource type. Thus, we merge agents {a mathematical formula}{1,3} and agents {a mathematical formula}{2,4} into two distinct agents. The resulting model {a mathematical formula}Mˆ2A is illustrated in Fig. 5.
       </paragraph>
       <paragraph label="Theorem 4">
        Model checking{a mathematical formula}prRALover the class ofiRBMs is undecidable, even in the case of a single resource type and two agents.
       </paragraph>
       <paragraph>
        The proof is given in Appendix A.2.
       </paragraph>
      </section>
     </section>
     <section label="4.3">
      The positive proponent-restricted fragment of {a mathematical formula}RAL
      <paragraph>
       Following the observation made in the previous sections about the proponent-restricted variants of {a mathematical formula}RAL (cf. Theorem 2, Theorem 4) we define a proponent-restricted but not resource-flat fragment of {a mathematical formula}RAL, {a mathematical formula}pprRAL, that has a decidable model checking property over iRBMs. We first define the positive fragment of {a mathematical formula}RAL as the set of all {a mathematical formula}RAL-formulae where no cooperation modality is under the scope of a negation symbol.
      </paragraph>
      <paragraph label="Definition 6">
       The fragment {a mathematical formula}pprRALThe logic {a mathematical formula}pprRAL is defined as the proponent-restricted and positive fragment of {a mathematical formula}RAL.{sup:8}
      </paragraph>
      <paragraph>
       As noted in the introduction, the {a mathematical formula}pprRAL-fragment allows us to express properties of coalitions of agents which re-consider their strategies without being re-equipped with fresh resources. For example, we can formalise the property “given their initial battery charge, rescue robots A can safely get to a position from which they can perform rescue while in visual contact with the base” as: {a mathematical formula}《A》ηinit(safeU(《A》↓(visualUrescue))). Intuitively, this reflects the constraint that the robots cannot recharge their batteries after reaching the position where they can perform rescue while in visual contact with the base. This is expressible in {a mathematical formula}pprRAL but not in {a mathematical formula}rfRAL. Another example is the formula {a mathematical formula}《1,2》ηinitF(rob∧《1》↓Fescape), expressing that the coalition {a mathematical formula}{1,2} can cooperate to eventually rob a bank, following which agent 1 has a strategy to escape on its own using only its remaining resources.
      </paragraph>
      <paragraph label="Observation 4">
       Before we show the decidability of {a mathematical formula}pprRAL over iRBMs in the next section, we make the following observation which follows from [2, Theorem 6]: Model checking{a mathematical formula}pprRALoverRBMs is undecidable.
      </paragraph>
      <paragraph>
       To give a flavour of the basic idea of the undecidability proof, let us consider Fig. 2. We have to modify the construction in such a way that, in test states {a mathematical formula}sE1E2, the opponent can always execute a test action corresponding to a counter that should be zero, after which a new state is reached in which the proponent has to execute a specific action. In a sense the opponent can challenge the proponent to execute this specific action. Now, there are two options. First, the proponent has not sufficient resources to execute the action, which means that the counter is simulated correctly. In that case the history leading to the current state is disregarded as it cannot be extended to a resource-extended path (recall that such paths have to be infinite). Second, the proponent can execute the action. This would result in a new fail state labelled with a specific proposition, say {a mathematical formula}error, indicating that the reduction is flawed. Then, the simulation is continued by connecting the fail state with the state {a mathematical formula}s′C1C2_ which would have been reached if the opponent had not executed the test action. Given this modification, we can show formally that {a mathematical formula}M,qinit,0¯⊨《1》0¯(¬error)Uhalt iff the automaton {a mathematical formula}A halts on the empty input, where {a mathematical formula}M is a modified version of {a mathematical formula}M2A essentially along the lines sketched above (in particular, all idle actions are removed).
      </paragraph>
      <paragraph>
       It is important to note that in the presence of idle actions, this reduction no longer works, as the proponent always has a choice. Even in the case where the proponent has no resources left, the computation of the system can always be extended to be infinite, either by visiting the fail state, or by looping in some state. As a consequence, a halting state may never be reached. This implies that the opponent has too much power, and can always spoil the simulation by performing a test action in cases where the simulation is sound and no resources are available. That there is no way to save the reduction is shown by the decidability result we present in the next section.
      </paragraph>
     </section>
    </section>
    <section label="5">
     Model-checking {a mathematical formula}pprRAL over iRBMs
     <paragraph>
      In this section we prove that the model checking problem for the fragment {a mathematical formula}pprRAL over iRBMs is decidable. We first present the model checking algorithm for {a mathematical formula}pprRAL over iRBMs, and then prove termination and correctness of the algorithm in Lemma 7, Lemma 8, respectively.
     </paragraph>
     <section label="5.1">
      Model checking algorithm for {a mathematical formula}pprRAL
      <paragraph>
       The model checking algorithm for {a mathematical formula}pprRAL over iRBMs takes as input a model {a mathematical formula}M, formula ϕ, and initial endowment η, and labels the set of states {a mathematical formula}[ϕ]Mη, where {a mathematical formula}[ϕ]Mη={q|M,q,η⊨ϕ} is the set of states satisfying ϕ (see Algorithm 1).{sup:9}
      </paragraph>
      <paragraph>
       Given ϕ, we produce the set of subformulae of ϕ, {a mathematical formula}Sub(ϕ), in the usual way, except that {a mathematical formula}《A》↓ and {a mathematical formula}《A》ζ modalities are replaced by standard ATL modalities {a mathematical formula}《A》. {a mathematical formula}Sub(ϕ) is ordered in increasing order of complexity. For a formula {a mathematical formula}ϕ′∈Sub(ϕ), we will write {a mathematical formula}s⊨ϕ′ to indicate that state s has been labelled by {a mathematical formula}ϕ′. Note that if a state s is not annotated with the standard ATL modality {a mathematical formula}《A》, then it cannot satisfy {a mathematical formula}《A》↓ or {a mathematical formula}《A》ζ. Algorithm 1 simply labels states with the subformulae of ϕ using the standard ATL labelling algorithm [32] (lines 2–3). It then calls the function strategy to label states with ϕ (line 4). prop is a function that returns either the proponents {a mathematical formula}A⊆Agt if ϕ is of the form {a mathematical formula}《A》⁎Xψ,《A》⁎ψ1Uψ2,《A》⁎Gψ where ⁎ is either ↓ or an endowment, or {a mathematical formula}Agt otherwise. The function {a mathematical formula}node0 initialises the root node for the function strategy and is explained below.{sup:10}
      </paragraph>
      <paragraph>
       The function strategy is shown in Algorithm 2 and proceeds by depth-first and-or search. That is, we examine each path in the search space in turn, as in standard depth-first search, but treat nodes corresponding to a particular choice of action by A as and-nodes, i.e., all branches corresponding to this choice must return true for the choice to be part of a successful strategy. The function strategy processes each coalition modality in turn, starting from the outermost modality. The logical connectives are standard, and simply call strategy on the subformulae. Each temporal operator is handled by a separate function: x-strategy for {a mathematical formula}Xψ, u-strategy for {a mathematical formula}ψ1Uψ2, and g-strategy for {a mathematical formula}Gψ, and are explained below. We record information about the state of the search in a search tree of nodes. A node is a structure which consists of a state of {a mathematical formula}M, the resources available to all the agents in that state, and a finite path of nodes leading to this node from the root node. Edges in the search tree correspond to joint actions by all agents. Note that the resources available to the agents in a state on a path constrain the edges from the corresponding node to be those action profiles {a mathematical formula}αA where for all proponent agents a, {a mathematical formula}(cons(αa,r))r∈Res is less than or equal to the available resources of agent a. We compare vectors of resources in the usual way; for example, {a mathematical formula}ζa≥(cons(αa,r))r∈Res stands for {a mathematical formula}ζa(r)≥cons(αa,r) for all resources r. For an action profile {a mathematical formula}αA of {a mathematical formula}A⊆Agt, we write {a mathematical formula}cons(α) to refer to the tuple {a mathematical formula}((cons(αa))r∈Res)a∈A. For each node n in the tree, we have a function {a mathematical formula}s(n) which returns its state, {a mathematical formula}p(n) which returns the sequence of nodes on the path to n, {a mathematical formula}e(n) which returns an endowment specifying the resource availability for all agents as a result of following {a mathematical formula}p(n), {a mathematical formula}v(n) which returns the resources potentially available to the agents as a result of traversing cycles on {a mathematical formula}p(n) additional times,{sup:11} and {a mathematical formula}c(n) which returns the current set of proponents. The function {a mathematical formula}node0(s,η,η′,A) returns the root node, i.e., a node {a mathematical formula}n0 such that {a mathematical formula}s(n0)=s, {a mathematical formula}p(n0)=[] (empty list), {a mathematical formula}e(n0)=η, {a mathematical formula}v(n0)=η′, and {a mathematical formula}c(n0)=A⊆Agt is the current set of proponents. The function {a mathematical formula}node(n,s′,α,A) returns a node {a mathematical formula}n′ where {a mathematical formula}s(n′)=s′, {a mathematical formula}p(n′)=[p(n)⋅n], {a mathematical formula}c(n′)=A=c(n),{a mathematical formula} and{a mathematical formula} where vectors are added and subtracted as usual unless their components are not integers. For technical reasons, we introduce an extra value for an agent's resource endowment, arb, which denotes an arbitrary finite value; for any {a mathematical formula}m∈Z, {a mathematical formula}m&lt;arb. arb cannot be incremented or decremented: {a mathematical formula}arb+m=arb and {a mathematical formula}arb−m=arb. Above, {a mathematical formula}e(n)(a,r) is used to keep track of the ‘real’ cost of the loops and does not contain arb values, while {a mathematical formula}v(n)(a,r)=arb indicates that the path {a mathematical formula}p(n) contains a productive loop, which can be traversed multiple times to generate an arbitrary finite amount of resource r for agent a. Intuitively, arb represents an arbitrary finite number; hence, having arb resources allows the agent to execute any action as well as any finite number of loop traversals, but does not allow the agent to traverse a loop infinitely many times.
      </paragraph>
      <paragraph>
       The function x-strategy for formulae of types {a mathematical formula}《A》↓Xψ and {a mathematical formula}《A》ζXψ is shown in Algorithm 3 and is straightforward. After checking if the search should be terminated with false because the ATL version of the formula is false (lines 2–3),{sup:12} we simply check if there is an action of A that is possible given the current endowment (line 4), and where in all outcome states A has a strategy to enforce ψ (lines 5–12). {a mathematical formula}atl(ϕ) is a function that returns the formula where each {a mathematical formula}《A》↓ and {a mathematical formula}《A》ζ in ϕ is replaced by {a mathematical formula}《A》.
      </paragraph>
      <paragraph>
       The function u-strategy for formulae of types {a mathematical formula}《A》↓ψ1Uψ2 and {a mathematical formula}《A》ζψ1Uψ2 is shown in Algorithm 4. First u-strategy checks whether the search should be terminated with false because either the ATL version of the formula is false (lines 2–3), or the current path ends in an unproductive loop (lines 4–5). We then check the path for a productive loop, and update {a mathematical formula}v(n) if we find one (lines 6–7). If the ATL version of {a mathematical formula}ψ2 is true, we try to find a strategy to enforce {a mathematical formula}ψ2 from {a mathematical formula}s(n), and, if we are successful, u-strategy returns true (lines 8–9). We then check if the endowment in n is insufficient to enforce {a mathematical formula}ψ1, and terminate the search with false if it is not (lines 10–11). (This check is required as only the ATL version of the formula is checked at lines 2–3.) Otherwise the search continues, as the node where strategy{a mathematical formula}(n,ψ2) returns true may be found later on the path. Each action available at {a mathematical formula}s(n) is considered in turn (lines 12–20). For each action {a mathematical formula}α′∈ActA, we check whether a recursive call of the algorithm returns true in all outcome states {a mathematical formula}s′ of {a mathematical formula}α′ (i.e., {a mathematical formula}α′ is part of a successful strategy). If such an {a mathematical formula}α′ is found, the algorithm returns true. Otherwise the algorithm returns false. Note that we never traverse a productive loop more than twice: if an arbitrary amount of the resource(s) produced by the loop is insufficient to enforce {a mathematical formula}ψ2 (and hence return true), at the beginning of the third traversal the search will be terminated with false at the test for an unproductive loop (since the second traversal of the loop did not result in a change in the endowment).
      </paragraph>
      <paragraph>
       The function g-strategy for formulae of types {a mathematical formula}《A》↓Gϕ and {a mathematical formula}《A》ζGϕ is shown in Algorithm 5. Again we check if the search should be terminated with false, either because the standard ATL modality does not hold (lines 2–3), or because the current path terminates in a resource consuming cycle (lines 4–7). The first check is for cycles where at least one resource is consumed and no resources are produced (lines 4–5). The second check is for cycles which both produce and consume resources (so the previous test does not apply), and where we have already shown we can produce an arbitrary amount of the resource being consumed (lines 6–7). As any arbitrary amount of resource is insufficient to maintain such a loop indefinitely, we terminate the search with false. We then check the path for a productive loop, and update {a mathematical formula}v(n) if we find one (lines 8–9). Note that, to enforce an invariant, only a path ending in a nondecreasing loop (as opposed to a productive loop) is required. However we must correctly update the endowment available in n in order to evaluate ψ in {a mathematical formula}《A》↓Gψ. We then check if the endowment in n is insufficient to enforce ψ from {a mathematical formula}s(n), and terminate the search with false if it is not (lines 10–11). If the current path terminates in a nondecreasing loop, we return true (lines 12–13): ψ is enforceable from each of the states on the path, and the loop can be traversed indefinitely. Otherwise we continue the search for a nondecreasing loop (lines 14–22).
      </paragraph>
      <paragraph>
       To illustrate the execution of the algorithm, we revisit the running example from Section 3.4 and consider the property{a mathematical formula} We skip the ATL labelling step and consider the initial call to{a mathematical formula} where {a mathematical formula}n0=node0(q0,(1:5,2:0),(1:5,2:0),{1}). For {a mathematical formula}n0, no cases of Algorithm 4 are applicable until line 12. {a mathematical formula}ActA (actions of agent 1 for which the resource consumption is less than {a mathematical formula}v1(n0), i.e., less than 5) consists of {a mathematical formula}idle and {a mathematical formula}move actions. Let us trace the algorithm calls for {a mathematical formula}idle first. There are two joint actions we need to consider (line 14): {a mathematical formula}(idle,idle) and {a mathematical formula}(idle,obstruct). In both cases the result will be the same, the next call to {a mathematical formula}u-strategy(n,《1》1:5,2:0⊤U《1》↓Gp), where n is the successor node by the joint action, will return false on line 4. This is because n will have the same state ({a mathematical formula}q0, since {a mathematical formula}o(q0,(idle,idle))=o(q0,(idle,obstruct))=q0) and {a mathematical formula}v1(n)=v1(n0) (resources available to agent 1 have not changed since {a mathematical formula}idle costs nothing). Let us consider the choice of {a mathematical formula}σ=move on line 13. There are two joint actions on line 14, {a mathematical formula}{(move,idle),(move,obstruct)}.
      </paragraph>
      <paragraph>
       First let us consider {a mathematical formula}(move,idle). On line 17, {a mathematical formula}s′ is {a mathematical formula}q1 and {a mathematical formula}node(n0,q1,(move,idle),{1}) is {a mathematical formula}n1 where {a mathematical formula}s(n1)=q1, {a mathematical formula}p(n1)=[n0], {a mathematical formula}e1(n1)=v1(n1)=3 (since move actions cost 2 units of energy, agent 1's resources are decremented) and {a mathematical formula}e2(n1)=v2(n1)=0 (agent 2's resources do not change since it is not in the proponent coalition). When we call {a mathematical formula}u-strategy(n1,《1》1:5,2:0⊤U《1》↓Gp), the first applicable case is on line 8. The ATL version of {a mathematical formula}《1》↓Gp is true, and in fact {a mathematical formula}g-strategy(n1,《1》↓Gp) returns true. (We will show this after we finish tracing the calls to u-strategy.) So on line 8 the call to {a mathematical formula}u-strategy(n1,《1》1:5,2:0⊤U《1》↓Gp) returns true. Let us consider {a mathematical formula}(move,obstruct). On line 17, {a mathematical formula}s′ is {a mathematical formula}q2 and {a mathematical formula}node(n0,q2,(move,obstruct),{1}) is {a mathematical formula}n2 where {a mathematical formula}s(n2)=q2, {a mathematical formula}p(n2)=[n0], {a mathematical formula}e1(n2)=v1(n2)=3 (since move actions cost 2 units of energy, agent 1's resources are decremented) and {a mathematical formula}e2(n2)=v2(n2)=0 (agent 2's resources do not change since it is not in the proponent coalition). When we call {a mathematical formula}u-strategy(n2,《1》1:5,2:0⊤U《1》↓Gp), the if statement on line 8 is not applicable since the invariant formula is not true in {a mathematical formula}q2. We continue to line 12 and collect all actions by agent 1 with resource consumptions of at most {a mathematical formula}v1(n2). Such actions are {a mathematical formula}idle and {a mathematical formula}move. We skip the case of {a mathematical formula}idle, as it is identical to choosing {a mathematical formula}idle in {a mathematical formula}n0. Let us consider {a mathematical formula}move. The only joint action possible if agent 1 choses {a mathematical formula}move is {a mathematical formula}(move,idle), since in {a mathematical formula}q2, agent 2 has only the {a mathematical formula}idle action. On line 17, {a mathematical formula}s′ is {a mathematical formula}q1 and {a mathematical formula}node(n2,q1,(move,idle),{1}) is {a mathematical formula}n3 where {a mathematical formula}s(n3)=q1, {a mathematical formula}p(n3)=[n0,n2], {a mathematical formula}e1(n3)=v1(n3)=1 (since move actions costs 2 units of energy, agent 1's resources are decremented) and {a mathematical formula}e2(n3)=v2(n3)=0 (agent 2's resources do not change since it is not in the proponent coalition). When we call {a mathematical formula}u-strategy(n3,《1》1:5,2:0⊤U《1》↓Gp), the call to {a mathematical formula}g-strategy(n3,《1》↓Gp) returns true (which will be shown next), and hence all calls to u-strategy from {a mathematical formula}n0 for the joint actions extending {a mathematical formula}move return true.
      </paragraph>
      <paragraph>
       Now we show that {a mathematical formula}g-strategy(n3,《1》↓Gp) returns true (the case of {a mathematical formula}g-strategy(n1,《1》↓Gp) is similar but easier, since agent 1 in {a mathematical formula}n1 has a greater resource availability). None of the cases in Algorithm 5 before line 14 are applicable. Here, the available actions are {a mathematical formula}idle and {a mathematical formula}send (the agent still has one unit of energy left). If we try {a mathematical formula}idle, then the next call to the algorithm will return false on line 2 since {a mathematical formula}idle will bring us back to {a mathematical formula}q0 which does not satisfy the ATL version of the formula {a mathematical formula}《1》↓Gp. If we select {a mathematical formula}send, then in the resulting node {a mathematical formula}n4 the applicable actions are {a mathematical formula}idle and {a mathematical formula}charge; the choice of {a mathematical formula}idle will again lead to failure, but by selecting {a mathematical formula}charge we reach {a mathematical formula}n5 where the state is {a mathematical formula}q1 again (so {a mathematical formula}s(n5)=s(n3)), and {a mathematical formula}e1(n5)=e1(n3), so the algorithm returns true on line 13.
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       Correctness of the model checking algorithm
      </section-title>
      <paragraph>
       In this section we show that the algorithm always terminates (Lemma 7) and that it gives the correct answer (Lemma 8). Together, the two lemmas give the proof of the main result:
      </paragraph>
      <paragraph label="Proof">
       The model checking problem for{a mathematical formula}pprRALoveriRBMs is decidable.Follows from Lemma 7 and Lemma 8 below. □
      </paragraph>
      <paragraph label="Lemma 7">
       Algorithm 2terminates.
      </paragraph>
      <paragraph label="Proof">
       The proof is by induction on the length of the formula. Calls for propositional formulae clearly terminate. For the inductive step, we need to show that a call for any connective terminates provided calls for lower complexity formulae terminate. Conjunction and disjunction are obvious. x-strategy makes a recursive call to determine if there is a strategy for a smaller complexity formula after one step. The only non-trivial cases are u-strategy and g-strategy.Let us consider termination of u-strategy first. We need to show that there cannot be an infinite sequence of recursive calls to {a mathematical formula}u-strategy(node(n,s′,α,A),《A》⁎ψ1Uψ2) (see line 18 of Algorithm 4). Such an infinite sequence would imply that the search is stuck in an infinite loop and hence encounters the same state infinitely often. There are three types of loops to consider: (1) a consuming or neutral loop (where for all proponent agents and all resources, the amount of each resource stays the same or decreases); (2) a productive loop (where for all proponent agents and all resources, the amount of each resource stays at least the same and increases for at least one agent and resource type) and (3) mixed (for some agents and resource types, resource availability increases and for some it goes down). Clearly the search will terminate in case (1) because of the loop check on line 4. Note that we compare v rather than e endowments because we do not want to keep looping after discovering a way to earn arb resources. If the agents are in a productive loop (case (2)), eventually all increasing resources are set to arb in line 7, and v stops changing, hence we fall back to case (1) and terminate due to the check on line 4. Finally, consider a case of a mixed loop (case (3)). Here we have two sub-cases: (3a) when for at least one agent and resource pair, {a mathematical formula}(a,r), the loop decreases the value of {a mathematical formula}e(n)(a,r), {a mathematical formula}v(n)(a,r)≠arb; and (3b) when for all such pairs where resources are consumed, {a mathematical formula}v(n)(a,r)=arb. In case (3a) termination is trivial since the actions which constitute the loop will not be possible after the required resources are consumed. In case (3b) the ‘decreasing’ resources are all arb, so the same actions are still available. However, we assumed that in (3b) for all other pairs {a mathematical formula}(a,r) resources grow (so {a mathematical formula}v(n)(a,r) is eventually set to arb) or stay the same. After all growing resources are set to arb, there is no further change and the search will terminate in the loop check on line 4. This concludes the proof that u-strategy terminates.Let us consider g-strategy. Again we need to show that there cannot be an infinite sequence of recursive calls to {a mathematical formula}g-strategy(node(n,s′,α,A),《A》⁎Gψ) (line 20 of Algorithm 5). Again such a sequence would need to involve a loop and there are three cases to consider: (1) an increasing or neutral loop (for all agents and resource types, endowments e increase or remain the same); (2) a decreasing loop (also for endowments e); and (3) a mixed loop. In case (1) we terminate on lines 12–13; in case (2) we terminate on lines 4–5. Case (3) again has two subcases: (3a) and (3b). The reasoning is the same as in the case for u-strategy; case (3a) is straightforward, case (3b) is covered by the check on lines 6–7. □
      </paragraph>
      <paragraph>
       Given {a mathematical formula}v:Agt×Res→N0∞∪{arb}, the set of endowments compatible with v is defined as {a mathematical formula}compatible(v)={e:Agt×Res→N0∞|∀a∈Agt,r∈Res:v(a,r)=arb∨e(a,r)=v(a,r)}, i.e., all individual endowments of e for each agent and resource agree with v whenever {a mathematical formula}v(a,r)≠arb.
      </paragraph>
      <paragraph label="Lemma 8">
       Algorithm 2is correct, that is,strategy({a mathematical formula}n,ϕ) returns true iff{a mathematical formula}∃e′∈compatible(v(n)):s(n),e′⊨ϕ. The proof is given in Appendix B.
      </paragraph>
     </section>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     Encodings and proofs from Section 4
     <section label="A.1">
      Encodings and proofs from Section 4.1
      <paragraph label="Proposition 1">
       Let{a mathematical formula}Abe an empty-band TCM and{a mathematical formula}λ=(qi,ηi)i=1,…,3(k−1)+1be an{a mathematical formula}A-computation pre-encoding.
      </paragraph>
      <list>
       <list-item>
        We have that{a mathematical formula}η3(k−1)+1(1,Rr)=η3(k−1)+1(2,Rr)for{a mathematical formula}r=1,2.
       </list-item>
       <list-item>
        If{a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′)is a finite resource-extended path, then so is{a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′)(s′,η″)for a uniquely defined endowment{a mathematical formula}η″.
       </list-item>
       <list-item>
        If{a mathematical formula}λ[i]=(qi,ηi)=(sE1E2,ηi)with{a mathematical formula}Er=0, then ({a mathematical formula}ηi(1,Rr)=0if, and only if,{a mathematical formula}ηi(2,Rr)=0), for{a mathematical formula}r∈{1,2}.
       </list-item>
      </list>
      <paragraph label="Proof">
       Let {a mathematical formula}λ=(qi,ηi)i=1,…,3(k−1)+1. (a) We show this by induction on k. For {a mathematical formula}k=1 the claim follows by definition. Now, suppose the claim is true for all computation pre-encodings up to (and excluding) {a mathematical formula}k≥2. That is, it is true for {a mathematical formula}λ=(qi,ηi)i=1,…,3(k−1)+1, which is also an {a mathematical formula}A-computation pre-encoding. That is, {a mathematical formula}η3(k−1)+1(1,Rr)=η3(k−1)+1(2,Rr) for {a mathematical formula}r=1,2. Consider the {a mathematical formula}A-computation pre-encoding (where we simply consider how λ has to be extended given the construction of the model){a mathematical formula} Now, a simple computation, taking into consideration the structure of the model, gives: {a mathematical formula}η3k+1(1,Rr)=η3(k−1)+3(1,Rr)=η3(k−1)+2(1,Rr)+Crk+Erk=η3(k−1)+1(1,Rr)+Crk=IHη3(k−1)+1(2,Rr)+Crk=η3(k−1)+2(2,Rr)+Crk=η3(k−1)+3(2,Rr)+Crk=η3k+1(2,Rr).(b) We have to show that {a mathematical formula}η″(1,Rr)≥0 and {a mathematical formula}η″(2,Rr)≥0 for {a mathematical formula}r∈{1,2}. The former is clear because {a mathematical formula}η′(1,Rr)≥0 and the endowment for player 1 does not change in the transition from {a mathematical formula}s′C1C2 to {a mathematical formula}s′. For the latter, we make the following observation: {a mathematical formula}η″(2,Rr)=η′(2,Rr)+Cr=η3(k−1)+1(2,Rr)+Cr where the latter equality holds as the resources of agent 2 do not change between the state {a mathematical formula}q3(k−1)+1 and {a mathematical formula}s′C1C2. Now, by (a), we have that {a mathematical formula}η3(k−1)+1(2,Rr)+Cr=η3(k−1)+1(1,Rr)+Cr. Finally, we can compute that {a mathematical formula}η3(k−1)+1(1,Rr)+Cr=η(1,Rr)+Er+Cr=η′(1,Rr)≥0 as {a mathematical formula}λ∘(sE1E2,η)(s′C1C2_,η′) is a finite resource-extended path by assumption. Finally, {a mathematical formula}η″ is uniquely defined as there is only a unique action from {a mathematical formula}s′C1C2_ to {a mathematical formula}s′.(c) Suppose a configuration {a mathematical formula}(sE1E2,ηi) with {a mathematical formula}Er=0 is reached. Then, action {a mathematical formula}E1E2 (resp. idle) was performed in {a mathematical formula}λ[i−1]=(s,ηi−1) by agent 1 (resp. 2). Note that none of the actions changes the resource balance of {a mathematical formula}Rr. Suppose now that {a mathematical formula}ηi(x,Rr)=0 for {a mathematical formula}x∈{1,2}. Then, also {a mathematical formula}ηi−1(x,Rr)=0 and by (a) {a mathematical formula}ηi−1(3−x,Rr)=0. With the above observation we can conclude that also {a mathematical formula}ηi(3−x,Rr)=0. □
      </paragraph>
      <paragraph label="Lemma 1">
       Simulation Lemma for {a mathematical formula}M1AThere is a bijection{a mathematical formula}fAbetween computations of{a mathematical formula}Aand{a mathematical formula}A-computation encodings of{a mathematical formula}M1Ain such a way that{a mathematical formula}fA(ρ)simulates the computation ρ. In particular, if ρ is an accepting computation then{a mathematical formula}fA(ρ)is also accepting.
      </paragraph>
      <paragraph label="Proof">
       Let {a mathematical formula}ρ=(si,v1i,v2i)i=1,…,k be a finite {a mathematical formula}A-computation. From ρ we inductively construct the following finite resource-extended path {a mathematical formula}λ=λρ=(qj,ηj)j=1,…,3(k−1)+1.
       <list>
        First, we consider the first configuration {a mathematical formula}i=1. Assume that {a mathematical formula}k&gt;1. Let {a mathematical formula}ρ1=((s1,E1,E2),(s2,C1,C2)). We define (i) {a mathematical formula}q1=s1, {a mathematical formula}η1(1,Rr)=η1(2,Rr)=vr1 for {a mathematical formula}r∈{1,2}; (ii) {a mathematical formula}q2=s1E1E2, {a mathematical formula}η2(1,Rr)=η1(1,Rr)−Er for {a mathematical formula}r∈{1,2}; and (iii) {a mathematical formula}q3=s2C1C2_, {a mathematical formula}η3(1,Rr)=η2(1,Rr)+Er+Cr for {a mathematical formula}r∈{1,2}. In the case that {a mathematical formula}k=1, we define {a mathematical formula}q1=s1, {a mathematical formula}η1(1,Rr)=η1(2,Rr)=vr1 for {a mathematical formula}r∈{1,2}.Inductively, we assume that the path has been constructed up to position {a mathematical formula}i−1 of computation ρ, that is up to {a mathematical formula}3(i−1)+3 on λ. Suppose {a mathematical formula}i&lt;k and let {a mathematical formula}ρi=((si,E1,E2),(si+1,C1,C2)). Again, we define (i) {a mathematical formula}q3i+1=si, {a mathematical formula}η3i+1(1,Rr)=vri for {a mathematical formula}r∈{1,2}; (ii) {a mathematical formula}q3i+2=siE1E2, {a mathematical formula}η3i+2(1,Rr)=η3i+1(1,Rr)−Er for {a mathematical formula}r∈{1,2}; and (iii) {a mathematical formula}q3i+3=si+1C1C2_, {a mathematical formula}η3i+3(1,Rr)=η3i+2(1,Rr)+Er+Cr for {a mathematical formula}r∈{1,2}. In the case that {a mathematical formula}k=i, we define {a mathematical formula}q3i+1=si, {a mathematical formula}η3i+1(1,Rr)=vri for {a mathematical formula}r∈{1,2}.Claim.
       </list>
       <paragraph>
        For every{a mathematical formula}i=1,…,kwe have that (i){a mathematical formula}si=q3(i−1)+1, (ii){a mathematical formula}vri=η3(i−1)+1(1,Rr)for{a mathematical formula}r∈{1,2}, and if{a mathematical formula}i&lt;k, then (iii){a mathematical formula}q3(i−1)+2=siE1iE2iwith{a mathematical formula}Eri=0for{a mathematical formula}r∈{1,2}implies{a mathematical formula}η3(i−1)+2(1,Rr)=0, and also (iv){a mathematical formula}vri+1=η3(i−1)+3(1,Rr)for{a mathematical formula}r∈{1,2}.Proof of claim. We prove the claim by induction on {a mathematical formula}i≤k.Induction base: Let {a mathematical formula}i=1≤k. We have that (i) {a mathematical formula}s1=q1 and (ii) {a mathematical formula}vr1=ηj1(1,Rr) by construction.Induction step: Suppose the claim is true up to {a mathematical formula}i&lt;k. We show the case for {a mathematical formula}i+1. First, suppose that {a mathematical formula}i+1=k. By induction, we have that {a mathematical formula}η3(i−1)+1(1,Rr)=vri, {a mathematical formula}η3(i−1)+3(1,Rr)=vri+1, and by Proposition 1(a) {a mathematical formula}η3(i−1)+1(1,Rr)=η3(i−1)+1(2,Rr). Thus, by Proposition 1(b) configuration {a mathematical formula}q3i+1=(si+1,η3i+1) can be reached. Moreover, the resources for agent 1 do not change in the step transition from {a mathematical formula}q3(i−1)+3 to {a mathematical formula}q3i+1, which shows that {a mathematical formula}η3i+1(1,Rr)=vri+1.Now, we consider the case {a mathematical formula}i+1&lt;k. Cases (i) and (ii) follow completely analogously. By construction, if {a mathematical formula}q3i+2=si+1E1i+1E2i+1 with {a mathematical formula}Eri+1=0 then {a mathematical formula}ρi+1=((si+1,E1,E2),(si+2,C1,C2)) with {a mathematical formula}Er=0. This transition can only be taken by the automaton if {a mathematical formula}vri+1=0. Then, by (ii) {a mathematical formula}η3i+1(1,Rr)=0. Finally, action {a mathematical formula}E1i+1E2i+1 can only consume resources by construction of the automaton. This shows that also {a mathematical formula}η3i+2(1,Rr)=0. For {a mathematical formula}(iv) we observe that {a mathematical formula}η3i+2(1,Rr)=η3i+1(1,Rr)−Eri+1 and thus {a mathematical formula}η3i+3(1,Rr)=η3i+2(1,Rr)+Cr+Eri+1=η3i+1(1,Rr)+Cr=(ii)vri+1+Cr=vri+2. □Using the claim we now have to show that the thus constructed sequence is indeed an {a mathematical formula}A-computation pre-encoding (Definition 4) and that it is a simulation (Definition 5). The two conditions of Definition 4 follow immediately. Also, by the claim it follows that λ is indeed a path in {a mathematical formula}M1A.For the first condition of Definition 5, we consider two cases. If {a mathematical formula}ρ=(s,v1,v2) consists of a single configuration, then by (a) {a mathematical formula}λ=(s,η). Hence, λ has length {a mathematical formula}3⋅0+1. For the second case, {a mathematical formula}|ρ|=k&gt;1, we observe that we added for each {a mathematical formula}i&lt;k, three states to λ (s, {a mathematical formula}sE1E2, and {a mathematical formula}s′C1C2_), and an additional state for {a mathematical formula}i=k. Thus, λ has length {a mathematical formula}3(k−1)+1. The other conditions (2) and (3) of the Definition follow from (i–iii) of the claim.We refer to the thus constructed path as {a mathematical formula}fA(ρ). Different ρ's yield different {a mathematical formula}fA(ρ)'s. It remains to show that {a mathematical formula}fA is surjective. For an arbitrary {a mathematical formula}A-computation encoding λ, each triple of states {a mathematical formula}(s)(sE1E2)(s′C1C2_) on λ defines a unique transition {a mathematical formula}τi=((s,E1,E2),(s′,C1,C2)). Given the initial configuration {a mathematical formula}(q1,η1) with {a mathematical formula}η1(1,Rr)=η1(2,Rr) for {a mathematical formula}r∈{1,2} and the sequence of the {a mathematical formula}τi's, we can compute the computation ρ. It is immediate that {a mathematical formula}fA(ρ)=λ. □
       </paragraph>
      </paragraph>
      <paragraph label="Lemma 2">
       The empty-band TCM{a mathematical formula}Ahalts iff{a mathematical formula}M1A,sinit,0¯⊨《1》{1,2}0¯Fhalt.
      </paragraph>
      <paragraph label="Proof">
       Let the empty-band TCM {a mathematical formula}A=(S,sinit,Sf,Δ) be given and {a mathematical formula}M1A be the iRBM constructed according to Definition 3.
      </paragraph>
      <list>
       <list-item label="“⇒”">
        Assume that {a mathematical formula}A halts and let {a mathematical formula}ρ=(si,v1i,v2i)i=1,…,k be a minimal length accepting run of {a mathematical formula}A. By Lemma 1 (Simulation Lemma), {a mathematical formula}λ=fA(ρ)=(qj,ηj)j=1…3(k−1)+1 is an accepting {a mathematical formula}A-computation encoding that simulates ρ. Each subsequent configurations {a mathematical formula}(qi,ηi) and {a mathematical formula}(qi+1,ηi+1), for {a mathematical formula}i=1,…,3(k−1)+1 on λ define a unique action of agent 1. Let {a mathematical formula}s1 be the strategy which assigns to each history {a mathematical formula}q1…qi this unique action of agent 1 leading to {a mathematical formula}qi+1. The strategy assigns idle to all other histories, including λ itself. We assume that player 1 follows strategy {a mathematical formula}s1. As λ simulates ρ, agent 2 can never perform a test action in states of type {a mathematical formula}sE1E2 according to Definition 5.3 and Proposition 1(c). Thus, agent 2 can only choose between actions in states of type {a mathematical formula}sC1C2_, otherwise it can only perform a unique action (the idle action). As a consequence, the outcome set wrt. {a mathematical formula}s1 contains the following paths:{a mathematical formula} All these paths contain a state labelled {a mathematical formula}halt. This shows that {a mathematical formula}M1A,sinit,0¯⊨《1》{1,2}0¯Fhalt.
       </list-item>
       <list-item label="“⇐”">
        Assume that {a mathematical formula}M1A,sinit,0¯⊨《1》{1,2}0¯Fhalt holds. Then, there is a witnessing strategy {a mathematical formula}s1 of agent 1 such that for all {a mathematical formula}λ=(qi,ηi)i∈N∈out(s1,0¯,s1,{1,2}) there is a minimal index k such that {a mathematical formula}π(qk)=halt. In particular, the set contains a path in which the state {a mathematical formula}qh is never visited. This follows from Proposition 1(b). We denote the prefix of this path that is cut directly after the state labelled {a mathematical formula}halt by {a mathematical formula}λ′. On {a mathematical formula}λ′ it can never be the case that in a state {a mathematical formula}qi=sE1E2 with {a mathematical formula}Er=0 we have that {a mathematical formula}ηi(2,Er)&gt;0; otherwise, the outcome would also contain a path which loops in {a mathematical formula}qf because agent 2 could perform the test action. But this would contradict {a mathematical formula}s1 being a witnessing winning strategy. Thus, we have {a mathematical formula}ηi(2,Er)=0 and by Proposition 1(c) also {a mathematical formula}ηi(1,Er)=0, for {a mathematical formula}r∈{1,2}. Thus, by the Simulation Lemma, there is ρ with {a mathematical formula}fA(ρ)=λ′ that is an accepting run of the automaton. The automaton halts. □
       </list-item>
      </list>
     </section>
     <section label="A.2">
      Encodings and proof from Section 4.2
      <paragraph>
       The formal definition of the encoding of a two counter automaton as a resource-bounded model with idle actions and a single resource type is given next.
      </paragraph>
      <paragraph label="Definition 7">
       {a mathematical formula}M2ALet {a mathematical formula}(S,sinit,Sf,Δ) be an empty-band TCM. From {a mathematical formula}A we construct the iRBM{a mathematical formula}M2A=({1,2,3,4},Q,Π,π,Act,d,o,{R},t) where:
      </paragraph>
      <list>
       <list-item label="1.">
        The sets of states {a mathematical formula}Q=S∪Q1∪Q2∪{qf,qh,q⥁} and of propositions and their valuations are defined as in Definition 3.
       </list-item>
       <list-item label="2.">
        The set Act is defined as follows. For each transition {a mathematical formula}(s,E1,E2)Δ(s′,C1,C2) of {a mathematical formula}A the set contains actions {a mathematical formula}E_1E2, {a mathematical formula}E1E_2, {a mathematical formula}sE_1E2′C_1C2, {a mathematical formula}sE1E_2′C1C_2, {a mathematical formula}s′C_1C2, and {a mathematical formula}s′C1C_2. Additionally, there is an action idle and test actions {a mathematical formula}testi for {a mathematical formula}i∈{1,2}.
       </list-item>
       <list-item label="3.">
        The action availability is defined according to Δ. For agent 1 we have:{a mathematical formula} and analogously for agent 2 but {a mathematical formula}E2 and {a mathematical formula}C2 are underlined instead of {a mathematical formula}E1 and {a mathematical formula}C1, respectively. For agent 3 we have:{a mathematical formula} and again analogously for agent 4 but {a mathematical formula}E2 and {a mathematical formula}C2 are underlined instead of {a mathematical formula}E1 and {a mathematical formula}C1, respectively. Moreover, {a mathematical formula}test2∈d4(sE1E2) iff E2=0, that is, the test action is only available if the counter which the agent is supposed to simulate is empty.
       </list-item>
       <list-item label="4.">
        We abstain from giving the transition function o and refer to Fig. 4 where we call an action profile {a mathematical formula}(E_1E2,E1′E_2′,idle,idle)invalid if (i) {a mathematical formula}Ei≠Ei′ for some {a mathematical formula}i∈{1,2} or (ii) if there is no transition {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ. Similarly, we call an action profile {a mathematical formula}(sE_1E2C_1C2,sE1′E_2′C1′C_2′,idle,idle)invalid in state {a mathematical formula}sE1E2 if (i) {a mathematical formula}Ci≠Ci′ or {a mathematical formula}Ei≠Ei′ for some {a mathematical formula}i∈{1,2} or (ii) if there is no transition {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ.
       </list-item>
       <list-item label="5.">
        For {a mathematical formula}i∈{1,2,3,4}, the actions' resource consumption/production is defined by the function t:{a mathematical formula}
       </list-item>
      </list>
      <paragraph label="Theorem 4">
       Model checking{a mathematical formula}prRALover the class ofiRBMs is undecidable even in the case of single resource and two agents.
      </paragraph>
      <paragraph label="Proof">
       We modify the model {a mathematical formula}M2A=({1,2,3,4},Q,Π,π,Act,d,o,{R},t) to a model {a mathematical formula}Mˆ2A=({1,2},Q\{qh},Π,πˆ,Actˆ,dˆ,oˆ,{R},tˆ). Essentially, we merge agents {a mathematical formula}{1,3} and agents {a mathematical formula}{2,4} into agent 1 and 2 in the new model, respectively. The main encoding is shown in Fig. 5. We define {a mathematical formula}dˆi(q) as {a mathematical formula}di(q) for {a mathematical formula}i∈{1,2} where it is additionally required that {a mathematical formula}test1∈dˆ1(sE1E2) iff E1=0, and {a mathematical formula}test2∈dˆ2(sE1E2) iff E2=0; coalition {a mathematical formula}{1,2} can now make all decisions. The action set {a mathematical formula}Actˆ equals Act but all actions of type {a mathematical formula}sC_1C2 and {a mathematical formula}sC1C_2are removed. The transition function {a mathematical formula}oˆ is obtained from o:{a mathematical formula} Moreover, invalid action profiles executed in states s and {a mathematical formula}sE1E2 also result in the loop state {a mathematical formula}q⥁. Here, we call an action profile {a mathematical formula}(E_1E2,E1′E_2′)invalid if (i) {a mathematical formula}Ei≠Ei′ for some {a mathematical formula}i∈{1,2} or (ii) if there is no transition {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ. Similarly, we call an action profile {a mathematical formula}(sE_1E2C_1C2,sE1′E_2′C1′C_2′)invalid in state {a mathematical formula}sE1E2 if (i) {a mathematical formula}Ci≠Ci′ or {a mathematical formula}Ei≠Ei′ for some {a mathematical formula}i∈{1,2} or (ii) if there is no transition {a mathematical formula}((s,E1,E2),(s′,C1,C2))∈Δ.The cost function {a mathematical formula}tˆ is defined as before restricted to the new action set. (States of type {a mathematical formula}sC1C2_ are only kept due to compatibility reasons.) As in the related case, it is easy to see that each resource-extended path {a mathematical formula}λ=(qi,ηi)i∈N in {a mathematical formula}M2A that does not contain state {a mathematical formula}qh corresponds to a path {a mathematical formula}λ=(qi,ηˆi)i∈N in {a mathematical formula}Mˆ2A with {a mathematical formula}ηˆi(1,R)=ηi(1,R) and {a mathematical formula}ηˆi(2,R)=ηi(2,R) for all i. By the analogue of Proposition 1(c) given in Section 4.2.2, the zero-test simulated in the test states can equivalently be defined with respect to agent 1's and 2's resource endowments. It holds that {a mathematical formula}M2A,qinit,0¯⊨《{1,2,3,4}》0¯((¬《{1,2,3,4}》↓Xfail)Uhalt) if, and only if, {a mathematical formula}Mˆ2A,qinit,0¯⊨《{1,2}》0¯((¬《{1,2}》↓Xfail)Uhalt). □
      </paragraph>
     </section>
    </section>
    <section label="Appendix B">
     Proof from Section 5
     <paragraph label="Lemma 8">
      Algorithm 2is correct, that is,strategy({a mathematical formula}n,ϕ) returns true iff{a mathematical formula}∃e′∈compatible(v(n)):s(n),e′⊨ϕ.
     </paragraph>
     <paragraph label="Proof">
      The proof is by induction on the structure of the formulae.Base case:{a mathematical formula}Caseϕ=p_ for some {a mathematical formula}p∈Π: strategy({a mathematical formula}n,p) returns true iff {a mathematical formula}s(n)⊨p (by lines 2–3 in Algorithm 2) iff {a mathematical formula}s(n),e′⊨p for any {a mathematical formula}e′∈compatible(v(n)) (by the semantics of {a mathematical formula}RAL). Obviously, {a mathematical formula}compatible(v(n))≠∅.{a mathematical formula}Caseϕ=¬p_ for some {a mathematical formula}p∈Π: Similarly, strategy({a mathematical formula}n,¬p) returns true iff {a mathematical formula}s(n)⊭p (by lines 4–5 in Algorithm 2) iff {a mathematical formula}s(n),e′⊭p for any {a mathematical formula}e′∈compatible(v(n)). Again, {a mathematical formula}compatible(v(n))≠∅.Induction step: The proof is done for each case of {a mathematical formula}pprRAL formulae.{a mathematical formula}Caseϕ=ϕ1∧ϕ2:_strategy({a mathematical formula}n,ϕ) returns true iff strategy({a mathematical formula}n,ϕ1) and strategy({a mathematical formula}n,ϕ2) return true (by lines 6–7), iff {a mathematical formula}∃e1′∈compatible(v(n)):s(n),e1′⊨ϕ1 and {a mathematical formula}∃e2′∈compatible(v(n)):s(n),e2′⊨ϕ2 (by induction hypothesis), iff {a mathematical formula}s(n),e′⊨ϕ1∧ϕ2 (by the semantics of {a mathematical formula}RAL) where {a mathematical formula}e′=max‾{e1′,e2′}∈compatible(v(n)) where {a mathematical formula}max‾V=v denotes the pointwise maximum from a finite set V of endowments, i.e., {a mathematical formula}v(i,r)=max⁡{e′(i,r)|e′∈V} for all {a mathematical formula}i∈Agt and {a mathematical formula}r∈Res (note that this is straightforward by induction on the structure of formulae in {a mathematical formula}pprRAL that {a mathematical formula}s,v⊨φ implies {a mathematical formula}s,e′⊨φ for all states s and {a mathematical formula}e′≥v since {a mathematical formula}pprRAL contains only positive formulae).{a mathematical formula}Caseϕ=ϕ1∨ϕ2:_strategy({a mathematical formula}n,ϕ) returns true iff strategy({a mathematical formula}n,ϕ1) or strategy({a mathematical formula}n,ϕ2) return true (by lines 8–9), iff {a mathematical formula}∃e1′∈compatible(v(n)):s(n),e1′⊨ϕ1 or {a mathematical formula}∃e2′∈compatible(v(n)):s(n),e2′⊨ϕ2 (by induction hypothesis) iff {a mathematical formula}s(n),e′⊨ϕ1∨ϕ2 (by the semantics of {a mathematical formula}RAL) for some {a mathematical formula}e′∈{v1,v2}⊆compatible(v(n)).{a mathematical formula}Caseϕ=《A》↓Xψ:_strategy({a mathematical formula}n,ϕ) returns true iff x-strategy({a mathematical formula}n′,ϕ) returns true (by lines 10–11) where {a mathematical formula}n′=node0(s(n),e(n),v(n),A), iff there exists {a mathematical formula}α′∈ActA (according to lines 4–5 of Algorithm 3) such that for every {a mathematical formula}α∈ActAgt (line 8 of Algorithm 3) strategy({a mathematical formula}n″,ψ) returns true where {a mathematical formula}n″=node(n′,sα,α,A) and {a mathematical formula}sα=o(s(n′),α) (recall that {a mathematical formula}va(n″)=va(n)−cons(αa)+prod(αa) for {a mathematical formula}a∈A, {a mathematical formula}va(n″)=va(n) for {a mathematical formula}a∉A and {a mathematical formula}s(n″)=sα), iff for every {a mathematical formula}α∈ActAgt, there exists {a mathematical formula}vα∈compatible(v(n)−cons(α)+prod(α)) such that {a mathematical formula}sα,vα⊨ψ (by induction hypothesis), iff there exists {a mathematical formula}e′∈compatible(v(n)−cons(α′)+prod(α′)) such that for every {a mathematical formula}α∈ActAgt{a mathematical formula}sα,e′⊨ψ, where {a mathematical formula}e′=max‾{vα|α∈ActAgt}∈compatible(v(n)−cons(α′)+prod(α′)), iff {a mathematical formula}s,e′+cons(α′)−prod(α′)⊨《A》↓Xψ where {a mathematical formula}e′+cons(α′)−prod(α′)∈compatible(v(n)).The case for {a mathematical formula}《A》ζXψ is similar to the above case, hence omitted here.{a mathematical formula}Caseϕ=《A》↓ψ1Uψ2:_strategy({a mathematical formula}n,ϕ) returns true iff {a mathematical formula}u-strategy(n0,ϕ) returns true (by lines 14–15) where {a mathematical formula}n0=node0(s(n),e(n),v(n),A).{a mathematical formula}(⇒): Let T denote the search tree rooted at {a mathematical formula}n0 when u-strategy({a mathematical formula}n0,ϕ) returns true. For the purpose of this proof, we assume that each interior node n in T has an additional function {a mathematical formula}a(n) which returns the action tuple of the proponent at {a mathematical formula}s(n); and the function {a mathematical formula}node(n,s,α,A) also assigns {a mathematical formula}a(n)=α.For every leaf n of T, we have that {a mathematical formula}strategy(n,ψ2) returns true according to lines 8–9 of Algorithm 4. By the induction hypothesis, we also have {a mathematical formula}s(n),vn⊨ψ2 for some {a mathematical formula}vn∈compatible(v(n)). Similarly, for every interior node n of T, {a mathematical formula}strategy(n,ψ1) returns true according to lines 10–11 of Algorithm 4 and, hence, {a mathematical formula}s(n),vn⊨ψ1 for some {a mathematical formula}vn∈compatible(v(n)). We first update the value of {a mathematical formula}e(n) for every node in T so that resource availability is enough to satisfy {a mathematical formula}ψ1 at every interior node and {a mathematical formula}ψ2 at every leaf node. The update is carried out from the leaves to the root of T as follows:
      <list>
       For a leaf n, {a mathematical formula}e(n):=max‾{vn,e(n)};For an interior node n with k children {a mathematical formula}n1,…,nk, if {a mathematical formula}e(ni) has been updated for all {a mathematical formula}i∈{1,…,k}, then {a mathematical formula}e(n):=max‾{vn,e(n),e(n1)+cons(a(n)),…,e(nk)+cons(a(n))}.Let
      </list>
      <paragraph>
       {a mathematical formula}sT denote the strategy for A where for each node {a mathematical formula}n∈T, with {a mathematical formula}p(n)=n0…nk, {a mathematical formula}sT(s(n0)…s(nk)s(n)){a mathematical formula}=(a(n))A. However, this strategy may not be executable from {a mathematical formula}n0 if, as a result of the initial resource availability {a mathematical formula}e(n0), there is some node n in T such that {a mathematical formula}e(n)(i,r)&lt;0 for some resource r and agent i. Note that whenever {a mathematical formula}e(n)(i,r)&lt;0, we have {a mathematical formula}v(n)(i,r)=arb according to lines 6, 7 and 12 of Algorithm 4. If {a mathematical formula}v(n0)(i,r)=arb, we can simply increase the value of {a mathematical formula}e(n0)(i,r) to compensate for the lack of resources above. In particular, we increase {a mathematical formula}e(n0)(i,r) to {a mathematical formula}e(n0)(i,r)−e(n)(i,r), then recalculate the value of {a mathematical formula}e(n′)(i,r) for every node {a mathematical formula}n′ in T. Then, {a mathematical formula}e(n)(i,r) becomes 0. Obviously, this step only removes negative values and can be repeated until no further negative values can be removed. This means for any {a mathematical formula}e(n)(i,r)&lt;0 we have {a mathematical formula}v(n0)(i,r)≠arb. Then, there must be a loop within the path {a mathematical formula}p(n) (according to lines 6–7 of Algorithm 4) that strictly increases resource r for agent i. To increase {a mathematical formula}e(n)(i,r) to a positive value, we need to determine the number of times the loop should be performed. In particular, there must be a node {a mathematical formula}n1∈p(n) such that {a mathematical formula}v(n1)(i,r) is assigned arb by the statement in lines 6–7 of Algorithm 4. Let {a mathematical formula}n2 be the node {a mathematical formula}n′ in line 6. We denote {a mathematical formula}n1 by {a mathematical formula}stopr(n) and {a mathematical formula}n2 by {a mathematical formula}startr(n). Let {a mathematical formula}T(nˆ) denote the subtree of T rooted in {a mathematical formula}nˆ for every {a mathematical formula}nˆ in T. For a resource r, if there is a node n with {a mathematical formula}e(n)(i,r)&lt;0 for some i we extend T until {a mathematical formula}e(n)(i,r)≥0 by repeating the branch between {a mathematical formula}startr(n) and {a mathematical formula}endr(n) finitely many times. There are two sub-cases to consider:
      </paragraph>
      <list>
       <list-item label="•">
        Sub-case 1: n is the only node in {a mathematical formula}T(startr(n)) with {a mathematical formula}e(n)(i,r)&lt;0 as depicted by Fig. 6(a).As the path from {a mathematical formula}startr(n) to {a mathematical formula}stopr(n) increases r for agent i by an amount of {a mathematical formula}e(stopr(n))(i,r)−e(startr(n))(i,r), it is necessary to repeat this path {a mathematical formula}⌈|e(n)(i,r)|e(stopr(n))(i,r)−e(startr(n))(i,r)⌉ times, as depicted in Fig. 6(b).
       </list-item>
       <list-item label="•">
        Sub-case 2: n is not the only node in {a mathematical formula}T(startr(n)) with {a mathematical formula}e(n)(i,r)&lt;0. Other nodes {a mathematical formula}n′ are either in the subtree {a mathematical formula}T(stopr(n)) (as depicted by Fig. 7(a)) or in the subtree of {a mathematical formula}T(startr(n)) but not {a mathematical formula}T(stopr(n)) (as depicted by Fig. 7(b)). Without loss of generality, we assume that {a mathematical formula}startr(n) is the ancestor of {a mathematical formula}startr(n′) for any of such {a mathematical formula}n′.Again, as the path from {a mathematical formula}startr(n) to {a mathematical formula}endr(n) increases r for agent i by an amount of {a mathematical formula}e(endr(n))(i,r)−e(startr(n))(i,r), it is necessary to repeat this path {a mathematical formula}k=⌈|e(n)(i,r)|e(endr(n))(i,r)−e(startr(n))(i,r)⌉ times, as depicted in Fig. 8(a). Note that this repetition will also repeat nodes {a mathematical formula}n′ which are in the subtree of {a mathematical formula}T(startr(n)) but not in {a mathematical formula}T(stopr(n)) and have {a mathematical formula}e(n′)(i,r)&lt;0 as {a mathematical formula}n1′,…,nk′ depicted in Fig. 8(b).
       </list-item>
      </list>
      <paragraph>
       Let {a mathematical formula}T1 be the obtained tree. Then, the number of nodes {a mathematical formula}n″ in {a mathematical formula}T1(nk−1) with {a mathematical formula}e(n″)(i,r)&lt;0 is strictly less than that in {a mathematical formula}T(startr(n)). Therefore, we can reapply the above construction to obtain a tree {a mathematical formula}T2 where all nodes {a mathematical formula}n″ in {a mathematical formula}T2(nk−1) have {a mathematical formula}e(n″)(i,r)≥0. These include node {a mathematical formula}n′ as depicted in Fig. 8a and {a mathematical formula}nk′ as depicted in Fig. 8b. Then, we further apply step by step the above construction for nodes {a mathematical formula}nk−1′,…,n1′ and {a mathematical formula}n′ in Fig. 8b. Finally, we obtain a tree {a mathematical formula}T3 where all nodes {a mathematical formula}n″ have {a mathematical formula}e(n″)(i,r)≥0. This construction can be repeated for other resources {a mathematical formula}r′≠r and agents {a mathematical formula}i′≠i. Finally, we obtain a tree {a mathematical formula}T4 where for all nodes n in {a mathematical formula}T4, {a mathematical formula}e(n)(i,r)≥0 for all r and i and {a mathematical formula}sT4 is a strategy satisfying ϕ at {a mathematical formula}s(n0) where {a mathematical formula}n0 is the root of {a mathematical formula}T4. In other words, we have {a mathematical formula}s(n0),e(n0)⊨ϕ where it is obvious that {a mathematical formula}e(n0)∈compatible(v(n0)). Since {a mathematical formula}n0=node0(s(n),e(n),v(n),A), {a mathematical formula}s(n)=s(n0) and {a mathematical formula}v(n)=v(n0); therefore {a mathematical formula}s(n),e(n0)⊨ϕ where {a mathematical formula}e(n0)∈compatible(v(n)).{a mathematical formula}(⇐): Assume that {a mathematical formula}s(n),e′⊨ϕ for some {a mathematical formula}e′∈compatible(v(n)), then there exists a strategy {a mathematical formula}sA such that for all {a mathematical formula}λ∈out(q,e′,sA,A):∃iλ≥0:λ|Q[iλ],λ|En[iλ]⊨ψ2 and {a mathematical formula}∀0≤j&lt;iλ:λ|Q[j],λ|En[j]⊨ψ1. We shall now prove that strategy({a mathematical formula}n,ϕ) returns true, i.e., equivalently u-strategy({a mathematical formula}node0(s(n),e(n),v(n),A),ϕ) returns true. Let {a mathematical formula}T=(V,E) be the tree induced by all runs {a mathematical formula}λ[0,iλ] for {a mathematical formula}λ∈out(q,e′,sA,A), i.e., {a mathematical formula}V={λ[0,i]|λ∈out(q,e′,sA,A),i≤iλ} and {a mathematical formula}E={(λ[0,i],λ[0,i+1])|λ∈out(s,e′,sA,A),i&lt;iλ}. We first attach to each node {a mathematical formula}λ[0,i] of T an element {a mathematical formula}v(λ[0,i]) where{a mathematical formula} In the following, we show how to convert T into a search tree which shows that u-strategy({a mathematical formula}node0(s(n),e(n),v(n),A),ϕ) returns true. Note that T must be finite and each edge in E corresponds to a join action of all agents.Initially, let {a mathematical formula}T0=T, then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl as follows. Case 1aIf there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃j&lt;k:λ|Q[j]=λ|Q[k]∧v(λ[0,j])≥v(λ[0,k]), then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing the subtree {a mathematical formula}Tl(λ[j]) by {a mathematical formula}Tl(λ[k]), updating the values for {a mathematical formula}λ[k′]|En and {a mathematical formula}v(λ[0,k′]) for all {a mathematical formula}k′≥k in the subtree {a mathematical formula}Tl(λ[k]) according to the values {a mathematical formula}λ[j]|En and {a mathematical formula}v(λ[0,j]) and the costs of actions in {a mathematical formula}Tl(λ[k]).Case 1bIf there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃j&lt;k:λ|Q[j]=λ|Q[k]∧v(λ[0,j])≤v(λ[0,k])∧v(λ[0,j])≠v(λ[0,k]), then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing the value {a mathematical formula}v(λ[0,k′]) for all nodes {a mathematical formula}λ[0,k′] in the subtree {a mathematical formula}Tl(λ[k]) as follows{a mathematical formula}Case 2Otherwise, {a mathematical formula}Tl+1=Tl, i.e., no more change. The construction stops when {a mathematical formula}Tl+1=Tl. Let the resulting tree {a mathematical formula}Tl+1=T′. For each node {a mathematical formula}λ[0,i] in {a mathematical formula}T′, we define a node {a mathematical formula}nλ[0,i] where: {a mathematical formula}s(nλ[0,i])=λ|Q[i], {a mathematical formula}p(nλ[0,i])=[λ|Q[0]⋅…⋅λ|Q[i−1]], {a mathematical formula}c(nλ[0,i])=A and {a mathematical formula}e(nλ[0,i])=λ|En[i] and {a mathematical formula}v(nλ[0,i])=v(λ[0,i]). In the following, we show by induction on the length of {a mathematical formula}T′(λ[0,i]) that {a mathematical formula}u-strategy(nλ[0,i],ϕ) returns true.Base case: Assume that {a mathematical formula}λ[0,i] is a leaf of {a mathematical formula}T′, then it is a leaf from T. Then, the condition of the if statement in lines 8–9 of Algorithm 4 is true, therefore, {a mathematical formula}u-strategy(nλ[0,i],ϕ) returns true.Induction step: Assume that {a mathematical formula}λ[0,i] is not a leaf of {a mathematical formula}T′. Then the condition of the if statement (lines 2–3) is false, since {a mathematical formula}s(n)⊨alt(ϕ) (where n is from the input of this Lemma). The condition of the next if statement (lines 4–5) is also false, since otherwise {a mathematical formula}T′ can be cut further by (Case 1a). The condition of the third or fourth if statement (lines 8–11) is false since otherwise {a mathematical formula}λ[0,i] must have been a leaf of {a mathematical formula}T′. Therefore, the algorithm must enter the second for loop. For {a mathematical formula}α=sA(λ|Q[0,i])∈dA(λ[i]) we have that, for every {a mathematical formula}s′∈out(λ|Q[i],α) with {a mathematical formula}n′=node(nλ[0,i],s′,α,A), there must be {a mathematical formula}λ′[0,i+1] in {a mathematical formula}T′ such that {a mathematical formula}n′=nλ′[0,i+1]. By the induction hypothesis, {a mathematical formula}u-strategy(nλ′[0,i+1],ϕ) returns true. Thus, {a mathematical formula}u-strategy(nλ[0,i],ϕ) also returns true.Obviously, {a mathematical formula}u-strategy(node0(s(n),e(n),v(n),A),ϕ) returns true since {a mathematical formula}nλ[0]=node0(s(n),e(n),v(n),A).The above proof can be adapted to the case {a mathematical formula}ϕ=《A》ζψ1Uψ2 by exchanging the role of {a mathematical formula}v(n) and ζ.{a mathematical formula}Caseϕ=《A》↓Gψ:_strategy({a mathematical formula}n,ϕ) returns true iff {a mathematical formula}g-strategy(n0,ϕ) returns true (by lines 18–19) where {a mathematical formula}n0=node0(s(n),e(n),v(n),A).{a mathematical formula}(⇒): Let T denote the search tree rooted at {a mathematical formula}n0 when g-strategy({a mathematical formula}n0,ϕ) returns true.For every node n of T, we have that {a mathematical formula}strategy(n,ψ) returns true according to lines 10–11 of Algorithm 5. By induction hypothesis, we also have {a mathematical formula}s(n),vn⊨ψ for some {a mathematical formula}vn∈compatible(v(n)). We first update the value of {a mathematical formula}e(n) for every node in T so that resource availability is enough to satisfy ψ at every node. The update is carried out from the leaves to the root of T as follows:
      </paragraph>
      <list>
       <list-item label="•">
        For a leaf n, {a mathematical formula}e(n):=max‾{vn,e(n)};
       </list-item>
       <list-item label="•">
        For an interior node n with k children {a mathematical formula}n1,…,nk, if {a mathematical formula}e(ni) has been updated for all {a mathematical formula}i∈{1,…,k}, then {a mathematical formula}e(n):=max‾{vn,e(n),e(n1)+cons(a(n)),…,e(nk)+cons(a(n))}.
       </list-item>
      </list>
      <paragraph>
       Let {a mathematical formula}sT denote the strategy for A where for each node {a mathematical formula}n∈T, with {a mathematical formula}p(n)=n0…nk, {a mathematical formula}sT(s(n0)…s(nk)s(n))=(a(n))A. However, this strategy may not be executable from {a mathematical formula}n0 if there is some node n in T such that {a mathematical formula}e(n)(i,r)&lt;0 for some resource r and agent i. We can repeat the tree expansions in the previous case to eliminate all such nodes. Let the obtained tree be {a mathematical formula}T1. By lines 12–13, for all leaves {a mathematical formula}n′ of {a mathematical formula}T1, we have that there exists {a mathematical formula}n″∈p(n′) such that {a mathematical formula}eA(n″)≤eA(n′). Then, we construct an infinite tree from {a mathematical formula}T1 as follows:
      </paragraph>
      <list>
       <list-item label="•">
        Given {a mathematical formula}Ti, we construct {a mathematical formula}Ti+1 by replacing all leaves {a mathematical formula}n′ of {a mathematical formula}Ti by the tree {a mathematical formula}T1(n″).
       </list-item>
       <list-item label="•">
        {a mathematical formula}T′=limi→∞⁡Ti.
       </list-item>
      </list>
      <paragraph>
       Then, the strategy {a mathematical formula}sT′ from {a mathematical formula}T′ obviously satisfies ϕ. In other words, we have {a mathematical formula}s(n0),e(n0)⊨ϕ where it is obvious that {a mathematical formula}e(n0)∈compatible(v(n)). Again, since {a mathematical formula}n0=node0(s(n),e(n),v(n),A), {a mathematical formula}s(n)=s(n0) and {a mathematical formula}v(n)=v(n0); therefore {a mathematical formula}s(n),e(n0)⊨ϕ where {a mathematical formula}e(n0)∈compatible(v(n)).{a mathematical formula}(⇐): Assume that {a mathematical formula}s(n),e′⊨ϕ for some {a mathematical formula}e′∈compatible(v(n)), then there exists a strategy {a mathematical formula}sA such that for all {a mathematical formula}λ∈out(q,e′,sA,A) and {a mathematical formula}i≥0:λ|Q[i],λ|En[i]⊨ψ. We shall now prove that strategy({a mathematical formula}n,ϕ) returns true, i.e., equivalently g-strategy({a mathematical formula}node0(s(n),e(n),v(n),A),ϕ) returns true. Let {a mathematical formula}T=(V,E) be the infinite tree induced by all runs {a mathematical formula}λ∈out(q,e′,sA,A), i.e., {a mathematical formula}V={λ[0,i]|λ∈out(q,e′,sA,A),i≥0} and {a mathematical formula}E={(λ[0,i],λ[0,i+1])|λ∈out(s,η,sA,A)}. We also attach to each node {a mathematical formula}λ[0,i] of T an element {a mathematical formula}v(λ[0,i]) where{a mathematical formula} Then, in the following, we cut T into a finite search tree which shows that g-strategy({a mathematical formula}node0(s(n),e(n),v(n),A),ϕ) returns true. Note that each edge in E corresponds to a join action of all agents. First, we repeatedly apply the following rule to prune the tree: Case 3If there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃0≤j&lt;k:λ|Q[j]=λ|Q[k]∧λ|En[j]≤λ|En[k], then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing in the subtree {a mathematical formula}Tl(λ[k]) by the node {a mathematical formula}λ[k]. This step must yield a finite tree {a mathematical formula}T′ since for every infinite path in the original tree, there must be a state appearing infinitely often and the corresponding endowments must be non-decreasing. These paths then are always cut by (Case 3).Then, let {a mathematical formula}T0=T′, then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl as follows. Case 4If there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃j&lt;k:λ|Q[j]=λ|Q[k]∧λ|En[j]≥λ|En[k] and {a mathematical formula}λ|En[j]≠λ|En[k], then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing the subtree {a mathematical formula}Tl(λ[j]) by {a mathematical formula}Tl(λ[k]), updating the values for {a mathematical formula}λ[k′]|En and {a mathematical formula}v(λ[0,k′]) for all {a mathematical formula}k′≥k in the subtree {a mathematical formula}Tl(λ[k]) according to the values {a mathematical formula}λ[j]|En and {a mathematical formula}v(λ[0,j]) and the costs of actions in {a mathematical formula}Tl(λ[k]).Case 5If there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃j&lt;k:λ|Q[j]=λ|Q[k] and ({a mathematical formula}v(λ[0,j])(a,r)=v(λ[0,k])(a,r)=arb or {a mathematical formula}λ|En[j](a,r)=λ|En[k](a,r) for all {a mathematical formula}a∈A,r∈Res) and {a mathematical formula}λ|En[j](a,r)&gt;λ|En[k](a,r) for some {a mathematical formula}a∈A,r∈Res, then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing the subtree {a mathematical formula}Tl(λ[j]) by {a mathematical formula}Tl(λ[k]), updating the values for {a mathematical formula}λ[k′]|En and {a mathematical formula}v(λ[0,k′]) for all {a mathematical formula}k′≥k in the subtree {a mathematical formula}Tl(λ[k]) according to the values {a mathematical formula}λ[j]|En and {a mathematical formula}v(λ[0,j]) and the costs of actions in {a mathematical formula}Tl(λ[k]).Case 6If there is a node {a mathematical formula}λ[0,k] in {a mathematical formula}Tl such that {a mathematical formula}∃j&lt;k:λ|Q[j]=λ|Q[k]∧v(λ[0,j])≤v(λ[0,k])∧v(λ[0,j])≠v(λ[0,k]), then {a mathematical formula}Tl+1 is constructed from {a mathematical formula}Tl by replacing the value {a mathematical formula}v(λ[0,k′]) for all nodes {a mathematical formula}λ[0,k′] in the subtree {a mathematical formula}Tl(λ[k]) as follows{a mathematical formula}Case 7Otherwise, {a mathematical formula}Tl+1=Tl, i.e., no more change. The construction stops when {a mathematical formula}Tl+1=Tl. Let the resulting tree {a mathematical formula}Tl+1=T″.For each node {a mathematical formula}λ[0,i] in {a mathematical formula}T″, we define a node {a mathematical formula}nλ[0,i] where: {a mathematical formula}s(nλ[0,i])=λ|Q[i], {a mathematical formula}p(nλ[0,i])=[λ|Q[0]⋅…⋅λ|Q[i−1]], {a mathematical formula}c(nλ[0,i])=A and {a mathematical formula}e(nλ[0,i])=λ|En[i] and {a mathematical formula}v(nλ[0,i])=v(λ[0,i]). In the following, we show by induction on the height of {a mathematical formula}T″(λ[0,i]) that {a mathematical formula}g-strategy(nλ[0,i],ϕ) returns true.Base case: Assume that {a mathematical formula}λ[0,i] is a leaf of {a mathematical formula}T″, then it is a leaf from {a mathematical formula}T″ and is the result of applying Case 3. Then, the condition of the if statement in lines 12–13 of Algorithm 5 is true, therefore, {a mathematical formula}g-strategy(nλ[0,i],ϕ) returns true.Induction step: Assume that {a mathematical formula}λ[0,i] is not a leaf of {a mathematical formula}T″. Then the condition of the if statement (lines 2–3) is false, since {a mathematical formula}s(n)⊨alt(ϕ) (where n is from the input of this Lemma). The condition of the next if statement (lines 4–5) is also false, since otherwise {a mathematical formula}T″ can be cut further by (Case 4). The condition of the third or fourth if statement (lines 6–7) is false since otherwise {a mathematical formula}T″ can be cut further by (Case 5). Therefore, the algorithm must enter the second for loop. For {a mathematical formula}α=sA(λ|Q[0,i])∈dA(λ[i]) we have that, for every {a mathematical formula}s′∈out(λ|Q[i],α) with {a mathematical formula}n′=node(nλ[0,i],s′,α,A), there must be {a mathematical formula}λ′[0,i+1] in {a mathematical formula}T′ such that {a mathematical formula}n′=nλ′[0,i+1]. By the induction hypothesis, {a mathematical formula}g-strategy(nλ′[0,i+1],ϕ) returns true. Thus, {a mathematical formula}g-strategy(nλ[0,i],ϕ) also returns true.Obviously, {a mathematical formula}g-strategy(node0(s(n),e(n),v(n),A),ϕ) returns true since {a mathematical formula}nλ[0]=node0(s(n),e(n),v(n),A).The above proof can be adapted to the case {a mathematical formula}ϕ=《A》ζGψ by exchanging the role of {a mathematical formula}v(n) and ζ. □
      </paragraph>
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>