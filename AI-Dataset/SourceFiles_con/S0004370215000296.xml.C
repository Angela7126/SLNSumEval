<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Temporally and spatially flexible plan execution for dynamic hybrid systems.
   </title>
   <abstract>
    Planners developed in the Artificial Intelligence community assume that tasks in the task plans they generate will be executed predictably and reliably. This assumption provides a useful abstraction in that it lets the task planners focus on what tasks should be done, while lower-level motion planners and controllers take care of the details of how the task should be performed. While this assumption is useful in many domains, it becomes problematic when controlling physically embedded systems, where there are often delays, disturbances, and failures. The task plans do not provide enough information about allowed flexibility in task duration and hybrid state evolution. Such flexibility could be useful when deciding how to react to disturbances. An important domain where this gap has caused problems is robotics, particularly, the operation of robots in unstructured, uncertain environments. Due to the complexity of this domain, the demands of tasks to be performed, and the actuation limits of robots, knowledge about permitted flexibility in execution of a task is crucial. We address this gap through two key innovations. First, we specify a Qualitative State Plan (QSP), which supports representation of spatial and temporal flexibility with respect to tasks. Second, we extend compilation approaches developed for temporally flexible execution of discrete activity plans to work with hybrid discrete/continuous systems using a recently developed Linear Quadratic Regulator synthesis algorithm, which performs a state reachability analysis to prune infeasible trajectories, and which determines optimal control policies for feasible state regions. The resulting Model-based Executive is able to take advantage of spatial and temporal flexibility in a QSP to improve handling of disturbances. Note that in this work, we focus on execution of QSPs, and defer the problem of how they are generated. We believe the latter could be accomplished through extensions to existing task planners.
   </abstract>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      The Computer Science, and particularly, Artificial Intelligence fields have fruitfully operated for decades using a “digital abstraction” in which instructions are assumed to execute predictably and reliably. Historically, the planning community began with a similar abstraction, using an action representation in which state is directly observable and controllable, and in which effects are deterministic and predictable. This is the case, for example, with PDDL (Planning Domain Definition Language) generative planners [1]. In reality, however, when controlling physically embedded systems, there are often delays, disturbances, and failures. Thus, there is a gap between the capabilities of such planners and plan executives, and the requirements for controlling physical systems. Specifically, the task plans generated by these planners do not provide enough information about allowed flexibility in task duration and hybrid state evolution. Such flexibility could be useful to a plan executive when deciding how to react to disturbances.
     </paragraph>
     <paragraph>
      While there are applications where the gap can be ignored, this is generally only the case in systems that are easy to control. An important domain where this gap has caused problems is robotics, particularly, the operation of robots in unstructured, uncertain environments. Due to the complexity of this domain, the demands of tasks to be performed, and the actuation limits of robots, knowledge about permitted flexibility in execution of a task is crucial. We address this gap through two key innovations. First, we specify a Qualitative State Plan (QSP), which supports representation of spatial and temporal flexibility with respect to tasks. Second, we extend compilation approaches developed for temporally flexible execution of discrete activity plans to work with hybrid discrete/continuous systems using a recently developed Linear Quadratic Regulator synthesis algorithm, which performs a state reachability analysis to prune infeasible trajectories, and which determines optimal control policies for feasible state regions. The resulting Model-based Executive is able to take advantage of spatial and temporal flexibility in a QSP to improve handling of disturbances. Note that in this work, we focus on execution of QSPs, and defer the problem of how they are generated. The latter can be accomplished through extensions to existing task planners [2].
     </paragraph>
     <paragraph>
      The temporal planning and execution community has addressed the issues of plan execution delays and disturbances in the context of time-critical, embedded missions, such as planetary fly bys [3]. In these systems, temporal disturbances are compensated for reactively by generating least-commitment temporal plans to offer temporal flexibility to the scheduler, and by scheduling execution times dynamically, as disturbances are observed. This provides a significant improvement in capabilities, but the gap still exists because in these systems, the controllers do not know about the plans in which they are used, and the planners do not know about the details of the controllers that implement their operations. When generating plans for robotic systems, such as humanoid robots (Fig. 1) or autonomous aerial vehicles, coupling between control actions and the continuous state of the robot is significant; the physical dynamics and actuation limits of the robot affect plan and schedule feasibility. Conversely, the controllers need to be able to respect constraints on arrival times of reaching a goal state imposed by the plan, as well as reaching that goal state itself.
     </paragraph>
     <paragraph>
      This investigation addresses this challenge by modeling robotic systems as hybrid discrete/continuous systems rather than just discrete systems. This model-based approach features two key innovations. First, we have developed a representation for temporally and spatially flexible tasks for hybrid systems, called a Qualitative State Plan (QSP). A QSP consists of a sequence of qualitative states, which correspond to discrete operating modes of the hybrid system. Each qualitative state has an associated set of continuous dynamic characteristics, and a set of temporal and spatial goals represented as constraints. We use the QSP representation to elevate the level of command of hybrid systems to the task level, while allowing the controller full latitude in responding to disturbances safely. Second, we have developed a Model-based Executive that executes QSPs. The Model-based Executive generates control actions that achieve the QSP goals, even if (bounded) disturbances occur. Key features of this executive are: 1) a whole-body controller that provides an abstraction of the hybrid system that is easier to control; 2) a plan compiler that transforms the QSP into an easily executable form called a Qualitative Control Plan (QCP), and 3) a plan dispatcher that executes the QCP. The whole-body controller transforms the robot, a system with tightly-coupled nonlinear dynamics, into a set of loosely-coupled linear systems [4]. This allows us to extend temporally flexible plan execution techniques, previously used only for discrete systems, to hybrid systems. The plan compiler incorporates compilation techniques used for temporally flexible plans, but extends these using recently developed algorithms for state reachability analysis and optimal controller synthesis. Thus, the plan compiler produces a QCP that contains feasible state and control input trajectory sets for the linearized abstraction. We call these trajectory sets flow tubes. The flow tube representation prunes infeasible trajectories from consideration at runtime, allowing the dispatcher to focus only on control actions that are feasible. Similarly, the QCP's compiled representations of qualitative state transition events, represented as a dispatchable graph, allows the dispatcher to focus only on control actions that correspond to feasible durations between events. Our dispatchable graph is similar to ones used previously for temporally flexible plan execution systems for discrete activities, but is integrated with the flow tube representation, resulting in a Qualitative Control Plan that supports both spatial and temporal flexibility.
     </paragraph>
     <section label="1.1">
      <section-title>
       Motivating examples
      </section-title>
      <paragraph>
       Consider a soccer player (human, or humanoid robot) running to a ball to kick it. An important question to consider is whether the goal of kicking the ball can be achieved in the required time, from a particular initial state. Will the player get to a state in which the ball can be kicked in time, or will it go by him? Given that the goal state can be achieved in an acceptable time, the next question to consider is how to determine a good sequence of control actions that achieves this. More generally, given that there may be disturbances, it is important to be able to determine the set of initial states from which the goal can be achieved in an acceptable time, and to determine a control policy that covers these states. The control policy representation must be such that when given a spatially and temporally specified goal, and a current state, it can quickly determine whether the goal can be achieved, and what the next control action should be.
      </paragraph>
      <paragraph>
       The inclusion of temporal requirements in the goal allows for representation of a broad class of problems involving synchronization of multiple agents. For example, when a soccer player kicks the ball to a teammate, both players must synchronize their movements in order for the pass to be successful. A play in American football involves synchronized movement of many players. It is also useful, in order to simplify control problems, to think of different points of interest, or reaction points, on a humanoid robot as separate agents that must be coordinated. For example, bipedal locomotion of a humanoid robot requires coordinating and synchronizing the motion of the center of mass (CM), with that of the stepping foot. Similarly, when a soccer goalie tries to block a kick, the motion of the legs, arms, and center of mass must be synchronized with that of the ball. When a baseball player tries to catch a ball, this also requires such synchronization.
      </paragraph>
      <paragraph>
       Disturbances to bipedal locomotion systems cause a disruption in the synchronization of the CM and stepping foot. For example, consider a forward push disturbance, directed at the CM, as shown in Fig. 2(a). This causes the CM to approach its goal region more quickly than the stepping foot approaches its goal region. Due to actuation and dynamic limits, as well as limits on the capabilities of the controller, it may not be possible to maintain the CM in its goal region until the stepping foot reaches its goal. In this case the plan fails. Note that this does not necessarily mean that the biped will fall down, but it does mean that the original goals cannot be accomplished. Note also that if the push is not directly towards the CM, angular momentum will be generated about the CM, possibly causing a disturbance to upright posture [5].
      </paragraph>
      <paragraph>
       A good controller would handle this case by trying to slow down the forward movement of the CM, and speed up the forward movement of the stepping foot, subject to the actuation constraints, so that synchronization is restored. Such a controller might purposely generate angular momentum about the CM to assist with slowing down forward momentum, even though this means (temporarily) sacrificing upright posture goals [5]. A good controller should also be able to determine, quickly, when the disturbance is so severe, that synchronization cannot be restored. In this case, it should quickly notify a higher-level control authority, and request an alternative plan (with achievable goals). This is important in that it may provide some warning of a fall, so that the robot can prepare itself (maybe put out its hands, like a human does).
      </paragraph>
      <paragraph>
       A trip disturbance occurs when the stepping foot is somehow delayed in its movement, as shown in Fig. 2(b). As with the forward push disturbance, this causes the CM to approach its goal region quickly relative to the stepping foot. Similarly, a good controller would either restore synchronization by slowing the CM and speeding up the stepping foot, or it would indicate that the goal cannot be achieved.
      </paragraph>
      <paragraph>
       Existing controllers for humanoid and other robots generally do not incorporate temporal constraints, and do not provide early warning of plan failure. These features are key contributions of this work. In particular, the Model-based Executive presented here supports the inclusion of externally imposed temporal constraints, and also considers the temporal constraints implied by the dynamic limitations of the mechanism. If the combination of both types of constraints results in an infeasible problem formulation, the Executive is able to quickly indicate this.
      </paragraph>
     </section>
    </section>
    <section label="2">
     <section-title>
      Background
     </section-title>
     <paragraph>
      A commonly used approach to the problem of autonomous robot movement consists of distinct planning and control phases. During the planning phase, a single, nominal reference trajectory for the robot's joints is generated taking into account constraints and optimization criteria [6]. During the control phase, the robot's joints are controlled to track the reference trajectory using high-gain PID controllers. A problem with this approach is that correct performance is guaranteed only within a close vicinity of the reference trajectory. If a large enough disturbance occurs, tracking of the reference trajectory may be lost. When this happens, there is no longer any guarantee that task goals will be met, even though there may be control actions (corresponding to alternative reference trajectories) that may be successful.
     </paragraph>
     <paragraph>
      The proper resolution of the inherent conflict between task requirements and robot capabilities must take into account the full capabilities of the robot, but should also take full advantage of any flexibility in the task specification. Hence, a robot's ability to accomplish a task ought to be limited only by its physical constraints, and by constraints associated with the task requirements, not by artificial limitations imposed by the control system, or a single feasible reference trajectory.
     </paragraph>
     <paragraph>
      An alternative approach is Model-Predictive Receding Horizon Control (MPC) [7]. With this approach, a plant model is used to continually predict and optimize future state and control actions over a limited (receding) horizon. At each control time increment, the algorithm runs such an optimization, resulting in an optimal sequence of control actions and states over the extent of the horizon. The approach is similar to ours, except that there is no compilation step; all significant computation of state and control trajectories is performed at execution time. This works well for systems with relatively slow continuous dynamics, such as chemical processes, but it does not always work for high-performance robots, where control action decisions must be made every 100 milli-seconds, or even faster. MPC approaches have been used successfully for generating online CM trajectories for walking robots [8], but the models used were simple linear inverted pendulums. In our work, we use linear inverted pendulum models as well (see Section 7.2), but we incorporate into these models the effects of angular momentum about the CM, which can be important for disturbance rejection. Further, whereas the approach in [8] uses a fixed time horizon, we incorporate temporal flexibility, and synchronization of CM movement with stepping foot movement into our approach, which further complicates the model, but improves robustness. Computing families of trajectories, with different durations, online is too time consuming on present day computers. For this reason, the compilation approach that we use is crucial.
     </paragraph>
     <paragraph>
      Of course, the continuing increase in computing power is an important consideration. The results presented in [8] likely would not have been possible 10 years ago, because computers were slower then. In 10 years, computers may be powerful enough that it may be possible to achieve 1 ms time increments using very sophisticated models. The best overall approach is probably to use a combination of offline and online computation that can be tuned to the needs of the application. This is an open area of research.
     </paragraph>
     <paragraph>
      The following sections provide background information on technologies that we have leveraged. Section 2.1 describes systems for temporally flexible plan execution, and Section 2.2 for spatially flexible plan execution.
     </paragraph>
     <paragraph>
      We conclude our discussion of related work with Section 2.3, which describes recent work using randomized algorithms for reachability analysis.
     </paragraph>
     <section label="2.1">
      <section-title>
       Temporally flexible plan execution
      </section-title>
      <paragraph>
       The problem of scheduling activities consistently with temporal constraints has been studied extensively for discrete activity systems. These systems have activities and temporal constraints, but do not represent or constrain state. It is useful to review techniques used in these systems in order to investigate how they can be extended to handle hybrid systems.
      </paragraph>
      <paragraph>
       A discrete activity plan consists of activities, events, and temporal constraints. Each activity has a start event and a finish event. Temporal constraints specify a lower and upper temporal bound on time between two events. The job of the execution system is to efficiently decide times for the events, and thereby, schedule execution of the activities, such that the event times are consistent with the temporal constraints of the plan.
      </paragraph>
      <paragraph>
       A challenge to efficient execution of activity plans is that the temporal constraints stated explicitly in the plan may imply further temporal constraints on activities that the executive must observe in order to ensure temporal consistency. Computing these implicit bounds at execution time is inefficient. Thus, for activity plans, execution efficiency is achieved by compiling the plan into a dispatchable form that makes the most restrictive temporal bounds explicit [9]. This compilation process involves first deriving the Simple Temporal Network (STN) [10] for a plan. An STN is a directed graph that represents the temporal constraints. An STN can be converted into an equivalent dispatchable graph by first computing the associated distance graph, and then computing the associated APSP graph [9]. The consistency of an STN is also checked using the APSP graph. If the APSP graph contains no negative cycles, then the STN is temporally consistent [10]. Negative cycles are detected by checking for negative distances on the diagonals of the tabular form of the APSP graph.
      </paragraph>
      <paragraph>
       The dispatcher for a dispatchable plan selects the execution time of events and then deduces the effect of this decision on the feasible execution times of future events through a one step local propagation. To do this, the dispatcher maintains an execution window (lower and upper bounds) for unexecuted events.
      </paragraph>
      <paragraph>
       Fig. 3 (see also [11]) shows an example of execution of a dispatchable plan. When event A is executed at {a mathematical formula}T=0, the dispatcher propagates the effect based on the temporal constraints in the dispatchable plan, resulting in an execution window of [1, 10] for event B, and [6, 20] for event C.
      </paragraph>
      <paragraph>
       The dispatcher then considers execution of events that become enabled by execution of event A. An event is enabled only if all events that must precede it have been executed. In this example, event B is enabled when A is executed.
      </paragraph>
      <paragraph>
       Event B, becomes alive when the current time is within its execution window. When an event is both alive and enabled, the dispatcher is free to execute it. In the example of Fig. 3, the dispatcher decides to execute event B at time {a mathematical formula}T=7. The effect of this execution is propagated to event C, resulting in a tightening of C's execution window. After event B is executed, event C becomes enabled, and it becomes alive when {a mathematical formula}T=12. The dispatcher decides to execute this event at {a mathematical formula}T=15. Pseudocode for this dispatching algorithm is shown in Algorithm 1.
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Spatially flexible plan execution
      </section-title>
      <paragraph>
       The problem of analyzing a state space offline to determine feasible trajectories and optimal control policies has been studied extensively [12], [13]. These systems compute sets of feasible trajectories called flow tubes, which lead from one qualitative state to another. In a related approach, trajectory primitives were interconnected to form a maneuver automaton, which was used to control helicopters through a flight plan [14]. Although these systems support spatial flexibility in plan execution, they do not allow specification of flexible temporal constraints, and they are limited to systems with low continuous state-space dimensionality.
      </paragraph>
      <paragraph>
       Multi-Parametric Programming[15], [16] computes flow tubes by optimally forming state-space regions using convex polytopes, and computing optimal control policies for each. Multi-Parametric Programming is based on the concept of a Linear Quadratic Regulator (LQR) [17], a controller that minimizes a quadratic function of state and control input. The parameters for an LQR can be derived analytically, but although the resulting controller is optimal, it assumes no constraints on state or control inputs. The lack of any capability to represent actuation or state constraints is a critical shortcoming of Linear Quadratic Regulators, which makes them unusable for high-performance hybrid systems with significant actuation and state limitations, like walking robots. Multi-Parametric Programming is a recently developed technique that addresses this shortcoming.
      </paragraph>
      <paragraph>
       Multi-Parametric Programming uses a linear discrete time formulation, where plant dynamics are represented by{a mathematical formula} and state and actuation constraints are represented by{a mathematical formula} where {a mathematical formula}x(k)∈ℜn is the state vector, and {a mathematical formula}u(k)∈ℜm is the input vector, and A and B are constant matrices. The problem is then formulated as a constrained optimization problem:{a mathematical formula} where P and Q are matrices representing cost on state, and R is a matrix representing cost on input. By combining (1) and (3), and using a series of matrix transformations, a formulation without a summation term is obtained:{a mathematical formula} where {a mathematical formula}Y,H,F,G,W,E are linear functions of the constant parameters in (1), (2), and (3). A further set of linear transformations results in a simpler formulation:{a mathematical formula} where {a mathematical formula}S=E+GH−1FT. The vector z is an input-like quantity, related to the input by {a mathematical formula}z=U+H−1FTx(0). Solving (5) is equivalent to, but easier than, solving (4).
      </paragraph>
      <paragraph>
       The Multi-Parametric Programming algorithm solves (5) by dividing the state space into polytope regions, and computing a control policy for each region. This control policy specifies z as a linear function of the initial state {a mathematical formula}x(0). The algorithm accomplishes this by choosing an initial feasible state, {a mathematical formula}x(0), and determining a polytope about this state within which a particular control policy is optimal. This polytope is computed by using the Karush–Kuhn–Tucker conditions to determine which constraints in (5) are active. After the first polytope is determined in this way, neighboring polytopes are expanded in a similar way. The result is a complete set of polytopes representing all feasible regions of state space, and specifying optimal control policies for each.
      </paragraph>
      <paragraph>
       Like Dynamic Programming, Multi-Parametric Programming is limited to systems with low dimensionality, and it does not support temporal flexibility. However, we choose this approach as a foundation to provide spatial flexibility. By combining this with the techniques developed for temporally flexible plan execution, we obtain a system that has both temporal and spatial flexibility. By using whole-body control techniques, we are able to use this approach for higher-dimensional systems.
      </paragraph>
     </section>
     <section label="2.3">
      <section-title>
       Sampling-based algorithms for motion planning and system verification
      </section-title>
      <paragraph>
       Recent work in the area of system verification has focused on the use of sampling-based motion planning algorithms to explore hybrid state spaces. The problem of verification of hybrid systems is addressed in [18] by trying to find a counter-example that violates a safety specification. In particular, this approach seeks to find valid initial safe states and trajectories that move the system to an unsafe state. This approach is similar, in concept, to what discrete model checking systems like Alloy and Z3 do; these use SAT solvers to try to find counter-examples that violate specifications. The general motivation for doing this is that searching the entire state space exhaustively in order to prove safety is computationally intractable, but focusing on directions that lead to unsafe regions of state space can often result in fast generation of a counter-example. The key innovations include: 1) the use of a sampling algorithm, RRT, which was originally developed for robot motion planning, to explore the state space; 2) a search heuristic that biases growth of the RRT tree towards the unsafe set; 3) metrics that provide information about the completeness of the search, which can be used to obtain a probabilistic certificate of validation; and 4) an extension of RRT called “Recursively Refined RRT”, which uses progressively smaller time steps to improve the resolution of the RRT tree.
      </paragraph>
      <paragraph>
       This work is extended in [19] by using non-zero volume regions instead of zero-volume points as vertices of the RRT tree, and using these to obtain a metric for coverage. Another extension, called Rapidly exploring Random Forest of Trees (RRFT) [20], attempts to obtain better coverage of the state space. The algorithm uses a metric for tree growth to decide when to stop expanding a particular tree in the forest, and focus computational resources on other trees. A test coverage measure using the star discrepancy notion from statistics is described in [21]. This coverage measure is used to quantify the validation ‘completeness’. It is also used to guide input stimulus generation by identifying the portions of the system behaviors that are not adequately examined. A system called “HyDICE” (Hybrid DIscrete Continuous Exploration) [22] has been used to analyze a nonlinear hybrid robotic system with over one million discrete modes. This system features an augmentation of the RRT approach in that it adds a discrete search component, which searches over “decomposition regions” of the continuous state space. These are analogous to qualitative states in our paper. The search over the decomposition regions allows the algorithm to quickly extend the RRT tree along the directions that lead to unsafe regions.
      </paragraph>
      <paragraph>
       A key difference between our work and the sampling-based verification approaches is the way in which we incorporate temporal constraints. In recent work, temporal constraints have been incorporated into sampling-based verification algorithms in the form of Linear Temporal Logic (LTL) [23], [24], [25]. In contrast we use simple, quantitative, conjunctive temporal constraints, rather than LTL. This allows for utilization of Simple Temporal Network algorithms for efficient feasibility checking and plan execution [3]. A second difference is that the sampling-based verification approaches emphasize reachability analysis biased towards reaching an unsafe region with a single trajectory; they are trying to discover whether any path exists from a safe region to an unsafe region. There may be multiple unconnected unsafe regions, and if a path can be found to any of them from the safe region, then the safety guarantee has been disproved, and the algorithm stops. In contrast, the goal of the work presented here is to find all (or as many as possible) trajectories that lead to a particular, convex goal region; we are attempting to synthesize a robust control policy based on a representation of families of feasible trajectories that is as complete as possible. A third difference is the way reach sets are computed. Sampling-based methods have been used for robot manipulation planning, particularly, planning around obstacles. While sampling-based methods have been used successfully for motion planning with obstacles and dynamics [26], we utilize convex linear optimization algorithms in our approach. The reason is that our problem formulation assumes challenging dynamics, but no obstacles, so convex approaches are appropriate. In particular, we assume that the Qualitative State Plan input to our system has already accounted for obstacles, and is therefore convex. Further, our plant models use linearized formulations. Due to these assumptions and characteristics, we are able to take advantage of convex linear optimization algorithms, which, when they can be used, are faster and provide results more reliably than the sampling-based methods. For linear systems, optimal controllers such as LQR controllers can be synthesized analytically. For linear systems with actuation and state constraints, explicit model-predictive control techniques, such as multi-parametric programming can be used, as is described in this paper. For smooth nonlinear systems, nonlinear optimizers such as SNOPT or BONMIN can be used to quickly determine parameters for basis functions such as splines so that they represent valid trajectories [27]. Of course, sampling-based methods could be used as a front end to our system to generate input Qualitative State Plans that avoid obstacles.
      </paragraph>
      <paragraph>
       A randomized tree approach that synthesizes local control policies called funnels (similar in concept to our flow tubes) about nominal trajectories discovered by the RRT algorithm is described in [28]. However, as with the RRT-based verification papers, temporal constraints are not considered. Also, the algorithm requires goal states that are stable equilibrium points, a limitation that our approach does not have. A general discussion of hybrid planning is presented in [29], but the focus of this discussion is on obstacle avoidance rather than on under-actuated dynamics, and temporal constraints are not considered.
      </paragraph>
      <paragraph>
       We do believe that the RRT-based reachability analysis algorithms provide unique capabilities, particularly for hybrid systems with discontinuities in the dynamics, and that these algorithms could be beneficially incorporated into our framework. They would be an alternative to the multi-parametric programming approach that we use for reachability analysis.
      </paragraph>
      <paragraph>
       RRT algorithms were originally developed to generate motion plans for robots. In [30] both kinematic and dynamic constraints are considered when expanding the RRT tree. The end result is a single reference trajectory that generally must be followed closely in order for the plan to succeed. The paper does not deal with control policies or funnels about this reference trajectory, and it does not consider temporal constraints. In [31] motion primitives combined with randomized search algorithms are used to solve foot placement and motion planning problems for high degree of freedom robots. The motion primitives could be constructed to include control policies, but the paper does not cover this. Also, temporal constraints are not considered.
      </paragraph>
     </section>
    </section>
    <section label="3">
     <section-title>
      Problem definition
     </section-title>
     <paragraph>
      We seek to guide a robotic articulated mechanism so that it accomplishes a particular motion task, such as walking at a specified speed, moving an end-effector to a desired region, walking on a set of irregularly placed stones, or walking to a soccer ball in time to kick it. Motion tasks are specified by a QSP, which is executed by a Model-based Executive[3], [5]. The Executive uses a Plant Model combined with current state estimates to generate control inputs. The flexibility provided by state and temporal constraints in the QSP allows the executive to consider multiple possible state and control input sequences, and to choose the most appropriate one given the situation. Sections 3.1 and 3.2 formally define the Plant Model and QSP representations and Section 3.3 defines the problem solved by the executive, based on these inputs.
     </paragraph>
     <section label="3.1">
      <section-title>
       Plant model
      </section-title>
      <paragraph>
       We assume that the plant can be modeled as a set of subsystems whose dynamics are linear and decoupled. The linearization and decoupling are provided by a Whole-body Controller [4], a component of the Model-based Executive. Thus, the Plant Model provides the Model-based Executive an abstraction of the actual system, which is easier to control.
      </paragraph>
      <paragraph label="Definition 1">
       Plant ModelA Plant Model is a Hybrid Concurrent Constraint Automaton (HCCA) [32], which consists of a set of hybrid automata. Each automaton is defined by the tuple {a mathematical formula}Aa=〈ma,La,Ta〉, where {a mathematical formula}ma is the discrete mode of the automaton, {a mathematical formula}La maps each mode to a Linearized Subsystem that defines the continuous dynamic behavior of the mode (see Definition 2), and {a mathematical formula}Ta is a set of transition functions. Given a current mode assignment and guard condition {a mathematical formula}ga (see Definition 3), each transition function {a mathematical formula}τa(ma,ga) specifies a target mode that the automaton will transition into, if the guard is satisfied.
      </paragraph>
      <paragraph label="Definition 2">
       Linearized SubsystemA Linearized Subsystem is a tuple {a mathematical formula}〈x,u,A,B,cc〉, where {a mathematical formula}x∈ℜn is the state vector, {a mathematical formula}u∈ℜm, is the input vector of the subsystem, and {a mathematical formula}A∈ℜn×n,B∈ℜm×n are matrices that represent the plant dynamics according to {a mathematical formula}x˙=Ax+Bu. Additionally, {a mathematical formula}cc is a set of actuation constraints of the form {a mathematical formula}Hc[xu]T≤Kc, where {a mathematical formula}Hc∈ℜo×n+m, {a mathematical formula}Kc∈ℜo×1, and o is the number of constraints. Each row of this linear inequality represents a half-space that is valid. The conjunction of the half-spaces for all rows defines a convex region. The executive controls each linearized subsystem via the control input u.
      </paragraph>
      <paragraph label="Definition 3">
       Guard ConditionA guard condition is associated with a Linearized Subsystem, and is represented by a set of (convex) linear algebraic equality and inequality constraints over the state vector of the Linearized Subsystem: {a mathematical formula}f(x)=c1, {a mathematical formula}g(x)≤c2 where {a mathematical formula}c1 and {a mathematical formula}c2 are vectors of constants.
      </paragraph>
      <paragraph>
       One requirement for successful plan execution is that the state trajectory satisfies the dynamics and actuation constraints of the linearized subsystems, and that it corresponds to valid mode transitions of the automata in the plant. We call such a trajectory a Plant-feasible Trajectory. We develop this concept by first defining a Mode Feasible Trajectory, for a particular mode of a particular automaton in the HCCA, and then generalizing.
      </paragraph>
      <paragraph label="Definition 4">
       Mode Feasible TrajectoryGiven a Plant Model, an automaton, A in the model, and a mode, M, for the automaton, imply a particular Linearized Subsystem {a mathematical formula}L=L(A,M). We call a state and input trajectory, {a mathematical formula}〈x(t),u(t)〉, a Mode Feasible Trajectory with respect to M if it satisfies the dynamics and actuation constraints of L, as specified in Definition 2.
      </paragraph>
      <paragraph>
       We now utilize this definition as a basis for defining feasible trajectories for a mode sequence in an automaton, and for automata in a plant.
      </paragraph>
      <paragraph label="Definition 5">
       Automaton Feasible TrajectoryGiven a Plant Model, and a particular automaton, A in the model, suppose we have a sequence of trajectories {a mathematical formula}{T0,T1,…,Tn}, where {a mathematical formula}Ti=〈xi(t),ui(t)〉,t∈[tsi,tfi]. Suppose, further, that each trajectory, {a mathematical formula}Ti, in the sequence is a Mode Feasible Trajectory with respect to a mode {a mathematical formula}Mi in A. We call the sequence of trajectories an Automaton Feasible Trajectory if for every trajectory, {a mathematical formula}Ti, in the sequence, the final continuous state, {a mathematical formula}xi(tfi), in the trajectory satisfies the guard condition for transition to mode {a mathematical formula}Mi+1, and {a mathematical formula}xi(tfi)=xi+1(tsi+1), and {a mathematical formula}tfi=tsi+1.
      </paragraph>
      <paragraph label="Definition 6">
       Plant Feasible TrajectoryGiven a Plant Model, a Plant Feasible Trajectory is a set of Automaton Feasible Trajectories, one for each automaton in the plant, where the start and finish times of all Automaton Feasible Trajectories in the set are the same.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Qualitative state plan
      </section-title>
      <paragraph>
       We formalize the concept of a Qualitative State as a set of constraints on state and temporal behavior. For example, a Qualitative State may contain constraints on which feet of a legged robot are on the ground, and may include constraints on the position of each foot. It may also include state constraints on quantities like center of mass, and temporal constraints specifying time ranges by which the state goals must be achieved. Thus, a qualitative state is a loose, partial specification of desired behavior for a specific maneuver, like taking a step.
      </paragraph>
      <paragraph>
       For example, a plan for a biped divides the walking cycle into a sequence of Qualitative States representing single and double support gait phases. Such a plan is shown in Fig. 4. In this plan, the first Qualitative State represents double support with the left foot in front, the second, left single support, the third, double support with the right foot in front, and the fourth, right single support. The fifth Qualitative State repeats the first, but is one gait cycle forward.
      </paragraph>
      <paragraph>
       The Qualitative State Plan in Fig. 4 has a temporal constraint between the start and finish events. This constraint specifies a lower and upper bound, {a mathematical formula}[l,u], on the time between these events. It is a constraint on the time to complete the gait cycle, and thus, can be used to specify walking speed.
      </paragraph>
      <paragraph>
       In addition to temporal constraints, QSPs include state constraints that specify valid initial, operating, and goal regions for an activity. If an initial region is specified for an activity, then the trajectory must be within this initial region, in order for the activity to begin. If an operating region is specified, then the trajectory must stay within this region for the duration of the activity. If a goal region is specified, then the trajectory must be within this region in order for the activity to end. In Fig. 4, the goal region constraint {a mathematical formula}CM∈r1 represents the requirement that the CM trajectory must be in region {a mathematical formula}r1 for the CM movement activity to finish successfully.
      </paragraph>
      <paragraph>
       We now provide formal definitions for Events and Activities, and then use these components to define a Qualitative State Plan.
      </paragraph>
      <paragraph label="Definition 7">
       EventAn event, e, represents a point in time. For a schedule, T, the specific time of e is given by {a mathematical formula}T(e).
      </paragraph>
      <paragraph label="Definition 8">
       ActivityAn activity is a tuple {a mathematical formula}〈es,ef,Rinput,Rop,Rinit,Rgoal,si〉, where {a mathematical formula}es is an event representing the start of the activity, {a mathematical formula}ef is an event representing its finish, {a mathematical formula}si is a Linearized Subsystem associated with the activity, {a mathematical formula}Rinput is a set of constraints on the inputs, u, of {a mathematical formula}si, {a mathematical formula}Rop is a set of operational constraints on the state, x, of {a mathematical formula}si that must hold for the duration of the activity, {a mathematical formula}Rinit is a set of constraints on the state that must hold for the activity to begin, and {a mathematical formula}Rgoal is a set of constraints on the state that must hold for the activity to finish. The state constraints, {a mathematical formula}Rop, {a mathematical formula}Rinit, and {a mathematical formula}Rgoal, are each of the form {a mathematical formula}Hx≤K, where {a mathematical formula}H∈ℜq×n and {a mathematical formula}K∈ℜq×1, and q is the number of linear inequalities in the set. The input constraints, {a mathematical formula}Rinput, are of the form {a mathematical formula}H[xTuT]T≤K.
      </paragraph>
      <paragraph label="Definition 9">
       Qualitative State PlanA Qualitative State Plan (QSP) is a tuple {a mathematical formula}〈E,A,C〉, where E is a set of Events, A is a set of Activities, and C is a set (conjunction) of externally imposed temporal constraints on the start and finish times of the activities. For example, the QSP shown in Fig. 4 has five Events (“start”, “right toe-off”, “right heel-strike”, “left toe-off”, “left heel-strike”), nine activities (“Left foot ground 1”, “Left foot step 1”, “CM1”, “CM2”, “CM3”, “CM4”, “Right foot ground 1”, “Right foot step 1”, “Right foot ground 2”), and one temporal constraint.
      </paragraph>
      <paragraph>
       Note that we assume that the externally imposed temporal constraints are conjunctive; any disjunctions in temporal constraints are resolved by higher-level planning mechanisms that generate the QSP (which are beyond the scope of this paper).
      </paragraph>
      <paragraph label="Definition 10">
       Temporal ConstraintA temporal constraint is a tuple {a mathematical formula}〈e1,e2,l,u〉, where {a mathematical formula}e1 and {a mathematical formula}e2 are events, and l and u represent lower and upper bounds on the time between these events. Thus, {a mathematical formula}l∈ℜ∪{−∞}, and {a mathematical formula}u∈ℜ∪{∞}, such that {a mathematical formula}l≤t(e2)−t(e1)≤u. Events are used to represent start and finish times of an activity, as in Definition 8, and can be constrained by temporal constraints.
      </paragraph>
     </section>
     <section label="3.3">
      <section-title>
       Plan execution: the problem solved by the model-based executive
      </section-title>
      <paragraph>
       Having formally defined a plant (Definition 1), and a QSP (Definition 9), we are now in a position to define the problem solved by the Model-based Executive in terms of a successful execution of a QSP. Successful execution can be expressed in terms of satisfaction of the individual activities in the QSP, and a consistent schedule, which combined, define satisfaction of a QSP.
      </paragraph>
      <paragraph label="Definition 11">
       Schedule and Consistent ScheduleGiven a QSP, Q, a Schedule, T, is an assignment of a specific time to each Event in Q. T is consistent with Q if it satisfies all Temporal Constraints in Q, that is, for each Temporal Constraint, {a mathematical formula}c∈C(Q), then a schedule assigns {a mathematical formula}t(e1(c))=T1, {a mathematical formula}t(e2(c))=T2 such that {a mathematical formula}l(c)≤T2−T1≤u(c), where {a mathematical formula}e1,e2,l,u are the elements of c from Definition 10.
      </paragraph>
      <paragraph label="Definition 12">
       Satisfaction of an activityGiven an activity, a (Definition 8), with associated Linearized Subsystem {a mathematical formula}si, a plant-feasible trajectory {a mathematical formula}〈x(t),u(t)〉 for {a mathematical formula}si, and a schedule T, then a is satisfied by {a mathematical formula}x(t) and T if the following conditions hold:
      </paragraph>
      <list>
       <list-item label="1)">
        {a mathematical formula}x(t) must satisfy the initial and goal region state constraints of a. Let {a mathematical formula}ts=T(es(a)) be the start time of a under schedule T, and {a mathematical formula}tf=T(ef(a)) be the finish time. Then, {a mathematical formula}x(t) satisfies the initial and goal region constraints if {a mathematical formula}x(ts)∈Rinit(a) and if {a mathematical formula}x(tf)∈Rgoal(a).
       </list-item>
       <list-item label="2)">
        {a mathematical formula}x(t) must satisfy the operating state constraints of a. That is, it must be the case that {a mathematical formula}x(t)∈Rop(a)∀t:ts≤t≤tf.
       </list-item>
      </list>
      <paragraph label="Definition 13">
       Satisfaction of a QSPGiven a QSP, Q (Definition 9), plant-feasible trajectory {a mathematical formula}〈X(t),U(t)〉 for all activities in Q, and a schedule, T, then Q is satisfied by {a mathematical formula}〈X(t),U(t),T〉 if T is consistent with Q (Definition 11), and {a mathematical formula}〈X(t),U(t),T〉 satisfies all activities in Q (Definition 12).
      </paragraph>
      <paragraph>
       We now formally define the problem solved by the Model-Based Executive.
      </paragraph>
      <paragraph label="Definition 14">
       Problem solved by the Model-Based ExecutiveGiven a QSP, Q, and a Plant Model, M, the Model-Based Executive must find a plant-feasible trajectory and schedule that satisfy the QSP (Definition 13), and then execute that trajectory and schedule. If no such trajectory and schedule exist, the executive will abort and indicate a plan infeasibility error. If a disturbance occurs during execution, the Model-Based Executive must find a new plant-feasible trajectory and schedule, and continue execution. If no such trajectory and schedule exist, the executive will abort and indicate a plan infeasibility error.
      </paragraph>
      <paragraph>
       We next describe the Model-based Executive, and how it solves this problem. We begin by presenting the Qualitative Control Plan (QCP), which is the compiled form of the QSP. Subsequently, we describe the compilation and execution algorithms of the Model-Based Executive.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Compilation output specification: the qualitative control plan
     </section-title>
     <paragraph>
      In order to reduce runtime computational load, we construct, at compile time, a Qualitative Control Plan (QCP), which uses Flow Tubes to represent all trajectories that satisfy the QSP and the plant dynamics (see also [33]). Using the QCP, the executive achieves efficiency by selecting an appropriate trajectory, within each flow tube, that begins at the current system state. In this section, we define the QCP, and present theorems that define conditions under which the problem is solvable by the Model-Based Executive.
     </paragraph>
     <paragraph>
      A key concept in plan feasibility for a hybrid system is Temporal Feasibility of individual activities in the plan.
     </paragraph>
     <paragraph label="Definition 15">
      Temporally Feasible ActivityGiven an activity and associated plant, the activity is Temporally Feasible in the duration range {a mathematical formula}[l,u] if{a mathematical formula}
     </paragraph>
     <paragraph>
      This states that the set of plant feasible trajectories includes ones that go from {a mathematical formula}Rinit to {a mathematical formula}Rgoal over the entire duration range {a mathematical formula}[l,u]. More specifically, if a trajectory starting anywhere in the initial region, {a mathematical formula}Rinit, of the activity (see Definition 8) and ending somewhere in the goal region, {a mathematical formula}Rgoal, at any duration d such that {a mathematical formula}l≤d≤u, is Plant Feasible, then the activity is temporally feasible in the duration range. This implies that the actuation limits imposed by the plant, and the operating constraints of the activity allow for actuation commands that can be used to control the linearized subsystem to the goal region from the initial region, at any duration in the duration range.
     </paragraph>
     <paragraph>
      We now introduce the concept of a control policy for an activity, and use this, along with the previous definition, to define a Temporally Controllable Activity.
     </paragraph>
     <paragraph label="Definition 16">
      Valid Control PolicyA control policy maps a state, x, associated with an activity's plant, to an actuation command u for the plant. A Valid Control Policy must provide the mapping for all states (all x) that satisfy the operating constraints of the plant and the activity.
     </paragraph>
     <paragraph label="Definition 17">
      Temporally Controllable ActivityGiven an activity and associated plant, and given a Valid Control Policy, P, for the activity, the activity is Temporally Controllable by P in the duration range {a mathematical formula}[l,u] if the activity is Temporally Feasible in this range, and if all trajectories for the activity are consistent with (generated by) P. A trajectory is consistent with, or generated by P if for every state {a mathematical formula}x(k) in the trajectory, the subsequent state {a mathematical formula}x(k+1) results from applying P to {a mathematical formula}x(k).
     </paragraph>
     <paragraph>
      We next use the concept of a Temporally Controllable Activity in a theorem that states the conditions under which a QSP can be satisfied.
     </paragraph>
     <paragraph label="Theorem 1">
      Dispatchable QSPGiven a hybrid system represented by a Plant Model (Definition 1), and given a plan represented by a QSP (Definition 9), suppose that each activity{a mathematical formula}aiin the QSP is Temporally Controllable over the duration range{a mathematical formula}[li,ui]. Let N be the Simple Temporal Network formed by combining the temporal constraints explicitly specified in the QSP, with the duration range temporal constraints{a mathematical formula}[li,ui]. If N is dispatchable[9], then a trajectory and schedule exist that satisfy the QSP (seeDefinition 13).
     </paragraph>
     <paragraph label="Proof">
      The duration range {a mathematical formula}[li,ui] for each activity {a mathematical formula}ai is a temporal constraint on the activity. The union of these temporal constraints for all activities, and the temporal constraints explicitly specified in the QSP, can be used to form an STN, N. If the All Pairs Shortest Paths graph corresponding to the STN contains no negative loops, then it is dispatchable [9] (see also Section 2.1). This implies that the full set of temporal constraints is consistent, which means a schedule exists that satisfies the QSP. Valid trajectories for each activity exist because each activity has a Valid Control Policy.  □
     </paragraph>
     <paragraph>
      Theorem 1 gives conditions under which a hybrid system, guided by a Valid Control Policy, can be controlled to successfully complete a particular plan; the plan is feasible with respect to the plant and control policy. This extends the notion of dispatchability, first introduced by Muscettola for discrete activity systems [9], to general hybrid systems, as represented by a Plant Model.
     </paragraph>
     <paragraph>
      Due to the inherently complex geometry of feasible trajectory sets, any practical flow tube representation will be an approximation. We use an internal, or under-approximation representation, which includes only feasible trajectories, but which may also exclude some feasible trajectories. The internal approximation is conservative; any solution from this approximation is guaranteed to be valid (within suitable disturbance bounds). Thus, it provides guarantees for successful execution, but it may also exclude some valid solutions; it is sound but not complete. Because digital control systems use a discrete control time increment, it is natural, and also expedient, to use a time discretization in the flow tube representation. Thus, we represent the feasible regions in the flow tube only at discrete time intervals, and we call these feasible regions cross-sections of the flow tube, as will be explained more formally in Definition 18, below.
     </paragraph>
     <paragraph>
      In order to support efficient execution, the flow tube representation must allow the dispatcher to: 1) quickly determine whether a feasible state trajectory exists from the current state, and 2) if such a trajectory exists, what the control commands should be (based on a control policy) that achieve the trajectory. In order to leverage the advantages of dispatchable representations for discrete activity systems introduced in Section 2, we require that the QCP temporal constraints be represented in minimum dispatchable form. This should include the temporal constraints specified in the QSP, and those implied by the dynamic limitations of the plant.
     </paragraph>
     <paragraph>
      Consider two QSP activities, {a mathematical formula}A1 and {a mathematical formula}A2, that share the same linearized sub-system, {a mathematical formula}si. Suppose that the finish event of {a mathematical formula}A1 is the start event of {a mathematical formula}A2. We call {a mathematical formula}A2 the Successor Activity of {a mathematical formula}A1. Now, consider feasible trajectories for {a mathematical formula}A1 and {a mathematical formula}A2 as shown in Fig. 5.
     </paragraph>
     <paragraph>
      Because {a mathematical formula}A2 is the successor of {a mathematical formula}A1, any feasible trajectory segment for {a mathematical formula}A1 must be part of a trajectory that has a feasible trajectory segment for {a mathematical formula}A2. Therefore, it is a requirement that the goal region for the flow tube for {a mathematical formula}A1 be a subset of the initial cross section of the flow tube for {a mathematical formula}A2.
     </paragraph>
     <paragraph>
      We now formally define a QCP in terms of Control Activities, and what it means for a QCP to be executed successfully. A QCP has a structure similar to that of a QSP, but augments this with flow tube cross-sections representing feasible state trajectories and corresponding control policies. A control activity includes the information of the corresponding activity in the QSP, augmented with flow tubes specifying the activity's feasible state trajectories and corresponding control policies.
     </paragraph>
     <paragraph label="Definition 18">
      Control activityA control activity is a tuple {a mathematical formula}〈A,Cs〉, where A is an activity, and {a mathematical formula}Cs is a set of cross-sections, {a mathematical formula}cd, which represent the flow tube. Each such cross-section is a tuple {a mathematical formula}〈Rs,nd,P〉, where {a mathematical formula}Rs is the state-space region for the cross-section, {a mathematical formula}nd is the number of time increments to get to the goal from this region, and P is a control policy. The duration to the goal from this cross-section is then {a mathematical formula}D=ndΔt, where Δt is the overall time increment. The region, {a mathematical formula}Rs, is a convex polytope represented by {a mathematical formula}Hx≤K, where {a mathematical formula}x∈ℜn is the state vector of {a mathematical formula}si, the linearized sub-system associated with A, {a mathematical formula}H∈ℜq×n and {a mathematical formula}K∈ℜq×1, and q is the number of linear inequality constraints used to represent the polytope. The control policy, P, is expressed in piecewise-linear form, by sub-dividing {a mathematical formula}Rs into a set of non-overlapping regions, {a mathematical formula}pj. Each such region is, itself, a convex polytope represented by {a mathematical formula}Hjx≤Kj, and has an associated linear control law of the form {a mathematical formula}u=Fjx+Gj. Fig. 6(a) shows an example cross-section containing sub-regions with separate control policies.
     </paragraph>
     <paragraph label="Definition 19">
      QCPA Qualitative Control Plan (QCP) is a triple {a mathematical formula}〈E,Ac,Ct〉, where E is a set of events (Definition 7), {a mathematical formula}Ct is a set of temporal constraints on the events (Definition 10), and {a mathematical formula}Ac is a set of control activities (Definition 18). Each event is either a start event or finish event of a control activity.
     </paragraph>
     <paragraph>
      Having specified the structure of a QCP, we now specify properties of a valid QCP. As stated in Definition 18, a cross-section for duration k time increments approximates the set of states from which the goal region can be achieved in this duration. Specifically, we define a valid cross-section in the following way to support this concept.
     </paragraph>
     <paragraph label="Definition 20">
      Valid cross-section of a control activityA cross-section, {a mathematical formula}cd, of a control activity is valid iff{a mathematical formula} where {a mathematical formula}Ai,Bi represent the discrete-time linearized dynamics of the linear subsystem {a mathematical formula}si, for the control activity, and where {a mathematical formula}u,xnew satisfy the actuation constraints {a mathematical formula}cc of {a mathematical formula}si (Definition 2), and also the QSP actuation and operation constraints {a mathematical formula}Rinput,Rop specified for the activity (Definition 8). For the case of the last cross section before the goal, the new state requirement is {a mathematical formula}xnew∈Rgoal, where {a mathematical formula}Rgoal is the goal region specified for the activity in the QSP.
     </paragraph>
     <paragraph>
      Thus, each linear control law of a valid cross section has the property that application of the control input to the linearized sub-system moves the state of this sub-system into the region of the cross section of the next time increment closer to the goal, if there are no disturbances. For example, suppose the current state of a linearized sub-system corresponding to a control activity is x. Suppose, further, that this state is in the region of a cross section, {a mathematical formula}cd(x∈Rs(cd)), as shown in Fig. 6(a), and that the state is also in the sub-region {a mathematical formula}pj. In this case, the control input {a mathematical formula}u=Fjx+Gj is applied to the linearized sub-system over the next time increment. Using the linearized, discretized plant dynamics, this results in a new state {a mathematical formula}xnew=Aix+Biu in the next time increment. The above stated property ensures that this new state is in the subsequent cross section of the flow tube: {a mathematical formula}xnew∈Rs(cd−1), as shown in Fig. 6(b).
     </paragraph>
     <paragraph label="Lemma 1">
      In a control activity, if the valid region of a cross section,{a mathematical formula}cd, for duration d increments is empty, then there are no valid trajectories for the activity with duration d increments or greater.
     </paragraph>
     <paragraph label="Proof">
      If no valid region for {a mathematical formula}cd exists, then no valid trajectory to the region for {a mathematical formula}cd−1 exists. The trajectory sequence is broken, and no valid trajectory exists that reaches the goal after duration d increments. Furthermore, because the valid region for {a mathematical formula}cd is empty, the valid region for {a mathematical formula}cd+1, and for all earlier cross sections must be empty as well, because there are no trajectories that can end in the valid region for {a mathematical formula}cd. Therefore, no valid trajectories exist for the activity with duration d or more increments.  □
     </paragraph>
     <paragraph>
      Consider a simple one-dimensional linearized sub-system, as shown in Fig. 7. No valid trajectories exist for the activity with duration 2 or more increments because the operation and actuation constraints for are incompatible.
     </paragraph>
     <paragraph label="Lemma 2">
      Given a control activity,{a mathematical formula}A2, with predecessor activity{a mathematical formula}A1, for any cross-section,{a mathematical formula}cd, of{a mathematical formula}A2{a mathematical formula}(cd∈Cs(A2))corresponding to duration d increments, if{a mathematical formula}is empty, then no valid trajectories exist for the activity with duration d increments (although there may be valid trajectories for longer durations).
     </paragraph>
     <paragraph label="Proof">
      If there is no overlap between the valid initial region of an activity, and a valid cross section corresponding to duration d, then there is no way for the activity to start from {a mathematical formula}Rs(cd), because the initial region constraint is violated. If there is no overlap between the goal region of the previous activity and the initial region and valid cross section corresponding to duration d, then there is no valid continuation from the previous activity to the current activity with duration d.  □
     </paragraph>
     <paragraph>
      Note that the elimination of feasible durations for activities due to Lemma 1, Lemma 2 will result in a tightening of the temporal bounds for such activities, beyond the [l, u] bounds specified in the QSP. In the extreme case, there are no feasible durations for the activity at all, leading to the following lemma.
     </paragraph>
     <paragraph label="Lemma 3">
      If there are no feasible durations according toLemma 1, Lemma 2within the [l, u] bounds specified for a control activity in the QCP, then there are no feasible trajectories for the activity, or for the QSP as a whole. Conversely, if a feasible duration exists, then a feasible trajectory exists for the activity that satisfies all initial, goal, operational, and actuation constraints.
     </paragraph>
     <paragraph label="Proof">
      In order for a QCP to be executed successfully, all activities in the QCP must be executed successfully (Definition 13). If an activity has no feasible durations within the temporal [l, u] bounds specified for the activity, then the activity cannot be executed. Therefore, the QCP cannot be executed successfully. If, on the other hand, at least one feasible duration exists, then there is a non-empty intersection of the activity's initial region, its predecessor's goal region, and a cross-section region, as specified in Lemma 2. The activity may begin if the initial state of the linearized sub-system lies within this intersection. Further, by Lemma 1, a control law exists that transitions the state to the region for the subsequent cross section. In this new cross section, the initial region and predecessor goal region constraints need not be checked since the activity is no longer in its initial state. By Lemma 1, each successive cross section has a control law that transitions the state to the subsequent cross section, ultimately ending in the goal region after the specified duration.  □
     </paragraph>
     <paragraph>
      The tightening of temporal constraints due to Lemma 1, Lemma 2 can cause a QCP to become infeasible, even if the individual activities are all feasible according to Lemma 3, as expressed in the following theorem.
     </paragraph>
     <paragraph label="Theorem 2">
      If a minimum dispatchable graph based on the temporal constraints specified in a QCP, and possibly tightened according toLemma 1, Lemma 2, has a negative loop, then the QCP is infeasible.
     </paragraph>
     <paragraph label="Proof">
      A minimum dispatchable graph represents a network of temporal constraints. If this graph has a negative loop, then there is an inconsistency in the temporal constraints [9]. If the minimum dispatchable graph is based on the temporal constraints explicitly specified for the QSP, as well as the additional temporal constraints implied by Lemma 1, Lemma 2, then a negative loop indicates an inconsistency in the overall set of temporal constraints, and the QCP is infeasible.  □
     </paragraph>
     <paragraph>
      A temporal inconsistency may result if the explicitly specified temporal constraints are themselves inconsistent. The more interesting case is when these constraints are consistent, but the overall set of temporal constraints becomes inconsistent due to Lemma 1, Lemma 2. This involves the more subtle interaction between the linearized sub-system dynamics, the state and actuation constraints of an activity, and the feasible activity durations.
     </paragraph>
     <paragraph>
      The lemmas and theorems presented here are useful for recognizing cases where the problem formulation, as represented by the QSP and plant model, is infeasible. This allows the compiler to generate useful warning messages informing the user why the QSP cannot be executed. It also allows the dispatcher to quickly detect if a plan becomes infeasible during execution due to disturbances.
     </paragraph>
    </section>
    <section label="5">
     <section-title>
      Plan compilation
     </section-title>
     <paragraph>
      The purpose of the plan compiler is to generate a Qualitative Control Plan (QCP) from a Qualitative State Plan (QSP). The main compilation steps are shown in Algorithm 2. The algorithm iterates over each activity in the QSP, calling ComputeFlowTubeForActivity. If the result is a flow tube with no valid cross sections, then the algorithm stops and indicates an error; the QSP is infeasible. If the flow tube is non-empty (has valid cross sections), then these cross sections are feasible in terms of plant dynamics, but not necessarily other aspects of the QSP. Therefore, the algorithm calls PruneInfeasibleCrossSections, which performs the intersection of initial region, predecessor goal region, and cross section regions specified in Lemma 2.
     </paragraph>
     <paragraph>
      The steps for computing the cross sections of a flow tube for an activity are shown in Algorithm 3. The function ComputeCrossSection performs the reach set and control policy computation described in Section 2.2.
     </paragraph>
     <paragraph>
      We use the algorithm described in Section 2[9] to compute the minimum dispatchable graph, based on the temporal constraints specified in the QSP, and the subsequent tightening due to Lemma 1, Lemma 2.
     </paragraph>
    </section>
    <section label="6">
     <section-title>
      Plan execution
     </section-title>
     <paragraph>
      The executive's dispatcher component executes a QCP output by the plan compiler. To execute a QCP, the dispatcher must successfully execute each control activity. The dispatcher accomplishes this by, in real time, monitoring plant state, and generating plant control inputs based on the appropriate QCP control policy for the current state and time. This causes the state trajectory of the linearized sub-systems to reach activity goal regions at acceptable times. In this way, the dispatcher indirectly schedules start and finish events so that they are consistent with the temporal constraints of the QCP. This is a key difference between our dispatcher, and those of discrete activity execution systems [9], in which event times are set directly by the dispatcher.
     </paragraph>
     <section label="6.1">
      <section-title>
       Dispatcher analysis
      </section-title>
      <paragraph>
       We now build on the previous definitions, lemmas, and theorems, which were intended to support plan compilation, deriving new ones that support plan execution. Subsequently, we describe the dispatcher algorithms that implement plan execution.
      </paragraph>
      <paragraph>
       In order to execute a QCP, the dispatcher must decide on a schedule that satisfies the QCP (see Theorem 1). However, the dispatcher does not decide an entire, fixed schedule before execution. Rather, it decides the schedule in a least-commitment manner, as described previously in Section 2.1. In order to understand how this is accomplished for the hybrid plants under consideration here, it is useful to distinguish between completed, currently executing, and future activities.
      </paragraph>
      <paragraph>
       The completed activities represent a partial schedule; their finish events have occurred, and they have occurred within their execution windows (or plan execution would have been aborted). Thus, no temporal constraints have been violated thus far. Furthermore, there are valid execution windows for the remaining events (for all finish events of the currently executing and future activities). This is a feature of the discrete activity dispatcher algorithms (see Section 2.1), which we utilize and extend. The future activities have not started, but if completion times for currently executing activities are within their execution windows, then future activities will be feasible (will have non-empty execution windows). When they become current activities, they will be dispatchable.
      </paragraph>
      <paragraph>
       We focus now on the currently executing activities. The dispatcher sets the schedule for a currently executing activity by deciding a target completion time for it that is within the activity's execution window. However, unlike discrete activity systems, which can simply set the occurrence of events so that they coincide with target completion times, our dispatcher must generate control inputs that guide the hybrid plant to its goal state at the target completion time. Thus, the activity completion event time cannot simply be set, but rather, occurs as a consequence of the control policy applied to the plant dynamics.
      </paragraph>
      <paragraph>
       The dispatcher uses a Valid Control Policy for Target Completion Time to accomplish this.
      </paragraph>
      <paragraph label="Definition 21">
       Valid Control Policy for Target Completion TimeA Valid Control Policy that results in achievement of an activity's goal state at time {a mathematical formula}tf is denoted by {a mathematical formula}P(tf); it is a Valid Control Policy with respect to the target completion time {a mathematical formula}tf.
      </paragraph>
      <paragraph>
       In order to understand which control policies are available to the dispatcher, recall Definition 17, which is utilized for plan compilation to determine valid compile time duration ranges for activities. We now extend this concept for use at runtime by the dispatcher, by defining a Temporally Controllable Activity for a Target Completion Time and Current State.
      </paragraph>
      <paragraph label="Definition 22">
       Temporally Controllable Activity for Target Completion Time and Current StateAn activity is Temporally Controllable for Target Completion Time {a mathematical formula}tf from current state x if there exists a Valid Control Policy for Target Completion Time, {a mathematical formula}P(tf), that covers x. We call this a Valid Control Policy for Target Completion Time and State, and denote this by {a mathematical formula}P(tf,x).
      </paragraph>
      <paragraph>
       The following lemma gives conditions under which such a control policy exists.
      </paragraph>
      <paragraph label="Lemma 4">
       Given the current state,x, and a valid cross section,{a mathematical formula}cd, of a currently executing Control Activity that started executing at time{a mathematical formula}ts, where{a mathematical formula}Rsis the state-space region for{a mathematical formula}cd, and D is the duration to the goal for{a mathematical formula}cd(seeDefinition 18), if{a mathematical formula}x∈Rsand{a mathematical formula}tf−ts=D, then{a mathematical formula}P(tf,x)exists, and is achieved by{a mathematical formula}cd.
      </paragraph>
      <paragraph label="Proof">
       This follows from the definition for a Valid Cross Section (Definition 20). In the absence of disturbances, application of the control law for the cross section moves the state into the region of the next time increment closer to the goal. Repeated application, for each cross section, achieves the goal in duration D.  □
      </paragraph>
      <paragraph>
       We can extend this to express the range of durations available to the dispatcher, using the following lemma.
      </paragraph>
      <paragraph label="Lemma 5">
       Given the current state,x, and a set of valid cross sections of a currently executing Control Activity that started executing at time{a mathematical formula}ts, then for each cross section{a mathematical formula}cd, if{a mathematical formula}cdrepresents{a mathematical formula}P(tf,x)according toLemma 4, and if the set of cross sections is contiguous, then the activity is temporally controllable in the duration range{a mathematical formula}[l,u], where l is the minimum duration in the set, and u is the maximum.
      </paragraph>
      <paragraph label="Proof">
       This follows from Lemma 4, and the assumption that the cross sections are contiguous (that there are not gaps in the corresponding time increments between the cross section for the minimum and maximum durations). This assumption is valid for linear systems, which are used in the plants under consideration here.  □
      </paragraph>
      <paragraph>
       We now extend Theorem 1 to state conditions under which a QCP that is being executed is dispatchable.
      </paragraph>
      <paragraph label="Theorem 3">
       Dispatchable Executing QCPGiven a Plant Model (Definition 1), a QCP (Definition 19) that is dispatchable according toTheorem 1, and the current statex, suppose that each activity{a mathematical formula}aiin the set of currently executing activities is Temporally Controllable in the duration range{a mathematical formula}[li,ui]for the current state according toLemma 5. Let N be the Simple Temporal Network formed by combining the temporal constraints of the QCP before execution, with the duration range temporal constraints{a mathematical formula}[li,ui]for the currently executing activities. If N is dispatchable[9], then a trajectory and schedule exist that satisfy successful execution of the QCP. Conversely, if N is not dispatchable, then no schedule exists for successful execution.
      </paragraph>
      <paragraph label="Proof">
       This follows directly from Theorem 1, with the addition of duration ranges for currently executing activities added to the original temporal constraints of the QCP.  □
      </paragraph>
      <paragraph>
       Theorem 3 gives conditions under which a QCP that is being executed can be successfully executed to its conclusion. In the absence of disturbances, this theorem is really just a re-statement of Theorem 1. Things get more interesting when there is a disturbance to the plant state.
      </paragraph>
      <paragraph>
       The dispatcher must be able to deal appropriately with unforeseen disturbances that may occur during plan execution. We define three classes of disturbances. For the first class, the disturbance is small enough that the dispatcher does not have to change the scheduled duration of the activity. We call this type of disturbance spatially and temporally controllable.
      </paragraph>
      <paragraph label="Theorem 4">
       Given a Dispatchable Executing QCP, according toTheorem 3, let{a mathematical formula}aibe an activity in the set of currently executing activities, andxthe current state associated with this activity, and t, the current time. Suppose that control policy{a mathematical formula}P(tf,x), achieved by cross section{a mathematical formula}cdaccording toLemma 4, is being used to execute the activity. In this case,{a mathematical formula}cdis the cross section that achieves the goal in d duration increments ({a mathematical formula}dΔt=tf−t). Suppose, further, thatxis a disturbed state; it is not the state predicted by applying the control law from the previous cross section in the flow tube ({a mathematical formula}cd+1, seeDefinition 18). If{a mathematical formula}x∈Rs, where{a mathematical formula}Rsis the state-space region for{a mathematical formula}cd, then the goal region will still be achieved by the current control policy at{a mathematical formula}tf; there is no need to change the target completion time ({a mathematical formula}tf) for the activity, and there is no need to change the target completion times for any other currently executing activities; the schedule does not have to be changed. The disturbance is spatially and temporally controllable.
      </paragraph>
      <paragraph label="Proof">
       This follows directly from Lemma 4. If the state is not disturbed out of the cross section for the control policy, then execution can continue as planned.  □
      </paragraph>
      <paragraph>
       For the second disturbance class, the disturbance is large enough that a change in the duration of one or more activities is necessary. We call this type of disturbance spatially controllable.
      </paragraph>
      <paragraph label="Theorem 5">
       Given a Dispatchable Executing QCP, let{a mathematical formula}aibe a currently executing activity,xthe current state associated with this activity, and t, the current time. Suppose that control policy{a mathematical formula}P(tf,x), achieved by cross section{a mathematical formula}cdis being used to execute the activity. Suppose, further, thatxis a disturbed state. If{a mathematical formula}x∋Rs, where{a mathematical formula}Rsis the state-space region for{a mathematical formula}cd, then the goal region cannot be achieved by the current control policy at{a mathematical formula}tf. If, however, the executing QCP is still dispatchable after the disturbance according toTheorem 3, then there exists a new control policy with a target execution time other than{a mathematical formula}tfthat satisfies{a mathematical formula}ai, and there exists a new schedule for the currently executing activities that maintains dispatchability, and guarantees successful execution of the QCP (in the absence of further disturbances). The disturbance is spatially controllable.
      </paragraph>
      <paragraph label="Proof">
       This follows from Lemma 4, and Theorem 3. The requirement to change {a mathematical formula}tf for {a mathematical formula}ai implies a possible tightening of execution windows, requiring a new schedule for the currently executing activities.  □
      </paragraph>
      <paragraph>
       We are assuming, for the purpose of these theorems, that the reach set approximation covers the entire actual reach set. In reality, given that the cross sections are inner approximations, it will sometimes be possible for the physical system to achieve the goal without change in target completion time, because the state is in the actual reach set, but not the approximation. However, our goal is to build a functional system, so we must work with the reach set approximation as if it were the actual reach set. Related research addresses this problem by striving to improve reach set approximations.
      </paragraph>
      <paragraph>
       For the third disturbance class, the disturbance is so large that no adjustment of control inputs is able to compensate for it. We call this type of disturbance uncontrollable.
      </paragraph>
      <paragraph label="Theorem 6">
       Given a Dispatchable Executing QCP, let{a mathematical formula}aibe a currently executing activity,xthe current state associated with this activity. Ifxis a disturbed state, such that the QCP is not dispatchable according toTheorem 3, then no control policy, and no schedule exists that guarantees successful execution of the QCP. The disturbance is uncontrollable.
      </paragraph>
      <paragraph label="Proof">
       This follows from Theorem 3. If the system is not dispatchable [9], then the temporal constraints are inconsistent, and no valid schedule exists for completion (see also Theorem 2).  □
      </paragraph>
      <paragraph>
       The dispatcher must recognize this immediately after the disturbance and abort execution, notifying a higher-level control authority that the current plan execution has failed and that a new plan is needed. Although it is possible that a future disturbance may occur that beneficially pushes the system back into a dispatchable state, that is typically unlikely; the best policy is to abort execution and start with a new plan.
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       Dispatcher algorithm
      </section-title>
      <paragraph>
       The dispatcher performs four key functions in executing a control activity: initialization, monitoring, control, and transition. During initialization, the dispatcher chooses a goal duration (and target completion time) for the control activity that is consistent with its execution window, and computes an initial control input, based on the control policy for the chosen target completion time. This control input is consistent with an optimal trajectory that will reach the activity's goal region in the chosen duration, if there are no disturbances.
      </paragraph>
      <paragraph>
       After initializing an activity, the dispatcher begins monitoring its execution by obtaining an updated state estimate at each time increment, and checking whether the state is within the flow tube as expected. If so, the dispatcher will continue to apply the control policy for the target completion time. If this is not the case, then a disturbance has occurred, and the dispatcher must determine the type of disturbance, and react accordingly.
      </paragraph>
      <paragraph>
       As part of the monitoring function, the dispatcher also checks whether the state trajectory has achieved the activity's goal region in an acceptable time. If this is the case, it checks whether the activity's end event has occurred. This involves checking if the state trajectories of other activities whose completion must be synchronized are in their respective goal regions. If all completion conditions for a control activity are satisfied, the dispatcher switches to the transition function. If the control activity has a successor, the transition function invokes the initialization function for this new activity. As part of this transition, the dispatcher notes the time of the transition event and propagates this through the temporal constraints.
      </paragraph>
      <paragraph>
       The dispatcher uses two key data structures: a Runtime Activity State, and an Event Horizon. The Runtime Activity State maintains information about currently executing activities.
      </paragraph>
      <paragraph label="Definition 23">
       Runtime Activity StateA Runtime Activity State is a set, {a mathematical formula}As={a1,…,ap}, of p activity information elements, {a mathematical formula}ai, one for each linearized sub-system in the linearized plant abstraction (Definition 1). Each element, {a mathematical formula}ai, is a tuple {a mathematical formula}〈ac,ts,tt,x˜init,x˜〉, where {a mathematical formula}ac is the currently executing activity for the linearized sub-system, {a mathematical formula}ts is the time this activity started, {a mathematical formula}tt is the target time for completion of the activity, {a mathematical formula}x˜init is an estimate of the initial state of the linearized sub-system, and {a mathematical formula}x˜ is an estimate of its current state.
      </paragraph>
      <paragraph>
       The concept of a target completion time represents a key distinction between our system, and the discrete activity execution systems discussed in Section 2.1. This concept is needed here because activity completion is controlled indirectly, by applying control inputs. Thus, activity completion event times cannot simply be set, but rather, occur as a consequence of the plant dynamics. If there are disturbances, the target completion time may have to be adjusted, as discussed previously.
      </paragraph>
      <paragraph>
       The need for an Event Horizon is an additional consequence of this distinction. Our dispatcher chooses a target activity completion time, and then selects an appropriate control policy that is predicted to complete the activity at the desired time. Because multiple activities are typically executing in parallel, achieving a desired event execution time requires synchronization of these activities. The Event Horizon provides a mechanism for ensuring this consistency.
      </paragraph>
      <paragraph label="Definition 24">
       Event HorizonAn Event Horizon is a set of Event Paths, each of which is a list of events and associated target execution windows. Hence, each element of an Event Path is a tuple {a mathematical formula}〈e,l,u〉 where e is the event, and l and u represent lower and upper bounds on times for the event.
      </paragraph>
      <paragraph>
       The Event Paths represent events whose target execution windows have to be propagated in order to properly set target completion times for current activities in the Runtime Activity State. This propagation is a special kind of tightening of execution windows, distinct from the execution window tightening that is performed when events occur. This special propagation is necessary in order to ensure that target activity completion times are temporally consistent. This is a unique feature of our dispatcher; it is not used in the discrete activity execution systems described in Section 2.1.
      </paragraph>
      <paragraph>
       The algorithm for determining the event horizon involves starting at the target events of current activities, and searching back along outgoing negative arcs in the minimum dispatchable graph until executed events are reached. Consider the example QSP shown in Fig. 8. Activity a11 is for linearized sub-system 1, and activities a21, a22, and a23 are for linearized sub-system 2. Suppose that event ev1 has just occurred, and activities a11 and a21 are about to start executing. The dispatcher must choose target completion times for each activity. However, it cannot just choose target completion times that fit inside the event execution windows that were propagated when ev1 occurred; the Event Horizon must be taken into account. For example, suppose that the duration constraints on a11 are [3, 15], and the duration constraints on a21, a22, and a23 are [1, 5]. If event ev1 occurs at time 0, then the execution window for ev4 is [3, 15], and the execution window for event ev2 is [1, 5]. If the dispatcher were to base its decisions about target completion times solely on these execution windows, it could choose a target duration of 4 for a21, and 4 for a11. This would cause a future temporal infeasibility, because a22 and a23 would have to be executed in 0 time, which violates their duration constraints.
      </paragraph>
      <paragraph>
       To solve this problem, the dispatcher considers the event horizon, which, in this case, is ev1, ev2, ev3, ev4. In this case, if the dispatcher chooses duration range midpoints as target durations, then the target completion times for a21, a22, and a23 are 3, 6, and 9, respectively, and the target completion time for a11 is 9 as well. Duration range midpoints are chosen to maximize robustness to temporal disturbances, assuming that the probability for temporal duration disturbance is symmetrically distributed. While this assumption is not always valid, a detailed analysis of target completion time selection is beyond the scope of this paper.
      </paragraph>
      <paragraph>
       Algorithm 4 shows the top-level dispatch loop of the executive. This algorithm is based on the one for discrete activity execution systems (Algorithm 1), but has some key extensions, which are highlighted.
      </paragraph>
      <paragraph>
       UpdateCurrentActivities transitions the currently executing activity element, {a mathematical formula}ac, in the runtime activity state (Definition 20). Thus, UpdateCurrentActivities iterates over each element in the runtime activity state, corresponding to each plant (linearized sub-system), checking if the event that has just occurred, ExecutableEvent?, is the finish event for the currently executing activity. If this is the case, it transitions {a mathematical formula}ac to the subsequent activity for the plant.
      </paragraph>
      <paragraph>
       Algorithm 5, UpdateEventHorizon is used to update the event horizon after an event has occurred. To perform the update, the algorithm first removes any paths from the event horizon that contain the executed event (Line 1). The algorithm then iterates over each currently executing activity (Line 2), obtaining the target event for the activity (Line 4). If the target event is not already in the event horizon, a search back from this event is started (Line 5). This depth-first search proceeds back from the target event along negative out-going arcs in the minimum dispatchable graph. The event horizon search queue maintains the state of this search. Nodes in this queue have an associated event, and an arc being searched, as well as flags that indicate whether a predecessor event is the executed event, and whether the path has already been added to the event horizon. The search proceeds back along events that have not been executed. When an event that has been executed is encountered, the search branch stops, and search proceeds along the next arc (Line 24). When there are no more arcs, the search node is popped, and the path is added to the event horizon, if it hasn't already been added (Line 25).
      </paragraph>
      <paragraph>
       For Fig. 8, this algorithm computes an event horizon {a mathematical formula}{{ev1,ev2,ev3,ev4}}. For the more complex scenario shown in Fig. 9, Algorithm 5 begins by iterating over current activities (outgoing activities of ev1), and getting the corresponding target (output) events (ev4, ev2, and ev5). From each of these, it finds a path back to an executed event. This results in paths {a mathematical formula}{{ev1,ev4}{ev1,ev2}{ev1,ev5}{ev1,ev2,ev3,ev4}{ev1,ev5,ev4}}. After eliminating paths that are subsets, this becomes {a mathematical formula}{{ev1,ev2,ev3,ev4}{ev1,ev5,ev4}}, which is the event horizon returned.
      </paragraph>
      <paragraph>
       Algorithm 6, UpdateTargetExecutionTimes uses the event horizon to decide target completion times for activities. The algorithm first initializes target execution windows of all events in the event horizon to be identical to the execution windows computed by InitializeExecutionWindows and PropagateExecutionWindows (Line 1). It then iterates over every path in the event horizon, retrieving the activity corresponding to the beginning of the path (Line 2). This is a currently executing activity in the runtime activity state. The algorithm sets the target completion time for the activity to be the midpoint of the execution window, and then propagates this decision to future events in the path (Line 5). This can result in a tightening of target execution windows for these events. Finally, the algorithm iterates over activity info elements in runtime activity state. For activities whose target completion times have not been set, this time is now set to the midpoint of the execution window.
      </paragraph>
      <paragraph>
       For the example in Fig. 9, suppose that the duration constraints are as shown in Fig. 10. The event horizon for this is {a mathematical formula}{{ev1,ev2,ev3,ev4}{ev1,ev5,ev4}}, as explained previously. UpdateTargetExecutionTimes iterates over the first activity in each path (a21, a31). It sets the target durations for both to be 3, and propagates this so that the target execution window for ev3 is [4, 8] and for ev4 is [5, 13]. Finally, the algorithm will set the target completion time of a11 to be the midpoint of [5, 13], or 9.
      </paragraph>
      <paragraph>
       The function UpdateCurrentState updates the estimate of plant state. The function UpdateControlInputs iterates over each activity info in runtime activity state, and computes new plant control inputs by accessing flow tube cross section policies based on the remaining execution time for the activity. The function EventOccurred checks whether an event has occurred, and if so, returns this as an executable event, whose occurrence must be propagated in the next iteration of the main loop in DispatchQCP.
      </paragraph>
      <paragraph>
       The main dispatcher algorithm checks whether an uncontrollable disturbance has occurred, and aborts execution if this is the case. It also checks whether a spatially controllable disturbance has occurred. If so, it calls UpdateTargetExecutionTimes2 to determine a new schedule. UpdateTargetExecutionTimes2 is like UpdateTargetExecutionTimes, but it first tightens execution windows according to Theorem 5.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Results
     </section-title>
     <paragraph>
      We now present test results for three applications, with three corresponding plant models. The first is a pedagogical system in which two simple linear second-order systems are loosely coupled through temporal constraints. The second is a sagittal plane bipedal walking robot, which is used to show the robustness of the system. The third is a full, 3D bipedal walking robot with foot placement constraints due to challenging terrain.
     </paragraph>
     <section label="7.1">
      <section-title>
       Loosely coupled linear second order model
      </section-title>
      <paragraph>
       Consider a plant consisting of two double integrators. Although this is a very simple plant, it is representative of a large class of problems involving synchronization of components. For example, in bipedal walking problems, it is important to synchronize movement of the forward CM component with the lateral, and to synchronize both with movement of the stepping foot.
      </paragraph>
      <paragraph>
       Each double integrator is a linear sub-system of the plant (see Definition 2) where{a mathematical formula} and where {a mathematical formula}x=[x1x2], and {a mathematical formula}x1 represents position (the output of the second integrator), {a mathematical formula}x2 represents velocity (the output of the first integrator), and u, the input, is acceleration. The actuation constraint on the input is {a mathematical formula}−10&lt;u&lt;10.
      </paragraph>
      <paragraph>
       Now, consider a very simple QSP for this plant that has only two events: start and finish. There are two activities, one for each linear sub-system and each activity goes from start to finish. Thus, the linear sub-systems are loosely coupled through the start and finish events. Suppose that the goal region for each of these activities is specified by {a mathematical formula}−1&lt;x1&lt;1, {a mathematical formula}−1&lt;x2&lt;1. Suppose, also, that the QSP imposes a temporal constraint requiring that the finish event must happen 0 to 1 seconds after the start event.
      </paragraph>
      <paragraph>
       The executive must guide the parallel linear sub-systems of the plant to their goal regions, so that they are in these regions at the same time. The initial conditions of each linear sub-system may be different, and each linear sub-system may be subject to different disturbances.
      </paragraph>
      <paragraph>
       Flowtube cross sections for various durations (see Definition 19) are shown in Fig. 11.
      </paragraph>
      <paragraph>
       Suppose that both linear subsystems begin with initial condition {a mathematical formula}x1=2,x2=0. For this initial state, there is flexibility in the duration from start to finish that the executive can select. As shown in Fig. 11, durations of 0.6, 0.8, and 1.0 s are all feasible. Suppose that the executive selects a target duration of 0.8 s. In the absence of disturbances, the resulting trajectory for both linear subsystems is the solid green plot shown in Fig. 12.
      </paragraph>
      <paragraph>
       Now, suppose that the initial condition of one of the linear subsystems is disturbed so that it is {a mathematical formula}x1=2.5,x2=0. This is a spatially and temporally controllable disturbance, because the executive does not have to change the original target duration of 0.8 s. The new trajectory for the disturbed system is the dashed black plot in Fig. 12.
      </paragraph>
      <paragraph>
       Next, suppose that the initial condition is disturbed to {a mathematical formula}x1=3.5,x2=0. As can be seen from Fig. 11(c), a duration of 0.8 s is no longer feasible. Neither are durations shorter than 0.8 s. However, the longer duration of 1 s is feasible, as can be seen from Fig. 11(d), so this is a spatially controllable disturbance. The executive must choose a new feasible duration, for example, 1 s, resulting in the trajectory shown as the dotted red plot in Fig. 12. The duration for the undisturbed subsystem must be changed to 1 s as well, which is feasible as indicated by the cross sections.
      </paragraph>
      <paragraph>
       Finally, suppose that the initial condition is disturbed to 4.5. This state is outside the bounds of the cross section for duration 1 s; a longer duration would be necessary. However, this would violate the temporal constraint, so the plan is infeasible. The executive aborts the plan in this case, and requests a new one, possibly, one with the temporal constraint of 1 s relaxed.
      </paragraph>
     </section>
     <section label="7.2">
      <section-title>
       Sagittal plane biped model
      </section-title>
      <paragraph>
       A sagittal plane biped walking model considers coordination of forward movement of the CM and stepping foot. This is simpler than the full 3D biped (described in the next subsection), but it is an important stepping stone. Full 3D biped walking can then be achieved by developing a similar model for the frontal plane, and then loosely coupling sagittal and frontal CM movement control. Thus, our algorithms focus on synchronization of movement of the forward and lateral CM components with the movement of the stepping foot, which are the key variables to control for successful locomotion.
      </paragraph>
      <paragraph>
       An abstraction commonly used for controlling bipedal walking robots is the linear inverted pendulum [5]. This abstraction captures the essential requirements for balancing, which involves managing movement of the CM relative to the support base, subject to limits on the force that can be exerted on the CM. This abstraction is provided by a “whole-body controller”, as discussed previously in Section 3. The whole-body controller is responsible for figuring out how the robot's joints should move so that CM movement goals are achieved. This allows key control policy decisions about balance control to be made using the abstraction, which is easier to work with than the underlying high d.o.f. robot. For this work, we have used a feedback linearization algorithm to implement the whole-body controller [4].
      </paragraph>
      <paragraph>
       To model forward CM movement, we use an enhanced linear inverted pendulum model that incorporates the force effects of angular momentum. The state vector is {a mathematical formula}x=[x1x2x3x4]T, where {a mathematical formula}x1 represents the forward CM position, {a mathematical formula}x2, the forward CM velocity, {a mathematical formula}x3, the orientation of the biped's torso, and {a mathematical formula}x4, the angular velocity of the torso about the CM [5], [4]. The input vector is {a mathematical formula}x=[u1u2]T, where {a mathematical formula}u1 is the forward Zero Moment Point (ZMP) position (directly related to forward force on the CM), and {a mathematical formula}u2 is the torque on the torso about the CM pitch axis. The ZMP is the point on the ground about which the moment is zero [34]. For flat terrain, it coincides with the center of pressure on the ground exerted by the feet. The plant model for forward CM movement is then:{a mathematical formula} where {a mathematical formula}k1=kz/m, {a mathematical formula}k2=I/m, {a mathematical formula}kz=980 is the “spring constant” for the linearized inverted pendulum, {a mathematical formula}m=100kg is the total mass of the biped, and {a mathematical formula}I=8.7kg/m2 is the inertia of the torso.
      </paragraph>
      <paragraph>
       The forward ZMP position input, {a mathematical formula}u1, is constrained to be within the back and front boundaries of the support foot. In this model, the ankle of the support foot is at position 0 in the forward direction, the front boundary of the foot is 0.2 meters in front of the ankle, and the back boundary is 0.04 meters behind. Therefore, {a mathematical formula}−0.04≤u1≤0.2. The torque input, {a mathematical formula}u2, is constrained to be within {a mathematical formula}+/−200Nm.
      </paragraph>
      <paragraph>
       Forward movement of the stepping foot is modeled as a double integrator, as in the previous pedagogical example. Acceleration and velocity constraints are such that the forward stepping movement can be completed in as fast as 0.3 seconds.
      </paragraph>
      <paragraph>
       The QSP for this experiment is similar to the previous one; it has a start and finish event connected by two activities, one for CM forward movement, and one for stepping foot forward movement. As in the previous experiment, the sub-systems are loosely coupled through the start and finish events. The goal region for the CM forward movement activity is {a mathematical formula}0.48≤x1≤0.52, {a mathematical formula}0.5≤x2≤1.5, {a mathematical formula}−0.1≤x3≤0.1, {a mathematical formula}−0.3≤x4≤0.3. The QSP imposes a temporal constraint requiring that the finish event must happen 0.6 to 1.5 seconds after the start event.
      </paragraph>
      <paragraph>
       Fig. 13 shows two sets of trajectories, one nominal, starting from an initial state of {a mathematical formula}x=[−0.2,1.0,0,0], and one corresponding to a push disturbance in the backward direction, starting from an initial state of {a mathematical formula}x=[−0.3,1.0,0,0]. The executive compensates for the disturbance by adjusting the ZMP and torque inputs, so that the disturbed trajectory still ends in the goal region. In particular, it temporarily sacrifices the goal of upright posture (see 13(c)) in order to enhance controllability of the CM (see also [5]). In this case, no change in duration is needed, so the disturbance is of the first class (spatially and temporally controllable).
      </paragraph>
      <paragraph>
       Now, suppose that we use a more conventional planning and control approach, where the nominal trajectory is computed as part of the planning step, and then a tracking controller is used to follow the nominal trajectory. For this experiment, we have used a high-gain PD tracking controller. Fig. 14 shows trajectories resulting from the same nominal and disturbed states as those in Fig. 13. In this case, however, the PD tracking controller, rather than the model-based executive, is used to handle the disturbance. The controller tries to follow the nominal trajectory, but fails, resulting in the disturbed trajectory diverging from, rather than converging to the nominal trajectory, and as a result, missing the goal by a wide margin. The reason, in large part, is that the PD tracking controller is not smart enough to utilize angular momentum to enhance controllability, whereas the executive's control policy is. The failure to meet a plan goal does not, necessarily, imply that the biped will fall, although in this case, the disturbed CM trajectory results in the CM movement being so far ahead of the stepping foot movement that a fall is inevitable.
      </paragraph>
      <paragraph>
       In order to test the robustness of the executive dispatcher relative to the PD tracking controller, we repeated the previous experiment 100 times, using random initial states, corresponding to random disturbances. The initial CM forward position ({a mathematical formula}x1) was sampled using a uniform distribution over the range {a mathematical formula}−0.5≤x1≤0.2. The initial CM forward velocity ({a mathematical formula}x2) was sampled using a uniform distribution over the range {a mathematical formula}0.6≤x1≤1.4. The initial orientation and angular velocity ({a mathematical formula}x3 and {a mathematical formula}x4) were set to 0. Test results are shown in Table 1. The executive dispatcher is able to handle all Class 1 (spatially and temporally controllable), and all Class 2 (spatially controllable) disturbances, whereas the PD controller is successful for only a fraction of the Class 1, and for none of the Class 2 disturbances.
      </paragraph>
     </section>
     <section label="7.3">
      <section-title>
       Biped model
      </section-title>
      <paragraph>
       We now present test results of execution of a variety of qualitative control plans for bipedal walking with foot placement and temporal constraints, and with disturbances. Test results for nominal walking at different speeds are provided in [5].
      </paragraph>
      <paragraph>
       To perform these tests, we used a high-fidelity, 20 degree-of-freedom humanoid simulation to represent the plant being controlled [4], [5]. This simulation accurately models gravity, ground reaction forces and joint torques, and the resulting link acceleration dynamics. In particular, just as with a real biped robot (or a human), this simulated humanoid will fall if inappropriate control commands are provided.
      </paragraph>
      <paragraph>
       The hybrid plant model (Definition 1) has four modes: left foot single support, double support right foot in front, right single support, double support left foot in front. The mode transition guard conditions are based on toe-off and heel-strike events. The linearized plant abstraction, for each mode, is provided by a feedback linearizing controller [4], [5]. This produces linearized decoupled models for the forward, lateral, and vertical center of mass components, and stepping foot components. Thus, performing walking tasks involves synchronization of the 3 CM and the 3 stepping foot components when in single support, and the 3 CM components when in double support. For example, when the mode is left foot single support, 6 parallel activities are in the Runtime Activity State, all with right heel strike as the finish event. Each activity must be in its goal region when right heel strike occurs in order for execution to proceed successfully. The event horizon in this case is simple since the parallel activities all share the same finish event.
      </paragraph>
      <section label="7.3.1">
       <section-title>
        Irregular foot placement
       </section-title>
       <paragraph>
        Fig. 15 shows dynamic walking, but with an irregular stepping pattern, which is necessary due the blocks the biped is walking on. These blocks move slowly, so the timing of foot placement, as well as the positioning is important. At this speed, the biped can't just balance statically on each block. Instead, the moderately fast speed requires dynamic balancing and coordination of the center of mass trajectory. Fig. 16 shows the CM trajectory and foot placements for this test. The dynamic nature is indicated by the fact that the CM trajectory barely touches the foot placement polygons, and in one case, is 0.1 m away. This indicates that the system is not statically stable in this pose, and is relying on the subsequent foot placement sequence to maintain balance.
       </paragraph>
      </section>
      <section label="7.3.2">
       <section-title>
        Lateral push disturbances
       </section-title>
       <paragraph>
        A biped is especially sensitive to lateral push disturbances when in single support, due to the limited support base provided by one foot. In particular, a biped is most sensitive to lateral push disturbances when there are foot placement constraints, and when the push disturbance results in acceleration towards the outer edge of the stance foot.
       </paragraph>
       <paragraph>
        Fig. 17 shows recovery from a lateral push disturbance, while walking on a balance beam. The push occurs from the right side of the biped during left single support. Thus, the push results in an acceleration of the CM to the biped's left. Because foot placement is constrained by the narrowness of the balance beam, compensation by stepping is not an option. Instead, the system compensates for the disturbance by exerting a restoring torque at the ankle. This torque has a significant actuation limit; the lateral center of pressure must not get too close to the outer edge of the foot, or the foot will roll. Because the foot is relatively narrow, this presents a severe actuation limit. Additional (but also limited) compensation is accomplished through the angular movement of the torso and right leg, as shown in the third frame of the sequence [4], [5]. In particular, as shown in Fig. 17, the torso rotates clockwise, from the viewer's perspective, which induces a counter-clockwise rotation of the stance leg, which, in turn, engenders an acceleration of the biped's CM toward the biped's right.
       </paragraph>
       <paragraph>
        Due to joint acceleration limits, there is a limit to the angular acceleration that can be produced by the torso and the right leg. Therefore, recovery of lateral balance takes some time; the right leg is out for a significantly longer time (about two seconds) than it would be if it were just taking a normal step. This means that the forward center of mass velocity must be reduced while the lateral compensation movement is taking place. This forward velocity reduction must be accomplished by the left (stance) foot alone. Due to support base limitations, there is a limit on the force that can be applied in this way, and therefore a limit to the negative forward acceleration that can be produced. Thus, the biped must be walking relatively slowly, in the first place, for this sort of maneuver to work at all. If this is the case, then forward movement of the CM can be slowed while the right leg is out, and then sped up again after the lateral compensation maneuver is completed. Thus, the forward CM position and the forward stepping position remain synchronized. This is one reason why people tend to walk slowly on tightropes or balance beams.
       </paragraph>
      </section>
      <section label="7.3.3">
       <section-title>
        Kicking a soccer ball
       </section-title>
       <paragraph>
        The problem of moving a biped to kick a soccer ball (Fig. 1(b)) requires synchronization of the forward and lateral components of the CM with the step movement, and with the movement of the kicking foot. Figs. 18(a) and 18(b) show flow tubes and nominal trajectories for the forward and lateral CM components. The flow tubes correspond to CM movement for taking three steps before kicking a soccer ball. Figs. 18(c) and 18(d) show flow tube cross sections (in the position–velocity plane) for the first activity. The intersection of the initial state with the cross sections determines the duration (temporal) controllability. If the initial state intersects all cross sections, as shown in the figure, then the executive is free to choose any duration in the range covered by the cross sections. This is important for adjusting timing of task completion when kicking a moving soccer ball. Disturbances from the nominal trajectory may restrict the controllable duration range. For example, suppose the system is subjected to a lateral push disturbance at the beginning of the task. This may cause the initial state to deviate from the nominal initial state. If the initial state intersects all cross sections for forward movement, but only a subset for lateral movement, then the overall temporal controllability is limited by the latter set of cross sections.
       </paragraph>
      </section>
     </section>
    </section>
   </content>
  </root>
 </body>
</html>