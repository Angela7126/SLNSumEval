<html>
<head>
<meta name="TextLength" content="SENT_NUM:37, WORD_NUM:1011">
</head>
<body bgcolor="white">
<a href="#0" id="0">Human – Robot Interaction (HRI) represents a challenge for Artificial Intelligence (AI).</a>
<a href="#1" id="1">These three challenges, communication, joint action, human-aware execution, structure the research in human – robot interaction.</a>
<a href="#2" id="2">a belief state that includes a priori common-sense knowledge and mental models of each of the agents involved (the robot and its human partners).</a>
<a href="#3" id="3">Specifically, the deliberative architecture of a robot designed to share space and tasks with humans, and to act and interact in a way that supports the human's own actions and decisions.</a>
<a href="#4" id="4">reuses the same set of affordances and inferences, together with explicit contextual reasoning on humans and robot abilities, to generate human – robot shared plans.</a>
<a href="#5" id="5">An active knowledge base (Oro), conveniently thought as a semantic blackboard, connects most of the modules: the geometric reasoning module (Spark) produces at relatively high frequency symbolic assertions describing the state of the robot environment and its evolution over time.</a>
<a href="#6" id="6">These logical statements are stored in the knowledge base, and queried back, when necessary, by the language processing module (Dialogs), the symbolic task planner (HATP) and the execution controller (Shary or pyRobots).</a>
<a href="#7" id="7">The output of the language processing module and the activities managed by the robot controller are stored back as symbolic statements as well.</a>
<a href="#8" id="8">Symbol grounding connects hence the knowledge model to the perception and actuation capabilities of the robot.</a>
<a href="#9" id="9">The different components that we have mentioned so far exhibit grounding mechanisms: geometric reasoning and dialogue processing modules constantly build and push new symbolic contents about the world to the knowledge base.</a>
<a href="#10" id="10">We present first the main internal cognitive capabilities, implemented in the Oro knowledge base itself, and then discuss successively the situation assessment module Spark, the dialogue processor Dialogs, the symbolic task planner HATP, and finally the main features of our execution controllers Shary and pyRobots.</a>
<a href="#11" id="11">As described in the next section, the environment model of the robot is continuously updated and the derived symbolic knowledge is therefore transient: it lasts only as long as the environment remains in the same state.</a>
<a href="#12" id="12">Building a grounded symbolic model of the physical environment does not suffice in general to fully ground the human – robot interaction, and a model of the current capabilities of the agents interacting with the robot is also required.</a>
<a href="#13" id="13">Natural language is a basic interaction modality that we use in our system both as an input (processing of the human speech) and as an output (verbalisation of the robot intentions, as well as human – robot shared plans).</a>
<a href="#14" id="14">Natural language processing is facilitated as our architecture manipulates semantics that are close to the human level.</a>
<a href="#15" id="15">As another example, when the human says “ this ” , the robot checks if the human is currently pointing at an object.</a>
<a href="#16" id="16">In that case, this is replaced by the object focused on.</a>
<a href="#17" id="17">For example, if the human says “ this ” without the robot tracking what the human points at, no 〈 HUMAN1 pointsAt ... 〉 fact is possibly available in the knowledge base, and the robot falls back on the anaphora resolution step alone.</a>
<a href="#18" id="18">The HATP planning domain defines a set of methods describing how to incrementally decompose a task and to allocate subtasks and actions to the robot and/or the human depending on the context.</a>
<a href="#19" id="19">This represents the procedural knowledge of the robot as well as its knowledge about the actions that the human partner is able to achieve.</a>
<a href="#20" id="20">HATP includes mechanisms called social rules to promote plans that are considered as suitable for human – robot interaction.</a>
<a href="#21" id="21">As HATP is a generic symbolic task planner and does not enforce any abstraction level for the planning domain, we have designed a planning domain made of top-level tasks whose semantics are close to the one used in the human – robot dialogue: the planner domain effectively contains concepts like Give, table, isOn.</a>
<a href="#22" id="22">This leads to an effective mapping between the knowledge extracted from the situation assessment or the dialogue, and the planner.</a>
<a href="#23" id="23">It enables the robot as well as the human to communicate their beliefs about the task to be achieved, in order to share mutual knowledge and to synchronise their activities.</a>
<a href="#24" id="24">The first one is focused on knowledge representation and verbal interaction: the human asks for help to find and pack objects (Interactive Grounding I in Table 3).</a>
<a href="#25" id="25">The second one (Cleaning the table) involves the Shary execution controller and the HATP symbolic task planner.</a>
<a href="#26" id="26">In this scenario, the human and the robot need to cooperatively remove objects from a table.</a>
<a href="#27" id="27">Robot behaviours and motions are fully planned and then executed.</a>
<a href="#28" id="28">This study focuses on multi-modal, interactive grounding only: the robot observes, builds and maintains knowledge about its human partners perspectives and affordances but does not actually perform any physical action besides verbal interaction and simple head movements.</a>
<a href="#29" id="29">The robot knowledge base is initialised with the Oro commonsense ontology.</a>
<a href="#30" id="30">We next describe two situations where we can follow the internal robot's reasoning and the interaction with the user.</a>
<a href="#31" id="31">Although there is an ambiguity from the robot's perspective, the human referred to the video tape using the definite quantifier the: this is interpreted by the natural language processor as the human referring to a known object, i.e.</a>
<a href="#32" id="32">the one visible in the human's knowledge model.</a>
<a href="#33" id="33">12, the video tape is computed by the robot as being reachable by the robot only (columns Perception and Knowledge), and the execution controller invokes the task planner, which produces a joint plan (column Plan) to move the tape so that the human can pick it and drop it into the bin.</a>
<a href="#34" id="34">This section synthesises what we see as the main challenges that human – robot interaction brings to Artificial Intelligence.</a>
<a href="#35" id="35">They would need to be accounted for when grounding human – robot interaction.</a>
<a href="#36" id="36">In our architecture, perspective taking, for instance, is tightly connected to the symbolic knowledge models, and since our knowledge base allows for storage of one knowledge model per agent, we have been able to endow the robot with a simple theory of mind (as explained in section 3.1.2): we explicitly model what the robot knows about its partners in a symbolic way.</a>
</body>
</html>