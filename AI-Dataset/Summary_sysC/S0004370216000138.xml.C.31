<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:366">
</head>
<body bgcolor="white">
<a href="#0" id="0">Definition 2.1</a>
<a href="#1" id="1">GeneratorLet {a mathematical formula}G ⊆ G be a set of graphs.</a>
<a href="#2" id="2">Let {a mathematical formula}R Θ ⊆ G×G be a binary relation over the structured domain {a mathematical formula}G parametrized by Θ .</a>
<a href="#3" id="3">A “ generator ” {a mathematical formula}M Θ is defined as:{a mathematical formula} that is {a mathematical formula}M Θ is a procedure that given a set of graphs G in input, returns the set of all the graphs for which the relation {a mathematical formula}R Θ holds true with at least one element of G.</a>
<a href="#4" id="4">The main difficulty in solving the constructive learning problem rests on 1) the generator {a mathematical formula}M Θ , which can be viewed as a procedure to obtain a set of instances, and 2) its optimization, which is a procedure to adapt the probability distribution of the output instances to a desired shape.</a>
<a href="#5" id="5">These operations are reminiscent of Markov chain Monte Carlo (MCMC) methods, a class of procedures for obtaining a sequence of samples from a probability distribution for which direct sampling is difficult.</a>
<a href="#6" id="6">Here we propose to model {a mathematical formula}M Θ using a type of MCMC known as the Metropolis – Hastings algorithm (MH).</a>
<a href="#7" id="7">The two main components of MH are (see Section 2.3) the proposal and the acceptance probability distribution.</a>
<a href="#8" id="8">We model the proposal probability distribution using a “ graph grammar ” (see Section 3.1.3) and the acceptance probability distribution using the probability estimator {a mathematical formula}fG0.</a>
<a href="#9" id="9">The probability estimators are implemented using calibrated one-class SVMs [40] (see Section 4.3) equipped with an efficient graph kernel [8] (see Section 4.1) to process graphs.</a>
<a href="#10" id="10">In Algorithm 2 we report the pseudo-code for the overall generative procedure.</a>
<a href="#11" id="11">Given a set of hypergraphs we extract a Local Substitutable Graph Grammar via Algorithm 1 (line 4) and we learn the associated approximate probability function via the one class SVM procedure detailed in Section 4.3 (line 6).</a>
<a href="#12" id="12">The generative procedure takes in input a set of seed graphs and a number of iterations.</a>
<a href="#13" id="13">Starting from each graph in the seed set (line 8), we apply the Metropolis – Hastings algorithm where the proposal distribution {a mathematical formula}g(x → x ′ ) is defined using the substitutability principle, i.e.</a>
</body>
</html>