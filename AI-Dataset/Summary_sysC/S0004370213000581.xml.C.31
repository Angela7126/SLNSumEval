<html>
<head>
<meta name="TextLength" content="SENT_NUM:18, WORD_NUM:424">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this work, we categorize the MIC methods according to how the information existent in the MI data is exploited (see Fig.</a>
<a href="#1" id="1">4).</a>
<a href="#2" id="2">In the Instance-Space (IS) paradigm, the discriminative information is considered to lie at the instance-level.</a>
<a href="#3" id="3">Therefore, the discriminative learning process occurs at this level: a discriminative instance-level classifier {a mathematical formula}f(x → ) is trained to separate the instances in positive bags from those in negative ones (see Fig.</a>
<a href="#4" id="4">1).</a>
<a href="#5" id="5">Based on it, given a new bag X the bag-level classifier {a mathematical formula}F(X) is obtained by simply aggregating instance-level scores {a mathematical formula}f(x → ), {a mathematical formula}x → ∈ X.</a>
<a href="#6" id="6">We say that this type of paradigm is based on local, instance-level information, in the sense that the learning process considers the characteristics of individual instances, without looking at more global characteristics of the whole bag.</a>
<a href="#7" id="7">In any categorization we will always find methods that fall close to the boundaries of two categories.</a>
<a href="#8" id="8">For example, in our taxonomy this happens with the BARTMIP method (see Section 7.6).</a>
<a href="#9" id="9">This is an ES method where each bag X is explicitly mapped into a vector {a mathematical formula}v → .</a>
<a href="#10" id="10">However, in order to perform this mapping, the bag X is compared with other bags Y from the training set through the definition of a bag-level distance function {a mathematical formula}D(X,Y).</a>
<a href="#11" id="11">In this sense, this method lies close to the boundary between the ES and BS categories.</a>
<a href="#12" id="12">In the rest of the work we will use two illustrative synthetic examples.</a>
<a href="#13" id="13">In order to estimate the instance-level classifier {a mathematical formula}f(x → ), the methods of this category use a training set of instances where each instance inherits the label of the bag where it lies.</a>
<a href="#14" id="14">The simplest approach is the SIL algorithm described by Bunescu and Mooney [20], which simply trains a standard supervised classifier {a mathematical formula}f(x → ) on the resulting training set.</a>
<a href="#15" id="15">Given a new bag X, the bag-level classifier {a mathematical formula}F(X) is obtained by using the sum as aggregation rule:{a mathematical formula}</a>
<a href="#16" id="16">Therefore, both the Histogram-based methods and the distance-based methods map the bag X to a vector {a mathematical formula}v → where the j-th element {a mathematical formula}vj measures the degree of “ presence ” of the class {a mathematical formula}Cj in the bag X.</a>
<a href="#17" id="17">In the Histogram-based methods this is done by counting the number of instances that fall into {a mathematical formula}Cj, while in the distance-based methods this is done by providing the lowest distance from {a mathematical formula}Cj to any instance in X.</a>
</body>
</html>