<html>
<head>
<meta name="TextLength" content="SENT_NUM:12, WORD_NUM:484">
</head>
<body bgcolor="white">
<a href="#0" id="0">Sections 6 and 7 discuss respectively how to design the core combinatorial structure of the optimization problem, and how to extract a system model from data: in both cases, our example problems are employed to present the process.</a>
<a href="#1" id="1">relatively simple compositions of non-linear, continuous, functions (only a minority of works have considered Artificial Neural Networks [23], [24]); (2) on specific problems, typically with continuous variables and range constraints; and (3) on specific solution techniques, e.g.</a>
<a href="#2" id="2">As a consequence, our focus is mostly on handling the integration of Machine Learning models in optimization: for example, we emphasize the importance of model embedding techniques (in Section 5), and of methods to exploit the structure of the extracted model for boosting the search process.</a>
<a href="#3" id="3">Black box optimization Black-box optimization approaches are concerned with finding solutions for optimization problems having cost or constraint functions with unknown structure: the typical case is that of systems lacking a declarative model, but for which a simulator is available.</a>
<a href="#4" id="4">This is done by relying on a set of functions {a mathematical formula}hkbal:{0,1}n â†’ (0,1], each of which associates a mapping of all jobs to a value for the {a mathematical formula}effk variable, representing the efficiency of core k. A base model for the second problem variant can be formulated as follows:</a>
<a href="#5" id="5">linear regression for fitting an expert-design model: we rely on the knowledge of the domain expert for defining the model structure, while we extract the parameter values from data.</a>
<a href="#6" id="6">Finally, we can use Empirical Model Learning and employ Machine Learning to extract from data both the structure and the parameters of the system model.</a>
<a href="#7" id="7">Local Search methods are originally designed for problems with discrete variables (unlike many blackbox optimization methods), and they can deal with non-trivial constraints (either via violation-based cost functions or by incorporating the constraints in the neighborhood definition).</a>
<a href="#8" id="8">In EML, this means that the Empirical Model constraints in the formulation from Section 4 are in fact a combination of two relations:{a mathematical formula} where y is a vector of variables representing the features, {a mathematical formula}hEM is the encoding of the Machine Learning model, and {a mathematical formula}hfeat are feature extraction constraints.</a>
<a href="#9" id="9">If the same values happen to be favorable in terms of cost in the problem model, then such input configurations, despite being uncommon in the training set, will be actively sought by the optimizer and will be much more likely to appear at search time.</a>
<a href="#10" id="10">We consider all the alternative modeling approaches discussed in Section 3, namely: (1) using a heuristic as a proxy for the efficiency values; (2) using fitting to adjust the parameters of an expert-designed model; and finally (3) several solution methods based on EML.</a>
<a href="#11" id="11">Linear regression makes it feasible to obtain values for all the parameters; however, it also requires one to build a training set, and therefore an overall design effort much closer to that of extracting an Artificial Neural Network.</a>
</body>
</html>