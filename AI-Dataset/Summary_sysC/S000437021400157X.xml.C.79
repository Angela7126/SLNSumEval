<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:376">
</head>
<body bgcolor="white">
<a href="#0" id="0">The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture.</a>
<a href="#1" id="1">Incremental means that the semantic map building process does not have to wait for the sensor data of some scene or environment to be complete (no matter how such completeness would have to be defined and determined), but has to start right away, based on individual sensor takes, such as single RGB-D frames or 3D laser scans.</a>
<a href="#2" id="2">Such reasoning is needed for the top-down part of closed-loop semantic mapping in the first place; it may be employed in other robot tasks using the previously acquired semantic map, such as object search (e.g., [6], [7]), human robot interaction on a high conceptual level [8], detecting norm violations [9].</a>
<a href="#3" id="3">The approach detailed in this paper combines a number of techniques that make it suitable for being used in on-line, incremental semantic mapping, starting from a stream of RGB-D frames: meshing of 3D points and referring to geometric features are used to compensate sensor noise and aperture limitations, and early closed-loop usage of the semantic knowledge is used to generate object hypotheses for guiding low-level sensor data processing.</a>
<a href="#4" id="4">Additionally, we include new comprehensive results about what effect the degree of similarity between CAD model and actual object has on the quality of the final pose estimation, and we apply the method to a full scene point cloud using a 6D SLAM algorithm.</a>
<a href="#5" id="5">1), consisting of three steps: (1) surface reconstruction (Section 3.1), as an instance of geometric primitive detection, transforms the input point cloud into a triangle mesh and extracts planar regions; (2) planar region classification (Section 3.2), as an instance of hypothesis generation, classifies the planar regions, detects furniture objects, and calculates initial pose estimates based on the planar regions; (3) final pose adjustment (Section 3.3), as an instance of hypothesis verification, computes the final pose using ICP, and places the corresponding CAD model in the scene.</a>
<a href="#6" id="6">While the output of ICP, i.e., the average point-to-point error, gives us a rough idea how well the sampled CAD model fits to the point cloud data, a more sophisticated evaluation of the final result is an important part of future work.</a>
</body>
</html>