<html>
<head>
<meta name="TextLength" content="SENT_NUM:42, WORD_NUM:1220">
</head>
<body bgcolor="white">
<a href="#0" id="0">The main activity in the competition is evaluation of state-of-the-art planners by running them on a set of planning problems and comparing their performance with some specific metrics.</a>
<a href="#1" id="1">A detailed analysis of the competition results that provides insights into the performance of state-of-the-art planners from different perspectives such as coverage, quality, CPU time, and memory usage.</a>
<a href="#2" id="2">This focuses on good plan quality, with less emphasis on the number of problems solved or the CPU time used.</a>
<a href="#3" id="3">Most temporal domains in previous competitions were temporally simple, in the sense that they did not require concurrency and problems could be solved by a pure sequential planner [27].</a>
<a href="#4" id="4">There are many ways to rank the expected difficulty of planning tasks, the most evident one being the number of planners that solved them.</a>
<a href="#5" id="5">1 shows the number of planners that solved a particular number of problems considering the whole benchmark, that is, those that were reused according to the procedure described in Appendix D and the new problems.</a>
<a href="#6" id="6">Thus, selection of structurally different problems becomes harder and problems tend in general to be more similar in terms of difficulty than in the other tracks: either they are not solved at all or a large number of planners solve them, as evidenced, for example, by the results for the barman domain.</a>
<a href="#7" id="7">Apart from the quality of the solutions, typical parameters used to compare planner performance in previous IPCs include the number of instances solved (or, alternatively, the overall problem solving success rate, defined as the percentage of problems solved{sup:7}), and the raw speed at which solutions were generated.</a>
<a href="#8" id="8">Table 4 lists the number of problems solved and the success rate for each planner in descending order.</a>
<a href="#9" id="9">Hence, the final score for each planner equals the number of problems it solved.</a>
<a href="#10" id="10">The results are not surprising and endorse the idea that optimal planners that solve more problems are superior; however, some insights are obtained.</a>
<a href="#11" id="11">3 shows the evolution of the number of problems solved by all entrants in the time interval {a mathematical formula}(0,1800]s. Although selmax performs worse than a number of planners at the start, it performs as well as merge-and-shrink at the end of the interval and moderately better than lmcut and fd-autotune.</a>
<a href="#12" id="12">However, although selmax was able to solve problems at faster pace than other planners, especially in the second half of the allotted time, lmcut and fd-autotune (which solved roughly the same number of problems) were faster than it at a confidence level of {a mathematical formula} Α =0.001.</a>
<a href="#13" id="13">Therefore, the following planners were distinguished by their performance in the sequential optimal track of IPC-2011:</a>
<a href="#14" id="14">It is evident that lama-2011 ranked first in terms of both the number of problems solved and the scoring function used.</a>
<a href="#15" id="15">In this section, we first show how the number of problems solved evolved over time in the range {a mathematical formula}(0,1800]s. Owing to the large number of participants in this track, Fig.</a>
<a href="#16" id="16">13 (page 101) shows the maximum memory required by all entrants in this track as a function of the number of problems solved by each of them.</a>
<a href="#17" id="17">Thus, the following planners were distinguished by their performance in the sequential track of IPC-2011:</a>
<a href="#18" id="18">To facilitate comparisons among tracks, entrants in the sequential multi-core track were faced with exactly the same problems chosen for the sequential satisficing track; the results of this comparison can be found in Section 5.2.</a>
<a href="#19" id="19">Table 6 shows the final score for each planner, along with the number of problems solved and the success rate.</a>
<a href="#20" id="20">The first test analyzes the number of problems effectively solved by each planner.</a>
<a href="#21" id="21">17 shows the evolution of the number of problems solved in the interval {a mathematical formula}(0,1800]s. phsff and yahsp2-mt are the fastest algorithms in the short term, with phsff always solving more problems than yahsp2-mt up to the end of the interval.</a>
<a href="#22" id="22">From this point on, the winner of this track progressed much faster and had already solved 123 problems at {a mathematical formula}t=14s, and yahsp2-mt solved only one additional problem.</a>
<a href="#23" id="23">However, these planners are still among the fastest up to {a mathematical formula}t=58s, at which point ayalsoplan catches yahsp2-mt, with both planners solving 123 problems by this time.</a>
<a href="#24" id="24">In general, it was observed that planners in this track showed a monotonically increasing profile even if memory decreases from time to time.</a>
<a href="#25" id="25">20 shows the maximum memory needed to solve a specific number of problems for all entrants in this track.</a>
<a href="#26" id="26">According to the results in Table 6 (page 101), arvandherd and ayalsoplan solved more problems with the highest score.</a>
<a href="#27" id="27">Thus, the following planners were distinguished by their performance in the sequential multi-core track of IPC-2011:</a>
<a href="#28" id="28">The following subsections examine the performance of entrants in the temporal satisficing track under the usual parameters: number of problems solved, quality, CPU time, and memory management.</a>
<a href="#29" id="29">Table 7 shows the final score, the number of problems solved, and the success rate for the temporal satisficing planners.</a>
<a href="#30" id="30">In this case, the coefficient for correlation between the number of problems solved and the score is 0.981.</a>
<a href="#31" id="31">The most remarkable observations are that yahsp2-mt and yahsp2 are the first- and second-ranked planners according to the number of problems solved, yet their score ranks them second and fourth, respectively.</a>
<a href="#32" id="32">24 shows an overall view of the number of problems solved by each planner and how quickly they provided responses; the makespan of the plans generated by each planner is ignored.</a>
<a href="#33" id="33">27 (page 109) shows how much memory was used over time in solving problem 003 of the elevators domain, which was solved by all the planners except cpt4, sharaabi, and tlp-gp.</a>
<a href="#34" id="34">Thus, the following planners were distinguished by their performance in the temporal satisficing track of IPC-2011:</a>
<a href="#35" id="35">According to the analysis in this section, overall, the optimal planner that won IPC-2011 improved on the performance of the optimal planner that won IPC-2008 with regard to the problems chosen for IPC-2011 in terms of both coverage and raw speed.</a>
<a href="#36" id="36">The difference in coverage is 13.22% over the whole set of planning tasks, but an improvement of 20% for the number of problems solved by the IPC-2008 winner.</a>
<a href="#37" id="37">Again, the analysis in this section shows that, overall, the planner that won IPC-2011 improves on the performance of the IPC-2008 winner for the problems chosen for IPC-2011 in terms of coverage, quality, and raw speed.</a>
<a href="#38" id="38">The analysis in this section shows that, overall, the temporal planner that won IPC-2011 improves on the performance of the temporal planner that won IPC-2008 for the problems chosen for IPC-2011 in terms of quality, but not necessarily coverage, and that it performs worse in terms of raw speed.</a>
<a href="#39" id="39">Both planners solved all problems in the Parking domain.</a>
<a href="#40" id="40">The fact that the winner of the sequential satisficing track surpassed the performance of the winner of the sequential multi-core track (at least in terms of both coverage and the official IPC score, and in terms of plan quality when considering the tasks solved by both planners) is not of great concern.</a>
<a href="#41" id="41">Likewise, the metric is not affected by Observation III: even if we assume that all planning tasks are solvable, the ratio {a mathematical formula}Cbest/C ⁎ {sup:14} equals either one (if at least one planner finds a solution) or zero (if a planning task is not solved by any entrant), so that the score for all planners is never affected.</a>
</body>
</html>