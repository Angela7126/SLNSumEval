<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:522">
</head>
<body bgcolor="white">
<a href="#0" id="0">Based on this discriminant function a TET structure learning algorithm is developed that, strictly speaking, will discover a feature {a mathematical formula}(T,f) (T a TET, f a discriminant function defined on T), but from which in a trivial abstraction step we can extract the model-independent TET feature T (Section 5).</a>
<a href="#1" id="1">We give the general definition of TET semantics in two steps: first we define the value space of nested counts associated with a given TET {a mathematical formula}T(V), and then the actual mapping {a mathematical formula}a ↦ V(T(a)).</a>
<a href="#2" id="2">In this case MLNs define a distribution over all models {a mathematical formula}M for a given signature R, and a fixed domain M. This distribution is defined by a knowledge base KB containing first-order logic formulas {a mathematical formula} Φ i with attached numeric weights {a mathematical formula}wi:{a mathematical formula} We refer to [36] for the details of MLN syntax and semantics.</a>
<a href="#3" id="3">Relevant in the current context is the fact that the distribution is defined as a function of count features, which, adapting the notation of the previous example, can be written in the form{a mathematical formula} where now {a mathematical formula} Φ (X) can be any first-order formula with free variables X.</a>
<a href="#4" id="4">While, thus, very similar in appearance to the aggregate features of the preceding example, there are some essential differences: first, MLNs depend on the actual integer-valued count feature, not only on derived Boolean features of the form {a mathematical formula}count{ … } ⩾ k.</a>
<a href="#5" id="5">Second, (10) takes the count of all substitutions of tuples of domain elements for all the free variables X in {a mathematical formula} Φ (X).</a>
<a href="#6" id="6">As a result, whereas {a mathematical formula}count{Y|triangle(Y) ∧ in(Y,X)} ⩾ 3 was a feature of the object X, now {a mathematical formula}count{X| Φ (X)} is a feature of entire models {a mathematical formula}M.Concrete MLN implementations will often allow only a restricted class of formulas {a mathematical formula} Φ (X) in the model specification (e.g.</a>
<a href="#7" id="7">3 shows a propositional TET for a, b, c. This TET is labeled with a weight assignment, where the weight at each node corresponds to the empirical frequency {a mathematical formula}n+/(n++n − ) of the positive class among the examples that satisfy all the conditions on the path from the root down to the node.</a>
<a href="#8" id="8">If all the groundings of the original branch are labeled with copies of the original weight assignment, then the discriminant function defined by the grounded TET is the same as the discriminant function defined by the original TET.</a>
<a href="#9" id="9">Thus, the interpretation of the discriminant function on propositional TETs also explains the discriminant function on general TETs, with two additional assumptions, or observations: our general independence assumption implies that features {a mathematical formula}T ′ (V,a),T ′ (V,a ′ ) defined by two different substitutions of constants in a sub-TET {a mathematical formula}T ′ (V,W) are assumed as independent, and the {a mathematical formula}d+/d − ratio one obtains is only an approximation of (14), since the weights defined by the initial TET are not exact class frequencies for the ground features, but only shared approximations obtained from aggregating statistics from all groundings (see Section 5).</a>
</body>
</html>