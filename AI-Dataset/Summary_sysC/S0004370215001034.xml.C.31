<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:170">
</head>
<body bgcolor="white">
<a href="#0" id="0">Since Euclidean distance plays a key role in our approach (e.g.</a>
<a href="#1" id="1">given its relationship to the notion of betweenness), instead of using NMF, we will show how we can identify (in an unsupervised) way interpretable directions in the space {a mathematical formula}S, corresponding to the most salient properties of the domain of interest (but typically not orthogonal to each other).</a>
<a href="#2" id="2">Let {a mathematical formula}C1, … ,Cm be disjoint categories and let {a mathematical formula}Oi be a set of entities that are known to belong to category {a mathematical formula}Ci (i.e.</a>
<a href="#3" id="3">{a mathematical formula}O= ⋃ iOi is the available training data).</a>
<a href="#4" id="4">We consider the problem of deciding which category is most likely to contain an unlabelled entity x.</a>
<a href="#5" id="5">In this context, using similarity based reasoning corresponds to k-NN classification [20], i.e.</a>
<a href="#6" id="6">we use {a mathematical formula}S to find the k entities {a mathematical formula}y1, … ,yk from O which are most similar to x and then assign x to the category to which most of the entities {a mathematical formula}yi belong.</a>
</body>
</html>