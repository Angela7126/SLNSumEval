<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:193">
</head>
<body bgcolor="white">
<a href="#0" id="0">The detailed algorithm is described in Algorithm 3.</a>
<a href="#1" id="1">We calculate the gradient {a mathematical formula}g ˆ t(wt − 1) of Lines 10 and 18 in Algorithm 3 by Eqs.</a>
<a href="#2" id="2">For finite instance spaces and least square loss{a mathematical formula} ℓ (t)=(1 − t)2, the pairwise surrogate loss{a mathematical formula} ℓ (f(x) − f(x ′ ))is consistent with AUC.</a>
<a href="#3" id="3">This section studies the regret bounds when the covariance matrices are approximated.</a>
<a href="#4" id="4">Recall that the covariance matrices are given by{a mathematical formula} where {a mathematical formula}Xt+ and {a mathematical formula}Xt − denote the matrices of positive and negative instances, respectively.</a>
<a href="#5" id="5">We try to approximate {a mathematical formula}Xt+[Xt+] ⊤ and {a mathematical formula}Xt − [Xt − ] ⊤ as done in Algorithm 2, Algorithm 3, since it is easy to store the means {a mathematical formula}ct+ and {a mathematical formula}ct − in memory.</a>
<a href="#6" id="6">In the following, we will derive the online-to-batch bounds for OPAUC algorithm.</a>
<a href="#7" id="7">First, we say that an online learning algorithm has a regret bound {a mathematical formula}RT if {a mathematical formula}wT0,wT0+1, … ,wT − 1 are such that{a mathematical formula} From Theorem 2, we can observe {a mathematical formula}RT=O(1/T) for the OPAUC algorithm.</a>
</body>
</html>