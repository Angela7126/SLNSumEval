<html>
<head>
<meta name="TextLength" content="SENT_NUM:13, WORD_NUM:384">
</head>
<body bgcolor="white">
<a href="#0" id="0">In practice, Value Iteration is stopped when:{a mathematical formula} where {a mathematical formula}S ′ is the set of states reachable from {a mathematical formula}s0 under some greedy policy Π w.r.t.</a>
<a href="#1" id="1">V and BE is known as the Bellman residual.</a>
<a href="#2" id="2">An indefinite horizon Markov Decision Process with Imprecise Probabilities, also called a Stochastic Shortest Path MDP-IP (SSP MDP-IP) is a sequential decision process with states, actions, a cost function, a set of goal states and an initial state, like an SSP MDP, but with a transition probability function that can be imprecisely defined.</a>
<a href="#3" id="3">That is, an SSP MDP-IP is an extension of an SSP MDP where, instead of a probability distribution {a mathematical formula}P( ⋅ |s,a) over the state space S, there is a set of probability distributions.</a>
<a href="#4" id="4">In practice, Value Iteration for SSP MDP-IPs is stopped when:{a mathematical formula} where {a mathematical formula}S ′ is the set of states reachable from {a mathematical formula}s0 under some greedy policy Π w.r.t.</a>
<a href="#5" id="5">V and {a mathematical formula}BEIP is known as the Bellman residual for SSP MDP-IP.</a>
<a href="#6" id="6">The imprecise probabilities of factored SSP MDP-IPs are given in terms of probability parameters subject to a set of constraints Φ .</a>
<a href="#7" id="7">Definition 4.4</a>
<a href="#8" id="8">Factored SSP MDP-IPFormally a Factored SSP MDP-IP is defined by {a mathematical formula} 〈 X → ,A,C,K,G,x → 0 〉 where A is defined as for any SSP MDP-IP, {a mathematical formula}X → is a vector of n state variables {a mathematical formula}(X1, … ,Xn), C is a factored cost function, {a mathematical formula}K is a set of factored transition credal sets (Definition 4.2), G is a set of goal states and {a mathematical formula}x → 0 the initial state.</a>
<a href="#9" id="9">For enumerated SSP MDP-IPs we assume state and action pair independence (Assumption 3.2).</a>
<a href="#10" id="10">In the case of factored SSP MDP-IP, instead of assuming independence for single states we now assume independence for abstract states, i.e., a set of states that are defined by the partial assignment of {a mathematical formula}paa(Xi ′ ).</a>
<a href="#11" id="11">Fig.</a>
<a href="#12" id="12">10 gives an example of PADD partial evaluation, where F is the probability transition function {a mathematical formula}PDD(X2 ′ |X1,X2,a1) and {a mathematical formula}w → is an assignment for the state variables {a mathematical formula}X1 and {a mathematical formula}X2, which results in a PADD with a single variable {a mathematical formula}X2 ′ .</a>
</body>
</html>