<html>
<head>
<meta name="TextLength" content="SENT_NUM:21, WORD_NUM:1018">
</head>
<body bgcolor="white">
<a href="#0" id="0">1 illustrates this context: the human and the robot share a common space and exchange information through multiple modalities (we specifically consider verbal communication, deictic gestures and social gaze), and the robot is expected to achieve interactive object manipulation, fetch and carry tasks and other similar chores by taking into account, at every stage, the intentions, beliefs, perspectives, skills of its human partner.</a>
<a href="#1" id="1">An active knowledge base (Oro), conveniently thought as a semantic blackboard, connects most of the modules: the geometric reasoning module (Spark) produces at relatively high frequency symbolic assertions describing the state of the robot environment and its evolution over time.</a>
<a href="#2" id="2">It becomes then an intention that the robot commits to.</a>
<a href="#3" id="3">As for any cognitive system, this fundamental interaction between knowledge and actions is central to our approach as well, and typically involves the dialogue module to acquire desires from the other agents, and the planner and the execution controller to first decide to take into account (or not) an incoming desire as a goal, and then to generate and manage intentions from these goals through the symbolic task planner.</a>
<a href="#4" id="4">This architecture design (a central knowledge base that essentially appears as a passive component to the rest of the system – even though it actually actively processes the knowledge pool in the background to perform inferences) departs from other approaches like the CAST model [31] where knowledge is represented as a diffuse, pervasive resource, or the CRAM/KnowRob architecture [32] where the knowledge base is an active hub that pro-actively queries perceptual components to acquire knowledge.</a>
<a href="#5" id="5">Our ‘ bottom-up ” design process of the ontology is apparent on this figure: only the subclasses relevant to the context of service robotics in an human-like environment are asserted: For performance reasons as well as clarity, we have decided against an extended conceptual coverage of what “ partially tangible things ” might be.</a>
<a href="#6" id="6">This represents an important cognitive skill, in particular in the human – robot interaction context: in this situation, the link that the robot has to establish between percepts and symbols must map as well as possible to the human representations in order to effectively support communication.</a>
<a href="#7" id="7">Symbol grounding connects hence the knowledge model to the perception and actuation capabilities of the robot.</a>
<a href="#8" id="8">The different components that we have mentioned so far exhibit grounding mechanisms: geometric reasoning and dialogue processing modules constantly build and push new symbolic contents about the world to the knowledge base.</a>
<a href="#9" id="9">Besides, Oro server implements several algorithms (presented in [17]) to identify similarities and differences between concepts (classes or instances): the Common Ancestors algorithm, useful to determine the most specific class(es) that include a given set of individuals; the First Different Ancestors algorithm that returns what can be intuitively understood as the most generic types that differentiate two concepts; and clarification and discrimination algorithms that play a key role in the process of interactive grounding of the semantics of concepts (we discuss this process in section 3.3).</a>
<a href="#10" id="10">We rely however on this mechanism in certain cases: some modules like the natural language processor use the short term memory profile to mark concepts that are currently manipulated by the robot as active concepts: if a human asks the robot “ Give me all red objects ” , the human, the Give action, and every red objects that are found are marked as active concepts by inserting statements such as 〈 HUMAN type ActiveConcept 〉 in the short-term memory (which can be considered, in this case, to be a working memory).</a>
<a href="#11" id="11">Full human action and activity recognition is a task that requires knowledge and reasoning both on high-level facts like goals, intentions and plans, as well as bottom-up data from human and object motions.</a>
<a href="#12" id="12">In its current form, our situation assessment module makes two assumptions: the objects are known in advance (hence, we can rely on proper 3D CAD model for spatial reasoning) and the robot benefits of an nearly perfect perception, made possible by the use of fiducial markers.</a>
<a href="#13" id="13">Combining the above criteria, we yield shared plans with desirable interaction features like having the human engaged in a number of tasks while her overall level of efforts remains low, or avoiding having the human to wait for the robot by preventing the action streams from having too many causal links between them.</a>
<a href="#14" id="14">In the future, we intend to extend the plan-search algorithm and integrate the social rules in the process itself.</a>
<a href="#15" id="15">As HATP is a generic symbolic task planner and does not enforce any abstraction level for the planning domain, we have designed a planning domain made of top-level tasks whose semantics are close to the one used in the human – robot dialogue: the planner domain effectively contains concepts like Give, table, isOn.</a>
<a href="#16" id="16">This leads to an effective mapping between the knowledge extracted from the situation assessment or the dialogue, and the planner.</a>
<a href="#17" id="17">When the knowledge base states that an agent experiences a particular emotion or state, the execution controller may decide to handle it, typically by trying to answer the question or using the emotional or physical state as a parameter for subsequent actions.</a>
<a href="#18" id="18">As an example, when the speaker says “ I feel tired ” , we change the motion planner parametrisation to lower the effort the human needs to provide for the following joint manipulation tasks.</a>
<a href="#19" id="19">We first discuss how embodied cognition is an essential challenge in human – robot interaction; we rephrase then the requirements of joint actions in terms of five questions; we discuss the importance of building and maintaining a multi-level model of the human; and we finally reflect on the importance of explicit knowledge management in robotic architectures that deal with human-level semantics and state in that respect the current limits of our logic framework.</a>
<a href="#20" id="20">In our architecture, perspective taking, for instance, is tightly connected to the symbolic knowledge models, and since our knowledge base allows for storage of one knowledge model per agent, we have been able to endow the robot with a simple theory of mind (as explained in section 3.1.2): we explicitly model what the robot knows about its partners in a symbolic way.</a>
</body>
</html>