<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:359">
</head>
<body bgcolor="white">
<a href="#0" id="0">), however, there are few generative approaches that can sample structures belonging to a desired distribution or class.</a>
<a href="#1" id="1">We call the task of generating samples from an empirical probability distribution of graphs a “ constructive learning problem ” (CLP) when the generative machinery is adaptive and data driven.</a>
<a href="#2" id="2">Constructive learning problem for finite samplesLet {a mathematical formula}S(G,G ′ ) be a similarity measure between two sets of graphs defined in terms of an underlying graph kernel {a mathematical formula}K( ⋅ , ⋅ ) between two graphs:{a mathematical formula}{a mathematical formula}The constructive learning problem for finite samples is the solution to the following optimization problem:{a mathematical formula}</a>
<a href="#3" id="3">The main difficulty in solving the constructive learning problem rests on 1) the generator {a mathematical formula}M Θ , which can be viewed as a procedure to obtain a set of instances, and 2) its optimization, which is a procedure to adapt the probability distribution of the output instances to a desired shape.</a>
<a href="#4" id="4">The two main components of MH are (see Section 2.3) the proposal and the acceptance probability distribution.</a>
<a href="#5" id="5">We model the proposal probability distribution using a “ graph grammar ” (see Section 3.1.3) and the acceptance probability distribution using the probability estimator {a mathematical formula}fG0.</a>
<a href="#6" id="6">The probability estimators are implemented using calibrated one-class SVMs [40] (see Section 4.3) equipped with an efficient graph kernel [8] (see Section 4.1) to process graphs.</a>
<a href="#7" id="7">{a mathematical formula}O(R ˆ T ˆ N|V||E|) in the worst case scenario.</a>
<a href="#8" id="8">Note that in case of sparse graphs, e.g.</a>
<a href="#9" id="9">for molecular graphs, (i.e.</a>
<a href="#10" id="10">{a mathematical formula}|E| ≈ k|V| with small constant k) and of small values for {a mathematical formula}R ˆ and {a mathematical formula}T ˆ , the algorithm runs with a complexity that is essentially linear in the cumulative data set vertex size.</a>
<a href="#11" id="11">In Algorithm 2 we report the pseudo-code for the overall generative procedure.</a>
<a href="#12" id="12">Given a set of hypergraphs we extract a Local Substitutable Graph Grammar via Algorithm 1 (line 4) and we learn the associated approximate probability function via the one class SVM procedure detailed in Section 4.3 (line 6).</a>
<a href="#13" id="13">The generative procedure takes in input a set of seed graphs and a number of iterations.</a>
</body>
</html>