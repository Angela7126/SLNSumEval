<html>
<head>
<meta name="TextLength" content="SENT_NUM:16, WORD_NUM:703">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this paper, we provide some insight on these issues, in the form of nine specific questions, by giving a comprehensive account of about thirty computer models, from the 1960s to nowadays, and their relationships, focussing on the range of intelligence test tasks they address, the purpose of the models, how general or specialised these models are, the AI techniques they use in each case, their comparison with human performance, and their evaluation of item difficulty.</a>
<a href="#1" id="1">As a conclusion, these tests and the computer models attempting them show that AI is still lacking general techniques to deal with a variety of problems at the same time.</a>
<a href="#2" id="2">We hope that our work can be a starting point towards a more systematic and general treatment of computer models solving intelligence tests and towards the development of (more) general intelligent systems passing arbitrary intelligence tests.</a>
<a href="#3" id="3">Taking this perspective, item difficulty can be either explained completely independent of humans by means of algorithmic information theory or based on the assumed complexity of the cognitive processes and representations necessary to solve a test item.</a>
<a href="#4" id="4">Strictly, this is not a big switch approach, but shows that the system would not work for a similar problem with different relations.</a>
<a href="#5" id="5">As an indirect result and based on the previous relations, they produced “ a pair (FAIRAVEN and BETTERAVEN) of computer simulation models that performed like the median or best college students in the sample ” , which were based on the analysis of eye fixations, verbal protocols, error patterns, and the identification of the previous rules.</a>
<a href="#6" id="6">As the reasons to choose RPM, Carpenter et al.</a>
<a href="#7" id="7">Unlike the previous work [121], the motivation of this work is to solve the problems in a cognitive way, i.e., explaining why the system fails (ambiguousness, objects neglected, incorrect rules applied, … ) and why some problems are more difficult than others (number and type of rules applied, number of calls to the declarative memory, objects stored, … ).</a>
<a href="#8" id="8">Considering the results obtained, the authors claim that the visual complexity involved in solving this kind of problems is smaller than the functional difficulty (rules to be applied).</a>
<a href="#9" id="9">The generalisation can then be compared to new objects: each given solution in a RPM problem is inserted into the matrix, returning the one with the closest matching structural relationship, or, each individual image in an odd-one-out problem can be compared to the generalisation thus returning the noticeably least similar as the solution.</a>
<a href="#10" id="10">Furthermore, since SME automatically figures out what kinds of things can be matched [152], this combination of qualitative representations and structure-mapping engine has also been used (all together with the Companion Cognitive Architecture to perform qualitative reasoning) to solve Bennett's Mechanical Comprehension Tests [116], demonstrating its generality.</a>
<a href="#11" id="11">As a computational formalisation of all this can be difficult, only the integration of all these approaches from psychometrics, artificial intelligence, and other areas may lead to a full understanding of what intelligence is.</a>
<a href="#12" id="12">Consequently, the answer of this fourth question is that, in our opinion, some of these models are shedding light about the kind of problems a general AI system should solve, but all this shows that other more universal and formal approaches for the definition and analysis of tasks will be required.</a>
<a href="#13" id="13">However, there is no point in making a comparison between these three systems since their aims were completely different: the goal of Sanghi and Dowe [15] was not to excel in any specific task, the aim of Ragni and Klein [121] was to successfully solve large sets of number series from OEIS, and the goal of Siebers and Schmid [128] was to get cognitive plausibility for series actually found in intelligence tests (including failure on those difficult series for which humans fail) instead of excelling on performance.</a>
<a href="#14" id="14">The creation of systems capable of doing this is more related to the areas of learning by demonstration and inductive programming [142], [143], as mentioned above, rather than other areas of artificial intelligence and machine learning.</a>
<a href="#15" id="15">As a result, the answer to this seventh question is that there has been limited feedback between the systems, and the progress is caused by the painstaking integration of more methods from AI and some incremental development for some particular techniques.</a>
</body>
</html>