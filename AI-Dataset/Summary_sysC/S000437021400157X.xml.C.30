<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:345">
</head>
<body bgcolor="white">
<a href="#0" id="0">This paper presents an approach to creating a semantic map of an indoor environment incrementally and in closed loop, based on a series of 3D point clouds captured by a mobile robot using an RGB-D camera.</a>
<a href="#1" id="1">Based on a semantic model about furniture objects (represented in an OWL-DL ontology with rules attached), we generate hypotheses for locations and 6DoF poses of object instances and verify them by matching a geometric model of the object (given as a CAD model) into the point cloud.</a>
<a href="#2" id="2">The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture.</a>
<a href="#3" id="3">We demonstrate the robustness of our approach against occlusion and aperture limitations of the RGB-D frames, and against differences between the CAD models and the real objects.</a>
<a href="#4" id="4">The key difference to our approach is that our system is applicable to arbitrary 3D data like point clouds from laser scanners and does not rely on the special structure of RGB-D frames.</a>
<a href="#5" id="5">1), consisting of three steps: (1) surface reconstruction (Section 3.1), as an instance of geometric primitive detection, transforms the input point cloud into a triangle mesh and extracts planar regions; (2) planar region classification (Section 3.2), as an instance of hypothesis generation, classifies the planar regions, detects furniture objects, and calculates initial pose estimates based on the planar regions; (3) final pose adjustment (Section 3.3), as an instance of hypothesis verification, computes the final pose using ICP, and places the corresponding CAD model in the scene.</a>
<a href="#6" id="6">To investigate how robust our ICP matching step is with respect to such differences between CAD model and actual object, we conducted an experiment where we matched several CAD models of chairs against recorded point data of a chair.</a>
<a href="#7" id="7">A photograph of the chair and a view of the resulting point cloud can be seen in Fig.</a>
<a href="#8" id="8">The results clearly indicate that as long as the CAD model is “ similar enough ” (chairs 1 – 4) to the objects found in the data, our system works.</a>
</body>
</html>