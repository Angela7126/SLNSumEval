<html>
<head>
<meta name="TextLength" content="SENT_NUM:22, WORD_NUM:812">
</head>
<body bgcolor="white">
<a href="#0" id="0">Planning domainA planning domain is a tuple {a mathematical formula}D= 〈 P,A, Τ 〉 , where:</a>
<a href="#1" id="1">Agent planning programAn agent planning program is a tuple {a mathematical formula}P= 〈 P,V,v0, Δ 〉 , where:</a>
<a href="#2" id="2">{a mathematical formula}v0 ∈ V is the program initial state of {a mathematical formula}P; and</a>
<a href="#3" id="3">Plan-based simulationLet {a mathematical formula}D= 〈 P,A, Τ 〉 be a planning domain and {a mathematical formula}P= 〈 P,V,v0, Δ 〉 an agent planning program.</a>
<a href="#4" id="4">A plan-based simulation relation, or PLAN-simulation relation, is a relation {a mathematical formula}R ⊆ V×2P such that {a mathematical formula} 〈 v,s 〉 ∈ R implies that, for every transition {a mathematical formula}v → Γ : Ψ , Φ v ′ in {a mathematical formula}P such that {a mathematical formula}s ⊨ Γ , there exists an HT-plan Π such that:</a>
<a href="#5" id="5">Π achieves Φ and maintains Ψ from s (in which case, plan Π is said to realize the transition {a mathematical formula}v → Γ : Ψ , Φ v ′ ); andfor all complete trajectories h of plan Π from domain state s, it is the case that {a mathematical formula} 〈 v ′ ,end[h] 〉 ∈ R (in which case plan Π is said to preserveR from {a mathematical formula} 〈 v,s 〉 for {a mathematical formula}v → Γ : Ψ , Φ v ′ ).A</a>
<a href="#6" id="6">Let us formalize this planning domain {a mathematical formula}D= 〈 P,A, Τ 〉 , as follows:</a>
<a href="#7" id="7">{a mathematical formula}XD=P, containing the propositions of the planning domain {a mathematical formula}D;</a>
<a href="#8" id="8">{a mathematical formula}XV=V, containing the states of the planning program {a mathematical formula}P;</a>
<a href="#9" id="9">for every program state {a mathematical formula}v ∈ V, we define a propositional formula {a mathematical formula}reqv= ⋁ 〈 v, 〈 Γ , Ψ , Φ 〉 ,v ′ 〉 ∈ Δ req Γ : Ψ , Φ v,v ′ .</a>
<a href="#10" id="10">That is, {a mathematical formula}reqv states that (at least) one transition among those available in the state v of the planning program is currently requested.</a>
<a href="#11" id="11">The initial (dummy) state is simply defined as {a mathematical formula}I={init}, i.e., {a mathematical formula}XI= ∅ and {a mathematical formula}YI={init,last}.</a>
<a href="#12" id="12">Notice that neither the agent planning program nor the domain are in their initial state.</a>
<a href="#13" id="13">{a mathematical formula}init → ◯ v0, which encodes that the planning program is initially in its initial state.</a>
<a href="#14" id="14">{a mathematical formula} ⋀ v ∈ XV ◯ [v → reqv], which encodes that at least one transition available in the state the planning program moves to must be requested next.</a>
<a href="#15" id="15">{a mathematical formula} ⋀ 〈 v, 〈 Γ , Ψ , Φ 〉 ,v ′ 〉 ∈ Δ [req Γ : Ψ , Φ v,v ′ ∧ last → ◯ v ′ ], capturing that if transition {a mathematical formula}v → Γ : Ψ , Φ v ′ is currently requested and the last action performed has completed the current HT-plan, then the planning program moves to {a mathematical formula}v ′ .</a>
<a href="#16" id="16">A planning problem with PESs and TESs is a tuple {a mathematical formula} 〈 D,s0, Ψ , Φ ,SP,ST 〉 where {a mathematical formula}D= 〈 P,A, Τ 〉 is a deterministic planning domain, {a mathematical formula}s0 is the initial state, {a mathematical formula} Ψ ∈ Φ (P) is a maintenance goal, {a mathematical formula} Φ ∈ Φ (P) is an achievement goal; {a mathematical formula}SP ⊆ 2P is a set of PESs; and, finally, {a mathematical formula}ST ⊆ 2P is a set of TESs.</a>
<a href="#17" id="17">Given a planning problem {a mathematical formula} Π = 〈 D,s0, Ψ , Φ ,SP,ST 〉 with PESs and TESs, an executable plan Π for {a mathematical formula}D, and state {a mathematical formula}s ′ =last( Π (s0)), we say that Π is valid for Π iff Π maintains Ψ , {a mathematical formula}s ′ ⊨ Φ and {a mathematical formula}s ′ ∉ ST.</a>
<a href="#18" id="18">SoundnessThe function computed by Algorithm RealizePlanProg is a realization of the input agent planning program{a mathematical formula}P, deterministic planning domain{a mathematical formula}Dand initial domain state{a mathematical formula}s0, provided that subroutine Plan is sound to solve planning problems with achievement and maintenance goals.</a>
<a href="#19" id="19">A planning problem with action costs is a tuple {a mathematical formula} 〈 D,s0, Ψ , Φ ,c 〉 where {a mathematical formula}D= 〈 P,A, Τ 〉 is a deterministic planning domain, {a mathematical formula}s0 is the initial state, {a mathematical formula} Ψ ∈ Φ (P) is a maintenance goal, {a mathematical formula} Φ ∈ Φ (P) is an achievement goal; and {a mathematical formula}c:A ↦ R is an action cost function.</a>
<a href="#20" id="20">the (current) planning program state {a mathematical formula}W[v] ∈ W ∩ V, which always exists and is unique due to definition of {a mathematical formula} Ρ e (recall that {a mathematical formula}XV=V);</a>
<a href="#21" id="21">We will say that W represents domain state {a mathematical formula}W[s], planning program state {a mathematical formula}W[v], transition {a mathematical formula}W[d], and action {a mathematical formula}W[a] (or, alternatively, that these are represented in W).</a>
</body>
</html>