<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:331">
</head>
<body bgcolor="white">
<a href="#0" id="0">After that, we present experimental results for both the original SimStudent and the extended SimStudent trained with problem sets used by real students in learning algebra, and show that the extended SimStudent is able to achieve performance comparable to the original SimStudent without requiring domain-specific knowledge as input.</a>
<a href="#1" id="1">Since previous research on algebra problem solving has pointed out that computational parsimony is an important factor in a quality cognitive model of human problem solving [28], when faced with a new task, the learning algorithm uses the existing grammar from previous tasks to build the smallest number of most probable parse trees for the new records.</a>
<a href="#2" id="2">In order to further understand how transfer learning affects learning efficiency, we carried out a second experiment where the previous grammar is not a subset of the current grammar.</a>
<a href="#3" id="3">Moreover, since we randomly pick features from randomly generated grammars in the overlapping task transfer, it is possible that the selected feature is at a relatively low level in the hierarchy, and thus corresponds to very short subsequences or one specific action sequence (no disjunctions).</a>
<a href="#4" id="4">In this case, the targeted feature is easy to learn, and the benefit of transfer is diminished.</a>
<a href="#5" id="5">But even so, all the extended learners (-Transfer +Feature Focus, and +Transfer -Feature Focus, and +Transfer +Feature Focus) still outperform the base learner (-Transfer -Feature Focus).</a>
<a href="#6" id="6">In order to understand whether the proposed algorithm is a good model of real students, we carried out a controlled simulation study in algebra using the +Transfer+Feature Focus learner.</a>
<a href="#7" id="7">Accelerated future learning, in which learning proceeds more effectively and more rapidly because of prior learning, is an essential measure of robust learning.</a>
<a href="#8" id="8">With the current extension, the representation is acquired by a deep feature learner before skill learning.</a>
<a href="#9" id="9">Hence, the acquired representation does not change during the course of skill acquisition.</a>
<a href="#10" id="10">As we will discuss in later sections, one possible future step is to use the feedback from the skill learning process to further refine the representation learning process.</a>
</body>
</html>