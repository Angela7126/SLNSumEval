<html>
<head>
<meta name="TextLength" content="SENT_NUM:19, WORD_NUM:441">
</head>
<body bgcolor="white">
<a href="#0" id="0">Lexical specificity computes the weights for each word by contrasting the frequencies of that word across {a mathematical formula}SC and {a mathematical formula}RC.</a>
<a href="#1" id="1">In this section we explain how we leverage lexical specificity in order to construct a lexical vector for a given text (i.e., {a mathematical formula}SC).</a>
<a href="#2" id="2">For instance, the vector representation obtained by averaging the vectors of the words Vietnam and capital is very close to the vector representation of the word Hanoi in the semantic space of word embeddings.</a>
<a href="#3" id="3">We evaluated this feature of the unified vectors on the task of cross-lingual word similarity in Section 6.1.3.</a>
<a href="#4" id="4">We first compute the lexical vectors of these Wikipedia pages, as well as for {a mathematical formula}wps.</a>
<a href="#5" id="5">We then apply Weighted Overlap (see Section 3.5) to calculate the similarity between the lexical vectors of each of these pages and that of {a mathematical formula}wps.</a>
<a href="#6" id="6">Specifically, we considered four different tasks: Semantic Similarity (Section 6), Sense Clustering (Section 7), Domain Labeling (Section 8) and Word Sense Disambiguation (Section 9).</a>
<a href="#7" id="7">Our system obtained state-of-the-art results on multilingual All-Words Word Sense Disambiguation using Wikipedia as sense inventory, evaluated on the SemEval-2013 dataset [95], and on English All-Words Word Sense Disambiguation using WordNet as sense inventory, evaluated on the SemEval-2007 [111] and SemEval-2013 [95] datasets.</a>
<a href="#8" id="8">This combination is based on the average similarity scores given by lexical and unified vectors for each sense pair.</a>
<a href="#9" id="9">We benchmark our system against other multilingual word similarity approaches.</a>
<a href="#10" id="10">We also compare this system with our embedded representations of synsets by using the polyglot word embeddings as input continuous representations (see Section 3.3).</a>
<a href="#11" id="11">We also report results for our system using the combination of lexical and unified English Nasari vectors.</a>
<a href="#12" id="12">Finally, we evaluated our embedded representations on the word to sense semantic similarity task.</a>
<a href="#13" id="13">As explained above, our system is based on Semantic Similarity (see Section 6) for the sense clustering tasks.</a>
<a href="#14" id="14">Lexical vectors were also computed for each Wikipedia page and the similarity between a Wikipedia page and each domain was calculated.</a>
<a href="#15" id="15">Given a set of target words in a text {a mathematical formula}T, we build a lexical vector for the context, as explained in Section 3.2.</a>
<a href="#16" id="16">We perform Word Sense Disambiguation experiments using two sense inventories: Wikipedia and WordNet.</a>
<a href="#17" id="17">Given that Nasari provides semantic representations for both concepts and named entities, this task was analogous to Word Sense Disambiguation (see Section 9.2) with the only difference being that in this task we only considered entity synsets as candidates.</a>
<a href="#18" id="18">We performed the evaluations on the same datasets as those used in Section 6.1.1 for word similarity and in Section 9.3.3 for Word Sense Disambiguation with WordNet as sense inventory.</a>
</body>
</html>