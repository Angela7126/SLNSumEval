<html>
<head>
<meta name="TextLength" content="SENT_NUM:37, WORD_NUM:669">
</head>
<body bgcolor="white">
<a href="#0" id="0">{a mathematical formula} Π ={pix|i ∈ {1,2} and x ∈ {s,m,e}},</a>
<a href="#1" id="1">the function d is defined as{a mathematical formula}</a>
<a href="#2" id="2">{a mathematical formula}w ⊨ LTLp iff {a mathematical formula}p ∈ w[0] and {a mathematical formula}p ∈ Π ;</a>
<a href="#3" id="3">{a mathematical formula}w ⊨ LTL ◯ Φ iff {a mathematical formula}w[1, ∞ ] ⊨ LTL Φ ; and</a>
<a href="#4" id="4">For example, we have that {a mathematical formula}NE(M1,q0, Γ → 1)={(WM,M ⋆ 2)| ⋆ 2 ∈ {M,W}} ∪ {(M ⋆ 1,WM)| ⋆ 1 ∈ {M,W}}.</a>
<a href="#5" id="5">The game {a mathematical formula} Γ (M1,q0, Γ → 1) has no dominant strategy equilibria whereas {a mathematical formula}DOE(M1,q0, Γ → 2)={(M ⋆ 1,M ⋆ 2)| ⋆ 1, ⋆ 2 ∈ {M,W}}.</a>
<a href="#6" id="6">Normative behaviour functionLet {a mathematical formula}Prefs be a set of preference profiles over Π .</a>
<a href="#7" id="7">A normative behaviour function{sup:8}f is a mapping {a mathematical formula}f:Prefs → LTL Π .</a>
<a href="#8" id="8">{a mathematical formula} Π ′ (x)={ Π (x)if x ∈ Q Π (q) ∪ Sif x=(q,S)</a>
<a href="#9" id="9">In particular, the effects of action profiles {a mathematical formula}(M,M),(M,W), and {a mathematical formula}(W,W) in the duplicated state {a mathematical formula}(q0,{fine1}) from {a mathematical formula}M1 ↾ N1 are defined as follows:{a mathematical formula}{a mathematical formula}{a mathematical formula} A different norm-based update of the environment model {a mathematical formula}M1 by the normative system that consists of only regimenting norms {a mathematical formula}N2={(p1s ∧ p2s,{(M,M)}, ⊥ ),(p1s ∧ p2s,{(W,M)}, ⊥ )} is illustrated in Fig.</a>
<a href="#10" id="10">That is, we have that:{a mathematical formula}</a>
<a href="#11" id="11">{a mathematical formula}Prefs is a set of preference profiles over {a mathematical formula}Agt and Π .</a>
<a href="#12" id="12">Norm-based mechanismLet {a mathematical formula}N ∈ Nrs be a normative system (over {a mathematical formula}M).</a>
<a href="#13" id="13">The tuple {a mathematical formula}(M,N) is called norm-based mechanism.</a>
<a href="#14" id="14">A norm-based mechanism {a mathematical formula}(M,N) gives rise to a CGS by updating {a mathematical formula}M with {a mathematical formula}N as introduced in Definition 11.</a>
<a href="#15" id="15">The next example gives a norm-based mechanism which strongly {a mathematical formula}NE-implements a normative behaviour function.</a>
<a href="#16" id="16">{a mathematical formula}F0 ⊆ Π is the initial state of the environment program,</a>
<a href="#17" id="17">{a mathematical formula}Acti is the set of actions of agent {a mathematical formula}i ∈ Agt,</a>
<a href="#18" id="18">{a mathematical formula}Agt={1, … ,k}</a>
<a href="#19" id="19">{a mathematical formula} Π (F)=F for {a mathematical formula}F ∈ Q</a>
<a href="#20" id="20">In the following, we use also variables {a mathematical formula}q0,q1, … to range over the set of states Q.</a>
<a href="#21" id="21">Norm-based multi-agent environment programLet {a mathematical formula}Agt={1, … ,k} be a set of agents.</a>
<a href="#22" id="22">A norm-based multi-agent environment program is a tuple {a mathematical formula}(F0,(Act1, … Actk),Aspec,N), where</a>
<a href="#23" id="23">{a mathematical formula}F0 ⊆ Π ,</a>
<a href="#24" id="24">{a mathematical formula}Acti and {a mathematical formula}Aspec are as introduced in Definition 15, and</a>
<a href="#25" id="25">{a mathematical formula}N is a set of (sanctioning and regimenting) norms as introduced in Definition 9.</a>
<a href="#26" id="26">{a mathematical formula}Agt, Π , Π ,Act,d are specified as in Definition 18,</a>
<a href="#27" id="27">A model updated by sanctioning norms can yield states of type {a mathematical formula}(q,S).</a>
<a href="#28" id="28">1.</a>
<a href="#29" id="29">{a mathematical formula} Π 1(q)= Π 2(f(q)) for all {a mathematical formula}q ∈ Q1.</a>
<a href="#30" id="30">We construct a preference profile {a mathematical formula} Γ → =( Γ v, Γ r) such that a winning strategy of the verifier in {a mathematical formula}M Φ is part of a Nash equilibria in {a mathematical formula} Γ (M Φ ,q,( Γ v, Γ r)) if, and only if, Φ is satisfiable.</a>
<a href="#31" id="31">We refer to the CGS just constructed as {a mathematical formula}M Φ .</a>
<a href="#32" id="32">{a mathematical formula}Agt={v,r},</a>
<a href="#33" id="33">Nash equilibria in {a mathematical formula}M Φ Let Φ be a QSAT2-formula in nnf and{a mathematical formula}( Γ v, Γ r)be the preference profile defined above.</a>
<a href="#34" id="34">We have that{a mathematical formula}(sd,sd ′ ) ∈ NE(M Φ ,q0,( Γ v, Γ r))for any two strategies{a mathematical formula}sdand{a mathematical formula}sd ′ with{a mathematical formula}sd(q0)=sd ′ (q0)= ⊤ .</a>
<a href="#35" id="35">Φ is satisfiable iff there is an{a mathematical formula}s ∈ NE(M Φ ,q0,( Γ v, Γ r))with{a mathematical formula}outM Φ (q0,s) ⊨ LTL ◇ winv.</a>
<a href="#36" id="36">We have that{a mathematical formula}(sd,sd ′ ) ∈ NE(M ˆ Φ ,q0,( Γ ˆ v, Γ ˆ r))for any strategies{a mathematical formula}sdand{a mathematical formula}sd ′ with{a mathematical formula}sd(q0)=sd ′ (q0)= ⊤ .</a>
</body>
</html>