<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:535">
</head>
<body bgcolor="white">
<a href="#0" id="0">In that respect, a plan computed offline represents a traversal between sets of states rather than complete descriptions of states, and has only the potential to achieve the goal, if there is some state sequence that could arise from the plan's execution and satisfies the goal.</a>
<a href="#1" id="1">{a mathematical formula}subgoal0under_condition{a mathematical formula}goal1 is satisfied if {a mathematical formula}subgoal0 is satisfied for the first time at some state s (see Definition 7) and {a mathematical formula}goali is satisfied in the state sequence preceding s. under_condition thus imposes a before-then relation between goals over the state traversal, and is particularly useful in cases where the user would like to go ahead with altering a variable, only if its sensed value satisfies a property beforehand.</a>
<a href="#2" id="2">We extend the function {a mathematical formula} Γ ˆ to capture the set of states that are brought forth by applying the actions in Π , starting from {a mathematical formula}S0[inPars0], where {a mathematical formula}S0[inPars0] is {a mathematical formula}S0 with the domains of input parameters updated according to {a mathematical formula}inPars0.</a>
<a href="#3" id="3">This implies that, setting aside uncertainty stemming from sensing effects, a plan has the potential to solve the planning problem if the goal is satisfied for all possible assignments to variables allowed by {a mathematical formula}prop_init.</a>
<a href="#4" id="4">After the phase of the parallel execution of some actions at step i completes, the solver is passed a full assignment to variables and parameters, which is the same as the assignment corresponding to the current plan, except that variables at state {a mathematical formula}i+1 are assigned the values delivered by the current environmental state.</a>
<a href="#5" id="5">If this process fails to find a valid solution within some limited time, then the instantiations to the action variables are removed, the search retracts to the generic model instance, and a new solution is sought with a partial assignment reflecting only the initial state.</a>
<a href="#6" id="6">Thus, considering the invocation of the parallel actions {a mathematical formula}Ai at state i, and some actions {a mathematical formula}Ap ⊆ Ai which do not respond within the short time limit, the new initial state is formed by assigning all variables that participate in the effects of {a mathematical formula}Ap to the values they have at the solver state {a mathematical formula}i+1.</a>
<a href="#7" id="7">3 shows plan computation time with respect to an increasing number of variables with domain range {a mathematical formula}[1,100], which all have to be sensed to fulfill the goal.</a>
<a href="#8" id="8">Because the notion of state for the RuGPlanner encloses a set of fully instantiated states, the number of possible initial (instantiated) states of knowledge variables and their domain size affects planning time only with respect to the number of sensing actions which have to be included in the plan, their interdependencies, and entailed constraints.</a>
<a href="#9" id="9">All plans consist of the same number of actions, however the state at which actions are placed varies: “ opt ” refers to the optimal situation where all the password sensing actions in the plan are concentrated at the first state, “ subOpt ” to the plan actually generated by the RuGPlanner by employing the random values assignment with restarts searching strategy, and “ worst ” to a plan where each password sensing action is scheduled just before the respective door opening.</a>
</body>
</html>