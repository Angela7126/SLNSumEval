<html>
<head>
<meta name="TextLength" content="SENT_NUM:25, WORD_NUM:1241">
</head>
<body bgcolor="white">
<a href="#0" id="0">Overall, the results of the competition indicate significant progress with respect to previous competitions, but they also reveal that some issues remain open and need further research, such as the coverage of temporal planners when concurrency is required and the performance in the multi-core track.</a>
<a href="#1" id="1">This fact, in conjunction with the public availability of the source code for the Fast Downward planning system,{sup:2} made the deterministic part of IPC-2011 extremely popular with a record number of entrants.</a>
<a href="#2" id="2">From a practical point of view, although faster identification of solutions is a primary concern in some real-world applications, finding good solutions is also relevant, especially if the cost of the plans is directly related to important features such as time or economic costs so that large time horizons are allowed for planning.</a>
<a href="#3" id="3">Similarly, the case of automated planning is complex because the branching factor and the depth of the planning problems are not easily bounded with the number of state variables.</a>
<a href="#4" id="4">Apart from the quality of the solutions, typical parameters used to compare planner performance in previous IPCs include the number of instances solved (or, alternatively, the overall problem solving success rate, defined as the percentage of problems solved{sup:7}), and the raw speed at which solutions were generated.</a>
<a href="#5" id="5">As well as figures showing results for coverage, quality, raw speed, memory usage, and the percentage of invalid plans, the analysis involved a number of statistical tests.</a>
<a href="#6" id="6">Although this is not the case when comparing the number of instances solved (since each planning instance is assigned a value per planner: it is either solved or not) or memory usage (even if a planner does not succeed in solving a problem, memory consumption can still be monitored), this situation arises when observing quality and raw speed, since one planner might not solve a particular planning instance whereas the other does.</a>
<a href="#7" id="7">In the third IPC, double hits were used in addition to ordinary analysis when studying plan quality; when observing runtime, the organizers assigned an infinitely bad speed to the planner that did not solve a particular case [37].</a>
<a href="#8" id="8">The organizers of the fifth IPC adopted a different, but similar, methodology: when comparing runtime they assigned twice the time limit to cases for which no solution was generated, observing that this was the minimum value for which the performance gap for a problem solved by one planner and not solved by the other is greater than the performance gap for any problem solved by both.</a>
<a href="#9" id="9">The reason is that in preliminary analysis conducted over all pairs of problems (and assigning infinitely bad quality to cases that were unsolved), we observed a significant influence of coverage, which dramatically favored participants that solved more problems.</a>
<a href="#10" id="10">In fact, when comparing the number of problems simultaneously solved by two planners in the same group, it was found that either the difference is too small to be significant (e.g., fdss-1 solves the same problems as fdss-2 and only three additional ones) or is slightly larger but the intersection is rather low (e.g., gamer and forkinit solve 148 and 158 problems, respectively, of which 119 are solved by both).</a>
<a href="#11" id="11">3 shows the evolution of the number of problems solved by all entrants in the time interval {a mathematical formula}(0,1800]s. Although selmax performs worse than a number of planners at the start, it performs as well as merge-and-shrink at the end of the interval and moderately better than lmcut and fd-autotune.</a>
<a href="#12" id="12">From the preceding figure, another diagnosis can easily be inferred: merge-and-shrink performs a number of shrinking operations, the most prominent one at {a mathematical formula}t=370.59s, at which the memory decreased from 5277.31 MB to 91.70 MB in just 5 s. fdss-1 shows the typical memory profile of a portfolio whereby memory is used and released as the solvers implemented in it are successively invoked.</a>
<a href="#13" id="13">In this section, we first show how the number of problems solved evolved over time in the range {a mathematical formula}(0,1800]s. Owing to the large number of participants in this track, Fig.</a>
<a href="#14" id="14">Since the evaluation schema of the competition emphasized quality by fixing the allotted time to 30 min, many planners followed one of two strategies: (i) most of them implemented anytime approaches that try to find a solution quickly and then refine it during the remaining time; and (ii) a few implemented portfolios or collections of different solvers that were invoked successively.</a>
<a href="#15" id="15">On the other hand, in spite of its differences in coverage from popf2, both planners solve rather different sets of problems: dae_yahsp, yahsp2-mt, and yahsp2 are epoch-based planners, which gives them a remarkable advantage when solving simple temporal domains, but they are incomplete, as witnessed by their poor performance in concurrent domains, for which they solved no problem at all.</a>
<a href="#16" id="16">The raw speed performance of the planners falls into four different categories: (i) yahsp2-mt dominates all the other entries; (ii) yahsp2 dominates dae_yahsp and popf2 most of the time, except at the end, where dae_yahsp solves one fewer problem than yahsp2 does; (iii) cpt4 and lmtd perform similarly and are dominated throughout the interval by the previously mentioned planners; and (iv) sharaabi and tlp-gp are included only for the sake of completeness, but their curve is hidden because they did not solve any problem.</a>
<a href="#17" id="17">According to the analysis in this section, overall, the optimal planner that won IPC-2011 improved on the performance of the optimal planner that won IPC-2008 with regard to the problems chosen for IPC-2011 in terms of both coverage and raw speed.</a>
<a href="#18" id="18">Again, this result suggests a significant improvement in the current state of the art, in optimal planning at least, with regard to the benchmarking set chosen in both IPC-2008 and IPC-2011.</a>
<a href="#19" id="19">The analysis in this section shows that, overall, the temporal planner that won IPC-2011 improves on the performance of the temporal planner that won IPC-2008 for the problems chosen for IPC-2011 in terms of quality, but not necessarily coverage, and that it performs worse in terms of raw speed.</a>
<a href="#20" id="20">The official scoring schema is not linear and tends to favor planners that effectively solve instances with low optimal cost, provided that other planners deviate from it, even if only slightly [44].</a>
<a href="#21" id="21">To prove this, observe that the score for planner p when using the best solution found as a reference for a specific planning task i is{a mathematical formula} where {a mathematical formula} Î” ip is the excess committed by planner p over the best solution found (and necessarily equal to zero for at least one planner) when solving instance i.</a>
<a href="#22" id="22">Although all planners see their score affected by the same constant, this value can be different for different planning tasks and can induce a final ranking that differs from the theoretical one.For clarity, assume that two planners, a and b, solve two different tasks.</a>
<a href="#23" id="23">An unwanted effect of not using optimal solutions as a reference baseline is that the final score is not properly scaled over the optimal performance, but instead over the best performance observed.In the preceding example, the scores {a mathematical formula}sa=1.909 and {a mathematical formula}sb=1.8333 are too close to the maximum achievable score of 2, which suggests that both planners perform very well but we can only say that they perform similarly.</a>
<a href="#24" id="24">This was the official metric for evaluating time performance in the learning track in IPC-2008.This metric makes an explicit effort to address Observation I by taking a logarithm of the ratio that represents the speed of each planner in relation to the fastest one.</a>
</body>
</html>