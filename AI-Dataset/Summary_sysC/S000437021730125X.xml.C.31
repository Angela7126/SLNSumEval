<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:232">
</head>
<body bgcolor="white">
<a href="#0" id="0">Since the algorithm selects a set which satisfies the constraint for each task with high probability, we can bound the overall regret by bounding the number of rounds in which the algorithm selects a sub-optimal set {a mathematical formula}St i.e.</a>
<a href="#1" id="1">{a mathematical formula}C(St)>C(S ⁎ ).</a>
<a href="#2" id="2">If {a mathematical formula}C(St)=C(S ⁎ ), then we get zero regret for those rounds with probability {a mathematical formula}(1 − Μ ).</a>
<a href="#3" id="3">We will show that the number of non-optimal rounds depends on the value of Δ where {a mathematical formula} Δ =infS ⊆ N ⁡ |fS(q) − Α |.</a>
<a href="#4" id="4">The value of Δ is typically unknown to the requester since qualities are unknown but our algorithm does not require the value of Δ beforehand and thus, CCB-NS is adaptive in nature.</a>
<a href="#5" id="5">The proposed algorithm is adaptive exploration separated and the number of suboptimal rounds for CCB-S is bounded by {a mathematical formula}2(h − 1( Δ ))2ln ⁡ (2n Μ ).</a>
<a href="#6" id="6">In Lemma 5.2, we prove that after {a mathematical formula}l=2(h − 1( Δ ))2ln ⁡ (2n Μ ) steps, there is no set S which satisfies the constraint with respect to upper confidence bound and its cost is less then the optimal cost.</a>
<a href="#7" id="7">Moreover, after {a mathematical formula}l=2(h − 1( Δ ))2ln ⁡ (2n Μ ) steps, we have {a mathematical formula}fS ⁎ (q ˆ − )< Α with probability {a mathematical formula}1 − Μ .</a>
</body>
</html>