<html>
<head>
<meta name="TextLength" content="SENT_NUM:36, WORD_NUM:785">
</head>
<body bgcolor="white">
<a href="#0" id="0">To create a plan to find the magazine, Dora must reason about two entities that do not yet exist in its relational map: the magazine and the room that object is in.</a>
<a href="#1" id="1">This incompleteness in knowledge requires open-world planning — that is, planning that takes into account the fact that new entities may become known to the robot during plan execution.</a>
<a href="#2" id="2">Given the initial relational map, the planner hypothesizes extensions to it.</a>
<a href="#3" id="3">To create these extensions, the planner has assumptive actions it can take, each making one or more assumptions about instance knowledge.</a>
<a href="#4" id="4">The planner selects a sequence of assumptive actions that are likely to be true according to default knowledge, and which enable goal achievement.</a>
<a href="#5" id="5">The planner does not make task-irrelevant assumptions.</a>
<a href="#6" id="6">In Fig.</a>
<a href="#7" id="7">1 (blue panel), five assumptions have been made in this way: (i) a meeting room exists; (ii) there is a route from a place-holder to the hypothesized meeting room; (iii) this meeting room contains objects of type magazine; (iv) a particular instance of type magazine exists; and (v) it exists in this instance of a meeting room.</a>
<a href="#8" id="8">The remainder of the plan (Fig.</a>
<a href="#9" id="9">3) is to move to the hypothesized meeting room and to plan to conduct a visual search for the object when the robot gets there.</a>
<a href="#10" id="10">The task-driven selection of assumptions is the key step in dealing efficiently with incomplete information, and we describe our approach to it in detail in Section 4.</a>
<a href="#11" id="11">Whenever a task failure is declared, Dora raises a new goal to explain it.</a>
<a href="#12" id="12">The sequence of plans gave a sequence of expected observations (the robot should see the magazine in the meeting room, or failing that in the office).</a>
<a href="#13" id="13">In the case of task failure, these observations did not occur, so there was a mismatch between expectation and experience.</a>
<a href="#14" id="14">We refer to the difference between the two as the set of surprises.</a>
<a href="#15" id="15">The aim is to explain the surprises that caused the task failure.</a>
<a href="#16" id="16">This problem is closely related to explanation-based learning, where explanations are generated by planning with a domain theory [30].</a>
<a href="#17" id="17">We pose it as the problem of finding an additional set of assumptions that change the expected outcomes to make them consistent with the actual observations.</a>
<a href="#18" id="18">Diagnostic knowledge is used to enable these new assumptions to be made.</a>
<a href="#19" id="19">There are two types of diagnostic knowledge.</a>
<a href="#20" id="20">The first type extends the action models from the default layer with knowledge of how those actions might fail.</a>
<a href="#21" id="21">These failure modes are represented with use of what are termed conditional effects in the planning community.</a>
<a href="#22" id="22">The resulting, more complex action models would make normal planning more time-consuming, and so are used only when unexpected failures occur.</a>
<a href="#23" id="23">The second type of diagnostic knowledge is a new set of assumptive actions that can hypothesize new pieces of default knowledge.</a>
<a href="#24" id="24">Using these two new kinds of actions, Dora tries to find a modified version of the plan that consists of the original plan, preceded by a new sequence of additional assumptions.</a>
<a href="#25" id="25">Addition of these assumptions in front of the old plan results in the previously surprising outcomes becoming expected outcomes.</a>
<a href="#26" id="26">In this run the explanation is as follows:</a>
<a href="#27" id="27">Assumptive actions allow us to model probabilistic instance states — for example, in the relational map.</a>
<a href="#28" id="28">If a variable v has a discrete value distribution with {a mathematical formula}Pr ⁡ (v=x0)=p0, … ,Pr ⁡ (v=xn)=pn, we can create a set of assumptions {a mathematical formula}a0, … ,an that represent this distribution by setting the effect {a mathematical formula}eff(ai)={A(v,xi)} and the assumption's probability {a mathematical formula} Ρ (ai)=pi.</a>
<a href="#29" id="29">{a mathematical formula} Π 0 is a solution to the original planning task Π ; that is, a plan that reaches g from the initial state {a mathematical formula}s0.</a>
<a href="#30" id="30">{a mathematical formula} Π i is a solution to the modified planning task {a mathematical formula} Π i= 〈 V,A,si,g 〉 ; that is, a plan that reaches g from the previous observed state {a mathematical formula}si.</a>
<a href="#31" id="31">The expected state after plan {a mathematical formula} Π i is denoted {a mathematical formula}si+1 ′ =app(si, Π ia, Π ie) and is the result of the application of {a mathematical formula} Π i's assumptions and executed actions from its initial state.</a>
<a href="#32" id="32">So, in our example, after searching the meeting room, the robot expects to know where the magazine is.</a>
<a href="#33" id="33">We use the following shorthand for the plan's actions: {a mathematical formula}ai,j for the jth assumption of {a mathematical formula} Π ia, {a mathematical formula}ei,j for the jth executed action in {a mathematical formula} Π ie, and {a mathematical formula}ui,j for the jth unexecuted action in {a mathematical formula} Π iu.</a>
<a href="#34" id="34">See Fig.</a>
<a href="#35" id="35">9 for an illustration of a sequence of three plans that uses this notation.</a>
</body>
</html>