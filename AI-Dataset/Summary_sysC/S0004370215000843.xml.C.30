<html>
<head>
<meta name="TextLength" content="SENT_NUM:31, WORD_NUM:820">
</head>
<body bgcolor="white">
<a href="#0" id="0">In order to robustly perform tasks based on abstract instructions, robots need sophisticated knowledge processing methods.</a>
<a href="#1" id="1">These methods have to supply the difference between the (often shallow and symbolic) information in the instructions and the (detailed, grounded and often real-valued) information needed for execution.</a>
<a href="#2" id="2">For filling these information gaps, a robot first has to identify them in the instructions, reason about suitable information sources, and combine pieces of information from different sources and of different structure into a coherent knowledge base.</a>
<a href="#3" id="3">To this end we propose the KnowRob knowledge processing system for robots.</a>
<a href="#4" id="4">In this article, we discuss why the requirements of a robot knowledge processing system differ from what is commonly investigated in AI research, and propose to re-consider a KR system as a semantically annotated view on information and algorithms that are often already available as part of the robot's control system.</a>
<a href="#5" id="5">We then introduce representational structures and a common vocabulary for representing knowledge about robot actions, events, objects, environments, and the robot's hardware as well as inference procedures that operate on this common representation.</a>
<a href="#6" id="6">The following section explains the representations of objects, their parts, properties, and locations in the environment as well as the robot's self-model.</a>
<a href="#7" id="7">It is followed by the representations of events and actions at the instance and class level and methods for projecting the effects of actions on objects.</a>
<a href="#8" id="8">Our knowledge base only has a rather shallow symbolic representation of general concepts, while most information about the robot, its environment and perceptions is merely a “ virtual knowledge base ” computed at runtime from the data structures of the robot's control program.</a>
<a href="#9" id="9">For example, a robot may ask if its gripper has been inside a container during a pick-up task in order to verify that a pick-up action has been attempted.</a>
<a href="#10" id="10">Such a query requires temporal reasoning about events during the pick-up action, ontological reasoning to determine which objects are containers and three-dimensional spatial reasoning to determine the “ inside ” relation.</a>
<a href="#11" id="11">These reasoners need access to the robot's task logs, to proprioceptive information about the gripper movements, to the environment model and to general knowledge about types of objects.</a>
<a href="#12" id="12">We therefore decided to use a common underlying representation for all these kinds of information and to have an ensemble of expert reasoners operate on this shared knowledge.</a>
<a href="#13" id="13">This section introduces the representations and associated inference methods for objects and other spatial information.</a>
<a href="#14" id="14">We start with class-level knowledge about objects types, continue with object instances, the representation of positions and orientations, the computation of qualitative spatial relations, and the representation of the object geometry and their composition from parts.</a>
<a href="#15" id="15">The last subsection deals with special kinds of objects, namely parts of the robot and their properties.</a>
<a href="#16" id="16">Since there is no structural difference between static objects in an environment map, movable objects detected by the robot's perception system, and parts of the robot, any kind of object information in the system can easily be compared.</a>
<a href="#17" id="17">On top of the component model, SRDL describes abstract capabilities such as “ navigation ” or “ object recognition ” and their dependencies on components.</a>
<a href="#18" id="18">At the highest level, actions can define dependencies on components (e.g.</a>
<a href="#19" id="19">a camera with certain properties) and capabilities (e.g.</a>
<a href="#20" id="20">recognition of textured objects).</a>
<a href="#21" id="21">These dependencies can automatically be checked against a robot model to infer about whether all components required for the action are available.</a>
<a href="#22" id="22">In addition, the component model can also be used for other kinds of reasoning, for example to compute which camera can see an object based on its pose and field of view [54].</a>
<a href="#23" id="23">For formulating queries to this system and for integrating the results with the existing knowledge base, it is important to have all information in the same language.</a>
<a href="#24" id="24">The representation language used in RoboEarth [45] is a subset of the representations described in this paper, so information described in that language can simply be loaded into KnowRob.</a>
<a href="#25" id="25">To ground the abstract object descriptions in an instruction into actual objects in the environment, the robot needs to add actions for searching for these objects and for retrieving them from their storage locations.</a>
<a href="#26" id="26">If the objects' locations are known, they can simply be looked up in the environment map (Section 4.2), but often this is not the case.</a>
<a href="#27" id="27">Then, the system has to reason about likely locations given the available knowledge about the locations of other objects and their properties.</a>
<a href="#28" id="28">This can for example be done using generic rules for storage locations [3] or based on a semantic similarity to other objects in the environment as explained in Section 4.1.</a>
<a href="#29" id="29">To further promote the use of knowledge representation and reasoning methods for robotics applications, we have created a web-based version of the KnowRob system called Open-EASE.</a>
<a href="#30" id="30">Its core is formed by the same KnowRob knowledge base that also runs on the robot, but users (or robots) can access and query the knowledge base over the Internet using a WebSocket interface.</a>
</body>
</html>