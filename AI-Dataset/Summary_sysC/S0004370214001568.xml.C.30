<html>
<head>
<meta name="TextLength" content="SENT_NUM:24, WORD_NUM:511">
</head>
<body bgcolor="white">
<a href="#0" id="0">AI researchers soon recognized that to solve the “ kinds of problems now reserved for humans ” would require a substantive knowledge base and a host of ways to use it [16].</a>
<a href="#1" id="1">In summary, people have skills that AI research has not yet reproduced in machines.</a>
<a href="#2" id="2">As envisioned here, a collaborative intelligence (CI) partners with a person to achieve the person's goals.</a>
<a href="#3" id="3">The assumption is that some subtasks are more reasonably delegated to the person, and others to the computer.</a>
<a href="#4" id="4">A CI is intended not to substitute for a human employee, but to engage in a task with one.</a>
<a href="#5" id="5">To collaborate effectively with a person, a CI must be able to model the human view of the world.</a>
<a href="#6" id="6">At the very least, a CI should be aware of such human perceptions, particularly when they differ from those of the machine.</a>
<a href="#7" id="7">A CI must engage in dialogue with its human partner.</a>
<a href="#8" id="8">As an ongoing example, consider a kitchen CI that is asked, “ How do you make soup? ” A CI with extensive knowledge must filter its possible responses, because its help will only be valued if it is neither too simplistic (e.g., “ Just open a can and heat the contents. ” ) nor too detailed (e.g., “ … the history of soup is probably as old as the history of cooking … ” {sup:6}).</a>
<a href="#9" id="9">A CI that elicits its user's goals can ask how they should be prioritized, so that it can model both the user's knowledge and the user's expectations.</a>
<a href="#10" id="10">Our kitchen CI, for example, could ask whether the soup ingredients are to be purchased or limited to those on hand.</a>
<a href="#11" id="11">Nonetheless, the construction of a CI must contend with the fundamental differences in the way that any machine and any person function.</a>
<a href="#12" id="12">As envisioned here, a CI is not a general intelligence.</a>
<a href="#13" id="13">Each CI would target problem areas in which it could assist people, and provide representations and procedures to support particular human activities.</a>
<a href="#14" id="14">Many of the key issues for a CI, however, have already received preliminary research attention.</a>
<a href="#15" id="15">2.</a>
<a href="#16" id="16">Line 1 is an alert to the system by the human H; line 2 is a response from the collaborative intelligence CI.</a>
<a href="#17" id="17">If the CI notes that some value is perfectly consistent over an extended period (e.g., H always eats at Jimmy's) it may ask the person whether it may safely make that assumption.</a>
<a href="#18" id="18">Such a CI is intended to support people who lack the time, resources, or inclination to consult a medical professional.</a>
<a href="#19" id="19">Note that the CI would not make decisions for the person.</a>
<a href="#20" id="20">This CI would work at multiple levels of granularity.</a>
<a href="#21" id="21">First, it would identify the person's priorities among what are likely to be multiple goals (e.g., conflicts, convenience, budget).</a>
<a href="#22" id="22">The CI would also have data on similar past meetings, including those arranged by the current user and by other users with their own CIs.</a>
<a href="#23" id="23">The dialogue required of a CI, however, is not a full-blown system that purports to “ understand. ” To serve, a CI need only respond appropriately and ask constructive questions.</a>
</body>
</html>