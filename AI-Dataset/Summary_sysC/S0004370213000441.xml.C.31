<html>
<head>
<meta name="TextLength" content="SENT_NUM:41, WORD_NUM:927">
</head>
<body bgcolor="white">
<a href="#0" id="0">Fig.</a>
<a href="#1" id="1">6a shows that a {a mathematical formula}ToM1 agent that has a learning speed {a mathematical formula} Λ i=0 cannot compete with his opponent.</a>
<a href="#2" id="2">When the agent does not learn from his opponent ʼ s behaviour, he loses nearly all rounds.</a>
<a href="#3" id="3">Similarly, his opponent loses nearly all rounds when she does not learn at all ({a mathematical formula} Λ j=0).</a>
<a href="#4" id="4">This shows that both zero-order theory of mind agents and first-order theory of mind agents can successfully model an opponent that always performs the same action.</a>
<a href="#5" id="5">Although the {a mathematical formula}ToM3 agent can still outperform a {a mathematical formula}ToM2 opponent at a small margin, Fig.</a>
<a href="#6" id="6">6d shows that a {a mathematical formula}ToM4 agent no longer outperforms a {a mathematical formula}ToM3 opponent in RPS.</a>
<a href="#7" id="7">In this scenario, the outcome of the game is mostly dependent on which of the agents has the highest learning speed, and no longer on theory of mind abilities.</a>
<a href="#8" id="8">In Fig.</a>
<a href="#9" id="9">6d, this can be seen by the fact that the {a mathematical formula}ToM4 agent obtains a positive outcome on average only if his learning speed {a mathematical formula} Λ i is higher than the learning speed {a mathematical formula} Λ j of his opponent.</a>
<a href="#10" id="10">In summary, the ability to make use of theory of mind can benefit an agent in the game of RPS.</a>
<a href="#11" id="11">As we hypothesized (cf.</a>
<a href="#12" id="12">hypothesis {a mathematical formula}HRPS, Section 2.4), both the {a mathematical formula}ToM1 agent and the {a mathematical formula}ToM2 agent outperform opponents of a lower order of theory of mind.</a>
<a href="#13" id="13">The performance of the {a mathematical formula}ToM3 agent and the {a mathematical formula}ToM4 agent suggests that there may be a limit to the effectiveness of application of higher orders of theory of mind.</a>
<a href="#14" id="14">However, since rock – paper – scissors involves three possible opponent actions, the game leaves room for only three unique predictions of the opponent ʼ s next action.</a>
<a href="#15" id="15">The low performance of the {a mathematical formula}ToM3 and {a mathematical formula}ToM4 agents may therefore be caused by specific characteristics of the RPS game, rather than a limit to the effectiveness of application of higher orders of theory of mind.</a>
<a href="#16" id="16">The next section describes a game with more than three actions in order to differentiate between these alternative explanations.</a>
<a href="#17" id="17">The results for ERPS are shown in Fig.</a>
<a href="#18" id="18">7.</a>
<a href="#19" id="19">Our expectation that performance of theory of mind agents in playing ERPS would be at least as good as performance in RPS is only partially correct.</a>
<a href="#20" id="20">Similar to our results of theory of mind agents playing RPS, Fig.</a>
<a href="#21" id="21">7a shows that a {a mathematical formula}ToM1 agent outperforms a {a mathematical formula}ToM0 opponent, while Fig.</a>
<a href="#22" id="22">7b shows that a {a mathematical formula}ToM2 agent outperforms a {a mathematical formula}ToM1 opponent as well.</a>
<a href="#23" id="23">However, performance in the game of ERPS is slightly reduced compared to the situation in which they were playing RPS.</a>
<a href="#24" id="24">Especially when either the agent or his opponent learns at a low speed, it is more difficult for a theory of mind agent to model his opponent in a game of ERPS than it is in RPS.</a>
<a href="#25" id="25">Since the richer action space of ERPS increases performance of the {a mathematical formula}ToM3 agent when playing against an opponent that does not learn, the structure of the game influences the effectiveness of theory of mind.</a>
<a href="#26" id="26">However, performance of a {a mathematical formula}ToM3 agent playing ERPS against a {a mathematical formula}ToM2 opponent is still poor in comparison to performance of the {a mathematical formula}ToM1 and {a mathematical formula}ToM2 agents playing ERPS against opponents of a lower order of theory of mind.</a>
<a href="#27" id="27">Fig.</a>
<a href="#28" id="28">7d shows the performance of a {a mathematical formula}ToM4 agent playing ERPS against a {a mathematical formula}ToM3 opponent.</a>
<a href="#29" id="29">Like the {a mathematical formula}ToM3 agent, the peak performance of the {a mathematical formula}ToM4 agent when playing against an opponent with learning speed {a mathematical formula} Λ j=0 shown in the figure indicates that the {a mathematical formula}ToM4 agent has no difficulty distinguishing agents that have learning speed zero from agents of a lower order of theory of mind.</a>
<a href="#30" id="30">However, the ability to make use of fourth-order theory of mind does not present an agent with advantages in ERPS beyond those of third-order theory of mind.</a>
<a href="#31" id="31">Fig.</a>
<a href="#32" id="32">7d shows that a {a mathematical formula}ToM4 agent that plays ERPS against a {a mathematical formula}ToM3 opponent only obtains a positive score on average if his learning speed {a mathematical formula} Λ i is higher than the learning speed {a mathematical formula} Λ j of his opponent.</a>
<a href="#33" id="33">That is, when a {a mathematical formula}ToM4 agent plays ERPS against a {a mathematical formula}ToM3 opponent, whoever has the highest learning speed is expected to win.</a>
<a href="#34" id="34">Fig.</a>
<a href="#35" id="35">8b shows the performance of a {a mathematical formula}ToM2 agent when playing RPSLS against a {a mathematical formula}ToM1 opponent.</a>
<a href="#36" id="36">Similar to the {a mathematical formula}ToM1 agent, performance of the {a mathematical formula}ToM2 agent is low when playing RPSLS against an opponent that learns at maximum speed, {a mathematical formula} Λ o=1.</a>
<a href="#37" id="37">The {a mathematical formula}ToM2 agent also has particular difficulties modeling a {a mathematical formula}ToM1 opponent in RPSLS when his own learning speed {a mathematical formula} Λ i is low.</a>
<a href="#38" id="38">In this case, the {a mathematical formula}ToM2 agent is outperformed by an opponent of lower order of theory of mind.</a>
<a href="#39" id="39">However, the {a mathematical formula}ToM2 agent will on average win when his learning speed {a mathematical formula} Λ i is over 0.7.</a>
<a href="#40" id="40">The relation between the performance of a theory of mind agent and the predictability of his opponent ʼ s behaviour is also reflected in the results of the rock – paper – scissors – lizard – Spock game.</a>
</body>
</html>