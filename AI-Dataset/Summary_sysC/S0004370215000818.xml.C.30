<html>
<head>
<meta name="TextLength" content="SENT_NUM:1, WORD_NUM:129">
</head>
<body bgcolor="white">
<a href="#0" id="0">This leads to the following approximation of the constrained log likelihood, that also factorizes according to the examples i:{a mathematical formula} Here, {a mathematical formula}Pr Θ , Λ denotes the distribution of the base network, which is now determined by two sets of parameters: (1) the parameter estimates Θ of the Bayesian network that we seek to learn, and (2) the parameters Λ of the soft observations {a mathematical formula}vi that are used to compensate for the relaxed equivalence constraints {a mathematical formula}C. Note that we use two sets of compensations {a mathematical formula} Λ 1 and {a mathematical formula} Λ 2, to approximate {a mathematical formula}P(D,C| Θ ) (with the dataset observed in the meta-network) and {a mathematical formula}P(C| Θ ) (with the dataset unobserved in the meta-network).</a>
</body>
</html>