<html>
<head>
<meta name="TextLength" content="SENT_NUM:30, WORD_NUM:1007">
</head>
<body bgcolor="white">
<a href="#0" id="0">In our approach, as in [36], [37], we introduce this type of information through the use of agent identifiers that represent the information sources, avoiding in that way the need of a separate data structure to maintain the measure of reliability.</a>
<a href="#1" id="1">This leads to a recursive setting in which the reliability of certain credibility information depends on the credibility of other pieces of information that should be subject to the same analysis.</a>
<a href="#2" id="2">In this paper, we will propose how to equip agents with a mechanism that will allow them to coherently infer information from their credibility base despite possible inconsistencies.</a>
<a href="#3" id="3">Therefore, the main contribution of our proposal is to define an argumentation formalism which will provide the capability to coherently infer strict partial orders from such bases.</a>
<a href="#4" id="4">An argument in this formalism will provide a reason to support the fact that an informant is more credible than other.</a>
<a href="#5" id="5">As arguments can be challenged, we will introduce different types of attacks.</a>
<a href="#6" id="6">We will use acceptability semantics (in particular preferred extensions) to determine which are the accepted arguments in our system, and then, we will formally show that the conclusions of an extension from a credibility base constitute a partial order with respect to the credibility relation.</a>
<a href="#7" id="7">For convenience, given a credibility base {a mathematical formula}C we will denote with {a mathematical formula}TAttsC the set of trust-attacks from {a mathematical formula}C, with {a mathematical formula}RAttsC the set of reliability-attacks from {a mathematical formula}C, and with {a mathematical formula}IAttsC the set of indirect-reliability-attacks from {a mathematical formula}C. Below we will explain the intuitions that motivate each type of attack and present their definitions.</a>
<a href="#8" id="8">The new credibility object represents that the newsletter Y-invest (abbreviated Y) has informed that agent J is more credible than H. Note that from {a mathematical formula}C5 we have the same arguments and attacks shown in Example 4 and, in addition, the argument {a mathematical formula}A5={[J>H,Y]} can be built.</a>
<a href="#9" id="9">4 that the reliability-attack Γ challenges the trust-attack Β and, simultaneously, the reliability-attack Δ challenges the trust-attack Α .</a>
<a href="#10" id="10">Therefore, considering Δ and Γ it could be seen that Γ is representing a preference of {a mathematical formula}A2 over {a mathematical formula}A3, meanwhile Δ represents the contrary, and thus this means an implicit conflict between reliability-attacks such as Δ and Γ exists.</a>
<a href="#11" id="11">Also note that, if we suppose that the reliability-attacks Δ and Γ are successful, then Α and Β will be ineffective.</a>
<a href="#12" id="12">This leads to an undesirable situation where arguments with contradictory conclusions, such as {a mathematical formula}A2 and {a mathematical formula}A3, could hold together.</a>
<a href="#13" id="13">To capture a conflict as the one between Δ and Γ discussed above, we will introduce indirect-reliability-attacks which originate from an argument and target a reliability-attack.</a>
<a href="#14" id="14">The argument producing the indirect-reliability-attack will be the same that produces the reliability-attack which is in conflict with the reliability-attack that is the target of the indirect-reliability-attack.</a>
<a href="#15" id="15">As we did for the basic reliability-attack, we will present the basic indirect-reliability-attacks that target basic reliability-attacks next.</a>
<a href="#16" id="16">Following [4], the first step towards determining the accepted arguments from an associated AFRA {a mathematical formula}(ArgsC,AttsC) is to establish the existing attacks and consequent defeats.</a>
<a href="#17" id="17">Note that, given a credibility base {a mathematical formula}C, there always exists an associated AFRA from which it is possible to obtain the extensions containing the acceptable arguments; hence, we will introduce to our framework the notion of extension of a credibility base that considers preferred extensions which satisfy a particular constraint.</a>
<a href="#18" id="18">As we mentioned in the introduction of this article, one of the main goals of our system was to determine from a potentially conflicting credibility base a strict partial order representing the credibilities that can be coherently justified.</a>
<a href="#19" id="19">As reported in [36], a set of justified credibilities from a credibility base is sound if it is a strict partial order.</a>
<a href="#20" id="20">The following theorem shows that our approach is sound, i.e., every set of justified credibilities obtained from a credibility base is sound.</a>
<a href="#21" id="21">Consider finally that from the same website it can be inferred that {a mathematical formula}[A>B,X], then our proposed approach can be applied to decide between two contradictory answers given by users G and H, using more information than the rankings of these answers.</a>
<a href="#22" id="22">As we mentioned before in this article, and also in [36], [37], trust kept as a credibility order can present contradictory information, that is, from a credibility base it is possible to infer that an agent is more credible than other and vice versa.</a>
<a href="#23" id="23">There, in order to determine which information prevails when contradictory information arises, a reliability function was used to obtain a set of agent identifiers which represents the credibility of a given credibility element, and it considers all the agent identifiers involved in every minimal proof of that credibility element.</a>
<a href="#24" id="24">They follow a cautious approach: the function first obtains the set with the least credible agent identifiers from each proof, and then, if there exist more than one proof, the most credible identifiers of the resulting set.</a>
<a href="#25" id="25">Therefore, to compute the reliability of a credibility element, they use a function min and a function max.</a>
<a href="#26" id="26">Thus, based on a credibility base, they define a function such that when given a credibility element in the transitive closure of the credibility base will return a set of agent identifiers that represents the reliability of the credibility element with respect to the credibility base.</a>
<a href="#27" id="27">In our work, where credibility bases may contain information in conflict, it becomes unsound to compute reliability using the functions min and max because this can lead to potential cycles.</a>
<a href="#28" id="28">For this reason, in this article, we defined an argumentation formalism with recursive attacks which provides the capability to infer a strict partial order from a credibility base (without contradictory information).</a>
<a href="#29" id="29">These four kinds of arguments are based on an inference rule and the trust evaluation of the agent, that is represented with an interval {a mathematical formula}[t − ,t+] over a discrete scale S, with the intended meaning that the trust is not larger than t+ and not smaller than t − .</a>
</body>
</html>