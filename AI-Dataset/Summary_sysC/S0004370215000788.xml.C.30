<html>
<head>
<meta name="TextLength" content="SENT_NUM:35, WORD_NUM:941">
</head>
<body bgcolor="white">
<a href="#0" id="0">Given the models, we propose two approaches to find the optimal ordering for a new set of items: (1) a best-first search that uses the models as a black-box to evaluate different orderings of the items; and (2) a novel white-box optimization method that translates the models and the set of items into a mixed-integer program (MIP) and runs this in an ILP-solver (CPLEX).</a>
<a href="#1" id="1">In Section 2, we formally introduce the problem of optimal ordering for sequential auctions (OOSA), and then we show how to learn regression models from historical auction data in Section 3 using standard machine learning methods.</a>
<a href="#2" id="2">Based on the learned models, our white-box optimization method and a black-box optimization are introduced to find the optimal ordering for OOSA in Section 4.</a>
<a href="#3" id="3">Extensive experiments are presented in Section 5 where we compare the performance of the two proposed optimization methods using both the learned models and the auction simulator.</a>
<a href="#4" id="4">Before we conclude, we compare and discuss more related works in Section 6.</a>
<a href="#5" id="5">We assume that such an auction is repeated over time, and each auction sells possibly different items S. At the end of each auction, we have the following information at our disposal: (1) the ordering of auctioned items; and (2) the allocation of items to agents with their payments.</a>
<a href="#6" id="6">The optimization problem we study is: given a set of items and budget constrained bidders, finding an optimal ordering of items in sequential auctions such that the expected revenue is maximized.</a>
<a href="#7" id="7">At the end of each sequential auction, we have the following information at our disposal: (1) the ordering of auctioned items; and (2) the price of each sold item.</a>
<a href="#8" id="8">Before we build the optimization model to solve the OOSA problem, we need to find a suitable way to model the expected revenue of given orderings of auctioned items.</a>
<a href="#9" id="9">An ordering can be thought of as a sequence of items.</a>
<a href="#10" id="10">However, to the best of our knowledge none of the existing sequence models fit our auction setting, see also Section 6.2.</a>
<a href="#11" id="11">In this work, we view the prediction of an auction's outcome as a regression problem.</a>
<a href="#12" id="12">We split this problem into the subproblems of predicting the value of the auctioned items.</a>
<a href="#13" id="13">We then sum these up to obtain the overall objective function, i.e., the expected revenue {a mathematical formula}P(S) given a set S ({a mathematical formula}|S|=n) of items:{a mathematical formula} where {a mathematical formula}G(sk,J,L) is a regression function that determines the expected value of {a mathematical formula}sk given that J was auctioned before and L will be auctioned afterwards.</a>
<a href="#14" id="14">Given historical auction data, a regression tree (or a LASSO linear regression function) is learned for each item type.</a>
<a href="#15" id="15">The regression tree (or LASSO) can be used to evaluate the values of selling different items based on the feature values that are computed on a given ordering of the items.</a>
<a href="#16" id="16">The learned regression trees (or LASSO functions) are then used in two ways to model the optimization problem OOSA: (1) Black-box optimization.</a>
<a href="#17" id="17">In this paper, we use a best-first search heuristic to come up orderings of the items, and then use the learned regression trees (or LASSO) to compute the expected revenue of these orderings; (2) White-box optimization.</a>
<a href="#18" id="18">We formulate the optimization problem of finding an optimal ordering as a mixed integer linear program (MIP), which is shown to be automatically constructed from the learned regression tress (or LASSO functions).</a>
<a href="#19" id="19">Subsequently, we learn regression trees for both item types {a mathematical formula}r1 and {a mathematical formula}r2, as shown in Fig.</a>
<a href="#20" id="20">Our method of regression modeling allows the use of any regression method from machine learning for predicting unknown quantities in optimization, such as objective values and parameters.</a>
<a href="#21" id="21">In addition, since the regression function G uses other values in a (proposed) solution as input ({a mathematical formula}J,L) instead of only external parameters/data, a learned regression model represents unknown relations between the different values in a solution.</a>
<a href="#22" id="22">Given regression tree and linear regression models for the expected value per item type, we automatically formulate the problem of finding an optimal ordering as a mixed integer linear program (MIP).</a>
<a href="#23" id="23">We discuss the encoding of a sequential auction, feature values, objective function, and translating the learned models (regression tree and linear regression respectively) below.</a>
<a href="#24" id="24">First, the regressors are tested by comparing their predictions with the revenues generated by the simulator on 50 random orderings of each of these item sets.</a>
<a href="#25" id="25">Second, we translate each of the item sets into constraints for both the black-box and white-box optimization solvers.</a>
<a href="#26" id="26">The best ordering found by these solvers are compared based on their values on the regression model, and in the simulator.</a>
<a href="#27" id="27">Model evaluation: we use the learned regression models to evaluate the solutions returned by the ordering methods to compute the predicted revenues.</a>
<a href="#28" id="28">We observe that all white-box LP methods are better than the black-box methods, except the LP models resulting from the trees with depth 8.</a>
<a href="#29" id="29">The depth 8 regression trees perform better for best-first search when evaluated on the model (Fig.</a>
<a href="#30" id="30">6), but better for LP when evaluated in the simulator (see Fig.</a>
<a href="#31" id="31">8 shows, the results are very similar to those in the first experiments: (1) all methods outperform the naive ordering strategies from the literature, (2) the white-box outperforms the black-box methods, and (3) the linear regression models perform best.</a>
<a href="#32" id="32">10 confirm that the regression functions perform much worse in this randomized population setting.</a>
<a href="#33" id="33">The larger problem instances are generated with the same settings as those used in the main experiments, expect for: 1) 12 item types, 2) 80 items per auction, and 3) 40 agents.</a>
<a href="#34" id="34">The regression tree for every item type {a mathematical formula}ri is shown in Fig.</a>
</body>
</html>