<html>
<head>
<meta name="TextLength" content="SENT_NUM:20, WORD_NUM:348">
</head>
<body bgcolor="white">
<a href="#0" id="0">1.</a>
<a href="#1" id="1">The first artificial hierarchy we created had 80 instances, 4 levels, was a balanced tree, and did not have overlapping clusterings.</a>
<a href="#2" id="2">The ground truth hierarchy for this dataset was therefore always the same.</a>
<a href="#3" id="3">We can turn the hierarchy into a pairwise distance matrix with the distance between two points a and b being the level of their first common ancestor.</a>
<a href="#4" id="4">We increased the complexity of this dataset by increasingly adding uniform error to the distances.</a>
<a href="#5" id="5">We used this data set to evaluate our basic ILP formulation which enforced transitivity (Fig.</a>
<a href="#6" id="6">4) and compared the results with standard hierarchical clustering algorithms (single, complete, UPGMA, WPGMA).</a>
<a href="#7" id="7">The results of the first experiment we used to answer this question are shown in Fig.</a>
<a href="#8" id="8">6, and they shows our method's ability to outperform many standard agglomerative clustering algorithms for standard hierarchical clustering (no overlapping clusters) on artificial data (Artificial Dataset 1).</a>
<a href="#9" id="9">The results show that our algorithm performs better when there is increasing distance error which is expected since agglomerative algorithms are greedy and erroneous steps cannot be undone.</a>
<a href="#10" id="10">It is significant to note that even in small data sets finding the global optimum is beneficial and we expect this improvement to be larger in bigger data sets.</a>
<a href="#11" id="11">This experiment was performed by using the F1 score to measure the difference for learned and ground truth hierarchies and repeating each test 10 times for each error factor.</a>
<a href="#12" id="12">The error factor is the quantity of error added, so that the ground truth hierarchical distances had uniform error added in the range {a mathematical formula}[0,errorfactor].</a>
<a href="#13" id="13">2.</a>
<a href="#14" id="14">Can our method find overlapping clusters in datasets?</a>
<a href="#15" id="15">We evaluated our overlapping clustering formulation against standard hierarchical clustering, using Artificial Dataset 2 and presented the results in Fig.</a>
<a href="#16" id="16">8.</a>
<a href="#17" id="17">We used the same overlapping hierarchy to test how well our expected linear programming results compared to the optimal results found using an ILP solver.</a>
<a href="#18" id="18">Those results are presented in Fig.</a>
<a href="#19" id="19">10 and show that in practice using an LP solution along with a very simple rounding scheme leads to results very close to the optimal ILP objective.</a>
</body>
</html>