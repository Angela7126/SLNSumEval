<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:426">
</head>
<body bgcolor="white">
<a href="#0" id="0">1 the class of instances 1 only appears in positive bags.</a>
<a href="#1" id="1">Therefore, it is enough to learn an instance-level classifier {a mathematical formula}f(x → ) ∈ [0,1] that provides the confidence that instance {a mathematical formula}x → belongs to class 1.</a>
<a href="#2" id="2">Once {a mathematical formula}f(x → ) has been learned, the bag-level classifier {a mathematical formula}F(X) can be simply obtained by taking the maximum over the instance-level scores: {a mathematical formula}F(X)=maxx → ∈ Xf(x → ).</a>
<a href="#3" id="3">This way, the bag X is classified as positive if any of its instances {a mathematical formula}x → ∈ X belongs to class 1, and classified as negative otherwise.</a>
<a href="#4" id="4">Note that by using such an approach, the learning is performed only at the instance-level, i.e., for obtaining a model of the instances of class 1 which is used by the instance-level classifier {a mathematical formula}f(x → ).</a>
<a href="#5" id="5">At the bag-level, however, there is no learning, as the classifier {a mathematical formula}F(X) is obtained as an aggregation of instance-level scores.</a>
<a href="#6" id="6">The parameter R is optimized by maximizing the number of positive bags in the training set that contain at least one instance in R and, at the same time, the number of negative bags that do not contain any instance in R. Based on this, the bag-level classifier can be expressed by using the max rule:{a mathematical formula} i.e., X is considered positive if at least one of the instances {a mathematical formula}x → ∈ X is positive.</a>
<a href="#7" id="7">However, the methods from the last section tend to discard a big part of the information, by either only modelling the characteristics of certain instances (as in MI-SVM [17], where only one instance per positive bag is considered in the learning stage, see also our technical report [19]), or by considering only the average vector of a positive bag (as in SMIL [20]).</a>
<a href="#8" id="8">In order to perform this embedding, the function {a mathematical formula}M(X,V) takes into account the matching between the instances {a mathematical formula}x → i ∈ X and the “ concepts ” {a mathematical formula}Cj ∈ V.</a>
<a href="#9" id="9">In many cases, this matching can be understood as a classification of instances, i.e., if an instance {a mathematical formula}x → i ∈ X matches the concept {a mathematical formula}Cj ∈ V, then we say that {a mathematical formula}x → i is classified as class {a mathematical formula}Cj.</a>
<a href="#10" id="10">Note that this is similar to the Simple MI method, but there we only had one vector {a mathematical formula}v → that summarized the attributes of all the instances of the bag, regardless of their class.</a>
</body>
</html>