<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:374">
</head>
<body bgcolor="white">
<a href="#0" id="0">However, their work did not evaluate feature labeling in a statistical user study involving a large number of actual end users.</a>
<a href="#1" id="1">In order to evaluate our feature labeling algorithm, we perform an empirical comparison on multiple data sets under ideal conditions, using feature labels obtained from an oracle, and under real-world conditions for one particular dataset, using feature labels harvested from actual end users.</a>
<a href="#2" id="2">We experimented with adding one oracle feature label per class, two oracle feature labels per class, and so on until a total of ten per class were added.</a>
<a href="#3" id="3">These oracle feature labels were added in the order of highest information gain.</a>
<a href="#4" id="4">Therefore the oracle study provides an optimistic estimate on the potential gains of using these feature labeling algorithms by providing enough ideal feature labels to benefit the algorithm and by carefully tuning the parameters of the feature labeling algorithms over a large validation set.</a>
<a href="#5" id="5">The strength of oracle studies is the ability to evaluate a variety of data sets, but their weakness is that they may not be realistic as to the choices real users might make.</a>
<a href="#6" id="6">Therefore, for our second experiment, we conducted a user study to harvest feature labels from actual end users on the same 20 Newsgroups classes as used in Section 4.1.</a>
<a href="#7" id="7">We then used the end users ʼ data to compare the performance of the same algorithms as in our oracle study, but with smaller validation sets of size 24 (six instances for each class) to simulate a realistic scenario in which end users were able to label only a limited amount of training instances for both a training and a validation set.</a>
<a href="#8" id="8">Most of the algorithms that incorporate feature labels are sensitive to key parameters that control the influence of the feature labels, but these parameters are difficult to set prior to deployment due to the uniqueness of each end user ʼ s data distribution.</a>
<a href="#9" id="9">Therefore, some algorithms that perform well in idealized situations may perform poorly in real-world circumstances.</a>
<a href="#10" id="10">The performance of the algorithm on 20 Newsgroups hardly improved beyond {a mathematical formula}k=0.5 which might suggest that instances in this dataset formed very few compact clusters in the feature space and the seed (labeled training) instances managed to cover most of them.</a>
</body>
</html>