<html>
<head>
<meta name="TextLength" content="SENT_NUM:33, WORD_NUM:793">
</head>
<body bgcolor="white">
<a href="#0" id="0">2.</a>
<a href="#1" id="1">For the satisfaction-based utilitarian framework we show the following.</a>
<a href="#2" id="2">For the Monroe rule with the Borda scoring function we give a randomized {a mathematical formula}(0.715 − Ε )-approximation algorithm (often, the ratio is much better; see Section 4 and the comment on Algorithm A above).</a>
<a href="#3" id="3">In the case of an arbitrary positional scoring function we give a ({a mathematical formula}1 − 1e)-approximation algorithm (Theorem 10).</a>
<a href="#4" id="4">For the Chamberlin – Courant rule with the Borda scoring function we give a polynomial-time approximation scheme (that is, for each Ε , {a mathematical formula}0< Ε <1, we have a polynomial-time {a mathematical formula}(1 − Ε )-approximation algorithm; see Corollary 13 and the comment on Algorithm P above).</a>
<a href="#5" id="5">Definition 1</a>
<a href="#6" id="6">Let Α be a normal IPSF.</a>
<a href="#7" id="7">An instance of Α -CC-DisWinner problem consists of a set of agents {a mathematical formula}N=[n], a set of alternatives {a mathematical formula}A={a1, … ,am}, a preference profile V of the agents, and a positive integer K. We ask for a K-assignment function Φ such that {a mathematical formula} ℓ sum Α ( Φ ) is minimized.</a>
<a href="#8" id="8">The problem Α -Monroe-DisWinner is defined in the same way but we additionally require Φ to be a Monroe K-assignment function.</a>
<a href="#9" id="9">Example 1</a>
<a href="#10" id="10">Consider a set {a mathematical formula}N={1,2,3,4,5,6} of six agents and a set {a mathematical formula}A={a,b,c,d} of four alternatives.</a>
<a href="#11" id="11">Suppose the agents have the following preference orders:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} and we are looking for a committee of size {a mathematical formula}K=2.</a>
<a href="#12" id="12">Consider the dissatisfaction-based variant of Chamberlin – Courant rule with the Borda dissatisfaction function, {a mathematical formula} Α B,inc (i.e., problem {a mathematical formula} Α B,inc-CC-DisWinner).</a>
<a href="#13" id="13">In this case, there is a unique optimal K-assignment Φ :{a mathematical formula} Agent 5 ranks her representative on the second position and all the other agents rank their representatives on the first positions.</a>
<a href="#14" id="14">Thus, the aggregated dissatisfaction of the agents is {a mathematical formula} ℓ sum Α B,inc( Φ )=0+0+0+0+1+0=1.</a>
<a href="#15" id="15">If we considered the satisfaction-based variant of the problem ({a mathematical formula} Α B,dec-CC-SatWinner), the assignment would be the same, but with the satisfaction {a mathematical formula} ℓ sum Α B,dec( Φ )=3+3+3+3+2+3=17.On the other hand, consider the dissatisfaction variant of the Monroe rule, that is, problem {a mathematical formula} Α B,inc-Monroe-DisWinner.</a>
<a href="#16" id="16">We now turn to approximation algorithms for the Monroe and Chamberlin – Courant multiwinner voting rules in the satisfaction-based framework.</a>
<a href="#17" id="17">Indeed, if one focuses on agents' total satisfaction then it is possible to obtain high-quality approximation results.</a>
<a href="#18" id="18">In particular, we show the first nontrivial (randomized) approximation algorithm for {a mathematical formula} Α B,dec-Monroe-SatWinner (recall that {a mathematical formula} Α B,dec is the Borda family of DPSFs; for the case of m candidates, we have {a mathematical formula} Α B,decm(i)=m − i).</a>
<a href="#19" id="19">We show that for each {a mathematical formula} Ε >0 we can provide a randomized polynomial-time algorithm that achieves {a mathematical formula}0.715 − Ε approximation ratio; the algorithm usually achieves even a better approximation.</a>
<a href="#20" id="20">For the case of arbitrarily selected DPSF we show a {a mathematical formula}(1 − 1e)-approximation algorithm.</a>
<a href="#21" id="21">Finally, we present the first polynomial-time approximation scheme (PTAS) for {a mathematical formula} Α B,dec-CC-SatWinner.</a>
<a href="#22" id="22">These results stand in sharp contrast to those from the previous section, where we have shown that approximation is hard for the dissatisfaction-based framework.</a>
<a href="#23" id="23">The core difficulty in computing the winners under the Monroe and Chamberlin – Courant rules is in selecting the alternatives that should be assigned to the agents.</a>
<a href="#24" id="24">Given a preference profile and a set S of up to K alternatives, using the standard network-flow argument, it is easy to find a (possibly partial) optimal assignment {a mathematical formula} Φ Α S of the agents to the alternatives from S.</a>
<a href="#25" id="25">Below we describe our algorithms for {a mathematical formula} Α B,dec-Monroe-SatWinner and for {a mathematical formula} Α B,dec-CC-SatWinner.</a>
<a href="#26" id="26">Formally speaking, every approximation algorithm for {a mathematical formula} Α B,dec-Monroe-SatWinner also gives feasible results for {a mathematical formula} Α B,dec-CC-SatWinner.</a>
<a href="#27" id="27">However, some of our algorithms are particularly well-suited for both problems and some are tailored to only one of them.</a>
<a href="#28" id="28">Thus, for each algorithm we clearly indicate if it is meant only for the case of Monroe, only for the case of Chamberlin – Courant, or if it naturally works for both systems.</a>
<a href="#29" id="29">Algorithm GM (greedy marginal improvement) was introduced by Lu and Boutilier for the case of the Chamberlin – Courant rule.</a>
<a href="#30" id="30">Here we generalize it to apply to the Monroe rule as well, and we show that it is a {a mathematical formula}(1 − 1e)-approximation algorithm for Α -Monroe-SatWinner.</a>
<a href="#31" id="31">We point out that this approximation result for the Monroe rule applies to all non-decreasing PSFs Α .</a>
<a href="#32" id="32">For the Monroe rule, the algorithm can be viewed as an extension of Algorithm B.</a>
</body>
</html>