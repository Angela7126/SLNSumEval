<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:308">
</head>
<body bgcolor="white">
<a href="#0" id="0">This is partly because the manipulation planning problems have intrinsic characteristics such as continuous state spaces which make the application of POMDP solvers less straightforward, and partly because the manipulation planning approaches have only recently advanced to the point where the explicit modeling of uncertainty becomes tractable.</a>
<a href="#1" id="1">In particular, POMDPs are beneficial if a particular problem has some of the following characteristics: 1) the problem requires weighting the value of information gathering versus collecting immediate rewards such as lifting objects to get a better view on other objects, 2) the world model is uncertain and thus it should be updated, for example when some objects are harder to grasp than others, or 3) the sequence of actions matters such as when objects occlude each other even partially.</a>
<a href="#2" id="2">In a POMDP, the transition probability {a mathematical formula}P(s ′ |s,a) models the uncertainty in action effects: what is the probability to move a cup successfully from a table (part of state s) into a dishwasher (part of {a mathematical formula}s ′ ), when the action a is “ move cup into dishwasher ” ?</a>
<a href="#3" id="3">The observation probability {a mathematical formula}P(o|s ′ ,a) models the uncertainty in observations: what is the probability of observing a cup as dirty (observation o), when it is dirty (part of state {a mathematical formula}s ′ ) and we are executing action a “ look at cup ” ?</a>
<a href="#4" id="4">In order to improve the policy, we use the current policy for finding a belief distribution over graph nodes, but other state-of-the-art POMDP methods based on particle filtering [9], [10] select an action and observation to find a new belief for which to compute a policy.</a>
<a href="#5" id="5">In these experiments, we form a world model from the point cloud and then repeatedly sample an initial belief and simulate the system using the probability model for 10 time steps.</a>
</body>
</html>