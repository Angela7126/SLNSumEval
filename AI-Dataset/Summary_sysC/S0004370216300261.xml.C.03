<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:196">
</head>
<body bgcolor="white">
<a href="#0" id="0">We initialize {a mathematical formula} Γ 0 − = Γ 0+=[0]d×d, where {a mathematical formula}u=d.</a>
<a href="#1" id="1">At each iteration, we denote {a mathematical formula} Γ t+=St+ and {a mathematical formula} Γ t − =St − .</a>
<a href="#2" id="2">To implement the approximate approach, we initialize {a mathematical formula} Γ 0 − = Γ 0+=[0]d× Τ in Algorithm 1.</a>
<a href="#3" id="3">We will take {a mathematical formula} Γ t+ and {a mathematical formula} Γ t − as approximations for {a mathematical formula}Xt+[Xt+] ⊤ and {a mathematical formula}Xt − [Xt − ] ⊤ , respectively.</a>
<a href="#4" id="4">Recall that the covariance matrices are given by{a mathematical formula} where {a mathematical formula}Xt+ and {a mathematical formula}Xt − denote the matrices of positive and negative instances, respectively.</a>
<a href="#5" id="5">First, we say that an online learning algorithm has a regret bound {a mathematical formula}RT if {a mathematical formula}wT0,wT0+1, … ,wT − 1 are such that{a mathematical formula} From Theorem 2, we can observe {a mathematical formula}RT=O(1/T) for the OPAUC algorithm.</a>
<a href="#6" id="6">{a mathematical formula} ‖ wk − w ‖ ≤ Ε /16(1+( Λ +2)B)).</a>
<a href="#7" id="7">Theorem 2 shows that the optimal learning rate {a mathematical formula} Η t depends on the optimal loss {a mathematical formula}L ⁎ yet it is unknown.</a>
</body>
</html>