<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:714">
</head>
<body bgcolor="white">
<a href="#0" id="0">The input language for competition benchmarks, represented in terms of a uniform (first-order) problem encoding along with (ground) facts specifying a problem instance, follows the ASP-Core-2 standard [15].</a>
<a href="#1" id="1">In view of the objective of comparing participant systems in a uniform setting, this edition of the ASP Competition did not include a Model&Solve track, but took place in the spirit of the former System track: it was open to any general-purpose solving system, provided it was able to process ASP-Core-2 programs.</a>
<a href="#2" id="2">Assuming that instances of {a mathematical formula}share(J1,J2) provide jobs {a mathematical formula}J1 and {a mathematical formula}J2 to be executed on a common device, the 2013 encoding includes a subprogram as follows for picking starting times and denying overlaps:{a mathematical formula}{a mathematical formula} Similar to (10), the integrity constraint in (16) lists all forbidden starting times {a mathematical formula}T2 for job {a mathematical formula}J2 relative to a starting time T and the length L of job {a mathematical formula}J1 explicitly.</a>
<a href="#3" id="3">That is, the exact starting times of {a mathematical formula}J1 and {a mathematical formula}J2 are not directly compared to figure out which order is needed and to deny impossible cases by means of the integrity constraint in (22), so that a ground instantiation saves space in comparison to (16).</a>
<a href="#4" id="4">In the 2013 encoding, the accumulation and limitation of costs is addressed by a subprogram as follows:{a mathematical formula} That is, basic rules describe the formation of total costs along n elements, whose individual costs depend on an interpretation at hand, and the limit is enforced by checking the existence of a viable outcome.</a>
<a href="#5" id="5">This allows for a compact retrieval of the relative positions of endpoints X and Y by means of a rule{a mathematical formula} of the same pattern as (21), whereas the 2013 encoding relies on a rule of the form{a mathematical formula} whose ground instances enumerate pairs of candidate positions explicitly.</a>
<a href="#6" id="6">In order to use common inputs, we compare the previous and this year's systems on Basic Decision encodings only, taking into account that lp2sat processes a legacy format that differs from ASP-Core-2 on advanced constructs such as aggregates.</a>
<a href="#7" id="7">Given that the Basic Decision track on 2013 encodings merely includes two domains, we here also consider the six alternative encodings with basic features only, and Table 13 shows respective scores and cumulative CPU times for solved instances.</a>
<a href="#8" id="8">To this end, Table 15 provides grounding parameters, obtained by running gringo-4 under the same time and memory limits as participant systems, along with the scores of systems in the SP category (except for wasp-wpm1-only-weak, which did not participate in the majority of domains) on previous and novel encoding variants, given in the upper or lower row, respectively, per domain.</a>
<a href="#9" id="9">Arguably, more challenging instances would be desirable for domains in which some encoding variant enables a participant system to complete all its runs in time, as it happens in half of the domains listed in Table 15.</a>
<a href="#10" id="10">At the beginning, it was mainly based on a weighted sum of the number of instances solved within given time and memory limits; in the 2011 and 2013 editions, the scoring scheme has been extended by awarding additional points to systems performing well in terms of elapsed time.</a>
<a href="#11" id="11">For a Decision or Query problem P, each system gained a score {a mathematical formula}S(P)=Ssolve(P)+Stime(P), where {a mathematical formula}Ssolve and {a mathematical formula}Stime ranged from 0 to 50 each: while {a mathematical formula}Ssolve was linearly dependent on the number of solved instances, {a mathematical formula}Stime involved a logarithmic dependence on participants' running times, thus rendering time differences at a common order of magnitude less significant.</a>
<a href="#12" id="12">At first, we found that time quota did not make much difference and accordingly use {a mathematical formula}Ssolve(P) only (simply denoted {a mathematical formula}S(P) in Section 3.5), which as before linearly reflects the number of solved instances of a Decision or Query problem P. Furthermore, we pondered that absolute objective values are not adequate for scoring solutions for Optimization problems, given that they depend heavily on domains and are susceptible to perturbations; rather than that, relative rankings can draw a more reliable picture.</a>
<a href="#13" id="13">The way tracks are defined depends on the competition at hand, but three main criteria can be identified: language features of inputs, the kind of problem domains, and reasoning tasks to be accomplished.</a>
</body>
</html>