<html>
<head>
<meta name="TextLength" content="SENT_NUM:25, WORD_NUM:617">
</head>
<body bgcolor="white">
<a href="#0" id="0">Specifically, this article explores a limited version of the full ad hoc teamwork problem in which an ad hoc agent knows the environmental dynamics and encounters unknown teammates, but has previous experience in the domain with other teammates.</a>
<a href="#1" id="1">Team Knowledge: Does the ad hoc agent know what its teammates' actions will be for a given state, before interacting with them?</a>
<a href="#2" id="2">Reactivity of teammates: How much does the ad hoc agent's actions affect those of its teammates?</a>
<a href="#3" id="3">The ad hoc agent's knowledge about its teammates' behaviors gives insight into the difficulty of planning in the domain.</a>
<a href="#4" id="4">The agent's knowledge can range from knowing the complete behaviors of its teammates to knowing nothing about them.</a>
<a href="#5" id="5">To estimate the ad hoc agent's knowledge about its teammates' behaviors, we compare the actions the ad hoc agent expects them to take and the ground truth of what actions they take.</a>
<a href="#6" id="6">Specifically, we compare the expected distribution of teammate actions to the true distribution that the teammates follow.</a>
<a href="#7" id="7">[47], but we consider the ad hoc agent's ability to change the actions of its teammates rather than the environment state.</a>
<a href="#8" id="8">In all of the scenarios in this article, TeamK is still relatively high given the ad hoc agent's previous experiences and the fact that the current teammate types are similar to the past teammates.</a>
<a href="#9" id="9">While the agents do react to the ad hoc agent's actions, they do not learn from it over time.</a>
<a href="#10" id="10">The ad hoc agent's actions have limited effects on its teammates; hence, the values of Reactivity are low to moderate for the domains in the article.</a>
<a href="#11" id="11">We believe that future research into teammates that learn about the ad hoc agent is needed; ad hoc agents should be able to deal with higher amounts of teammate reactivity.</a>
<a href="#12" id="12">The moderate reactivity means that the ad hoc agent can help its team and should consider how its actions affect its teammates, especially in the full HFO domain.</a>
<a href="#13" id="13">However, it also means that the teammates have limited ability to change based on the ad hoc agent's actions.</a>
<a href="#14" id="14">In this variant, the ad hoc agent learns a policy to cooperate with each of its past teammates, selects which policies best match how to cooperate with its current teammates, and then selects actions using these policies.</a>
<a href="#15" id="15">When an agent has a good model of its environment, it can use this model to plan good actions using a limited number of interactions with the environment.</a>
<a href="#16" id="16">For an ad hoc agent to plan, it also needs to model its teammates; therefore, it is useful for the ad hoc agent to build models of its teammates' behaviors.</a>
<a href="#17" id="17">Given that learning new models online takes many samples, it is useful to reuse information learned from past teammates.</a>
<a href="#18" id="18">This section describes PLASTIC-Model, a variant of the PLASTIC approach that learns models of prior teammates and selects which models best predict its current teammates.</a>
<a href="#19" id="19">An overview of this approach is given in Fig.</a>
<a href="#20" id="20">PLASTIC-Model(CorrectLearned) evaluates the performance of the learning algorithm, where PLASTIC-Model knows which teammates the agent is cooperating with and uses its past observations of these teammates to learn a model of them.</a>
<a href="#21" id="21">PLASTIC-Model(SetIncluding) evaluates the more general ad hoc teamwork scenario where the current type of teammate is unknown, but the current teammates have been previously observed.</a>
<a href="#22" id="22">Finally, PLASTIC-Model(SetExcluding) shows the true ad hoc teamwork scenario, when the ad hoc agent has never seen the current teammates, but uses PLASTIC-Model to reuse knowledge it has learned from previous teammates.</a>
<a href="#23" id="23">They consider the case where the ad hoc agent knows the environment, but not its teammates.</a>
<a href="#24" id="24">Additionally, their ad hoc agent is given a large amount of expert knowledge and the set of possible teammates is limited compared to this article.</a>
</body>
</html>