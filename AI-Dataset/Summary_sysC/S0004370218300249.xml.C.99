<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:263">
</head>
<body bgcolor="white">
<a href="#0" id="0">The process of constructing models of other agents, sometimes referred to as agent modelling or opponent modelling,{sup:2} often involves some form of learning since the model may be based on information observed from the current interaction and possibly data collected in past interactions.</a>
<a href="#1" id="1">Current methodologies include learning detailed models of an agent's decision making as well as reasoning about spaces of such models; inferring an agent's goals and plans based on hierarchical action descriptions; recursive reasoning to predict an agent's state of mind and its higher-order beliefs about other agents; and many other approaches.</a>
<a href="#2" id="2">Such partial observability can make the modelling task significantly more difficult, since agents can make decisions based on private observations and the modelling method must take such possibilities into account.</a>
<a href="#3" id="3">[187] propose a method which consists of two neural networks: one network is trained to predict a mixture of types, taking as input the observed actions of the modelled agent; another network is trained to make decisions by assigning probabilities to available actions, taking as input the observed actions and the predicted mixture from the first network.</a>
<a href="#4" id="4">The authors show how existing exact and approximate planning methods can be adopted to compute this set of goals, essentially by solving the planning problem for the modelled agent such that the solution is consistent with the observed actions.</a>
<a href="#5" id="5">For methods that predict an agent's actions, such as policy reconstruction (Section 4.1), type-based reasoning (Section 4.2), and recursive reasoning (Section 4.5), modelling single agents is predicated on the assumption that agents choose actions independently from each other, as defined in Section 3.</a>
</body>
</html>