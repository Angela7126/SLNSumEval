<html>
<head>
<meta name="TextLength" content="SENT_NUM:22, WORD_NUM:713">
</head>
<body bgcolor="white">
<a href="#0" id="0">Taking these considerations into account, the Fifth ASP Competition was based on the System track of the 2013 edition,{sup:2} reusing the available benchmarks but also adding novel problem encodings.</a>
<a href="#1" id="1">In view of the objective of comparing participant systems in a uniform setting, this edition of the ASP Competition did not include a Model&Solve track, but took place in the spirit of the former System track: it was open to any general-purpose solving system, provided it was able to process ASP-Core-2 programs.</a>
<a href="#2" id="2">However, the 2013 edition still made exceptions and admitted problem encodings in legacy formats, while the Fifth ASP Competition insisted on ASP-Core-2 compliance.</a>
<a href="#3" id="3">For Decision and Query problems, the score of a solver S on a domain P featuring N instances is calculated as{a mathematical formula} where {a mathematical formula}NS is the number of instances solved within the allotted time and memory limits.</a>
<a href="#4" id="4">Let M be the number of participant systems; then, the score of a solver S for an instance I in a domain P featuring N instances is calculated as{a mathematical formula} where {a mathematical formula}MS(I) is</a>
<a href="#5" id="5">The score {a mathematical formula}S(P) of a solver S for domain P consists of the sum of scores {a mathematical formula}S(P,I) over all N instances I featured by P. Note that, as with Decision and Query problems, {a mathematical formula}S(P) can range from 0 to 100.</a>
<a href="#6" id="6">The benchmark domains used in this edition of the ASP Competition largely coincide with the ones from 2013.</a>
<a href="#7" id="7">Hence, half of the systems were in 2013 run on “ equivalent ” encoding reformulations in legacy formats, and the Fifth ASP Competition is the first edition relying on common inputs in ASP-Core-2.</a>
<a href="#8" id="8">As described in Section 3, the benchmarks in the Fifth ASP Competition are categorized into tracks based on the language features utilized by encodings.</a>
<a href="#9" id="9">Table 1 provides an overview that groups benchmark domains in terms of language features in the ASP-Core-2 encodings from 2013.</a>
<a href="#10" id="10">The second column of Table 1 summarizes the usage of particular language features, among the ones introduced in Section 2, for the encodings from the Fourth ASP Competition in 2013.</a>
<a href="#11" id="11">Finally, Abstract Dialectical Frameworks is the only Optimization problem in the Fifth ASP Competition for which more than one level, i.e.</a>
<a href="#12" id="12">Moreover, evaluating participant systems on previous encodings as well as alternative variants serves to validate competition results and to gain insights regarding the impact of encodings on system performance, where deviations may help to identify more or less successful modeling approaches.</a>
<a href="#13" id="13">Such a space blow-up is avoided by using a {a mathematical formula}#sum aggregate in an integrity constraint of the form{a mathematical formula} included in the 2014 encoding for the Weighted-Sequence Problem domain.</a>
<a href="#14" id="14">In this way, twenty instances were picked per domain in order to assess the participant systems both on the encodings from 2013 as well as their new variants.</a>
<a href="#15" id="15">It is also worth mentioning that, in order to assess improvements in system implementation, we reran a selection of the systems submitted to the Fourth ASP Competition in 2013.</a>
<a href="#16" id="16">We start by presenting performance results for the systems introduced in Section 5 on benchmarks consisting of 2013 problem encodings and twenty randomly selected instances per domain.</a>
<a href="#17" id="17">Finally, Table 6 provides the results for Track #4, containing non-HCF instances of the Decision problems Complex Optimization and Minimal Diagnosis, the Query problem Strategic Companies, and the Optimization problem Abstract Dialectical Frameworks.</a>
<a href="#18" id="18">3 plot the score acquisition of systems for Optimization problems (marked with “ O ” in Table 1), where system runs are ordered by the achieved positive scores, and the sum of scores for the number of instances on the x-axis is given on the y-axis.</a>
<a href="#19" id="19">Given that the Basic Decision track on 2013 encodings merely includes two domains, we here also consider the six alternative encodings with basic features only, and Table 13 shows respective scores and cumulative CPU times for solved instances.</a>
<a href="#20" id="20">Table 14 contrasts both systems on 2013 encodings for all but the domains aiming at Query answering (Reachability and Strategic Companies), where Decision problems are addressed in the upper part and Optimization problems in the lower part.</a>
<a href="#21" id="21">4, which contrasts overall scores, displayed in decreasing order, of systems in the SP category on alternative encoding variants with corresponding scores on 2013 encodings (as listed in Table 7).</a>
</body>
</html>