<html>
<head>
<meta name="TextLength" content="SENT_NUM:15, WORD_NUM:636">
</head>
<body bgcolor="white">
<a href="#0" id="0">An operator or action o is classical (or deterministic) if {a mathematical formula}effects(o) contains just one conjunction of literals.</a>
<a href="#1" id="1">A planning domain {a mathematical formula}D=(L,O) is classical if every operator in O is classical.</a>
<a href="#2" id="2">A planning problem {a mathematical formula}P=(D,S0,G) is classical if D is classical and there is just one initial state, i.e., {a mathematical formula}S0={s0} for some {a mathematical formula}s0 ∈ S.</a>
<a href="#3" id="3">In this case we will dispense with {a mathematical formula}S0 and write {a mathematical formula}P=(D,s0,G).</a>
<a href="#4" id="4">NDPR works by calling CP on problems of the form {a mathematical formula}(D¯,s,G), and combining CP's solutions into a solution for P. It is nearly identical to the NDP algorithm in [30], except that it omits NDP's faulty pseudocode for unsolvable states and it specifies exactly how to incorporate a plan into the policy (NDP left it unstated).</a>
<a href="#5" id="5">In Section 4.1 we present ConstrainProblem, a procedure for modifying a classical planning problem {a mathematical formula}P=(D¯,s,G) to make some of the actions inapplicable at the first step of any solution to P. Unlike removing state-action pairs, ConstrainProblem only incurs a quadratic increase in the size of the domain description per constrained action.</a>
<a href="#6" id="6">Algorithm 2 is the ConstrainProblem procedure, which takes a classical planning problem {a mathematical formula}(D¯,s,G) and a set A of actions, and returns a new planning problem {a mathematical formula}(D¯ ′ ,s ′ ,G) for which a solution is any solution to {a mathematical formula}(D¯,s,G) that does not start with an action in A.</a>
<a href="#7" id="7">This requires overcoming two potential problems: (1) if the plan p generated by CP contains a cycle, then p cannot be translated into a policy because it will require two different actions at one of its states, and (2) if p goes through a state in U, then it cannot be translated into a policy that solves the nondeterministic problem {a mathematical formula}(D,{s},G), since the states in U are known to be unsolvable.</a>
<a href="#8" id="8">On the other hand, many of the problems have solutions that differ only slightly from the shortest path, and NDP2's performance is “ only ” exponential in the length of that path, and so NDP2's indirect use of FF's heuristic function enabled it to solve some of the planning problems all the way up to size 66, even though MBP could not solve any problems larger than size 21.</a>
<a href="#9" id="9">As we mentioned earlier, our original purpose in developing the Lost in Space (LiS) domain was to test NDP2's subroutines for avoiding unsolvable states.</a>
<a href="#10" id="10">The proof is by induction on the size of U.Let s be the first state added to U, which means Find-Acceptable-Plan returned failure when planning from s. Since U is empty and by Lemma 6 Find-Acceptable-Plan is complete, there is no path to a goal state from s, and so s would not be a Π -descendant of {a mathematical formula}s0 in any valid strong cyclic policy.Induct.</a>
<a href="#11" id="11">Algorithm 7 then finds the Π -corresponding state {a mathematical formula}s ⁎ (which is potentially equal to s) and replaces {a mathematical formula} Π (s) with {a mathematical formula} Π (s ⁎ ).</a>
<a href="#12" id="12">Algorithm 7 then, for every child {a mathematical formula}si of s for which {a mathematical formula} Π (si) is undefined, adds the corresponding action from the unabstracted image of {a mathematical formula}(s ⁎ ,a ⁎ ).</a>
<a href="#13" id="13">The policy Π should be a strong cyclic solution to a partially unabstracted {a mathematical formula}P ⁎ after every iteration of the main loop.</a>
<a href="#14" id="14">So if after merging the unabstracted image of {a mathematical formula}(s ⁎ ,a ⁎ ), s no longer has a path to the goal, then Algorithm 7 picks a state in the children of s replaces the policy for it with a {a mathematical formula}merge({ … }) action pointing to one of the former children of s (one in {a mathematical formula} Γ (s,a ⁎ )).</a>
</body>
</html>