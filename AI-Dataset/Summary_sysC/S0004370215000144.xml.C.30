<html>
<head>
<meta name="TextLength" content="SENT_NUM:46, WORD_NUM:1210">
</head>
<body bgcolor="white">
<a href="#0" id="0">A detailed analysis of the competition results that provides insights into the performance of state-of-the-art planners from different perspectives such as coverage, quality, CPU time, and memory usage.</a>
<a href="#1" id="1">Therefore, planner performance can be analyzed from different perspectives, such as the number of problems solved, CPU time, plan length, total cost, makespan, or other features such as the diversity or flexibility of the solutions.</a>
<a href="#2" id="2">This focuses on good plan quality, with less emphasis on the number of problems solved or the CPU time used.</a>
<a href="#3" id="3">Accordingly, if two planners find solutions within the same time and memory bounds, the plan with the lower cost is awarded a better score.</a>
<a href="#4" id="4">This is not applicable to the optimization track, for which all solutions are expected to have the same cost and thus only the number of solutions found (or coverage) is relevant for the final score.</a>
<a href="#5" id="5">Therefore, planners in both tracks were evaluated over the same collection of domains, but problems for the optimal track were carefully selected to be easier to solve.</a>
<a href="#6" id="6">In addition, to facilitate direct comparisons, planners in the multi-core track were faced with exactly the same planning tasks used in the sequential satisficing track (Section 5.2).</a>
<a href="#7" id="7">1 shows the number of planners that solved a particular number of problems considering the whole benchmark, that is, those that were reused according to the procedure described in Appendix D and the new problems.</a>
<a href="#8" id="8">In our experience, selecting problems for this track seems to be very challenging, mainly because planners scale worse in this track, which reduces the maximum level of problem complexity they can handle.</a>
<a href="#9" id="9">Thus, selection of structurally different problems becomes harder and problems tend in general to be more similar in terms of difficulty than in the other tracks: either they are not solved at all or a large number of planners solve them, as evidenced, for example, by the results for the barman domain.</a>
<a href="#10" id="10">Apart from the quality of the solutions, typical parameters used to compare planner performance in previous IPCs include the number of instances solved (or, alternatively, the overall problem solving success rate, defined as the percentage of problems solved{sup:7}), and the raw speed at which solutions were generated.</a>
<a href="#11" id="11">Table 4 lists the number of problems solved and the success rate for each planner in descending order.</a>
<a href="#12" id="12">Since we checked that all correct solution plans had the same quality, the score assigned to each planner and planning task can only take a value of 0 (unsolved or invalid) or 1 (optimally solved).</a>
<a href="#13" id="13">Hence, the final score for each planner equals the number of problems it solved.</a>
<a href="#14" id="14">Therefore, Table 4 also shows the final score for every entry.</a>
<a href="#15" id="15">Therefore, the following planners were distinguished by their performance in the sequential optimal track of IPC-2011:</a>
<a href="#16" id="16">In this section, we first show how the number of problems solved evolved over time in the range {a mathematical formula}(0,1800]s. Owing to the large number of participants in this track, Fig.</a>
<a href="#17" id="17">13 (page 101) shows the maximum memory required by all entrants in this track as a function of the number of problems solved by each of them.</a>
<a href="#18" id="18">Thus, the following planners were distinguished by their performance in the sequential track of IPC-2011:</a>
<a href="#19" id="19">To facilitate comparisons among tracks, entrants in the sequential multi-core track were faced with exactly the same problems chosen for the sequential satisficing track; the results of this comparison can be found in Section 5.2.</a>
<a href="#20" id="20">Table 6 shows the final score for each planner, along with the number of problems solved and the success rate.</a>
<a href="#21" id="21">17 shows the evolution of the number of problems solved in the interval {a mathematical formula}(0,1800]s. phsff and yahsp2-mt are the fastest algorithms in the short term, with phsff always solving more problems than yahsp2-mt up to the end of the interval.</a>
<a href="#22" id="22">phsff solved 120 problems in the first 13 s (and yahsp2-mt solved 109), whereas arvandherd solved 119 problems.</a>
<a href="#23" id="23">From this point on, the winner of this track progressed much faster and had already solved 123 problems at {a mathematical formula}t=14s, and yahsp2-mt solved only one additional problem.</a>
<a href="#24" id="24">20 shows the maximum memory needed to solve a specific number of problems for all entrants in this track.</a>
<a href="#25" id="25">The maximum memory reported by ayalsoplan results from various observations already made in Section 4.1.</a>
<a href="#26" id="26">The following subsections examine the performance of entrants in the temporal satisficing track under the usual parameters: number of problems solved, quality, CPU time, and memory management.</a>
<a href="#27" id="27">Table 7 shows the final score, the number of problems solved, and the success rate for the temporal satisficing planners.</a>
<a href="#28" id="28">In this case, the coefficient for correlation between the number of problems solved and the score is 0.981.</a>
<a href="#29" id="29">The most remarkable observations are that yahsp2-mt and yahsp2 are the first- and second-ranked planners according to the number of problems solved, yet their score ranks them second and fourth, respectively.</a>
<a href="#30" id="30">27 (page 109) shows how much memory was used over time in solving problem 003 of the elevators domain, which was solved by all the planners except cpt4, sharaabi, and tlp-gp.</a>
<a href="#31" id="31">Thus, the following planners were distinguished by their performance in the temporal satisficing track of IPC-2011:</a>
<a href="#32" id="32">We now compare the performance of the winners of IPC-2011 with the winners of IPC-2008 for the same planning tasks: the problems selected for IPC-2011.</a>
<a href="#33" id="33">If refined versions of the winners of IPC-2008 were available, these were preferred over the versions submitted at the time, which gives an additional advantage to those entrants.</a>
<a href="#34" id="34">This happened in the sequential satisficing and optimal tracks, for which the versions entered in IPC-2011 were used instead of the old versions.</a>
<a href="#35" id="35">This analysis was not possible for the sequential multi-core track since it was run for the first time in IPC-2011.</a>
<a href="#36" id="36">The comparisons are performed with regard to coverage and raw speed.</a>
<a href="#37" id="37">According to the analysis in this section, overall, the optimal planner that won IPC-2011 improved on the performance of the optimal planner that won IPC-2008 with regard to the problems chosen for IPC-2011 in terms of both coverage and raw speed.</a>
<a href="#38" id="38">Table 4 (page 92) shows that fdss-1 solved 185 problems and gamer solved 37 fewer.</a>
<a href="#39" id="39">The difference in coverage is 13.22% over the whole set of planning tasks, but an improvement of 20% for the number of problems solved by the IPC-2008 winner.</a>
<a href="#40" id="40">In addition, 136 problems were solved by both the planners.</a>
<a href="#41" id="41">This leaves 12 problems that were solved by gamer but not by fdss-1, and about four times more problems solved by the latter that could not be solved by the former.</a>
<a href="#42" id="42">In 2008 the winner of the sequential satisficing track was lama-2008 and a refined version of this planner was entered in IPC-2011.</a>
<a href="#43" id="43">Thus, this version was compared with the current winner, lama-2011, instead of the version submitted in 2008.</a>
<a href="#44" id="44">Again, the analysis in this section shows that, overall, the planner that won IPC-2011 improves on the performance of the IPC-2008 winner for the problems chosen for IPC-2011 in terms of coverage, quality, and raw speed.</a>
<a href="#45" id="45">The fact that the winner of the sequential satisficing track surpassed the performance of the winner of the sequential multi-core track (at least in terms of both coverage and the official IPC score, and in terms of plan quality when considering the tasks solved by both planners) is not of great concern.</a>
</body>
</html>