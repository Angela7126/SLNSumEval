<html>
<head>
<meta name="TextLength" content="SENT_NUM:21, WORD_NUM:384">
</head>
<body bgcolor="white">
<a href="#0" id="0">5.</a>
<a href="#1" id="1">For each {a mathematical formula}n ∈ (1 … N), generate {a mathematical formula}vn ∼ N( Μ V, Λ V − 1).</a>
<a href="#2" id="2">SSTF applies biases from semantic classes to item (or tag) feature vectors in tensor factorization to solve the sparsity problem.</a>
<a href="#3" id="3">First, it creates augmented tensors by incorporating relationships composed of classes of sparse objects (e.g.</a>
<a href="#4" id="4">multi-object relationships composed of “ users ” , “ classes of sparse items ” , and “ tags ” or relationships composed of “ users ” , “ items ” , and “ classes of sparse tags ” ) into the original tensor (Section 4.3.1).</a>
<a href="#5" id="5">As an illustration of how this is done, suppose that items {a mathematical formula}v1 and {a mathematical formula}v2 in Fig.</a>
<a href="#6" id="6">1 are sparse items.</a>
<a href="#7" id="7">SSTF creates an augmented tensor by incorporating the relationships composed of {a mathematical formula}u1 (or {a mathematical formula}u2), CV1 (or CV2), and “ Breathless ” into the original tensor.</a>
<a href="#8" id="8">Furthermore, it determines multiple sets of sparse objects according to their degree of sparsity and creates multiple augmented tensors; this gives semantic biases to sparse objects according to the degree of sparsity.</a>
<a href="#9" id="9">Next, it factorizes the original tensor and augmented tensors simultaneously to compute feature vectors for objects and classes (Section 4.3.2).</a>
<a href="#10" id="10">SSTF incorporates semantic biases into the tensor factorization by updating the feature vectors for objects using those for classes.</a>
<a href="#11" id="11">For example, it creates feature vectors for classes, CV1 and CV2, which share semantic knowledge on sparse items, {a mathematical formula}v1 and {a mathematical formula}v2.</a>
<a href="#12" id="12">It then uses the feature vectors for classes, CV1 and CV2, as semantic biases and incorporates them into feature vectors for sparse items, {a mathematical formula}v1 and {a mathematical formula}v2.</a>
<a href="#13" id="13">This procedure aims to solve the sparsity problem.</a>
<a href="#14" id="14">(2)</a>
<a href="#15" id="15">SSTF uses the same precision Α , feature vectors {a mathematical formula}um, {a mathematical formula}vn, and {a mathematical formula}tk, and their hyper-parameters when factorizing the original tensor and augmented tensors.</a>
<a href="#16" id="16">Thus, the factorization of the original tensor is influenced by those of the augmented tensors through these shared parameters.</a>
<a href="#17" id="17">It lets the factorization of the original tensor be biased by the semantic knowledge in the augmented tensors.</a>
<a href="#18" id="18">In Fig.</a>
<a href="#19" id="19">2-(ii), {a mathematical formula}um and {a mathematical formula}tk are shared among the factorizations of {a mathematical formula}R, {a mathematical formula}Rv(1), and {a mathematical formula}Rv(2).</a>
<a href="#20" id="20">5.</a>
</body>
</html>