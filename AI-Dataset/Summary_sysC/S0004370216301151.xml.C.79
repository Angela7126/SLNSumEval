<html>
<head>
<meta name="TextLength" content="SENT_NUM:24, WORD_NUM:921">
</head>
<body bgcolor="white">
<a href="#0" id="0">As soon as enough data has been provided, the learner will start to construct its own grammar and will attempt to produce appropriate utterances (i.e., it learns in an incremental way the language it is exposed to).</a>
<a href="#1" id="1">Our model is based on similar assumptions, but it differs in three main aspects: i) utterances given to our learner offer a partial or total description of the scene, but they do not refer to things that are not in the scene; ii) we are not limited to word learning (our learning task is more complex: our system learns to generate and understand relevant utterances in a given scene); iii) we use a richer semantic representation.</a>
<a href="#2" id="2">Unlike in TWIG, our learner has no initial knowledge of words or grammar, there is no restriction on the number of new words in a sentence given to the learner, and our learner is allowed to interact with the teacher and possibly receive corrections.</a>
<a href="#3" id="3">The model takes syllable-segmented input, learns to associate words with meanings under referential uncertainty, discovers compositional combinations of words, learns to make appropriate use of word ordering, and derives grammar rules and classes describing a language fragment.</a>
<a href="#4" id="4">In [47], she gives a very interesting theoretical account of the possible relationship between semantics and syntactic learning, and suggests that “ the acquisition of a conceptual representation of the world is necessary before the acquisition of the syntax of a natural language can start. ” Our system reflects a similar assumption that the learner embarking on language learning has a considerable stock of semantic knowledge.</a>
<a href="#5" id="5">Given a situation and an utterance by the teacher, the learner uses the transitively reduced implication graph {a mathematical formula}Hr in an attempt to determine the meaning of the teacher's utterance as follows.</a>
<a href="#6" id="6">For each successive word of the teacher's utterance, the learner finds the list of all predicate symbols such that there is an edge from the word to the predicate symbol in {a mathematical formula}Hr.</a>
<a href="#7" id="7">Some of the predicate symbols may then be removed from each word's list as follows.</a>
<a href="#8" id="8">The resulting set S of sequences of predicate symbols is then compared with the situation to try to determine the teacher's meaning.</a>
<a href="#9" id="9">In this case, the learner takes the unique meaning as the basis of a possible general form for meanings in the target language.</a>
<a href="#10" id="10">Specifically, the learner uses its prior knowledge of the categories of the predicate symbols to generalize the unique meaning to a general form, by replacing each predicate symbol by its generalization (if any) in the set of categories.</a>
<a href="#11" id="11">In attempting to produce an utterance appropriate to the current situation, the learner finds all the meanings generated by its general forms using predicates from the current situation, and tests each meaning to see if it is denoting in the current situation, producing a set of possible denoting meanings for this situation.</a>
<a href="#12" id="12">To produce one utterance for the current situation, the learner selects one of the possible denoting utterances with a probability proportional to the square of the interaction number stored with the general form used to produce the corresponding meaning.</a>
<a href="#13" id="13">For each variable atom that the learner has encountered in a unique teacher meaning, there is a decision tree that determines what sequence of words to produce for that atom in the context of the whole meaning.</a>
<a href="#14" id="14">Thus, when the learner's utterance is correct there is some probability that the teacher will simply repeat it.</a>
<a href="#15" id="15">The process used by the teacher to analyze the learner's utterance is as follows.</a>
<a href="#16" id="16">If the learner's utterance is equal to one of the correct denoting utterances for the situation, the teacher classifies the learner's utterance as correct.</a>
<a href="#17" id="17">The decision trees are updated using a computed alignment between the teacher's utterance and the learner's understanding of the teacher's meaning, which assigns a (possibly empty) subsequence of words from the utterance to each gap or atom position in the meaning.</a>
<a href="#18" id="18">These interactions show the learner beginning to comprehend the teacher's utterances and acquiring and using both incorrect and correct general forms, producing both incorrect and correct denoting utterances.</a>
<a href="#19" id="19">To avoid this kind of behavior, the basic n-gram model was enhanced to reject randomly generated utterances that are either (1) of a length not observed in the input list of utterances, or (2) contain words {a mathematical formula}w1 and {a mathematical formula}w2 in different positions of the utterance that have occurred in utterances fairly frequently, but never together in the same utterance.</a>
<a href="#20" id="20">This means that if the learner needs to see utterances involving two objects in order to master certain aspects of syntax (for example, cases of articles, adjectives and nouns), the waiting time is noticeably longer in the case of 8-form languages.</a>
<a href="#21" id="21">This is a very simplified model of the interactions in our system: different tokens represent different possible (atomic) utterances, the teacher can always understand what the learner intended to say, and the learner completely corrects its utterance with one exposure to the correct version.</a>
<a href="#22" id="22">Here is the first interaction in which the learner perceives a correction by the teacher, because the meaning intended by the learner and the learner's understanding of the teacher's utterance are the same, but the actual utterances are different (the learner's utterance has an incorrect choice for the article for the word triangle).</a>
<a href="#23" id="23">The learner continues to produce unintelligible utterances, utterances with errors in form and meaning, and correct utterances, while refining its co-occurrence graph (allowing it to understand the teacher's utterances more accurately), acquiring new general forms, and improving its rules for word choice.</a>
</body>
</html>