<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:178">
</head>
<body bgcolor="white">
<a href="#0" id="0">We also develop theoretical analysis that extends the sample complexity result of [29] for dictionary learning using standard sparse coding to the smooth sparse coding case.</a>
<a href="#1" id="1">This result specifically shows how the sample complexity depends on the {a mathematical formula}L1 norm of the kernel function used.</a>
<a href="#2" id="2">The distance function {a mathematical formula} Ρ ( ⋅ , ⋅ ) may be one of the standard distance functions, for example, based on the {a mathematical formula}Lp norm.</a>
<a href="#3" id="3">Alternatively, {a mathematical formula} Ρ ( ⋅ , ⋅ ) may be expressed by domain experts, learned from data before the sparse coding training, or learned jointly with the dictionary and codes during the sparse coding training.</a>
<a href="#4" id="4">Slow rates: When the theorem on covering numbers for the function class {a mathematical formula}F Λ (Theorem 5.1) is used along with Lemma 1 stated in the appendix (corresponding to slow rate generalization bounds) it is straightforward to obtain the following generalization bounds with slow rates for the smooth sparse coding problem.</a>
<a href="#5" id="5">We follow the same procedure described in the previous experiments to construct the dictionary.</a>
</body>
</html>