<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:265">
</head>
<body bgcolor="white">
<a href="#0" id="0">First, benchmarks selected for such competitions tend to emphasize problem instances that are currently hard for existing standalone algorithms (to drive new research on solving strategies) rather than the wide range of both easy and hard instances that would be encountered in practice (which would be appropriately targeted by researchers developing algorithm selectors).</a>
<a href="#1" id="1">Examples of such probing features include the number of search nodes explored within a certain time, the fraction of partial solutions that are disallowed by a certain constraint or clause, the average depth reached before backtracking is required, or characteristics of local minima found quickly using local search.</a>
<a href="#2" id="2">A problem closely related to algorithm selection is the algorithm configuration problem: given a parameterized algorithm A, a set of problem instances I and a performance measure m, find a parameter setting of A that optimizes m on I (see [52] for a formal definition).</a>
<a href="#3" id="3">Some algorithm selectors do not select a single algorithm, but compute a schedule of several algorithms: they apply a to i for a resource budget {a mathematical formula}r âˆˆ R (e.g., CPU time), evaluate the performance metric, evaluate a stopping criterion, and repeat as necessary, taking observations made during the run of a into account.</a>
<a href="#4" id="4">To provide further insight into our algorithm selection scenarios, we applied forward selection [61] to the algorithms and features to determine whether smaller subsets still achieve comparable performance.</a>
<a href="#5" id="5">We accept this caveat since our goal here is to study the ranking of the features and the size of the selected sets, and a more complex, nested approach would have resulted in multiple selected sets.</a>
</body>
</html>