<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:243">
</head>
<body bgcolor="white">
<a href="#0" id="0">Most NERC taggers are supervised statistical systems that extract patterns and term features which are considered to be indications of Named Entity (NE) types using the manually annotated training data (extracting orthographic, linguistic and other types of evidence) and often external knowledge resources.</a>
<a href="#1" id="1">Furthermore, we also stack or accumulate features of the same type of word representation induced from different data sources, trusting each clustering lexicon to a different degree, as shown by the five encoded clustering features in Table 3: two Clark and Word2vec features from different source data and one Brown feature.</a>
<a href="#2" id="2">When using word representations as semi-supervised features for a task like NERC, two principal factors need to be taken into account: (i) the source data or corpus used to induce the word representations and (ii) the actual word representation used to encode our features which in turn modify the weight of our model's parameters in the training process.</a>
<a href="#3" id="3">In other words, combining and stacking different types of clustering features induced over a variety of data sources should help to capture more similarities between different words in the training and test sets, increasing the contribution to the weights of the model parameters in the training process.</a>
<a href="#4" id="4">Contrary to previous suggestions that the larger the number of classes and the corpus used to induced the clusters the better [60], our results provide a number of interesting pointers to choose the appropriate type of corpus and clustering method required for optimal performance.</a>
</body>
</html>