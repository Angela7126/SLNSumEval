<html>
<head>
<meta name="TextLength" content="SENT_NUM:41, WORD_NUM:936">
</head>
<body bgcolor="white">
<a href="#0" id="0">In a sequential auction with multiple bidding agents, the problem of determining the ordering of the items to sell in order to maximize the expected revenue is highly challenging.</a>
<a href="#1" id="1">The challenge is largely due to the fact that the autonomy and private information of the agents heavily influence the outcome of the auction.</a>
<a href="#2" id="2">The main contribution of this paper is two-fold.</a>
<a href="#3" id="3">First, we demonstrate how to apply machine learning techniques to solve the optimal ordering problem in sequential auctions.</a>
<a href="#4" id="4">We learn regression models from historical auctions, which are subsequently used to predict the expected value of orderings for new auctions.</a>
<a href="#5" id="5">Given the learned models, we propose two types of optimization methods: a black-box best-first search approach, and a novel white-box approach that maps learned regression models to integer linear programs (ILP), which can then be solved by any ILP-solver.</a>
<a href="#6" id="6">Although the studied auction design problem is hard, our proposed optimization methods obtain good orderings with high revenues.</a>
<a href="#7" id="7">Our second main contribution is the insight that the internal structure of regression models can be efficiently evaluated inside an ILP solver for optimization purposes.</a>
<a href="#8" id="8">To this end, we provide efficient encodings of regression trees and linear regression models as ILP constraints.</a>
<a href="#9" id="9">This new way of using learned models for optimization is promising.</a>
<a href="#10" id="10">As the experimental results show, it significantly outperforms the black-box best-first search in nearly all settings.</a>
<a href="#11" id="11">Nowadays more and more auctions utilize information technology, which makes it possible to automatically store detailed information about previous auctions along with their selling sequences and the selling price per auctioned item.</a>
<a href="#12" id="12">Our approach to solving the problem of optimal ordering for sequential auctions starts with the historical auction data.</a>
<a href="#13" id="13">We define and compute several relevant features and then use them to learn regression trees and linear regression models for the expected revenue.</a>
<a href="#14" id="14">Given the models, we propose two approaches to find the optimal ordering for a new set of items: (1) a best-first search that uses the models as a black-box to evaluate different orderings of the items; and (2) a novel white-box optimization method that translates the models and the set of items into a mixed-integer program (MIP) and runs this in an ILP-solver (CPLEX).</a>
<a href="#15" id="15">Fig.</a>
<a href="#16" id="16">1 displays the general framework of our approaches using these two optimization methods.</a>
<a href="#17" id="17">In Section 2, we formally introduce the problem of optimal ordering for sequential auctions (OOSA), and then we show how to learn regression models from historical auction data in Section 3 using standard machine learning methods.</a>
<a href="#18" id="18">Based on the learned models, our white-box optimization method and a black-box optimization are introduced to find the optimal ordering for OOSA in Section 4.</a>
<a href="#19" id="19">Extensive experiments are presented in Section 5 where we compare the performance of the two proposed optimization methods using both the learned models and the auction simulator.</a>
<a href="#20" id="20">Before we conclude, we compare and discuss more related works in Section 6.</a>
<a href="#21" id="21">An ordering can be thought of as a sequence of items.</a>
<a href="#22" id="22">However, to the best of our knowledge none of the existing sequence models fit our auction setting, see also Section 6.2.</a>
<a href="#23" id="23">In this work, we view the prediction of an auction's outcome as a regression problem.</a>
<a href="#24" id="24">We split this problem into the subproblems of predicting the value of the auctioned items.</a>
<a href="#25" id="25">We then sum these up to obtain the overall objective function, i.e., the expected revenue {a mathematical formula}P(S) given a set S ({a mathematical formula}|S|=n) of items:{a mathematical formula} where {a mathematical formula}G(sk,J,L) is a regression function that determines the expected value of {a mathematical formula}sk given that J was auctioned before and L will be auctioned afterwards.</a>
<a href="#26" id="26">The main benefit of this representation is that modern machine learning methods can be used to learn this function G from data.</a>
<a href="#27" id="27">In addition, since every item sold represents a single sample, every auction contains many samples that can be used for learning, further reducing the amount of required data.</a>
<a href="#28" id="28">We study two popular regressions functions.</a>
<a href="#29" id="29">We first give an overview in Fig.</a>
<a href="#30" id="30">1 of the connection between the regression models and the optimization models for solving OOSA.</a>
<a href="#31" id="31">Given historical auction data, a regression tree (or a LASSO linear regression function) is learned for each item type.</a>
<a href="#32" id="32">The regression tree (or LASSO) can be used to evaluate the values of selling different items based on the feature values that are computed on a given ordering of the items.</a>
<a href="#33" id="33">The learned regression trees (or LASSO functions) are then used in two ways to model the optimization problem OOSA: (1) Black-box optimization.</a>
<a href="#34" id="34">In this paper, we use a best-first search heuristic to come up orderings of the items, and then use the learned regression trees (or LASSO) to compute the expected revenue of these orderings; (2) White-box optimization.</a>
<a href="#35" id="35">We formulate the optimization problem of finding an optimal ordering as a mixed integer linear program (MIP), which is shown to be automatically constructed from the learned regression tress (or LASSO functions).</a>
<a href="#36" id="36">If we look at the results of the white-box methods built from the learned regression trees, i.e., tree3lp, tree5lp, tree8lp, we notice that tree5lp and tree8lp performed similarly and they are slightly better than tree3lp.</a>
<a href="#37" id="37">This result is consistent with the higher {a mathematical formula}R2 scores of the larger trees.</a>
<a href="#38" id="38">Interestingly, despite their lower {a mathematical formula}R2 scores, the linear regression LP methods return good orderings especially lasso2lp and lasso3lp which are on average better than the three regression tree LP models.</a>
<a href="#39" id="39">Proof</a>
<a href="#40" id="40">The proof follows from the fact that we can use simple regression trees to model the preferences of the two agents from Theorem 1, and evaluating an ordering using these trees can be done in polynomial time.</a>
</body>
</html>