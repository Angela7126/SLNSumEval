<html>
<head>
<meta name="TextLength" content="SENT_NUM:27, WORD_NUM:936">
</head>
<body bgcolor="white">
<a href="#0" id="0">Although the {a mathematical formula}ToM1 agent models his opponent as being able use zero-order theory of mind, agents in our setup do not know the extent of the abilities of their opponents with certainty.</a>
<a href="#1" id="1">Agents form beliefs {a mathematical formula}b(0) in the form of a probability distribution over the opponent ʼ s actions {a mathematical formula}Aj for every game state, such that {a mathematical formula}b(0)(aj;s) represents what the agent believes to be the probability that his opponent will play action {a mathematical formula}aj ∈ Aj given that the game is in situation {a mathematical formula}s ∈ S.</a>
<a href="#2" id="2">We assume:{a mathematical formula}{a mathematical formula} That is, (1) agents assign non-negative probability to their opponent playing a certain action in a certain game state, and (2) the probabilities assigned to each possible opponent action sum up to 1 for each possible game state.</a>
<a href="#3" id="3">For a {a mathematical formula}ToM0 agent, the belief structure {a mathematical formula}b(0) represents the extent of his beliefs concerning his opponent ʼ s behaviour.</a>
<a href="#4" id="4">Given the game ʼ s payoff function and his beliefs about the way his opponent plays the game, a {a mathematical formula}ToM0 agent is able to assign a subjective value {a mathematical formula} Φ i(ai;b(0),s) to playing a certain action {a mathematical formula}ai ∈ Ai in game state {a mathematical formula}s ∈ S, given his beliefs {a mathematical formula}b(0) concerning his opponent ʼ s behaviour.</a>
<a href="#5" id="5">To determine this value, the agent considers how likely he considers it to be that his opponent is going to play some action {a mathematical formula}aj ∈ Aj.</a>
<a href="#6" id="6">If the opponent would play {a mathematical formula}aj, playing {a mathematical formula}ai would yield the agent an immediate payoff {a mathematical formula} Π i(s,(ai,aj)), but it would also cause the game to move forward, and end up in a new state {a mathematical formula}s ′ =T(s,(ai,aj)).</a>
<a href="#7" id="7">The agent then integrates his first-order beliefs {a mathematical formula}b(1), which he believes to correspond to his opponent ʼ s zero-order beliefs, with the prediction that he will play R.{a mathematical formula}{a mathematical formula}{a mathematical formula} These integrated beliefs specify what the agent believes what his opponent ʼ s beliefs are concerning his actions.</a>
<a href="#8" id="8">For example, based on application of his second-order theory of mind, the {a mathematical formula}ToM2 agent believes that his opponent believes that there is an 88% probability that he himself will play R. From the viewpoint of his opponent, the agent then determines what the value would be for playing each of the possible actions, given the integrated beliefs of opponent action.</a>
<a href="#9" id="9">{a mathematical formula}{a mathematical formula}{a mathematical formula} The action that maximizes this value represents the agent ʼ s prediction of the action his opponent is going to play according to his second-order theory of mind.</a>
<a href="#10" id="10">{a mathematical formula} Based on second-order theory of mind, the agent therefore believes his opponent will play P.To make a decision, the agent integrates his zero-order beliefs {a mathematical formula}b(0), his first-order prediction {a mathematical formula}a ˆ j(1)=P (see Example 2), and his second-order prediction {a mathematical formula}a ˆ j(2)=P.</a>
<a href="#11" id="11">Example 2 shows how the agent ʼ s zero-order beliefs and his first-order prediction of opponent behaviour are integrated.</a>
<a href="#12" id="12">Using this confidence {a mathematical formula}c2, the agent also integrates his belief that his opponent is going to play P. In this example, the agent has confidence {a mathematical formula}c2=0.1 in second-order theory of mind.</a>
<a href="#13" id="13">This results in the following integrated beliefs:{a mathematical formula}{a mathematical formula}{a mathematical formula} Based on these integrated beliefs, the agent determines the value for playing each of the actions.</a>
<a href="#14" id="14">{a mathematical formula}{a mathematical formula}{a mathematical formula} The agent then chooses to play the action that maximizes the value.</a>
<a href="#15" id="15">In this case:{a mathematical formula} Based on his integrated beliefs of what the opponent is going to do, the {a mathematical formula}ToM2 agent ʼ s choice is to play S.</a>
<a href="#16" id="16">For every order of theory of mind available to the agent beyond the second-order, say order k, the agent maintains an additional belief structure {a mathematical formula}b(k).</a>
<a href="#17" id="17">These beliefs are used to expand his decision process by modeling the decision process of a {a mathematical formula}(k − 1)st-order theory of mind agent from his opponent ʼ s point of view.</a>
<a href="#18" id="18">The resulting prediction is weighted against the decision process of {a mathematical formula}(k − 1)st-order of theory of mind from his own point of view.</a>
<a href="#19" id="19">The performance of the {a mathematical formula}ToM3 agent and the {a mathematical formula}ToM4 agent suggests that there may be a limit to the effectiveness of application of higher orders of theory of mind.</a>
<a href="#20" id="20">However, since rock – paper – scissors involves three possible opponent actions, the game leaves room for only three unique predictions of the opponent ʼ s next action.</a>
<a href="#21" id="21">The low performance of the {a mathematical formula}ToM3 and {a mathematical formula}ToM4 agents may therefore be caused by specific characteristics of the RPS game, rather than a limit to the effectiveness of application of higher orders of theory of mind.</a>
<a href="#22" id="22">8a shows, these two distinct types of behaviour make it more difficult for the {a mathematical formula}ToM1 agent to accurately model his opponent.</a>
<a href="#23" id="23">In the present model, a {a mathematical formula}ToM1 agent that has a learning speed {a mathematical formula} Λ i<1 believes that his opponent has the same learning speed.</a>
<a href="#24" id="24">As a result, he believes that there is a single action that maximizes the opponent ʼ s expected payoff.</a>
<a href="#25" id="25">However, when his opponent has the maximal learning speed {a mathematical formula} Λ j=1, she actually randomizes her choice over two possible actions.</a>
<a href="#26" id="26">The {a mathematical formula}ToM1 agent is therefore expected to predict his opponent ʼ s behaviour incorrectly in half the cases.</a>
</body>
</html>