<html>
<head>
<meta name="TextLength" content="SENT_NUM:20, WORD_NUM:527">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our algorithms thus allow computing offline strategies in larger games than previously possible (using {a mathematical formula}DO Α Β ).</a>
<a href="#1" id="1">The {a mathematical formula}BI Α Β algorithm first serializes the game and solves the serialized games using the standard alpha-beta algorithm; if the bounds are equal then this value is returned directly (line 3).</a>
<a href="#2" id="2">The following algorithm incorporates this idea to {a mathematical formula}BI Α Β , which leads to additional pruning of the game tree.</a>
<a href="#3" id="3">Similarly to {a mathematical formula}BI Α Β , the algorithm first tests, whether the whole game can be solved by using the serialized variants of the game (line 3).</a>
<a href="#4" id="4">The goal of the best response algorithm is to find the best action from the original unrestricted game against the current strategy of the opponent {a mathematical formula} Σ − i ′ .</a>
<a href="#5" id="5">The performance of algorithms {a mathematical formula}BI Α Β and {a mathematical formula}DO Α Β represent a significant improvement over the results of the pruning algorithm SMAB presented in [38].</a>
<a href="#6" id="6">The advantage of {a mathematical formula}BI Α Β and {a mathematical formula}DO Α Β algorithms that exploit the serialized variants of alpha-beta algorithms is dramatic.</a>
<a href="#7" id="7">This is an easy game for {a mathematical formula}DO Α Β and {a mathematical formula}BI Α Β with a pure NE and both of these algorithms are able to solve the game in less than a second (0.73).</a>
<a href="#8" id="8">We compare all of the approximative sampling algorithms and {a mathematical formula}DO Α Β as a representative of backward induction algorithms, because it was clearly the fastest algorithm in all of the considered games.</a>
<a href="#9" id="9">Next, we analyze the results of the {a mathematical formula}DO Α Β algorithm compared to the sampling algorithms.</a>
<a href="#10" id="10">The results show that even though {a mathematical formula}DO Α Β uses a domain-specific heuristic evaluation function, it does not win significantly against any of the sampling algorithms that do not use any domain knowledge.</a>
<a href="#11" id="11">The performance of the other sampling algorithms is very similar against {a mathematical formula}DO Α Β , with Exp3 winning the least in the reward optimization.</a>
<a href="#12" id="12">The best algorithm in this game variant is RM, which wins against all other sampling algorithms and wins most often against {a mathematical formula}DO Α Β and Exp3.</a>
<a href="#13" id="13">With this modification, UCT already significantly outperforms all algorithms including {a mathematical formula}DO Α Β .</a>
<a href="#14" id="14">{a mathematical formula}DO Α Β is the second best and still winning over the remaining sampling algorithms.</a>
<a href="#15" id="15">{a mathematical formula}DO Α Β wins over all other sampling algorithms.</a>
<a href="#16" id="16">The evaluation function in Tron approximates the situation in the game fairly well; hence, {a mathematical formula}DO Α Β strongly outperforms all other algorithms when they do not use the evaluation function (top).</a>
<a href="#17" id="17">Using the evaluation function improves the performance of all sampling algorithms against {a mathematical formula}DO Α Β and it decreases the differences in performance between each algorithm.</a>
<a href="#18" id="18">This pool includes {a mathematical formula}DO Α Β and each of the sampling algorithms with one setting of the parameter selected based on the results of the offline experiments.</a>
<a href="#19" id="19">Second, {a mathematical formula}DO Α Β with a good evaluation function often wins over the sampling algorithms without a domain specific knowledge.</a>
</body>
</html>