<html>
<head>
<meta name="TextLength" content="SENT_NUM:25, WORD_NUM:602">
</head>
<body bgcolor="white">
<a href="#0" id="0">The problem of ad hoc teamwork revolves around how an agent should cooperate with teammates it knows little about.</a>
<a href="#1" id="1">In this article, we assume that the teammates are given; the ad hoc agent does not select its teammates.</a>
<a href="#2" id="2">However, the ad hoc agent may not know its teammates' behaviors ahead of time; we investigate how an ad hoc agent can reuse knowledge about past teammates to learn quickly about its new teammates.</a>
<a href="#3" id="3">The optimal behavior for the ad hoc agent also depends on how much its teammates react to its actions.</a>
<a href="#4" id="4">Specifically, we explore settings in which the ad hoc agent has prior experiences with past teammates and is trying to use knowledge from these experiences to quickly adapt to new teammates.</a>
<a href="#5" id="5">In this article, we assume that all of the teammates and the ad hoc agent share a common goal.</a>
<a href="#6" id="6">Therefore, the ad hoc agent must observe its teammates to determine their behaviors.</a>
<a href="#7" id="7">Once it knows the behaviors its teammates exhibit, the ad hoc agent can adapt accordingly.</a>
<a href="#8" id="8">We believe that future research into teammates that learn about the ad hoc agent is needed; ad hoc agents should be able to deal with higher amounts of teammate reactivity.</a>
<a href="#9" id="9">[63] which evaluates an ad hoc team agent while considering the teammates and domains it may encounter.</a>
<a href="#10" id="10">It is expected that the differences between these teammates will require the ad hoc agent to adapt and reason about how its actions will influence its teammates' actions.</a>
<a href="#11" id="11">When the ad hoc agent knows its teammates' behaviors, {a mathematical formula}TeamK=1.</a>
<a href="#12" id="12">In addition, the ad hoc agent does not directly observe the actions of its teammates.</a>
<a href="#13" id="13">While the previous section discusses methods for how an ad hoc agent can compute a policy for cooperating with its teammates given a model of its teammates, it does not specify where these models come from.</a>
<a href="#14" id="14">When the ad hoc agent has a limited amount of experiences with its current teammates in addition to extensive experiences with past experiences, it may be able to learn models specific to the current teammates.</a>
<a href="#15" id="15">Note that this may not be the optimal performance of any team, but it is optimal for the ad hoc agent given that the behaviors of its teammates are fixed.</a>
<a href="#16" id="16">The short summary of the approach is that the ad hoc agent either learns about a set of prior teammates or is given some hand-coded information about possible teammates.</a>
<a href="#17" id="17">When an ad hoc agent has a model of both the environment and its teammates, it can use this model to plan about the effects of its actions and how it should adapt to its teammates.</a>
<a href="#18" id="18">The previous sections discuss how an ad hoc agent should cooperate with teammates it has interacted with before as well as how the agent should cooperate with completely new teammates.</a>
<a href="#19" id="19">These results show that the ad hoc agent can do much better than just copying the behavior of its teammates by using PLASTIC-Model.</a>
<a href="#20" id="20">The ad hoc agent does know that these teammates are drawn from the set of hand-coded predators.</a>
<a href="#21" id="21">Ideally, the ad hoc agent should be able to use the observations of its past teammates to better cooperate with its current teammates.</a>
<a href="#22" id="22">PLASTIC-Model performs well even when it has never seen the current teammates before if the ad hoc agent has experience with previous teammates that exhibit similar behaviors.</a>
<a href="#23" id="23">PLASTIC-Model allows the ad hoc agent to adapt to a variety of teammates.</a>
<a href="#24" id="24">The results in this section show that in the HFO domain, PLASTIC-Policy is effective allowing an ad hoc team agent to reuse knowledge from past teammates to improve cooperation with its teammates.</a>
</body>
</html>