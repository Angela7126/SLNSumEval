<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:228">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our RIM approach consists of two phases.</a>
<a href="#1" id="1">In the first phase, we learn macro-operators and action models with the given plan cases {a mathematical formula}C and the incomplete domain {a mathematical formula}M ˜ .</a>
<a href="#2" id="2">In the second phase, we exploit the learned macro-operators and action models in solving new planning problems.</a>
<a href="#3" id="3">In the subsequent subsections, we first address the learning phase in detail, and then describe the planning phase briefly.</a>
<a href="#4" id="4">Our learning framework (the first phase) can be found in Algorithm 4.</a>
<a href="#5" id="5">It begins with the step of collecting sets of predicates P, action schemas A and macro-operator schemas O from incomplete action models {a mathematical formula}A ˜ and plan cases {a mathematical formula}C. In the next two steps, it constructs sets of soft and hard constraints to ensure that the learned domain model can best explain the input plan cases and incomplete action models.</a>
<a href="#6" id="6">Finally, we solve these constraints using a weighted MAX-SAT solver to obtain sets of macro-operators and (refined) action models.</a>
<a href="#7" id="7">We first build soft constraints encoding possible preconditions and effects of actions and macro-operators implied by state transitions in plan cases.</a>
<a href="#8" id="8">We preprocess plan cases using incomplete action models to obtain more state information for building state constraints.</a>
<a href="#9" id="9">To do this, we simply “ execute ” each plan case starting from its initial state, and calculate (incomplete) states between actions using incomplete action models.</a>
</body>
</html>