<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:390">
</head>
<body bgcolor="white">
<a href="#0" id="0">First, labeling data instances is a tedious process and a substantial number of instances must often be labeled before a change to the learning algorithm is noticeable to an end user.</a>
<a href="#1" id="1">However, their work did not evaluate feature labeling in a statistical user study involving a large number of actual end users.</a>
<a href="#2" id="2">In order to evaluate our feature labeling algorithm, we perform an empirical comparison on multiple data sets under ideal conditions, using feature labels obtained from an oracle, and under real-world conditions for one particular dataset, using feature labels harvested from actual end users.</a>
<a href="#3" id="3">Since we were interested in the benefits due solely to feature labeling, we did not compare against methods such as Tandem Learning [29] and dual supervision [2], [33] which allow users to label both features and data instances after the algorithm has been trained.</a>
<a href="#4" id="4">Therefore the oracle study provides an optimistic estimate on the potential gains of using these feature labeling algorithms by providing enough ideal feature labels to benefit the algorithm and by carefully tuning the parameters of the feature labeling algorithms over a large validation set.</a>
<a href="#5" id="5">We then used the end users ʼ data to compare the performance of the same algorithms as in our oracle study, but with smaller validation sets of size 24 (six instances for each class) to simulate a realistic scenario in which end users were able to label only a limited amount of training instances for both a training and a validation set.</a>
<a href="#6" id="6">Most of the algorithms that incorporate feature labels are sensitive to key parameters that control the influence of the feature labels, but these parameters are difficult to set prior to deployment due to the uniqueness of each end user ʼ s data distribution.</a>
<a href="#7" id="7">The performance of the algorithm on 20 Newsgroups hardly improved beyond {a mathematical formula}k=0.5 which might suggest that instances in this dataset formed very few compact clusters in the feature space and the seed (labeled training) instances managed to cover most of them.</a>
<a href="#8" id="8">A naïve implementation of matrix inversion does not scale well to large datasets since the complexity is {a mathematical formula}O(n3) for n instances (where n is the number of training and test instances) and is a roadblock to allowing LWLR-SS-FL to be applied to large datasets in an interactive setting, which is an important requirement of feature labeling [32].</a>
</body>
</html>