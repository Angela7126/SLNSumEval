<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:415">
</head>
<body bgcolor="white">
<a href="#0" id="0">An optimal policy {a mathematical formula} Π ⁎ is any proper policy that minimizes, over all proper policies, the expected cost of reaching a goal state from {a mathematical formula}s0, i.e., {a mathematical formula}V Π ⁎ (s0) ≤ min Π s.t. Π isclosed ⁡ V Π (s0).</a>
<a href="#1" id="1">For a given SSP, {a mathematical formula} Π ⁎ might not be unique; however, the optimal value function {a mathematical formula}V ⁎ , representing for each state s the minimal expected accumulated cost to reach a goal state over all policies, exists and is unique [4].</a>
<a href="#2" id="2">For all optimal policies {a mathematical formula} Π ⁎ and {a mathematical formula}s ∈ S Π ⁎ , we have that {a mathematical formula}V ⁎ (s)=V Π ⁎ (s); formally, {a mathematical formula}V ⁎ is the fixed-point solution for the Bellman Equation(s):{a mathematical formula} Every optimal policy {a mathematical formula} Π ⁎ can be obtained by replacing min by argmin in (2), i.e., {a mathematical formula} Π ⁎ is a greedy policy of {a mathematical formula}V ⁎ :</a>
<a href="#3" id="3">Because convergence to {a mathematical formula}V ⁎ is not feasible in the general case, one solution is to find a value function {a mathematical formula}V ˆ that is at most Ε away from {a mathematical formula}V ⁎ , i.e., {a mathematical formula}|V ˆ (s) − V ⁎ (s)| ≤ Ε for all {a mathematical formula}s ∈ S[2], [12].</a>
<a href="#4" id="4">Given a state s, FF-Hindsight performs the following three steps: (i) it randomly generates a set of nonstationary deterministic problems {a mathematical formula}D starting from s; (ii) it uses FF to solve them; and (iii) it combines the cost of their solutions to estimate the true cost of reaching a goal state from s. Each deterministic problem in {a mathematical formula}D has a fixed horizon and is generated by sampling one outcome of each probabilistic action for each time step.</a>
<a href="#5" id="5">Formally, suppose that a short-sighted SSP {a mathematical formula}Ss,t generated in line 6 of Algorithm 5 has an avoidable dead end (i.e., there exists at least one proper policy Π for {a mathematical formula}Ss,t) thus {a mathematical formula}sd ∉ Ss,t Π for all dead end states {a mathematical formula}sd ∈ Ss,t.</a>
<a href="#6" id="6">Since an optimal policy {a mathematical formula} Π Ss,t ⁎ is computed for {a mathematical formula}Ss,t (line 7), then {a mathematical formula} Π Ss,t ⁎ is one of the existing proper policies by the definition of optimal policies; therefore, the avoidable dead ends are not reached by executing {a mathematical formula} Π Ss,t ⁎ .</a>
</body>
</html>