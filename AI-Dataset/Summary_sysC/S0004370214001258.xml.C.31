<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:321">
</head>
<body bgcolor="white">
<a href="#0" id="0">Instance: A Bayesian network {a mathematical formula}B=(GB,Pr), where V is partitioned into evidence variables E with joint value assignment e, explanation variables H, and intermediate variables I.</a>
<a href="#1" id="1">Instance: A Bayesian network {a mathematical formula}B, partitioned into a set of observed evidence variables E, a set of explanation variables H, a set of ‘ relevant ’ intermediate variables {a mathematical formula}I+ that are marginalized over, and a set of ‘ irrelevant ’ intermediate variables {a mathematical formula}I − that are not marginalized over.</a>
<a href="#2" id="2">Note that MFE is not guaranteed to give the MAP explanation, unless we marginalize over all intermediate variables (i.e., consider all variables to be relevant).</a>
<a href="#3" id="3">When the set of irrelevant variables is non-empty, the most frugal explanation may differ from the MAP explanation, even when using a voting strategy based on all joint value assignments to the irrelevant intermediate variables, since both explanations are computed differently.</a>
<a href="#4" id="4">Take for example the small network with two ternary variables H with values {a mathematical formula}{h1,h2,h3} and I with values {a mathematical formula}{i1,i2,i3}, with I uniformly distributed and H conditioned on I as follows:{a mathematical formula} Now, the most probable explanation of H, marginalized on I, would be {a mathematical formula}H=h2, but the most frugal explanation of H with irrelevant variable I would be {a mathematical formula}H=h1 as this is the most probable explanation for two out of three value assignments to I.</a>
<a href="#5" id="5">Only in borderline cases MAP and MFE are guaranteed to give the same results independent of the number of samples taken and the partition in relevant and irrelevant intermediate variables.</a>
<a href="#6" id="6">This will, for example, be the case when the MAP explanation has a probability of 1 and all the intermediate variables are uniformly distributed.</a>
<a href="#7" id="7">Instance: A Bayesian network {a mathematical formula}B=(GB,Pr), where V is partitioned into evidence variables E with joint value assignment e, explanation variables H, and intermediate variables I, and a designated variable {a mathematical formula}I ∈ I.</a>
</body>
</html>