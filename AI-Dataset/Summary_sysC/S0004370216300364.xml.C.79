<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:559">
</head>
<body bgcolor="white">
<a href="#0" id="0">Regression analysis models assume that the bidding strategy of the opponent could be defined by a formula with unknown parameters; that is, the problem of estimating the bidding strategy of the opponent could be easily reduced to the regression analysis on the utility values of the received offers from the opponent in the agent's own utility space.</a>
<a href="#1" id="1">However, according to the underlying scheme in which they are applied to extract the opponent's preferences, the existing state of the art opponent models (which use a common negotiation setting for estimating the preference order of the negotiation outcomes and are designed and implemented in the Genius framework [36], [37] in the ANAC tournaments) could be categorized into the following [38]:</a>
<a href="#2" id="2">The Value models: are the same as frequency models except that they assume equal and constant values for issue weights and focus on estimating the evaluation values of each issue value instead.</a>
<a href="#3" id="3">Though assuming constant and equal values for issue weights would degrade the model's accuracy, it would also make the agent free of the need for estimating the issue weights.</a>
<a href="#4" id="4">In other words, the preference profile of an agent is modeled as a linear combination of a set of weights (which measures the relative importance of the negotiation issues) and a number of individual utility functions (or evaluation functions) which calculate the utility of a possible value for a negotiation issue.</a>
<a href="#5" id="5">The objective here is to minimize the error E by searching for the best preference profile which yields the minimum error between the estimated offer utility values, according to the bidding behavior of the opponent ({a mathematical formula}td) and the estimated offer utility values according to the current values of the preference profile of the opponent ({a mathematical formula} ∑ i=1nevaliOP( Ω i).wiOP) for all the training examples in D. The direction of steepest descent along the error surface can be determined by computing the gradient or derivative of E with respect to each component of the opponent profile vector {a mathematical formula}k → .</a>
<a href="#6" id="6">Now, in order to find the best preference profile, in the incremental gradient descent algorithm, after each training instance {a mathematical formula}d( Ω ) → is met, Equations (21) and (22) are applied, and the evaluation values for the values that have been observed in the bid ({a mathematical formula} 〈 Ω 1, ⋯ , Ω n 〉 ) and their weight values are updated.</a>
<a href="#7" id="7">The problem of preference modeling in bilateral multi issue negotiations through supervised learning methods can be separated in two sub-problems: 1) estimating the utility values of the opponent's offer history (the history of the offers received from the opponent through the negotiation session) and 2) extracting the estimated utility function (or the preference profile) of the opponent from the opponent's offer history.</a>
<a href="#8" id="8">To evaluate the proposed POPPONENT model, two separate experimental settings are applied for assessing its accuracy and performance (in real world negotiation examples) compared to the available opponent models.</a>
<a href="#9" id="9">[38], there exist the following three features of a negotiation scenario that significantly influence the ability of the opponent model in estimating the opponent's preferences in an accurate manner [38]:</a>
<a href="#10" id="10">8, we show how the MBGD search method seeks to minimize Standard Error (Equation (5)) by converging towards zero, while this proposed POPPONENT model is being trained against a simple Time-Dependent Agent in a total of 5000 rounds.</a>
</body>
</html>