<html>
<head>
<meta name="TextLength" content="SENT_NUM:18, WORD_NUM:1013">
</head>
<body bgcolor="white">
<a href="#0" id="0">1 illustrates this context: the human and the robot share a common space and exchange information through multiple modalities (we specifically consider verbal communication, deictic gestures and social gaze), and the robot is expected to achieve interactive object manipulation, fetch and carry tasks and other similar chores by taking into account, at every stage, the intentions, beliefs, perspectives, skills of its human partner.</a>
<a href="#1" id="1">An active knowledge base (Oro), conveniently thought as a semantic blackboard, connects most of the modules: the geometric reasoning module (Spark) produces at relatively high frequency symbolic assertions describing the state of the robot environment and its evolution over time.</a>
<a href="#2" id="2">As for any cognitive system, this fundamental interaction between knowledge and actions is central to our approach as well, and typically involves the dialogue module to acquire desires from the other agents, and the planner and the execution controller to first decide to take into account (or not) an incoming desire as a goal, and then to generate and manage intentions from these goals through the symbolic task planner.</a>
<a href="#3" id="3">The main ones include situation assessment, action monitoring and processing of non-imperative speech (including performative dialogue that can possibly change the internal state of the robot, but does not lead directly to the creation of desires, like assertion of new facts or question answering).</a>
<a href="#4" id="4">This architecture design (a central knowledge base that essentially appears as a passive component to the rest of the system – even though it actually actively processes the knowledge pool in the background to perform inferences) departs from other approaches like the CAST model [31] where knowledge is represented as a diffuse, pervasive resource, or the CRAM/KnowRob architecture [32] where the knowledge base is an active hub that pro-actively queries perceptual components to acquire knowledge.</a>
<a href="#5" id="5">Our ‘ bottom-up ” design process of the ontology is apparent on this figure: only the subclasses relevant to the context of service robotics in an human-like environment are asserted: For performance reasons as well as clarity, we have decided against an extended conceptual coverage of what “ partially tangible things ” might be.</a>
<a href="#6" id="6">This represents an important cognitive skill, in particular in the human – robot interaction context: in this situation, the link that the robot has to establish between percepts and symbols must map as well as possible to the human representations in order to effectively support communication.</a>
<a href="#7" id="7">The different components that we have mentioned so far exhibit grounding mechanisms: geometric reasoning and dialogue processing modules constantly build and push new symbolic contents about the world to the knowledge base.</a>
<a href="#8" id="8">Besides, Oro server implements several algorithms (presented in [17]) to identify similarities and differences between concepts (classes or instances): the Common Ancestors algorithm, useful to determine the most specific class(es) that include a given set of individuals; the First Different Ancestors algorithm that returns what can be intuitively understood as the most generic types that differentiate two concepts; and clarification and discrimination algorithms that play a key role in the process of interactive grounding of the semantics of concepts (we discuss this process in section 3.3).</a>
<a href="#9" id="9">We rely however on this mechanism in certain cases: some modules like the natural language processor use the short term memory profile to mark concepts that are currently manipulated by the robot as active concepts: if a human asks the robot “ Give me all red objects ” , the human, the Give action, and every red objects that are found are marked as active concepts by inserting statements such as 〈 HUMAN type ActiveConcept 〉 in the short-term memory (which can be considered, in this case, to be a working memory).</a>
<a href="#10" id="10">Full human action and activity recognition is a task that requires knowledge and reasoning both on high-level facts like goals, intentions and plans, as well as bottom-up data from human and object motions.</a>
<a href="#11" id="11">In its current form, our situation assessment module makes two assumptions: the objects are known in advance (hence, we can rely on proper 3D CAD model for spatial reasoning) and the robot benefits of an nearly perfect perception, made possible by the use of fiducial markers.</a>
<a href="#12" id="12">While Spark algorithms do not concern themselves with the nature of the input sources, and would work equally well with a full object recognition stack, we did not investigate this research area so far.</a>
<a href="#13" id="13">Combining the above criteria, we yield shared plans with desirable interaction features like having the human engaged in a number of tasks while her overall level of efforts remains low, or avoiding having the human to wait for the robot by preventing the action streams from having too many causal links between them.</a>
<a href="#14" id="14">As HATP is a generic symbolic task planner and does not enforce any abstraction level for the planning domain, we have designed a planning domain made of top-level tasks whose semantics are close to the one used in the human – robot dialogue: the planner domain effectively contains concepts like Give, table, isOn.</a>
<a href="#15" id="15">We first discuss how embodied cognition is an essential challenge in human – robot interaction; we rephrase then the requirements of joint actions in terms of five questions; we discuss the importance of building and maintaining a multi-level model of the human; and we finally reflect on the importance of explicit knowledge management in robotic architectures that deal with human-level semantics and state in that respect the current limits of our logic framework.</a>
<a href="#16" id="16">While the task of describing all the (dynamic) human models that are useful to robots is immense (if doable at all), we claim that it is possible to devise and use such models in limited, but still interesting and useful, contexts such as collaborative human – robot objects manipulation, fetch-and-carry and associated activities in home or work environments.</a>
<a href="#17" id="17">In our architecture, perspective taking, for instance, is tightly connected to the symbolic knowledge models, and since our knowledge base allows for storage of one knowledge model per agent, we have been able to endow the robot with a simple theory of mind (as explained in section 3.1.2): we explicitly model what the robot knows about its partners in a symbolic way.</a>
</body>
</html>