<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:410">
</head>
<body bgcolor="white">
<a href="#0" id="0">The approach brings together two main advantages: (1) it provides a unified representation for all linguistic items, enabling the meaningful comparison of arbitrary items, irrespective of their scales or the linguistic levels they belong to (e.g., the phrase take a walk to the verb stroll); (2) it disambiguates linguistic items to a set of intended concepts prior to modeling and, hence, it is able to identify the semantic similarities that exist at the deepest sense level, independently of the text's surface forms or any semantic ambiguity therein.</a>
<a href="#1" id="1">Our technique models arbitrary linguistic items through a unified representation, called semantic signature, which is a probability distribution over concepts, word senses, or words in a lexicon.</a>
<a href="#2" id="2">Thanks to this unified representation, our approach can compute the similarity of linguistic items at and across arbitrary levels, from word senses to texts.</a>
<a href="#3" id="3">From the above examples we observe that the same task of semantic similarity involves an inherently different focus as we move from one linguistic level to another: the similarity for the case of senses and words is characterized by the direct similarity of the concepts they surrogate, while for larger textual items similarity denotes the amount of overlapping information between the two items.</a>
<a href="#4" id="4">In fact, to our estimate, less than 20% of word entries in Wiktionary are provided with at least one lexical semantic relation (e.g., synonymy and hypernymy).</a>
<a href="#5" id="5">As a result, attempts at exploiting these pre-defined relations for the transformation of Wiktionary into an ontology generally fail, as they can only produce sparse semantic networks with many of the nodes left in isolation [113].</a>
<a href="#6" id="6">This demonstrates that our transformation of semantic signatures into ordered lists of concepts and our similarity calculation by rank comparison are helpful.</a>
<a href="#7" id="7">As mentioned earlier, previous approaches for measuring similarity between concepts often rely on the path length between two synsets in the WordNet graph or their information content.</a>
<a href="#8" id="8">{sup:22} A comparison between Table 12 and Table 2, Table 3, which list the ten most related terms to the same three words{sup:23} in the automatically-induced networks, reveals the reasons behind the better performance of our manually-crafted semantic networks: (1) the edges in the automatically-induced networks connect synonyms or highly-similar words only, whereas the manually-crafted networks benefit from a wider set of relations of various types (e.g., print{sup:2}v to paper{sup:1}n, debrick{sup:2}v to smartphone{sup:1}n, and abortion_pill{sup:1}n to terminate{sup:1}v); (2) sense-level distinctions provided by the WordNet and Wiktionary graphs result in more accurate representations of meaning in the semantic signatures.</a>
</body>
</html>