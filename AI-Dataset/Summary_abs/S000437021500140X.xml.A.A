<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:267">
</head>
<body bgcolor="white">
<a href="#0" id="0">This paper describes a novel method for building affectively intelligent human-interactive agents.</a>
<a href="#1" id="1">The method is based on a key sociological insight that has been developed and extensively verified over the last twenty years, but has yet to make an impact in artificial intelligence.</a>
<a href="#2" id="2">The insight is that resource bounded humans will, by default, act to maintain affective consistency.</a>
<a href="#3" id="3">Humans have culturally shared fundamental affective sentiments about identities, behaviours, and objects, and they act so that the transient affective sentiments created during interactions confirm the fundamental sentiments.</a>
<a href="#4" id="4">Humans seek and create situations that confirm or are consistent with, and avoid and suppress situations that disconfirm or are inconsistent with, their culturally shared affective sentiments.</a>
<a href="#5" id="5">This “affect control principle” has been shown to be a powerful predictor of human behaviour.</a>
<a href="#6" id="6">In this paper, we present a probabilistic and decision-theoretic generalisation of this principle, and we demonstrate how it can be leveraged to build affectively intelligent artificial agents.</a>
<a href="#7" id="7">The new model, called BayesAct, can maintain multiple hypotheses about sentiments simultaneously as a probability distribution, and can make use of an explicit utility function to make value-directed action choices.</a>
<a href="#8" id="8">This allows the model to generate affectively intelligent interactions with people by learning about their identity, predicting their behaviours using the affect control principle, and taking actions that are simultaneously goal-directed and affect-sensitive.</a>
<a href="#9" id="9">We demonstrate this generalisation with a set of simulations.</a>
<a href="#10" id="10">We then show how our model can be used as an emotional “plug-in” for artificially intelligent systems that interact with humans in two different settings: an exam practice assistant (tutor) and an assistive device for persons with a cognitive disability.</a>
</body>
</html>