<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:350">
</head>
<body bgcolor="white">
<a href="#0" id="0">Cargo-bearing unmanned aerial vehicles (UAVs) have tremendous potential to assist humans by delivering food, medicine, and other supplies.</a>
<a href="#1" id="1">For time-critical cargo delivery tasks, UAVs need to be able to quickly navigate their environments and deliver suspended payloads with bounded load displacement.</a>
<a href="#2" id="2">As a constraint balancing task for joint UAV-suspended load system dynamics, this task poses a challenge.</a>
<a href="#3" id="3">This article presents a reinforcement learning approach for aerial cargo delivery tasks in environments with static obstacles.</a>
<a href="#4" id="4">We first learn a minimal residual oscillations task policy in obstacle-free environments using a specifically designed feature vector for value function approximation that allows generalization beyond the training domain.</a>
<a href="#5" id="5">The method works in continuous state and discrete action spaces.</a>
<a href="#6" id="6">Since planning for aerial cargo requires very large action space (over 106 actions) that is impractical for learning, we define formal conditions for a class of robotics problems where learning can occur in a simplified problem space and successfully transfer to a broader problem space.</a>
<a href="#7" id="7">Exploiting these guarantees and relying on the discrete action space, we learn the swing-free policy in a subspace several orders of magnitude smaller, and later develop a method for swing-free trajectory planning along a path.</a>
<a href="#8" id="8">As an extension to tasks in environments with static obstacles where the load displacement needs to be bounded throughout the trajectory, sampling-based motion planning generates collision-free paths.</a>
<a href="#9" id="9">Next, a reinforcement learning agent transforms these paths into trajectories that maintain the bound on the load displacement while following the collision-free path in a timely manner.</a>
<a href="#10" id="10">We verify the approach both in simulation and in experiments on a quadrotor with suspended load and verify the method's safety and feasibility through a demonstration where a quadrotor delivers an open container of liquid to a human subject.</a>
<a href="#11" id="11">The contributions of this work are two-fold.</a>
<a href="#12" id="12">First, this article presents a solution to a challenging, and vital problem of planning a constraint-balancing task for an inherently unstable non-linear system in the presence of obstacles.</a>
<a href="#13" id="13">Second, AI and robotics researchers can both benefit from the provided theoretical guarantees of system stability on a class of constraint-balancing tasks that occur in very large action spaces.</a>
</body>
</html>