<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:185">
</head>
<body bgcolor="white">
<a href="#0" id="0">This work proposes a novel high-level paradigm, agent planning programs, for modeling agents behavior, which suitably mixes automated planning with agent-oriented programming.</a>
<a href="#1" id="1">Agent planning programs are finite-state programs, possibly containing loops, whose atomic instructions consist of a guard, a maintenance goal, and an achievement goal, which act as precondition-invariance-postcondition assertions in program specification.</a>
<a href="#2" id="2">Such programs are to be executed in possibly nondeterministic planning domains and their execution requires generating plans that meet the goals specified in the atomic instructions, while respecting the program control flow.</a>
<a href="#3" id="3">In this paper, we define the problem of automatically synthesizing the required plans to execute an agent planning program, propose a solution technique based on model checking of two-player game structures, and use it to characterize the worst-case computational complexity of the problem as EXPTIME-complete.</a>
<a href="#4" id="4">Then, we consider the case of deterministic domains and propose a different technique to solve agent planning programs, which is based on iteratively solving classical planning problems and on exploiting goal preferences and plan adaptation methods.</a>
<a href="#5" id="5">Finally, we study the effectiveness of this approach for deterministic domains through an experimental analysis on well-known planning domains.</a>
</body>
</html>