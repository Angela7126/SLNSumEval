<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:179">
</head>
<body bgcolor="white">
<a href="#0" id="0">This paper presents an approach to creating a semantic map of an indoor environment incrementally and in closed loop, based on a series of 3D point clouds captured by a mobile robot using an RGB-D camera.</a>
<a href="#1" id="1">Based on a semantic model about furniture objects (represented in an OWL-DL ontology with rules attached), we generate hypotheses for locations and 6DoF poses of object instances and verify them by matching a geometric model of the object (given as a CAD model) into the point cloud.</a>
<a href="#2" id="2">The result, in addition to the registered point cloud, is a consistent mesh representation of the environment, further enriched by object models corresponding to the detected pieces of furniture.</a>
<a href="#3" id="3">We demonstrate the robustness of our approach against occlusion and aperture limitations of the RGB-D frames, and against differences between the CAD models and the real objects.</a>
<a href="#4" id="4">We evaluate the complete system on two challenging datasets featuring partial visibility and totaling over 800 frames.</a>
<a href="#5" id="5">The results show complementary strengths and weaknesses of processing each frame directly vs.</a>
<a href="#6" id="6">processing the fully registered scene, which accord with intuitive expectations.</a>
</body>
</html>