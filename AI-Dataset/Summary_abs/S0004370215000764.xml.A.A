<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:261">
</head>
<body bgcolor="white">
<a href="#0" id="0">Reinforcement Learning (RL) agents are typically deployed to learn a specific, concrete task based on a pre-defined reward function.</a>
<a href="#1" id="1">However, in some cases an agent may be able to gain experience in the domain prior to being given a task.</a>
<a href="#2" id="2">In such cases, intrinsic motivation can be used to enable the agent to learn a useful model of the environment that is likely to help it learn its eventual tasks more efficiently.</a>
<a href="#3" id="3">This paradigm fits robots particularly well, as they need to learn about their own dynamics and affordances which can be applied to many different tasks.</a>
<a href="#4" id="4">This article presents the texplore with Variance-And-Novelty-Intrinsic-Rewards algorithm (texplore-vanir), an intrinsically motivated model-based RL algorithm.</a>
<a href="#5" id="5">The algorithm learns models of the transition dynamics of a domain using random forests.</a>
<a href="#6" id="6">It calculates two different intrinsic motivations from this model: one to explore where the model is uncertain, and one to acquire novel experiences that the model has not yet been trained on.</a>
<a href="#7" id="7">This article presents experiments demonstrating that the combination of these two intrinsic rewards enables the algorithm to learn an accurate model of a domain with no external rewards and that the learned model can be used afterward to perform tasks in the domain.</a>
<a href="#8" id="8">While learning the model, the agent explores the domain in a developing and curious way, progressively learning more complex skills.</a>
<a href="#9" id="9">In addition, the experiments show that combining the agent's intrinsic rewards with external task rewards enables the agent to learn faster than using external rewards alone.</a>
<a href="#10" id="10">We also present results demonstrating the applicability of this approach to learning on robots.</a>
</body>
</html>