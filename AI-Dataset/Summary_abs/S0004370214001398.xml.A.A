<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:319">
</head>
<body bgcolor="white">
<a href="#0" id="0">Anticipation can enhance the capability of a robot in its interaction with humans, where the robot predicts the humans' intention for selecting its own action.</a>
<a href="#1" id="1">We present a novel framework of anticipatory action selection for human–robot interaction, which is capable to handle nonlinear and stochastic human behaviors such as table tennis strokes and allows the robot to choose the optimal action based on prediction of the human partner's intention with uncertainty.</a>
<a href="#2" id="2">The presented framework is generic and can be used in many human–robot interaction scenarios, for example, in navigation and human–robot co-manipulation.</a>
<a href="#3" id="3">In this article, we conduct a case study on human–robot table tennis.</a>
<a href="#4" id="4">Due to the limited amount of time for executing hitting movements, a robot usually needs to initiate its hitting movement before the opponent hits the ball, which requires the robot to be anticipatory based on visual observation of the opponent's movement.</a>
<a href="#5" id="5">Previous work on Intention-Driven Dynamics Models (IDDM) allowed the robot to predict the intended target of the opponent.</a>
<a href="#6" id="6">In this article, we address the problem of action selection and optimal timing for initiating a chosen action by formulating the anticipatory action selection as a Partially Observable Markov Decision Process (POMDP), where the transition and observation are modeled by the IDDM framework.</a>
<a href="#7" id="7">We present two approaches to anticipatory action selection based on the POMDP formulation, i.e., a model-free policy learning method based on Least-Squares Policy Iteration (LSPI) that employs the IDDM for belief updates, and a model-based Monte-Carlo Planning (MCP) method, which benefits from the transition and observation model by the IDDM.</a>
<a href="#8" id="8">Experimental results using real data in a simulated environment show the importance of anticipatory action selection, and that POMDPs are suitable to formulate the anticipatory action selection problem by taking into account the uncertainties in prediction.</a>
<a href="#9" id="9">We also show that existing algorithms for POMDPs, such as LSPI and MCP, can be applied to substantially improve the robot's performance in its interaction with humans.</a>
</body>
</html>