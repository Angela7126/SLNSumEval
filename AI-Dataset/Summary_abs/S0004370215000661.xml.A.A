<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:290">
</head>
<body bgcolor="white">
<a href="#0" id="0">The inclusion of robots in our society is imminent, such as service robots.</a>
<a href="#1" id="1">Robots are now capable of reliably manipulating objects in our daily lives but only when combined with artificial intelligence (AI) techniques for planning and decision-making, which allow a machine to determine how a task can be completed successfully.</a>
<a href="#2" id="2">To perform decision making, AI planning methods use a set of planning operators to code the state changes in the environment produced by a robotic action.</a>
<a href="#3" id="3">Given a specific goal, the planner then searches for the best sequence of planning operators, i.e., the best plan that leads through the state space to satisfy the goal.</a>
<a href="#4" id="4">In principle, planning operators can be hand-coded, but this is impractical for applications that involve many possible state transitions.</a>
<a href="#5" id="5">An alternative is to learn them automatically from experience, which is most efficient when there is a human teacher.</a>
<a href="#6" id="6">In this study, we propose a simple and efficient decision-making framework for this purpose.</a>
<a href="#7" id="7">The robot executes its plan in a step-wise manner and any planning impasse produced by missing operators is resolved online by asking a human teacher for the next action to execute.</a>
<a href="#8" id="8">Based on the observed state transitions, this approach rapidly generates the missing operators by evaluating the relevance of several causeâ€“effect alternatives in parallel using a probability estimate, which compensates for the high uncertainty that is inherent when learning from a small number of samples.</a>
<a href="#9" id="9">We evaluated the validity of our approach in simulated and real environments, where it was benchmarked against previous methods.</a>
<a href="#10" id="10">Humans learn in the same incremental manner, so we consider that our approach may be a better alternative to existing learning paradigms, which require offline learning, a significant amount of previous knowledge, or a large number of samples.</a>
</body>
</html>