<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Joint search with self-interested agents and the failure of cooperation enhancers.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Consider the problem of a CS graduate student named Jill, whose paper was accepted to one of the top conferences in the field and now needs to search for a way of traveling to the conference. While Jill knows there are many options to travel to the conference venue (e.g., different flights of diverse airlines to nearby airports and different means of transportation from each airport) she does not know a priori their feasibility of getting her to the conference on time, and more importantly, the cost of each option. Checking an alternative potentially involves several activities (e.g., checking locations on the map and checking the companies' web-sites for routes, timetables, fares and availability) thus incurs some “opportunity cost”. Therefore Jill will not necessarily seek the cheapest alternative that can be found, but rather at any time throughout the process she will weigh the benefits of additional search against its costs. The optimal search strategy dictates continued search only insofar as its expected utility is greater than its associated cost.
     </paragraph>
     <paragraph>
      The above setting is the archetypal setting of costly search[12], [70], [51], [30], [34], [13], [26] (which essence is “optimal stopping”). In general, the setting considers a decision maker (a “searcher”) that needs to choose one of several available opportunities, any of which is associated with some value to her. The value of each opportunity, e.g., the price, but more generally: expense, reward, utility, is a priori unknown to the searcher however can be obtained for a cost, denoted “search cost” (either monetary or in terms of resources that need to be consumed). The value and search costs are assumed to be measured on the same scale and the searcher can obtain the value of as many opportunities requested, incurring the search cost of each of them. The goal of the searcher is to maximize her overall expected utility, defined as the value of the opportunity eventually picked minus the accumulated search costs. A strategy for this problem is a mapping from prior findings to the next action – which can be either terminated the search, or continue by checking another specific opportunity.{sup:1} The problem as formulated above applies to a variety of real-world situations, including: job search, buying and selling goods, house search, technology R&amp;D, making decisions on a bank to deposit funds, a vacation, where to drill an oil well, or a path to route packets, and many more [47], [70], [41], [64].
     </paragraph>
     <paragraph>
      At times, not a single but rather a group of agents may benefit from the fruits of the search. In our example, Jill's advisor can ask another student from her research group, Jack, who will be attending the same conference, to join Jill in checking different alternatives for traveling to its location, i.e., execute the search jointly. Numerous other examples of joint search can be found in other domains. For example, a drilling company may send multiple agents to explore possible drilling sites, and the best site of all those found by all agents will be chosen. Similarly when looking to fill-in a position, HR managers can interview candidates in parallel and recruit the best candidate found. The benefits of the multi-agent joint search is twofold. First, since each search result can benefit many agents, the relative cost of search is reduced, and the overall welfare increases. Secondly, the search space can be divided according to the expertise of the different agents, if such expertise exists.{sup:2}
     </paragraph>
     <paragraph>
      While multi-agent search has been considered in the past, it has been limited to the case of a single agent (e.g., “a representative agent”) searching on behalf of the group [25], [63], [11], [43], [10], [62]. More important, most previous work assumes that the agents are fully cooperative, and that their shared goal is to maximize the joint utility. While this may be the case in some situations, it is not so in a growing number of others. Rather, agents are frequently self-interested, i.e., may represent different entities, and attempt to maximize their individual utility rather than the joint utility [58], [16], [42], [37]. A selfish agent will engage in search only if it is individually beneficial. Moreover, if other agents search, it will prefer to take advantage of their search, rather than do the work itself. For example, Jill may find it more beneficial to spend her time working on her research or resting and rely on Jack's findings. The analysis of such settings calls for a strategic, incentive driven approach, seeking stable, equilibrium solutions.
     </paragraph>
     <paragraph>
      In this paper we supply a comprehensive analysis of a model of joint search, both for the case of fully cooperative and self-interested agents. For the fully-cooperative case the optimal strategy is proved to be based on the reservation-value (threshold). For the self-interested-agents case we prove a specific structure of the strategies used in equilibrium, wherein each agent first determines whether it will engage in search at all, and if so it inevitably uses a reservation-value-based search strategy. The analysis for this case considers Bayesian Nash equilibria, introducing the sets of equations that need to be solved to extract agents' strategies and the conditions that need to be checked for validating the stability of these solutions. The analysis for both settings is extended for the case where communication is enabled throughout the search process such that findings are shared continuously rather than only at the end of the process.
     </paragraph>
     <paragraph>
      The analysis facilitates demonstrating that methods and instruments (termed “enhancers”) that are easily proved to be beneficial in the fully cooperative case, can actually have a negative impact, both on individual and overall performance, in the self-interested case. The explanation for the phenomena is that when the agents are self-interested they might prefer to limit their individual search efforts while counting on potential findings of others. In this case, many potential solutions, in the form of search strategies that are beneficial from the individual and overall expected utility point of view, become unstable, and the resulting stable solutions are such that the agents find it beneficial to search to a lesser extent.
     </paragraph>
     <paragraph>
      One key aspect of joint search that the paper emphasizes is communication between the agents along the search process. Communication is known to be a critical enhancer of joint search with fully cooperative agents [56], [54] and of coordination between agents in general [57]. Alas, as demonstrated in later sections, the use of communication by the self-interested agents in joint search often results in substantial performance degradation (both individually and in total). This stems from a somewhat unique characteristic of the value an individual finds in communication in the model considered – a self-interested agent finds the communication to be beneficial only when it receives a report of a favorable finding from another agent. When the agent is the one to report, the report may lead to a reduction in the extent of search carried out by all other agents, and consequently to an expected loss for the agent.
     </paragraph>
     <paragraph>
      The study of the effect of different joint search “enhancers”, and in particular communication throughout the process, which often turns out to be counter-intuitive, provides market designers and platform owners with a better understanding of the benefit and usefulness of enabling such search “enhancers” in their systems. In the context of the Jack and Jill example the implication for the student's advisor can potentially be that it is better to divide all students in the group who need to attend the conference into sub-groups, each executing the joint search separately or ask them to execute the joint search with no communication between them (e.g., have them work on computers located at different offices so they cannot see each other's findings).
     </paragraph>
     <paragraph>
      In the following section we formally present the model of joint search. In Section 3 we detail the model analysis and provide the formal proof of the benefit of the enhancers discussed above when the agents are fully cooperative. In Section 4 we illustrate the equilibrium dynamics and resulting performance under different settings, giving evidence to the potential reverse effect of the enhancers analyzed in the paper. Related work is surveyed in Section 5. Finally, we conclude and discuss directions for future research in Section 6.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      The model
     </section-title>
     <paragraph>
      We first formally present the model and then give the appropriate justifications for the assumptions made.
     </paragraph>
     <section label="2.1">
      <section-title>
       Model assumptions
      </section-title>
      <paragraph>
       The model considers a set {a mathematical formula}K={A1,...,Ak} of fully-rational agents, all interested in individually achieving a similar goal.{sup:3} In order to achieve its goal, any agent {a mathematical formula}Ai needs to pick one of several opportunities available to it, which differ in their value for the agent (where the value represents either an expense or utility). The value of each opportunity is a priori unknown to the agent – only the probability distribution function from which the values of the different opportunities are drawn, denoted {a mathematical formula}fi(x), is known. The process of revealing the value of an opportunity (denoted “exploring”) incurs a cost, denoted {a mathematical formula}ci. The cost {a mathematical formula}ci and the distribution {a mathematical formula}fi(x) are defined in the agent's level to support settings where different agents have different skills and capabilities. The agent thus needs to “search”, i.e., explore the value of some of the opportunities and eventually pick one of the values revealed (i.e., recall is permitted). It is assumed that costs and opportunity values are additive and each agent is interested in maximizing its expected utility, defined as the value from the opportunity eventually picked minus the costs accumulated along the search process. The model assumes that the agents are constrained by a common search horizon of n time periods and that in each period each agent can explore at most one opportunity (while incurring the appropriate cost).
      </paragraph>
      <paragraph>
       The model assumes that each opportunity which value was obtained by an agent is applicable to all the other agents. Furthermore, it is assumed there is no limit on the number of agents that can benefit from a single opportunity, and that the utility from an opportunity is the same for all agents that choose to use it, regardless of their number or the search strategy they use.
      </paragraph>
      <paragraph>
       Given the above model formulation, the agents have an incentive to cooperate in the sense of exchanging information regarding their search findings. The information sharing process is assumed to be reliable and costless (or incurs a fixed global cost).{sup:4} The agents are assumed to be truthful, when searching jointly, in the sense that they always report the true values they obtain and never conceal findings. Furthermore, it is assumed that the overall number of opportunities available to the agents is greater than the maximum number of opportunities the agents can potentially explore jointly, {a mathematical formula}k⋅n, and that the agents can distinguish between the different opportunities and ensure that none of the opportunities is explored by more than one agent (i.e., no overlap). Finally, it is assumed that when engaging in a joint search all agents are a priori acquainted with the probability distribution functions and search costs of all agents, i.e., the only possible difference in the information available to the different agents throughout the joint search is their own findings and the findings of others.
      </paragraph>
      <paragraph>
       We distinguish between four model variants of joint search, differing only by the nature of the agents (“fully cooperative” versus “self-interested”) and the way communication is applied (no communication throughout search versus continuous communication throughout search). In the self-interested case, each agent attempts to maximize its individual expected utility as defined above. In the fully cooperative case, the agents are interested in the sum of the individual expected utilities, hence the optimal joint search strategy is the overall-expected-utility-maximizing strategy. The way communication is applied reflects the way findings are shared. With no communication throughout the search findings are shared only when all individual searches are completed. In the case of continuous communication, each finding of each agent is immediately (reliably) broadcast to all other agents. Meaning that the agents must broadcast their finding upon exploring an opportunity and it is not up to them to decide whether to do so or not. It is assumed that when the agents communicate only at the end of the search they can learn about whether or not others have engaged in search to some extent only at the end of the process. For the case with continuous communication the agent can realize at the end of each period which of the other agents engaged in search during that period and their findings. Finally, we assume that findings are not discounted over time, thus all agents will necessarily prefer waiting for the other agents to terminate their search before accepting an opportunity.
      </paragraph>
      <paragraph>
       The main question in the fully cooperative case is how to execute the groups' joint search optimally, i.e., such that the overall expected utility is maximized. In the self-interested case, the main question is which search strategies will be used by the individual agents in equilibrium.
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Assumptions' justification
      </section-title>
      <paragraph>
       The characterization of the individual agent's search model given above is standard and has been widely used in prior work [34], [30], [12], [49], [79], [59]. Taking the Jack and Jill example from the introduction, each agent represents a student, interested in purchasing the same well-defined, however complex, service (transportation to the conference venue). Opportunities represent alternative combinations of different segments, each possibly executed with a different means of transportation, departing originally from the university and arriving eventually to the specified destination. Opportunities differ in their overall cost (i.e., represent an expense). In order to find the applicability and the cost of an opportunity, the student needs to spend time searching online, visiting different web-sites and checking various related details, as described in the introduction. The search is thus costly in the sense of passing up the next best alternative use of that time (termed “opportunity costs” in economics). The students are assumed to be acquainted with the price distribution that characterizes opportunities [76], [78], [32], primarily based on past experience or market characteristics.{sup:5} Each student, therefore, attempts to minimize her total expense, defined as the sum of the cost at which the trip is eventually executed and the costs incurred along the process of checking alternatives. The number of alternatives that can potentially be evaluated in this case can be constrained either by the total number of alternatives that can be found online or by a deadline set by the students' advisor for finishing their search (e.g., the trip needs to be approved by some office which closes at 5 pm). Similar mapping to the above costly search problem can be made for any of the applications discussed in the previous section.
      </paragraph>
      <paragraph>
       Continuing with the above example, cooperation between the students can be either imposed by their advisor or initiated by the students themselves. Obviously each alternative can be applicable for all students (discarding opportunities in which the number of available tickets remaining for a specific segment is less than the number of students who need to travel). Communication in this case is trivially implemented and necessarily reliable, e.g., the students could be sitting in the same office showing one another their results, or they can search from computers located in different offices and meet at the end of the day. The students will unquestionably obey the rules of disclosing the information they find, reliably and upon obtaining it, due to severe reputation loss if their advisor or colleagues would find out that they had deviated from the rules.
      </paragraph>
      <paragraph>
       The students can either be self-interested (e.g., where each pays for her trip from her own allowance and considering her own opportunity cost) or fully cooperative (e.g., where the costs are paid from the same allowance, or by their advisor, and they have a deadline for a paper they both co-author hence any time saving for either of them will benefit both).
      </paragraph>
     </section>
    </section>
    <section label="3">
     <section-title>
      Analysis
     </section-title>
     <paragraph>
      We first introduce the optimal search strategy for a single agent, i.e., when the agent benefits only from opportunities it explored by itself (Section 3.1). The single agent's strategy is then augmented to consider joint search for both the fully cooperative and self-interested cases with no-communication throughout the search (Sections 3.2 and 3.3, respectively). For the fully cooperative case, we prove that some elements (enhancers) are always beneficial (social-wise). Finally, we extend the analysis for the case where communication between the agents is continuous throughout the individual searches (Section 3.4).
     </paragraph>
     <paragraph>
      For exposition purposes, the supporting illustrations and numerical examples consider homogeneous agents (i.e., associated with the same search cost and their opportunity values are drawn from the uniform distribution function over ({a mathematical formula}0,1)). We emphasize that the use of this synthetic environment is only for illustrative purposes, and the formal analysis supplies the theoretical proof for all claims made, for any kind of environment.
     </paragraph>
     <section label="3.1">
      <section-title>
       A single agent's optimal strategy
      </section-title>
      <paragraph>
       The individual search problem when findings are not shared whatsoever can be mapped to the standard sequential economic search model found in literature and the optimal search strategy in this case is reservation-value (threshold) based [47], [26], [35], [79]. According to this strategy, each agent {a mathematical formula}Ai calculates a reservation-value {a mathematical formula}ri, and resumes its search as long as the best value found so far is below {a mathematical formula}ri. The opportunities are evaluated sequentially in a random order, as they are all a priori alike. The optimal {a mathematical formula}ri value is extracted from:{a mathematical formula}
      </paragraph>
      <paragraph>
       Intuitively, {a mathematical formula}ri is the value where the agent is precisely indifferent: the expected marginal utility from obtaining the value of the opportunity exactly equals the cost of obtaining that additional value. It is notable that the decision rule is myopic, i.e., the value of {a mathematical formula}ri does not depend on the number of opportunities that can still be potentially explored [79]. The proof for the stationarity of {a mathematical formula}ri (based on [79], however substantially shortened based on the fact the opportunities available to the agent are associated with common probability distribution function and search cost) is given in Appendix A.1. A further quite intuitive observation that can be made based on Eq. (1) is that the value of {a mathematical formula}ri decreases as {a mathematical formula}ci increases.
      </paragraph>
      <paragraph>
       The expected utility of agent {a mathematical formula}Ai, when using the reservation value {a mathematical formula}ri, denoted {a mathematical formula}EBi, is given by:{a mathematical formula} where the first term is the expected cost incurred throughout the search carried out by {a mathematical formula}Ai, calculated as: {a mathematical formula}ci∑j=1n(Fi(ri))j−1=ci1−Fi(ri)n1−Fi(ri), as the number of opportunities explored is a geometric random variable bounded by n, with a success probability {a mathematical formula}1−Fi(ri). The second term is the expected “best” (i.e., maximum) opportunity-value found by the agent along its search. The calculation of this latter value relies on the probability distribution function of the maximum value obtained along agent {a mathematical formula}Ai's search, denoted {a mathematical formula}fireturn(y). In order to formulate {a mathematical formula}fireturn(y), we make use of the probability that the maximum value obtained along the search process of agent {a mathematical formula}Ai, when using the reservation value {a mathematical formula}ri, is less than x, denoted {a mathematical formula}Fireturn(x), calculated according to:{a mathematical formula} When {a mathematical formula}x&lt;ri all n explored opportunities must result in a value below x. When {a mathematical formula}x≥ri there are two possible scenarios. The first is where all n explored opportunities result in a value below the reservation value {a mathematical formula}ri, i.e., with probability {a mathematical formula}Fi(ri)n. The second, is where the search terminates right after j periods, upon revealing a value y such that {a mathematical formula}ri&lt;y&lt;x (otherwise, if {a mathematical formula}y&lt;ri the search should resume) and all the former {a mathematical formula}j−1 opportunities queried returned a value smaller than {a mathematical formula}ri (otherwise the jth opportunity is not reached). The probability of the latter case occurring (summing over all values of {a mathematical formula}j≤n) can be calculated using the geometric series {a mathematical formula}∑j=1n(Fi(x)−Fi(ri))Fi(ri)j−1.
      </paragraph>
      <paragraph>
       The probability function {a mathematical formula}fireturn(x) is, by definition, the first derivative of {a mathematical formula}Fireturn(x):{a mathematical formula}
      </paragraph>
      <paragraph>
       While the number of opportunities available to the agent, n, does not affect {a mathematical formula}ri as explained above, it does affect the agent's expected utility in such a way that an increase in the number of opportunities results in an increase in the expected utility. This is due to the fact that with the increased number of opportunities it is less likely to run into situations where it is optimal to resume search however there are no additional opportunities available.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Joint search with fully cooperative agents
      </section-title>
      <paragraph>
       The optimal strategy for the fully cooperative case may dictate that some of the agents should not engage in search at all. For example, consider the case of k fully cooperative agents where each agent may explore only a single opportunity (i.e., {a mathematical formula}n=1). In this case, the individual (stand-alone) optimal strategy is to explore one opportunity if {a mathematical formula}c&lt;0.5 (since values are drawn from the uniform distribution). Each agent's expected utility is thus {a mathematical formula}0.5−c and the overall expected utility is {a mathematical formula}k⋅(0.5−c). In joint search, where {a mathematical formula}k′ agents explore their opportunity ({a mathematical formula}1≤k′≤k), the search cost is {a mathematical formula}k′⋅c and the expected utility is the maximum of a {a mathematical formula}k′-size sample taken from a uniform distribution, which equals {a mathematical formula}k′/(k′+1) (see [71]). The expected overall net utility is thus {a mathematical formula}k⋅(k′k′+1)−k′⋅c which is maximized for different {a mathematical formula}k′ values, depending on the value of c. In this example, if initially there are {a mathematical formula}k=5 agents then indeed for a cost of {a mathematical formula}c=0.1 it is optimal to have all agents search, however for a cost of {a mathematical formula}c=0.3 it is optimal that only two agents search.
      </paragraph>
      <paragraph>
       Therefore, the analysis first develops the optimal strategy for the case where subset {a mathematical formula}K′={A1′,...,Ak′′}∈K of agents engage in search, while the remaining {a mathematical formula}k−k′ agents do not search. In this manner the subset that maximizes the overall expected utility can be chosen.
      </paragraph>
      <paragraph label="Proof">
       Consider the case where a subset{a mathematical formula}K′⊆Kof the agents engage in search, with no communication between the agents, and the remaining agents (i.e.,{a mathematical formula}K−K′) completely refrain from searching. The strategy of agent{a mathematical formula}Ai∈K′that maximizes the group's expected benefit, given the set of (not necessarily reservation-value based) strategies used by all other searching agents{a mathematical formula}K′/Ai, is to follow reservation value{a mathematical formula}ri, which satisfies:{a mathematical formula}where{a mathematical formula}f¯i(x)denotes the probability distribution function of the maximum value obtained by all agents except agent{a mathematical formula}Ai, throughout their search. Agent{a mathematical formula}Aishould always choose to obtain the value of an additional opportunity (if one is available) if the highest value it obtained so far is below{a mathematical formula}riand otherwise terminate the search.See Appendix A.2. □
      </paragraph>
      <paragraph>
       Eq. (5) also has the intuitive interpretation as in the single agent's stand-alone search, in the form of indifference between the expected marginal utility from obtaining the value of the opportunity (represented by the right-hand term of the equation), this time, however, calculated for all group members (hence multiplied by k) and taking into consideration the findings of others.
      </paragraph>
      <paragraph>
       Theorem 1 proves that the group-expected-benefit-maximizing strategy for any agent is reservation-value based, regardless of the search strategies used for the other agents. Therefore, the optimal group's search strategy is a set {a mathematical formula}{rj|Aj∈K′}. This enables formulating {a mathematical formula}f¯i(x). The probability function {a mathematical formula}f¯i(x) is the derivative of {a mathematical formula}F¯i(x), the probability that the maximum value obtained by all the searching agents except for {a mathematical formula}Ai is smaller than or equal to x. The value of {a mathematical formula}F¯i(x) is given by:{a mathematical formula} where {a mathematical formula}Fjreturn(x) is the probability that the maximum value obtained along the search process of an agent {a mathematical formula}Aj that uses a reservation value {a mathematical formula}rj is lesser than x, as given in (3). Therefore:{a mathematical formula}
      </paragraph>
      <paragraph>
       Given the subset of agents {a mathematical formula}K′={A1′,...,Ak′′}∈K that engage in search, the optimal set of reservation values can be derived by solving the set of {a mathematical formula}k′ equations based on (5) and (7) for each {a mathematical formula}Ai∈K′.{sup:6} Based on the set of reservation values obtained, the overall expected utility can be calculated. The computation is separated into the expected value the agents attain and the expected accumulated cost along the agents' search. The probability distribution function of the best value obtained throughout all agents' search, denoted {a mathematical formula}f¯(x), can be formulated using a modification of (7):{a mathematical formula} The expected value the agents end up with, denoted EV, is thus given by:{a mathematical formula} The expected accumulated cost of any agent {a mathematical formula}Ai∈K′ is given by {a mathematical formula}ci1−Fi(ri)n1−Fi(ri) (see (2)), thus the overall expected utility is:{a mathematical formula}
      </paragraph>
      <paragraph>
       The optimal strategy can thus be obtained by checking the overall expected utility of each subset {a mathematical formula}K′⊆K according to Theorem 1 and Eq. (10) and selecting the subset of reservation values associated with the highest value.{sup:7} The computational complexity of evaluating all subsets is combinatorial in the number of agents. Although the focus of the paper is not on the computational aspects but rather on analyzing the structure of the optimal and equilibrium cooperative strategies, we note that in most joint search settings the computational complexity becomes a non-issue since the number of agents taking part in the joint search is relatively small.
      </paragraph>
      <paragraph>
       The fact that the agents use a reservation-value-based strategy requires further discussion regarding the need to check all combinations of {a mathematical formula}K′⊆K. Seemingly, one could expect the solution for the set of k equations of type (5) to result in a reservation value {a mathematical formula}ri=−∞ for each agent that does not need to engage in search according to the optimal strategy, consequently eliminating the need to evaluate each subset separately. Using such reservation values, would have precluded any search on behalf of the agent. Yet, Eq. (5) is valid only if it is beneficial for the agent to conduct the search, as it captures the indifference between the cost of search and the gain obtained from it. The equality represented by (5) cannot hold for agents that should not engage in search according to the optimal joint search strategy, even if {a mathematical formula}ri=−∞ is used.
      </paragraph>
      <paragraph>
       Fig. 1 depicts the effect of agent's search cost (left) and the number of opportunities (right) available for search on the agents' individual expected utility for different number of agents taking part in the search. The left graph, which relates to the search cost as the independent variable, uses a setting with five agents and three search periods (i.e., {a mathematical formula}k=5, {a mathematical formula}n=3). As expected, the individual expected utility decreases as the search cost c increases. This is due to the fact that the greater the search cost, the lower the reservation values and the resulting expected utility, since search becomes less favorable. The dashed lines in the graph mark the costs for which the optimal number of agents that need to engage in search changes (i.e., the points of alternation in the identity of the most upper curve). As observed from the graph, the optimal number of searching agents decreases as the search cost increases. This is because when the search cost is relatively small, it is best that all agents engage in search, in order to fully exploit the {a mathematical formula}k⋅n opportunities that can be explored in parallel. As the search cost increases, the relative utility from further search decreases, thus it becomes more effective to have less agents engage in search, while taking advantage of the permitted search horizon to its full extent. Thus, the same expected number of opportunities can be explored, except the process is executed with less parallelism. The preference of a sequential over parallel search is straightforward, as in the absence of any discounting of gains the parallel process can be decomposed to a sequential one that yields at least as much expected utility (as it offers the utility of terminating the search once a favorable value is obtained, potentially incurring only part of the search costs).
      </paragraph>
      <paragraph>
       The right graph of Fig. 1, which relates to the search horizon as the independent variable, uses a setting with five agents as well and a search cost of 0.01 (i.e., {a mathematical formula}k=5, {a mathematical formula}c=0.01). As expected, the overall expected utility increases as the number of opportunities that each agent can potentially explore increases. This property, while intuitive, is proved later (see Proposition 1). As observed from the graph, the optimal number of agents to engage in search decreases as the search horizon increases. This is because of the tradeoff between parallel and sequential search. Ideally, if the agents were not limited by the search horizon, they would have preferred the search process to be executed with one agent searching at a time. However, as the search horizon decreases, the agents will need to rely more on parallel searches as a means of extending the overall amount of opportunities that theoretically can be explored.
      </paragraph>
      <paragraph>
       For the fully cooperative case, in Proposition 1 we define four joint-search enhancers that necessarily benefit the agents that use them. Nonetheless, in the following section we will demonstrated that they are potentially devastating for joint-search with self-interested agents.
      </paragraph>
      <paragraph label="Proposition 1">
       In fully cooperative joint search:
      </paragraph>
      <list>
       <list-item label="(a)">
        If the sharing of findings at the end of the individual searches is costless, then increasing the size of the group of agents taking part in the search can only improve and never worsen the per agent average expected utility.
       </list-item>
       <list-item label="(b)">
        Extending the search horizon necessarily increases the overall expected utility.
       </list-item>
       <list-item label="(c)">
        A decrease in the search cost of some of the agents that engage in search according to the optimal strategy necessarily increases the overall expected utility.
       </list-item>
       <list-item label="(d)">
        Starting the joint search with some pre-known value (i.e., a fallback value available for the group) necessarily increases the overall expected utility.
       </list-item>
      </list>
      <paragraph>
       The proof of these is trivial in most cases hence it is formally presented in Appendix A.3.
      </paragraph>
     </section>
     <section label="3.3">
      <section-title>
       Joint search with self-interested agents
      </section-title>
      <paragraph>
       The analysis of the self-interested case follows the equilibrium concept. Specifically, since findings of agents are a priori uncertain, we use Bayesian Nash equilibria.{sup:8} A solution in this case is a set of search strategies, where each agent's strategy maximizes its own individual expected utility given the search strategies used by the other agents. The set of strategies available for each agent potentially includes engaging in search to some extent or completely avoiding search. Since it is possible that in the end none of the agents will actually engage in the search, in equilibrium, we define the agents' utilities for such cases as {a mathematical formula}v0.
      </paragraph>
      <paragraph label="Theorem 2">
       An equilibrium solution to the problem with self-interested agents is a set of strategies{a mathematical formula}{(p1,r1),...,(pk,rk)}, where{a mathematical formula}piis the probability that agent{a mathematical formula}Aiwill engage in search ({a mathematical formula}0≤pi≤1), and{a mathematical formula}riis the reservation value it will be using if engaged in search, such that: (a) for every agent{a mathematical formula}Aifor which{a mathematical formula}pi=0,{a mathematical formula}EBi(search)≤EBi(¬search); (b) for every agent{a mathematical formula}Aifor which{a mathematical formula}pi=1,{a mathematical formula}EBi(search)≥EBi(¬search); and (c) for every agent{a mathematical formula}Aifor which{a mathematical formula}0&lt;pi&lt;1,{a mathematical formula}EBi(search)=EBi(¬search), where:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph label="Proof">
       We first prove that regardless of the strategies used by the other agents the best-response search strategy for agent {a mathematical formula}Ai, if it chooses to actively engage in search, is a reservation value {a mathematical formula}ri, where {a mathematical formula}ri is the solution to (11).{sup:9} The proof is similar to the one given for Theorem 1, with the difference being only that the agent does not multiply the improvement in the expected value the agents attain by k, as it is only interested in its own expected utility. A solution will be considered stable (i.e., in equilibrium), if none of the agents will find it beneficial to deviate from it individually. A Bayesian Nash equilibrium in pure strategies for the problem would require {a mathematical formula}pi∈{0,1}∀i. Any other solution is a mixed strategy Bayesian Nash equilibrium.The above establishes the fact that all agents will be using a reservation value strategy whenever actively engaging in search, thus we can formulate {a mathematical formula}Fjreturn(x), the probability that the maximum value obtained along the search process of an agent {a mathematical formula}Aj (that chooses to engage in search and uses {a mathematical formula}rj), is less than x, as in (3). This facilitates the extraction of the probability distribution function of the maximum value obtained throughout agent {a mathematical formula}Aj's search, {a mathematical formula}fjreturn(x), using the same principle as in (4). Thus, we can now formulate the probability that the maximum value that will be found by all the agents except {a mathematical formula}Ai will be smaller than or equal to x, denoted {a mathematical formula}F¯i(x):{a mathematical formula} and finally the probability distribution function of that value, {a mathematical formula}f¯i(x), is the derivative of {a mathematical formula}F¯i(x).These enable us to calculate the expected utility of agent {a mathematical formula}Ai when any other agents {a mathematical formula}Aj uses a strategy {a mathematical formula}(pj,rj). If agent {a mathematical formula}Ai chooses to engage in search then its expected utility, denoted {a mathematical formula}EBi(search), is given by (13).{sup:10} The first term on the right of (13) is the cost incurred for the search carried out by {a mathematical formula}Ai, as in (2). The second term is the expected maximum between the best value found by the agent itself (i.e., associated with a distribution {a mathematical formula}fireturn(y)) and the best value returned by the other agents (associated with a distribution {a mathematical formula}f¯i(x)). When the agent opts not to search at all, its expected utility, denoted {a mathematical formula}EBi(¬search), is simply the expected value of the maximum value returned by the other agents, as given by (14).The three stability conditions specified in the theorem, thus guarantee that the agent is indifferent between actively engaging in search and not engaging in search at all whenever a mixed strategy is used ({a mathematical formula}0&lt;pi&lt;1) and that for pure strategies (i.e., when {a mathematical formula}pi∈{0,1}) the strategy used is indeed the dominating one. □
      </paragraph>
      <paragraph>
       Therefore, in order to find the equilibrium, one needs to check the stability of {a mathematical formula}3k possible solutions of the type {a mathematical formula}{(p1,r1),...,(pk,rk)} differing in the value each {a mathematical formula}pi obtains ({a mathematical formula}pi=0, {a mathematical formula}pi=1 and {a mathematical formula}0&lt;pi&lt;1). For every combination, the reservation values of the agents that do not use {a mathematical formula}p=0 and the probability p of each agent that uses a non-pure mixed strategy (i.e., with {a mathematical formula}0&lt;p&lt;1) should be calculated by solving a set of equations of type (11), for every agent that engages in search and of type {a mathematical formula}EBi(search)=EBi(¬search), according to Eqs. (13), (14), for every agent {a mathematical formula}Ai for which {a mathematical formula}0&lt;pi&lt;1. Once the appropriate reservation values and probabilities are obtained for a given set, the stability conditions need to be validated.
      </paragraph>
      <paragraph>
       We note that it is possible to have more than a single equilibrium solution (i.e., multi-equilibria, see for example Fig. 4 in the following section). In the latter case, if there is an equilibrium that dominates the others in terms of the individual expected utility each and every agent obtains then it will likely be the one used. Otherwise, there is no way of deciding which of the equilibria is the one that will be used.{sup:11} The totally-mixed-strategy-based equilibrium (i.e., one where all players assign a strictly positive probability to every pure strategy), if one exists, is a natural choice in this case as typically it guarantees that all agents “contribute” to the joint search. With pure-strategies equilibria, it is very common to find one agent engaging in search while all others are essentially free-riders. In particular, when the agents are relatively homogeneous in terms of their search competence, as in many real-life settings, the mixed-strategies case will result in a balanced solution in terms of individual expected utilities, whereas the pure-strategies case will be highly inequitable. Still, a totally-mixed-strategy-based equilibrium does not necessarily exist, e.g., when search costs are substantially low (hence the equilibrium is based on having all agents search) or substantially high (hence the equilibrium is based on having none of the agents search). This is also demonstrated in the following section for various settings, e.g., in Fig. 4.
      </paragraph>
     </section>
     <section label="3.4">
      <section-title>
       The effect of continuous communication throughout search
      </section-title>
      <paragraph>
       So far we have assumed that the agents share their findings only at the end of the individual search processes. We now analyze the settings in which the agents can also communicate throughout the search process. In this case, values are shared in real-time, thus the agents' search decisions should take into consideration other agents' findings (rather than merely the distribution of the best value that will be returned by others at the end of the process). Unlike the non-continuous communication case, here the agents' joint search strategies are proved to be non-reservation-value based.
      </paragraph>
      <section label="3.4.1">
       <section-title>
        The fully cooperative case
       </section-title>
       <paragraph>
        With continuous communication the agents' strategy is based on more complete information, hence the agents' expected utility is likely to improve compared to the case of non-continuous communication.
       </paragraph>
       <paragraph label="Proof">
        The agents can use the optimal strategy for the fully-cooperative case with no communication, however, instead of having each agent use its own findings for terminating the search, based on its reservation value, it will consider the best finding obtained so far by any of the agents. □
       </paragraph>
       <paragraph>
        If all agents are characterized by a common probability distribution of values, i.e., {a mathematical formula}f1(x)=f2(x)=...=fk(x)=f(x), then the problem can be mapped to Morgan's optimal sequential sampling problem [44] (even if the search costs of the different agents vary). In this problem, a single agent can explore one or more opportunities in any period, where the cost of exploring {a mathematical formula}k′ opportunities is given by some monotonically increasing function {a mathematical formula}C(k′). The solution in this case is based on extracting the optimal number of opportunities to explore at each period given the best value obtained so far and the optimal strategy onwards.{sup:12}
       </paragraph>
       <paragraph label="Proposition 3">
        In our case, however, different agents may be assigned with different probability distribution functions, precluding the use of Morgan's solution. Our solution is based on dynamic programming, using the joint distribution of the maximum value obtained in any given turn. We use {a mathematical formula}Kj′(v) ({a mathematical formula}Kj′(v)⊆K) to denote the subset of agents that need to search during the coming search period, according to the optimal search strategy, when there are only j remaining search opportunities and the best value found till this point is v. The resulting distribution of the best value among the values obtained by the agents in {a mathematical formula}Kj′(v) in a single search period, denoted {a mathematical formula}f¯Kj′(v)(x), is given by {a mathematical formula}f¯Kj′(v)(x)=d(F¯Kj′(v)(x))dx, where {a mathematical formula}F¯Kj′(v)(x) is the probability that the maximum value found by the searching agents in a single search period is smaller or equal to x, given by:{a mathematical formula}If the optimal joint fully-cooperative search strategy with j search periods remaining ({a mathematical formula}j&gt;1) is to have none of the agents search ({a mathematical formula}Kj′(v)=∅) then the same strategy is optimal when less than j periods are left.
       </paragraph>
       <paragraph>
        The proof for the proposition is given in Appendix A.4 and its main implication is that once the agents choose not to explore an additional opportunity, their search necessarily terminates.
       </paragraph>
       <paragraph>
        We use {a mathematical formula}EBj(v) to denote the overall expected utility of the agents when j search periods remain, if the optimal fully cooperative search strategy is used, given that the best value obtained so far by any of the agents is v. The value of {a mathematical formula}EBj(v) can be calculated recursively, based on the overall expected utility of the subsequent search period:{a mathematical formula} where for the case where there is only one remaining search period:{a mathematical formula} The first element in (17) represents the sum of the search costs of the agents that engage in search during the coming search period. The second term is the expected utility in the subsequent period, based on the different options of the “best” value with which to continue, which is the maximum among the best values found so far and the results of the searches that take place during the current search period. The determination of {a mathematical formula}Kj′(v) should thus be based on extracting the set of all subsets {a mathematical formula}Kj⊆K and evaluating them using (17), selecting the one associated with the maximum expected utility. The case of {a mathematical formula}Kj′(v)=∅ derives from Proposition 3. For the last period (Eq. (18)), no further search can take place beyond the current period, hence the actual values are taken into account (rather than the expected value {a mathematical formula}EBj−1(max(v,y))).
       </paragraph>
       <paragraph>
        The expected utility of the entire search process, denoted EB, can be calculated using a recursive equation similar to (18) and (17):{a mathematical formula} We note that if the communication is costly the only change required in (17), (18), (19) is in the costs part. For example, if the communication costs are global (e.g., do not depend on the amount of communication carried out) then the costs should only be subtracted from EB calculated in (19). Otherwise, if each communication session or each transmission incurs a cost, then the said cost simply can be added to the cost {a mathematical formula}ci in (17) and (18).
       </paragraph>
       <paragraph>
        The best value that has been obtained so far along all agents' search, v, substantially influences the optimal number of agents that will engage in search in the coming search periods. The number of agents in {a mathematical formula}Kj′(v) decreases as v increases, because the expected improvement due to further search decreases, for the increased v value, whereas the cost of such further search does not change. This makes any additional parallel search efforts less beneficial and consequently the optimal number of agents that need to engage in search decreases. As for the expected utility, this increases as v increases, as a better “fallback” is enabled. If v is initially low, its increase results in a minor increase in the expected utility because the chance that despite all the searches performed by the agents no better value will be obtained is insignificant. Similarly, when v is initially high, the optimal strategy is to have none of the agents search hence any increase in v results in an identical increase in the individual expected utility.
       </paragraph>
       <paragraph>
        As for the effect of the agents' search costs, the greater the search cost the lower {a mathematical formula}Kj′(v) becomes. The intuition is the same as the one given for the effect of the increase in v, with the only change being that while the increase in v has a positive effect on the group's starting point the increase in c has a negative effect.
       </paragraph>
      </section>
      <section label="3.4.2">
       <section-title>
        The self-interested case
       </section-title>
       <paragraph>
        From the individual agent's point of view, when being self-interested, disclosing a “good” value that was obtained along the search is not beneficial, as this will likely discourage the other agents from resuming their search. Therefore, the exchange of information in this case is mandatory and does not depend on the agents' desire, due to the justifications given in Section 2. In this case, as we prove in the following paragraphs, the agent's strategy needs to take into consideration not only the best value obtained so far, as in the “no communication” case, but also the remaining number of potential search periods. Agent {a mathematical formula}Ai's strategy can thus be represented as the mapping {a mathematical formula}S(v,j)→pij(v), where {a mathematical formula}pij(v) is the probability that {a mathematical formula}Ai will choose to explore an additional opportunity when the number of remaining allowed searches is j and the best value obtained so far by all agents is v. We use {a mathematical formula}EBij(v) to denote the expected utility of agent {a mathematical formula}Ai if it follows the optimal search strategy, given the strategies used by the other agents, with j search opportunities remaining, and the best value obtained through all the agents' searches so far is v.
       </paragraph>
       <paragraph>
        Similar to the use of {a mathematical formula}F¯i(x) in Section 3.3, we use {a mathematical formula}F¯ij(x) to denote the probability that the maximum value that will be found by all the agents, except for agent {a mathematical formula}Ai, during the next search period (if carried out), when there are only j remaining opportunities, will be smaller than or equal to x. The function {a mathematical formula}f¯ij(x) is {a mathematical formula}F¯ij(x)'s corresponding probability distribution function (the equivalent to {a mathematical formula}f¯i(x)). Both {a mathematical formula}F¯ij(x) and {a mathematical formula}f¯ij(x) can be calculated using the following modifications of Eqs. (15), (12):{a mathematical formula}{a mathematical formula}
       </paragraph>
       <paragraph>
        These enable us to calculate the expected utility of agent {a mathematical formula}Ai when there are j search periods remaining, given the best value v obtained so far by any of the agents and the search strategies of the other agents {a mathematical formula}{pwj(v)|w≠i}. If agent {a mathematical formula}Ai chooses to explore an additional opportunity then its expected utility, denoted {a mathematical formula}EBij(search,v) is given by:{a mathematical formula} where {a mathematical formula}EBi0(v)=v, as when no further search is allowed (i.e., when the allowed search horizon n has been reached) the process inevitably terminates and the agents receive the best value found so far. If the agent opts to not search during the next search period, its expected utility, denoted {a mathematical formula}EBij(¬search,v), is:{a mathematical formula} Eq. (22) includes the search cost of agent {a mathematical formula}Ai in the coming search period. The second term is the expected utility from reaching the next search period when the best value known is the maximum between the value found by the agent itself in the current search period, the best value returned by the other agents in the current search period (associated with a distribution {a mathematical formula}f¯ij(x)), and the best value obtained by all the agents in former {a mathematical formula}n−j periods. The term on the right-hand-side of Eq. (23) is simply the expected utility of the agent given the maximum value found so far and the best value obtained in the coming search period j.
       </paragraph>
       <paragraph>
        Agent {a mathematical formula}Ai's decision when in state {a mathematical formula}(v,j) is thus to use {a mathematical formula}pij(v)=1 if {a mathematical formula}EBij(search,v)&gt;EBij(¬search,v), {a mathematical formula}pij(v)=0 if {a mathematical formula}EBij(search,v)&lt;EBij(¬search,v), and any value {a mathematical formula}0≤pij(v)≤1 in case {a mathematical formula}EBij(search,v)=EBij(¬search,v). Consequently, the value of {a mathematical formula}EBij(v) is calculated as:{a mathematical formula} The expected utility of agent {a mathematical formula}Ai in the joint search is thus given by {a mathematical formula}EBin(−∞).
       </paragraph>
       <paragraph>
        Using the above, the equilibrium strategy can be unfolded using linear programming principles – for each number of remaining search opportunities, j, the equilibrium set of probabilities {a mathematical formula}{p1j(v),...,pkj(v)} can be obtained, for any value v, by solving the set of equations of types (22) and (23) where the value of {a mathematical formula}EBij(v) is calculated based on the equilibrium set of probabilities attained for {a mathematical formula}j−1 periods for all the potential different values that the “best” value parameter may obtain after the current search step.
       </paragraph>
       <paragraph>
        The equilibrium stability conditions in this case should now be specified in the search period level – a set of strategies {a mathematical formula}{p1j(v),...,pkj(v)} will be in equilibrium only if the following conditions hold: (a) for every agent {a mathematical formula}Ai for which {a mathematical formula}pij(v)=0, {a mathematical formula}EBij(search,v)≤EBij(¬search,v); (b) for every agent {a mathematical formula}Ai for which {a mathematical formula}pij(v)=1, {a mathematical formula}EBij(search,v)≥EBij(¬search,v); and (c) for every agent {a mathematical formula}Ai for which {a mathematical formula}0&lt;pij(v)&lt;1, {a mathematical formula}EBij(search,v)=EBij(¬search,v). Therefore, as in the case with no communication, in order to find the equilibrium one needs to check the stability of {a mathematical formula}3k possible solutions of the type {a mathematical formula}{p1n(v),...,pkn(v)} differing in the value that each {a mathematical formula}pin(v) obtains ({a mathematical formula}pin(v)=0, {a mathematical formula}pin(v)=1 and {a mathematical formula}0&lt;pin(v)&lt;1). This time however, such an equilibrium needs to be found for any possible best value obtained, v, and for each possible number of remaining search periods, {a mathematical formula}j≤n. The expected utility of agent {a mathematical formula}Ai according to this solution is given by:{a mathematical formula}
       </paragraph>
       <paragraph>
        Once again, we note that it is possible that several equilibria will be found for a specific state {a mathematical formula}(v,j). In this case, however, the determination of which will hold becomes more critical as the determination of the equilibrium strategies in states {a mathematical formula}(v′,j′&lt;j) depends on it. This multi-equilibria problem is beyond the scope of the current paper, and we focus our illustrations on settings where only a single equilibrium exists, or where the choice of the equilibrium the agents will use is straightforward (e.g., with homogeneous agents).
       </paragraph>
       <paragraph>
        As with the case of fully cooperative agents we note that when the communication is costly the only change required in (22), (23), (24) is in the costs part: If communication costs are global then the costs should only be subtracted from {a mathematical formula}EBi calculated in (24) for each agent {a mathematical formula}Ai, and if each transmission incurs a cost then this can be simply added to the cost {a mathematical formula}ci in (22) or subtracted directly from (23).
       </paragraph>
      </section>
     </section>
    </section>
    <section label="4">
     <section-title>
      The failure of cooperation enhancers with self-interested agents
     </section-title>
     <paragraph>
      In this section, we illustrate that applying the cooperation enhancers given in Proposition 1, may actually hinder beneficial cooperation rather than nurture it when the agents are self-interested. For each of the enhancers we first provide an example where it is indeed beneficial (in terms of the resulting change in the agents' expected utility), even when the agents are self-interested, as in the fully cooperative case. Then, we provide an example where the enhancer's actual effect is negative, due to the agents' self-interestedness. Unless specifically stated otherwise, all illustrations used in this section rely on the same synthetic environment as in the previous section (i.e., a uniform distribution of values and homogeneous agents that share the same search cost). The illustrations primarily consider the totally-mixed-strategies-based equilibrium, for the reasons given in the previous section. Still, for some cases, where the number of pure-strategies-based equilibria is relatively small, we also include them in the figures.
     </paragraph>
     <section label="4.1">
      <section-title>
       Adding an additional agent
      </section-title>
      <paragraph>
       Fig. 2 depicts the individual expected utility of the agents, in equilibrium, in a self-interested-agents setting, as a function of the number of agents k. The setting used for this example considers a search horizon of three search periods ({a mathematical formula}n=3) and the search cost is {a mathematical formula}c=0.1. From Fig. 2 we observe that the individual expected utility of the agents increases as the number of agents increases. This means that the improvement achieved by the addition of agents (in terms of the number of opportunities that can now be explored in parallel and overall) is greater than the decrease in the search extent resulting from the reliance of each of the agents on the others. While the above improvement in the individual expected utility due to the increase in the group's size is correlated with the case of fully cooperative agents, we now present an opposite example that is unique to the case of self-interested agents. Consider a setting where three self-interested agents search jointly, when the search cost is {a mathematical formula}c=0.2 and the search horizon is {a mathematical formula}n=10. In this case, the individual expected utility according to the mixed equilibrium is {a mathematical formula}EB=0.464. We now add a fourth agent to the joint search setting, with a search cost of 0.45, while keeping the search horizon unchanged. In this case, the expected utility of the additional agent in equilibrium is 0.075, however the expected per-agent utility of the original three agents decreases to 0.453 (compared to 0.464 when it was only the original three agents). Furthermore, in the four-agents setting, even the average expected utility decreased and it is now {a mathematical formula}EB=0.358 (compared to 0.464 in the three-agents setting).
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Increasing the number of opportunities available (search horizon)
      </section-title>
      <paragraph>
       Fig. 3 depicts the individual expected utility of the agents, in a self-interested-agents setting, as a function of the search horizon n. The setting used for this example considers two homogeneous agents ({a mathematical formula}k=2), each associated with the same search cost (0.16 for graph (a) and 0.2 for graph (b)). In this case, two different equilibria hold. The first is pure equilibria, where only one of the agents actually executes search (represented by the upper and lower curves, depending on whether the agent is the one doing the search or not). The second equilibrium is a mixed one ({a mathematical formula}0&lt;p&lt;1). As observed from the figure, the increase in the search horizon can have either a positive effect (as in the case of fully-cooperative agents) or a negative one on the individual expected utility. This phenomenon is explained by the interplay between the positive effect of the increase in the number of search periods each agent can potentially utilize, if deciding to engage in search, and the negative effect the extension of the search horizon has on the probability an agent will indeed engage in search (p). As the search cost increases from 0.16 to 0.2, each agent finds it more beneficial to rely on the other, resulting in a substantially greater decrease in the value of p.
      </paragraph>
     </section>
     <section label="4.3">
      <section-title>
       Improving an agent's competence
      </section-title>
      <paragraph>
       Fig. 4 depicts the individual expected utility of two homogeneous agents {a mathematical formula}A1 and {a mathematical formula}A2, associated with an equal search cost {a mathematical formula}c1=c2=0.2, when a third agent with a search cost c (given as the horizontal axis) is added. The search horizon is limited to a single opportunity, i.e., {a mathematical formula}n=1. In this case there is a totally mixed equilibrium only for the interval {a mathematical formula}0.1≤c≤0.5. Two additional pure equilibria also hold for some c values, both consisting of only one of the three agents engaging in search. In the first, depicted in (a), the searching agent is one of the two homogeneous agents. This equilibrium holds only for c values in the {a mathematical formula}(0.17,0.5) interval. It is notable that in this case the expected utility of the different agents do not depend on the cost c (which is relevant only to the third agent) since the agent engaged in search is one of the two homogeneous agents. The expected utility of the two homogeneous agents and the third (joining) agent, when the mixed equilibrium is used, are distinguished by the labels “Mixed (M)” and “Mixed (T)”, respectively. In the second pure equilibrium, depicted in (b), the searching agent is the third agent. This equilibrium holds for any {a mathematical formula}c≤0.5 and hence is the only equilibrium (and essentially the one used) when {a mathematical formula}c&lt;0.1. With this equilibrium the cost of the searching agent, which is the third agent, decreases as its cost of search c increases (since neither of the other two agents search). As with the former examples, the two pure equilibria are associated with an expected utility smaller than with the mixed equilibrium for the agent engaged in search and vice-versa for the agent that does not search, motivating once again the adoption of the totally mixed equilibrium as the solution to the problem.
      </paragraph>
      <paragraph>
       As observed in the figure, as the cost of search of the third partner increases, the expected utility of the two homogeneous agents (i.e., the “Mixed (M)” curve) increases, however from a certain c value, any further increase in the search cost of the joining agent results in a decrease in the two agents' expected utility. This result means that the agents sometimes should prefer that the less competent agent (i.e., the one associated with a smaller search cost compared to other potential candidates) join their joint search process. In this example the agents would prefer that an agent associated with a search cost of {a mathematical formula}c=0.15 join the search over a more competent agent (e.g., one associated with a search cost of {a mathematical formula}c=0.1).
      </paragraph>
      <paragraph>
       Fig. 4(c) presents the overall expected utility with the three equilibria and when the agents are fully cooperative. From this figure we can see that in this example, while the individual utility of the first two agents may increase as c increases, the overall utility (when including the expected utility of the added agent) indeed decreases. Nevertheless, the overall expected utility in the self-interested case can also decrease due to an improvement in an agent's competence. We illustrate this by means of a simplistic example. Consider the case of two-agents with a search horizon of {a mathematical formula}n=1. Agent {a mathematical formula}A1 can explore an opportunity that yields either 10 or 1 with an equal probability and is associated with a search cost {a mathematical formula}c1=2. Agent {a mathematical formula}A2 can explore an opportunity that yields either 1 or 1.1 with an equal probability and is associated with a search cost {a mathematical formula}c1=3. In this case, the only equilibrium that holds is a pure one. The expected utility of agent {a mathematical formula}A1 according to the equilibrium is {a mathematical formula}EB1=3.5 and the expected utility of agent {a mathematical formula}A2 is {a mathematical formula}EB2=5.5, resulting in an overall expected utility of 9. Now assume the search competence of {a mathematical formula}A2 is improved, such that {a mathematical formula}c2=1. Now, the expected utilities are {a mathematical formula}EB1=3.8 and {a mathematical formula}EB2=4.8, resulting in a decrease in the overall expected utility to 8.6, despite the improvement in {a mathematical formula}A2's search competence.
      </paragraph>
     </section>
     <section label="4.4">
      <section-title>
       An improvement in the available fallback value
      </section-title>
      <paragraph>
       This enhancer relates to the case where the agents are already familiar with a value they can use (i.e., a fallback value) before starting the joint search, or, when continuous communication is used, the agents learn about a better value based on which they should decide on their next search decisions.
      </paragraph>
      <paragraph>
       Fig. 5 depicts the effect of the best value that has been found so far (v) and the number of remaining search periods on the probability of engaging in search (graph (a)) and the individual expected utility (graph (b)) in the self-interested setting with continuous communication. The setting uses three agents and the search cost is 0.1 (i.e., {a mathematical formula}k=3 and {a mathematical formula}c=0.1). The figure considers the totally mixed equilibrium applicable for that setting. The decrease observed in the value of p as v increases is explained by the decrease in the attractiveness of further search whenever a better value is available a priori. Similar to the case of fully cooperative agents, here the increase in the number of remaining search periods results in a reduced individual search probability (which is equivalent to a decrease in the number of searching agents in the fully cooperative case). The influence of the best value found thus far and the number of remaining opportunities over the expected utility, however, is strikingly opposite to the one that holds in the fully cooperative case; here an increase in these two parameters results in a decrease in the expected utility. Therefore, despite being at an initially superior starting point (i.e., with a greater search horizon and/or with a better known value) the agents end up with an inferior expected utility. We note that for {a mathematical formula}v&gt;0.554, the search probability becomes zero, i.e., the agents are happy with the fallback value they already have, and further individual search is not justified. Therefore, in this case, the agents do not incur any search costs, and the increase in v (i.e., starting with a greater fallback value) fully translates into an identical increase in the individual utility.
      </paragraph>
     </section>
     <section label="4.5">
      <section-title>
       Enabling continuous communication
      </section-title>
      <paragraph>
       Finally, we get to the use of continuous communication as a means of improving a joint search. There are many examples of individual and overall performance improvement due to the use of communication throughout the search process when the agents are self-interested. For example, consider a two-agent case with a search horizon of {a mathematical formula}n=2, a search cost of {a mathematical formula}c=0.01 and a discrete distribution of values, applicable to both agents' searches, where the value obtained is 1 with a probability of 0.5 and otherwise 0. When communication is continuous, the totally mixed equilibrium in this case results in an individual expected utility of 0.925. If communication is prohibited throughout the process, the agents' individual expected utility, according to the totally mixed equilibrium, is 0.922. In other words, the agents' expected utility increases by enabling communication between them throughout the search process.
      </paragraph>
      <paragraph>
       However, an improvement due to enabling continuous communication cannot be generally guaranteed in the case of self-interested agents. Fig. 6 depicts the expected utility of three homogeneous agents as a function of the different model parameters when communication is used along the process and when it is not. The figure shows that the phenomenon according to which the communication actually hinders individual performance in the self-interested case is common, and occurs in a wide range of settings, differing in their search horizon, the number of searching agents and search cost. The explanation of the phenomenon, as briefly discussed in the preceding section, is that while each agent finds the communication to be beneficial when on the receiving end, i.e., being informed that a lower price was found, it actually loses from such communication when on the reporting end since the report can potentially encourage the other agents to terminate their individual search.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      The model analyzed in this paper is based on two important concepts that are extensively researched in literature on multi-agent systems. The first is cooperation between agents and the second is costly search.
     </paragraph>
     <paragraph>
      In general, cooperation is a key concept that drives multi-agent systems. By joining efforts and acting in coordination/cooperation agents can better achieve their goals [72], [73] or improve their performance measures [36], [68], [18], [77], especially when there are differences in their capabilities, knowledge and resources and/or when an agent is incapable of completing a task by itself [8], [39]. In a more broader range, group based cooperative behavior can be found in various domains, such as solving complex optimization problems [75], [17], [77], [81], [82], [69], [60], military and rescue domains [17], [15], cognitive radio networks [60], [1], [80], e-business applications [77], [81], and many more. The introduction of ad-hoc and advanced mobile networks suggests a big boost for cooperative behavior in applications where agents' adaptation to changing resources, environments, user context, etc. is vital. The study of cooperation mechanisms for multi-agent cooperation is also highly common in robotics, e.g., for the purpose of cooperative patrolling [19], [20].
     </paragraph>
     <paragraph>
      The recognition of the advantages encapsulated in teamwork and cooperative behaviors, is the main driving force of many coalition formation models in the area of cooperative game theory and MAS [40], [68], [33], [27]. While coalition formation and coordination models can be widely found in the electronic market domain, most work in this domain emphasizes mechanisms for forming cooperation for the purpose of aggregating demands in order to obtain volume discounts [77], [81]. Additional coalition formation models for the electronic marketplace consider extensions of transaction-oriented coalitions to long-term ones [8], and for large-scale electronic markets [39]. Overall, the majority of cooperation and coalition formation MAS-related research tends to focus on the way coalitions are formed and consequently concerns issues such as the optimal division of agents into disjoint exhaustive coalitions [61], [81], division of coalition payoffs [81] and enforcement methods for interaction protocols [48]. Very few authors have considered the problem of determining the strategy of a group once formed [31], [62], [43], [63]; however, for the most part their focus was on fully-cooperative agents. None of these works considered the cooperation problem of a group of self-interested agents in costly search settings where findings can benefit all agents.
     </paragraph>
     <paragraph>
      Much work has been dedicated to developing mechanisms for collaboration between self-interested agents that act in a group in the planning domain [28], [74]. Nonetheless, these works considered the collaboration to be based on pre-defined protocols and behaviors the agents should have followed, dictated by the system designer, rather than pure selfishness considerations. For example, in [28] agents use threshold-criteria for deciding when to cooperate and often engage in activities that are not necessarily beneficial when considering only their own utility. The incentive for cooperation is the mutual belief that if everyone follows the pre-specified protocol then the overall gain will increase. In [74], the agents' cooperation derives from their need to maintain their “reputation”, as other agents will become reluctant to cooperate with an agent that acts selfishly.
     </paragraph>
     <paragraph>
      Group-based cooperation of self-interested agents can also be found in social good allocation games (e.g., in the centipede game [3], [50], [46]). Common to these games is that according to their equilibrium each agent individually should opt out as soon as possible or invest the minimum allowed. Therefore the research of cooperation in this domain is mainly limited to repeated games [66] or to the case of bounded-rational participants (e.g., people) for which cooperation is commonly shown to some extent. Much effort has been placed on developing reciprocity-based mechanisms, e.g., tit-for-tat [4] that facilitate cooperation even when agents find it momentarily beneficial to act selfishly. This way, long-term considerations override short-term greedy behavior. Many have extended the basic mechanism to support various variants of the model, such as asymmetric costs, heterogeneously repeating instances and other factors [67]. The main difference between social good allocation games and our work is thus the complexity of the settings used. In our settings there is much room for individual search, to some extent, even if all others are “free riders”. Moreover, with the simplistic settings used in social good allocation games, issues such as communication between the players, size of the group that act cooperatively, changes in the competence of individual players and issues of homogeneity and heterogeneity of the agents become irrelevant (when considering self-interested agents).
     </paragraph>
     <paragraph>
      The second concept upon which this paper relies, costly search, is an important inherent feature of MAS, in particular when there is no central source that can supply full immediate reliable information on the environment and the state of the other agents that can be found. The introduction of search costs into MAS models leads to a more realistic description of these environments. This is because agents are typically required to invest/consume some of their resources in order to obtain information concerning opportunities available in their environment [5], [65], [34].
     </paragraph>
     <paragraph>
      Optimal search strategies for settings where individuals need to search for an applicable opportunity while incurring a search cost have been widely studied, prompting several literature reviews [70], [47], [49]. These models have been developed to the point where their total contribution is referred to as “search theory”. Over the years, many search model variants have been considered, focusing on different aspects of the model, such as the decision horizon (finite versus infinite) [41], the presence of the recall option [47], the distribution of values and the extent to which findings remain valid along the process [38]. Nevertheless, search theory literature mainly investigates the extraction of an optimal stopping rule for the individual searching agent, and most often does not consider joint search. Few studies have attempted to extend the search to a multi-agent (or a multi-goal) search model, e.g., attempting to purchase several commodities while facing imperfect information concerning prices or operating several robots in order to evaluate opportunities in different locations [30], [63], [25], [10], [24], [11]. However, these works consider fully cooperative agents that attempt to maximize the overall utility. More importantly, the search considered in these models relies solely on a “representative agent” that explores on behalf of the group, rather than utilizing the fact that several agents can execute individual sequential searches in parallel. Since the search horizon in our model is finite (as in most real-life settings), the joint search strategy we provide for the fully cooperative case is more effective in terms of the resulting overall expected utility.
     </paragraph>
     <paragraph>
      Some prior works of ours have considered a multi-agent search model in which all agents take an active part in the search process [55], [56]. These works, however, assume that one agent's search process is constrained by the findings of the other agents, rather than augmented/improved by such findings as in our case. Consequently, the nature of the equilibrium set of search strategies used is substantially different. For example, since these models take the minimum among the values obtained, all agents must engage in search to some extent, and they cannot fully opt out pf searching. Furthermore, in [55] the agents are constrained to searching sequentially, with no coordination whatsoever. In [56], the agents are fully cooperative, and they all need to commit eventually to the same opportunity hence: (a) the model becomes inapplicable in the absence of continuous communication; and (b) all agents must follow the same search sequence and the same opportunity each time.
     </paragraph>
     <paragraph>
      Finally, we note that the non-intuitive findings according to which methods that are easily proved to be beneficial in the fully cooperative case, can actually have a negative impact in the self-interested case follows, in spirit, previous results in other settings. In particular, ones in which it has been shown that so-called “inefficiencies” can increase market performance, under certain circumstances. For example, Masters [45] shows that an increase in the minimum wage, which is often considered by economics as inefficiency, can have positive employment effects. In transportation economics (e.g. congestion games), equilibrium is frequently not the overall optimum. In such cases, it has been shown that taxation can change the equilibrium to a more desirable one [53], [52], [23]. Similarly, taxes can facilitate more desirable equilibria in Boolean games [21] and in centralized matching schemes [2]. In this work we show that a somehow similar phenomena also occur in the context of costly search, though the model and analysis are, of course, totally different from the above mentioned.
     </paragraph>
    </section>
    <section label="6">
     <section-title>
      Discussion and conclusions
     </section-title>
     <paragraph>
      The uniqueness of the analysis given in the paper is two-fold. First, the joint search model it uses does not rely on the notion of a “representative agent” that searches on behalf of the group, as in prior work, but rather utilizes the fact that several agents can execute individual search in parallel. This use of parallel search improves the group's performance whenever the search horizon is finite, which is the case in most real-life settings. Second, it allows agents to be self-interested, which makes the model more applicable (than the fully cooperative one used in prior work) whenever the agents represent different individuals with different goals or that cannot be forced to obey some external solution which is “socially beneficial”.
     </paragraph>
     <paragraph>
      The model is, of course, applicable to any multi-agent search application in which findings can benefit all agents, information can be shared (either throughout or at the end of the process) and costs and benefits are additive. From the practical aspect, the research of joint search has gained increasing importance with the rapid growth of ad-hoc cooperation and group formation over the Internet. Many new web-sites are now allowing users to achieve their goals by sharing their knowledge and information. The results reported in this paper are important inputs for such markets and system designers by enabling them to predict the strategies that will be used and the resulting system's performance. These primarily facilitate the proper design of the system and the determination of what elements should and should not be included in such systems in order to achieve specific goals and promote certain behavior. In particular, the introduction of some seemingly beneficial elements may actually be counterproductive. The paper illustrates the failure of several such “enhancers” when used with self-interested agents. The failure of these enhancers is explained by the stability requirement. That is, while better solutions that improve both individual and overall expected utilities by making use of these enhancers can be extracted, these solutions cannot hold as some of the agents have an incentive to individually deviate from them. The solutions that are stable in the latter case are based on an overall search to a lesser extent, resulting in degradation of overall and individual performance. The implication of these somehow non-intuitive results is that cooperation-enhancers should not be taken for granted and used as a default whenever some of the agents are self-interested. The idea of sub-optimal behavior resulting from self-interestedness is not new in itself and has been demonstrated in other various domains as discussed earlier in this paper. Nonetheless, the model and analysis given in this paper are totally different from the above mentioned and reveal the effect of unique properties of the costly search problem in such context.
     </paragraph>
     <paragraph>
      There are numerous extensions to the basic joint search model presented in this paper that are worth pursuing. For example, each individual agent may be interested in more than a single item. Similarly, the communication between the agents does not necessarily have to be reliable, and in some cases the agents may incur costs due to such communication. For some standard cost structures, the changes are straightforward, as discussed in the relevant analysis sections. For others, and for the case of noisy communication, substantial changes may be required. In fact, the introduction of noisy and/or costly communication can actually turn out to be beneficial, based on the examples given for the disadvantages of communication in these settings.
     </paragraph>
     <paragraph>
      Similarly, for the case where the agents are heterogeneous in terms of their goals, the amount of changes required in the analysis depends on the specific model variant used. For example, consider the case where each agent values differently the different opportunities and the agents may use any of the findings of others. In the fully cooperative joint search, the optimal joint-search strategy is no longer reservation-value based, but now relies on a reservation frontier [10]. This is because the state of the agents along their search, as a group, depends on the different values assigned to the attributes upon which the valuation functions are defined. As for the case of joint search with self-interested agents, here the change is simpler and mainly applies to the way the distribution of values obtained by others are calculated. The individual strategies remain reservation-value-based. In other cases, e.g., when using continuous communication or when all agents are constrained to eventually pick the same opportunity, among those searched, the changes are substantial, and many additional aspects need to be clarified first (e.g., how the agents decide on the opportunity that will be eventually selected in settings with conflicting preferences).
     </paragraph>
     <paragraph>
      Finally, the analysis given in the paper can be augmented for designing and testing methods and mechanisms that will increase the overall and/or individual welfare in joint search with self-interested agent settings. For the most part, the goal is to induce increased cooperation and individual search in cases where such cooperation is beneficial for the system as a whole, but strategically disadvantageous for the individual self-interested agent. Among these are methods for restructuring the incentives to promote cooperation and increase overall utility (e.g., by requiring all agents to pay a fee to the agent that found the lowest price), partitioning the agents into separate groups – each sharing its results only within the group – or limiting communication between agents. Other methods may include adding enforcement mechanisms into the system, which will require the agents to follow some prescribed behavior (e.g. search some fixed number of opportunities), achieved by allowing only the agents that agree to the enforcement to enjoy the results of other such agents.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <section-title>
      Proofs
     </section-title>
     <section label="A.1">
      <section-title>
       Proof for the stationarity of the reservation value in a single agent's search
      </section-title>
      <paragraph label="Proof">
       The reservation-value nature of the strategy is trivial. Since recall is allowed then if the agent prefers terminating search given the best known value v and {a mathematical formula}n′ remaining uncertain opportunities it will also prefer that choice when the best known value is {a mathematical formula}v′&gt;v (and {a mathematical formula}n′ remaining uncertain opportunities). The proof that the value of the reservation value does not depend on the number of remaining uncertain opportunities is inductive, showing that if with any number of remaining uncertain opportunities greater than {a mathematical formula}n′ the optimal choice is to use reservation value {a mathematical formula}ri then so is the case with {a mathematical formula}n′ remaining uncertain opportunities. The reservation value when only one uncertain opportunity is available derives from equating the search cost of that opportunity with the expected improvement obtained by the additional search, i.e., the search resumes for any v for which {a mathematical formula}ci&lt;∫y=v∞(y−v)fi(y)dy, resulting in a reservation value {a mathematical formula}ri according to Eq. (1). Now assume that the optimal reservation value to be used with any {a mathematical formula}n″&gt;n′ uncertain opportunities is {a mathematical formula}ri and consider the agent's decision regarding exploring one more opportunity, if the best value it obtained so far is x and the number of uncertain available opportunities is {a mathematical formula}n″. If {a mathematical formula}x&gt;ri and the agent executes one additional search, then regardless of the value obtained next the agent will definitely terminate the search after the additional search (as it already has a value greater than {a mathematical formula}ri). This is equivalent to resuming the search when the best value obtained thus far is x and only one uncertain opportunity is available. The latter choice however is not optimal according to the assumption that a reservation value {a mathematical formula}ri is used for any {a mathematical formula}n″&gt;n′ uncertain available opportunities. Similarly, if {a mathematical formula}x&lt;ri and the agent chooses not to resume the search, then in the next time period the agent will inevitably explore an additional opportunity according to the induction assumption. In this case, searching already in the current period dominates waiting and then resuming the search. □
      </paragraph>
     </section>
     <section label="A.2">
      Proof of Theorem 1
      <paragraph label="Proof">
       We first prove the reservation-value nature of the optimal strategy for agent {a mathematical formula}Ai. Then we continue with an inductive proof, showing that if the reservation value calculated according to (5) is indeed the optimal strategy for any number of available opportunities {a mathematical formula}n″&gt;n′ then this reservation value should also be used when the number of available opportunities is {a mathematical formula}n′.In the absence of any other new information along the search process, agent {a mathematical formula}Ai's strategy is the mapping {a mathematical formula}S(x→,n′)→{terminate,resume}, where {a mathematical formula}x→ is the set of values obtained so far and {a mathematical formula}n′ is the number of potential remaining search periods. Since the agent is interested merely in the maximum opportunity value, its strategy is affected only by the maximum value in {a mathematical formula}x→, hence the strategy can be defined in the form {a mathematical formula}S(x,n′)→{terminate,resume}, where x is the maximum value in {a mathematical formula}x→. Obviously, if according to the optimal strategy agent {a mathematical formula}Ai needs to resume the search upon reaching state {a mathematical formula}(x,n′) then the same should be true for any state {a mathematical formula}(x′,n′) where {a mathematical formula}x′&lt;x. Similarly, if according to the optimal strategy the search should terminate at state {a mathematical formula}(x,n′) then the same should hold for any state {a mathematical formula}(x″,n′) where {a mathematical formula}x″&gt;x. Therefore, for each given number of remaining search periods {a mathematical formula}n′, the optimal individual search strategy of agent {a mathematical formula}Ai can be characterized by the reservation value {a mathematical formula}rin′ such that the agent should resume the search if the best value obtained so far is below {a mathematical formula}rin′ and otherwise it should terminate the individual search process.We begin with the case of {a mathematical formula}n′=1. If the best value obtained so far by agent {a mathematical formula}Ai is x then exploring one last opportunity will incur an individual cost {a mathematical formula}ci and the expected value the agents will attain will be:{a mathematical formula} (where y is the value obtained from the explored opportunity and z is the best value obtained from the other agents' search). On the other hand, if the search is terminated when {a mathematical formula}n′=1, the overall expected utility is given by:{a mathematical formula} Therefore, agent {a mathematical formula}Ai should explore one last opportunity if and only if:{a mathematical formula} which transforms to:{a mathematical formula}Since the right-hand-side of the latter equality is a decreasing function of x, the agent should explore one last opportunity whenever the value of x is less than the value of {a mathematical formula}ri that satisfies (5). This establishes the first part of the proof. Now consider the agent's decision regarding exploring one more opportunity, if the best value it obtained so far is x, the number of opportunities that can still be potentially explored is {a mathematical formula}n′, and the optimal strategy for {a mathematical formula}n″&lt;n′ is to use reservation value {a mathematical formula}ri according to (5). If {a mathematical formula}x&gt;ri and the agent executes one additional search, then regardless of the value obtained next the agent will definitely terminate the search after the additional search (as it already has a value greater than {a mathematical formula}ri and according to the induction assumption the optimal strategy thereafter is the reservation value {a mathematical formula}ri). Therefore the utility obtained from exploring is given by {a mathematical formula}k∫y=−∞∞fi(y)∫z=−∞∞(max(y,x,z)−max(z,x))f¯i(z)dzdy−ci. Alas, since the latter term decreases as x increases, and obtains zero for {a mathematical formula}x=ri (according to (5)), then since {a mathematical formula}x&gt;ri the term obtains a negative value, hence an additional search cannot be the preferred choice.Similarly, if {a mathematical formula}x&lt;ri and the agent chooses not to explore one more opportunity, then in the next time period the agent will inevitably explore an additional opportunity according to the induction assumption. In this case, executing the search already in the current period dominates waiting and then searching. This is because searching in the current time period provides the same results if no search takes place in the subsequent period, however at the same time also enables an additional search period in case the current search yields a poor value. Therefore, the optimal strategy for {a mathematical formula}n′ is also a reservation value strategy and the optimal reservation value is calculated, once again, according to (5). □
      </paragraph>
     </section>
     <section label="A.3">
      Proof of Proposition 1
      <paragraph label="Proof">
       (d) The agents can simply maintain the same optimal strategy as if they do not know any value and use the known value as a fallback at the end of the search. □
      </paragraph>
     </section>
     <section label="A.4">
      Proof of Proposition 3
      <paragraph label="Proof">
       Assume otherwise, i.e., according to the optimal strategy S, for some j: {a mathematical formula}Kj′(v)=∅ and {a mathematical formula}Kj−1′(v)≠∅. Now consider an alternative strategy {a mathematical formula}S′, which is identical to S except that it executes no search when {a mathematical formula}j−1 search periods remain and also instead of using {a mathematical formula}Kj′(v)=∅, it uses the search guidelines set for the subsequent period (i.e., when {a mathematical formula}j−1 search periods remain) according to S. Since according to both S and {a mathematical formula}S′ the agents end up with the same distribution of values when only {a mathematical formula}j−2 search periods remain and the expected search cost is the same (as the same agents execute search in both strategies), the expected utility from both strategies is equal. However, it is possible that when the point with only {a mathematical formula}j−1 remaining search periods using {a mathematical formula}S′ is reached, the best known value has not changed despite the search that took place in the prior search period. In the latter case the optimal way to continue is obviously that some search be performed in the current search period (according to S which is assumed to be optimal). Therefore, strategy {a mathematical formula}S′ is certainly not optimal, and since its performance is equal to S, strategy S also cannot be the optimal one. □
      </paragraph>
     </section>
    </section>
    <section label="Appendix B">
     <section-title>
      Nomenclature
     </section-title>
     <paragraph>
      {a mathematical formula}
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>