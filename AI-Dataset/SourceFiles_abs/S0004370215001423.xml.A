<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    A hybrid exact algorithm for complete set partitioning.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      The Complete Set Partitioning problem models the setting where every subset of a finite set is associated with a (positive or negative) real value, and the goal is to partition the set into pairwise disjoint subsets so as to maximise the sum of the subset values.{sup:2} This problem captures a number of important applications. For instance, early papers on its algorithmic complexity were motivated by the structuring of corporate tax in the United States [20], [21], [22] (see Section 7 for details). More recently, Complete Set Partitioning has been studied in the context of combinatorial auctions [36], [18], where there are multiple different items for sale, each bidder can place a bid on every subset of items, and the auctioneer's goal is to allocate the items to the bidders (and charge each bidder what she bid for the set of items she received) so as to maximise the total profit. It also plays an important role in the analysis of cooperation in multi-agent systems. Indeed, one of the most important aspects of such systems is the agents' ability to interact with one another in order to improve their performance and compensate for each other's deficiencies. One means of interaction that has been extensively studied in the literature is to form a coalition, i.e., a group of agents that agree to coordinate their activities (and possibly agree on how the reward from cooperation should be divided among them) in order to achieve a certain objective. The settings where the total worth of a coalition is determined solely by the identities of its members (and not by other co-existing coalitions) can be modelled by characteristic function games. In such games, we are given a set of agents, denoted by A, and the value of every subset, or coalition, of agents is specified by a characteristic function{a mathematical formula}v:2A→R. To optimise the social welfare, we need to find a partition of agents into coalitions (a coalition structure) that maximises the sum of the values of the coalitions in the partition. A wide range of potential applications of coalition formation have been considered in the literature. For instance, by forming coalitions, autonomous sensors can improve their surveillance of certain areas [13], green-energy generators can reduce their uncertainty regarding their expected energy output [7], cognitive radio networks can increase their throughput [16], and buyers can obtain cheaper prices through bulk purchasing [19]; see the work of Sandholm et al. [38] and Rahwan et al. [35] for further examples.
     </paragraph>
     <paragraph>
      In this article, our main goal is to improve our understanding of the complete set partitioning problem and to develop exact algorithms for this problem. Observe that the input to the complete set partitioning problem is a list of {a mathematical formula}2n−1 real values (where n is the size of the ground set), and every algorithm that is guaranteed to find an optimal solution on every instance of this problem has to inspect all of these values. Thus, the running time of every exact algorithm is at least exponential in n, and in some of the applications we have discussed (such as combinatorial auctions or multi-agent systems) the value of n can be quite large. Therefore, an important goal is to design an algorithm that can find an optimal partition as efficiently as possible, both in the worst case and on average (for realistic value distributions).
     </paragraph>
     <paragraph>
      The main techniques used in exact algorithms for solving computationally hard problems are: (1) dynamic programming, (2) tree search, (3) data preprocessing, and (4) local search [47]. With respect to our problem, we focus on two exact algorithms, which are based on techniques (1) and (2), respectively. Specifically:
     </paragraph>
     <list>
      <list-item label="•">
       DP: This algorithm was originally proposed by Yeh [48] to solve the complete set partitioning problem, and was re-discovered by Rothkopf et al. [36], who used it to solve the winner determination problem in combinatorial auctions. This algorithm is based on dynamic programming: to find an optimal partition of the set of agents A, we start by computing an optimal partition of every subset {a mathematical formula}C⊆A with {a mathematical formula}|C|=2, then use those to compute an optimal partition of every {a mathematical formula}C⊆A with {a mathematical formula}|C|=3, and so on, until an optimal partition of A is found.
      </list-item>
      <list-item label="•">
       IP: This algorithm, which was proposed by Rahwan et al. [32] for the coalition structure generation problem, is based on a representation of the search space that groups partitions into disjoint subspaces based on the sizes of the subsets within each partition. With this representation, it is possible to compute upper and lower bounds on the quality of the best solution in each subspace. By comparing the bounds for different subspaces, it is possible to identify, and thus focus on, the promising subspaces. For every such subspace, the algorithm constructs multiple search trees, where every node represents a subset, and every path (from a root node to a leaf node) represents a partition. Every such tree is traversed in a depth-first manner. To speed up the search, IP applies a branch-and-bound technique to identify and avoid branches that have no potential of containing an optimal solution.
      </list-item>
     </list>
     <paragraph>
      The above two algorithms are based on fundamentally different design paradigms, so it is not surprising that they exhibit quite different computational behaviour. More specifically, in what follows, we provide a comparison of these algorithms from three different perspectives:
     </paragraph>
     <list>
      <list-item label="•">
       Worst case performance: The time required to exhaustively enumerate all partitions of an n-element set is {a mathematical formula}Ω(nn/2)[38]. Such enumeration, however, involves repeating certain operations multiple times. As mentioned earlier, DP avoids such repetition by storing partial solutions in memory, thereby lowering the required time to {a mathematical formula}O(3n). On the other hand, the techniques used by IP to speed up the search cannot ensure that the worst-case time drops below {a mathematical formula}nn/2. This is because the effectiveness of IP is strongly influenced by the proportion of the search space that it identifies as being unpromising. This proportion, in turn, depends on the values of the subsets. It is possible to define a class of problem instances for which IP searches the entire space exhaustively (e.g., one in which every set {a mathematical formula}{a1,…,as} with {a mathematical formula}s∈{1,…,n} has a value of 1, and every other set has a value of 0).
      </list-item>
      <list-item label="•">
       Average performance: When tested on popular value distributions, IP has been shown to be faster than DP, by several orders of magnitude for some distributions [32]. This is because, in practice, IP is able to identify many (if not the vast majority of) subspaces and/or branches of the search trees as being unpromising. DP, on the other hand, is not capable of any such shortcuts.
      </list-item>
      <list-item label="•">
       Returning solutions anytime: IP has the advantage of being an anytime algorithm: it returns a valid solution very quickly, and then improves on the quality of its solution over time, while establishing progressively-better guarantees on solution quality. DP, on the other hand, is not an anytime algorithm; it can only return a solution once it has successfully terminated. Being anytime is important since the size of the search space grows exponentially with the number of elements to be partitioned, and hence there might not always be sufficient time to run the algorithm to completion. Moreover, being anytime makes the algorithm more robust against failure; if the execution is stopped before the algorithm would normally have terminated, then it can still provide a solution that is better than the initial one, and the quality of this solution improves over time.
      </list-item>
     </list>
     <paragraph>
      The above comparison shows that each algorithm has its relative strengths and weaknesses compared to the other. In other words, there is a trade-off between the advantages of one algorithm and the advantages of the other. This raises the following question: Is this trade-off inevitable?
     </paragraph>
     <paragraph>
      Against this background, the main contributions of this article are three-fold:
     </paragraph>
     <list>
      <list-item label="•">
       Analysing the search space: We provide a theoretical analysis of the search space, which reveals how two fundamentally different exact algorithms can be combined and significantly improved upon in terms of actual runtime. This, in turn, contributes towards a better understanding of the set partitioning problem itself, and a better understanding of the complementarities that evidently exist between two algorithm-design paradigms, namely Dynamic Programming and Depth-First Search.
      </list-item>
      <list-item label="•">
       Developing ODP: We draw a link between the workings of DP and the coalition structure graph—a graphical representation of the search space due to Sandholm et al. [38], where every node represents a partition. This link provides an intuitive interpretation of DP's operations: the algorithm evaluates all the movements along the edges of the aforementioned graph, and stores the most beneficial movements in a table. Then, starting from the node where all items are in one set, DP makes a series of movements until it reaches an optimal node. This visualisation suggests that certain movements are not needed to reach an optimal node. We formalise this observation and use it to design our Optimal Dynamic Programming (ODP) algorithm, which performs only one third of DP's operations, without losing the guarantee of finding a best partition. ODP is optimal in that it avoids all redundant operations without losing the guarantee of finding an optimal solution.
      </list-item>
      <list-item label="•">
       Developing ODP-IP: As we will show, ODP and IP approach the optimisation problem in different ways. Nevertheless, instead of viewing these as two alternative choices, we develop a new search-space representation that draws a link between the two algorithms, and reveals the potential of combining them into a single, superior algorithm. Building upon this analysis, we refine both algorithms, and use the refined versions as building blocks to construct a hybrid approach, called ODP-IP. The ODP-IP algorithm runs its two constituent algorithms in parallel, and uses the information provided by ODP to speed up IP's search. This approach results in an algorithm that has the best features of its components: it runs in {a mathematical formula}O(3n) just like ODP, and returns solutions anytime, with progressively-better guarantees, just like IP. Better still, when tested on a wide variety of value distributions, ODP-IP is empirically shown to significantly outperform both ODP and IP in all cases.{sup:3}
      </list-item>
     </list>
     <paragraph>
      Importantly, we benchmarked our algorithms against the primary alternative proposed in the literature, namely the inclusion–exclusion algorithm of Björklund et al. [8], which is an exact dynamic-programming algorithm for set partitioning that is built around the inclusion–exclusion principle. From a theoretical perspective, this is the state-of-the-art algorithm in terms of worst-case complexity; it runs in {a mathematical formula}O(2n) time. However, when implementing it, we found that it requires multiplying numbers that consist of hundreds of digits, which tends to be costly in practice. As a consequence, in our tests the runtime of this algorithm grows at a rate of {a mathematical formula}O(6n) rather than {a mathematical formula}O(2n). For instance, given 15 agents, the algorithm requires more than five months to terminate, while our algorithm for the worst-case problem instance takes 0.01 second (see Section 6.3 for more details). Thus, ours is the fastest exact algorithm for complete set partitioning to date.
     </paragraph>
     <paragraph>
      The open-source Java implementation of all the algorithms discussed or developed in this article (namely, IP, DP, ODP, ODP-IP, as well as the inclusion–exclusion algorithm by Björklund et al. [8]) is publicly available at the following link: https://github.com/trahwan/ODP-IP_and_InclusionExclusion.
     </paragraph>
     <paragraph>
      The remainder of this article is structured as follows. Section 2 formalises the complete set partitioning problem. Section 3 provides detailed descriptions of IP and DP. Section 4 presents ODP—our optimal version of DP, while Section 5 presents our hybrid algorithm, ODP-IP. The two new algorithms are then evaluated in Section 6. The related literature is discussed in Section 7. Section 8 concludes the article and outlines future work. Appendix A provides a summary of the main notation used throughout the article. Appendix C and Appendix D contain the omitted proofs, while Appendix E discusses a certain aspect of ODP-IP in detail.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Preliminaries
     </section-title>
     <paragraph>
      In this section, we formally introduce the key definitions and notation used throughout the article. In what follows, we use the language of cooperative game theory, i.e., we talk about the coalition structure generation problem rather than the complete set partitioning problem. The reason for this is twofold. First, much of the recent work on this topic was done within the multi-agent research community, which views this problem from the coalition structure generation perspective, so adopting the language of cooperative games facilitates the comparison with prior work. The second reason is purely linguistic: when speaking about coalition structure generation, we refer to subsets of agents as “coalitions”, and thus avoid the overuse of the term “set”.
     </paragraph>
     <paragraph>
      An instance of the Coalition Structure Generation problem is given by a finite set {a mathematical formula}A={a1,a2,…,an} and a function v that assigns a real value to every non-empty subset of A. We refer to every non-empty subset of A as a coalition. We denote by {a mathematical formula}CA the set of coalitions over A, i.e., {a mathematical formula}CA={C:C⊆A,C≠∅}; we have {a mathematical formula}|CA|=2n−1. For any two coalitions {a mathematical formula}C1,C2∈CA, we write {a mathematical formula}C1&lt;C2 when {a mathematical formula}C1 precedes {a mathematical formula}C2 lexicographically, e.g., we write {a mathematical formula}{a1,a3,a9}&lt;{a1,a4,a5} and {a mathematical formula}{a4}&lt;{a4,a5}.
     </paragraph>
     <paragraph>
      An exhaustive partition of all the agents in a given set {a mathematical formula}C⊆A into disjoint coalitions is called a coalition structure over C. Formally, a coalition structure is defined as follows.
     </paragraph>
     <paragraph label="Definition 1">
      Given a subset {a mathematical formula}C⊆A, a coalition structure over C is a collection of coalitions {a mathematical formula}CS={C1,…,C|CS|} that satisfies the following conditions: {a mathematical formula}⋃j=1|CS|Cj=C, and for all {a mathematical formula}i,j∈{1,…,|CS|} such that {a mathematical formula}i≠j it holds that {a mathematical formula}Ci∩Cj=∅.
     </paragraph>
     <paragraph>
      For each {a mathematical formula}C⊆A, we will denote by {a mathematical formula}ΠC the set of all coalition structures over C. Furthermore, given a coalition structure {a mathematical formula}CS∈ΠC, we will refer to the sum of the values of all coalitions in CS as the value of CS, and denote it by {a mathematical formula}V(CS). Formally, {a mathematical formula}V(CS)=∑C′∈CSv(C′). We are now ready to state our optimisation problem formally.
     </paragraph>
     <paragraph label="Definition 2">
      The coalition structure generation problem is to find an optimal coalition structure {a mathematical formula}CS⁎∈ΠA, i.e., an (arbitrary) element of the set{a mathematical formula}
     </paragraph>
     <paragraph>
      Given a coalition {a mathematical formula}C⊆A, we denote by {a mathematical formula}f(C) the value of an optimal partition of C, i.e., {a mathematical formula}f(C)=V(CS), where {a mathematical formula}CS∈argmaxCS∈ΠCV(CS).
     </paragraph>
     <paragraph>
      The coalition structure generation problem is computationally challenging, as the number of possible coalition structures over n players, which is known as the n-th Bell number{a mathematical formula}Bn[6], satisfies {a mathematical formula}αnn/2≤Bn≤nn for some positive constant α (see, e.g., the work of Sandholm et al. [38] for proofs of these bounds, and the book of de Bruijn [10] for an asymptotically tight bound). Moreover, it is NP-hard to find an optimal coalition structure given oracle access to the characteristic function [38].
     </paragraph>
     <paragraph>
      Since every coalition structure represents a possible solution to the coalition structure generation problem, the terms “coalition structure” and “solution” will be used interchangeably. Furthermore, the set of possible coalition structures will often be referred to as the “search space”.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      The IP algorithm vs. the DP algorithm
     </section-title>
     <paragraph>
      In this section we provide a detailed description of the main exact algorithms in the literature: (1) IP—the anytime, depth-first search algorithm by Rahwan et al. [30], and (2) DP—the dynamic programming algorithm by Yeh [48].
     </paragraph>
     <section label="3.1">
      <section-title>
       The IP algorithm
      </section-title>
      <paragraph>
       The IP algorithm is based on the integer partition-based representation[29] of the space of possible coalition structures. This representation divides the space into disjoint subspaces that are each represented by an integer partition of n. Recall that an integer partition of n is a multiset of positive integers, or parts, whose sum (with multiplicities) is equal to n[1]. We denote the set of all integer partitions of n by {a mathematical formula}In. For instance, {a mathematical formula}I4={{4},{1,3},{2,2},{1,1,2},{1,1,1,1}}. In the IP algorithm, every integer partition {a mathematical formula}I∈In corresponds to a subspace{a mathematical formula}ΠIA⊆ΠA consisting of all coalition structures in which the sizes of the coalitions match the parts of I. For instance, {a mathematical formula}Π{1,1,2}{a1,a2,a3,a4} is the subspace consisting of all coalition structures over {a mathematical formula}{a1,a2,a3,a4} that contain two coalitions of size 1 and one coalition of size 2. A four-agent example is shown in Fig. 1.
      </paragraph>
      <paragraph>
       Using this representation, it is possible to compute upper and lower bounds on the value of the best coalition structure that can be found in each subspace. To this end, for every coalition size {a mathematical formula}s∈{1,2,…,n}, let {a mathematical formula}CsA denote the set of all possible coalitions of size s. Furthermore, let {a mathematical formula}Maxs and {a mathematical formula}Avgs be the maximum and average values of the coalitions in {a mathematical formula}CsA, respectively. Rahwan et al. [32] prove that, by computing {a mathematical formula}Avgs for all {a mathematical formula}s∈{1,2,…,n}, it is possible to compute the average value of the coalition structures in each subspace {a mathematical formula}ΠIA, {a mathematical formula}I∈In, as follows.
      </paragraph>
      <paragraph label="Theorem 3">
       (See Rahwan et al.[32].) For every{a mathematical formula}I∈In, let{a mathematical formula}I(i)be the multiplicity of i in I. Then{a mathematical formula}
      </paragraph>
      <paragraph>
       Since the value of the best coalition structure in {a mathematical formula}ΠIA is at least the average value of the coalition structures in {a mathematical formula}ΠIA, we obtain the following lower bound on the value of the best coalition structure in {a mathematical formula}ΠIA: {a mathematical formula}LBI=∑i∈II(i)Avgi. By replacing {a mathematical formula}Avgi with {a mathematical formula}Maxi in this expression, we obtain an upper bound{a mathematical formula}UBI on the value of the best coalition structure in {a mathematical formula}ΠIA: {a mathematical formula}UBI=∑i∈II(i)Maxi. Using these bounds, the algorithm computes an upper bound {a mathematical formula}UB⁎=maxI∈In⁡UBI and a lower bound {a mathematical formula}LB⁎=maxI∈In⁡LBI on the value of an optimal coalition structure {a mathematical formula}CS⁎. Knowing {a mathematical formula}UB⁎ enables us to bound the quality of {a mathematical formula}CS⁎⁎—the best coalition structure found by the algorithm at a given point in time; we set {a mathematical formula}β=UB⁎/V(CS⁎⁎).{sup:4} On the other hand, computing {a mathematical formula}LB⁎ is useful for identifying subspaces that have no potential of containing an optimal coalition structure: these are subspaces {a mathematical formula}ΠIA with {a mathematical formula}UBI&lt;LB⁎. These subspaces are pruned from the search space. As for the remaining subspaces, the algorithm searches them one at a time. During this search, if a solution is found whose value is greater than {a mathematical formula}V(CS⁎⁎), then the algorithm updates {a mathematical formula}CS⁎⁎ by setting it to the newly found solution. If {a mathematical formula}LB⁎&lt;V(CS⁎⁎), the algorithm also updates {a mathematical formula}LB⁎ by setting it to {a mathematical formula}V(CS⁎⁎), and repeats the attempt of pruning unpromising subspaces, i.e., those whose upper bounds are smaller than the updated {a mathematical formula}LB⁎. The order in which the subspaces are searched is always based on the upper bounds: out of all the remaining subspaces, the one with the highest upper bound is searched first. Next, we explain how a subspace is searched.
      </paragraph>
      <paragraph>
       The process of searching a subspace, say {a mathematical formula}ΠIA, where {a mathematical formula}I={i1,…,ik}, is carried out in a depth-first manner: the algorithm iterates over the coalitions in {a mathematical formula}Ci1A and, for every coalition {a mathematical formula}C1∈Ci1A that the algorithm encounters, it iterates over the coalitions in {a mathematical formula}Ci2A that do not overlap with {a mathematical formula}C1. Similarly, for every coalition {a mathematical formula}C2∈Ci2A that the algorithm encounters, it iterates over the coalitions in {a mathematical formula}Ci3A that do not overlap with {a mathematical formula}C1∪C2, and so on. This process is repeated until the last set, {a mathematical formula}CikA, is reached. In this way, by the time the algorithm picks the last coalition {a mathematical formula}Ck∈CikA, it has selected a combination of {a mathematical formula}k−1 coalitions that, together with {a mathematical formula}Ck, form a coalition structure in {a mathematical formula}ΠIA. The algorithm repeats this process so that, eventually, every coalition structure in {a mathematical formula}ΠIA is examined. Here, it should be noted that a straightforward repetition of the aforementioned process would not be efficient, because some of the coalition structures will be examined multiple times. For instance, every coalition structure {a mathematical formula}{C1,C2,C3}∈Π{2,2,3}A will be examined twice, once as {a mathematical formula}{C1,C2,C3} and once as {a mathematical formula}{C2,C1,C3}, because in this example we have {a mathematical formula}|C1|=|C2|. Rahwan et al. [32] explain how IP avoids such redundant operations.
      </paragraph>
      <paragraph>
       To speed up the search, IP applies a branch-and-bound technique at every depth {a mathematical formula}d&lt;k. Specifically, after fixing d coalitions {a mathematical formula}C1∈Ci1A,…,Cd∈CidA, and before iterating over the relevant coalitions in {a mathematical formula}Cid+1A,…,CikA, it checks whether{a mathematical formula} Now, if inequality (1) holds, every coalition structure containing {a mathematical formula}C1,…,Cd can be skipped during the search, because its value cannot be greater than {a mathematical formula}V(CS⁎⁎)—the value of the best coalition structure found by the algorithm so far. Fig. 2 provides an illustration of how IP searches {a mathematical formula}Π{1,3,4}A given 8 agents.
      </paragraph>
      <paragraph>
       As mentioned earlier, before IP can use the branch-and-bound technique, it needs to compute {a mathematical formula}Maxi and {a mathematical formula}Avgi for all {a mathematical formula}i∈{1,…,n}. To do so, the algorithm iterates over the values of all coalitions, in order to compute the average and maximum values for coalitions of every size. One way to perform this iteration is to first go through all coalitions of size 1 (to compute {a mathematical formula}Max1 and {a mathematical formula}Avg1), then through all coalitions of size 2 (to compute {a mathematical formula}Max2 and {a mathematical formula}Avg2), then size 3 and so on. However, to allow for certain subspaces to be searched during the iteration process, IP goes through the coalitions in a different order. More specifically, it iterates over all coalitions of size {a mathematical formula}s∈{1,…,⌊n/2⌋} in lexicographic order, while simultaneously iterating over all coalitions of size {a mathematical formula}n−s in anti-lexicographic order.{sup:5} With this order, the i-th coalition of size s and the i-th coalition of size {a mathematical formula}n−s form a coalition structure in {a mathematical formula}Π{s,n−s}A. By going through every such pair, IP examines every coalition structure in {a mathematical formula}Π{s,n−s}A. By the end of this process, every subspace {a mathematical formula}ΠIA with {a mathematical formula}|I|=2 is searched.
      </paragraph>
      <paragraph>
       The IP algorithm runs in {a mathematical formula}O(nn) time, and in the worst case it can end up constructing every possible coalition structure. In practice, however, IP has been shown to run significantly faster than DP given popular coalition-value distributions. Furthermore, the bound that IP generates, i.e., {a mathematical formula}β=UB⁎/V(CS⁎⁎), has been shown to improve rapidly during the search process, e.g., reaching {a mathematical formula}90% when less than a {a mathematical formula}10−9 fraction of the search space for 25 agents has been searched (given certain value distributions).
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       The DP algorithm
      </section-title>
      <paragraph>
       The DP algorithm is based on the following theorem.
      </paragraph>
      <paragraph label="Theorem 4">
       (See Yeh[48].) Given a coalition{a mathematical formula}C⊆A, the value of an optimal partition of C can be computed recursively as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       The pseudocode of DP is given in Algorithm 1. For every coalition {a mathematical formula}C⊆A, the algorithm computes {a mathematical formula}f(C) as well as {a mathematical formula}t(C)—a variable that provides an indication of the optimal partition of C. Once {a mathematical formula}f(C) and {a mathematical formula}t(C) are computed for every {a mathematical formula}C⊆A, an optimal coalition structure {a mathematical formula}CS⁎ is computed recursively. A four-agent example is illustrated in Fig. 3.
      </paragraph>
      <paragraph>
       DP requires storing a total of {a mathematical formula}2n+1 values, namely {a mathematical formula}f(C) and {a mathematical formula}t(C) for every {a mathematical formula}C⊆A. This memory requirement is not burdensome since we are dealing with the complete set partitioning problem, and the input to this problem contains {a mathematical formula}2n values already. In other words, we implicitly assume there is {a mathematical formula}O(2n) available space.
      </paragraph>
      <paragraph>
       The running time of DP has been shown to be {a mathematical formula}O(3n)[48]. This is significantly less than {a mathematical formula}Ω(nn/2)—the time required to exhaustively enumerate all coalition structures. However, the disadvantage is that DP provides no interim solution before completion, meaning that it is not possible to trade computation time for solution quality.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Improving the DP algorithm
     </section-title>
     <paragraph>
      In this section, we present the first contribution of this article, which is an optimal version of DP. More specifically, in Section 4.1 we demonstrate that there exists a strong link between the way DP works and the way nodes are connected in a certain graph. Based on this link, we analyse in Section 4.2 the effect of avoiding certain operations of DP. Building upon this analysis, we present in Section 4.3 our optimal dynamic programming (ODP) algorithm—a modified version of DP that avoids all the redundant operations of DP, without losing the guarantee of finding an optimal solution.
     </paragraph>
     <section label="4.1">
      <section-title>
       The link between DP and the coalition structure graph
      </section-title>
      <paragraph>
       To obtain a deeper understanding of how DP works, we consider the coalition structure graph[38]. In this undirected graph, every node represents a coalition structure. These nodes are categorised into n levels, namely {a mathematical formula}Π1A,…,ΠnA, so that level {a mathematical formula}ΠiA is composed of the nodes that represent coalition structures containing exactly i coalitions each. An edge connects two coalition structures if and only if (1) they belong to two consecutive levels {a mathematical formula}ΠiA and {a mathematical formula}Πi−1A, and (2) the coalition structure in {a mathematical formula}ΠiA can be obtained from the one in {a mathematical formula}Πi−1A by splitting one coalition into two. Fig. 4 shows a four-agent example of the coalition structure graph. It also shows the values of all coalition structures based on the characteristic function from Fig. 3.
      </paragraph>
      <paragraph>
       This graph enables us to visualise how DP works. To this end, observe that every movement upwards in the graph (between adjacent nodes) corresponds to splitting one coalition into two (see Fig. 4). Based on this observation, we can divide the work of DP into three main tasks, which can all be seen on the graph.
      </paragraph>
      <list>
       <list-item label="1.">
        Task 1: evaluate all the movements in the graph: For every coalition C with {a mathematical formula}|C|≥2, the algorithm evaluates every partition{a mathematical formula}{C′,C″}∈ΠC by computing {a mathematical formula}f(C′)+f(C″) (see line 9 of the pseudocode). This can be interpreted as evaluating every movement that involves splitting C in two. Since the algorithm does this for every possible coalition of size {a mathematical formula}s≥2, all the movements in the graph are eventually evaluated.
       </list-item>
       <list-item label="2.">
        Task 2: store the most beneficial movements: In lines 8–11, the algorithm determines, for every coalition C, whether it is beneficial to make a movement that involves splitting C and, if so, what is the best such movement (this decision is stored in {a mathematical formula}t(C)). In terms of the coalition structure graph, this step can be interpreted as follows. Setting {a mathematical formula}t(C)={C} means that, from any node representing a coalition structure {a mathematical formula}CS∋C, it is not beneficial to make a movement that involves splitting C. On the other hand, setting {a mathematical formula}t(C)={C′,C″} means that, from any node representing {a mathematical formula}CS∋C, one of the most beneficial movements is to split C into {a mathematical formula}C′ and {a mathematical formula}C″.
       </list-item>
       <list-item label="3.">
        Task 3: move upwards in the graph: This occurs in lines 12 to 16. Here, DP first initialises {a mathematical formula}CS⁎ by setting {a mathematical formula}CS⁎={A}. This means that DP starts at the node that represents {a mathematical formula}{A}, i.e., the bottom node in the graph. After that, DP selects some coalition {a mathematical formula}C∈CS⁎ with {a mathematical formula}t(C)≠{C} (if such a coalition exists), and replaces it with {a mathematical formula}t(C). By doing this, DP makes a movement that involves splitting C into the two coalitions that are stored in {a mathematical formula}t(C). This process is repeated until {a mathematical formula}t(C)={C} for all {a mathematical formula}C∈CS. In other words, DP keeps moving upwards in the graph through a series of connected nodes—a “path”—until it reaches a node after which no movement is beneficial. For instance, in our example from Fig. 3, the way DP reached {a mathematical formula}{{a1},{a2},{a3,a4}} can be visualised as a sequence of movements through the dashed path in Fig. 4, where the first movement involved splitting {a mathematical formula}{a1,a2,a3,a4} into {a mathematical formula}{a1,a2} and {a mathematical formula}{a3,a4}, and the second movement involved splitting {a mathematical formula}{a1,a2} into {a mathematical formula}{a1} and {a mathematical formula}{a2}.
       </list-item>
      </list>
      <paragraph>
       From this visualisation it is clear that, for every coalition structure CS with {a mathematical formula}|CS|&gt;2, there are multiple paths that start from the bottom node of the graph and end with the node that contains CS. For example, in Fig. 4 one could reach {a mathematical formula}{{a1},{a2},{a3,a4}} through three different paths, which are highlighted using dotted, dashed, and bold edges, respectively. Furthermore, if there are multiple paths that lead to the same optimal node, DP can reach this node through any of those paths. Indeed, we have not specified in which order the algorithm goes through the possible splits of C (line 8), and for every choice of {a mathematical formula}{C′,C″} from {a mathematical formula}argmax{C′,C″}∈ΠC(f(C′)+f(C″)) there exists an order that results in {a mathematical formula}t(C) being set to {a mathematical formula}{C′,C″}. For example, in Fig. 3, {a mathematical formula}t({a1,a2,a3,a4}) was set to {a mathematical formula}{{a1,a2},{a3,a4}} because this was one of the movements evaluated to 150. However, {a mathematical formula}t({a1,a2,a3,a4}) could have been set to {a mathematical formula}{{a1},{a2,a3,a4}} instead, since this movement is also evaluated to 150. If that happened, DP would have found, based on {a mathematical formula}t({a2,a3,a4}), that it is beneficial to split {a mathematical formula}{a2,a3,a4} into {a mathematical formula}{a2} and {a mathematical formula}{a3,a4}. As a result, the same optimal solution (i.e., {a mathematical formula}{{a1},{a2},{a3,a4}}) would have been found, but through the dotted path rather than the dashed one.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Analysing the effect of avoiding certain operations in DP
      </section-title>
      <paragraph>
       We have shown that DP evaluates all the movements in the coalition structure graph, stores the best ones in the table t, and then selects from t the movements that together form a path from the bottom node to an optimal node. We have also shown that DP is indifferent among the paths that lead to the same optimal node. All of these observations raise an important question: “what happens if DP is modified so that it only evaluates some of the movements in the graph?” Suppose that for a certain coalition C the algorithm did not evaluate some movement that involves splitting C into two coalitions, namely {a mathematical formula}C1 and {a mathematical formula}C2. That is, suppose that the term {a mathematical formula}ΠC in line 8 of the pseudocode was replaced with {a mathematical formula}ΠC\{{C1,C2}}. In this case, the movement stored in {a mathematical formula}t(C) would be the best out of all the movements that DP has evaluated (i.e., excluding the one in which C is split into {a mathematical formula}C1 and {a mathematical formula}C2). As a result, since DP always selects its movements from the table t, whenever a coalition structure {a mathematical formula}CS∋C is reached, the movement to {a mathematical formula}CS′=(CS\{C})∪{C1,C2} would no longer be an option. In other words, DP would ignore the existence of the edge that connects CS to {a mathematical formula}CS′, evaluate the movements through the remaining edges, and decide on its path accordingly. This can be visualised on the graph by removing the edge that connects CS to {a mathematical formula}CS′. Now, if {a mathematical formula}CS′ happened to be the only optimal solution in the graph, and if the removed edge happened to be the only one leading to {a mathematical formula}CS′, then DP would no longer be able to find the optimal solution. We formalise this observation in the remainder of this section.
      </paragraph>
      <paragraph>
       Given two disjoint coalitions {a mathematical formula}C1 and {a mathematical formula}C2, let {a mathematical formula}mC1,C2 denote the movement that corresponds to splitting {a mathematical formula}C=C1∪C2 into {a mathematical formula}C1 and {a mathematical formula}C2. Observe that the movement {a mathematical formula}mC1,C2 can be made through different edges in the coalition structure graph. More precisely, it can be made through any edge that connects a coalition structure {a mathematical formula}CS∋C to the coalition structure {a mathematical formula}CS′=(CS\{C})∪{C1,C2}. Further, let {a mathematical formula}M denote the set of all possible movements in the coalition structure graph, i.e., {a mathematical formula}M={mC1,C2:C1,C2⊆A,C1∩C2=∅}. Now, given a coalition {a mathematical formula}C⊆A, a subset of movements {a mathematical formula}M⊆M and two partitions {a mathematical formula}π,π′∈ΠC, we write {a mathematical formula}π→Mπ′ if and only if {a mathematical formula}π′ can be reached from π via a single movement in M. That is, we set{a mathematical formula}
      </paragraph>
      <paragraph>
       While {a mathematical formula}→M expresses the notion of reachability with respect to single movements from M, the following definition generalises this notion to multiple movements.
      </paragraph>
      <paragraph label="Definition 5">
       Given a coalition {a mathematical formula}C⊆A, a subset of movements {a mathematical formula}M⊆M and two partitions {a mathematical formula}π,π′∈ΠC, we say that {a mathematical formula}π′is reachable from π via M, and write {a mathematical formula}π⇝Mπ′, if and only if {a mathematical formula}π′ is either equal to π, or can be reached from π via one or more movements in M. More formally,{a mathematical formula}
      </paragraph>
      <paragraph>
       Given a coalition {a mathematical formula}C⊆A and a partition {a mathematical formula}π∈ΠC, let us denote by {a mathematical formula}RMπ the set of all partitions that are reachable from π via M, that is, {a mathematical formula}RMπ={π′∈ΠC:π⇝Mπ′}. Observe that every partition in {a mathematical formula}RMπ is either equal to π or reachable from π via at least one movement in M, in which case it must also be reachable from at least one of the partitions in {a mathematical formula}{π′∈ΠC:π→Mπ′}. Based on this observation, the set {a mathematical formula}RMπ can be computed recursively as follows:{a mathematical formula} Now, let us define {a mathematical formula}fM(C) as the value of an optimal partition in {a mathematical formula}RM{C}. More formally, {a mathematical formula}fM(C)=maxπ∈RM{C}⁡V(π). With this definition, we are ready to generalise Theorem 4 (the main theorem behind DP) by replacing {a mathematical formula}f(C) and {a mathematical formula}ΠC with {a mathematical formula}fM(C) and {a mathematical formula}RM{C}, respectively.
      </paragraph>
      <paragraph label="Theorem 6">
       For every coalition{a mathematical formula}C⊆Aand for every subset of movements{a mathematical formula}M⊆Mit holds that{a mathematical formula}
      </paragraph>
      <paragraph>
       For the proof of Theorem 6, see Appendix C.
      </paragraph>
      <paragraph>
       Now, we can analyse the effect of replacing every {a mathematical formula}f(C) and {a mathematical formula}ΠC in DP with {a mathematical formula}fM(C) and {a mathematical formula}RM{C}, respectively. Let us call the resulting algorithm {a mathematical formula}DPM. Theorem 6 implies that {a mathematical formula}DPM computes {a mathematical formula}fM(C) recursively for every {a mathematical formula}C⊆A. When {a mathematical formula}DPM terminates, it has computed {a mathematical formula}fM(A)—the value of the best coalition structure reachable from {a mathematical formula}{A} via M. To identify this coalition structure, {a mathematical formula}DPM uses the table t in the same way as DP does. This leads to the following corollary.
      </paragraph>
      <paragraph label="Corollary 7">
       For an arbitrary subset of movements{a mathematical formula}M⊆M, the algorithm{a mathematical formula}DPMoutputs a coalition structure in{a mathematical formula}argmaxCS∈RM{A}V(CS).
      </paragraph>
      <paragraph>
       Having analysed the effect of avoiding the evaluation of certain movements in the coalition structure graph, we will now use this analysis to design an optimal version of DP.
      </paragraph>
     </section>
     <section label="4.3">
      <section-title>
       The ODP algorithm
      </section-title>
      <paragraph>
       In this section, we present our optimal dynamic programming (ODP) algorithm—a modified version of DP that avoids all the redundant operations of DP, while maintaining the guarantee of finding an optimal solution. Of course, it would be possible to avoid all redundant operations by simply considering all movements, and checking them one by one to identify (and avoid) any movements that lead to an already-examined split. This, however, would require storing all movements, rather than just the most promising ones, as is currently the case. Instead, ODP identifies the relevant movements a priori, without any need for extra memory requirements, and without having to search for these relevant movements.
      </paragraph>
      <paragraph>
       According to Corollary 7, given a subset of movements M, {a mathematical formula}DPM finds an optimal coalition structure if and only if {a mathematical formula}RM{A}=ΠA. We will now identify a “small” set of movements M for which this is the case. Recall that, given two coalitions {a mathematical formula}C′,C″∈CA, we write {a mathematical formula}C′&lt;C″ if and only if {a mathematical formula}C′ precedes {a mathematical formula}C″ lexicographically.{sup:6} Set{a mathematical formula} It turns out that, to find an optimal partition, it suffices to consider the movements in {a mathematical formula}M⁎.
      </paragraph>
      <paragraph label="Theorem 8">
       {a mathematical formula}
      </paragraph>
      <paragraph label="Proof">
       It suffices to prove that for every {a mathematical formula}k≥2, every coalition structure {a mathematical formula}CS={C1,…,Ck} is reachable from some coalition structure {a mathematical formula}CS′ with {a mathematical formula}|CS′|=k−1 via some movement in {a mathematical formula}M⁎. Assume without loss of generality that {a mathematical formula}C1&lt;⋯&lt;Ck. We will show that CS is reachable from the coalition structure {a mathematical formula}(CS\{C1,C2})∪{C1∪C2} via {a mathematical formula}M⁎. To this end, it suffices to show that {a mathematical formula}mC1,C2∈M⁎.First, suppose that {a mathematical formula}k=2. In this case, we have {a mathematical formula}CS={C1,C2}, and so {a mathematical formula}C1∪C2=A. This means that {a mathematical formula}mC1,C2∈M⁎.Now, suppose that {a mathematical formula}k&gt;2. In this case, since {a mathematical formula}C1&lt;⋯&lt;Ck, we obtain {a mathematical formula}C1&lt;C2&lt;(C3∪⋯∪Ck), and hence {a mathematical formula}C1&lt;C2&lt;A∖(C1∪C2). Thus, {a mathematical formula}mC1,C2∈M⁎ in this case as well.  □
      </paragraph>
      <paragraph label="Definition 9">
       We are now ready to define our algorithm, which we call ODP. ODP is the version of DP that only evaluates the movements in {a mathematical formula}M⁎, i.e., uses {a mathematical formula}fM⁎ instead of f. Formally, {a mathematical formula}ODP=DPM⁎.
      </paragraph>
      <paragraph>
       Theorem 8 together with Corollary 7 imply that ODP finds an optimal partition of A. We will now analyse the running time of this algorithm. First, we prove the following two important lemmas. The first lemma will be used in our implementation of ODP (see lines 5 to 25 of Algorithm 3 in Appendix B), while the second lemma states that ODP does not evaluate any redundant movements.
      </paragraph>
      <paragraph label="Lemma 10">
       For every coalition{a mathematical formula}C∈CAsuch that{a mathematical formula}{a1,a2}⊈C, the ODP algorithm does not evaluate any of the possible ways of splitting C.
      </paragraph>
      <paragraph label="Proof">
       Consider a coalition {a mathematical formula}C∈CA such that {a mathematical formula}{a1,a2}⊈C. We will prove that for all {a mathematical formula}mC′,C″∈M such that {a mathematical formula}C′∪C″=C it holds that {a mathematical formula}mC′,C″∉M⁎.We will deal with each of the following complementary cases separately:
      </paragraph>
      <list>
       <list-item label="•">
        Case 1:{a mathematical formula}a1∉C. This means that {a mathematical formula}a1∈A∖(C′∪C″). Therefore, we have {a mathematical formula}C′∪C″≠A and {a mathematical formula}A∖(C′∪C″)&lt;C′. Thus, {a mathematical formula}mC′,C″∉M⁎ according to (5).
       </list-item>
       <list-item label="•">
        Case 2:{a mathematical formula}a1∈C and {a mathematical formula}a2∉C. In this case, one of the two coalitions in {a mathematical formula}{C′,C″} contains neither {a mathematical formula}a1 nor {a mathematical formula}a2. Let this coalition be {a mathematical formula}C″. Now, since {a mathematical formula}a2∈A∖(C′∪C″), we have {a mathematical formula}C′∪C″≠A and {a mathematical formula}A∖(C′∪C″)&lt;C″. This implies that {a mathematical formula}mC′,C″∉M⁎ according to (5). □
       </list-item>
      </list>
      <paragraph label="Lemma 11">
       For every coalition structure CS with{a mathematical formula}|CS|≥2, the ODP algorithm evaluates exactly one movement that leads to CS.
      </paragraph>
      <paragraph label="Proof">
       Consider a coalition structure {a mathematical formula}CS={C1,…,Ck} with {a mathematical formula}k≥2. Without loss of generality, we can assume that {a mathematical formula}C1&lt;⋯&lt;Ck. In our proof, we will distinguish between the following two cases:
      </paragraph>
      <list>
       <list-item label="•">
        Case 1:{a mathematical formula}k=2. In this case, there is exactly one possible movement that leads to CS, which is {a mathematical formula}mC1,C2. Since {a mathematical formula}C1∪C2=A, we have {a mathematical formula}mC1,C2∈M⁎.
       </list-item>
       <list-item label="•">
        Case 2:{a mathematical formula}k&gt;2. In this case, we have {a mathematical formula}C1&lt;C2&lt;A∖(C1∪C2), so {a mathematical formula}mC1,C2∈M⁎. It remains to show that no other movement in {a mathematical formula}M⁎ leads to CS. To this end, observe that a movement {a mathematical formula}mCi,Cj∈M leads to CS only if {a mathematical formula}Ci,Cj∈CS. We will show that if {a mathematical formula}{i,j}≠{1,2}, then {a mathematical formula}mCi,Cj∉M⁎. This is a direct consequence of the following observations.
       </list-item>
      </list>
      <paragraph>
       We will now establish a one-to-one correspondence between movements in {a mathematical formula}M⁎ and partitions of A into two and three parts.
      </paragraph>
      <paragraph label="Theorem 12">
       The number of movements in{a mathematical formula}M⁎is equal to the number of coalition structures in{a mathematical formula}Π2A∪Π3A—levels 2 and 3 of the coalition structure graph. That is,{a mathematical formula}
      </paragraph>
      <paragraph label="Proof">
       Fix a coalition structure {a mathematical formula}CS={C1,…,Ck} with {a mathematical formula}k&gt;1, and assume without loss of generality that {a mathematical formula}C1&lt;⋯&lt;Ck. To establish a one-to-one correspondence between {a mathematical formula}M⁎ and {a mathematical formula}Π2A∪Π3A, it is sufficient to make the following observations.
      </paragraph>
      <list>
       <list-item label="•">
        Every movement {a mathematical formula}mC′,C″∈M⁎ with {a mathematical formula}C′∪C″=A leads to exactly one coalition structure, namely {a mathematical formula}{C′,C″}, which is in {a mathematical formula}Π2A. Similarly, every coalition structure {a mathematical formula}{C1,C2}∈Π2A is reachable via exactly one movement in {a mathematical formula}M⁎, namely {a mathematical formula}mC1,C2. Thus, there is a one-to-one correspondence between {a mathematical formula}Π2A and {a mathematical formula}{mC′,C″∈M⁎:C′∪C″=A}. Therefore,{a mathematical formula}
       </list-item>
       <list-item label="•">
        Every movement {a mathematical formula}mC′,C″∈M⁎ with {a mathematical formula}C′∪C″⊂A leads to exactly one coalition structure in {a mathematical formula}Π3A, namely {a mathematical formula}{C′,C″,A∖(C′∪C″)}, as this is the only coalition structure in {a mathematical formula}Π3A that contains both {a mathematical formula}C′ and {a mathematical formula}C″. Similarly, every coalition structure {a mathematical formula}{C1,C2,C3}∈Π3A with {a mathematical formula}C1&lt;C2&lt;C3 is reachable via exactly one movement in {a mathematical formula}M⁎, namely, {a mathematical formula}mC1,C2. This means that there is a one-to-one correspondence between {a mathematical formula}Π3A and {a mathematical formula}{mC′,C″∈M⁎:C′∪C″⊂A}, and hence{a mathematical formula}
       </list-item>
      </list>
      <paragraph>
       We can use Theorem 12 to compute the size of {a mathematical formula}M⁎ (for the proof, see Appendix C).
      </paragraph>
      <paragraph label="Corollary 13">
       The number of movements in{a mathematical formula}Mis{a mathematical formula}12(3n+1)−2n, whereas the number of movements in{a mathematical formula}M⁎is{a mathematical formula}12(3n−1−1).
      </paragraph>
      <paragraph>
       Corollary 13 shows that ODP evaluates roughly one third of the movements evaluated by DP.
      </paragraph>
      <paragraph>
       More importantly, Theorem 12 can be used to show that it is not possible to evaluate fewer movements than those evaluated by ODP and still be guaranteed to find an optimal solution.
      </paragraph>
      <paragraph label="Theorem 14">
       For every subset of movements{a mathematical formula}M⊆Msuch that{a mathematical formula}|M|&lt;|M⁎|we have{a mathematical formula}RM{A}≠ΠA.
      </paragraph>
      <paragraph label="Proof">
       Suppose that {a mathematical formula}RM{A}=ΠA; we will argue that in this case M has to contain at least {a mathematical formula}|Π2A|+|Π3A|=|M⁎| movements.Consider an arbitrary coalition structure of size 2, say, {a mathematical formula}CS2={C1,C2}. The only way to reach {a mathematical formula}CS2 is to make the movement {a mathematical formula}mC1,C2 from {a mathematical formula}{A}. Thus, since {a mathematical formula}DPM reaches all coalition structures, we have {a mathematical formula}mC1,C2∈M. Further, observe that if {a mathematical formula}{C1,C2} and {a mathematical formula}{C1′,C2′} are two different coalition structures of size 2, then {a mathematical formula}mC1,C2≠mC1′,C2′.Similarly, consider an arbitrary coalition structure of size 3, say, {a mathematical formula}CS3={C1,C2,C3}. If M contains none of the movements {a mathematical formula}mC1,C2, {a mathematical formula}mC1,C3, {a mathematical formula}mC2,C3, then {a mathematical formula}DPM cannot reach {a mathematical formula}CS3. Further, if {a mathematical formula}{C1,C2,C3} and {a mathematical formula}{C1′,C2′,C3′} are two different coalition structures of size 3, then the sets {a mathematical formula}{mC1,C2,mC1,C3,mC2,C3} and {a mathematical formula}{mC1′,C2′,mC1′,C3′,mC2′,C3′} are disjoint. Indeed, the only coalition structure of size 3 that can be reached by a movement in the former set is {a mathematical formula}{C1,C2,C3}, whereas the only coalition structure of size 3 that can be reached by a movement in the latter set is {a mathematical formula}{C1′,C2′,C3′}. Moreover, none of the movements in the set {a mathematical formula}{mC1,C2,mC1,C3,mC2,C3} can be used to reach a coalition structure of size 2, as we have {a mathematical formula}|C1|+|C2|&lt;n, {a mathematical formula}|C1|+|C3|&lt;n, {a mathematical formula}|C2|+|C3|&lt;n.Now, if {a mathematical formula}DPM can reach all coalition structures, then for each coalition structure of size 2 or 3 the set M contains a movement that reaches this coalition structure, and we have argued that all these movements must be pairwise distinct. It follows that if {a mathematical formula}RM{A}=ΠA, then {a mathematical formula}|M|≥|Π2A|+|Π3A|=|M⁎|, which is what we wanted to prove.  □
      </paragraph>
      <paragraph>
       Appendix B provides the pseudocode of ODP, and shows how to avoid storing the table t, thus leading to a significant reduction in memory requirements at the expense of a negligible increase in computation time.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      The ODP-IP algorithm
     </section-title>
     <paragraph>
      Having detailed the ODP algorithm, we will now show how to combine it with the IP algorithm. Our starting point is the “vanilla” hybrid algorithm, which runs the two algorithms in parallel and terminates as soon as the faster of the two returns an answer. Our main contribution here is to modify ODP and IP so that they can assist one another during this process. Ideally, this should be done so that the two algorithms explore non-overlapping portions of the search space, while dividing the labour in an ad hoc manner (rather than a priori) to reflect the actual strengths of the two algorithms. For instance, if ODP happens to be twice as fast as IP on a given problem instance, then ODP must naturally end up putting twice as much effort as IP. Another desirable property would be to have some meaningful information flow between the two algorithms, rather than having each one working independently without acknowledging the presence of the other. Here, the goal would be to have some synergy between the two, making the overall outcome greater than the sum of its parts. The main challenge here stems from the fact that ODP and IP are based on entirely different design paradigms.
     </paragraph>
     <paragraph>
      Against this background, we present in Section 5.1 a new representation of the search space, which provides the corner stone upon which our hybrid algorithm is built. Based on this, we show in Section 5.2 how to modify ODP such that it searches subspaces of the integer partition graph—those same subspaces that IP was originally designed to explore. After that, in Section 5.3 we show how to use the information provided by ODP to speed up IP's depth-first search, while in Section 5.4 we show how to modify IP so that it searches multiple subspaces simultaneously, building upon ODP's partial outcome. When combining the modified versions of ODP and IP, we obtain our hybrid algorithm, ODP-IP, a summary of which is provided in Section 5.5.
     </paragraph>
     <section label="5.1">
      <section-title>
       The link between DP and IP
      </section-title>
      <paragraph>
       Given the differences between ODP and IP, in terms of both the search-space representation and the search techniques that are being used, it is not trivial to determine how these two algorithms can be combined effectively, i.e., how to divide the search effort between the two algorithm in a meaningful way. As a starting step, we will draw a link between IP and DP (not ODP). In order to do so, we introduce yet another graph, which we call the integer partition graph. This is an undirected graph where every node represents an integer partition, and two nodes representing integer partitions I and {a mathematical formula}I′ are connected by an edge if and only if there exist two parts {a mathematical formula}i,j∈I such that {a mathematical formula}I′=(I∖{i,j})⊎{i+j} (here ⊎ denotes the multiset union operation). A four-agent example is shown in Fig. 5(A).
      </paragraph>
      <paragraph>
       By looking at this graph, we can visualise the way DP searches the subspaces that are represented by different integer partitions. To this end, recall that the operation of DP can be interpreted as the evaluation of movements in the coalition structure graph. Furthermore, avoiding the evaluation of some of these movements can be interpreted as removing the edges through which these movements are made. Importantly, these same operations can also be visualised on the integer partition graph. Specifically, we make the following observations.
      </paragraph>
      <list>
       <list-item label="•">
        By making a movement from a coalition structure CS to a coalition structure {a mathematical formula}CS′ in the coalition structure graph, DP makes a movement from the integer partition I with {a mathematical formula}CS∈ΠIA to the integer partition {a mathematical formula}I′ with {a mathematical formula}CS′∈ΠI′A in the integer partition graph. For example, the movement from {a mathematical formula}{{a1},{a2,a3,a4}} to {a mathematical formula}{{a1},{a2},{a3,a4}} in Fig. 5(B) corresponds to the movement from {a mathematical formula}Π{1,3}A to {a mathematical formula}Π{1,1,2}A in Fig. 5(A).
       </list-item>
       <list-item label="•">
        Removing all edges of the coalition structure graph that correspond to splitting a coalition of size s into two coalitions of sizes {a mathematical formula}s′ and {a mathematical formula}s″ corresponds to removing every edge of the integer partition graph that connects an integer partition I with {a mathematical formula}s∈I to the integer partition {a mathematical formula}I′=(I∖{s})⊎{s′,s″}. For instance, removing the dotted edges in Fig. 5(B) corresponds to removing the dotted edge that connects {a mathematical formula}Π{2,2}A to {a mathematical formula}Π{2,1,1}A in Fig. 5(A). This is because it is no longer possible to move from a coalition structure in {a mathematical formula}Π{2,2}A to a coalition structure in {a mathematical formula}Π{2,1,1}A.
       </list-item>
      </list>
      <paragraph>
       This visualisation provides a link between DP and IP, since the latter deals with subspaces that are represented by integer partitions. Building upon this, we show in the next section how to divide the search effort between ODP and IP.
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       Searching subspaces using ODP
      </section-title>
      <paragraph>
       We have shown that, for a given triple of positive integers {a mathematical formula}s,s′,s″ with {a mathematical formula}s′+s″=s, avoiding the evaluation of all possible ways of splitting all coalitions of size s into two coalitions of sizes {a mathematical formula}s′ and {a mathematical formula}s″ corresponds to removing edges from the integer partition graph—the graph that links DP and IP. The problem with ODP is that it avoids the evaluation of only some of the movements from coalitions of a given size. For instance, given {a mathematical formula}n=4 and {a mathematical formula}s=2, one can check that ODP avoids evaluating the movements from {a mathematical formula}{a1,a3}, {a mathematical formula}{a1,a4}, {a mathematical formula}{a2,a3}, {a mathematical formula}{a2,a4} and {a mathematical formula}{a3,a4}, but evaluates the movement from {a mathematical formula}{a1,a2}. Because of this single movement from a coalition of size 2, we cannot remove the dotted edge from Fig. 5(A). To circumvent this, we will now present a size-based version of ODP that, for any three sizes {a mathematical formula}s,s′,s″∈{1,…,n} such that {a mathematical formula}s=s′+s″, evaluates either all or none of the movements in which a coalition of size s is split into coalitions of sizes {a mathematical formula}s′ and {a mathematical formula}s″. While the resulting version of DP still performs some redundant evaluations, we will later see that its performance is very close to that of ODP.
      </paragraph>
      <paragraph>
       Given two positive integers {a mathematical formula}s′,s″∈Z+, let {a mathematical formula}Ms′,s″⊆M be the set that consists of every movement in which a coalition of size {a mathematical formula}s′+s″ is split into two coalitions of sizes {a mathematical formula}s′ and {a mathematical formula}s″. That is, {a mathematical formula}Ms′,s″={mC′,C″∈M:|C′|=s′,|C″|=s″}. Furthermore, let us define {a mathematical formula}M⁎⁎⊆M as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       We will now show that, in order to find an optimal coalition structure, it suffices to evaluate all movements in {a mathematical formula}M⁎⁎. The proof of the following theorem is similar to that of Theorem 8, and can be found in Appendix D.
      </paragraph>
      <paragraph label="Theorem 15">
       {a mathematical formula}
      </paragraph>
      <paragraph>
       Theorem 15 shows that {a mathematical formula}DPM⁎⁎ finds an optimal coalition structure. Furthermore, while it clearly performs some redundant evaluations, we will now argue that its running time is very close to that of ODP.
      </paragraph>
      <paragraph>
       We will first show that {a mathematical formula}DPM⁎⁎ evaluates none of the movements from a coalition of size s, where {a mathematical formula}s∈{⌊2n3⌋+1,…,n−1}. The proof of the following lemma is similar to that of Lemma 10, and can be found in Appendix D.
      </paragraph>
      <paragraph label="Lemma 16">
       The{a mathematical formula}DPM⁎⁎algorithm does not evaluate any of the possible ways of splitting a coalition of size s, where{a mathematical formula}s∈{⌊2n3⌋+1,…,n−1}.
      </paragraph>
      <paragraph>
       We can now provide an upper bound of the number of movements evaluated by {a mathematical formula}DPM⁎⁎ (for the proof, see Appendix D).
      </paragraph>
      <paragraph label="Theorem 17">
       The number of movements in{a mathematical formula}M⁎⁎is{a mathematical formula}123n−1+o(3n).
      </paragraph>
      <paragraph>
       Theorem 17 means that {a mathematical formula}DPM⁎⁎ is essentially just as fast as ODP.
      </paragraph>
      <paragraph>
       Next, we show how to further modify {a mathematical formula}DPM⁎⁎ so that it searches subspaces of the integer partition graph. To this end, observe that {a mathematical formula}DPM⁎⁎ works in three main steps:
      </paragraph>
      <list>
       <list-item label="•">
        for {a mathematical formula}s=2,…,⌊2n3⌋, evaluate all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}|C′|+|C″|=s;
       </list-item>
       <list-item label="•">
        for {a mathematical formula}s=n, evaluate all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}|C′|+|C″|=s and compute {a mathematical formula}t(A);
       </list-item>
       <list-item label="•">
        make the best movements from {a mathematical formula}{A} using the function {a mathematical formula}getBestPartition(A,t(A)).
       </list-item>
      </list>
      <paragraph>
       We modify {a mathematical formula}DPM⁎⁎ by changing this sequence of operations as follows:
      </paragraph>
      <list>
       <list-item label="•">
        initialise {a mathematical formula}t(A)←{A} and {a mathematical formula}fM⁎⁎(C)←v(C) for all {a mathematical formula}C⊆A;
       </list-item>
       <list-item label="•">
        for {a mathematical formula}s=2,…,⌊2n3⌋: (1) evaluate all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}|C′|+|C″|=s; (2) evaluate all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}{|C′|,|C″|}={s,n−s}; (3) update {a mathematical formula}t(A); (4) make the best movements from {a mathematical formula}{A} using the function {a mathematical formula}getBestPartition(A,t(A)).
       </list-item>
      </list>
      <paragraph>
       In what follows, we refer to the resulting algorithm as the size-based version of ODP, or sb-ODP; its pseudocode is given in Algorithm 2. To understand the intuition behind these modifications, let us consider a 10-agent example, where sb-ODP has just finished evaluating the movements {a mathematical formula}mC′,C″∈M⁎⁎ such that {a mathematical formula}|C′|+|C″|∈{2,3}. At this moment, although some movements in {a mathematical formula}M⁎⁎ have not yet been evaluated, sb-ODP can reach some subspaces in the integer partition graph. This is illustrated in Fig. 6(A), where every movement not evaluated by ODP has been removed from the graph. As can be seen, some subspaces are reachable from {a mathematical formula}Π{10}A—the bottom node in the graph. Consequently, based on Corollary 7, the best coalition structure in those subspaces can easily be identified: simply repeat the process of splitting the coalition(s) in {a mathematical formula}{A} in the best way (out of all the ways that were evaluated by sb-ODP thus far) until no such splitting is beneficial. Similarly, as soon as the movements {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}|C′|+|C″|=4 are evaluated, more edges are added to the graph, and so more subspaces become reachable from the bottom subspace (see Fig. 6(B)). Just as before, the best coalition structure in all of those subspaces can easily be identified. By repeating this process for every size s, sb-ODP gradually evaluates more and more subspaces, until it eventually searches the entire space.
      </paragraph>
      <paragraph>
       We remark that, unlike {a mathematical formula}DPM⁎⁎, sb-ODP is an anytime algorithm: at any point in time {a mathematical formula}CS⁎⁎ stores the best coalition structure identified so far, and the value of this coalition structure goes up as s increases. However, this improvement comes at a price: while {a mathematical formula}DPM⁎⁎ evaluates each movement at most once, sb-ODP evaluates some of the movements twice. Specifically, a movement of the form {a mathematical formula}mC′,C″ with {a mathematical formula}|C′|+|C″|=n, {a mathematical formula}|C′|≤⌊2n3⌋, {a mathematical formula}|C″|≤⌊2n3⌋, {a mathematical formula}|C′|&lt;|C″|, is evaluated first for {a mathematical formula}s=|C′| and then for {a mathematical formula}s=|C″|. Fortunately, the number of such movements is less than {a mathematical formula}2n−1=o(3n), and all other movements in {a mathematical formula}M⁎⁎ are evaluated once. Thus, we obtain the following corollary.
      </paragraph>
      <paragraph label="Corollary 18">
       The sb-ODP algorithm performs{a mathematical formula}123n−1+o(3n)evaluations.
      </paragraph>
      <paragraph>
       So far in this section, we have developed a size-based version of ODP, and shown how to modify it so that it searches integer partition-based subspaces. This has the following important advantage: at any point in time during execution, the part of the space that is yet to be searched can also be represented as the union of integer partition-based subspaces. As a result, IP can focus on these subspaces, and avoid searching the ones that have been searched by ODP.{sup:7} This division of work (between ODP and IP) gives ODP-IP the ability to calibrate itself automatically so that the amount of search assigned to each of its two constituent parts (ODP and IP) reflects the relative strength of that part with respect to the problem instance at hand. This is particularly important since IP could be significantly faster than ODP in some cases, while in some other cases it could be significantly slower (see Section 6 for more details).
      </paragraph>
      <paragraph>
       Now that we have shown how IP and ODP can share the workload without duplicating each other's efforts, in the following sections we show how to further enhance this combination. In particular, we will focus on how IP's performance can be improved by using the information that has been already computed by ODP.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Speeding up IP's depth-first search
      </section-title>
      <paragraph>
       As mentioned in Section 3.1, every time IP reaches a certain depth d in the search tree of a subspace {a mathematical formula}ΠIA, it adds a coalition {a mathematical formula}Cd to a set of disjoint coalitions {a mathematical formula}{C1,…,Cd−1}. After that, it determines whether it is worthwhile to go deeper into the search tree. To do so, it checks whether inequality (1) holds. If not, then the set of all coalition structures in {a mathematical formula}ΠIA that start with {a mathematical formula}{C1,…,Cd−1} is considered promising, i.e., one of the coalition structures in this set could potentially have a value greater than {a mathematical formula}V(CS⁎⁎)—the value of the best coalition structure found so far. In this case, IP goes deeper into the search tree. However, we will now show how, with the help of ODP, some coalition structures can still be pruned even if they are promising.
      </paragraph>
      <paragraph>
       The basic idea is to modify IP so that, for any subset of agents {a mathematical formula}C⊆A, it keeps track of the value of the best partition of C that it has encountered so far. This is done using a table w, with an entry for every possible coalition. In more detail, IP initially sets {a mathematical formula}w(C)=v(C) for all {a mathematical formula}C⊆A. After that, every time IP reaches a certain depth d, it performs the following operation:{a mathematical formula} Since IP performs this operation every time it goes one step deeper into the search tree, the information in w is kept up-to-date throughout the search. Now, to use this information, IP is modified so that, at depth d, it checks whether one of the following inequalities holds:{a mathematical formula}{a mathematical formula} If (12) holds, then {a mathematical formula}{C1,…,Cd} is not an optimal partition of {a mathematical formula}C1∪⋯∪Cd, and so there does not exist an optimal coalition structure {a mathematical formula}CS⁎ such that {a mathematical formula}{C1,…,Cd}⊆CS⁎. Similarly, if (13) holds, then {a mathematical formula}{Cd} is not an optimal partition of {a mathematical formula}Cd, and so there does not exist an optimal coalition structure {a mathematical formula}CS⁎ such that {a mathematical formula}Cd∈CS⁎. In either case, every coalition structure containing {a mathematical formula}{C1,…,Cd} can be skipped during the search. Note that this pruning occurs even if the set of all coalition structures that contain{a mathematical formula}{C1,…,Cd}is promising. This is because the pruning here occurs whenever an optimal coalition structure cannot possibly appear among the coalition structures containing {a mathematical formula}{C1,…,Cd}, even if one of these coalition structures is indeed better than{a mathematical formula}CS⁎⁎—the best coalition structure found so far.
      </paragraph>
      <paragraph>
       Now, knowing that ODP runs in parallel with IP, we can improve the above technique as follows. Instead of having IP use the table w, and ODP use another table, i.e., {a mathematical formula}fM⁎⁎, we modify IP so that it uses the same table as ODP. Formally, we replace w with {a mathematical formula}fM⁎⁎ in (11), (12) and (13). This implicitly means that IP will make its decisions based not only on the best partitions that it has encountered, but also on those encountered by ODP.
      </paragraph>
      <paragraph>
       To better understand the effect that ODP has on the new branch-and-bound technique, let us consider an example of 19 agents. With such a relatively small number of agents, ODP can compute optimal partitions of all coalitions of size 9 or less in a very short time (e.g., less than 0.2 seconds on a standard desktop PC, see Section 6 for more details). Now suppose that, after this short time, IP started searching the subspace {a mathematical formula}Π{2,2,2,2,1,1,3,3,3}A. As mentioned earlier, IP goes deeper into the search tree as long as it encounters promising coalition structures. For instance, suppose that the set of all coalition structures containing {a mathematical formula}{a1,a2},{a3,a4},{a5,a6},{a7,a8},{a9} happens to be promising. With the new branch-and-bound technique, and with the information now provided by ODP, this combination of coalitions would only be reached by IP if all of the following conditions hold:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}{{a1,a2}} happens to be an optimal partition of {a mathematical formula}{a1,a2};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a3,a4}} happens to be an optimal partition of {a mathematical formula}{a3,a4};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a1,a2},{a3,a4}} happens to be an optimal partition of {a mathematical formula}{a1,…,a4};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a5,a6}} happens to be an optimal partition of {a mathematical formula}{a5,a6};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a1,a2},{a3,a4},{a5,a6}} happens to be an optimal partition of {a mathematical formula}{a1,…,a6};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a7,a8}} happens to be an optimal partition of {a mathematical formula}{a7,a8};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a1,a2},{a3,a4},{a5,a6},{a7,a8}} happens to be an optimal partition of {a mathematical formula}{a1,…,a8};
       </list-item>
       <list-item label="•">
        {a mathematical formula}{{a1,a2},{a3,a4},{a5,a6},{a7,a8},{a9}} happens to be an optimal partition of {a mathematical formula}{a1,…,a9}.
       </list-item>
      </list>
      <paragraph>
       The probability of all these events happening simultaneously is extremely low for reasonable distributions of coalitional values, even if the set of all coalition structures containing {a mathematical formula}{a1,a2}, {a mathematical formula}{a3,a4}, {a mathematical formula}{a5,a6}, {a mathematical formula}{a7,a8}, {a mathematical formula}{a9} is promising. This example clearly demonstrates the great potential of this new branch-and-bound technique for speeding up the search.
      </paragraph>
     </section>
     <section label="5.4">
      <section-title>
       Searching multiple subspaces simultaneously
      </section-title>
      <paragraph>
       In this section, we show how to modify IP so that it searches multiple subspaces simultaneously and thus avoids repeating certain operations. After that, we show how IP can use this technique more effectively using the partial outcome of ODP. For presentation clarity, we will postpone the formal description of this technique until after we have presented the basic idea through an example of five subspaces.
      </paragraph>
      <paragraph>
       Recall that IP searches each subspace in a depth-first manner. The crucial idea behind the modification we are going to describe is that the first few levels of IP's search tree for a given subspace {a mathematical formula}ΠIA can be exactly the same as those for several other subspaces.{sup:8} For instance, the first two levels are exactly the same in the search trees of the subspaces that are represented by the following ordered integer partitions: {a mathematical formula}I1={2,4,4}, {a mathematical formula}I2={2,4,1,3}, {a mathematical formula}I3={2,4,2,2}, {a mathematical formula}I4={2,4,1,1,2}, and {a mathematical formula}I5={2,4,1,1,1,1}. Searching any of those subspaces in a depth-first manner (as IP does) involves constructing pairs of disjoint coalitions {a mathematical formula}C1,C2 with {a mathematical formula}|C1|=2,|C2|=4 (for more details, see Section 3.1). Now, instead of repeating this process for every one of these five subspaces, we need only perform it once. More specifically, for every pair {a mathematical formula}C1,C2 with {a mathematical formula}|C1|=2,|C2|=4, we can perform the following steps:
      </paragraph>
      <list>
       <list-item label="1.">
        Compute the value of {a mathematical formula}{C1,C2,A∖(C1∪C2)}—the only coalition structure in {a mathematical formula}ΠI1A that contains {a mathematical formula}C1 and {a mathematical formula}C2.
       </list-item>
       <list-item label="2.">
        Find the best partition of {a mathematical formula}A∖(C1∪C2) into two coalitions of sizes 1 and 3, and add those to {a mathematical formula}{C1,C2}. This gives the best coalition structure in {a mathematical formula}ΠI2A that contains {a mathematical formula}C1 and {a mathematical formula}C2.
       </list-item>
       <list-item label="3.">
        Find the best partition of {a mathematical formula}A∖(C1∪C2) into two coalitions of sizes 2 and 2, and add those to {a mathematical formula}{C1,C2}. This gives the best coalition structure in {a mathematical formula}ΠI3A that contains {a mathematical formula}C1 and {a mathematical formula}C2.
       </list-item>
       <list-item label="4.">
        Find the best partition of {a mathematical formula}A∖(C1∪C2) into three coalitions of sizes 1, 1 and 2, and add those to {a mathematical formula}{C1,C2}. This gives the best coalition structure in {a mathematical formula}ΠI4A that contains {a mathematical formula}C1 and {a mathematical formula}C2.
       </list-item>
       <list-item label="5.">
        Compute the value of {a mathematical formula}{C1,C2}∪ai∈A∖(C1∪C2){{ai}}—the only coalition structure in {a mathematical formula}ΠI5A that contains {a mathematical formula}C1 and {a mathematical formula}C2.
       </list-item>
       <list-item label="6.">
        Select the best out of the coalition structures that were found in the above five steps.
       </list-item>
      </list>
      <paragraph>
       This procedure returns the best coalition structure containing {a mathematical formula}C1 and {a mathematical formula}C2 in the set {a mathematical formula}∪i=15ΠIiA. By repeating this procedure for every pair {a mathematical formula}C1,C2 with {a mathematical formula}|C1|=2,|C2|=4, we can find the best coalition structure in {a mathematical formula}∪i=15ΠIiA.
      </paragraph>
      <paragraph>
       Next, we will show how to significantly speed up the above technique using the information provided by ODP. To this end, suppose that IP started searching {a mathematical formula}ΠI1A,…,ΠI5A after ODP has finished evaluating the movements {a mathematical formula}mC,C′∈M⁎⁎ with {a mathematical formula}|C|+|C′|∈{2,3,4}. This means that, for all {a mathematical formula}C⊆A with {a mathematical formula}|C|∈{2,3,4}, ODP has computed {a mathematical formula}fM⁎⁎(C). In this case, for every pair {a mathematical formula}C1,C2 with {a mathematical formula}|C1|=2,|C2|=4, it is possible to find the value of the best coalition structure containing {a mathematical formula}C1 and {a mathematical formula}C2 in {a mathematical formula}∪i=15ΠIiA without having to examine the different partitions of {a mathematical formula}A∖(C1∪C2) as in the above six steps. Instead, we can now perform a single step, which is
      </paragraph>
      <list>
       <list-item label="1.">
        Compute {a mathematical formula}v(C1)+v(C1)+fM⁎⁎(A∖(C1∪C2)).
       </list-item>
      </list>
      <paragraph>
       This is because in this example {a mathematical formula}A∖(C1∪C2) is a coalition of four agents, which means that ODP has already computed {a mathematical formula}fM⁎⁎(A∖(C1∪C2)).
      </paragraph>
      <paragraph>
       By repeating this step for every pair {a mathematical formula}C1,C2 with {a mathematical formula}|C1|=2,|C2|=4, we find a coalition structure{a mathematical formula} It remains to partition {a mathematical formula}C3⁎ in the best way using the movements in {a mathematical formula}M⁎⁎ (so far we only know the value of that partition, which is {a mathematical formula}fM⁎⁎(C3⁎); we do not yet know the partition itself). This can be done by simply replacing {a mathematical formula}C3⁎ with {a mathematical formula}getBestPartition(C3⁎,t(C3⁎)), which partitions {a mathematical formula}C3⁎ by making the best out of all the movements that ODP has evaluated so far (see Algorithm 4). This process is illustrated in Fig. 7(A), where IP searches {a mathematical formula}ΠI1A, and the partitioning of {a mathematical formula}C3⁎ using getBestPartition is illustrated by the movements from {a mathematical formula}ΠI1A to the other subspaces, i.e., {a mathematical formula}ΠI2A, {a mathematical formula}ΠI3A, {a mathematical formula}ΠI4A, and {a mathematical formula}ΠI5A.
      </paragraph>
      <paragraph>
       In general, the modified version of IP proceeds as follows. As before, it picks the next subspace {a mathematical formula}ΠIA to evaluate based on its upper bound {a mathematical formula}UBI. Next, it chooses an integer s in I{sup:9} such that ODP has already evaluated {a mathematical formula}fM⁎⁎(C) for all coalitions C with {a mathematical formula}|C|=s. It then goes over all coalition structures in {a mathematical formula}ΠIA, and evaluates them: the coalitions that match integers in {a mathematical formula}I∖{s} are evaluated according to v, and the coalition that matches s is evaluated according to {a mathematical formula}fM⁎⁎. This has the effect of simultaneously searching all subspaces that are reachable from {a mathematical formula}ΠIA by splitting s. The resulting coalition structure can then be found using getBestPartition. To enhance readability, the details of this procedure are moved to Appendix E.
      </paragraph>
      <paragraph>
       So far, we have shown how multiple subspaces can be searched simultaneously by partitioning exactly one coalition. However, one can partition multiple coalitions. This way, more subspaces can be searched simultaneously. For example, while searching {a mathematical formula}ΠI1A, if IP evaluates every {a mathematical formula}{C1,C2,C3}∈ΠI1A as {a mathematical formula}fM⁎⁎(C1)+fM⁎⁎(C2)+fM⁎⁎(C3), then the result of this search will be a coalition structure {a mathematical formula}CS′={C1′,C2′,C3′} that maximises {a mathematical formula}fM⁎⁎(C1′)+fM⁎⁎(C2′)+fM⁎⁎(C3′). By replacing every coalition {a mathematical formula}C′∈CS′ with {a mathematical formula}getBestPartition(C′,t(C′)), we end up with the best coalition structure in all the subspaces that are reachable from {a mathematical formula}ΠI1A. This is illustrated in Fig. 7(B).
      </paragraph>
      <paragraph>
       When searching multiple subspaces simultaneously, it is important to modify the branch-and-bound technique used by IP. To this end, recall that when searching a single subspace {a mathematical formula}ΠIA, IP encounters a new combination of disjoint coalitions every time it takes one step deeper into the search tree. For every such combination {a mathematical formula}{C1,…,Cd}, IP computes an upper bound on the value of every coalition structure {a mathematical formula}CS∈ΠIA such that {a mathematical formula}{C1,…,Cd}⊆CS. If this upper bound happens to be smaller than {a mathematical formula}V(CS⁎⁎)—the value of the best solution found so far—then the combination is deemed unpromising. However, when searching multiple subspaces, e.g., {a mathematical formula}ΠI1A,…,ΠI5A, the computation of the upper bound must take into consideration all of those subspaces. In our example, the upper bound must be on the value of every {a mathematical formula}CS∈ΠIA∪⋯∪ΠI5A with {a mathematical formula}{C1,…,Cd}⊆CS. This makes it more difficult to discard branches of the search tree. Appendix E provides more details on how to split multiple integers, and compares this approach with the one where only a single integer is partitioned. We remark that in our experimental evaluation (Section 6) we always split a single integer.
      </paragraph>
      <paragraph>
       Finally, note that the original IP algorithm ignores the order of the coalitions within a coalition structure. For instance, given a set of agents {a mathematical formula}A={a1,…,a10}, the coalition structures {a mathematical formula}{{a1,a2},{a3,a4,a5,a6},{a7,a8,a9,a10}} and {a mathematical formula}{{a1,a2},{a7,a8,a9,a10},{a3,a4,a5,a6}} are considered to be the same, and so only one of the them is generated. However, when multiple subspaces are searched simultaneously, the order matters. For instance, consider the example from Fig. 7(A). Here, since a coalition of size 4 will be replaced with its optimal partition, IP will have to evaluate every {a mathematical formula}{C1,C2,C3}∈Π{2,4,4}A as {a mathematical formula}v(C1)+v(C2)+fM⁎⁎(C3). As can be seen, {a mathematical formula}v({a1,a2})+v({a3,a4,a5,a6})+fM⁎⁎({a7,a8,a9,a10}) is different from {a mathematical formula}v({a1,a2})+v({a7,a8,a9,a10})+fM⁎⁎({a3,a4,a5,a6}), and so both must be calculated.
      </paragraph>
     </section>
     <section label="5.5">
      <section-title>
       Summary and complexity analysis of ODP-IP
      </section-title>
      <paragraph>
       Below is a summary of the main modifications that we have made to ODP and IP to enable them to help each other when running in parallel:
      </paragraph>
      <list>
       <list-item label="•">
        Enable ODP to search subspaces of the integer partition graph: To do this, ODP uses {a mathematical formula}fM⁎⁎ instead of {a mathematical formula}fM⁎. Further, for {a mathematical formula}s=2,…,⌊2n3⌋, the algorithm: (1) evaluates all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}|C′|+|C″|=s, (2) evaluates all {a mathematical formula}mC′,C″∈M⁎⁎ with {a mathematical formula}{|C′|,|C″|}={s,n−s}, (3) updates {a mathematical formula}t(A), and (4) makes the best movements from {a mathematical formula}{A} using the function {a mathematical formula}getBestPartition(A,t(A)). The pseudocode can be found in Algorithm 2.
       </list-item>
       <list-item label="•">
        Speed up IP's depth-first search: To do this, whenever a coalition {a mathematical formula}Cd is added to a set of disjoint coalitions {a mathematical formula}C1,…,Cd−1, check whether {a mathematical formula}{Cd} and {a mathematical formula}{C1,…,Cd} are the best partitions of {a mathematical formula}Cd and {a mathematical formula}C1∪⋯∪Cd, respectively, that have been encountered by IP and/or ODP so far. If not, skip every coalition structure containing {a mathematical formula}C1,…,Cd.
       </list-item>
       <list-item label="•">
        Enable IP to search multiple subspaces simultaneously: When searching a subspace {a mathematical formula}ΠIA, identify the integer partitions that are reachable from I using the movements that have been evaluated by ODP thus far (e.g., see the dashed edges in Figs. 7(A) and 7(B)). Now, let {a mathematical formula}I⁎⊆I be the integers in I that will be split to reach other integer partitions (e.g., {a mathematical formula}I⁎={4} in Fig. 7(A) and {a mathematical formula}I⁎={2,4,4} in Fig. 7(B)). Then, for every coalition structure {a mathematical formula}CS∈ΠIA, evaluate every {a mathematical formula}C∈CS to {a mathematical formula}fM⁎⁎(C) if the size of C corresponds to an integer in {a mathematical formula}I⁎, otherwise evaluate it to {a mathematical formula}v(C). Finally, modify IP's branch-and-bound technique so that the upper bounds reflect the subspaces whose integer partitions are reachable from I by splitting the integers in {a mathematical formula}I⁎. The details of this modification can be found in Appendix E.
       </list-item>
      </list>
      <paragraph label="Theorem 19">
       We conclude this section with the following theorem, whose proof follows immediately from Corollary 18 and the observation that ODP-IP terminates as soon as one of ODP and IP does. Given n agents, ODP-IP runs in{a mathematical formula}O(3n)time.
      </paragraph>
      <paragraph>
       Having presented ODP-IP, in the following section we evaluate both of our algorithms, namely ODP and ODP-IP.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Performance evaluation
     </section-title>
     <paragraph>
      This section is divided into two parts: the first evaluates ODP, while the second evaluates ODP-IP.
     </paragraph>
     <section label="6.1">
      <section-title>
       Evaluating ODP
      </section-title>
      <paragraph>
       We know that DP evaluates {a mathematical formula}12(3n+1)−2n movements, while ODP evaluates {a mathematical formula}12(3n−1−1) movements (Corollary 13). In other words, ODP evaluates roughly 33% of the movements evaluated by ODP. Furthermore, we know that the size-based version of ODP (i.e., the version that is compatible with IP) evaluates {a mathematical formula}123n−1+o(3n) movements (Corollary 18), i.e., in terms of performance it is more similar to ODP than to DP.
      </paragraph>
      <paragraph>
       Fig. 8 compares those numbers, with n running from 5 to 40. It shows that, as the number of agents increases, the percentage of movements that are evaluated by the size-based version of ODP drops (compared to that of DP), and converges at around 37%. This is very close to the optimal reduction in movements, which is 33%. The reason behind the observed fluctuation is simply because the algorithm evaluates all splits of coalitions of size {a mathematical formula}{1,2,…,⌊2n/3⌋}. Thus, the number of performed operations is influenced by the shape of the function {a mathematical formula}⌊2n/3⌋.
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       Evaluating ODP-IP
      </section-title>
      <paragraph>
       ODP-IP was developed in order to obtain the best features of ODP and IP, namely: (1) being anytime, (2) running in {a mathematical formula}O(3n) time, and (3) being on average as fast as (and hopefully faster than) the faster of the two algorithms, ODP and IP. While our analysis in Section 5.1 showed that ODP-IP indeed has features (1) and (2), the following experiments are meant to verify whether ODP-IP has feature (3). The algorithms were implemented in Java,{sup:10} and tested on a PC equipped with an Intel{sup:®} Core™ i7 processor (3.40 GHz) and 12 GB of RAM.
      </paragraph>
      <paragraph>
       Observe that the number of operations performed by ODP is not influenced by the characteristic function at hand, i.e., it depends solely on the number of agents. On the other hand, the number of operations performed by IP (and consequently by ODP-IP) depends on the effectiveness of IP's branch-and-bound technique, which in turn depends on the characteristic function at hand. With this in mind, we compare the termination times of all three algorithms (ODP, IP, and ODP-IP) given different value distributions. Specifically, we consider the following distributions.
      </paragraph>
      <list>
       <list-item label="1.">
        Uniform, as studied by Larson and Sandholm [17]: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼U(a,b), where {a mathematical formula}a=0 and {a mathematical formula}b=|C|.
       </list-item>
       <list-item label="2.">
        Normal, as studied by Rahwan et al. [30]: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼N(μ,σ2), where {a mathematical formula}μ=10×|C| and {a mathematical formula}σ=0.1.
       </list-item>
       <list-item label="3.">
        NDCS (Normally Distributed Coalition Structures), as proposed by Rahwan et al. [32]: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼N(μ,σ2), where {a mathematical formula}μ=|C| and {a mathematical formula}σ=|C|. The rationale behind developing NDCS came from the authors' observation that, with Uniform and Normal distributions, a coalition structure is less likely to be optimal if it contains more coalitions. In order to develop a test-bed that is free from this bias, the authors proposed NDCS and proved it to be the only coalition-value distribution that results in normally-distributed coalition structure values. As a result, under NDCS, all coalition structures are equally likely to be optimal.
       </list-item>
       <list-item label="4.">
        Modified Uniform, as proposed by Service and Adams [40]: Every coalition's value is first drawn from {a mathematical formula}U(0,10×|C|), and then increased by a random number {a mathematical formula}r∼U(0,50) with probability 0.2.
       </list-item>
       <list-item label="5.">
        Modified Normal, proposed by Rahwanet et al. [34] as a natural counterpart to the Modified Uniform distribution. Under this distribution, each coalition's value is first drawn from {a mathematical formula}N(10×|C|,0.01), and then increased by a random number {a mathematical formula}r∼U(0,50) with probability 0.2.
       </list-item>
       <list-item label="6.">
        Exponential: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼|C|×Exp(λ), where {a mathematical formula}λ=1.
       </list-item>
       <list-item label="7.">
        Beta: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼|C|×Beta(α,β), where {a mathematical formula}α=β=0.5.
       </list-item>
       <list-item label="8.">
        Gamma: for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)∼|C|×Gamma(k,θ), where {a mathematical formula}k=θ=2.
       </list-item>
       <list-item label="9.">
        Agent-based Uniform, as proposed by Rahwan et al. [34]: Under this distribution, each agent {a mathematical formula}ai is assigned a random “power” {a mathematical formula}pi∼U(0,10), reflecting its average performance over all coalitions. Then for every coalition {a mathematical formula}C∋ai, the actual power of {a mathematical formula}ai in C is determined as {a mathematical formula}piC∼U(0,2pi), and a coalition's value is computed as the sum of the powers of its members. That is, for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)=∑ai∈CpiC.
       </list-item>
       <list-item label="10.">
        Agent-based Normal, proposed in this article. As the name suggests, it is similar to the Agent-based Uniform distribution except that every agent's average and actual powers are drawn from normal, rather than uniform, distributions. Formally, for all {a mathematical formula}ai∈A, {a mathematical formula}pi∼N(10,0.01) and for all {a mathematical formula}ai and for all {a mathematical formula}C⊆A such that {a mathematical formula}ai∈C, {a mathematical formula}piC∼N(pi,0.01). Finally, for all {a mathematical formula}C∈CA, {a mathematical formula}v(C)=∑ai∈CpiC.
       </list-item>
      </list>
      <paragraph>
       For each of the above distributions, we plotted the termination times of ODP, IP, and ODP-IP given different numbers of agents (see Fig. 9). Here, time is measured in seconds, and plotted on a log scale. For each distribution and each number of agents, we took an average over multiple runs; the number of runs was chosen to ensure the error bars are sufficiently small. As can be seen, for all the aforementioned distributions, ODP-IP is faster than the fastest of the two other algorithms, by one or two orders of magnitude for some distributions. This illustrates that the modifications introduced to IP and ODP (see Sections 5.2, 5.3, and 5.4) allow the two algorithms to help one another, leading to a positive synergy when they join forces as in ODP-IP. Observe that these modifications involve the use of branch-and-bound techniques, whose effectiveness depends heavily on the characteristic function at hand. Consequently, the resulting synergistic effect varies from one value distribution to another. This applies both to the termination time (as we have seen in Fig. 9) and to the speed of improvement in the solution quality and established bounds during the runtime of ODP-IP (as we will see in the following figures).
      </paragraph>
      <paragraph>
       Next, we evaluate the anytime property of ODP-IP. The results in Fig. 10 are shown for 25 agents. The x-axis in the figures corresponds to the percentage of time that has elapsed, with 0% being the time when the algorithm starts, and 100% being the time when it terminates. For every percentage of time {a mathematical formula}t%, we report the following:
      </paragraph>
      <list>
       <list-item label="•">
        Solution quality: This is computed as the ratio between the value of the “current” best solution (found at {a mathematical formula}t% of the runtime) and the value of the optimal solution (found at 100%). Formally, the solution-quality plot represents {a mathematical formula}(V(CS⁎⁎)×100V(CS⁎))%.
       </list-item>
       <list-item label="•">
        Bound quality: This is computed as the ratio between the value of the “current” best solution and the maximum upper bound of all “remaining” subspaces (i.e., those that were not yet searched nor pruned).
       </list-item>
      </list>
      <paragraph>
       With a few exceptions, the results show that if ODP-IP is interrupted before running to completion, it may still return a solution with relatively high quality and good guarantees (i.e., bound quality). Specifically, in terms of the guarantees that the algorithm places on its solution, we find that:
      </paragraph>
      <list>
       <list-item label="•">
        with Agent-based Uniform and Modified Normal distributions, it takes a substantial percentage of the runtime until the guarantees reach 80%;
       </list-item>
       <list-item label="•">
        with NDCS, Modified Uniform, Exponential, and Gamma distributions, the guarantees exceed 80% (or 90% in the NDCS case) after 10% of the runtime;
       </list-item>
       <list-item label="•">
        with Normal, Agent-based Normal, Uniform, and Beta distributions, the guarantees exceed 99% after about 3% of the runtime.
       </list-item>
      </list>
      <paragraph>
       In terms of solution quality, our results show that:
      </paragraph>
      <list>
       <list-item label="•">
        with the Modified Normal distribution, it takes a substantial percentage of the runtime for solution quality to reach 80%;
       </list-item>
       <list-item label="•">
        with the Modified Uniform distribution, solution quality reaches 90% after 10% of the runtime;
       </list-item>
       <list-item label="•">
        with all other distributions, solution quality reaches 95% (if not 100%) after 3% of the runtime.
       </list-item>
      </list>
      <paragraph>
       Next, we evaluate the effectiveness of the two main optimisation techniques in ODP-IP. In particular, Technique 1 improves the branch-and-bound approach used by IP (Section 5.3), whereas Technique 2 enables IP to search multiple subspaces simultaneously (Section 5.4). The results for 26 agents are shown in Table 1, where the shortest runtimes are highlighted in bold.{sup:11} As can be seen, the effectiveness of each technique varies from one coalition-value distribution to another. Moreover, due to the overhead of those techniques, for some distributions the performance can actually be slower than simply running ODP and IP in parallel (see, e.g., the runtime for the agent-based distributions when Technique 1 is deactivated). However, when both techniques are activated, it is faster to run ODP-IP (sometimes by nearly two orders of magnitude, e.g., given the modified-normal distribution) than to run ODP or IP alone, or even run them both in parallel.
      </paragraph>
      <paragraph>
       Finally, observe that we do not benchmark our algorithms against integer-programming solvers. This is because Rahwan et al. [30] showed that even an industrial-strength solver such as ILOG's CPLEX is not suited for complete set partitioning, where matrices tend to be very dense. In particular, Rahwan et al. showed that CPLEX is much slower than IP (let alone ODP-IP), and that it runs out of memory with about 18 agents.
      </paragraph>
     </section>
     <section label="6.3">
      <section-title>
       Benchmarking against the inclusion–exclusion algorithm
      </section-title>
      <paragraph>
       In this section, we benchmark ODP-IP against the Inclusion–Exclusion algorithm of Björklund et al. [8]. As mentioned in the introduction, this is theoretically the state-of-the-art set partitioning algorithm in terms of worst-case runtime; it runs in time {a mathematical formula}O(2n). In contrast, the running time of ODP-IP is {a mathematical formula}O(3n). Thus, theoretically speaking, our algorithm should be significantly slower when solving a worst-case problem instance. Our goal in this section is to verify whether this happens in practice. Importantly, we test both algorithms on a worst-case problem instance, not on average instances. Thus, when we say “in practice”, we do not mean “on average”. Instead, we mean measuring the runtime on a PC, to account for any potential delays that were disregarded in the theoretical analysis.
      </paragraph>
      <paragraph>
       We provide the pseudocode of the inclusion–exclusion algorithm in Appendix F, and provide the open-source Java implementation at https://github.com/trahwan/ODP-IP_and_InclusionExclusion. Fig. 11 depicts the runtime of the algorithm on a log scale, given different numbers of agents. It also depicts the functions {a mathematical formula}y=2x and {a mathematical formula}y=6x. As can be seen, the runtime growth rate resembles {a mathematical formula}6n, not {a mathematical formula}2n (we had to extrapolate the results beyond 11 agents, as the runtime became extremely slow). The reason behind this delay is that the algorithm encodes information in extremely large numbers, which may contain hundreds, or even thousands of digits. To be more precise, for every coalition value, {a mathematical formula}v(C), the algorithm needs to use the following number: {a mathematical formula}(nn)v(C). Furthermore, {a mathematical formula}v(C) must be integer. Therefore, even if we use 64-bit integers, we can only handle cases of up to 6 agents with coalition values restricted to the set {a mathematical formula}{0,1,…,6}. We have considered using Matlab, which is slower, but at least allows for much larger numbers, compared to Java. However, the maximum number that can be represented in Matlab is {a mathematical formula}1.8⋅10308, which means that we could handle at most 16 agents with coalition values restricted to the set {a mathematical formula}{0,1,…,16}. Thus, in our implementation, we used BigInteger—a Java class that allows for integers that are unbounded in length. However, the algorithm of Bjorklund et al. needs to perform many operations with these large numbers, resulting in huge delays that are hidden by the asymptotic analysis. As a result, even for 15 agents, the algorithm needs about {a mathematical formula}1.5⋅1010 milliseconds (more than 5 months) to terminate. This is despite the fact that, in order to speed up the algorithm, we restrict the experiment to coalition values taken from the set {a mathematical formula}{0,1,…,9}, which is obviously very restrictive (a larger range would increase the number of required digits dramatically, resulting in a very significant slowdown). On the other hand, the runtime of ODP-IP cannot possibly be slower than that of ODP, even on worst-case instances. The runtime of ODP (which depends solely on the number of agents, and is not affected by any variations in coalition values, as long as these can be represented by floating-point numbers) is only 0.01 seconds given 15 agents.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      The term “complete set partitioning problem” was introduced by Lin [20] for a special class of set partitioning problems. The application that motivated this study was the structuring of corporate tax in the United States. In particular, several states, such as Ohio, allowed any corporation to file its annual unemployment compensation payment either on a subsidiary basis or by grouping subsidiaries into disjoint aggregations. The total unemployment compensation tax payment depended on particular aggregations chosen by the parent corporation. To provide an exact solution to this optimisation problem, Lin and Salkin [21], [22] developed an integer programming algorithm with branch search enumeration[12] that runs in time {a mathematical formula}O(2n2/2). Yeh [48] later showed that this algorithm is substantially slower than DP. The DP algorithm was later on re-discovered in the combinatorial-auctions literature, to solve the winner determination problem in cases where every possible bundle of goods has a (possibly zero-valued) bid placed on it [36]. Sandholm [37] provided further analysis of the complexity of this algorithm; in particular, he observed that its running time is polynomial in the size of the input (i.e., the number of possible subsets of goods). However, in contrast with our work, this analysis did not expose the redundant operations in DP.
     </paragraph>
     <paragraph>
      The “complete” set partitioning problem differs from the “incomplete” version in terms of the input: in the complete version, the input consists of the values of all possible subsets, whereas in the incomplete version some values are listed explicitly, while others are assumed to be 0. Thus, the complete version usually involves tens of agents, with billions and billions of possible partitions. On the other hand, the incomplete version could involve, say, thousands of agents, and thousands of subsets. Thus, the complete version has a much larger, and much more structured, input. This is a fundamental difference, rendering some techniques effective for one version, and ineffective for the other. Consider CPLEX, for example. It is very effective on the incomplete version, but very quickly runs out of memory for the complete version [32].
     </paragraph>
     <paragraph>
      The rapid growth of the multi-agent systems research community in the 1990s led to renewed interest in the complete set partitioning problem. In this literature, the problem was called the “coalition structure generation problem”, and was studied in the context of partitioning agents into coalitions so as to maximise the social welfare. In this context, a number of exact, anytime algorithms were proposed, with the focus being on establishing a bound on the quality of their “interim” solutions (i.e., the solutions that the algorithms return during execution, not after completion). These algorithms can be divided into two categories, based on the techniques they use:
     </paragraph>
     <list>
      <list-item label="•">
       The first class of algorithms focuses on (1) proposing a criterion for dividing the search space into disjoint and exhaustive subspaces, and (2) identifying a sequence in which these subspaces should be searched, so that the worst-case bound on solution quality is guaranteed to improve after each subspace. We will denote the chosen sequence of subspaces by {a mathematical formula}S1,…,Sk, and the bound established after searching {a mathematical formula}S1∪⋯∪Si by {a mathematical formula}βi. This bound is based solely on comparing the coalition structures that have already been considered against those that are yet to be considered (i.e., those in {a mathematical formula}Si+1∪⋯∪Sk), without paying attention to the actual coalition values at hand. This makes such algorithms applicable in settings where only coalition structure values can be observed, not coalition values. This also makes the bounds independent of the coalition-value distribution, meaning that such algorithms can guarantee their bounds regardless of the distribution.Any algorithm in this class can be extended (possibly in different directions) by specifying the technique(s) used to search the subspaces. Such technique(s) can capitalise on the extra information accrued during the actual search, which can be used, e.g., to avoid examining all solutions in a subspace, or to establish bounds other than, and hopefully better than, {a mathematical formula}βi, {a mathematical formula}i=1,…,k. The advantage of such an extension is that it can place guarantees on its bounds; they cannot be worse than {a mathematical formula}βi, {a mathematical formula}i=1,…,k.The first algorithm in this class was put forward in the seminal article by Sandholm et al. [38], where the proposed sequence was {a mathematical formula}S1=Π1A∪Π2A and {a mathematical formula}Si=Πn−i+2A for {a mathematical formula}i=2,…,n−1. Two particularly interesting bounds were {a mathematical formula}β1=n and {a mathematical formula}β2=⌈n/2⌉; the authors proved that {a mathematical formula}S1 and {a mathematical formula}S2 are the smallest subsets of solutions that one can search to establish the tight bounds n and {a mathematical formula}⌈n/2⌉, respectively (unless, of course, one uses extra information obtained from the characteristic function at hand). An alternative algorithm was later suggested by Dang and Jennings [9], who proposed a different sequence, along with a different set of bounds, compared to Sandholm et al. This algorithm was able to establish certain bounds by going through a smaller number of solutions. Another algorithm was proposed by Rahwan et al. [33]; it represents every {a mathematical formula}Si as a union of integer partition-based subspaces. Consequently, one can readily extend this algorithm by using IP (or ODP-IP) to search every {a mathematical formula}Si.All the algorithms in this class discussed so far are proposed for characteristic function games, where there are no influences among co-existing coalitions. Rahwan et al. [31] proposed the first algorithm for the more general class of partition function games (PFGs), i.e., games with externalities. In such games, the value of a coalition depends on the coalition structure it appears in. Rahwan et al. focused on two sub-classes of partition function games: (1) {a mathematical formula}PFG+, where externalities are non-negative, and (2) {a mathematical formula}PFG−, where externalities are non-positive. Each of these two sub-classes is a generalisation of characteristic function games and, arguably, many realistic partition function games are either {a mathematical formula}PFG+ games or {a mathematical formula}PFG− games. This algorithm was later on extended by Banerjee and Kraemer [5] to settings where agents are grouped into categories, or “types”. Here, the authors assume that if two coalitions {a mathematical formula}C1 and {a mathematical formula}C2 merge, then the externality imposed by this merge on a third coalition {a mathematical formula}C3 is non-negative if the types of the agents in {a mathematical formula}C1∪C2 do not overlap with those of the agents in {a mathematical formula}C3. Otherwise, the externality is non-positive. Let us denote this class of games by {a mathematical formula}PFGtype. Banerjee and Kraemer [5] argue that this class is intuitive, and maps to a number of applications.
      </list-item>
      <list-item label="•">
       The second class of anytime, exact algorithms focuses on finding, and recognising, an optimal coalition structure as quickly as possible. The main techniques used here are (1) branch-and-bound, where the aim is to identify, and thus avoid evaluating, unpromising combinations of coalitions, and (2) dynamic programming, where the aim is to avoid evaluating any combination of coalitions more than once.Arguably, the first algorithm in this class is IP, due to Rahwan et al. [30], [32], which uses branch-and-bound techniques as described in Section 3.1. A distributed version of IP was later on proposed by Michalak et al. [23] as the first distributed, exact algorithm for coalition structure generation.Since the initial publication of ODP [28], an anytime version of the size-based version of ODP was proposed by Service and Adams [41]. In this version, an initial stage is added, whereby, for each coalition C, the algorithm identifies and stores the subset of C that has the highest value. The authors showed how, using this extra information, every time the algorithm finishes evaluating the splits of all coalitions of a certain size s, it can construct a coalition structure whose value is guaranteed to be within a bound r from optimal, where {a mathematical formula}r=max⁡{i:i∈Z,s≤⌊ni⌋}. The termination time of this modified ODP is almost identical to that of the original ODP (except for the time required to run the added initial stage). This implies that the modified ODP algorithm is significantly slower than ODP-IP for all coalition-value distributions mentioned in Section 6.2 (see the difference in termination time between ODP-IP and ODP in Fig. 9). Moreover, the guarantees provided by Service and Adams's modified ODP do not exceed 50% until termination, while the guarantees provided by ODP-IP often exceed 80% (or even 99%) after only 10% (or even 3%) of the termination time (see Fig. 10). Finally, Service and Adams's modified ODP requires twice as much memory compared to ODP-IP, as it has to store the best subset of every coalition.So far in this class, we focused on algorithms for characteristic function games. Next, we shift our attention to partition function games. Recall that in the presence of externalities, a coalition may have different values depending on the coalition structure it is embedded in. It is not difficult to show that in the most general case, where externalities are arbitrary, it is impossible to place any bound on the solution quality without examining every single coalition structure. However, for two common classes of partition function games, namely {a mathematical formula}PFG+ and {a mathematical formula}PFG−, Rahwan and Ramchurn [32], Rahwan et al. [35] proved that it is possible to compute upper and lower bounds on the values of any set of disjoint coalitions in linear time. These bounds can then be used to identify unpromising search directions using techniques similar to those used in IP. Similarly, Banerjee and Kraemer [5] proposed an extension of IP to handle externalities in {a mathematical formula}PFGtype settings.
      </list-item>
     </list>
     <paragraph>
      Another extension of ODP, which however is not anytime, is due to Voice et al. [46], who focus on the restricted coalition formation model proposed by Myerson [24]. In this model, the space of feasible coalitions is restricted by a graph G, where nodes represent agents and edges represent possibilities of collaboration; a coalition C is only feasible if the agents in C induce a connected subgraph of G. A “feasible” coalition structure is then simply one where all coalition are feasible. Recall that we have shown in Theorem 6 that, for any set of movements between coalition structures, if DP only evaluates those movements, it will find the best coalition structure reachable using those movements. Voice et al. focused on the set of movements between feasible coalition structures (i.e., restricted by G). This provides significant speedups in computation when the graph is sparse.
     </paragraph>
     <paragraph>
      In this article we focused on the classical representation of characteristic function games, where the value of every coalition {a mathematical formula}C⊆A is returned by a characteristic function {a mathematical formula}v:2A→R. However, one can also study the optimal coalition structure generation problem for alternative representations, which are designed to efficiently capture situations where the characteristic function has some structure. For instance, Ueda et al. [44] studied coalition structure generation under the DCOP (Distributed Constraint Optimisation Problem) representation (where every agent has a set of actions to choose from), while Bachrach et al. [4], [3] studied it under the skill-game representation (where every agent has a set of skills required to perform tasks). Ohta et al. [25] studied coalition structure generation under the Marginal Contribution Nets representation of Ieong and Shoham [14], where synergies between agents are described by a (possibly small) collection of weighted logical formulas. Furthermore, Ueda et al. [45] and Aziz and de Keijzer [2] considered this problem under the agent-type representation (where agents are grouped into categories, or “types”). A common denominator of all these works is that the proposed algorithms for the coalition structure generation problem capitalise heavily on features of the underlying representation. As ODP-IP is a general-purpose algorithm, it is unlikely to outperform these algorithms on problem instances where the alternative representation happens to compactly and efficiently represent the game. In such settings, ODP-IP can serve as a common benchmark to evaluate the potential speedups achieved by using specific representations.
     </paragraph>
     <paragraph>
      While this article focuses on exact coalition structure generation algorithms, we mention a number of metaheuristic algorithms, which do not guarantee that an optimal solution is ever found, nor do they provide any guarantees on the quality of their solutions. However, such algorithms are usually fast, and can therefore be applied when the number of agents is large. These include a greedy algorithm by Shehory and Kraus [42], a genetic algorithm by Sen and Dutta [39], a simulated-annealing algorithm by Keinänen [15], and an algorithm by Di Mauro et al. [11] that combines a greedy technique with another local-search technique.
     </paragraph>
    </section>
    <section label="8">
     <section-title>
      Conclusions and future work
     </section-title>
     <paragraph>
      Our goal in this article was to provide extensive theoretical analysis of the search space of the Complete Set Partitioning problem and to improve upon two fundamentally-different exact algorithms, namely DP and IP. We drew a link between the workings of DP and the coalition structure graph, which revealed that many of DP's operations are redundant. Building upon this observation, we developed ODP—an optimal version of DP that avoids all redundant operations.
     </paragraph>
     <paragraph>
      Although ODP and IP are based on different design paradigms, we developed a new search-space representation (namely, the integer partition graph) that exposes the possibility of having them combined into a single hybrid algorithm. Building upon this, we modified, and improved upon, both DP and IP, and combined the modified versions into a new algorithm called ODP-IP. Our analysis and empirical evaluation showed that ODP-IP possesses the strengths and avoids the weaknesses of both DP and IP: it is anytime, runs in {a mathematical formula}O(3n) time, and is faster than both algorithms for a wide variety (10 in total) of value distributions considered in this article (with speedups reaching one or two orders of magnitude, given 25 agents). The community can benefit from the open-source implementation, which is made publicly available.{sup:12}
     </paragraph>
     <paragraph>
      While the focus in this article was on settings where there are no influences (or externalities) among co-existing coalitions, it would be interesting to see whether the underlying techniques of ODP-IP can be extended to settings with externalities, and to identify conditions under which such an extension can be efficient (in the spirit of Rahwan et al. [35]).
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <section-title>
      Summary of notation
     </section-title>
     <paragraph>
      the set of all possible movements in the coalition structure graphMa subset of {a mathematical formula}M{a mathematical formula}M⁎the subset of {a mathematical formula}M that is evaluated by ODP{a mathematical formula}M⁎⁎the subset of {a mathematical formula}M that is evaluated by the size-based version of ODP{a mathematical formula}Ms′,s″the set of movements in {a mathematical formula}M that correspond to splitting a coalition of size {a mathematical formula}s′+s″ into two coalitions of sizes {a mathematical formula}s′ and {a mathematical formula}s″, respectively{a mathematical formula}mC1,C2the movement that corresponds to splitting {a mathematical formula}C=C1∪C2 into {a mathematical formula}C1 and {a mathematical formula}C2{a mathematical formula}RMπthe set of all partitions that are reachable from π via M{a mathematical formula}f(C)the value of an optimal partition of C{a mathematical formula}fM(C)the value of a partition with the highest value in {a mathematical formula}RM{C}
     </paragraph>
    </section>
    <section label="Appendix B">
     <section-title>
      Pseudocode of the ODP-IP algorithm
     </section-title>
     <paragraph>
      Algorithm 3 provides the pseudocode of ODP, while Algorithm 4 provides the pseudocode of getBestPartition—the function used in line 32 of Algorithm 3. Here, we use a hash table to access the characteristic function, where a coalition C acts as the key to the entry containing {a mathematical formula}v(C). While this is clearly the most efficient data structure, for large problem instances the available memory might not be sufficient, in which case other data structures must be explored. However, we did not consider any such alternatives in this article.
     </paragraph>
     <paragraph>
      We remark that, to save memory, we avoid storing the table t, i.e., we only store {a mathematical formula}fM⁎(C) for all {a mathematical formula}C⊆A, and then recompute t on-the-fly (see Algorithm 4). Observe that we need to compute the value of t for at most {a mathematical formula}2n−1 coalitions during each execution of the algorithm, and, given the values of {a mathematical formula}f(C′) for all {a mathematical formula}C′⊆C, we can compute {a mathematical formula}t(C) in time {a mathematical formula}2|C|. Thus, this modification requires less than {a mathematical formula}(2n−1)×2n additional operations, which is negligible compared to {a mathematical formula}O(3n)—the runtime of ODP. In return, the algorithm only needs to store the characteristic function, v, instead of storing both v and t, resulting in 50% reduction in memory requirements compared to DP.
     </paragraph>
    </section>
    <section label="Appendix C">
     Proofs for Section 4
     <paragraph label="Theorem 6">
      For every coalition{a mathematical formula}C⊆Aand for every subset of movements{a mathematical formula}M⊆Mit holds that{a mathematical formula}
     </paragraph>
     <paragraph label="Proof">
      If {a mathematical formula}|C|=1, then no movement can be made from {a mathematical formula}{C}. This means that {a mathematical formula}RM{C}={{C}} and hence {a mathematical formula}fM(C)=v(C).Now, suppose that {a mathematical formula}|C|&gt;1. Consider a partition {a mathematical formula}{C′,C″}∈ΠC and a set of movements {a mathematical formula}M⊆M. Abusing notation, set{a mathematical formula} Observe that{a mathematical formula}Since {a mathematical formula}{C} contains exactly one coalition, namely, C, every partition reachable from {a mathematical formula}{C} via a single movement in M contains exactly two coalitions. Conversely, every partition in {a mathematical formula}RM{C} that contains exactly two coalitions is reachable from {a mathematical formula}{C} via at most one movement in M. Thus,{a mathematical formula} Hence, we have{a mathematical formula} where the first equality is based on (3), the second equality is based on (C.2), and the last equality is based on (C.1). Consequently, we obtain{a mathematical formula}  □
     </paragraph>
     <paragraph label="Corollary 13">
      The number of movements in{a mathematical formula}Mis{a mathematical formula}12(3n+1)−2n, whereas the number of movements in{a mathematical formula}M⁎is{a mathematical formula}12(3n−1−1).
     </paragraph>
     <paragraph label="Proof">
      For {a mathematical formula}M, the argument is essentially provided by Yeh [48]; we reproduce it here for completeness. For each coalition C of size k, {a mathematical formula}2≤k≤n, there are {a mathematical formula}2k−1−1 ways of splitting C into two non-empty coalitions, so DP evaluates {a mathematical formula}2k−1−1 movements from C. Thus, the total number of movements evaluated by DP can be written as{a mathematical formula} Using the fact that{a mathematical formula} with {a mathematical formula}x=2 and {a mathematical formula}x=1, we conclude that DP evaluates {a mathematical formula}12(3n+1)−2n movements.We will now consider {a mathematical formula}M⁎. By Theorem 12, we have{a mathematical formula}Now, recall that the number of ways to partition n elements into k parts—known as the Stirling number of the second kind[43], and denoted by {a mathematical formula}S(n,k)—is computed as follows:{a mathematical formula} Thus, the number of movements that are evaluated by ODP is {a mathematical formula}S(n,2)+S(n,3), which equals{a mathematical formula}  □
     </paragraph>
    </section>
    <section label="Appendix D">
     Proofs for Section 5
     <paragraph label="Theorem 15">
      {a mathematical formula}
     </paragraph>
     <paragraph label="Proof">
      We will show that every coalition structure CS with {a mathematical formula}|CS|≥2 is reachable via {a mathematical formula}M⁎⁎ from some other coalition structure {a mathematical formula}CS′ with {a mathematical formula}|CS′|=|CS|−1. To this end, assume without loss of generality that {a mathematical formula}CS={C1,…,Ck}, where {a mathematical formula}k≥2 and {a mathematical formula}|C1|≤⋯≤|Ck|. We will argue that {a mathematical formula}mC1,C2∈M⁎⁎, and hence CS can be reached from the coalition structure {a mathematical formula}(CS\{C1,C2})∪{C1∪C2} via {a mathematical formula}M⁎⁎. Let {a mathematical formula}s1=|C1|, {a mathematical formula}s2=|C2|; by construction, we have {a mathematical formula}mC1,C2∈Ms1,s2.First, suppose that {a mathematical formula}k=2. In this case, we have {a mathematical formula}CS={C1,C2}, and so {a mathematical formula}s1+s2=n. This means that {a mathematical formula}Ms1,s2 is a subset of {a mathematical formula}M⁎⁎ (see equation (9)).Now, suppose that {a mathematical formula}k&gt;2. We have {a mathematical formula}|C1|≤|C2|≤|C3|≤n−|C1|−|C2|, so {a mathematical formula}max⁡{s1,s2}=s2≤n−s1−s2. This means that {a mathematical formula}Ms1,s2 is a subset of {a mathematical formula}M⁎⁎ in this case as well (again, see equation (9)).  □
     </paragraph>
     <paragraph label="Lemma 16">
      The{a mathematical formula}DPM⁎⁎algorithm does not evaluate any of the possible ways of splitting a coalition of size s, where{a mathematical formula}s∈{⌊2n3⌋+1,…,n−1}.
     </paragraph>
     <paragraph label="Proof">
      We will prove that for every {a mathematical formula}s∈{⌊2n3⌋+1,…,n−1} and for all {a mathematical formula}s′,s″∈Z+ such that {a mathematical formula}s′+s″=s it holds that{a mathematical formula} This immediately implies our claim: since {a mathematical formula}s′+s″=s, we have {a mathematical formula}max⁡{s′,s″}≥⌈s/2⌉&gt;n−s and hence {a mathematical formula}Ms′,s″∩M⁎⁎=∅. Since the expression {a mathematical formula}⌈s/2⌉+s is monotone in s, it suffices to prove equation (D.1) for the smallest value of s in {a mathematical formula}{⌊2n3⌋+1,…,n−1}, i.e., for {a mathematical formula}s0=⌊2n3⌋+1. We have {a mathematical formula}s0&gt;2n3, so {a mathematical formula}⌈s02⌉≥s02&gt;n3, and thus {a mathematical formula}⌈s02⌉+s0&gt;n3+2n3=n. Rearranging, we obtain {a mathematical formula}⌈s02⌉&gt;n−s0, which is what we wanted to prove.  □
     </paragraph>
     <paragraph label="Theorem 17">
      The number of movements in{a mathematical formula}M⁎⁎is{a mathematical formula}123n−1+o(3n).
     </paragraph>
     <paragraph label="Proof">
      Let {a mathematical formula}Mˆ={mC′,C″:C′∪C″⊂A}∩M⁎⁎, and consider the mapping {a mathematical formula}α:Mˆ→Π3A given by{a mathematical formula} Note that by construction of {a mathematical formula}Mˆ, for each {a mathematical formula}mC′,C″∈Mˆ the set {a mathematical formula}A∖(C′∪C″) is not empty, so {a mathematical formula}α(mC′,C″) is indeed an element of {a mathematical formula}Π3A, i.e., a partition of A into three non-empty parts.To prove the theorem, we will show that (1) {a mathematical formula}|M⁎⁎∖Mˆ|=o(3n) and (2) {a mathematical formula}|Mˆ|=123n−1+o(3n). Taken together, these claims show that{a mathematical formula} which is what we want to prove.The first of these claims is immediate: we have{a mathematical formula} To prove the second claim, we will show that for almost all coalition structures in {a mathematical formula}Π3A their pre-image under α consists of exactly one movement, and for the remaining coalition structures in {a mathematical formula}Π3A their pre-image under α contains at most 3 movements. To complete the proof, we then use the fact that{a mathematical formula} (see the proof of Corollary 13).In more detail, consider a coalition structure {a mathematical formula}CS={C1,C2,C3} in {a mathematical formula}Π3A, let {a mathematical formula}s1=|C1|, {a mathematical formula}s2=|C2|, {a mathematical formula}s3=|C3|, and assume without loss of generality that {a mathematical formula}s1≤s2≤s3. If {a mathematical formula}s2&lt;s3, then the only element of {a mathematical formula}Mˆ that is mapped to CS by α is {a mathematical formula}mC1,C2: indeed, we have {a mathematical formula}mC1,C3∉Mˆ, {a mathematical formula}mC2,C3∉Mˆ. If {a mathematical formula}s1&lt;s2=s3, then there are two elements of {a mathematical formula}Mˆ that are mapped to CS by α, namely, {a mathematical formula}mC1,C2 and {a mathematical formula}mC1,C3. Finally, if {a mathematical formula}s1=s2=s3, then there are three elements of {a mathematical formula}Mˆ that are mapped to CS by α, namely, {a mathematical formula}mC1,C2, {a mathematical formula}mC1,C3, and {a mathematical formula}mC2,C3.Let{a mathematical formula}{a mathematical formula}{a mathematical formula} and set {a mathematical formula}x=|X|, {a mathematical formula}y=|Y|, {a mathematical formula}z=|Z|. Since every movement in {a mathematical formula}Mˆ is mapped to some coalition structure in {a mathematical formula}Π3A by α, the argument above shows that {a mathematical formula}|Mˆ|=x+2y+3z≤(x+y+z)+2(y+z)=|Π3A|+2(y+z). We have observed that {a mathematical formula}|Π3A|=S(n,3)=123n−1+o(3n). Thus, to complete the proof, it suffices to show that {a mathematical formula}y+z=o(3n).Note that every coalition structure {a mathematical formula}{C1,C2,C3}∈Y∪Z has the property that {a mathematical formula}|C1|≤|C2|=|C3|. To obtain such a coalition structure, we can first choose the coalition {a mathematical formula}C1, whose size is at most {a mathematical formula}n/3, and then partition the remaining elements into two sets of equal size. Equivalently, we can first choose which elements will appear in {a mathematical formula}C2∪C3, and then partition the selected elements into two sets of equal size; note that the number of elements selected at the first step needs to be even and cannot be less than {a mathematical formula}2⌊n3⌋. It follows that{a mathematical formula} This completes the proof.  □
     </paragraph>
    </section>
    <section label="Appendix E">
     <section-title>
      Analysing different methods of searching multiple subspaces simultaneously
     </section-title>
     <paragraph>
      This appendix provides further details on how IP can simultaneously search multiple subspaces using the information provided by ODP.
     </paragraph>
     <paragraph>
      Assume that ODP has already finished evaluating all movements {a mathematical formula}mC,C′∈M⁎⁎ with {a mathematical formula}|C|+|C′|∈{2,…,s⁎}. Then, for any given subspace {a mathematical formula}ΠIA with {a mathematical formula}I={i1,…,ik}, we modify IP so that, instead of searching for a coalition structure in {a mathematical formula}argmaxCS∈ΠIAV(CS), it performs the following steps:
     </paragraph>
     <list>
      <list-item label="1.">
       Identify{a mathematical formula}X⁎—the set of all integer partitions whose corresponding subsets have not yet been searched and are reachable from {a mathematical formula}ΠIA using only the movements that have been evaluated by ODP so far. For instance, given {a mathematical formula}I={2,4,4} and {a mathematical formula}s⁎=4, the set {a mathematical formula}X⁎ consists of all integer partitions that are reachable through the dotted edges in Fig. 7(B).
      </list-item>
      <list-item label="2.">
       Identify{a mathematical formula}I⁎—the set of integer(s) in I that will be split in order to reach (some of) the subspaces in {a mathematical formula}X⁎. As mentioned in Section 5.4, one can choose either to split a single integer in I or to split multiple integers at once. We will consider both cases. Specifically, if exactly one integer will be split, pick an integer {a mathematical formula}s∈I so that splitting s allows for reaching the largest number of integer partitions in{a mathematical formula}X⁎, and set {a mathematical formula}I⁎={s}. On the other hand, if multiple integers will be split, choose {a mathematical formula}I⁎ so that splitting the integers in {a mathematical formula}I⁎ allows for reaching all the integer partitions in{a mathematical formula}X⁎. The subset of{a mathematical formula}X⁎that is reachable by splitting the integer(s) in{a mathematical formula}I⁎will be denoted by{a mathematical formula}Y⁎. For instance, given {a mathematical formula}I={2,4,4} and {a mathematical formula}s⁎=4, if exactly one integer will be split, then we have {a mathematical formula}I⁎={4}, and {a mathematical formula}Y⁎ consists of the integer partitions that are reachable through the dashed edges in Fig. 7(A). On the other hand, if multiple integers will be split, then we have {a mathematical formula}I⁎={2,4,4}, and {a mathematical formula}Y⁎ consists of the integer partitions that are reachable through the dotted edges in Fig. 7(B).
      </list-item>
      <list-item label="3.">
       Change the order of the integers in I and in every{a mathematical formula}I′∈Y⁎. To this end, let {a mathematical formula}ij⁎ denote the j-th element in {a mathematical formula}I⁎. Furthermore, for every {a mathematical formula}ij⁎∈I⁎ and every {a mathematical formula}I′∈Y⁎, let {a mathematical formula}S(I′,ij⁎) be the subset of {a mathematical formula}I′ that results from splitting {a mathematical formula}ij⁎. Now, order the integers in I by putting the ones in {a mathematical formula}I∖I⁎ first, followed by {a mathematical formula}i1⁎, then {a mathematical formula}i2⁎, and so on until {a mathematical formula}i|I⁎|⁎. Similarly, for every {a mathematical formula}I′∈Y⁎, change the order of integers in {a mathematical formula}I′ by putting the ones in {a mathematical formula}I′∖I⁎ first, then those in {a mathematical formula}S(I′,i1⁎), then those in {a mathematical formula}S(I′,i2⁎), and so on until {a mathematical formula}S(I′,i|I⁎|⁎).
      </list-item>
      <list-item label="4.">
       Search{a mathematical formula}ΠIA, where every{a mathematical formula}{C1,…,Ck}∈ΠIAis evaluated as follows:{a mathematical formula} During this search, at every depth d, use the following modified branch-and-bound inequality:{a mathematical formula} where {a mathematical formula}UBId is an upper bound computed as follows:{a mathematical formula} The result of this search is a coalition structure {a mathematical formula}{C1⁎,…,Ck⁎}∈ΠIA that maximises (E.1).
      </list-item>
      <list-item label="5.">
       Replace every{a mathematical formula}Cj⁎such that{a mathematical formula}j&gt;|I∖I⁎|with{a mathematical formula}getBestPartition(Cj⁎,t(Cj⁎)). The result is a coalition structure in {a mathematical formula}argmaxCS∈({ΠIA}∪Y⁎)V(CS).
      </list-item>
     </list>
     <paragraph>
      At first glance, it may seem that partitioning multiple integers is better than partitioning a single integer, because the former approach enables us to search more subspaces simultaneously. Surprisingly, however, it can actually be faster to partition one integer only. We will now explain why this may be the case.
     </paragraph>
     <paragraph>
      The difficulty with splitting multiple integers is that it may interfere with our branch-and-bound technique. Specifically, recall that when we search subspaces one by one, we prune branches of the search tree by checking inequality (1) (reproduced below for convenience).{a mathematical formula} In contrast, when searching multiple subspaces simultaneously, we use inequality (E.2), which holds less frequently than (1), because the left-hand side in (E.2) is greater than that in (1). This increase (in the left-hand side) can be seen as the price that must be paid in order to avoid searching every {a mathematical formula}ΠI′A with {a mathematical formula}I′∈Y⁎ separately later on.
     </paragraph>
     <paragraph>
      The problem, however, is that this price is often too large. To see why, let us analyse the two modifications that are behind this increase.
     </paragraph>
     <list>
      <list-item label="•">
       The first modification is when {a mathematical formula}|I∖I⁎|&lt;d. In this case, every {a mathematical formula}Cj with {a mathematical formula}j∈{|I∖I⁎|,…,d} is evaluated as {a mathematical formula}fM⁎(Cj) rather than as {a mathematical formula}v(Cj).
      </list-item>
      <list-item label="•">
       The second modification is in the upper bound on the values of the coalitions that will be added to {a mathematical formula}C1,…,Cd. In particular, since every {a mathematical formula}ΠI′A with {a mathematical formula}I′∈Y⁎ is searched simultaneously with {a mathematical formula}ΠIA, the upper bound in (E.2) becomes {a mathematical formula}UBId instead of {a mathematical formula}∑j=d+1|I|Maxij.
      </list-item>
     </list>
     <paragraph>
      A key point here is that {a mathematical formula}Y⁎ does not necessarily contain all the integer partitions that are reachable from I; it only contains those representing subspaces that have not yet been searched. This important point is reflected in the second modification, but not in the first one. More specifically, in the second modification, a new upper bound is used that only takes into account{a mathematical formula}ΠIAas well as{a mathematical formula}ΠI′Awith{a mathematical formula}I′∈Y⁎. However, in the first modification, every {a mathematical formula}Cj with {a mathematical formula}j∈{|I∖I⁎|,…,d} is evaluated as {a mathematical formula}fM⁎(Cj)—the value of the best partition of {a mathematical formula}Cj in all the subspaces that are reachable from {a mathematical formula}ΠIA, including those that have already been searched. In other words, this modification ignores the fact that certain subspaces have already been searched.
     </paragraph>
     <paragraph>
      Now, let us analyse the case where {a mathematical formula}I⁎ contains exactly one integer. To this end, observe that if {a mathematical formula}d=|I|−1, then there is no need to determine whether {a mathematical formula}{C1,…,Cd} is promising. Instead, one can straight away construct the only coalition structure of size {a mathematical formula}|I| containing {a mathematical formula}C1,…,Cd—it suffices to put all the remaining agents in a coalition of their own. Thus, whenever the branch-and-bound technique is used, we always have {a mathematical formula}d&lt;|I|−1. This implies that, when {a mathematical formula}I⁎ contains exactly one integer, we always have {a mathematical formula}min⁡(d,|I∖I⁎|)=d. Consequently, inequality (E.2) can be written as follows:{a mathematical formula} This way, we get rid of the first modification, and only keep the second one, which takes into consideration only the subspaces that have not yet been searched, and are reachable from {a mathematical formula}ΠIA.
     </paragraph>
    </section>
    <section label="Appendix F">
     <section-title>
      Pseudocode of the inclusion–exclusion algorithm
     </section-title>
     <paragraph>
      While Björklund et al. [8] provide a detailed description of their inclusion–exclusion algorithm, they do not include pseudocode for it. We therefore provide pseudocode for their algorithm in this appendix. Note that the algorithm is defined for situations where (1) the goal is to find the best partition containing at most k subsets, (2) there are k evaluation functions, {a mathematical formula}f1,…,fk, and (3) the value of the i-th subset is given by the i-th evaluation function, {a mathematical formula}fi. In our setting, we have {a mathematical formula}k=n (since coalition structures are allowed to contain up to n coalitions) and {a mathematical formula}fi=v for all {a mathematical formula}i∈{1,…,k} (since all coalitions are evaluated using the same function, v). Thus, the pseudocode below is for the case where {a mathematical formula}k=n and {a mathematical formula}fi=v for all {a mathematical formula}i∈{1,…,k}.
     </paragraph>
     <paragraph>
      {a mathematical formula}
     </paragraph>
     <paragraph>
      {a mathematical formula}
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>