<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Efficient symbolic search for cost-optimal planning.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Classical planning consists of finding a sequence of operators, commonly called a plan, that achieves a set of goals from a given initial state. The objective of optimal planners is to find the plan of minimum cost, defined by the sum of the cost of its operators. A prominent method for cost-optimal planning is state-space search. Dijkstra search [1] is a classical algorithm also known as “Uniform-Cost Search”, which is arguably a more precise name [2]. Uniform-cost search always expands a reachable state with least cost among those yet unexpanded, thus guaranteeing an optimal solution when a goal state is expanded. {a mathematical formula}A⁎ search [3] uses admissible heuristics that provide a lower bound on the distance from a state to the goal to reduce the number of expanded states. State-space search algorithms can be classified by the direction in which they traverse the search space: progression or regression. In progression, search is performed in forward direction, from the initial state towards the goal. In regression, backward search is performed from the set of goal states towards the initial state. Additionally, bidirectional algorithms search in both directions simultaneously.
     </paragraph>
     <paragraph>
      Forward {a mathematical formula}A⁎ with admissible heuristics is the most popular approach for cost-optimal planning, thanks to effective domain-independent admissible heuristics such as Merge-and-Shrink [4] or LM-cut [5]. On the other hand, regression and bidirectional search have lost importance due to the shortcomings associated with regression in planning [6]. Regression in planning is commonly thought to be less robust than progression due to (a) the existence of multiple goal states, which requires considering partially-defined states (i.e., in which the value of some variables is unknown) and (b) the impact that states unreachable from the initial state have on backward search [7].
     </paragraph>
     <paragraph>
      The main shortcoming of state-space search is that the number of states that must be explored to find an optimal solution may be exponential on the size of the problem. Symbolic search aims to alleviate this problem by reasoning about sets of states, represented by efficient data-structures like Binary Decision Diagrams (BDDs) [8], instead of individual states. BDDs can sometimes represent sets of states with exponentially less memory than their explicit enumeration so symbolic search with BDDs usually lessens in practice the memory requirement of explicit-state search algorithms. This means that symbolic versions of common search algorithms, such as symbolic uniform-cost search and symbolic {a mathematical formula}A⁎[9] (also known as {a mathematical formula}BDDA⁎) are often able to solve problems that explicit-state algorithms are unable to solve due to memory problems. Moreover, BDDs also provide efficient operations to manipulate sets of states and perform search.
     </paragraph>
     <paragraph>
      Symbolic planning with BDDs was brought over from symbolic model checking [10] and has been pioneered by Cimatti et al. [11] to develop non-deterministic planners. The Model-Checking Integrated Planning System MIPS[12] was the first classical planning system based on symbolic search with BDDs. Later on, state-set branching [13] was proposed as an improvement over regular {a mathematical formula}BDDA⁎. Finally, Gamer[14], [15] is an evolution of MIPS with several improvements like symbolic pattern database heuristics to guide {a mathematical formula}BDDA⁎ and an optimization of the BDD variable ordering. However, and despite the advantages that symbolic search has over explicit-state search and its relative success in different AI competitions, the area as a whole remains relatively unexplored. In this paper, we aim to improve symbolic search for cost-optimal planning with two orthogonal lines of research:
     </paragraph>
     <paragraph>
      Image computation. We experiment with different ways to perform the image computation, used to perform successor generation in symbolic search and one of the main computational bottlenecks in symbolic planning. We discuss different methods to represent the transition relations (TRs), i.e., the BDD encoding of planning operators. Planning operators are intelligently grouped in order to decide which operators should be represented together in the same TR and speed-up image computation.
     </paragraph>
     <paragraph>
      State-invariant constraints. We study the exploitation of constraints such as mutexes and invariant groups in combination with BDDs, both in symbolic search and symbolic abstractions. We show that constraints can be encoded as BDDs efficiently, and that they can also be encoded in the TRs.
     </paragraph>
     <paragraph>
      In order to evaluate the benefit of these advances in state-of-the-art symbolic planning algorithms, we implemented them in Gamer. We also extended Gamer symbolic bidirectional breadth-first search to uniform-cost search, which is optimal in domains with non-uniform operator costs. We call the resulting planner constrainedGamer, cGamer for short.
     </paragraph>
     <paragraph>
      Experimental results show that our proposed refinements in image computation and state-invariant pruning lead to a more efficient search. These improvements are orthogonal and, when combined, they get an important leap in performance for symbolic planning algorithms. With these enhancements, the best variant of cGamer, which uses bidirectional uniform-cost search, outperforms current explicit-state heuristic search in most domains.
     </paragraph>
     <paragraph>
      Some previous conference papers contain preliminary results of our work, both the analysis of image computation [16] and state-invariant pruning in symbolic planning [17]. In this article, we extend our previous work by considering more detailed aspects such as additional strategies for image computation or the use of relevance invariants that detect dead-end states in forward search. The article at hand is structured as follows. Sections 2 formally introduces cost-optimal planning. Section 3 introduces BDDs and symbolic search. Sections 4 and 5 present our analysis of image computation and state-invariant pruning in symbolic search, respectively. Finally, Section 6 shows the experimental results of the proposed techniques in multiple settings and Section 7 discusses the conclusions of this work.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Preliminaries
     </section-title>
     <paragraph>
      A finite-domain variable planning task is defined as a tuple {a mathematical formula}Π=〈V,O,I,G〉. {a mathematical formula}V is a set of state variables, and every variable {a mathematical formula}v∈V has an associated finite domain{a mathematical formula}Dv. A partial state p is a function on a subset of variables {a mathematical formula}Vp⊆V that assigns each variable {a mathematical formula}v∈Vp a value in its domain, {a mathematical formula}p[v]. A state s is a complete assignment to all the variables. We denote {a mathematical formula}S to the set of all states. A fact is an assignment to a single variable and is usually identified as a variable-value pair, {a mathematical formula}〈v,d∈Dv〉. Thus, a partial state p can be defined as a set of facts and is associated with the set of states that satisfy the partial assignment, {a mathematical formula}{s|p[v]=s[v]∀v∈Vp}. We denote as {a mathematical formula}p|V′ the projection of p to the set of variables {a mathematical formula}V′⊆Vp, i.e., as the partial assignment over {a mathematical formula}V′ having the same value as p for variables it is defined for. {a mathematical formula}I is the initial state and {a mathematical formula}G is the partial state that defines the goals. {a mathematical formula}O is a set of operators, where each operator is a tuple {a mathematical formula}o=〈(pre(o),eff(o),w(o))〉, where {a mathematical formula}pre(o) and {a mathematical formula}eff(o) are partial assignments over {a mathematical formula}Vpre(o) and {a mathematical formula}Veff(o) that represent the preconditions and effects of the operator, respectively, and {a mathematical formula}w(o)↦R0+ is the non-negative cost of o. The set of preconditions, {a mathematical formula}pre(o) can be split depending on whether they are affected by the operator effects or not. The prevail conditions of the operators are the subset of preconditions that are not affected by the effects of the operator, {a mathematical formula}prev(o)={fi=〈v,d〉|fi∈pre(o) and v∉Veff(o)}.
     </paragraph>
     <paragraph>
      An operator {a mathematical formula}o∈O is applicable (in progression) in a state s if {a mathematical formula}pre(o)⊆s. The state {a mathematical formula}o(s) resulting from the application of o in s is defined as {a mathematical formula}o(s)=s|V∖Veff(o)∪eff(o). While applicability of operators in progression is defined over complete states, in order to perform regression from the goals of the problem we define the reversed applicability over partial states. An operator {a mathematical formula}o∈O is applicable in a partial state p over {a mathematical formula}Vp in regression if p is consistent with the operator effects and prevails, {a mathematical formula}∀v∈Vp:(v∉Veff(o) or p[v]=eff(o)[v]) and (v∉Vprev(o) or p[v]=prev(o)[v]) and is relevant to p, {a mathematical formula}Vp∩Veff(o)≠∅. The resulting partial state {a mathematical formula}p′ obtained from the application in regression of o in p is defined as {a mathematical formula}p′=(p∪eff(o))|V∖Vpre(o)∪pre(o).
     </paragraph>
     <paragraph>
      A solution plan is a sequence of operators, {a mathematical formula}π=(o1,…,on) related to a sequence of states {a mathematical formula}(s0,s1,…,sn) such that {a mathematical formula}s0 is the initial state and {a mathematical formula}sn∈S⋆, i.e., the set of all goal states, and {a mathematical formula}si results from executing the operator {a mathematical formula}oi in the state {a mathematical formula}si−1, {a mathematical formula}∀i=1..n in progression. The cost of a plan is the sum of the cost of its operators, {a mathematical formula}w(π)=∑0≤i≤nw(oi). A plan is optimal if no other plan of lower cost exists. Most state-of-the-art cost-optimal planners employ heuristic search. A heuristic is a function h: {a mathematical formula}S→R0+ which estimates the cost to reach {a mathematical formula}S⋆ from a state {a mathematical formula}s∈S. The heuristic is perfect if it equals the optimal cost {a mathematical formula}h⁎(s){a mathematical formula}∀s∈S. It is admissible if {a mathematical formula}h(s)≤h⁎(s) for all {a mathematical formula}s∈S.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Symbolic planning with BDDs
     </section-title>
     <paragraph>
      Symbolic search takes advantage of succinct data structures to represent sets of states through their characteristic functions. Given a set of states S, its characteristic function{a mathematical formula}fS is a Boolean function {a mathematical formula}fS(x1⋯xn):S→{⊤,⊥} that represents whether a given state belongs to S, i.e., {a mathematical formula}fS(s)=⊤ iff {a mathematical formula}s∈S. The input of the function is the bit-vector description of a state represented by binary variables {a mathematical formula}xi such that each finite-domain variable {a mathematical formula}υ∈V with domain {a mathematical formula}Dυ is represented with {a mathematical formula}⌈log2⁡|Dv|⌉ binary variables.{sup:1} To simplify the notation, we use the same symbol, S, to denote a set of states and its characteristic function.
     </paragraph>
     <paragraph>
      We also use characteristic functions to operate with sets of states. The union (∪) and intersection (∩) of sets of states are derived from the disjunction (∨) and conjunction (∧) of their characteristic functions, respectively. Also, the complement set ({a mathematical formula}Sc) corresponds with the negation (¬) of the characteristic function. Quantification of variables is another type of function transformation commonly encountered in symbolic search. The existential quantification of a variable υ, {a mathematical formula}∃υS, computes the projection of S to {a mathematical formula}V∖{υ}. Formally, {a mathematical formula}∃υS:=S|υ=⊤∨S|υ=⊥, where {a mathematical formula}fS|υ=x:=(fS∧{s|s[υ]=x})|V∖{υ} is the sets of assignments to variables {a mathematical formula}V∖{υ} so that they make {a mathematical formula}fS true whenever {a mathematical formula}υ=x. Thus, the result of the existential quantification corresponds to the projection of the set of states to the set of variables {a mathematical formula}V∖{υ}.
     </paragraph>
     <paragraph>
      The set of operators {a mathematical formula}O is represented with one or more Transition Relations (TRs). A TR is a function {a mathematical formula}Tc(x,x′) that represents one or more operators with the same cost, c. TRs are defined using two sets of variables, the source-set, x and the target-set {a mathematical formula}x′. Both sets of variables have the same cardinality as the set of variables of the characteristic function, so that each variable in the source- and target-sets corresponds to a variable in the characteristic function. The variables of the source-set correspond to the preconditions of the operators of the TR and the variables of the target-set correspond to the effects. {a mathematical formula}image(S,T):=(∃x(S∧T))[x′/x] computes the set of successor states that can be reached from any state in S by applying any operator represented by T. Similarly, {a mathematical formula}pre-image(S,T):=∃x′((S(x)[x/x′])∧T(x,x′)) computes the set of predecessor states that can reach a state in S by applying an operator in T. Image computation is discussed in detail in Section 4.
     </paragraph>
     <section label="3.1">
      <section-title>
       Binary decision diagrams
      </section-title>
      <paragraph>
       Reduced Ordered Binary Decision Diagrams, BDDs for short, are the most popular data structure to represent the logical formulæ employed in symbolic search [8]. BDDs are decision diagrams in which each internal node decomposes the function according to the possible values of a variable, following a fixed variable ordering on every path from the root to a sink. This variable ordering allows the application of two reduction rules that eliminate any unnecessary or redundant nodes. Fig. 1 shows an example of two BDDs and their intersection. The definition of BDDs ensures their canonicity [8]: for any Boolean function {a mathematical formula}fS and variable ordering, there exists a unique BDD representing {a mathematical formula}fS. The application of reduction rules provides up to exponential memory gains in the number of variables when representing some functions with respect to the number of states it represents. Theoretical analyses on the complexity of representing those states in some planning domains and games have proved them to have polynomial upper bounds and exponential lower bounds on the number of nodes needed to represent different relevant sets of states on different domains [18], [19], [20].
      </paragraph>
      <paragraph>
       For certain kinds of functions there is an exponential gap between the complexity of describing them with one variable ordering or another [8], [21]. We follow Gamer's strategy to select a static ordering through domain analysis [15]. Gamer uses a local search optimization procedure that places variables related in the causal graph as close as possible. Recent research has shown empirically that Gamer's criteria is among the best known strategies to select static orderings and is significantly better than a random ordering though still arbitrarily far from optimal [22], [23]. A promising alternative is to perform dynamic variable reordering [24].
      </paragraph>
      <paragraph>
       Tight bounds can be proved on the complexity of BDD operations as long as all the involved BDDs share the same variable ordering [8]. Equivalence comparison and negation are performed in constant time. The apply operation of two BDDs {a mathematical formula}B1∘B2, used to compute the disjunction, conjunction (e.g., see Fig. 1) and other binary operations over two Boolean functions, has quadratic space and time complexity on the size of the BDDs, {a mathematical formula}|B1|×|B2| — the conjecture that the time complexity is linear on {a mathematical formula}|B1|+|B2|+|B1∘B2| was recently disproved [25], [26]. However, not all operations involved in symbolic search are polynomial. Disjunction or conjunction of several BDDs has exponential complexity on the number of BDDs. Finally, existential and universal quantification have exponential complexity in the number of quantified variables.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Symbolic bidirectional uniform-cost search
      </section-title>
      <paragraph>
       Symbolic search uses BDDs to represent and operate with set of states. As usual, symbolic uniform-cost search uses an open list that contains the states that have been reached but not expanded and a closed list that stores the states that have already been expanded. States are classified by the cost g with which they have been reached from the initial state of the search. Therefore, Open and Closed are lists of BDDs where {a mathematical formula}Openi and {a mathematical formula}Closedi represent the sets of states reached or expanded with {a mathematical formula}g=i, respectively. {a mathematical formula}Closed⁎:=⋁iClosedi is the set of all expanded states. At each step, the algorithm expands the set of states with lowest g-value in Open that are not yet in {a mathematical formula}Closed⁎, inserting them in Closed and all their successors in Open.
      </paragraph>
      <paragraph>
       Bidirectional uniform-cost search performs a forward and a backward uniform-cost searches. The forward search starts at the initial state, {a mathematical formula}I, and advances towards the goal states, {a mathematical formula}S⋆. The backward search performs regression from {a mathematical formula}S⋆ towards {a mathematical formula}I. The two searches are performed in an interleaved manner so that at each step the algorithm decides whether to continue the backward or forward search. Newly generated states are compared with the set of expanded states from the other search direction. In case of a match, a solution plan has been found, though it is not necessarily optimal. Rather, it is necessary to continue until the plan is proved to be optimal [27].
      </paragraph>
      <paragraph>
       The symbolic version of bidirectional uniform-cost search is detailed in Algorithm 1. The Step procedure performs a step in an uniform-cost search. If there are 0-cost operators, it first performs a breadth-first search only using 0-cost operators in order to retrieve all states with the same g-value (line 14). Then, the selected states are inserted into the closed list and expanded. The image operator (described in detail in Section 4) generates the successor states and they are inserted into Open.
      </paragraph>
      <paragraph>
       The UpdatePlan procedure checks whether a new better plan has been found over an expanded state (line 16) or a newly generated state (line 20). The check for generated states is not strictly needed, but it helps to decrease the cost of the best plan found so far, {a mathematical formula}wtotal, as soon as possible. This reduces the number of image computations by skipping those that cannot possibly lead to a better plan (line 18). Also, after checking whether a plan exists, states in {a mathematical formula}Closed⁎′ can be removed from succ since they have already been expanded in the opposite direction so that their optimal distance to the goal is known. Since the check ignores states in the Open list of the opposite frontier, UpdatePlan must be called again when states are expanded in order to ensure that no plan is missed. To check if a new plan has been found, UpdatePlan compares the newly expanded/generated states with the closed list of the opposite search. In case of a match, a new plan has been found. The cost of the new plan is the sum of the g-values of the intersected states in both searches (line 31). If this cost is smaller than the smallest cost found so far ({a mathematical formula}wtotal), then {a mathematical formula}wtotal is updated and the corresponding solution path π can be created. Solution reconstruction works differently than in explicit-state search, because symbolic search algorithms do not keep track of the parents of generated states. ConstructSolution retrieves a path from any state to the initial state or the goal using the closed list that contains all the expanded states classified by their g-value. The complete plan is the concatenation of a path from {a mathematical formula}I to a state s in the intersection of both frontiers, and a path from s to the goal. Both paths are retrieved with two calls to the ConstructSolution algorithm. The algorithm may stop when the sum of the minimum g values of generated states for the forward and backward searches is at least {a mathematical formula}wtotal, the cost of the cheapest solution path found so far. This stopping condition guarantees that the current plan, π, is optimal [27], [28].
      </paragraph>
      <paragraph>
       At each step, the algorithm decides whether to perform a forward or backward step. A typical criterion is Ira Pohl's cardinality principle that picks the direction with fewer frontier states [29]. In symbolic search, however, fewer states does not necessarily imply less search effort. Therefore, Gamer estimates the time needed to perform the next step in each direction and selects the one that is easier. This greedy policy works well under the assumption that, as the search progresses, sets of states are usually harder to represent. To compute the estimated time for step k, {a mathematical formula}tk, we take into account the time spent on the previous step, {a mathematical formula}tk−1, and the BDD sizes for the state set to be expanded in the next and the previous step, {a mathematical formula}sk and {a mathematical formula}sk−1, respectively. In general, we assume a linear relation between BDD size and image computation time. However, this might not work well at the beginning of the search, where {a mathematical formula}tk is too low and the BDD size ratio is too large. Thus, we estimate {a mathematical formula}tk as shown in Equation (1), using the time of the previous layer whenever it was below one second and the linear estimation for all the other cases.{a mathematical formula}
      </paragraph>
      <paragraph>
       This estimation, though not perfect, often balances the search effort made by both frontiers. However, in some domains the time may grow exponentially in the frontier size. To avoid exhausting all the available time in a single step, we interrupt any step if it takes more than twice the estimated time for the opposite direction. In that case, we re-estimate the time needed for the failed step to double the time spent before failure, so that if the planner retries it, its allotted time will be at least doubled.
      </paragraph>
     </section>
     <section label="3.3">
      Symbolic {a mathematical formula}A⁎ search
      <paragraph>
       Symbolic {a mathematical formula}A⁎ (alias {a mathematical formula}BDDA⁎) was first introduced by Edelkamp and Reffel [9] and integrated in the planning context by Edelkamp and Helmert [12] in the model checking integrated planning system MIPS. As usual with {a mathematical formula}A⁎, {a mathematical formula}BDDA⁎ expands states in ascending order of {a mathematical formula}f=g+h. The difference is that {a mathematical formula}BDDA⁎ groups sets of states with the same g and h-value into {a mathematical formula}g,h-buckets, and expands all states in a bucket at once (see Fig. 2a). The heuristic function in symbolic search is precomputed prior to the search and represented as a list of BDDs, heur, one per possible heuristic value. The heuristic evaluation is done with a conjunction: given a set of states S and the {a mathematical formula}heuri BDD, {a mathematical formula}S∧heuri corresponds to the subset of states that have a heuristic value equal to i.
      </paragraph>
      <paragraph>
       Different tie-breaking criteria can be used to select which node will be expanded next among those with minimum f-value. In explicit-state search nodes with larger g-value (and therefore smaller h-value) are preferred in order to expand a goal state as soon as possible, terminating the algorithm. In symbolic search, however, buckets with minimum g-value are preferred, i.e., the opposite criterion to that used in explicit-state search. This expansion order may be detrimental on the last f-diagonal (e.g., buckets 6–10 in Fig. 2a) because all the states with {a mathematical formula}f=f⁎ are expanded. The advantage is that this avoids re-expanding any bucket because once a {a mathematical formula}g,h-bucket has been expanded, no new states with such {a mathematical formula}g,h-values will be generated. For example, in Fig. 2a, after having expanded buckets 1 and 2, buckets 3 and 4 have the same f-value. When bucket 3 is expanded, new states may be inserted in bucket 4, so if bucket 4 is expanded first, then it will be re-expanded twice.
      </paragraph>
      <paragraph>
       Multiple variants of {a mathematical formula}BDDA⁎ exist across the literature, varying the representation of state sets involved in the search. {a mathematical formula}ADDA⁎[30] is an alternative implementation with ADDs, while Set {a mathematical formula}A⁎[31] refines the partitioning in a matrix representation of g- and h-buckets in the open list. Gamer uses the Matrix {a mathematical formula}BDDA⁎ implementation [32]. In this article, we use List {a mathematical formula}BDDA⁎, which is a variant of Matrix {a mathematical formula}BDDA⁎ in which the open list buckets are only distinguished by their g-value [33], [34]. Fig. 2b shows how List {a mathematical formula}BDDA⁎ expands the states in exactly the same way as Matrix {a mathematical formula}BDDA⁎. The difference is that all the buckets in the same row of the {a mathematical formula}g,h-matrix are represented by a single BDD. The heuristic evaluation (conjunction of the sets of states with each heuristic BDD) is deferred until a set of states is going to be expanded, avoiding to compute the precise h value of states that will never be expanded anyway. The advantage of List {a mathematical formula}BDDA⁎ is that it reduces the number of conjunctions with the heuristic BDDs, having a positive impact specially when there are many different heuristic values. For example, consider states in the first row of Fig. 2 with {a mathematical formula}g=1. In Fig. 2a, in order to know in which bucket the states have to be inserted, one conjunction is needed for every possible value of h. In Fig. 2b only one conjunction is needed in order to extract bucket 9.
      </paragraph>
      <paragraph>
       To inform {a mathematical formula}BDDA⁎, Gamer uses symbolic partial pattern databases. Pattern databases (PDBs) map the original state space to a smaller abstract state space. PDBs use backward uniform-cost search to precompute the optimal solution cost from each abstract state to the set of abstract goal states, and use it as an estimation for the original problem [35], [36]. In the planning literature, this abstract problem is usually defined by the projection of the planning task over a subset of variables [37]. A partial PDB[38] is a PDB that is not fully computed, but rather its calculation is stopped at some point, e.g., when the pre-defined allotted time has expired. If all abstract states with a solution cost of d or less have been expanded, then {a mathematical formula}d+1 is an admissible estimation for all non-expanded states. Symbolic PDBs[39] are PDBs constructed with symbolic backward uniform-cost search. Gamer uses an automatic pattern selection procedure to generate a well-informed PDB. This is similar to the one proposed for explicit-search planners [40], though instead of constructing a collection of PDBs, it aims to construct a single bigger PDB. Details can be found in the literature [15], [32].
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Image computation
     </section-title>
     <paragraph>
      As introduced in Section 3, the image operation is used to compute the set of successor states. This is often the most time-consuming process in symbolic search, so it is important to perform it as efficiently as possible. In this section we study the related work on image computation and propose three different image computation methods for symbolic search in planning. Our first method, {a mathematical formula}TR1+, avoids using the set of auxiliary variables {a mathematical formula}x′ when using a TR per operator. Then, we present the {a mathematical formula}CT method whose goal is to improve how the operator preconditions are matched. Finally, we discuss the {a mathematical formula}UT method, other disjunctive partitioning criteria to represent the TRs.
     </paragraph>
     <section label="4.1">
      <section-title>
       Basics of image computation
      </section-title>
      <paragraph>
       In symbolic search planning, operators are described in the transition relations (TRs). A TR is a relation between predecessor and successor states, i.e., it represents all the pairs of states {a mathematical formula}〈s,s′〉 such that {a mathematical formula}s′=o(s) for an operator o represented by the TR. Thus, if sets of states are described as functions over the set of variables x, TRs also use a set of auxiliary variables, {a mathematical formula}x′, to represent successor states.{sup:2} In the BDD variable ordering variables from x and {a mathematical formula}x′ are alternated ({a mathematical formula}x1,x1′,x2,x2′,…,xn,xn′) as proposed, e.g., by Burch et al. [41]. This ordering is logical because {a mathematical formula}xi and {a mathematical formula}xi′ are closely related since for any operator o with {a mathematical formula}vi∉Veff(o), {a mathematical formula}xi′ is assigned the value of {a mathematical formula}xi.
      </paragraph>
      <paragraph>
       The image operation of a set of states with respect to a given transition relation can be decomposed into basic logical operations over BDDs: {a mathematical formula}image(S,T):=(∃x(S∧T))[x′/x]. The conjunction {a mathematical formula}S∧T corresponds tow all pairs of states {a mathematical formula}〈s,s′〉 such that {a mathematical formula}s∈S and {a mathematical formula}s′=o(s) for an operator o represented by T. Then, the existential quantification ignores predecessor states and the variable swapping, {a mathematical formula}[x′/x], represents the resulting states {a mathematical formula}s′ with the standard set of variables x. In practice, {a mathematical formula}∃x(S∧T) is a single BDD operation, the so-called relational product, which is often implemented in a more efficient way than the sequential application of conjunction and quantification [41]. The related pre-image operation, used to perform regression, is decomposed into similar operations. In this case, variables are swapped first and the existential quantification is performed over {a mathematical formula}x′ instead of x. {a mathematical formula}pre-image(S,T):=∃x′((S[x/x′])∧T). Even though we focus our discussion in this section on image computation, the same conclusions can be obtained about pre-image computation for all purposes.
      </paragraph>
      <paragraph>
       The representation of the TRs plays a key role in image computation. As we must distinguish the cost of each transition, different TRs have to be used for each operator cost. The monolithic representation uses a single TR, {a mathematical formula}Tc, to represent all operators of cost c. However, this is often unfeasible because, in the worst case, a TR uses exponential memory in the number of operators that it represents. A traditional solution is to use a conjunctive or disjunctive partitioning of the transition relations [42]. Instead of having a single {a mathematical formula}Tc that represents all operators with cost c, we have a list of TRs {a mathematical formula}{Tc,1,…,Tc,k} such that {a mathematical formula}Tc=⋁i=1kTc,0 (disjunctive partitioning) or {a mathematical formula}Tc=⋀i=1kTc,0 (conjunctive partitioning). Then, the images with respect to the individual TRs can be combined to obtain the same result, i.e., {a mathematical formula}image(S,Tc)=⋁i=1kimage(S,Tc,i) or {a mathematical formula}image(S,Tc)=⋀i=1kimage(S,Tc,i), respectively.
      </paragraph>
      <paragraph>
       Whether it is better to use a conjunctive or a disjunctive partitioning depends on the characteristics of the problem being modeled. In symbolic model checking, a conjunctive partitioning is often better because most studied systems are described in terms of rules that are applied in parallel. For this reason, research has generally been focused on the problem of scheduling the conjunction and quantification operations during image computation [43], [44], with a few works combining both types of partitioning [45]. In planning, though, disjunctive partitioning is more natural, since planning operators are applied sequentially. Jensen et al. [46], [13] first proposed the partitioning of TRs so that each partition contains operators that change the f-value of the states by the same amount. The precomputation of Δf was obtained from the cost of the operators of the problem and the increase or decrease of the heuristic value. However, this method is limited to problems and heuristics where Δh can be precomputed from the problem description.
      </paragraph>
      <paragraph>
       Due to the intractability of using a single {a mathematical formula}Tc, Gamer uses a TR per operator. Given an operator {a mathematical formula}o=〈(pre(o),eff(o),w(o))〉, its associated transition relation {a mathematical formula}To is obtained as the conjunction of its literals, describing the preconditions with variables from x and the effects with variables from {a mathematical formula}x′. Any variable not modified by o must also be explicitly encoded so that it keeps its value after the application of o. This is encoded in the TR as a bi-implication of the form {a mathematical formula}biimp(xi,xi′)=(xi∧xi′)∨(x‾i∧x‾i′). Thus, if we assume that the function {a mathematical formula}fBDD(v,val,x) returns the BDD that corresponds to the fact {a mathematical formula}〈v,val〉 represented with the set of variables x, the TR of a single operator is computed as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       The size of a TR representing a single operator is linear in the number of variables of the planning task. First, the preconditions and effects are simple conjunctions of facts, which require a BDD whose size is linear in the number of relevant variables. Second, each bi-implication is represented by just three BDD nodes as long as the variables from x and {a mathematical formula}x′ that correspond to the same variable {a mathematical formula}v∈V are adjacent in the variable ordering, as they are in our ordering schema. Finally, as all the bi-implication, precondition and effect BDDs are independent, {a mathematical formula}To is just a concatenation of these BDDs.
      </paragraph>
      <paragraph>
       When a disjunctive partitioning is used, the image is computed in two steps. First, the image is computed for each TR, and then the results of TRs associated to operators of the same cost, c, are aggregated computing their disjunction {a mathematical formula}⋁i=1kimage(S,Tc,i). This is not a single operation, but rather {a mathematical formula}k−1 disjunctions of two BDDs at a time. Even though the result will always be the same, the order in which the individual BDDs are merged has an impact on the performance of image computation. The computational cost of most BDD operations critically depends on the BDD size, so is important to keep the intermediate BDDs as small as possible. Gamer uses an iterative algorithm. Given a list of BDDs to be aggregated, {a mathematical formula}S1,…,Sk, it aggregates pairs of BDDs {a mathematical formula}(S1∨S2,…,Sk−1∨Sk) and repeats the process until only one BDD remains. To model the order in which disjunctions are applied, we represent them in a binary tree, called disjunction tree. Each internal node applies the disjunction of the result of its left and right branches. Each leaf node is associated with an operator, so that it represents the image result with respect to that operator's TR. Gamer's procedure corresponds to a balanced tree like the one in Fig. 3.
      </paragraph>
     </section>
     <section label="4.2">
      Image without auxiliary variables ({a mathematical formula}TR1+)
      <paragraph>
       Our first method for image computation, {a mathematical formula}TR1+, leverages the particular structure of planning operators for faster image computation when a TR {a mathematical formula}To encodes a single operator o. First, as all variables not appearing in the effects retain their values, the existential quantification and variable swapping only need to be applied over variables modified by {a mathematical formula}eff(o), which we call {a mathematical formula}xo. Therefore, the bi-implication term may be omitted from {a mathematical formula}To, using instead {a mathematical formula}To˜, which is defined as: {a mathematical formula}To˜=⋀〈v,val〉∈pre(o)fBDD(v,val,x)∧⋀〈v,val〉∈eff(o)fBDD(v,val,x′). With this encoding, the image is computed as {a mathematical formula}image(S,To)=(∃xo(S∧To))[xo′/xo].
      </paragraph>
      <paragraph>
       Moreover, since according to the semantics of a planning operator the effect does not depend on the predecessor state, {a mathematical formula}To can be divided into a precondition {a mathematical formula}Topre over x and an effect {a mathematical formula}Toeff over {a mathematical formula}x′ such that {a mathematical formula}To=Topre∧Toeff. In fact, once preconditions and effects are encoded separately there is no need to relate the sets x and {a mathematical formula}x′ anymore. Thus, the TRs can be represented using only the set of predecessor variables x. This way the variables representing the successor states {a mathematical formula}x′ as well as the swap operation are no longer needed, reducing the size of intermediate BDDs and speeding up image computation. The new image operation is:{a mathematical formula}
      </paragraph>
     </section>
     <section label="4.3">
      Conjunction trees ({a mathematical formula}CT)
      <paragraph>
       When considering multiple TRs it is advisable to avoid checking their applicability individually. This is especially important when {a mathematical formula}TR1+ is used, as the number of grounded operators can become very large in some planning problems. Some explicit-state planners employ speed-up techniques to filter non-applicable operators efficiently, such as the successor generator used by Fast Downward [47]. In Fast Downward the operators are organized in a decision tree similar to the structures used by RETE networks to detect the triggering of a rule [48]. Fig. 4 shows our conjunction tree, which resembles these decision trees in which each leaf node contains a set of operators that have the same preconditions. Every internal node is associated with a variable {a mathematical formula}v∈V and has an edge for every value i of v and an additional “don't care” edge. An operator {a mathematical formula}o∈O is propagated down the i edge if and only if {a mathematical formula}〈v=i〉∈pre(o) and down the “don't care” edge if {a mathematical formula}v∉Vpre(o). To compute the successors of a state s, the tree is traversed, omitting branches labeled with unsatisfied preconditions and always following “don't care” edges. An operator is applicable in s if and only if it is in a leaf reached by that traversal.
      </paragraph>
      <paragraph>
       This approach carries over to BDDs as follows. As all the variables are binary, each internal node only has three children {a mathematical formula}c0, {a mathematical formula}c1 and {a mathematical formula}c⋆, dividing the operators into three sets: those that require {a mathematical formula}v‾ as a precondition, those that require v as a precondition and those whose applicability does not depend on v at all. Applicability of operators is different for progression and regression search, so different conjunction trees are needed. Conjunction trees for forward search take into account the preconditions of operators. Conjunction trees for backward search take into account the preconditions of the inverted operators, i.e., their effects and prevail conditions. In the presence of zero-cost operators, all algorithms studied in Section 3 apply breadth-first search using only the subset of zero-cost operators until a fix-point is reached. Since regular and zero-cost operators are applied over different sets of states, two different conjunction trees are needed: one with the zero-cost operators and another one with the rest. Therefore, in order to apply bidirectional search in domains with zero-cost operators up to four different conjunction trees are needed: fw-zero, fw-cost, bw-zero, and bw-cost.
      </paragraph>
      <paragraph>
       In symbolic search the operators are not applied over a single state but rather over sets of states. Nevertheless, operators only need to be applied over states that satisfy the corresponding conditions. We take advantage of this by precomputing the subset of states relevant to a given TR prior to the image operation. This is done by splitting the original set of states into subsets as the successor tree is traversed. This way, the subset on which a TR, {a mathematical formula}To is applied once a leaf node is reached is the subset of states that satisfy {a mathematical formula}pre(o). We call this method {a mathematical formula}CT.
      </paragraph>
      <paragraph>
       Algorithm 2 shows how to compute the image of a BDD using {a mathematical formula}CT. It takes as input a set of states S and the root node of the conjunction tree and returns the sets of successor states, associated with the cost of the operators that generated them. At every inner node one recursive call is made for each child node, applying the corresponding conjunction between the set of states S and the precondition {a mathematical formula}v∈V associated with the node. Moreover, if there are no states satisfying the preconditions of a branch, it is not traversed. When a leaf node is reached, the image is computed with respect to {a mathematical formula}S′=S∧pre(o) so here we should only account for the effects. Thus, in the leaf nodes the image is computed as {a mathematical formula}imageCT(S′,To)=(∃xoS′)∧Toeff.
      </paragraph>
      <paragraph>
       {a mathematical formula}CT has several advantages over the baseline approach: first, if S does not contain any state matching the conditions of a branch of the tree, all the operators regarding that branch are ignored, which reduces the number of individual image operations that are needed. Second, if several operators share the same preconditions, the conjunction of S with that set of preconditions is computed only once. Finally, the conjunction with the preconditions is done with BDDs whose size usually decreases as we go deeper in the conjunction tree, so the time required to do the individual conjunctions will be shorter.
      </paragraph>
      <paragraph>
       An overhead may occur due to the computation and storage of intermediate BDDs in memory, though. The conjunction with a precondition should only be used when the benefits compensate the overhead, i.e., when a precondition is shared between many operators. Thus, {a mathematical formula}CT can be parameterized with a parameter min operators conjunction, so that the intermediate conjunction with a partial precondition is only computed when needed for at least that number of operators. If the number of operators that should go down some edge is less than min operators conjunction, they are propagated down the don't care branch {a mathematical formula}c⋆ instead, and marked so that we know that not all their preconditions have been checked. When computing the image of marked operators, the conjunction with their preconditions is needed. When min operators conjunction is set to 1 we have the full tree strategy and when it is set to ∞ the conjunction tree consists of only one leaf node containing all the operators, which is equivalent to not having a tree at all. Setting the parameter to intermediate values produces intermediate strategies.
      </paragraph>
      <paragraph>
       The performance of {a mathematical formula}CT may depend on the order in which it checks the conditions. We check the preconditions in the same ordering as in the BDD representation. This aims at making the conjunctions as simple as possible, since a conjunction with the first variable of a BDD is trivial. A comparison with different heuristic criteria showed that this does not have a large impact and our simple criterion works well in practice [34].
      </paragraph>
     </section>
     <section label="4.4">
      Unions of transition relations ({a mathematical formula}UT)
      <paragraph>
       Even though having a monolithic TR per operator cost is often unfeasible due to its size, computing the union of TRs of only a subset of operators may be beneficial. The union of a set of TRs {a mathematical formula}T is a new TR, {a mathematical formula}Union(T), such that the image with respect to {a mathematical formula}Union(T) is equivalent to the disjunction of the images of the individual TRs in {a mathematical formula}T, {a mathematical formula}image(S,Union(T))=⋁T∈Timage(S,T). {a mathematical formula}Union(T) cannot be represented with separated preconditions and effects as described in Section 4.2 though, as the bi-implications are needed to ensure that the generated successors are correct. However, not all the bi-implications need to be explicitly included: a TR {a mathematical formula}To∈T must include a bi-implication related to some variables {a mathematical formula}xi only if {a mathematical formula}xi is modified by some other {a mathematical formula}To′∈T (and not by {a mathematical formula}To). Thus, {a mathematical formula}Union(T) may be computed as shown in Equation (2), where {a mathematical formula}XT and {a mathematical formula}XT are the sets of variables in the effects of operators represented by the transition relation T and any transition relation in the set {a mathematical formula}T, respectively. The image is computed with the standard method presented in Section 4.1.{a mathematical formula}
      </paragraph>
      <paragraph>
       A critical decision is which operators should be joined together in a single TR while ensuring that the resulting {a mathematical formula}Union(T) is tractable to compute. Algorithm 3 is a simple algorithm for creating a disjunctive partitioning starting from the set of one TR per each operator. The algorithm aggregates TRs using equation (2) until a monolithic TR is created or the time and memory (in terms of BDD nodes) bounds are exceeded. Recall that, as the cost of reaching a state must be preserved, only operators with the same cost w may be aggregated. Therefore, we call the algorithm once per different cost, i, with {a mathematical formula}Ti={To|o∈O,w(o)=i}.
      </paragraph>
      <paragraph>
       The most important aspect of the algorithm is the selection of the TRs to be aggregated in line 3. This is important, not only because it may impact the algorithm performance, but also because, if a single {a mathematical formula}Union(Tc) cannot be computed for some cost c, it is important to have a set of TRs as balanced in size as possible. As we impose a limit on the maximum size of a TR, balancing the size of the TRs will often lead to a better partitioning with a lower number of TRs. We define three strategies, based on different criteria, to select which TRs should be unified: {a mathematical formula}UTDT, {a mathematical formula}UTSM and {a mathematical formula}UTCT.
      </paragraph>
      <list>
       <list-item label="•">
        The {a mathematical formula}UTDT strategy employs the balanced disjunction tree shown in Fig. 3. Instead of computing the union of the successors generated with the TRs at the leaf nodes, the actual TRs are merged. TRs that share the same parent node are merged in a bottom-up fashion until maxNodes is exceeded in that branch or the algorithm runs out of time.
       </list-item>
       <list-item label="•">
        The {a mathematical formula}UTSM strategy aggregates the two smallest TRs at every step. With {a mathematical formula}UTDT, if a small TR is merged with another TR whose size is close to maxNodes and the union of both TRs is bigger than maxNodes, then the first TR will not be considered for merging anymore. If this occurs, it may happen that the set of final TRs contains individual TRs that could have been merged without exceeding maxNodes.
       </list-item>
       <list-item label="•">
        The {a mathematical formula}UTCT strategy aims to leverage the synergy between operators, using the conjunction tree described in Section 4.3. The intuition is that the union of two TRs whose operators have similar preconditions and effects tends to be more succinct. {a mathematical formula}UTCT aggregates TRs of operators present in the same branch of the conjunction tree just like {a mathematical formula}UTDT does. This ensures that there will be some degree of similarity between the TRs because at least one subset of the preconditions will be shared between all the operators. Also, this allows us to use {a mathematical formula}CT in combination with a disjunctive partitioning in a seamless way: TRs are merged up the tree from the leaves until Algorithm 3 finishes, in which case the merged TRs will be the new leaf nodes of the conjunction tree. This keeps the property of {a mathematical formula}CT that only states that can be expanded by some operator are propagated down the tree even if the TRs of the individual operators are merged.
       </list-item>
      </list>
     </section>
    </section>
    <section label="5">
     <section-title>
      State-invariant constraints in symbolic search
     </section-title>
     <paragraph>
      The most successful uses of symbolic search in planning so far have been bidirectional blind search and symbolic abstraction heuristics [9], [49]. A common point of these methods is that they require performing regression on the goals of the problem. Regression in planning is considered to be less robust than progression, mainly due to the existence of numerous spurious states in regression. Spurious states are defined as states that are not reachable from {a mathematical formula}s0[7], although other definitions exist [50]. To alleviate the impact of spurious states, constraints obtained from state invariants of the problem have been employed by explicit-state planners [7], [51], [6].
     </paragraph>
     <paragraph>
      In this section we consider how to exploit state-invariant constraints in a symbolic setting. We consider two different approaches: encoding the constraints in a separate BDD ({a mathematical formula}MBDD) or encoding them directly in the transition relation ( e-del). We conclude the section discussing the how constraints can be used in symbolic abstractions to generate more informed heuristics.
     </paragraph>
     <section label="5.1">
      <section-title>
       Background on state-invariant constraints
      </section-title>
      <paragraph>
       A state-invariant constraint is a logical formula that must hold in every state that can be part of a plan from the initial state to the goal.{sup:3}
      </paragraph>
      <paragraph label="Definition 1">
       State-invariant constraintLet c be a logical formula and let {a mathematical formula}Sfw,Sbw⊆S be the set of states reachable from the initial state and from which a goal state can be reached, respectively. Then, c is a reachability constraint iff for any s, {a mathematical formula}s⊭c⇒s∉Sfw. c is a relevance constraint iff for any s, {a mathematical formula}s⊭c⇒s∉Sfw. c is a state-invariant constraint iff for any s, {a mathematical formula}s⊭c⇒s∉Sfw∩Sbw. Any reachability or relevance constraint is a state-invariant constraint, though the opposite does not hold in general.
      </paragraph>
      <paragraph>
       A state is valid if and only if satisfies all the constraints. Invalid states that violate a constraint can be pruned during the search since they are either unreachable or dead ends. By definition, reachability constraints cannot possibly prune any state in forward search. Similarly, relevance constraints are not useful in backward search. An operator is valid if it is consistent with the constraints, i.e., exist s, {a mathematical formula}s′ s.t. {a mathematical formula}o(s)=s and {a mathematical formula}s,s′⊨c. Invalid operators are removed in a preprocessing step so we assume all operators to be valid.
      </paragraph>
      <paragraph>
       We consider two types of state-invariant constraints: mutexes and “exactly-1” invariant groups. Mutexes are pairs of mutually exclusive facts.{sup:4} A pair of facts {a mathematical formula}M=〈f1,f2〉 is a mutex if there is no state s that may belong to a solution path such that {a mathematical formula}M⊆s. Invariant groups are invariants defined over a set of facts. An “at-most-1” invariant group is a set {a mathematical formula}Ma={f0,f1,…,fn} such that {a mathematical formula}∀pm∈{〈fi,fj〉|fi,fj∈Ma and fi≠fj}{a mathematical formula}pm is mutex. Thus, a priori these invariant groups do not offer more information than taking into account individual binary mutexes. An “exactly-1” invariant group is an “at-most-1” invariant group with an additional constraint: at least one of the facts in the set must hold in any state.
      </paragraph>
      <paragraph>
       State invariants are usually computed prior to the search using a variety of methods. Monotonicity analysis, which is generally employed to generate a finite-domain representation of the problem [53], detects reachability mutexes and “exactly-1” invariant groups. Another common method to find mutexes is the {a mathematical formula}h2 heuristic [54]. {a mathematical formula}h2 performs a reachability analysis in {a mathematical formula}P2[55], a version of the original problem in which the atoms are actually pairs of facts. Every pair of facts that is unreachable in {a mathematical formula}P2 is a mutex. {a mathematical formula}h2 can be computed backwards too in order to find relevance mutex constraints [56], [57]. In this article we use the invariants detected by the monotonicity analysis and the preprocessing algorithm presented by Alcázar and Torralba [57], which iteratively computes {a mathematical formula}h2 in forward and backward direction in order to discover reachability and relevance mutexes.
      </paragraph>
      <paragraph>
       In the example of Fig. 5, there are reachability and relevance mutexes. An example of reachability mutex is that at time 1 the truck cannot be at location C. It is impossible since the truck is at location A at time 0 so at location 1 it can only be at A or B. Similarly, an example of relevance mutex is that, at time 3, the package cannot be at B, since there would be no remaining time to deliver the package.
      </paragraph>
     </section>
     <section label="5.2">
      Encoding state invariants as BDDs ({a mathematical formula}MBDD)
      <paragraph>
       Pruning spurious states has been considered essential for backward search since long ago [7]. The use of mutexes in explicit-state search is straightforward: simply prune every (partial) state s such that facts {a mathematical formula}fi,fj∈s are mutex. Despite the impact of state invariants in explicit-state regression, they have not been employed in symbolic search. Although it is obvious that a per state application of mutexes in symbolic search is not practical, there are alternatives. In particular, we propose creating a BDD that represents in a succinct way all the states that are valid according to the state invariants. This BDD, that we call the constraint BDD (cBDD), can be used to discard all the invalid states that have been generated during the search.
      </paragraph>
      <paragraph>
       The cBDD is created in the following way. Every binary mutex is a pair of facts {a mathematical formula}〈fi,fj〉 ({a mathematical formula}fi≠fj) such that if {a mathematical formula}fi,fj∈s, then state s is invalid. This corresponds to the logical formula {a mathematical formula}¬fi∧¬fj. Constraints derived from “exactly-1” invariant groups are encoded in a similar way. Given an “exactly-1” invariant group {a mathematical formula}θ={f1,…,fk}, two types of constraints may be deduced: first, the set of all the mutexes of the form {a mathematical formula}fi∧fj if {a mathematical formula}fi≠fj; second, the fact that at least one fact {a mathematical formula}fi∈θ must be true in every valid state. The first constraint overlaps with the mutex constraints, so it is not necessary to consider it again. The latter however can be encoded as an additional “at-least-1” constraint of the form {a mathematical formula}(f1∨f2∨⋯∨fk).
      </paragraph>
      <paragraph>
       All constraints must hold in valid states so cBDD results from the conjunction of all the constraints. Formally, if M is the set of binary mutexes found by {a mathematical formula}h2 and {a mathematical formula}Ig the set “exactly-1” invariant groups:{a mathematical formula}
      </paragraph>
      <paragraph>
       Even though each mutex and “at-least-1” constraint is efficiently representable with only one node per fact, the size of cBDD is exponential in the number of encoded constraints in the worst case [20]. To ensure that we can represent cBDD, we use a conjunctive partitioning, dividing cBDD into k BDDs: {a mathematical formula}cBDD=cBDD1∧cBDD2∧⋯∧cBDDk.
      </paragraph>
      <paragraph>
       To obtain an efficient partitioning, we follow Algorithm 3, Aggregate, described on page 61 that computes a partitioning of a set of BDDs. In this case, the algorithm is initialized with the BDDs of individual constraints and Union corresponds to the conjunction of the individual BDDs. These are aggregated until the remaining BDDs are larger than a given threshold. The order in which these conjunctions are applied affects the efficiency of the procedure and the number of BDDs used to represent cBDD. To optimize it, we compute a BDD for each variable {a mathematical formula}vi∈V that describes all mutexes relative to {a mathematical formula}vi and any {a mathematical formula}vj with {a mathematical formula}j&gt;i and use those BDDs to initialize Algorithm 3.
      </paragraph>
      <paragraph>
       Invalid states are pruned by computing the difference {a mathematical formula}Sg∖¬cBDD of a newly generated set of states {a mathematical formula}Sg with the set of invalid states, ¬cBDD. In terms of BDD manipulation this is simply {a mathematical formula}Sg∧cBDD. Extending the operation to the case where we have more than one cBDD is straightforward: {a mathematical formula}Sg∧cBDD1∧⋯∧cBDDk. In the rest of the section we assume that cBDD is represented in a single BDD, without loss of generality.
      </paragraph>
      <paragraph>
       An important remark about the usefulness of pruning invalid states is necessary, though. In general, the size of a BDD is not proportional to the number of states it represents. This means that there is no guarantee that pruning invalid states will help in symbolic search, as opposed to the explicit-state case. Indeed, pruning mutexes may cause an exponential blow-up on the BDD representation. There exist alternatives to the computation of the difference {a mathematical formula}Sg∖cBDD such as BDD “don't care” minimization methods [58], [59], [60]. However, an experimental analysis showed that in practice they are consistently worse than the approach presented in this article [34].
      </paragraph>
      <paragraph>
       Finally, a clarification about the source of the constraints is needed. As described in Section 5.1, there are reachability and relevance constraints, which can be violated only by backward and forward search, respectively. Consequently, it is not useful to encode both types of constraints in the same BDD, as they should be exploited only in the appropriate direction. Hence, we use two cBDDs, {a mathematical formula}cBDDfw for forward and {a mathematical formula}cBDDbw for backward search.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Encoding constraints in the TRs
      </section-title>
      <paragraph>
       Encoding the state invariants in the cBDD allows the search to prune invalid states after they are generated. In partial-state regression, e-deletion[61] modifies the definition of applicability in regression [6] in order to avoid the generation of spurious partial states. We apply the same idea in symbolic search, encoding the state-invariant constraints in the TRs to avoid the generation of invalid states. Our encoding differs from previous work because we eliminate all invalid states from the search. In partial-state regression this is not possible because partial states implicitly contain states that violate invariants related to undefined variables.
      </paragraph>
      <paragraph>
       We take as input the TR of an operator and a set of reachability and relevance constraints to define a new TR that does not generate invalid states. However, not all constraints need to be encoded in every operator. Replicating all the constraints in the TRs is possible, but may lead to a great degree of redundancy. We thus identify which constraints must be encoded in each operator in order to guarantee that no invalid state is generated. By assuming that the set of states to be expanded does not contain invalid states, we can safely consider only a subset of constraints in each TR, still avoiding the generation of invalid states. We say that a constraint is relevant for an operator if it may become violated after its application.
      </paragraph>
      <paragraph label="Definition 2">
       (Relevant constraint) A reachability constraint c is relevant in regression for an operator o iff exists s s.t. {a mathematical formula}o(s)⊨c and {a mathematical formula}s⊭c. A relevance constraint c is relevant in progression for an operator o iff exists s s.t. {a mathematical formula}s⊨c and o(s)⊭c.
      </paragraph>
      <paragraph>
       As an example, consider Fig. 5 on page 62. {a mathematical formula}¬(vt=1∧vp=A) is relevant in progression for drive{a mathematical formula}(A,B,0), which drives the truck from A to B at time step 0, because if we apply the operator in the initial state, {a mathematical formula}〈vp=A,vT=A,vt=0〉, we reach a state in which {a mathematical formula}vp=A and {a mathematical formula}vt=1. On the other hand, {a mathematical formula}¬(vt=2∧vp=A) is irrelevant for drive{a mathematical formula}(A,B,0) because this operator does not produce either {a mathematical formula}vt=2 or {a mathematical formula}vp=A so the successor state cannot violate the constraint unless the predecessor does.
      </paragraph>
      <paragraph>
       Reachability constraints are encoded as additional preconditions to avoid the generation of invalid states in regression. This does not affect the applicability of the operator in forward search, since any reachable state necessarily satisfies these constraints. Relevance constraints are encoded in a similar way, as postconditions that must hold after applying the operator.
      </paragraph>
      <paragraph label="Definition 3">
       (Constrained operator) Let {a mathematical formula}To be the TR of {a mathematical formula}o∈O and let {a mathematical formula}cBDDbwo[x] and {a mathematical formula}cBDDfwo[x′] be BDDs representing the reachability and relevance constraints relevant for o in terms of variables x and {a mathematical formula}x′. Then the constrained TR is {a mathematical formula}Toc=To∧cBDDbwo[x]∧cBDDfwo[x′].
      </paragraph>
      <paragraph label="Proof">
       Let{a mathematical formula}S⊆¬cBDDbe a state set that does not contain states detected as invalid,{a mathematical formula}o∈Obe an operator, and{a mathematical formula}Tocbe the constrained TR derived from o. Let{a mathematical formula}Sp,{a mathematical formula}Srbe the resulting state sets from the image and pre-image of S with{a mathematical formula}Toc, respectively. Then{a mathematical formula}Sp,Sr⊆cBDD, i.e., they do not contain states that can be detected as invalid.Let c be a constraint, and {a mathematical formula}s′ a state that violates c. Suppose that {a mathematical formula}s′∈Sr. As c was satisfied by every {a mathematical formula}s∈S, c is relevant for o in regression. Then {a mathematical formula}c∈pre(oc), so {a mathematical formula}oc is not applicable on {a mathematical formula}s′, reaching contradiction.Suppose that {a mathematical formula}s′∈Sp. As c was satisfied by every {a mathematical formula}s∈S, c is relevant for o in progression. Then c is a postcondition of {a mathematical formula}oc, so {a mathematical formula}s′≠oc(s) for all {a mathematical formula}s∈S, reaching contradiction. □
      </paragraph>
      <paragraph>
       Using {a mathematical formula}Toc with relevant constraints suffices to guarantee that the successor set does not contain invalid states as long as the source set does not either. In progression this is always the case, as {a mathematical formula}I is single valid state in any solvable instance. In regression, we compute the difference {a mathematical formula}S⋆∖cBDD to remove all invalid states from the goal description. The advantage is that this difference is only computed once, before starting the search. This avoids further overhead in using cBDD, which can be discarded to free memory.
      </paragraph>
      <paragraph>
       Relevant constraints in progression.Proposition 1 shows the sufficient and necessary conditions for mutexes to be relevant in progression. In our case “at-least-1” groups are not relevant in progression, since we only infer them with a forward reachability analysis.
      </paragraph>
      <paragraph label="Proposition 1">
       (Relevant mutex in progression) Let{a mathematical formula}M=¬(f1∧f2)be a relevance mutex and{a mathematical formula}o∈Obe a valid operator. Then M is relevant for o in progression if and only if:
      </paragraph>
      <list>
       <list-item label="1.">
        M is not implied by{a mathematical formula}prev(o)∪eff(o).
       </list-item>
       <list-item label="2.">
        For some fact{a mathematical formula}fi∈{f1,f2},{a mathematical formula}fi∈eff(o).
       </list-item>
      </list>
      <paragraph label="Proof">
       Assume WLOG that {a mathematical formula}fi=f1. To prove the if part of the statement, let s be any state s.t. {a mathematical formula}f1∉s, {a mathematical formula}f2∈s and all other variables have values compatible with {a mathematical formula}pre(o). Such state exists because otherwise, either o is not valid (e.g., if {a mathematical formula}f2∈eff(o)) or condition (1) does not hold contradicting the premises. Then s satisfies the three statements:
       <list>
        {a mathematical formula}s⊨M: because {a mathematical formula}f1∉s.o is applicable in s: By the construction of s. {a mathematical formula}f1∉pre(o) because {a mathematical formula}f1∈eff(o). If {a mathematical formula}f2∈eff(o), then {a mathematical formula}f2∉pre(o). If {a mathematical formula}f2∉eff(o), then {a mathematical formula}f2 is compatible with {a mathematical formula}prev(o) by condition (1).{a mathematical formula}o(s)⊭M: {a mathematical formula}f1∈eff(o) so {a mathematical formula}f1∈o(s). {a mathematical formula}f2∈o(s) because either {a mathematical formula}f2∈eff(o) or {a mathematical formula}f2∈s. Condition (1) ensures that {a mathematical formula}f2 is not deleted by o.To prove the
       </list>
       <paragraph>
        only if case, note that if (1) does not hold, then there does not exist s such that {a mathematical formula}o(s)⊭M, so M is not relevant for o in progression. We may deduce condition (2) assuming that M is relevant for o in progression, that is, M is satisfied in s but not in {a mathematical formula}o(s). Then, for some fact {a mathematical formula}f1=〈υ1,x〉, {a mathematical formula}f1∉s, {a mathematical formula}f1∈o(s). Therefore, {a mathematical formula}s[υ1]≠o(s)[υ1], which implies {a mathematical formula}v1∈Veff(o). As {a mathematical formula}o(s) is the result of applying o in s, {a mathematical formula}eff(o)[v1]=x and {a mathematical formula}f1∈eff(o). □
       </paragraph>
      </paragraph>
      <paragraph>
       Relevant constraints in regression. Next, Proposition 2, Proposition 3 show the sufficient and necessary conditions for mutexes and “at-least-1” groups to be relevant in regression. Essentially the relevant constraints are those that contain facts that may be added or removed when o is applied in regression.
      </paragraph>
      <paragraph label="Proposition 2">
       (Relevant mutex in regression) Let{a mathematical formula}M=¬(f1∧f2)be a reachability mutex and{a mathematical formula}o∈Obe a valid operator. Let{a mathematical formula}Vu(o)=Veff(o)∖Vpre(o)be the set of undefined preconditions of o. Then M is relevant in regression for o if and only if:
      </paragraph>
      <list>
       <list-item label="1.">
        M is not implied by{a mathematical formula}pre(o).
       </list-item>
       <list-item label="2.">
        For some fact{a mathematical formula}fi=〈vi,x〉∈{f1,f2}, either (2a){a mathematical formula}fi∈pre(o)∖prev(o)or (2b){a mathematical formula}υi∈Vu(o)∧fi∉eff(o).
       </list-item>
      </list>
      <paragraph label="Proof">
       Assume WLOG that {a mathematical formula}fi=f1. To prove the if part of the statement, let s be any state s.t. {a mathematical formula}f1,f2∈s and the rest of facts are compatible with {a mathematical formula}pre(o). Such an assignment exists when the operator is valid and condition (1) holds. Then s satisfies the three statements:
       <list>
        {a mathematical formula}s⊭M since {a mathematical formula}f1,f2∈s.o is applicable in s: By the construction of s. Condition (1) ensures that {a mathematical formula}f1 and {a mathematical formula}f2 do not contradict {a mathematical formula}pre(o).{a mathematical formula}o(s)⊨M: Due to rule (2), {a mathematical formula}f1∉o(s). We have two cases (2a) or (2b). If (2b) holds, this is automatic, since {a mathematical formula}f1∉eff(o) and {a mathematical formula}v1∈Veff(o). If (2a) holds, {a mathematical formula}f1∈pre(o) implies that o deletes {a mathematical formula}f1 (otherwise {a mathematical formula}f1 would be in {a mathematical formula}prev(o)). Therefore, {a mathematical formula}f1∉o(s) so {a mathematical formula}o(s)⊨M.To prove the
       </list>
       <paragraph>
        only if case, note that if (1) does not hold, then there does not exist s such that {a mathematical formula}s⊭M and o is applicable in s, so M is not relevant for o. We may deduce condition (2) assuming that M is relevant for o in regression, i.e., there exists a state s such that {a mathematical formula}M⊨o(s) and {a mathematical formula}M⊭s. Then, for some fact {a mathematical formula}f1=〈υ1,x〉, {a mathematical formula}f1∉o(s), {a mathematical formula}f1∈s. Therefore, {a mathematical formula}s[υ1]≠o(s)[υ1], which implies {a mathematical formula}v1∈Veff(o) and f1∉eff(o)[v1]. Two cases are possible with respect to the preconditions of o, that correspond to conditions (2a) and (2b):
       </paragraph>
       <list>
        <list-item label="(a)">
         {a mathematical formula}υ1∈Vpre(o). As o must be applicable in s, {a mathematical formula}f1∈pre(o).
        </list-item>
        <list-item label="(b)">
         {a mathematical formula}υ1∉Vpre(o) and {a mathematical formula}υ1∈Vu(o) immediately follows. □
        </list-item>
       </list>
      </paragraph>
      <paragraph label="Proposition 3">
       (Relevant “at-least-1” invariant in regression) Let{a mathematical formula}Minv=f1∨⋯∨fkbe a reachability “at-least-1” invariant, and{a mathematical formula}o∈Obe a valid operator. Then{a mathematical formula}Minvis relevant in regression for o if and only if:
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}Minvis not implied by the preconditions of the operator{a mathematical formula}pre(o).
       </list-item>
       <list-item label="2.">
        For some fact{a mathematical formula}fi=〈υi,x〉∈Minv,{a mathematical formula}fi∈eff(o).
       </list-item>
      </list>
      <paragraph label="Proof">
       To prove the if part of the statement, let s be a state s.t. {a mathematical formula}fj∉s for all {a mathematical formula}fj∈Minv and all other facts are compatible with {a mathematical formula}pre(o). Such an assignment exists when o is valid and condition (1) holds. Then s satisfies:
       <list>
        {a mathematical formula}s⊭Minv since all {a mathematical formula}fj∈Minv are false in s.o is applicable in s. By the construction of s since, by condition (1), {a mathematical formula}fj∈Minv does not contradict {a mathematical formula}pre(o).{a mathematical formula}o(s)⊨Minv: Necessarily {a mathematical formula}fi∈o(s) since {a mathematical formula}fi∈eff(o) due to rule (2).To prove the
       </list>
       <paragraph>
        only if case, note that if (1) does not hold, then there does not exist s such that {a mathematical formula}s⊭Minv and o is applicable in s, so {a mathematical formula}Minv is not relevant for o. We may deduce condition (2) from {a mathematical formula}Minv being relevant in regression for o, i.e., {a mathematical formula}Minv is satisfied in {a mathematical formula}o(s) but not in s. Then, for some fact {a mathematical formula}fi=〈υi,x〉∈Minv, {a mathematical formula}fi∉s, {a mathematical formula}fi∈o(s). Therefore, {a mathematical formula}s[υi]≠s′[υi]=x, which implies {a mathematical formula}eff(o)[vi]=x and, therefore, {a mathematical formula}fi∈eff(o). □
       </paragraph>
      </paragraph>
     </section>
     <section label="5.4">
      <section-title>
       Constrained symbolic abstraction heuristics
      </section-title>
      <paragraph>
       The use of regression is not limited to backward search in the original state space. For instance, PDBs [35] usually perform regression in an abstraction, α, of the original problem to precompute the distance from every abstract state to the goal. PDBs in explicit-state search that make use of mutexes are known as constrained PDBs[51], cPDBs for short. cPDBs perform two types of pruning in the regression search over the abstract state space:
      </paragraph>
      <list>
       <list-item label="1.">
        Prune all abstract states that violate a state invariant of the problem.
       </list-item>
       <list-item label="2.">
        Prune transitions {a mathematical formula}sα→otα when the abstract states, {a mathematical formula}sα and {a mathematical formula}tα, are incompatible with the semantics of the operator,{sup:5} i.e., when the operator can only be applied on invalid states in {a mathematical formula}sα or its application on a valid state from {a mathematical formula}sα leads to an invalid state in {a mathematical formula}tα.
       </list-item>
      </list>
      <paragraph>
       The use of pruning in cPDBs may simplify the regression search by reducing the size of the abstract state space. More importantly, cPDBs may potentially prune spurious paths, i.e., solution plans in the abstract state space that do not have a corresponding plan in the original problem. Thus, cPDBs are able to derive heuristics more informed than standard PDBs and are always as good as them. As mentioned in Section 3.3, Gamer uses a symbolic version of PDBs [39], [15]. We propose symbolic constrained PDBs, a constrained version of symbolic PDBs that exploits constraints as studied in previous sections, by encoding them in a cBDD or in the TRs. There are some subtleties related to the usage of constraints in PDBs that make it different from backward search in the original problem. We classify constraints into three classes depending on whether their variables are abstracted or not. Full constraints are entirely in the pattern, partial constraints have some facts in the pattern and some abstracted away and null constraints are those without facts in the pattern. These types of constraints are related with the pruning methods mentioned above:
      </paragraph>
      <list>
       <list-item label="1.">
        Full constraints can be used to prune invalid abstract states. Partial or null constraints cannot be used for these purposes because some of their facts are abstracted so that they are never violated. As an example, take a mutex constraint {a mathematical formula}m=¬(f1∧f2). If we ignore the variable related to {a mathematical formula}f2, then we do not know whether it is true so that no abstract state will violate the constraint m.
       </list-item>
       <list-item label="2.">
        Partial constraints can be used to prune transitions in which the semantics of the operator are incompatible with the abstract states.
       </list-item>
       <list-item label="3.">
        Finally, null constraints are never useful for pruning the search. They could help to infer other constraints, but here we are assuming that the set of constraints is provided as input. Thus, we may ignore null constraints and assume that all the constraints are either full or partial.
       </list-item>
      </list>
      <paragraph>
       Another remarkable difference (applicable to explicit-state search too) is that, while relevance constraints are redundant in regression and do not provide additional pruning in backward search, in the abstract space those constraints may be violated. Therefore, when working with abstractions both reachability and relevance constraints should be used.
      </paragraph>
      <paragraph>
       Encoding constraints as BDDs. As studied in Section 5.2, one can encode the constraints in a BDD, cBDD, that corresponds to the conjunction of all the constraints and represents the set of valid states. Only full constraints are considered because the rest are never violated by abstract states. This corresponds to the pruning method proposed by Haslum et al. [51] in explicit cPDBs. Pruning transitions with a cBDD is more complicated because it depends of the operator being applied, so that one has to individually check each operator. We do not contemplate this possibility since it would require maintaining different cBDDs, one per operator, and it cannot be combined with methods of image computation that represent multiples operators in the same TR as explained in Section 4.4. Therefore, unlike the case of search in the original state space, {a mathematical formula}MBDD does not perform all the pruning possible.
      </paragraph>
      <paragraph>
       Encoding constraints in the TRs. In Section 5.3, we identified which subset of constraints must be encoded in the TR of each operator to guarantee that no invalid state is generated, given that the predecessor set of states does not contain invalid states. For symbolic PDBs, full constraints are treated as in the case of the original search, getting the same guarantees of not generating any invalid abstract states. This suffices to perform the first type of pruning, as with the {a mathematical formula}MBDD approach. However, in the abstract search the predecessor set of states may contain invalid states. In PDBs the value of abstracted variables is undefined, so abstract states correspond to partial states. Consider the set of states associated to an abstract state, {a mathematical formula}Siα, that corresponds to all the possible assignments that the abstracted variables may take. Partial constraints may be violated for some states in {a mathematical formula}Siα but not for others. {a mathematical formula}Siα cannot be pruned without loss of admissibility because there exist valid states associated to it. As an example, take the constraint of our trucks example, {a mathematical formula}¬(vt=2∧vp=A). If we ignore the time, an abstract state is composed of the position of the package and the position of the truck. Consider the abstract state {a mathematical formula}Iα, {a mathematical formula}〈vp=A,vT=A〉. Obviously we cannot prune {a mathematical formula}Iα. And still, for some values of the time variable {a mathematical formula}vt, the state would be invalid. Hence, this identifies abstract transitions {a mathematical formula}sα→otα that are incompatible with the state invariants.
      </paragraph>
      <paragraph>
       A simple way to consider all the possible inferences is to encode all the constraints in the TR representing the original operator and then abstract away the variables not in the pattern. Variables are abstracted away with existential quantification: there is a transition between two abstract states {a mathematical formula}sα, {a mathematical formula}tα if and only if a transition {a mathematical formula}s→ot exists in the original state space such that {a mathematical formula}α(s)=sα and {a mathematical formula}α(t)=tα. This encoding ensures that all the possible pruning is performed. The original TR represents all the pairs of states {a mathematical formula}s,t such that there exists a transition {a mathematical formula}s→ot in the original state space. Including all the constraints, we remove all the pairs related to invalid states. The result of the existential quantification is just the transitions between abstract states {a mathematical formula}sα,tα such that a valid pair of states {a mathematical formula}s,t supports the transition.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Experiments
     </section-title>
     <paragraph>
      In this section, we empirically evaluate the new techniques proposed in this paper. As the basis for the experiments we take the symbolic search planner Gamer[15], [32]. All planners used in our experiment use the {a mathematical formula}h2 invariant analysis to remove operators and simplify the planning task before starting the search [57]. This is very beneficial even for configurations that do not use the state invariant constraints. Originally, Gamer used unidirectional uniform-cost search and {a mathematical formula}BDDA⁎ with symbolic Pattern Databases. On top of that, we implemented the symbolic bidirectional uniform-cost search as described in Section 3.2. We also implemented the image computation refinements and state-invariant pruning techniques. We call the resulting planner cGamer, standing for constrained Gamer.
     </paragraph>
     <paragraph>
      We ran the experiments on a core of an Intel(R) Xeon(R) X3470 CPU@2.93 GHz with a time limit of 30 min and maximal memory usage of 4 GB. For BDD manipulation, the planner uses version 2.5.0 of the CUDD library [62]. All planners and libraries were compiled for 32-bit architectures. We evaluate our algorithms in all the STRIPS benchmarks in the optimal tracks of the International Planning Competition (IPC) from 1998 to 2011, without conditional effects or derived predicates. They include 1396 tasks divided into 44 domains. The main metric to compare cost-optimal planners is coverage, i.e., the number of problems solved.
     </paragraph>
     <paragraph>
      A caveat of the IPC benchmark set is that the number of problems in each domain is not uniform and there is overlapping between the domains used in different competitions, even reusing some problems. In order to get a total score comparison, we report a total metric that normalizes the score in every domain with respect to the number of problems, so that all the domains have the same weight (1 point per domain). In this metric, we consider the repeated problems and domains as a single entry, so that no domain or problem is counted twice.
     </paragraph>
     <paragraph>
      In some cases, coverage is not fine-grained enough since, due to the exponential gap between problems, all versions have the same coverage even if there is a huge performance gap. Thus, in cases where the running time is not biased (e.g., by an expensive preprocessing phase when using PDBs), we use the time score metric used in the learning track of IPC-2011. This metric assigns a score between 0 and 1 to each planner for each problem solved, depending on the time it took to solve the problem (t) with respect to the time of the best planner ({a mathematical formula}t⁎). The fastest planner receives 1 point, and others receive less points according to a logarithmic scale:{a mathematical formula}
     </paragraph>
     <paragraph>
      An important drawback of this time metric is that the results depend on the planners under consideration because {a mathematical formula}t⁎ may be different. Adding a new planner may change the relative score of others, i.e., the winner between two planners may depend on whether a third planner is included, biasing the results. Hence, in general we will compare planners based on coverage metrics, using the time score to reveal differences between planners in domains where coverage is the same.
     </paragraph>
     <paragraph>
      Of all symbolic algorithms, bidirectional uniform-cost search is the most suitable for an analysis on the impacts of our contributions because it is a state-of-the-art algorithm and the results do not depend on more parameters like the PDB generation procedure. Thus, we start evaluating the impact of image computation and state-invariant pruning in symbolic bidirectional uniform-cost search and, only later, we extend our analysis to other algorithms. We conclude our experiments by comparing our results to explicit-state search planners, showing that our improvements allow cGamer to outperform other state-of-the-art planners across a variety of domains.
     </paragraph>
     <section label="6.1">
      <section-title>
       Image computation
      </section-title>
      <paragraph>
       Table 1 shows the results of different image computation methods:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}TR1 is our baseline, Gamer's original image computation.
       </list-item>
       <list-item label="•">
        {a mathematical formula}TR1+ (see Section 4.2) separately represents preconditions and effects to avoid using auxiliary variables.
       </list-item>
       <list-item label="•">
        {a mathematical formula}CT and {a mathematical formula}CT20 use the conjunction tree (see Section 4.3). We report results with {a mathematical formula}CT20 because it gave the best results, though other parameter configurations of the conjunction tree have similar results [34].
       </list-item>
       <list-item label="•">
        {a mathematical formula}UT100kDT unifies TRs (see Section 4.4) using up to 100 000 nodes and limiting the TR aggregation time to 60 s.
       </list-item>
      </list>
      <paragraph>
       All the new image computation methods outperform the baseline. They are better not only in terms of total coverage and score, but also on a domain per domain basis. The time score results show that the new image computation methods provide an improvement in almost all domains (except in PSR-small, where all the problems are solved, and Parking, where no configuration solves any problem). This increase in efficiency allows the planner to solve more problems in 21 out of 44 domains. Given the exponential growth in problem complexity in most domains this reveals significant performance gains. Next, we analyze the results of each technique.
      </paragraph>
      <paragraph>
       {a mathematical formula}TR1+dominates the baseline. It has equal or better performance in all domains except Tidybot and the two versions of Pipesworld. In total, it solves 36 more problems than {a mathematical formula}TR1 across 17 domains.
      </paragraph>
      <paragraph>
       {a mathematical formula}CT20dominates{a mathematical formula}TR1+. Even though {a mathematical formula}CT has slightly worse total score than {a mathematical formula}TR1+, it performs well in domains that have lots of operators with many shared preconditions. This is the case in Freecell and, especially, Tidybot where {a mathematical formula}CT is the best method. However, in other domains (e.g., Blocksworld, Sokoban, or Transport) the coverage decreases due to the additional overhead. {a mathematical formula}CT20 limits this overhead by setting the min operators conjunction parameter to 20 operators. In most domains, the time score of {a mathematical formula}CT20 is just the maximum of {a mathematical formula}TR1+ and {a mathematical formula}CT, so the parameter is successfully able to control when it is useful to use the conjunction tree approach. Moreover, there are some cases in which {a mathematical formula}CT20 is better than both {a mathematical formula}TR1+ and {a mathematical formula}CT like in Freecell and Gripper.
      </paragraph>
      <paragraph>
       Overall,{a mathematical formula}UT100kDTis the best image computation method. Even though all the new image approaches improve the results of our base planner, Gamer, the clear winners among our image computation variants are the approaches that aggregate TRs. The total time score of {a mathematical formula}UT100kDT is 806.67, very close to the total coverage of 814. This means that {a mathematical formula}UT100kDT is reliably the fastest image computation method in almost every domain. In the few domains where it is not the fastest one, its performance is close to the fastest. Fig. 6 reflects the overwhelming superiority of {a mathematical formula}UT100kDT over the baseline. {a mathematical formula}UT100kDT is better in the vast majority of problems, solving problems up to two orders of magnitude faster than the baseline and being only clearly worse on four problems of the whole benchmark set. Moreover, {a mathematical formula}UT100kDT obtains the best coverage in many domains, solving 66 more problems than the original image computation of Gamer (27 of those are in Miconic). Other methods outperform {a mathematical formula}UT100kDT only in a few domains and by a small margin.
      </paragraph>
      <paragraph>
       What is the best parameter configuration of TR aggregation? Our aggregation algorithm (see Algorithm 3), which automatically derives a disjunctive partitioning of the TR, has two different parameters to control the resulting partitioning. On the one hand, in Section 4.4, we defined three criteria to select which TRs to merge in each algorithm iteration, {a mathematical formula}UTDT, {a mathematical formula}UTSM and {a mathematical formula}UTCT. On the other hand, the maximum TR size controls the memory used to represent the TRs. If the maximum TR size is set to 1, no TRs are aggregated and the algorithm behaves as the original {a mathematical formula}TR1. If the maximum TR size is set to ∞, the planner will use a monolithic TR for each operator cost, but may exceed the available memory in the initialization. Given the memory limit of 4 GB, we set the parameter to different values ranging from 1000 nodes (1k) to one million (1M) plus ∞ which corresponds to the monolithic TR approach. Fig. 7 shows the time score and total coverage of each parameter configuration.
      </paragraph>
      <paragraph>
       The configuration without any TR aggregation only solves 748 instances, 73 less than the best configuration in terms of coverage. However, setting the maximum TR size to 1000 nodes is enough to solve 818 instances, only 3 behind the best achieved. The fastest configurations are reliably those setting the maximum size of TRs in 10 000 or 100 000. The coverage slightly decreases with larger values, mainly because the TRs use too much memory.
      </paragraph>
      <paragraph>
       Regarding the aggregation criteria, {a mathematical formula}UTSM performs clearly worse than the other criteria, but the differences between the rest are not significant. Thus, any of these strategies which aggregate “similar” TRs with respect to different definitions are all valid strategies to decide which TRs should be aggregated. In the rest of the experiments we will use the {a mathematical formula}UT100kDT image computation. Even though there are other configurations with slightly better coverage, {a mathematical formula}UT100kDT is a simpler criterion and has the best time score.
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       Constrained symbolic search
      </section-title>
      <paragraph>
       Table 2 shows the impact of using state-invariant constraints to prune symbolic bidirectional uniform-cost search. Our baseline is the original Gamer planner that does not use state-invariant pruning. The rest of the configurations prune all the states that violate any invariant found by the preprocessor and they only differ on how the constraints are encoded. {a mathematical formula}MBDD1k and {a mathematical formula}MBDD100k encode the constraints as BDDs with a maximum number of nodes of 1000 and 100 000, respectively. In e-del and edel{sup:+} constraints are encoded directly in the TRs. edel{sup:+} include all discovered constraints in the TR of each operator and e-del encodes only the necessary constraints for each operator.
      </paragraph>
      <paragraph>
       State-invariant pruning dramatically improves the performance. The best configuration solves up to 862 problems, 48 more than the baseline. Given that the difficulty of the instances increases exponentially in many domains, such increase in performance is very significant. Even though there is no theoretical guarantee that pruning states increases the performance of BDD-based search, this seems to be the case for the set of benchmarks considered in our experiments. The only cases where the search performance slightly decreases are Grid, PARC-Printer and VisitAll. This may be due to many different factors, though it can be observed that in Grid and VisitAll relatively few mutexes are found with respect to other domains so there is less potential for pruning. PARC-Printer is characterized for having a large number of action costs, so that not too many states have the same g-value and BDDs are never too large. On the other hand, performance increases dramatically in many cases, such as Barman, Floortile, Freecell, etc. As shown by Fig. 8 the use of state invariants is almost always beneficial and the speed-up is of up to two orders of magnitude.
      </paragraph>
      <paragraph>
       What is the best encoding for state-invariant constraints? Whenever we use the encoding of constraints in separated BDDs of different sizes, {a mathematical formula}MBDD1k and {a mathematical formula}MBDD100k, we obtain similar results, though slightly favoring the version with a larger limit of nodes. As concluded in the experiments regarding the TR representation in the previous section, using larger bounds for the BDD size leads to faster computation at the expense of using more memory. Encoding constraints in the TRs, e-del, is the most efficient way to use the constraints in the search. The BDDs involved in the search are not affected, but e-del reduces the overhead in pruning the invalid states and even gets speed-ups in the image computation. The advantage of e-deletion is especially noticeable in Barman, Freecell or Pipesworld, in which there are many mutexes, though the performance decreases in a few domains like Mystery or Zenotravel. The right plot of Fig. 8 shows that the advantage of e-del over {a mathematical formula}MBDD100k is more moderate than our other comparisons.
      </paragraph>
      <paragraph>
       Encoding only the necessary constraints is important.e-del encodes the necessary constraints, according to our theoretical results in Section 5.3. In order to show the importance of identifying which constraints are relevant, we compare the results with edel{sup:+}, which encodes all the constraints in the TRs. Even though in Rovers and Satellite encoding all the constraints simplifies the search, in most cases it is unfeasible to do so, such that the overall results are worse than the configuration not performing pruning at all. This highlights the importance of not including constraints in the operators if they are completely unrelated to the variables affected by the operator.
      </paragraph>
      <paragraph>
       What is the impact ofe-delon TR representation?Fig. 9 plots the relative number of BDD nodes used to represent each transition relation. Cases where a monolithic TR could not been generated were excluded, since they are not really comparable. The size of the TRs is expected to increase when encoding state-invariant constraints and, indeed, that is the general trend. However, the increase is in most cases below an order of magnitude and there even are a number of cases where the constraints simplify the TRs. This explains how e-del is able to provide an advantage over representing the constraints in separated BDDs.
      </paragraph>
     </section>
     <section label="6.3">
      <section-title>
       Symbolic unidirectional uniform-cost search
      </section-title>
      <paragraph>
       The results of previous subsections have shown that the new image computation and state invariant pruning methods greatly enhance the performance of bidirectional search. In this section, we compare the results in unidirectional search and examine whether the new image techniques have more impact in forward or backward search.
      </paragraph>
      <paragraph>
       Image computation in forward and backward search.Table 3 shows the summary scores of the image computation methods on unidirectional uniform-cost search in forward and backward direction. The results are similar to those in the bidirectional search case, with {a mathematical formula}UT100kDT being the best configuration for image computation in almost every domain and the new image computation approaches outperforming the baseline, {a mathematical formula}TR1. The directionality of the search does not affect the comparison of the different image approaches. This confirms that the same principles apply to image and pre-image computation as introduced in Section 4.1.
      </paragraph>
      <paragraph>
       State-invariant pruning in forward and backward search. In IPC benchmarks, there are more reachability than relevance state-invariant constraints [57]. Thus, invariant constraints can be expected to have a greater impact in backward search than forward search. Table 4 reports the results of different state-invariant pruning methods in forward and backward search. The impact of pruning invalid states during the search is much larger in backward than in forward search. While invariant pruning increases the coverage of forward search in 8 problems, it allows backward search to solve 165 more instances. This is mainly due to the number of mutexes found in each direction:
      </paragraph>
      <list>
       <list-item label="•">
        In forward search, not enough mutexes are found to improve the performance. Mutexes are reliably found for all the problem instances only in Floortile, Mystery, PARC-Printer and Trucks. The results in these domains vary a lot. Mutex pruning helps greatly in Floortile, moderately in Trucks, does not have an impact in Mystery and decreases performance in PARC-Printer. The case of PARC-Printer is an exception caused by the structure of the domain, since the search performs many cheap steps and the overhead of mutex pruning might decrease performance. This overhead is almost completely eliminated with e-deletion, though. On the other hand, it is remarkable that e-deletion may increase the performance of forward search, even in domains where constraints provide no pruning such as Blocksworld, Depot, Pipesworld or Tidybot. In those domains, encoding the constraints in the TRs helps to simplify image computation and to moderately speed up search.
       </list-item>
       <list-item label="•">
        In backward search, however, there are many available constraints in most domains and they can be successfully exploited to improve performance in most of them. In several domains where regression without pruning fails completely such as Barman or Blocksworld, using state-invariant pruning not only makes regression possible, but makes it outperform forward search.
       </list-item>
      </list>
      <paragraph>
       The results of unidirectional search also shed more light on what is the best encoding for state-invariant constraints. e-del outperforms {a mathematical formula}MBDD100k both in forward and backward search, but its impact is larger in the case of backward search, where there are more state invariants to take advantage of. Since bidirectional uniform-cost search combines takes advantage of the best search direction, the advantages of e-del are only truly reflected in domains where backward search is not inferior to forward search, e.g., Barman, Blocksworld, or Freecell.
      </paragraph>
      <paragraph>
       Do state invariants affect the directionality of the domains? In general, the results depict a great advantage of forward over backward search. However, the use of state-invariant constraints helps to reduce the gap. Without the use of invariants, backward search is only clearly better in Miconic, whereas using state-invariants, it is also better in Barman, Blocksworld, NoMystery, Satellite, and Woodworking. This is also important to improve the performance of bidirectional search, as we have analyzed in Section 6.2.
      </paragraph>
     </section>
     <section label="6.4">
      Symbolic {a mathematical formula}BDDA⁎
      <paragraph>
       Table 5 evaluates our symbolic search enhancements in {a mathematical formula}BDDA⁎ with symbolic PDBs. The symbolic PDBs are generated with Gamer's hill climbing method [15] in a precomputation phase that is terminated after 900 s. All our enhancements are used both in the symbolic PDB generation and in the symbolic {a mathematical formula}A⁎ algorithm. Time score metrics are omitted because they are not representative of {a mathematical formula}A⁎ performance, given that all the algorithms spend a maximum of 900 s in the PDB generation before starting the search.
      </paragraph>
      <paragraph>
       Do our techniques improve{a mathematical formula}BDDA⁎? Image computation methods improve {a mathematical formula}BDDA⁎ as much as bidirectional symbolic uniform-cost search. This reveals that the advantage of the new image computation methods is not limited to a particular algorithm. State-invariant constraints also help, but less than in bidirectional symbolic uniform-cost search. The overall results again show that the use of state invariants helps to improve results of {a mathematical formula}A⁎ as well. However, the benefits are not as stable as in the case of uniform-cost search. Even though pruning invalid states ({a mathematical formula}MBDD100k) increases total coverage, it decreases the coverage in 9 domains with respect to the version without invalid state pruning ({a mathematical formula}M∅). In order to find out whether the performance loss is caused by the abstract searches that generate the heuristic or the {a mathematical formula}A⁎ search, we analyze the quality of the heuristic used. One typical way to measure such quality is the heuristic value of the initial state.
      </paragraph>
      <paragraph>
       Fig. 10 shows that the our techniques can be used for the generation of more informed PDB heuristics. The image computation methods improve the performance of the abstract searches across all domains, allowing the planner to explore more informed abstractions, so they are almost always beneficial. State-invariant pruning, however, decreases performance in some cases, obtaining worse heuristic estimates. Obviously, using state invariants cannot decrease the values of a given abstraction so the reason is that different abstractions are being explored. Even though state-invariant constraints can only increase the heuristic value for a given pattern, this may change which patterns are preferred by the hill-climbing search in the space of possible patterns. Another reason is that, for some patterns, the abstract searches become much harder when using state-invariant constraints. This is not completely unexpected since, as argued before, there are no theoretical guarantees of the search being simpler when using state-invariants constraints. However, it may be surprising that this only happens in abstract state spaces and not in the whole search space. The reason is that the abstract symbolic search may have lower complexity than the original search, especially if the abstract problem consists of independent subproblems, i.e., the causal graph of the abstract task has separated components. In that case, the symbolic abstract search complexity depends on the size of the components instead of the number of variables in the abstraction. Introducing the state-invariant constraints of the original state space breaks the independence of the variables, significantly increasing the complexity of the abstract search.
      </paragraph>
     </section>
     <section label="6.5">
      <section-title>
       Symbolic versus explicit-state search
      </section-title>
      <paragraph>
       In this section, we compare symbolic and explicit-state search algorithms, emphasizing the relevance of our improvements for symbolic search.
      </paragraph>
      <paragraph>
       Symbolic vs. explicit uniform-cost search. The left part of Table 6 shows the benefits of the symbolic representation in blind search, especially when using our improvements. For forward search we used the {a mathematical formula}A⁎ implementation of the Fast Downward planning system [47] with the blind heuristic (FD). For backward search we used the FDR planner [6], implemented on top of Fast Downward. FDR runs partial-state regression with state-invariant pruning.
      </paragraph>
      <paragraph>
       In forward uniform-cost search, the symbolic variant is better in most domains, solving 154 more problems even without our improvements. With cGamer, the advantage gets increased to 208 problems, making symbolic search at least as good as the explicit version in all domains. In backward search, the performance of the symbolic baseline, Gamer, is similar to that of FDR. Gamer has better total coverage but FDR has better coverage score. Moreover FDR is faster when the solving times are considered. Nonetheless, note that FDR already uses state-invariant pruning. When our symbolic search enhancements are used, we consistently beat FDR in all domains except Mystery. In total, the advantage of symbolic uniform-cost search is notable, obtaining better results than the explicit version in all but 6 domains in which they are tied. Forward search is usually better than backward search in both variants, though its good results in some domains suggest that backward search should not be abandoned.
      </paragraph>
      <paragraph>
       Symbolic versus heuristic state-of-the-art planners. To compare against state-of-the-art planners, we use {a mathematical formula}A⁎ with LM-cut[5] and two configurations of the merge-and-shrink heuristic [4]. Fast Downward Stone Soup[63], the winner of the optimal-track of IPC-2011 [64], was a portfolio sequentially running {a mathematical formula}A⁎ with these three heuristics. To compare against the best portfolio of that kind, we use an optimistic over-approximation of the best possible results using the three planners (best), which considers a problem solved if it was solved by any of the individual planners. Gamer and cGamer use bidirectional uniform-cost search and {a mathematical formula}BDDA⁎ with symbolic PDBs.
      </paragraph>
      <paragraph>
       The right part of Table 6 shows that symbolic algorithms outperform explicit-state planners across a variety of domains. Regarding total performance, explicit-state search planners beat both variants of Gamer, mainly due to the accuracy of the LM-cut heuristic. However, the total performance of cGamer is superior to explicit-state search planners in this set of benchmarks. The case of bidirectional uniform-cost search is clear, beating even the portfolio approaches. {a mathematical formula}BDDA⁎ is also superior when considering standalone planners, but it is still behind the optimistic results of the explicit-state search portfolio. The results highlight the importance of symbolic search not only in terms of average performance but also in a per-domain basis. Symbolic planners are required to obtain the best results in 23 domains. Comparatively, heuristic planners only get better results than symbolic search algorithms in 11 cases.
      </paragraph>
      <paragraph>
       Analysis of coverage with different runtime limits.Fig. 11 shows the cumulative number of instances solved by every planner at every second, in logarithmic scale. In general, the final score of the planners after 30 min is representative of the results with other time limits. However, there are some remarkable conclusions related to the behavior of these planners.
      </paragraph>
      <paragraph>
       Blind search starts faster than other planners, but it converges quickly because the memory limit is exceeded after approximately 5 min. Symbolic unidirectional search is not only faster than explicit-state blind search (solving more problems in the first seconds), but also has a much better convergence rate due to the memory savings of BDDs.
      </paragraph>
      <paragraph>
       Our symbolic search enhancements increase the score of Gamer uniformly over time. This speedup makes cGamer-fw faster than Gamer, even though it does not perform bidirectional search. However, the lack of regression search causes a faster convergence and it is not clear whether cGamer-fw would beat Gamer for larger timeouts.
      </paragraph>
      <paragraph>
       Well-informed heuristics, such as LM-cut, increase the performance of explicit-state search and the total performance is slightly better to that of symbolic forward search and similar to symbolic {a mathematical formula}BDDA⁎ with PDB heuristics. However, symbolic bidirectional search with our improvements is able to beat LM-cut except for very short timeouts, probably due to the time spent in BDD initialization and the instances for which LM-cut is perfectly informed.
      </paragraph>
      <paragraph>
       IPC-2014 analysis. The results of the last IPC in 2014{sup:6} confirm that symbolic bidirectional search is a leading approach for cost-optimal planning. In the sequential-optimal track, the symbolic bidirectional uniform-cost version of cGamer was the runner-up, beating other symbolic search, explicit-state search, and portfolio planners. The winner of the sequential-optimal track, {a mathematical formula}SymBA⁎, is another symbolic planner that uses the improvements presented in this paper, combining bidirectional search with abstraction heuristics [65], [66]. In total, symbolic planners outperformed explicit-state search planners in 10 out of 14 domains. From the seven domains that had already been used in previous IPCs, symbolic search planners are better in 5 of them. In the new domains, we see a similar trend with symbolic planners being better in 5 out of 7 domains. This supports the idea that our analysis is not biased by the benchmark set used in this paper and complements the results of our experiments to affirm that symbolic search planners are once again competitive with the state of the art [67].
      </paragraph>
      <paragraph>
       Further experiments on {a mathematical formula}SymBA⁎ have shown that, while abstraction heuristics may improve the performance of bidirectional search on particular domains, symbolic bidirectional uniform-cost search is yet a state-of-the-art planner [66]. Thus, the race for the state of the art in cost-optimal planning is not over. Currently, both symbolic approaches (blind and guided) are about on par on the existing benchmark set. If abstraction heuristics can be improved slightly (maybe with some better selection policy) the table may turn in favor to heuristic search approaches, but at the moment to the best of the authors' knowledge bidirectional blind search as presented in this article is competitive with bidirectional heuristic search approaches, even though it does not make use of any heuristic and hence has the advantage of being simpler.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Discussion
     </section-title>
     <paragraph>
      Heuristic and symbolic search are two leading methods for cost-optimal planning. There is no doubt that symbolic search has the effectiveness to explore large state sets, while the explicit-state heuristics are often more informed. While the result of IPC 2011 suggested a clear advantage for heuristic explicit-state search, in this paper we introduced two orthogonal improvements to symbolic search planners that change this picture.
     </paragraph>
     <paragraph>
      On the one hand, we have presented and analyzed image computation methods for symbolic search planning. Our starting point was the state-of-the-art symbolic search planner Gamer that computes the image using a transition relation for each planning operator. We proposed three different alternatives for image computation:
     </paragraph>
     <list>
      <list-item label="1.">
       {a mathematical formula}TR1+: Instead of representing each planning operator by means of a single BDD, represent the preconditions and effects independently. That way, no auxiliary set of variables is needed in order to represent the successor states.
      </list-item>
      <list-item label="2.">
       {a mathematical formula}CT: Apply the preconditions of operators at the same time using the conjunction tree, an approach similar to the one used in explicit-state search planning.
      </list-item>
      <list-item label="3.">
       {a mathematical formula}UT: Aggregate several operators in a single transition relation, controlling the memory used and avoiding to exceed a given memory limit.
      </list-item>
     </list>
     <paragraph>
      Our analysis has shown that the three approaches improve the previous image computation of Gamer in terms of coverage and time score. Moreover, the experimental results show a dominance across most domains, so that the new image computation methods can replace the previous image computation of Gamer. We observed that it is better to avoid the usage of an auxiliary set of variables, representing conditions and effects separately. Unfortunately, this cannot be done when more than one operator is represented in the same TR, so the best image computation techniques still need the auxiliary set of variables to represent the relation between the precondition and the effect of the operators. In terms of time-efficiency, it is best to use a single monolithic TR to describe all the operators. However, as already noticed by previous works, the TR that describes all the planning operators can easily exceed the available memory (that was the main reason to split it into one TR per operator). Thus, one of the main conclusions of our analysis is that for efficient image computation, it is best to represent the planning operators with as few TRs as possible, using a monolithic TR for all operators with the same cost whenever possible. When constructing a monolithic TR within a reasonable memory limit is impossible, a disjunctive partitioning of the TR is necessary. Previous work in model checking had already suggested similar partitionings. Here, we proposed an algorithm to derive the disjunctive partitioning automatically, according to several heuristic criteria. Our analysis shows the importance of keeping the size of the TRs as balanced as possible, so we recommend the {a mathematical formula}UT100kDT method for future work.
     </paragraph>
     <paragraph>
      On the other hand, we used state-invariant constraints in order to prune symbolic search. We interpret state invariants as properties that must hold in any state that is part of a plan for the task, so that they can be used to prune forward and backward search. Our main contribution is to study different methods to encode and use these constraints:
     </paragraph>
     <list>
      <list-item label="•">
       {a mathematical formula}MBDD: Encodes the constraints as BDDs and, during the search, uses a conjunction to compute the subset of valid states.
      </list-item>
      <list-item label="•">
       e-del: Encodes the constraints as additional conditions in the operators, i.e., in the TRs. We proved which subset of constraints must be encoded in each TR to ensure that no invalid states are generated during the search.
      </list-item>
     </list>
     <paragraph>
      Empirical results show that state-invariant pruning is tremendously effective in symbolic search, especially in regression. According to our evaluation, e-deletion is recommended for taking advantage of constraints in symbolic search. This has impact specially in regression search where there are more state-invariant constraints, and may also be relevant for encoding constraints from other sources, such as novel dead-end detection methods [68].
     </paragraph>
     <paragraph>
      Our enhanced version of Gamer, cGamer, not only outperforms Gamer in most domains but also has superior performance compared to explicit-state search approaches. The good results of symbolic blind search are especially surprising as after many years of research of finding refined heuristics for AI planning, this form of blind search still outperforms heuristic search planners on many domains, while being close on most others. The impact of the directionality of the domains [69] explains why this configuration fares so well, as a simple alternating strategy allows choosing the direction in which the problem may be more easily solved, compensating the use of heuristics. This highlights the importance of regression. Progression is usually believed to be more robust than regression for search-based planning. While the results on unidirectional search somewhat confirm the superiority of forward search, our improvements help to reduce the gap in symbolic search, beating the results of partial-state backward search. An important conclusion to be drawn from our results is that symbolic backward search is a useful technique that can be complementary to standard heuristic search techniques.
     </paragraph>
     <paragraph>
      In the last IPC in 2014 cGamer made the second place, outperforming other symbolic search based planners as well as explicit-state search based planners. The winner of the competition, {a mathematical formula}SymBA⁎ was also built upon the ideas of cGamer, using the enhancements proposed in this paper with a combination of symbolic bidirectional search and abstraction heuristics. This reflects the relevance of our enhancements, unifying operators based on the balanced disjunction tree up to a maximum memory limit of 100 000 nodes ({a mathematical formula}UT100kDT) for image computation and e-deletion for state-invariant pruning, to make symbolic search a state-of-the-art technique for cost-optimal planning.
     </paragraph>
     <paragraph>
      A more detailed analysis of the impact of abstraction heuristics in bidirectional search shows that, while abstraction heuristics may be helpful in particular domains, the overall performance of {a mathematical formula}SymBA⁎ is similar to that of symbolic bidirectional uniform-cost search [66]. Bidirectional heuristic search has recently seen some possibilities [70] and limitations [71]. Insights have lead to variants like MM [72], [73] with a set-based parallel implementation on external memory [74]. Given the success of BDD-based bidirectional search documented in this work, the implementation of MM with BDDs and its application to AI planning domains is one tempting option for future research.
     </paragraph>
    </section>
   </content>
  </root>
 </body>
</html>