<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Strong temporal planning with uncontrollable durations.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Planning in real world domains often involves modeling and reasoning about the duration of actions. For example, the activities of a planetary rover, such as navigation and data transmission, require non-negligible time to be completed, and their successful execution is subject to timing constraints. Both navigation and transmission actions must occur in time windows when sufficient solar power is available, and the transmission action must occur in a time window when a receiving satellite is in view.
     </paragraph>
     <paragraph>
      An approach to tackle the problem consists in combining classical planning, where actions are assumed to be instantaneous, with a subsequent scheduling phase, where the durations are taken into account. Unfortunately, valid classical plans may turn out not to admit a feasible schedule.
     </paragraph>
     <paragraph>
      Temporal planning [3] attempts to overcome this problem by allowing for modeling and reasoning about durative actions. In the domain description, actions are associated not only to preconditions and effects on the state, but also with constraints on the durations. For example, a navigation or drilling task may have lower and upper duration bounds. A temporal planner looks for plans where each action is associated with start and end time points. The idea can be described as effectively integrating the scheduling aspects within the search for the set of actions to be executed, checking at the same time for the existence of a schedule.
     </paragraph>
     <paragraph>
      In some practical applications, however, the duration of actions may be uncertain and not under the control of the executor. For example, a navigation task to a given location may take more or less time, depending on external factors, such as terrain or weather conditions. The plan may specify when to start the operation, but the actual duration is controlled by the environment.
     </paragraph>
     <paragraph>
      In this paper, we introduce the problem of Strong Temporal Planning with Uncontrollable Durations (STPUD ). In this setting, the planner is only allowed to choose the start of the actions, while the duration of uncontrollable actions is chosen by the environment at run time, within known bounds. A solution plan is required to be temporally strong, i.e. robust, with respect to uncontrollable action durations, and to achieve the goal over all possible executions, despite the run-time choices of the environment. These plans are quite similar to temporal plans in PDDL, where a specific starting time and duration is specified for each action in the plan, with the difference being that we do not specify the duration of uncontrollable actions.
     </paragraph>
     <paragraph>
      The STPUD problem is the lifting to the planning case of the strong controllability problem for temporal networks [4], [5] and thus does not allow conditional execution based on the observation of action durations at run-time. This means that all the uncertainty is resolved at planning time and the plans do not contain conditional branches. Such plans can be sub-optimal in terms of make-span, and one can construct examples where strong plans do not exist. However, for duration uncertainty, this seems to be less common than for other types of uncertainty (e.g. uncertainty in the outcome of actions). For example, with Mars rovers there is considerable duration uncertainty for driving operations, but the approach used in practice is to construct strong plans assuming maximum duration, and just wait if the rover gets to a location too early for the next desired activity. This is practical in this domain because there is often little penalty for waiting, except the delay of future actions. In general, unless a domain has a lot of intricate temporal constraints with both lower and upper bounds, there is a good chance that a strong plan exists. This plan may not be optimal if one is interested in minimizing make-span, but it usually exists. Moreover, in some situations the executor of the plan may not have the time or the computational power to perform a re-scheduling of the plan at run-time. A typical example is a spacecraft during an orbit insertion maneuver: the pace of the operations and communication limitations require that a plan be pre-computed with no run-time adjustment.
     </paragraph>
     <paragraph>
      One distinct advantage of strong plans is understandability: a human can read, understand and check a STPUD plan, while the same operation can be extremely difficult for a conditional plan or a flexible plan represented for example as an STN(U) or even as a simple precedence graph. Finally, while this paper focuses on techniques for automatic synthesis of strong plans, the resulting plans can often be relaxed to partially-ordered plans before execution, similar to what can be done for deterministic PDDL plans to reduce make-span (e.g. [6]). This could improve the quality of such plans during execution, but adapting such techniques for the STPUD case is left for future work.
     </paragraph>
     <paragraph>
      In this paper, we explore two complementary approaches to STPUD. First, we discuss a dedicated planning method to deal with uncontrollable durations, which generalizes the forward state-space temporal planning (FSSTP ) framework introduced in [7] and used in [8], [9]. Intuitively, FSSTP applies classical planning over an abstraction of the temporal domain, where temporal precedences over events are taken into account at a qualitative level, to enumerate candidate plans. The quantitative aspects are then taken into account by solving the consistency problem of the induced Simple Temporal Network (STN ) [10]. In order to deal with temporal uncertainty, we retain the main loop of FSSTP, dealing with the quantitative aspects by means of Temporal Networks with Uncertainty{sup:1} (TNUs), leveraging recent scheduling techniques for TNU [11] based on Satisfiability Modulo Theories [12]. We call the derived technique S-FSSTP. This approach is far from being trivial; we show how simply replacing the STN in [9] with the corresponding STNU may result in an unsound technique.
     </paragraph>
     <paragraph>
      Second, we present a compilation-based planning method, that reduces any STPUD problem to a temporal planning problem, where all the actions have controllable durations. The sound-and-complete reduction eliminates uncontrollable durations by introducing intermediate effects and conditions, which are events that take place during an action execution.
     </paragraph>
     <paragraph>
      We also investigate a domain transformation technique that is able to eliminate some of the uncontrollable durations by reasoning in terms of worst case execution. This technique preserves the space of plans/set of solutions, and can be used as a preprocessor for both the planning approaches.
     </paragraph>
     <paragraph>
      The approaches described above have been implemented and experimentally analyzed. We considered a large number of instances obtained by extending the temporal planning domains available in the literature with uncontrollable durations. Our results demonstrate the practical applicability of our approaches, and provide interesting insights. First, the two approaches we present often exhibit complementary behaviors, so that further efficiency can be achieved using a portfolio approach. Second, the preprocessing technique has negligible costs, but it greatly pays off, in selected cases, for both planning approaches.
     </paragraph>
     <paragraph>
      Paper structure. The paper is structured as follows. In Section 2 we discuss related work. Section 3 introduces and formalizes the Strong Temporal Planning with Uncontrollable Durations problem. In Section 4 we give a structured overview of the approaches. Section 5 proposes a generalization of the state-space temporal planning framework for solving the STPUD problem. In Section 6 we describe the compilation technique, which removes the duration uncertainty from a given STPUD. In Section 7, we describe the domain simplification technique for uncontrollability elimination. In Section 8 we experimentally evaluate the merits of all the proposed techniques. We conclude in Section 9 by reviewing the paper and proposing future research directions.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      A few works in the literature consider the problem of planning with uncontrollable durations, but none of them consider the STPUD problem as it is presented in this paper. The only framework available for planning with uncertain duration is probabilistic, while here we focus on exact techniques for Strong planning with interval durations. There is a significant corpus of papers concerning the pure scheduling problem, most notably works on temporal networks with uncertainty, but these do not consider plan generation from a model of a system, only the temporal allocation of activities. STPUD can be thought of as a combination of scheduling under temporal uncertainty with temporal planning.
     </paragraph>
     <section label="2.1">
      <section-title>
       Temporal networks with uncertainty
      </section-title>
      <paragraph>
       Temporal uncertainty is a well-understood concept in scheduling. It has been widely studied [13], [14], [15], [11]. Given a set of actions with uncontrollable durations subject to a set of temporal constraints, we are interested in solutions to schedule the actions such that all the temporal constraints are respected regardless of the actual duration the actions may take. Depending on the information available to the scheduler at run-time, different classes of problems have been defined [4].
      </paragraph>
      <paragraph>
       The problem we address in this paper can be seen as a generalization of Strong Controllability for Temporal Networks [4], [5] to planning (rather than scheduling). Strong controllability is the problem of finding a fixed schedule for the controllable time points that fulfills all the constraints in each valid situation encoded by the network. Dealing with planning is much harder because the actions (and thus the time points associated with them) in a plan are not known a-priori and must be searched for. Moreover causal relationships in planning are much more complex than Temporal Network constraints.
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Temporal planning
      </section-title>
      <paragraph>
       In temporal planning, duration uncertainty is a known challenge [16], but few temporal planners address it explicitly. Some temporal planners [17], [18] cope with this issue by generating “flexible temporal plans”: instead of fixing the execution time of each action, they return a (compactly represented) set of plans that must be scheduled at run-time by the plan executor. This approach cannot guarantee plan executability and goal achievement at runtime, because there is no formal modeling of the boundaries and contingencies in which the system is going to operate. Instead, our proposed approach requires a formal modeling of the problem uncertainty and guarantees plan executability and goal achievement under any modeled contingency. In addition, flexible plans require an executor able to solve constraints at runtime to schedule the activities. Flexibility and controllability are complementary: controllability provides guarantees with respect to the modeled uncertainty, while flexibility allows the plan to be adjusted during execution. In principle, we can use any temporal planner that can generate flexible plans in combination with our compilation to generate a flexible strong plan.
      </paragraph>
      <paragraph>
       IxTeT [19] is the first attempt to lift to the planning case the results in temporal reasoning under uncertainty. The planner generates a strategy for scheduling the actions depending on contingent observations and encodes it as a dynamically controllable Simple Temporal Network with Uncertainty (STNU) [4]. This plan representation requires a powerful plan executor, able to dynamically schedule an STNU. These plans sometimes work in more situations than the Strong Plans we generate in our work, but they are also more complex to generate, understand, and execute. Strong Plans are frequently required for safety critical systems like space applications, where guarantees are needed, and computational power is limited.
      </paragraph>
      <paragraph>
       There has also been work on temporal planning with probabilistic duration uncertainty, e.g. [20], [21], [22], [23], [24], [25], [26], [27]. This work assumes a probability distribution over action durations, and attempts to generate policies or conditional plans that branch on the observed action durations at run time. A good discussion of much of this work can be found in [25]. The primary limitations of these approaches is that they are either incomplete (only generate partial policies), or tend to suffer from scalability issues. Instead we assume that durations are bounded in convex intervals, and attempt to generate Strong Plans – that is, non-branching plans that guarantee goal achievement and plan executability in all the allowed contingencies.
      </paragraph>
      <paragraph>
       There is a clear parallel between the problem we are solving and conformant planning [28]. In this sense, the work we describe in Section 6 is similar to [29] in which the authors transform conformant planning into deterministic planning, although the translation is very different.
      </paragraph>
      <paragraph>
       Finally, the work in [30] presents a logical characterization of the STPUD problem for timelines with temporal uncertainty, as well as a first-order encoding of the problem having bounded horizon. In Section 5 of this paper, we generalize this framework, as we do not impose any bounded horizon for the problem and we consider a more expressive language allowing disjunctive preconditions, effects at arbitrary time points during actions, and durative conditions on arbitrary sub-intervals.
      </paragraph>
     </section>
    </section>
    <section label="3">
     <section-title>
      The STPUD problem
     </section-title>
     <paragraph>
      In this section, we formally define the syntax and semantics of Strong Temporal Planning with Uncontrollable Durations (STPUD ) and we discuss the issues that arise in comparison to temporal planning without uncertainty.
     </paragraph>
     <section label="3.1">
      <section-title>
       Syntax
      </section-title>
      <paragraph>
       In order to express planning problems with uncontrollable durations, we propose a rich language that includes timed-initial-literals (TILs), and multi-valued variables. In addition, we extend the language to allow conditions expressed over sub-intervals of actions, and effects at arbitrary time points during an action. These features turn out to be particularly useful for encoding many problems of interest, and for our translation.{sup:2}
      </paragraph>
      <paragraph>
       In order to define the abstract syntax of our language we need to consider four kinds of intervals, namely closed, left-open, right-open and open. We will use these intervals to express durative conditions.
      </paragraph>
      <paragraph label="Definition 1">
       Given two numeric expressions a and b, we define the four possible intervals having extremes a (lower bound) and b (upper bound) as: {a mathematical formula}[a,b] closed interval; {a mathematical formula}(a,b] left-open interval; {a mathematical formula}[a,b) right-open interval; and {a mathematical formula}(a,b) open interval.We write {a mathematical formula}[(a,b)] to indicate an instance of the above possibilities without distinguishing the type, similarly {a mathematical formula}[(a,b] indicates an interval that can be open or closed on the left, but closed on the right, and so on. Moreover, we write {a mathematical formula}[a] to indicate the single-point interval {a mathematical formula}[a,a].
      </paragraph>
      <paragraph>
       We can now define a STPUD planning problem P as a tuple {a mathematical formula}〈V,I,T,A,G〉 where:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}V={f1,⋯fn} is a finite set of variables,{sup:3} each having a domain {a mathematical formula}Dom(fi).
       </list-item>
       <list-item label="•">
        I is the initial state: a complete assignment of values to each variable in V: for each variable {a mathematical formula}f∈V, {a mathematical formula}I(f)∈Dom(f).
       </list-item>
       <list-item label="•">
        T is a set of timed-initial-literals, each of the form {a mathematical formula}〈[t]f:=v〉 with {a mathematical formula}f∈V, {a mathematical formula}v∈Dom(f) and {a mathematical formula}t∈R&gt;0. The real number t is the wall-clock time at which f will be assigned the value v.{sup:4}
       </list-item>
       <list-item label="•">
        A is a set of durative actions each of the form {a mathematical formula}a=˙〈[l,u],C,E〉 where{sup:5}:
       </list-item>
       <list-item label="•">
        G is the set of disjunctive goal conditions, each of the form {a mathematical formula}⋁i=1nfi=vi, where each {a mathematical formula}fi∈V and {a mathematical formula}vi∈Dom(fi).
       </list-item>
      </list>
      <paragraph>
       Intuitively, the syntactic tokens {a mathematical formula}sta and {a mathematical formula}eta indicate the start and end times of action a, and are used to specify timings of effects and conditions relative to the action timing. Note that for the sake of simplicity, we do not permit a condition c with {a mathematical formula}stc=eta−δ1 and, simultaneously, {a mathematical formula}etc=sta+δ2, while all other cases are allowed. In practice, this means that we cannot express a condition that starts at a time point relative to the end of the action and ends at a time point expressed relative to the start of the action. We believe this combination isn't particularly useful in practice and this limitation simplifies the semantics and the explanation of the techniques. However, there is no fundamental problem in extending all the proposed techniques to cover this case. Moreover, we do not require {a mathematical formula}stc to be lower than (or equal to, if the interval is closed) {a mathematical formula}etc: this is because such an interval would be empty (i.e. it would contain no time-point). As such, any condition expressed over an empty interval is imposed over no time-point, and thus is vacuously true. All the subsequent semantics and techniques are defined in such a way that an empty interval poses no constraints on the problem. For these reasons, we allow this degenerate case. Finally, when the interval for a condition c is a single point (i.e. {a mathematical formula}[stc]), the condition is instantaneous.
      </paragraph>
      <paragraph>
       We assume that the set of actions A is partitioned into two sets {a mathematical formula}Ac and {a mathematical formula}Au of controllable and uncontrollable actions, respectively. This is needed to distinguish between actions whose duration can be controlled by the agent, and those that have uncontrollable durations. In both cases, the bounds on the duration need to be satisfied, but analogously to TNU contingent links, if an action is uncontrollable, its duration is assumed to take a value in the specified bound.
      </paragraph>
      <paragraph>
       The solution to a STPUD problem P is a plan π that assigns the starting of all the actions and specifies the duration only for controllable actions.
      </paragraph>
      <paragraph label="Definition 2">
       A plan π of P is a finite set of tuples {a mathematical formula}〈t,a,d〉, in which actions {a mathematical formula}a∈A, {a mathematical formula}t∈R≥0, {a mathematical formula}d∈R&gt;0 if {a mathematical formula}a∈Ac and {a mathematical formula}d=⊥ if {a mathematical formula}a∈Au.
      </paragraph>
      <paragraph>
       Intuitively, an element {a mathematical formula}〈t,a,d〉 indicates the start of an instance of the action a at time t, with duration d if a is a controllable action. The assignment of {a mathematical formula}d=⊥ for uncontrollable actions reflects the intuitive notion that since the duration is not under the control of the plan executor, the plan cannot specify it.
      </paragraph>
      <section label="3.1.1">
       <section-title>
        Discussion
       </section-title>
       <paragraph>
        The planning problem formalism we describe includes several features that allow considerable expressiveness. In particular, we focus on the presence of uncertainty in the action durations, that constitutes the main objective of this work. We also allow the presence of “intermediate” effects and conditions: the possibility of having action effects at intermediate times, and to impose conditions in sub-intervals of the action execution. This latter feature is not new, languages such as ANML [31] or NDL [32] support it natively, but it is not natively supported in other languages. For example, PDDL 2.1 does not allow for intermediate effects nor for conditions at times different from the start, the end, or the entire action duration.
       </paragraph>
       <paragraph>
        If we classify according to the presence or absence of these features, we obtain the landscape of planning problem sub-classes depicted in Table 1. The table shows four classes of problems. Clearly, every class with arbitrary intervals subsumes the class with extreme intervals having the same action controllability. Similarly, each class having action uncertainty is strictly more general than the class without it. Given these subsumption rules, the only two incomparable classes are Unc-Extr and Ctrl-Arbit: both subsume Ctrl-Extr, but no obvious relation is present between the two. Unc-Arbit is the most general class that subsumes every other case and coincides with the language we discussed in the previous section. The aim of this work is to tackle the Unc-Arbit problem class in its full complexity.
       </paragraph>
       <paragraph>
        Some of the reported problem classes are supported in the literature and by dedicated planning tools. In particular, Ctrl-Extr is the temporal planning problem addressed by all the planners supporting the PDDL 2.1 language. Ctrl-Arbit is a sub-case of the features provided by the ANML language, therefore tools such as FAPE [33] can natively reason on instances of this class. Moreover, reduction techniques have been presented for transforming an instance of the Ctrl-Arbit class to a problem in Ctrl-Extr[34], [31].
       </paragraph>
      </section>
     </section>
     <section label="3.2">
      <section-title>
       Running example
      </section-title>
      <paragraph>
       We give a small example problem that will be used throughout the paper.
      </paragraph>
      <paragraph>
       A rover, initially at location {a mathematical formula}l1, needs to transmit some science data from location {a mathematical formula}l2 to an orbiter that is only visible in the time window {a mathematical formula}[14,30]. The rover can move from {a mathematical formula}l1 to {a mathematical formula}l2 using an action {a mathematical formula}move that has uncontrollable duration between 10 and 15 time units. The data transmission action {a mathematical formula}trans takes between 5 and 8 time units to complete. The goal of the rover is to transmit the data to the orbiter. Because of the harsh daytime temperatures at location {a mathematical formula}l2, the rover cannot be at {a mathematical formula}l2 until the sun goes behind the mountains at time 15. Fig. 1 illustrates this scenario, which we encode as follows{sup:6}:{a mathematical formula} The pos variable indicates the position of the rover, {a mathematical formula}visible is true if the satellite is available for data transmission, hot is true if the temperature at {a mathematical formula}l2 is too hot for the rover, and {a mathematical formula}sent is set to T after the data is sent to the satellite.
      </paragraph>
      <paragraph>
       Fig. 2 graphically shows a valid strong plan {a mathematical formula}πex for the running example. The plan is defined as follows.{a mathematical formula} Note that all the actions in {a mathematical formula}πex have uncontrollable duration; hence, the strong plan does not specify their duration (durations are replaced by ⊥).
      </paragraph>
     </section>
     <section label="3.3">
      <section-title>
       Semantics
      </section-title>
      <paragraph>
       We give the semantics of the planning language by defining the validity of a plan π for any given STPUD problem P. As usual, P admits a solution if there exists a valid plan, otherwise the problem is said to be unsolvable.
      </paragraph>
      <paragraph>
       We start by defining the projection of a STPUD problem. Intuitively, in a projected problem, the durations of uncontrollable actions become controllable choices for the planner. For example, the {a mathematical formula}trans action is originally assumed to last between 5 and 8 time units; in the projection this choice becomes controllable, but we retain the requirement that the duration lies within 5 and 8.
      </paragraph>
      <paragraph label="Definition 3">
       Projected problemGiven a STPUD problem {a mathematical formula}P=˙〈V,I,T,A,G〉 with durative actions {a mathematical formula}A=˙Ac∪Au, the projected problem without uncertainty is a STPUD {a mathematical formula}ctrl(P)=˙〈V,I,T,A′,G〉 that is identical to P except for the partition of the set of actions that is {a mathematical formula}A′=˙Ac′∪Au′ with {a mathematical formula}Ac′=˙Ac∪Au and {a mathematical formula}Au′=˙∅.
      </paragraph>
      <paragraph>
       The basic element of our semantics is a chronicle, that is used to assign a value to each variable in V for each time instant.
      </paragraph>
      <paragraph label="Definition 4">
       ChronicleA chronicle τ for a given STPUD problem instance {a mathematical formula}P=˙〈V,I,T,A,G〉 is a set of functions {a mathematical formula}τf:R≥0→Dom(f), one for each {a mathematical formula}f∈V.
      </paragraph>
      <paragraph>
       Given a plan, we can now define the chronicle induced by it. In our language we have three components that contribute to change the state of a variable, namely the initial state, the TILs and action effects. Apart from these events, each variable is assumed to maintain its value in the other time instants. To formalize this concept we start by collecting the set of change events in the execution of the plan.
      </paragraph>
      <paragraph label="Definition 5">
       Set of changes {an inline-figure}Given a projected planning problem instance {a mathematical formula}ctrl(P)=˙〈V,I,T,A,G〉 and a plan {a mathematical formula}π=˙{〈ti,ai,di〉|i∈[1,n]}, the multi-set of changes induced by π is a set {an inline-figure} defined as follows.
       <list>
        for each {a mathematical formula}f∈V, {an inline-figure};for each {a mathematical formula}〈[t]f:=v〉∈T, {an inline-figure};for each {a mathematical formula}〈t,a,d〉∈π with {a mathematical formula}a=˙〈[l,u],C,E〉:Given a positive time
       </list>
       <paragraph>
        {a mathematical formula}x∈R&gt;0 and a variable f, let {a mathematical formula}PExf be all the elements {a mathematical formula}〈t,f,v〉 of {an inline-figure} with {a mathematical formula}t&lt;x; let {a mathematical formula}maxPExf be the maximum timing in {a mathematical formula}PExf (i.e. {a mathematical formula}max(t|〈t,f,v〉∈PExf)). We indicate with {an inline-figure} the multi-set {a mathematical formula}{v|〈maxPExf,f,v〉∈PExf}.
       </paragraph>
      </paragraph>
      <paragraph>
       We remark that, at this stage, we need to keep a multi-set of changes because it is possible for two effects to set the same variable to the same value. We consider such a situation illegal and we will catch it in Definition 8.
      </paragraph>
      <paragraph>
       Now, we can define the chronicle induced by a plan by imposing that at each time point corresponding to a change in {an inline-figure}, the chronicle changes its value; and between two successive changes, the chronicle maintains its value. In this sense, the chronicle is constrained to be a piecewise-constant function. The {an inline-figure} multi-set contains the changes on variable f that are applied immediately before time x. Note the strict inequality in the definition of {an inline-figure}: we consider the value of the change immediately before, but not at the time x.
      </paragraph>
      <paragraph label="Definition 6">
       Induced chronicleGiven a projected planning problem instance {a mathematical formula}ctrl(P)=˙〈V,I,T,A,G〉 and a plan π, a chronicle {a mathematical formula}τπ induced by π is defined as follows.For each variable f,
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}τfπ(0)=v with {an inline-figure};
       </list-item>
       <list-item label="•">
        for each {a mathematical formula}x∈R&gt;0, {a mathematical formula}τfπ(x)=v with {an inline-figure}.
       </list-item>
      </list>
      <paragraph>
       Intuitively, each variable in each time point assumes the value imposed by the last change until another is applied. Note that, if no two effects on the same variable happen at the same time, then the induced chronicle is unique (otherwise, we will deem the execution invalid in Definition 8).
      </paragraph>
      <paragraph>
       For example, consider an effect {a mathematical formula}〈[eta]f:=v〉 and suppose the action a ends at absolute time 10. The value of f is not changed at time 10 but immediately after. This means, that a condition requiring f to have value v is not satisfied at time 10, but a positive amount of time is required to pass. This view is practically compatible with the PDDL 2.1 specification{sup:7} and also with the continuous time version of the ANML language.
      </paragraph>
      <paragraph>
       As an auxiliary definition, we introduce the Absolute-Time Interval of a condition of an action appearing in a plan. The idea is to define the subset of the time points in which each condition is required to hold, given a plan.
      </paragraph>
      <paragraph label="Definition 7">
       Absolute-time intervalGiven a plan π and a plan element {a mathematical formula}〈t,a,d〉∈π, the absolute-time interval of a condition {a mathematical formula}c∈C of action a is a subset of the real numbers {a mathematical formula}ATI(c,〈t,a,d〉) defined as follows.{a mathematical formula}
      </paragraph>
      <paragraph>
       We can now define the validity of a plan for a projected problem. Intuitively, we need to check three conditions to validate a plan. First, we require that there are not two or more changes of the same variable at the same time; second, we check that all the conditions of all the actions used in the plan are satisfied; and finally we require that all the goals are reached immediately after the end of the last action in the plan.
      </paragraph>
      <paragraph label="Definition 8">
       Projected problem plan validityGiven a projected problem {a mathematical formula}ctrl(P)=˙〈V,I,T,A,G〉, a plan π is valid if the following conditions hold:
      </paragraph>
      <list>
       <list-item label="1.">
        for each {a mathematical formula}t∈R≥0 and each {a mathematical formula}f∈V,{an inline-figure};
       </list-item>
       <list-item label="2.">
        for each {a mathematical formula}〈t,a,d〉∈π with {a mathematical formula}a=˙〈[l,u],C,E〉, the following holds:
       </list-item>
       <list-item label="3.">
        for each goal condition {a mathematical formula}(⋁i=1nfi=vi)∈G, {a mathematical formula}⋁i=1nτfiπ(x)=vi holds, for any {a mathematical formula}x∈[tmax,tmax+ϵ] with {a mathematical formula}tmax=˙max({t+d|〈t,a,d〉∈π}) and a sufficiently small {a mathematical formula}ϵ∈R&gt;0.
       </list-item>
      </list>
      <paragraph>
       We remark that here we are defining the semantics of a valid plan for a projected planning problem, hence we reject as invalid any plan yielding an execution that violates any of the above constraints.
      </paragraph>
      <paragraph label="Definition 9">
       Finally, we can define the semantics of any STPUD problem P by imposing that each plan obtained by specifying a valid duration for each uncontrollable action is valid for the projected problem of P. This captures the intuitive notion of strong plan: regardless of the actual duration of each uncontrollable action specified in the plan, the execution is valid and all the goals are satisfied. STPUD plan validityGiven a STPUD problem P, a plan {a mathematical formula}π=˙{〈ti,ai,di〉|i∈[1,n]} is valid, if all the plans {a mathematical formula}π′∈{〈t,a,d〉|〈t,a,d〉∈π,a∈Ac}∪{〈t,a,k〉|〈t,a,d〉∈π,a∈Au,a=˙〈[l,u],C,E〉,k∈[l,u]} are valid for {a mathematical formula}ctrl(P).
      </paragraph>
      <paragraph>
       A valid plan for a given STPUD is called a “strong plan”.
      </paragraph>
     </section>
     <section label="3.4">
      <section-title>
       Discussion
      </section-title>
      <paragraph>
       In the general case, finding a strong plan for a problem with uncontrollable durations is different from simply considering the maximum or the minimum duration for each action. Consider our rover example and its strong plan shown in Fig. 2. The {a mathematical formula}move action must end before the transmit action can start and, at the same time, {a mathematical formula}move cannot end before time 15 due to the temperature constraint. If we only consider the lower-bound on the duration of {a mathematical formula}move (i.e., planning with a fixed duration of 10 for {a mathematical formula}move) then one valid plan is: {a mathematical formula}πlb=˙{〈11,move〉,〈22,trans〉}. However, because of the uncertainty in the actual execution duration of {a mathematical formula}move, it may actually take 14 time units to arrive at {a mathematical formula}l2. Thus, the rover would start transmitting at time 22 before it actually arrives at {a mathematical formula}l2 at time {a mathematical formula}11+14=25. Thus, plan {a mathematical formula}πlb is not a valid strong plan. Similarly, if we consider only the maximal duration (i.e., planning with a fixed duration of 15), then one possible plan would be: {a mathematical formula}πub=˙{〈1,move〉,〈22,trans〉}. However, the actual execution of {a mathematical formula}move, may take only 11 time units (and not the planned maximum of 15 time units) to arrive at {a mathematical formula}l2. This would violate the constraint that the rover should arrive at {a mathematical formula}l2 after {a mathematical formula}t=15 to avoid the sun, so {a mathematical formula}πub is also not a valid plan.
      </paragraph>
      <paragraph>
       Disjunctive conditions. In contrast to ordinary temporal planning, given a STPUD problem it is not possible to compile away disjunctive conditions using the action duplication technique [35]. This is because the set of satisfied disjuncts in the presence of uncertainty can depend on the contingent execution. For example, consider the situation depicted in Fig. 3. An action a is starting at time t where two Boolean variables {a mathematical formula}p1 and {a mathematical formula}p2 are F. The action a has uncontrollable duration in {a mathematical formula}[l,u], a starting effect {a mathematical formula}e1=˙〈[sta]p1:=T〉 and two ending effects {a mathematical formula}e2=˙〈[eta]p1:=F〉 and {a mathematical formula}e3=˙〈[eta]p2:=T〉. An at-start condition {a mathematical formula}p1∨p2 of another action b is satisfied anywhere between the start of the action a and the next deletion of {a mathematical formula}p2. Thus, b can start anytime after t. However, by applying the compilation on this disjunctive condition we replace b with two actions {a mathematical formula}b1 and {a mathematical formula}b2, one with an at-start condition {a mathematical formula}p1 and the other with an at-start condition {a mathematical formula}p2. Now, {a mathematical formula}b1 is not executable within {a mathematical formula}(t+l,t+u] because there is no time point in d in which we can guarantee that {a mathematical formula}p1=T (because a may take the minimum duration l and thus the at-end effect {a mathematical formula}e2 will occur at {a mathematical formula}t+l to set {a mathematical formula}p1=F). Similarly, we cannot start {a mathematical formula}b2 within {a mathematical formula}(t+l,t+u] because there is no guarantee that {a mathematical formula}p2 will be T during {a mathematical formula}(t+l,t+u] (this is because a may take the maximum duration u and thus {a mathematical formula}e3 that sets {a mathematical formula}p2=T will not happen until {a mathematical formula}t+u). Thus, compiling away disjunctive conditions as in temporal planning leads to incompleteness (some valid plans cannot be found) when actions with uncontrollable duration are present. For this reason, it is important to explicitly model disjunctive conditions in our language.
      </paragraph>
      <paragraph>
       Computational complexity. Considering decidability and computational complexity of the STPUD problem, we first note that the domain of the variables in a STPUD problem may be finite or infinite, but only finitely-many values from each domain are used in a problem instance, because we only allow for the equality relation in effects and conditions. So, each problem instance can be polynomially transformed, by means of a logarithmic encoding of the relevant values of each domain, into an equivalent one that only has Boolean variables. In this way, we can meet the general framework of Rintanen [36] for temporal planning.
      </paragraph>
      <paragraph>
       The STPUD problem is decidable: this paper presents sound-and-complete solution algorithms. Concerning the computational complexity of STPUD, we present the following results.
      </paragraph>
      <paragraph label="Proof">
       The STPUD problem is EXPSPACE-Hard.(Sketch) STPUD trivially subsumes temporal planning (any temporal planning instance is just a STPUD instance with no action having uncontrollable duration). Because temporal planning is EXPSPACE-Complete [36], the STPUD problem is EXPSPACE-Hard. □
      </paragraph>
      <paragraph label="Proof">
       The STPUD problem is in 2-EXPSPACE.(Sketch) Any STPUD problem instance can be reduced to a corresponding temporal planning problem without uncontrollable durations of exponential size (see for example the compilation we present in Section 6). Since temporal planning without uncontrollable durations is EXPSPACE-Complete [36], the STPUD problem is in 2-EXPSPACE. □
      </paragraph>
      <paragraph>
       We currently have no proof of membership in EXPSPACE nor a proof of 2-EXPSPACE-Hardness; we only know that the STPUD problem lies in between these two classes. We leave a detailed analysis of the computational complexity of the STPUD problem and its sub-classes for future work. In this paper we concentrate on practical solution techniques for the problem.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Overview of the approaches
     </section-title>
     <paragraph>
      Given the problem classification in Table 1, here we give an outline of the techniques included in this paper that have been developed to address the more general Unc-Extr and Unc-Arbit class.
     </paragraph>
     <paragraph>
      First, we focus on the Unc-Extr class and in Section 5 we present a dedicated solving technique that extends the Forward State-Space Temporal Planning (FSSTP ) approach to deal with uncontrollable durations. We indicate this technique as S-FSSTP (for Strong FSSTP ). We propose different variants of the technique that are sound for the Unc-Extr problem class; in addition, we prove that one of the approaches is also complete for the same problem class.
     </paragraph>
     <paragraph>
      Second, we devise a compilation technique that transforms any instance of the Unc-Arbit class into an instance of the Ctrl-Arbit class, effectively removing the temporal uncertainty from the problem. The compilation is such that any plan of the controllable instance admits a plan if and only if the original Unc-Arbit planning problem has a valid strong plan. This compilation, discussed in Section 6, makes use of arbitrary-time conditions and effects; hence, even if applied on a Unc-Extr instance, it produces an equivalent Ctrl-Arbit instance.
     </paragraph>
     <paragraph>
      We also present a simplification technique that is able to reduce (and in some cases, to remove) the temporal uncertainty in a planning instance. This technique does not make use of intermediate effects nor conditions, hence it can be applied on both the Unc-Arbit and Unc-Extr classes without ending up in a different problem class.
     </paragraph>
     <paragraph>
      Finally, in the experimental evaluation section (Section 8), we adapt existing techniques for removing intermediate conditions and effects in the context of PDDL 2.1. We discuss and extend existing techniques to obtain an efficient compilation for the removal of intermediate effects and conditions when no actions having uncontrollable duration are present.
     </paragraph>
     <paragraph>
      Table 2 gives an overview of the aforementioned techniques and reductions in the problem classes landscape.
     </paragraph>
    </section>
    <section label="5">
     <section-title>
      STPUD via forward state-space search
     </section-title>
     <paragraph>
      In this section, we focus on the Unc-Extr problem class: for each action a, effects can only be specified at times {a mathematical formula}sta and {a mathematical formula}eta, and conditions are limited to timings {a mathematical formula}[sta], {a mathematical formula}[eta] or {a mathematical formula}(sta,eta). We propose a dedicated approach for solving the STPUD problem, based on an extension of the Forward State-Space Temporal Planning (FSSTP ) approach. We first introduce the relevant background on Temporal Networks with Uncertainty and we formalize the Forward State-Space Temporal Planning (FSSTP ) approach, then we generalize it to handle temporal uncertainty. The resulting technique, that handles the Unc-Extr problem class, is referred to as S-FSSTP.
     </paragraph>
     <section label="5.1">
      <section-title>
       FSSTP background
      </section-title>
      <section label="5.1.1">
       <section-title>
        Temporal networks with uncertainty
       </section-title>
       <paragraph>
        In temporal planning, we need to reason not only about the ordering of actions in time, but also about their duration. A common framework to represent and reason about these kinds of constraints in scheduling (i.e. when the set of activities is known and only a suitable timing for the activities is sought) is the Temporal Network (TN ) [10], [37]. The TN formalism is used to represent temporal constraints over time-valued variables representing time points. Each constraint is a disjunction of atoms in the form {a mathematical formula}x−y∈[l,u], where x and y are time points and {a mathematical formula}l,u∈R∪{∞,−∞}. Formally, a TN is a tuple {a mathematical formula}〈X,C〉 where X is a set of time points and C is a set of temporal constraints. Time points are typically used to represent the start or the end of actions; causal relations are represented as precedence constraints, forcing one event to happen before another; and metric constraints allow for the encoding of action durations by constraining the difference between start and end of an action. A solution to a TN is an assignment of real values to the time points that satisfies all the constraints. A TN is said to be consistent if it has a solution.
       </paragraph>
       <paragraph label="Definition 10">
        In order to deal with temporal uncontrollability, TNs with uncertainty (TNUs ) have been proposed [4], [5]. Temporal network with uncertaintyA Temporal Network with Uncertainty (TNU ) is a tuple {a mathematical formula}〈Xc,Xu,Cc,Cf〉, where {a mathematical formula}Xc and {a mathematical formula}Xu are sets of time points; {a mathematical formula}Cc=˙{cc1,⋯,ccm} is a set of constraints of the form {a mathematical formula}cci=˙⋁jxi−yi∈[li,j,ui,j] with {a mathematical formula}xi∈Xu, {a mathematical formula}yi∈Xc∪Xu and {a mathematical formula}li,j,ui,j∈R∪{∞,−∞}; and {a mathematical formula}Cf=˙{cf1,⋯,cfn} is a set of constraints of the form {a mathematical formula}cfi=˙⋁jxi,j−yi,j∈[li,j,ui,j] with {a mathematical formula}xi,j,yi,j∈Xc∪Xu and {a mathematical formula}li,j,ui,j∈R∪{∞,−∞}.
       </paragraph>
       <paragraph>
        In a TNU some of the time points can be controlled (assigned values) by the solver ({a mathematical formula}Xc), while the others ({a mathematical formula}Xu) are controlled (assigned values) by the environment. Similarly, the constraints are divided according to requirements (called free constraints, {a mathematical formula}Cf) and assumptions (called contingent constraints, {a mathematical formula}Cc). As such, TNUs can be seen as a form of game between the solver and an adversarial Nature [11].
       </paragraph>
       <paragraph>
        Given a TNU, different kinds of queries are possible. In this paper, we focus on strong controllability [4], [5]. A TNU is strongly controllable if there exists an assignment (called a strong schedule) of real values to each controllable time point, such that all free constraints are satisfied for every possible assignment of the uncontrollable time points satisfying the contingent constraints.
       </paragraph>
       <paragraph>
        Depending on the structure of the constraints, various classes of TNUs have been identified [5]. We focus on two classes of TNUs: Simple Temporal Networks with Uncertainty (STNUs ) and Disjunctive Temporal Networks with Uncertainty (DTNUs ). An STNU is a TNU where each constraint has exactly one disjunct (i.e. it is conjunctive), while DTNUs allow for arbitrary Boolean combinations in the constraints.
       </paragraph>
       <paragraph>
        Several approaches to check strong controllability of a TNU have been proposed. In [4], the authors show that the strong controllability problem for an STNU is polynomial-time, while for a DTNU it is NP-hard [5]. Recently, new techniques to solve strong controllability for DTNUs have been presented [11]: they rely on the reduction of strong controllability to a Satisfiability Modulo Theory [12] problem.
       </paragraph>
      </section>
      <section label="5.1.2">
       <section-title>
        FSSTP
       </section-title>
       <paragraph>
        The idea behind the FSSTP approach is an interplay between a state-based forward search planner to generate an abstract plan and a temporal reasoner to check its temporal feasibility [7], [9]. Intuitively, a temporal plan is a set of action instances scheduled at specific times with specific durations. FSSTP works by encoding each durative action as a pair of instantaneous, classical actions: a classical planner is employed to generate sequences of such instantaneous action instances that are sound from the propositional point of view, but might violate some temporal constraint. Then, a scheduler is used to check temporal feasibility and to associate a proper time-stamp to each action instance. If the scheduling succeeds, a valid temporal plan is constructed, otherwise the sequence of classical action instances is refused and another must be found.
       </paragraph>
       <paragraph>
        Most existing FSSTP planners are designed to operate on the PDDL 2.1 language. PDDL only allows effects at the start ({a mathematical formula}sta) or at the end ({a mathematical formula}eta) of an action, instantaneous conditions can be specified at the start or at the end of the action and durative conditions are possible only on the whole interval {a mathematical formula}(sta,eta). This coincides with the Ctrl-Extr problem class we defined in Section 4.
       </paragraph>
       <paragraph>
        In FSSTP, each durative action a is expanded into a pair of classical planning actions called snap actions: {a mathematical formula}ast encoding the starting event of a, and {a mathematical formula}aet corresponding to the ending of a. The action {a mathematical formula}ast has the starting conditions and effects of a as preconditions and effects, and, similarly, {a mathematical formula}aet has the ending conditions and effects of a as preconditions and effects. FSSTP planners like Colin force the planner to instantiate snap actions in pairs (each start is coupled with exactly one end) and forbid any action threatening the overall condition of a between the snap actions for a[7].
       </paragraph>
       <paragraph>
        Similarly, timed initial literals are treated as instantaneous actions that can be instantiated without preconditions and have the TIL as effect. For a TIL t, we indicate with {a mathematical formula}TA(t) such an instantaneous action.
       </paragraph>
       <paragraph>
        We can now define a Domain Abstraction as a classical planning problem derived from a Ctrl-Extr STPUD planning instance.
       </paragraph>
       <paragraph label="Definition 11">
        Domain abstractionGiven a temporal planning problem {a mathematical formula}P=〈V,I,G,T,A〉 restricted to the Ctrl-Extr problem class, the abstraction of P (written {a mathematical formula}abs(P)) is a classical (non-temporal) planning problem defined as {a mathematical formula}〈V,I,G,⋃a∈A{ast,aet}∪{TA(t)|t∈T}〉.
       </paragraph>
       <paragraph>
        The (highly simplified) pseudo-code of a forward state-space temporal planner (FSSTP ) is shown in Algorithm 1. A classical planner (implemented as a forward state-space search) is used as an iterator{sup:8} over all the valid plans of the abstract problem {a mathematical formula}abs(P). The planner keeps a totally-ordered partial plan χ composed of abstract action instances we call steps. We indicate a step corresponding to an instance of action a as {a mathematical formula}sa. Each time an action instance is added to the partial plan, the scheduling check is invoked to assess the temporal consistency of the partial plan. The scheduling check builds a TN{sup:9} that has the steps of χ as time points and has a set of constraints composed of duration constraints D and precedence constraints P. Duration constraints (created by the Durations function) are used to bind pairs of snap action instances {a mathematical formula}(siast,sjaet), forcing the duration of each action instance to obey the domain specification ({a mathematical formula}aet−ast∈[l,u], being {a mathematical formula}a=˙〈[l,u],C,E〉). In addition, each TIL {a mathematical formula}t=˙〈[k]f:=v〉 is forced to happen at the predefined time by imposing a temporal constraint{sup:10}{a mathematical formula}TA(t)=k. Precedence constraints (created by the Precedences function) are used to maintain causality in the plan. If a step {a mathematical formula}si is needed to achieve a precondition for another step {a mathematical formula}sj, we must impose a precedence among the two steps ({a mathematical formula}sj−si&gt;0), in order to inform the scheduler of the causal constraint.{sup:11} Similarly, precedence constraints are used to ensure that the overall conditions for an action a are maintained.
       </paragraph>
       <paragraph>
        When the TN is found to be consistent, two situations can occur. If χ is a plan achieving the goal in {a mathematical formula}abs(P), each {a mathematical formula}siast is followed by a corresponding {a mathematical formula}sjaet and all TILs appear in the plan (IsComplete returns true), we can terminate the procedure, otherwise we continue the search in the abstract domain (continue). To terminate, we build a temporal plan π from a consistent schedule μ of the TN: we write {a mathematical formula}μ(x) to indicate the value assigned to x by μ. Each pair of snap actions steps {a mathematical formula}siast, {a mathematical formula}sjaet in χ is a step in π, the time for the step is {a mathematical formula}μ(siast) and the duration is {a mathematical formula}μ(sjaet)−μ(siast). Instead, if the TN is not consistent, the classical planner is required to generate a new plan, as χ is not temporally sound and cannot be further extended.
       </paragraph>
       <paragraph>
        In the rest of this section, we use the following notation. Given a step {a mathematical formula}si of χ (that is an instance of a classical planning action), we write {a mathematical formula}effects(si) to indicate the set of its effects, each of the form {a mathematical formula}〈f:=v〉. Moreover, we write {a mathematical formula}conditions(si) to indicate the set of preconditions of {a mathematical formula}si, each in the form {a mathematical formula}⋁i=1nfi=vi.
       </paragraph>
      </section>
     </section>
     <section label="5.2">
      S-FSSTP
      <paragraph>
       The general idea we pursue is to substitute the scheduling steps of Algorithm 1 to solve a strong controllability problem for a TNU instead of consistency for a TN. The generalization of the framework to the STPUD case is shown in Algorithm 2.
      </paragraph>
      <paragraph>
       As in FSSTP, we first consider the abstract domain enumerating the “discrete” plans that are a solution of the abstract problem. The key difference with respect to the FSSTP schema is that to accommodate uncontrollable durations we substitute the TN with a TNU (checking strong controllability instead of consistency), and we consider different formulations for the precedence constraints.
      </paragraph>
      <paragraph>
       Thanks to the limitation to the Unc-Extr class of problems, we can consider all the time points corresponding to the starting of actions as controllable (the planner decides if and when an action should be started), while ending time points are controllable if the corresponding action is controllable, otherwise they are uncontrollable.
      </paragraph>
      <paragraph>
       The duration constraints are built analogously to the plain temporal case, but are divided in two sets: {a mathematical formula}Dc are the duration constraints for controllable actions, {a mathematical formula}Du are the ones for uncontrollable actions.
      </paragraph>
      <paragraph>
       Building a strong plan σ from a strong schedule for the TNU is analogous to the plain temporal planning case: each pair of corresponding {a mathematical formula}〈siast,sjaet〉∈χ is a step of σ, the time for the step is {a mathematical formula}μ(siast) and, if a is controllable, the duration is {a mathematical formula}μ(sjaet)−μ(sjast). We do not set the duration for uncontrollable durative action instances.
      </paragraph>
      <paragraph>
       The encoding of the precedence constraints {a mathematical formula}Precedences(χ,P) is crucial, because in the presence of uncontrollability not all the techniques presented in the temporal planning literature for the controllable case [9], [8] are complete. In the following, we consider two different encodings proposed in the temporal planning literature and we show that they are incomplete for solving the STPUD problem. Then, we borrow the idea of reordering from [6] and we derive the first sound and complete approach for the STPUD problem in the Unc-Extr class.
      </paragraph>
      <section label="5.2.1">
       <section-title>
        Total order encoding
       </section-title>
       <paragraph>
        A simple way of building the ordering constraints is to maintain the total order (TO ) of the partial plan χ. Forcing this total order clearly maintains the causal soundness but, as noted in [8], is heavily dependent on the order of action instances chosen by the classical planner. Nevertheless, this encoding is complete for temporal planning without duration uncontrollability and is adopted in the Colin[9] and Crikey 3 [7] planners.
       </paragraph>
       <paragraph>
        We call {a mathematical formula}PrecedencesTO(χ,P) the set of precedence constraints for a given totally ordered plan {a mathematical formula}χ=˙〈s1,…,sn〉, and we define it as follows:{a mathematical formula} We note that no disjunction is created, hence the encoding results in an STNU.{sup:12} Unfortunately, this encoding is incomplete in the presence of temporal uncertainty. Indeed, at each step of Algorithm 2, it might be the case that no total order produces a strongly controllable TNU, even if there exists a strong plan for the given problem. Thus, the planner can explore the complete search space and declare the problem unsolvable even if there exists a solution. Nonetheless, the approach is sound: if a solution is returned, it is a valid strong plan.
       </paragraph>
       <paragraph>
        In our running example, reported in Section 3.2, the TO approach can terminate yielding the strong plan {a mathematical formula}πex when the following abstract plan is generated by the classical planner and the relative total order is considered.{a mathematical formula} This very same example of an abstract plan that works for finding the plan {a mathematical formula}πex also works in the other approaches in this section.
       </paragraph>
       <paragraph>
        As an example of the approach incompleteness, consider the situation depicted in Fig. 4. Suppose that both actions a and b must be started at the same time.{sup:13} Action a is uncontrollable and b must end between the earliest and the latest possible ends of a. Literals p and q are initially true and no action falsifies them. Let us focus on the relative order of {a mathematical formula}siaet and {a mathematical formula}sjbet. If {a mathematical formula}χ=〈⋯,siaet,⋯,sjbet,⋯〉, then we (transitively) impose the constraint {a mathematical formula}siaet&lt;sjbet. However, the resulting STNU is not strongly controllable because if a takes longer than 7 time units, {a mathematical formula}aet can happen after {a mathematical formula}bet, violating the constraint. If {a mathematical formula}χ=〈⋯,sjbet,⋯,siaet,⋯〉, then the situation is reversed and again the STNU is not strongly controllable. Therefore, in both cases χ is rejected and the planner returns ⊥. This is incomplete, because there exists a simple strong plan for the problem: start both actions at time 0 (the two actions are non-interfering and all the conditions are satisfied as p and q are never falsified).
       </paragraph>
      </section>
      <section label="5.2.2">
       <section-title>
        Last achiever deordering encoding
       </section-title>
       <paragraph>
        Another possible precedence encoding lifts totally ordered plans to partially ordered plans [8]. The underlying idea is to use the greedy algorithm proposed in [38] to reconstruct the causal links as precedence links. For each action instance in the plan requiring a literal l as precondition, the algorithm searches for the last achiever of that literal in the totally ordered plan, and imposes a precedence link between the two action instances. In this way, it builds a partial order plan as a deordering [6] of χ and possibly reduces the commitment on the specific input ordering. Note that, similar to the previous encoding, we never introduce disjunctions, hence the resulting TNU is an STNU.{sup:14}
       </paragraph>
       <paragraph>
        We now define the Last Achiever Deordering (LAD ). Using a common trick in partial order planning, we consider two fictitious steps, {a mathematical formula}s0 and {a mathematical formula}sn+1, representing the initial state and the goal condition, respectively. Step {a mathematical formula}s0 has no preconditions and has the initial state I as effect. Step {a mathematical formula}sn+1 has the goal as precondition and no effect.
       </paragraph>
       <paragraph>
        Given a variable f and a value v, we denote with {a mathematical formula}ach(f,v) the subset of steps in χ that set the variable f to value v and with {a mathematical formula}del(f,v) the set of action instances that set f to a value different from v. Formally, {a mathematical formula}ach(f,v) is defined as the set of steps {a mathematical formula}{si∈χ|〈f:=v〉∈effects(si)} and {a mathematical formula}del(f,v) as the set {a mathematical formula}⋃v′∈Dom(f),v′≠vach(f,v′).
       </paragraph>
       <paragraph>
        Given a step {a mathematical formula}sk and a disjunctive condition {a mathematical formula}c=˙⋁i=1nfi=vi, we denote with {a mathematical formula}last(c,sk) the step {a mathematical formula}sj such that {a mathematical formula}sj∈⋃i=1nach(fi,vi) and j is the maximum index strictly lower than k. Intuitively, {a mathematical formula}last(c,sk) is the last action instance that sets an {a mathematical formula}fi to its desired value {a mathematical formula}vi before {a mathematical formula}sk in χ.
       </paragraph>
       <paragraph>
        The precedence constraints {a mathematical formula}PrecedencesLAD(χ,P) of this approach are defined as follows.
       </paragraph>
       <paragraph label="Definition 12">
        Given {a mathematical formula}χ=〈s0,⋯,sn+1〉, {a mathematical formula}PrecedencesLAD(χ,P) is as follows.
       </paragraph>
       <list>
        <list-item label="1.">
         {a mathematical formula}{(s0&lt;si),(si&lt;sn+1)|i∈[1,n]}⊆PrecedencesLAD(χ,P).
        </list-item>
        <list-item label="2.">
         For each {a mathematical formula}ska∈χ and for each {a mathematical formula}c∈conditions(a), {a mathematical formula}(last(c,ska)&lt;ska)∈PrecedencesLAD(χ,P).
        </list-item>
        <list-item label="3.">
         For each {a mathematical formula}skast∈χ and for each overall condition {a mathematical formula}〈(sta,eta)⋁i=1nfi=vi〉 of action a, {a mathematical formula}{(sj&lt;skast)|sj∈⋃i=1ndel(fi,vi),j&lt;k}⊆PrecedencesLAD(χ,P).
        </list-item>
        <list-item label="4.">
         For each {a mathematical formula}skaet∈χ and for each overall condition {a mathematical formula}〈(sta,eta)⋁i=1nfi=vi〉 of action a, {a mathematical formula}{(skaet&lt;sj)|sj∈⋃i=1ndel(fi,vi),k&lt;j}⊆PrecedencesLAD(χ,P).
        </list-item>
       </list>
       <paragraph>
        For example, consider the following abstract plan for the running example of Section 3.2.{a mathematical formula} The abstract plan is the same as {a mathematical formula}χex defined in the previous section, but we shuffled the positions of {a mathematical formula}s2visible:=T, {a mathematical formula}s3hot:=F and {a mathematical formula}s4moveet. For this abstract plan, the Total Order approach would construct an STNU that is not strongly controllable (nor Consistent) because the {a mathematical formula}visible:=T TIL must happen before the {a mathematical formula}hot:=F one. However, there is no causal relation between the two TILs (they operate on different variables) nor between the changes to the hot variable and the starting of the {a mathematical formula}trans action. In this sense, the algorithm in [38] would not introduce a precedence requirement from {a mathematical formula}s3hot:=F to {a mathematical formula}s2visible:=T, nor from {a mathematical formula}s4moveet to {a mathematical formula}s2visible:=T; leaving to the scheduler the task of finding a suitable order. In this view, the example abstract plan would correctly generate the plan {a mathematical formula}πex. In Fig. 5, we show the STNU produced by the LAD approach.
       </paragraph>
       <paragraph>
        This encoding is able to find a plan in many situations even in the presence of uncertainty, but it is not complete in general. For example, it fails on the problem of Fig. 4: the encoding greedily assumes that the last achiever is the one that must be preserved in the form of a causal link; in reality there may be other achievers that could be used instead. Just as in the previous case, if {a mathematical formula}χ=〈⋯,siaet,⋯,sjbet,⋯〉, then we impose the constraint {a mathematical formula}siaet&lt;bet because {a mathematical formula}siaet is the last achiever of p (required by {a mathematical formula}sjbet). Instead, if {a mathematical formula}χ=〈⋯,sjbet,⋯,siaet,⋯〉, we impose the constraint {a mathematical formula}sjbet&lt;siaet because {a mathematical formula}sjbet is the last achiever of q (required by {a mathematical formula}siaet).
       </paragraph>
      </section>
      <section label="5.2.3">
       <section-title>
        Disjunctive reordering encoding
       </section-title>
       <paragraph>
        In order to obtain sound and complete reasoning, we need to relax the total order produced by the state-space search, retaining the precedence constraints needed to ensure plan validity. However, we must be careful to not over-constrain the TNU, otherwise we may discard valid plans. A solution is to consider all the reorderings [6] of the given plan that are causally sound: we build a set of (disjunctive) precedence constraints in such a way that all the orderings fulfilling the constraints are causally sound. We call the approach using these precedence constraints Disjunctive Reordering (DR ) and formally define it below. We show that, given a partial plan χ, using DR to construct the precedences in Algorithm 2, yields a complete technique for STPUD.
       </paragraph>
       <paragraph>
        Given a variable f, a value v and a pair of action instances a and r of χ, we define the disjunctive temporal constraint {a mathematical formula}ρ(f,v,a,r) as follows.{a mathematical formula}
       </paragraph>
       <paragraph>
        Intuitively, for a condition {a mathematical formula}c=˙〈f=v〉, if a is an achiever of c and r is a step having c as precondition, {a mathematical formula}ρ(f,v,a,r) holds if a was the last achiever of c before r. We now define the precedence constraints induced by the DR approach, indicated as {a mathematical formula}PrecedencesDR(χ,P). As before, {a mathematical formula}s0 and {a mathematical formula}sn+1, represent the initial state and the goal condition, respectively.
       </paragraph>
       <paragraph label="Definition 13">
        Given {a mathematical formula}χ=〈s0,⋯,sn+1〉, {a mathematical formula}PrecedencesDR(χ,P) is as follows.
       </paragraph>
       <list>
        <list-item label="1.">
         {a mathematical formula}{(s0&lt;si),(si&lt;sn+1)|i∈[1,n]}⊆PrecedencesDR(χ,P).
        </list-item>
        <list-item label="2.">
         For each {a mathematical formula}ska∈χ and for each {a mathematical formula}⋁i=1nfi=vi∈conditions(a), the following constraints belong to {a mathematical formula}PrecedencesDR(χ,P):
        </list-item>
        <list-item label="3.">
         For each {a mathematical formula}skast∈χ and its corresponding {a mathematical formula}swaet∈χ and for each overall condition {a mathematical formula}〈(sta,eta)⋁i=1nfi=vi〉 of the action a, {a mathematical formula}⋁i=1n⋀sj∈⋃i=1ndel(fi,vi)((sj&lt;skast)∨(sj&gt;swaet).
        </list-item>
       </list>
       <paragraph>
        Intuitively, constraint 2a says that at least one step {a mathematical formula}sj having as effect one of the disjuncts of the precondition of step {a mathematical formula}ska occurs before {a mathematical formula}ska. Constraint 2b says that there is at least one precondition disjunct {a mathematical formula}c=˙〈f=v〉 of action a such that if {a mathematical formula}sj is the last achiever for c, between {a mathematical formula}sj and {a mathematical formula}ska there must be no action instance falsifying c. Overall conditions cannot be canceled between their extremal time point markers (constraint 3).
       </paragraph>
       <paragraph>
        The following theorem states that DR is sound and complete. We give the full proof of the theorem in Appendix A.
       </paragraph>
       <paragraph label="Theorem 3">
        DR completenessGiven a STPUD problem P admitting a valid strong plan σ, if DR is used,Algorithm 2terminates with a valid strong plan.
       </paragraph>
       <paragraph>
        The intuition is that in DR, the disjunctions encode all reorderings that are causally sound in the form of a DTNU, allowing the scheduler to re-arrange the action instances independently of the total ordering of χ. In fact, the precedence constraints generated by this approach are independent of the order of the steps in χ; practically χ is treated as a multi-set. Therefore, it is possible that this approach will generate and reject the same DTNU multiple times. In principle, it would be possible to cache these DTNUs and require that the underlying plan enumeration avoid the same multi-set of actions directly, but we leave these technical considerations and improvements for future work.
       </paragraph>
       <paragraph>
        We note that the set of precedence constraints generated by the DR approach, conjoined with the duration constraints, yields a TNU that is not formally a DTNU. This is because of the use of strict inequalities and negations that are not expressible in the DTNU framework. However, if we take the PDDL 2.1 semantics, this is not a problem because this semantics prescribes that there is always a minimal time quantum (called ϵ) that is required to separate two steps: each constraint {a mathematical formula}si&gt;sj can then be rewritten as {a mathematical formula}si−sj≥ϵ, and negations can be handled by reversing the inequalities (e.g. {a mathematical formula}¬(si&gt;sj) is equivalent to {a mathematical formula}(si≤sj)). Therefore, we can encode these constraints as a proper DTNU. Moreover, we remark that the strong controllability techniques presented in [11] are applicable even in the presence of strict inequalities.
       </paragraph>
       <paragraph>
        The strong controllability of a DTNU is an NP-Hard problem [5] (and the same is true for the generalized DTNU with strict inequalities), thus the use of this encoding is quite costly; however, DR is important as it overcomes the incompleteness limitation of the other encodings.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="6">
     <section-title>
      Compiling STPUD into temporal planning
     </section-title>
     <paragraph>
      In this section, we present our compilation technique, which can be used to reduce any planning instance P having duration uncertainty into a temporal planning instance {a mathematical formula}P′ in which all actions have controllable durations. The translation guarantees that P is solvable if and only if {a mathematical formula}P′ is solvable, and it fully supports the Unc-Arbit problem class. Moreover, given any plan for {a mathematical formula}P′ we can derive a plan for P. This approach comes at the cost of duplicating some of the variables in the domain, but allows for the use of off-the-shelf temporal planners.
     </paragraph>
     <section label="6.1">
      <section-title>
       Formal compilation
      </section-title>
      <paragraph>
       The intuition behind the translation is that we are representing the uncertainty about duration as uncertainty about the values of variables during certain action intervals. In practice, we use additional variables to encode in a single execution all the possible uncertain executions of the STPUD. In a sense, this is analogous to the expansion of a universal quantifier in logic: we make sure that all the possible realizations of the quantified variable are satisfied by a single model.
      </paragraph>
      <paragraph>
       Consider for example the {a mathematical formula}transmit (i.e., {a mathematical formula}trans) action in our example, and suppose it is scheduled to start at time k. Let v be the value of {a mathematical formula}sent at time {a mathematical formula}k+5; since {a mathematical formula}transmit has an at-end effect {a mathematical formula}〈[ettrans]sent:=T〉, we know that the value of the variable {a mathematical formula}sent during the interval {a mathematical formula}(k+5,k+8] will be either v or T depending on the duration of the action. After time {a mathematical formula}k+8 we are sure that the effect took place, and we are sure of the value of {a mathematical formula}sent until another effect is applied.{sup:15} Since in STPUD the plan cannot take advantage of observed durations at run-time, we need to consider the uncertainty in the value of {a mathematical formula}sent and produce a plan that works for all the possible uncertain values. Since {a mathematical formula}sent could appear as a condition of another action (or as a goal condition, as in our example) we must rewrite such conditions to be true only if the value of {a mathematical formula}sent is certain to be the required value, or if either value will satisfy the condition. To achieve this, we create an additional variable {a mathematical formula}sentσ (called the shadow variable of{a mathematical formula}sent). This secondary variable stores the alternative value of {a mathematical formula}sent during uncertainty periods. When there is no uncertainty in the value of {a mathematical formula}sent, both {a mathematical formula}sent and {a mathematical formula}sentσ will have the same value. In this way, all the conditions involving {a mathematical formula}sent can be rewritten in terms of {a mathematical formula}sent and {a mathematical formula}sentσ to ensure they are satisfied by both the values.
      </paragraph>
      <paragraph>
       In general, our translation rewrites a STPUD problem {a mathematical formula}P=˙〈V,I,T,G,A〉 into a new planning instance {a mathematical formula}P′=˙〈V′,I′,T′,G′,A′〉 that does not contain actions with uncontrollable duration.
      </paragraph>
      <section label="6.1.1">
       <section-title>
        Uncertain variables
       </section-title>
       <paragraph>
        The first step is to identify the set of variables {a mathematical formula}L⊆V that appear as effects of uncontrollable actions and are executed at a time depending on the end of the action.{a mathematical formula} Intuitively, this is the set of variables that can possibly have uncertain value during plan execution. A variable that is modified only at times linked to the start of actions or by timed initial literals cannot be uncertain: neither the starting time of actions nor the timed initial literals can be uncertain in our model. In our running example, the set L is the set {a mathematical formula}{sent,pos}.
       </paragraph>
       <paragraph>
        We now define the set {a mathematical formula}V′ as the original variables V plus a shadow variable for each variable appearing in L.{a mathematical formula} We use the pair of variables f and {a mathematical formula}fσ to represent uncertainty: if {a mathematical formula}f=fσ we know that there is no uncertainty in the value of f, while if {a mathematical formula}f≠fσ we know that the actual value of f in the original problem is either f or {a mathematical formula}fσ.
       </paragraph>
      </section>
      <section label="6.1.2">
       <section-title>
        Disjunctive conditions
       </section-title>
       <paragraph>
        At the end of Section 3, we outlined the reason why existing approaches for compiling away disjunctive conditions will not work with uncontrollable action durations. To rewrite a condition {a mathematical formula}c=˙〈[(stc,etc)]⋁i=1nfi=vi〉 we need to ensure that at each time in which the condition must hold, the set of disjuncts for at least one variable {a mathematical formula}fi in c is satisfied by the values of both {a mathematical formula}fi and {a mathematical formula}fiσ. When there is only one disjunct {a mathematical formula}fi=vi for the variable {a mathematical formula}fi, this requires that both {a mathematical formula}fi and {a mathematical formula}fiσ have the value {a mathematical formula}vi. However, if c contains multiple disjuncts for a variable {a mathematical formula}fi, say {a mathematical formula}fi=vi1∨fi=vi2, this condition will be satisfied whenever both {a mathematical formula}fi and {a mathematical formula}fiσ have values in the set {a mathematical formula}{vi1,vi2}. To accomplish this, we define an auxiliary function {a mathematical formula}θ(ψ) that takes a single disjunctive condition without timing information and returns a set of untimed disjunctive conditions.{a mathematical formula} with{a mathematical formula} where {a mathematical formula}ϕ[f→fσ] indicates logical substitution of variable f with variable {a mathematical formula}fσ in formula ϕ.
       </paragraph>
       <paragraph>
        Using this, the condition of the {a mathematical formula}trans action, {a mathematical formula}pos=l2, is translated as the two conditions {a mathematical formula}pos=l2 and {a mathematical formula}posσ=l2. Analogously, assuming that both f and g are in L, a given condition {a mathematical formula}(f=T)∨(g=F) in P is translated by function θ as the set of conditions {a mathematical formula}{(f=T)∨(g=F), {a mathematical formula}(fσ=T)∨(g=F),(f=T)∨(gσ=F),(fσ=T)∨(gσ=F)} in {a mathematical formula}P′. The intuition behind θ is as follows. Semantically, a condition is satisfied at time t if the evaluation of the variables at time t satisfies the condition. If some variables are uncertain, then the condition must be satisfied by all the possible values of the variables at time t. In our rewriting, we know that at each time the value of an uncertain variable f in the original problem is uncertain between the value of f and the value of {a mathematical formula}fσ in the rewritten problem. So, we must ensure that a condition is valid for every possible combination of both the f value and the {a mathematical formula}fσ value, and θ produces a set of conditions that exactly ensures this property.
       </paragraph>
      </section>
      <section label="6.1.3">
       <section-title>
        Uncertain temporal intervals
       </section-title>
       <paragraph>
        We also need to identify the temporal interval in which the value of a given variable can be uncertain. Given an action a with uncertain duration {a mathematical formula}da in {a mathematical formula}[l,u], let {a mathematical formula}λ(t) and {a mathematical formula}ν(t) be the earliest and latest possible times at which an effect at {a mathematical formula}t=˙eta′−δ may happen, i.e. {a mathematical formula}λ(t)=˙sta′+l−δ and {a mathematical formula}ν(t)=˙sta′+u−δ. Both functions are equal to {a mathematical formula}sta′+δ if {a mathematical formula}t=˙sta+δ.
       </paragraph>
       <paragraph>
        For example, consider the effect {a mathematical formula}e1=˙〈[ettrans]sent:=T〉 of action {a mathematical formula}trans. We know that the duration of transmit is uncertain in {a mathematical formula}[5,8], therefore the effect could occur at any time between {a mathematical formula}λ(ettrans)=˙sttrans′+5 and {a mathematical formula}ν(ettrans)=˙sttrans′+8 and the {a mathematical formula}sent variable has an uncertain value within that interval.
       </paragraph>
      </section>
      <section label="6.1.4">
       <section-title>
        Uncontrollable actions
       </section-title>
       <paragraph>
        For each uncontrollable action {a mathematical formula}a=˙〈[l,u],Ca,Ea〉) in {a mathematical formula}Au in the original model we create a new action {a mathematical formula}a′=˙〈[u],Ca′,Ea′〉 in {a mathematical formula}Ac′. Specifically, we first fix the maximal duration u as the only allowed duration for {a mathematical formula}a′ and then add appropriate effects and conditions during the action to capture the uncertainty.
       </paragraph>
       <paragraph>
        The effects {a mathematical formula}Ea′ are partitioned in two sets {a mathematical formula}Ea′l and {a mathematical formula}Ea′u to capture possible values within the uncertain action execution duration. The conditions {a mathematical formula}Ca′ are also composed of two elements: the rewritten conditions {a mathematical formula}Ca′R and the conditions added to protect the new effects {a mathematical formula}Ca′E (thus {a mathematical formula}Ca′=˙Ca′R∪Ca′E).
       </paragraph>
       <paragraph>
        Rewritten conditions{a mathematical formula}Ca′R. Controllable conditions are compiled by rewriting existing action conditions by means of the θ function. The intervals specifying the duration of the conditions are preserved as they are written in the original model. However, since the action duration is now set to its maximum, the effective duration of conditions is “stretched” to match the maximal duration (this is because temporal anchors such as {a mathematical formula}sta and {a mathematical formula}eta are interpreted over the new maximal duration of the action).{a mathematical formula} Here we keep the interval type: for example a {a mathematical formula}[t1,t2) interval gets translated into {a mathematical formula}[λ(t1),ν(t2)).
       </paragraph>
       <paragraph>
        For example, the set {a mathematical formula}Ctrans′R for the {a mathematical formula}trans action is: {a mathematical formula}{〈[sttrans′,sttrans′+8]pos=l2〉, {a mathematical formula}〈[sttrans′,sttrans′+8]posσ=l2〉, {a mathematical formula}〈[sttrans′,sttrans′+8]visible=T〉}. This requires variables {a mathematical formula}visible, pos and {a mathematical formula}posσ to be true throughout the execution of {a mathematical formula}trans′.
       </paragraph>
       <paragraph>
        Compiling action effects. The effects on variables in L of the original action are duplicated: both the affected variable f and its shadow {a mathematical formula}fσ are modified, but at different times. We first identify the earliest and latest possible times at which an effect can happen due to the duration uncertainty. We then apply the effect on {a mathematical formula}fσ at the earliest time point {a mathematical formula}λ(t), and at the latest time point {a mathematical formula}ν(t) we re-align f and {a mathematical formula}fσ by also applying the effect on f:{a mathematical formula}{a mathematical formula} For example, the {a mathematical formula}trans action has {a mathematical formula}Etrans′l=˙{〈[sttrans′+5]sentσ:=T〉} and {a mathematical formula}Etrans′u=˙{〈[sttrans′+8]sent:=T〉}.
       </paragraph>
       <paragraph>
        Additional conditions{a mathematical formula}Ca′E. Let {a mathematical formula}t=˙eta−δ be the time of an at-end effect that affects the value of f. In order to prevent other actions from changing the value of f during the interval {a mathematical formula}(λ(t),ν(t)] where the value of f is uncertain, we add a condition in {a mathematical formula}Ca′E to maintain the value of {a mathematical formula}fσ throughout the uncertain duration {a mathematical formula}(λ(t),ν(t)].{a mathematical formula} Since the effect on {a mathematical formula}fσ (belonging to {a mathematical formula}Ea′l) is applied at time {a mathematical formula}λ(t), the condition is satisfied immediately after the effect and we want to avoid concurrent modifications of either f or {a mathematical formula}fσ until the uncertainty interval ends at {a mathematical formula}ν(t).{sup:16}
       </paragraph>
       <paragraph>
        For example, the {a mathematical formula}trans action gets the added condition {a mathematical formula}Ctrans′E=˙{〈(sttrans+5,sttrans+8]sentσ=T〉}. The compilation of the {a mathematical formula}trans action is depicted in Fig. 6.
       </paragraph>
      </section>
      <section label="6.1.5">
       <section-title>
        Controllable actions
       </section-title>
       <paragraph>
        Controllable actions are much simpler. For each {a mathematical formula}a=˙〈[l,u],Ca,Ea〉∈Ac we introduce a replacement action {a mathematical formula}a′=˙〈[l,u],Ca′,Ea′〉∈Ac′, in which: (1) each condition in C containing variables in L is rewritten to check the values of both those variables and their shadows, and (2) each effect on a variable in L is applied to the variable and its shadow.{a mathematical formula}{a mathematical formula}
       </paragraph>
      </section>
      <section label="6.1.6">
       Initial state I
       <paragraph>
        The initial state is handled by initializing variables and their corresponding shadow variables in the same way as in the original problem.{a mathematical formula} Intuitively, each initial condition on original variables is kept, and all shadow variables are initialized exactly like the corresponding original variable.
       </paragraph>
       <paragraph>
        For example, the initial state of our running problem is the original initial state plus {a mathematical formula}{sentσ=F,posσ=l1}.
       </paragraph>
      </section>
      <section label="6.1.7">
       <section-title>
        Timed initial literals
       </section-title>
       <paragraph>
        Timed Initial Literals {a mathematical formula}T′ are set similarly to controllable effects.{a mathematical formula} In our example, we do not have timed initial literals operating on uncertain variables, thus {a mathematical formula}T′=˙T.
       </paragraph>
      </section>
      <section label="6.1.8">
       <section-title>
        Goal conditions
       </section-title>
       <paragraph>
        The goal conditions G are augmented to consider both the original and shadow variables.{a mathematical formula} In our example, the set {a mathematical formula}G′ becomes {a mathematical formula}{(sent=T),(sentσ=T)}.
       </paragraph>
      </section>
     </section>
     <section label="6.2">
      <section-title>
       Example
      </section-title>
      <paragraph>
       The compiled STPUD obtained by applying the compilation approach to the rover running example is as follows.{a mathematical formula}
      </paragraph>
     </section>
     <section label="6.3">
      <section-title>
       Discussion
      </section-title>
      <paragraph>
       This compilation is sound and complete. Theorem 4 states that the original problem is solvable if and only if the resulting problem is solvable.
      </paragraph>
      <paragraph label="Theorem 4">
       Soundness and completenessLet{a mathematical formula}P=˙〈V,I,T,G,A〉be a planning instance and{a mathematical formula}R=˙〈V′,I′,T′,G′,A′〉be its translation. P has a strong plan π if and only if R has a temporal plan σ.
      </paragraph>
      <paragraph>
       The proof we give in Appendix B is constructive and shows that any plan for the rewritten temporal planning problem is automatically a strong plan for the original problem (with the obvious mapping from the rewritten to the original actions).
      </paragraph>
      <paragraph>
       The compilation produces a problem that has: (i) at most twice the number of variables of the original problem, (ii) at most twice the initial and timed assignments and (iii) exactly the same number of actions. The only point in which the compilation might produce exponentially large formulae is in the application of the θ function, which is exponential in the number of disjuncts constraining variables appearing in L. Since this only happens for disjunctive conditions, and the number of disjuncts is typically small, this is normally not a serious issue in practice.
      </paragraph>
      <paragraph>
       Finally, we remark that any technique can be used to solve the compiled temporal planning problem, and any valid plan corresponds to a strong plan. Therefore, this technique allows for the mix of controllability and flexibility: if we employ a planner that is able to produce flexible solutions (i.e. an STN of possible solutions), all those solutions will be valid strong plans. This is an example of flexible-strong planning.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Worst-case simplification
     </section-title>
     <paragraph>
      As we discussed in Section 3.4, it is in general impossible to solve the STPUD problem by considering uncontrollable actions as taking either the maximal or minimal duration of their duration interval: this motivated the development of S-FSSTP and the compilation approaches we presented in Section 6. However, under some specialized conditions, it is possible to soundly remove uncertainty simply by fixing the duration of an action to its maximal or minimal duration. In this section, we report a set of sufficient conditions that can be statically checked on a planning instance to simplify the uncertainty of an uncontrollable action.
     </paragraph>
     <section label="7.1">
      <section-title>
       Maximal-duration simplification
      </section-title>
      <paragraph>
       In order to soundly lengthen an uncontrollable action {a mathematical formula}a=˙〈[l,u],C,E〉 to its maximum duration u without changing its conditions or its effects, we need to make sure that there are no other action conditions or effects (or TILs) that could interfere with conditions or effects of the action a that are specified relative to the end time of a. This means that any such threatening action conditions or effects (or TILs) must be impossible during the time window when the end-relative condition or effect might occur. For example, if a has duration in {a mathematical formula}[l,u] and has an end-relative effect {a mathematical formula}〈[eta−δ]f:=v〉, no other action could have a condition or effect on f that might occur within {a mathematical formula}[l−δ,u−δ]. Likewise, no TIL on f could occur within {a mathematical formula}[l−δ,u−δ].
      </paragraph>
      <paragraph>
       To make this more precise, let {a mathematical formula}a′ be the extension of action a to its maximal duration u. For this extension to be sound, we require:
      </paragraph>
      <list>
       <list-item label="1.">
        For each end-relative effect {a mathematical formula}〈[eta′−δ]f:=v〉 of {a mathematical formula}a′:
       </list-item>
       <list-item label="2.">
        For each end-relative condition {a mathematical formula}〈[eta′−δ1,eta′−δ2)]ϕ〉:
       </list-item>
       <list-item label="3.">
        For each end-relative condition {a mathematical formula}〈(eta′−δ1,eta′−δ2)]ϕ〉:
       </list-item>
      </list>
      <paragraph>
       Some notes are in order. First, the difference between cases (2) and (3) above is whether the condition interval is closed or open on the left, which determines whether the restriction needs to be open or closed on the right. Whether the condition interval is closed or open on the right does not affect the requirements. Second, it might seem like the interval in condition (2) above should be {a mathematical formula}[l−δ1,u−δ2)] rather than the sub-interval {a mathematical formula}[l−δ1,u−δ1). However the extended action {a mathematical formula}a′ still has the condition ϕ over the interval {a mathematical formula}[eta′−δ1,eta′−δ2)] and since {a mathematical formula}a′s duration is u, the interval from {a mathematical formula}[u−δ1,u−δ2)] is covered by the new action. As a result, we only need to guard against a threat that might occur within {a mathematical formula}[l−δ1,u−δ2). Similarly for case (3). Finally, it might seem that we also need to consider conditions of the form {a mathematical formula}〈[(sta+δ1,eta−δ2)]ϕ〉. However, this is not needed because the condition for {a mathematical formula}a′ is still over the interval {a mathematical formula}[(sta′+δ1,eta′−δ2)] which covers the required interval. This also applies to overall conditions since the extended action {a mathematical formula}a′ still has an overall condition that covers the maximum possible duration of the original action a.
      </paragraph>
      <paragraph>
       While the above criteria are fairly general, they are difficult to apply. In particular, showing that some condition or effect of another action cannot occur within some specific subinterval of action {a mathematical formula}a′ may require computationally complex reasoning about the ways in which the actions can overlap. A more restrictive, but more practical set of conditions is:
      </paragraph>
      <list>
       <list-item label="1.">
        For each end-relative effect {a mathematical formula}〈[eta′−δ]f:=v〉 of {a mathematical formula}a′:
       </list-item>
       <list-item label="2.">
        For each end-relative condition {a mathematical formula}〈[(eta′−δ1,eta−δ2)]ϕ〉 of {a mathematical formula}a′:
       </list-item>
      </list>
      <paragraph>
       An action b cannot overlap with action {a mathematical formula}a′ if any of the following hold:
      </paragraph>
      <list>
       <list-item label="•">
        b has an overall condition inconsistent with an overall condition of {a mathematical formula}a′;
       </list-item>
       <list-item label="•">
        b cannot start during {a mathematical formula}a′ and {a mathematical formula}a′ cannot start during b. This holds if a start condition or effect of b is incompatible with an overall condition of {a mathematical formula}a′ and a start condition or effect of {a mathematical formula}a′ is incompatible with an overall condition of b;
       </list-item>
       <list-item label="•">
        b cannot end during {a mathematical formula}a′ and {a mathematical formula}a′ cannot end during b. This holds if an end condition or effect of b is incompatible with an overall condition of {a mathematical formula}a′ and an end condition or effect of {a mathematical formula}a′ is incompatible with an overall condition of b.
       </list-item>
      </list>
      <paragraph>
       Two conditions are incompatible if they are logically inconsistent. An effect {a mathematical formula}〈f:=v〉 is incompatible with a condition ϕ if ϕ contains f. Two effects {a mathematical formula}〈f1:=v1〉 and {a mathematical formula}〈f2:=v2〉 are incompatible if {a mathematical formula}f1=f2.
      </paragraph>
      <paragraph>
       These conditions can be checked syntactically for the actions in a domain, making this easy and efficient to implement.
      </paragraph>
      <section label="7.1.1">
       <section-title>
        Example
       </section-title>
       <paragraph>
        To clarify the rules for this simplification, let us consider the running example of Section 3.2. We show how the {a mathematical formula}transmit action in the example can be simplified by considering its maximal duration, while the {a mathematical formula}move action cannot be simplified.
       </paragraph>
       <paragraph>
        The {a mathematical formula}transmit action has only one effect: {a mathematical formula}〈[ettrans]sent:=T〉 and no other action nor TIL can change the {a mathematical formula}sent variable. Moreover, no action has a condition that depends on {a mathematical formula}sent, hence general condition (1) is satisfied. Finally, general conditions (2) and (3) are trivially satisfied because the {a mathematical formula}transmit action has no ending conditions. Therefore, all the conditions are satisfied and the example problem can be simplified as follows.{a mathematical formula} The resulting simplified problem now has one uncontrollable action and one controllable action, without any additional variables or conditions. Moreover, each plan for the resulting problem corresponds to a strong plan for the original problem (with the obvious removal of durations for the simplified actions in the plan).
       </paragraph>
       <paragraph>
        Let us now consider the {a mathematical formula}move action. In this case, condition (2) is violated, because the TIL {a mathematical formula}〈[15]hot:=F〉 affects the variable hot that appears in the condition {a mathematical formula}〈[etmove]hot=F〉. In fact, a plan starting the move action at time 1 would be valid in the simplified problem, but it does not yield a strong plan because the uncontrollable action {a mathematical formula}move could end at time 11 and the ending condition {a mathematical formula}〈[etmove]hot=F〉 would be unsatisfied. For this reason, the {a mathematical formula}move action cannot be simplified to its maximal duration.
       </paragraph>
      </section>
     </section>
     <section label="7.2">
      <section-title>
       Minimal-duration simplification
      </section-title>
      <paragraph>
       In order to soundly shorten an uncontrollable action {a mathematical formula}a=˙〈[l,u],C,E〉 to its minimum duration l, we need to make sure that there are no other action conditions or effects (or TILs) that could interfere with conditions or effects of the action a that are specified relative to the end time of a. This means that any such threatening action conditions or effects (or TILs) cannot occur during the time window when the end-relative condition or effect might actually occur if a takes more time than the minimum. For example, if a has duration in {a mathematical formula}[l,u] and has an end-relative effect {a mathematical formula}〈[eta−δ]f:=v〉, no other action could have a condition or effect on f that might occur within {a mathematical formula}[l−δ,u−δ]. Likewise, no TIL on f could occur within {a mathematical formula}[l−δ,u−δ].
      </paragraph>
      <paragraph>
       To make this more precise, let {a mathematical formula}a′ be the shortening of action a to its minimum duration l. For this simplification to be sound, we require:
      </paragraph>
      <list>
       <list-item label="1.">
        For each end-relative effect {a mathematical formula}〈[eta′−δ]f:=v〉 of {a mathematical formula}a′:
       </list-item>
       <list-item label="2.">
        For each end-relative condition {a mathematical formula}〈[(t,eta′−δ2]ϕ〉:
       </list-item>
       <list-item label="3.">
        For each end-relative condition {a mathematical formula}〈[(t,eta′−δ2)ϕ〉:
       </list-item>
      </list>
      <paragraph>
       Again, some notes are in order, similar to those for the maximal duration simplification case. First, the difference between cases (2) and (3) above is whether the condition interval is closed or open on the right, which determines whether the restriction needs to be open or closed on the left. Whether the condition interval is closed or open on the left does not affect the requirements. Likewise, whether the start of the condition interval is relative to the start or end of the action does not matter. Second, it might seem like the interval in condition (2) above should be {a mathematical formula}[(t,u−δ2] rather than the sub-interval {a mathematical formula}(l−δ2,u−δ2]. However the shortened action {a mathematical formula}a′ still has the condition ϕ over the interval {a mathematical formula}[(t,eta′−δ2] and since {a mathematical formula}a′s duration is l, the interval from {a mathematical formula}[(t,l−δ2] is covered by the new action. As a result, we only need to guard against a threat that might occur within {a mathematical formula}(l−δ2,u−δ2]. Similarly for case (3). Finally, the intervals mentioned in the above requirements often extend beyond the duration of the action {a mathematical formula}a′. For example, if action a has an end effect {a mathematical formula}〈[eta]f:=v〉 and is shortened to its minimum duration, the safety interval {a mathematical formula}[l,u] starts at the end of the shortened action {a mathematical formula}a′.
      </paragraph>
      <section label="7.2.1">
       <section-title>
        Example
       </section-title>
       <paragraph>
        As an example, consider the classical match-fusebox example. An action a lights a match producing the light needed to change a fuse by an action b as illustrated in Fig. 7. Suppose that the duration of a is uncertain in {a mathematical formula}[10,15] (because different matches burn differently), and suppose that b has an overall condition of having light (hence b must be contained in a). In this simple scenario, a can be simplified to its minimal duration because there are no other actions with threatening effects, and the only threatening condition is the overall condition of b, but it cannot happen during {a mathematical formula}[10,15] because b is now forced to occur within the shortened action {a mathematical formula}a′, hence b must start after the start of {a mathematical formula}a′ and must end before the end of {a mathematical formula}a′ at time {a mathematical formula}sta′+10.
       </paragraph>
       <paragraph>
        The catch here is that we need to ensure that the light-match action {a mathematical formula}a′ can only happen once. If {a mathematical formula}a′ ends at time {a mathematical formula}t+10 and we were to execute a second light-match {a mathematical formula}a2′ at time {a mathematical formula}t+12, it's possible that the end-effect {a mathematical formula}light:=false of {a mathematical formula}a′, could actually happen at the same time as the start-effect {a mathematical formula}light:=true of {a mathematical formula}a2′, violating the semantics (which prohibits simultaneous effects on a variable). In this case, the second light-match action {a mathematical formula}a2′ would be violating condition (1) above. If there were two fuses to change, and a single match is only sufficient for changing one fuse, the minimum duration simplification is problematic. If we used the shortened light-match action, we might think that the plan shown in Fig. 8 is valid. However, the first light-match could end after the second light-match starts, resulting in {a mathematical formula}light:=false during the second change-fuse action. It might seem that this could be fixed by a more sophisticated modeling of {a mathematical formula}light as a metric quantity that is increased at the beginning of light-match, and decreased at the end of light-match. However, even with this modeling, we would have to show that there is no upper bound on the amount of light that can occur, or that the maximum number of possible overlapping light-match actions cannot possibly exceed this bound. We would also need to show that no other possible action (like developing film) depends on the light being below a certain level. All of this illustrates the sophistication of the reasoning that may be required to shorten an action to its minimum duration.
       </paragraph>
      </section>
     </section>
     <section label="7.3">
      <section-title>
       Discussion
      </section-title>
      <paragraph>
       The conditions we listed above are sufficient to soundly simplify away uncontrollable durations to either the maximal or minimal duration.
      </paragraph>
      <paragraph>
       The lengthening conditions are much easier to satisfy than the conditions for shortening an action to its minimum duration. The reason for this is that the lengthening process extends overall conditions of an action a, which tends to prevent bad things from happening during {a mathematical formula}[l,u]. In contrast, the conditions for shortening an action are much harder to satisfy because they impose some outside-of-action requirements that are rarely met in practice, or are much more difficult to prove. A common source of problems for the minimum duration simplification is when the action being shortened can appear more than once in a plan, because such actions often interfere with themselves.
      </paragraph>
     </section>
    </section>
    <section label="8">
     <section-title>
      Experimental evaluation
     </section-title>
     <paragraph>
      We now empirically evaluate the approaches and simplifications we presented. First we discuss the experimental set-up, then we explain how to use PDDL 2.1 planners for dealing with the compilation output, and finally we discuss the results.
     </paragraph>
     <section label="8.1">
      <section-title>
       Experimental set-up
      </section-title>
      <paragraph>
       In order to enable the specification of durative actions with uncontrollable durations, we extended the PDDL 2.1 planning language syntax with the addition of the keyword uncontrollable-durative-action: the construct is analogous to the usual durative-action construct, but marks the action as uncontrollable. We refer to this extension of the language as PDDL-U.
      </paragraph>
      <paragraph>
       For testing, we adopted the temporal planning domains from the temporal track of the International Planning Competition in 2011 [39]: these domains are written in the PDDL 2.1 language. We modified them by making some actions uncontrollable, enlarging the duration intervals of actions, and created several versions of each domain. The resulting benchmark set is composed of a total of 901 planning problem instances. Since both the compilation and the simplification techniques manipulate the domain specifications and automated planners are quite sensitive to the input, we implemented a tool that randomly “scrambles” PDDL input problems. The tool always generates a problem instance that is logically equivalent to the original one, but it changes the order of actions, conditions and effects in the concrete specification. Using this tool, we performed each experiment 5 times (with different random seeds to obtain different “scramblings”), considering each run as a separate experiment. Thus, we are left with a virtual benchmark set of 4505 planning instances. We chose this approach because we realized that minimal variations in the ordering of actions or in the ordering of the conditions within an action produced very different performance. This sensitivity issue is highlighted in several papers in the literature [40]; we use this scrambling augmentation procedure to limit the bias due to sensitivity to the syntactic ordering in the problem.
      </paragraph>
      <paragraph>
       We implemented the direct approaches for the Unc-Extr problem class (described in Section 5) as an extension of the Colin planner [9]. The parser and the internal structures of Colin were modified to support the processing of this extension. We added three new schedulers to Colin, each implementing one of the defined encodings. The temporal solvers for strong controllability were implemented in C++, following the approach presented in [11], using the MathSAT [41] SMT solver as workhorse. Finally, the heuristic for the forward search planner was left unchanged.
      </paragraph>
      <paragraph>
       In the following, we write TO to refer to the encoding based on Total Ordering, LAD for the Last Achiever Deordering and DR for the Disjunctive Reordering.
      </paragraph>
      <paragraph>
       The compilation described in Section 6 was implemented as a Java translator that takes as input a PDDL-U specification and produces a plain PDDL 2.1 temporal planning problem. The formal translation is designed to generate a Ctrl-Arbit problem even when starting from an Unc-Extr instance. For this reason, the translator is equipped with a technique to remove intermediate effects and conditions resulting in a PDDL 2.1 description. We discuss this technique in detail in Section 8.2. Since the direct approaches have been implemented using a modification of the Colin planner, we also used Colin to solve the temporal planning instances produced by the compilation.
      </paragraph>
      <paragraph>
       Finally, the maximal-duration simplification has been implemented as a Java re-writer that takes as input a PDDL-U instance and produces a simplified PDDL-U specification. We note that in some cases the simplifier is able to remove all the temporal uncertainty from the problem and, thanks to the way PDDL-U is defined, a plain PDDL 2.1 planning problem is produced by the simplifier. In these experiments we did not attempt to use the minimal-duration simplification.
      </paragraph>
      <paragraph>
       The implemented tools and the possible data-flows are depicted in Fig. 9.
      </paragraph>
      <paragraph>
       All the experiments were executed on a Scientific Linux 64 bit, 12 core Intel Xeon at 2.67 GHz, with 96 GB RAM. We used a timeout of 10 minutes, and a memory limit of 8 GB.
      </paragraph>
      <paragraph>
       All the tools and the benchmark set can be downloaded from http://es.fbk.eu/people/amicheli/resources/aij-stpud.
      </paragraph>
     </section>
     <section label="8.2">
      <section-title>
       Dealing with intermediate effects and conditions
      </section-title>
      <paragraph>
       Given a PDDL-U planning instance, the compilation described in Section 6 produces an instance having no uncontrollable durations, but with intermediate effects and conditions. In particular, for the Unc-Extr case that is expressible by PDDL-U, the algorithm introduces an intermediate effect and a durative condition for each uncontrollable action. Unfortunately, the PDDL 2.1 language does not support these features natively. Therefore, we need to get rid of these characteristics before being able to use PDDL 2.1 planners on the result of our compilation.
      </paragraph>
      <paragraph>
       In the following we assume a PDDL semantics: we require a minimum time quantum called ϵ forcing each pair of time points in the plan to be separated by at least ϵ time.
      </paragraph>
      <paragraph>
       The papers [42], [34], [31] present some ideas on how to encode intermediate events in PDDL 2.1. In particular, [34] assumes actions have a fixed duration and proposes some “standard” constructs to encode several features as polynomial transformations of the PDDL domain. The work in [31] uses the construction in [42] to develop a more general translation from ANML to PDDL.
      </paragraph>
      <paragraph>
       The clip-action construction described in [34] allows one to force two or more time points (either the start or the end of actions) to happen simultaneously or to be separated by exactly ϵ. The construction uses one additional action with duration 2ϵ (or 3ϵ in case an ϵ separation is required). Each time point {a mathematical formula}pi being clipped requires a special effect {a mathematical formula}〈fpi:=T〉 where {a mathematical formula}fpi is a fresh Boolean variable. The clip action for clipping the points {a mathematical formula}{p1,⋯,pn} is defined as follows.{a mathematical formula}
      </paragraph>
      <paragraph>
       Intuitively the clip is an action that sets a fresh, dummy variable {a mathematical formula}fs to true when it starts and resets it upon termination. We can now clip time points to impose the condition {a mathematical formula}fs=T exactly at those time points. Since no two events can happen with distance lower than ϵ, the clip guarantees simultaneous execution. If the time points being clipped have mutually-exclusive effects, we need a clip of duration 3ϵ to achieve an ϵ separation of the two time points. The special effects on the {a mathematical formula}fpi variables are needed to prevent a clip from being instantiated without clipping all the needed time points.
      </paragraph>
      <paragraph>
       Fig. 10 shows an example of the construction for the action {a mathematical formula}τ′ derived from the running example action τ by means of the uncertainty compilation.
      </paragraph>
      <paragraph>
       This construction can be used to encode intermediate effects and conditions by splitting an action duration in pieces, one for each sub-interval of the action duration delimited by an intermediate effect or condition bound. This technique works perfectly for fixed duration actions (note that this is enough for the outcome of the translation as each uncontrollable action is compiled as a fixed-duration action and no other intermediate effects or conditions are artificially added).
      </paragraph>
      <paragraph>
       The clip action is not the only construction that can be used to encode intermediate effects and conditions. A second relevant technique [42], [31] uses a container action that spans the whole duration of the original action and exactly contains a number of sub-actions, one for each sub-interval. This paradigm is depicted in Fig. 11.
      </paragraph>
      <paragraph>
       Both these techniques have significant overhead: to remove an intermediate effect or condition, a single action is replaced with three actions, increasing the plan length; moreover, additional variables are added to the problem description to support the construction, widening the search space.
      </paragraph>
      <paragraph>
       We improved these two classical constructions by developing a modification to guide the planners and limit this overhead. The fundamental observation is that both these encodings are designed in such a way that when the first action of the construction is started (the first piece in the clip action construction and the container in the other), the planner has no choice but to instantiate the rest of the construction. However, nothing is telling the planner to avoid useless search on branches where the structure has not been correctly instantiated. We can exploit the PDDL 2.1 features to force the planner into the correct choice: we call the resulting technique “exclusion literal simplification”.
      </paragraph>
      <paragraph>
       We start by describing the idea on the clip-action construction. Suppose we are clipping two actions a and b with a clip c. We introduce a fresh Boolean variable {a mathematical formula}fce that is initially true and is falsified during the execution of the clip c with appropriate start and end effects. Then, {a mathematical formula}fce becomes a condition for starting and terminating each action in the problem except for the clip c and the two clipped actions a and b. Moreover {a mathematical formula}fce is a condition for starting a and for terminating b. In this way, once c is inserted in the plan, the search has no choice but to immediately start b, because no other successor is possible given that b is the only action that can be started during c. This additional construction is applied for every clip-action in the instance to prune the search in all the cases.
      </paragraph>
      <paragraph>
       The same idea can also be applied to the container construction by imposing mutual exclusion on the “holes” within the container action to force the planner to immediately expand the next action in the sequence. All these techniques have been implemented as a post-processing of the compilation result and are evaluated in the following sections.
      </paragraph>
     </section>
     <section label="8.3">
      <section-title>
       Overall results
      </section-title>
      <paragraph>
       In the following, Colin-Clip refers to the compilation approach solved with the Colin planner using the clip technique to remove intermediate effects. Colin-Clip-MuxLiterals indicates the same but with the addition of mutual exclusion literals to guide the solver. Similarly, Colin-Container and Colin-Container-MuxLiterals refer to the compilation techniques using the container construction to remove intermediate effects. The S-FSSTP techniques are referred to as S-FSSTP-TO, S-FSSTP-LAD and S-FSSTP-DR, for the TO, LAD and DR techniques, respectively.
      </paragraph>
      <paragraph>
       Fig. 12 gives an overview of the performance of the presented techniques in our experiments. First, we consider the direct approach obtained extending the FSSTP planning framework. We note how the LAD approach performs much better than the TO approach, which in turn performs better than the DR approach. In fact, LAD is able to solve almost twice as many instances as DR. However, both the LAD and TO techniques are not complete in general: it might be the case that a problem is reported as unsolvable when a strong plan exists. This situation never occurred in our experiments: in each instance the planner either returned a valid strong plan or did not terminate within the allowed time limit.
      </paragraph>
      <paragraph>
       For the compilation technique, we note how the performance dramatically depends on the technique used to compile away intermediate effects and conditions. The clip construction proved to be more effective than the container construction. Moreover, both the techniques benefit from the mutual exclusion improvement.
      </paragraph>
      <paragraph>
       In order to compare the compilation technique with the direct approach, we report in Fig. 13 the result of the best-performing compilation technique with the two native approaches. The results are mixed with no clear winner. This means that the two techniques exhibit a complementary behavior: on some instances the direct approach is vastly superior, on others it is beaten by the compilation. This is confirmed by the performance of the Virtual Best Solver (VBS) in Fig. 12: the performance of the VBS is obtained by taking the results of the fastest solver for each instance. The VBS line in the plot solves far more instances than any actual solver; hence, the various solvers that contribute to the VBS are able to solve different sets of instances.
      </paragraph>
      <paragraph>
       We analyzed several features of the instances without finding a clear correlation with the better solver. We leave the use of automated data mining techniques for the best solver prediction as future work.
      </paragraph>
      <section label="8.3.1">
       <section-title>
        Impact of worst-case simplification
       </section-title>
       <paragraph>
        We implemented the simplifier following the maximal-duration simplification described in Section 7. Since the simplification requires a mutual exclusion generator, we provided a simple generator based on syntactic rules. Moreover, to strengthen the mutual exclusion predicate we manually checked for all the domains that all the uncontrollable actions were mutually exclusive with themselves, and we forced this information in the mutual-exclusion generator.
       </paragraph>
       <paragraph>
        The pseudo-code of the generator is reported in Algorithm 3. The mutual exclusion rules are purely syntactic and only exploit the overall condition of the actions. The entry function MaxDurationSimplifiable returns ⊤ if the given action a can be simplified to its maximal duration. The function ConflictingActions returns the set of actions that have a condition or an effect conflicting with an ending effect of the given uncontrollable action. CheckMutexAssume implements the policy we described: all action are mutually exclusive with themselves. Finally, CheckMutex performs the syntactic check: in the code StartConditions, OverallConditions, and EndConditions return the set of starting, overall and ending conditions, respectively. Moreover, StartEffects and EndEffects return the set of starting and ending effects for the given action.
       </paragraph>
       <paragraph>
        We note that the generator is sound but incomplete: if two actions are marked as mutually exclusive, they are, but it might be the case that two actions are mutually exclusive but the generator fails to recognize this. This is acceptable in our framework, because if an uncontrollable action is not mutually exclusive with all the actions threatening its ending effects or conditions, the simplification is not applied and a sound and complete technique for dealing with uncertainty is used.
       </paragraph>
       <paragraph>
        We ran the benchmark tests with the simplification used as a pre-processor for all the techniques: the results are reported in Fig. 14, Fig. 15. We differentiate a technique from its version in which simplification is applied as pre-processing by adding a “+ Simp” to the technique name.
       </paragraph>
       <paragraph>
        The simplification turns out to be useful in all the cases but the LAD and TO approaches where it has virtually no effect. This is because there is little overhead in solving an STNU with a DTNU solver. The simplification technique removes some of the uncertainty, but only changes some time points from uncontrollable to controllable while keeping the same constraint structure.
       </paragraph>
       <paragraph>
        On the other hand, the simplification is very beneficial for the compilation approaches: this is because of two factors. First, converting a single uncontrollable action from an instance results in a reduction of the plan length in the compiled domain. In fact, each uncontrollable action gets translated into three controllable actions in the compilation. Second, all the additional variables needed for the intermediate effect construction of an uncontrollable action are removed if the action is simplified as controllable.
       </paragraph>
       <paragraph>
        In order to show the impact of the simplification on the solvers, we show a scatter plot of the DR and Colin-Clip-MuxLiterals approaches with and without the simplification pre-processing step (Fig. 16). The plots highlights that the simplification is either beneficial or neutral with very few detrimental cases.
       </paragraph>
       <paragraph>
        We also analyzed in detail the performance of the best-performing solvers for the compilation and direct approaches, all with the addition of simplification. We show the scatter plots in Fig. 17. As before, there is evident complementary behavior for the two approaches.
       </paragraph>
       <paragraph>
        Finally, Fig. 18 shows a comparison of the performance of all the solvers with the simplification enabled. The VBS + Simp line is calculated by taking, for each instance, the best performing solver among the others shown in the plot. Comparing this plot with Fig. 12, it is evident that the simplification technique is very effective for the compilation approaches, which are now able to beat the native techniques. Moreover, we still see that the virtual best solver is far more effective than any other technique; hence, there is still a strong partitioning of the instances in terms of the best solving technique. This plot also shows that taking a portfolio approach with the simplification, we can solve more instances than without the simplification. In fact, while the VBS solver is able to solve a total of 2052 instances, the VBS + Simp solver can handle 2597 instances within the timeout.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="9">
     <section-title>
      Conclusions and future work
     </section-title>
     <paragraph>
      In this paper we introduced the Strong Temporal Planning with Uncontrollable Durations (STPUD ) problem, which extends Temporal Planning to deal with actions having uncontrollable duration. We search for temporally strong solutions, i.e. plans that are guaranteed to achieve the goal regardless of the actual duration of the actions that are under the control of the execution environment.
     </paragraph>
     <paragraph>
      We presented two complementary approaches. The first one is based on the integration of a “classical” temporal planner with a solver for temporal networks with uncertainty. The second approach reduces any STPUD problem to a “classical” temporal planning problem, where the actions have controllable durations. Finally, we proposed a technique that is able to eliminate some of the uncontrollable durations by reasoning in terms of worst case execution. We implemented and experimentally evaluated the approaches. The results demonstrate the complementarity of the two planning methods, and of the effectiveness of the proposed optimizations.
     </paragraph>
     <paragraph>
      This work is a first step in a more comprehensive research effort on real-wold planning with durative actions. The target is a richer domain description language based on ANML [31], extended with uncertain durations, uncertain resource usage, and uncontrollable effects, all of which allow more natural representation of real-world domains and overcome the many limitations of PDDL. In particular, several directions can be explored.
     </paragraph>
     <paragraph>
      First, some interesting features, such as timed initial literals with uncontrollable time windows and conditional effects, are not included in the abstract language used in this paper because they are not fundamental to explain the characteristics of the approach. Timed initial literals have been modeled as fixed-time effects that happen exogenously in every plan, but we can allow TILs having a time window in which they can controllably or uncontrollably occur. Such a feature could be useful to model unpredictable events and can be easily handled in our framework by considering each TIL as the end effect of an action (controllable or uncontrollable) that must be started at time 0. In this view, both the approaches we presented can be extended to deal with non-fixed or even uncontrollable TILs. Conditional effects are another useful feature that can be included in our language. Unlike uncertainty in TILs, this feature requires more adaptation in order to be included in our framework. The compilation approach we presented is based on the assumption that at each point in time while executing a plan, each variable can be either certain, meaning that we know the exact value, or uncertain between exactly two values. Moreover, we know that outside of uncertainty intervals, all the variables are certain. The introduction of conditional effects changes this situation: if a conditional effect with a condition on variable f takes place while f is uncertain, the outcome of the effect is uncertain. This uncertainty is not removed at the end of the uncertainty intervals and multiple conditional effects can increase the cardinality of the set of possible uncertain values. One possible idea to deal with this problem is to extend our compilation to allow a bounded number of uncertain values for each variable, so that we can accommodate a finite number of uncertain effect occurrences. This approach would maintain the soundness of the compilation, but sacrifice completeness.
     </paragraph>
     <paragraph>
      Another interesting question is whether a compilation approach can be developed to handle (uncertain) resource usage. In this paper we do not consider resources, but they are important in many planning applications. Resources can be uncertain due to different factors. Either the production or consumption of a resource depends on the duration of some uncontrollable action (e.g. the amount of fuel consumed in a trip depends on its duration, which is uncontrollable because of uncontrollable traffic conditions), or the amount being added or removed for a resource is uncertain by itself (e.g. the amount of energy produced by a solar panel depends on uncontrollable weather conditions). One idea to extend our work in this direction is to encode the resource profile with the upper and lower bounds and modifying conditions accordingly. This compilation would probably be sound but incomplete, but more research is needed to fully understand the issues.
     </paragraph>
     <paragraph>
      In terms of planning problems, another challenge is to deal with the ability of the executor to observe the end of actions with uncontrollable duration. This amounts to lifting to the level of planning the TNU notion of dynamic controllability. We would like to produce plans that are able to change their course of action based on the duration of activities observed at run-time. Notice that in STPUD the start of actions is decided a-priori, and plans must achieve the goal “blindly” (which is the planning counterpart of strong controllability in TNU ).
     </paragraph>
     <paragraph>
      On the experimental side, we would like to better understand the impact of the intermediate effect constructions (such as clip-actions) by modifying a PDDL temporal planner to natively understand such constructions. Another direction we would like to pursue is to study the compilation technique performance using a native ANML planner.
     </paragraph>
     <paragraph>
      Finally, we intend to study the plan- and domain-validation problems for the case of STPUD, by using techniques based on formal verification. In fact, validating a plan when uncertainty is present is no trivial task, and so is the development of domain models for complex applications. We want to investigate automated techniques that can help domain experts in the creation and debugging of planning models to foster the applicability of the planning technologies presented in this paper.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     Proof of Theorem 3
     <paragraph>
      In this section we prove Theorem 3.
     </paragraph>
     <paragraph label="Lemma 1">
      Given a strong plan σ, let{a mathematical formula}χ=⋃s∈σsnap(action(s)). σ is valid for a STPUD if and only if the DTNU K created byAlgorithm 2with DR is strongly controllable.
     </paragraph>
     <paragraph label="Proof">
      Clearly, K is defined over all and only the snap actions of the action appearing in σ.First, we prove that if σ is valid, then K is strongly controllable. Let μ be the assignment to the controllable time points of K, defined as follows.{a mathematical formula} We now prove that μ is a strong schedule for K. For the sake of contradiction, suppose it is not. Then, there exists a duration for the uncontrollable actions for which one of the free constraints in K is violated. It is impossible to violate a duration constraint, therefore one of the three constraints in Definition 13 must be violated for some {a mathematical formula}a¯. This is impossible, because σ is a valid plan and if we violate constraint 2a or constraint 2b, it means that the preconditions of the action in σ corresponding to {a mathematical formula}a¯ are unsatisfied, if we violate constraint 3, then the overall conditions of the action in σ corresponding to {a mathematical formula}a¯ are unsatisfied.Now, we prove that if K is strongly controllable, σ is valid. Reversing the argument before, we assume we have a strong schedule μ for K, and prove that setting each step s of σ as follows, yields a valid strong plan.
     </paragraph>
     <list>
      <list-item label="•">
       {a mathematical formula}t(s)=μ(ast),
      </list-item>
      <list-item label="•">
       {a mathematical formula}δ(s)=μ(aet−μ(ast), if s is controllable,
      </list-item>
     </list>
     <paragraph>
      The proof of Theorem 3 follows directly from Lemma 1.
     </paragraph>
     <paragraph label="Theorem 3">
      DR completenessGiven a STPUD problem P admitting a valid strong plan σ, if DR is used,Algorithm 2terminates with a valid strong plan.
     </paragraph>
     <paragraph label="Proof">
      We assume that the classical planner employed in Algorithm 2 is sound and complete. Therefore, sooner or later it will produce the abstract plan {a mathematical formula}χ=⋃s∈σsnap(action(s)) as it is a plan achieving the goal {a mathematical formula}abs(P). Then, by Lemma 1, we know that the DR approach yields a strongly controllable DTNU, and therefore the algorithm terminates with a valid strong plan. □
     </paragraph>
    </section>
    <section label="Appendix B">
     Proof of Theorem 4
     <paragraph>
      In this appendix we prove Theorem 4.
     </paragraph>
     <section label="B.1">
      <section-title>
       Plan mapping
      </section-title>
      <paragraph>
       Consider a plan σ for R, with actions {a mathematical formula}ai at time {a mathematical formula}ti and having duration {a mathematical formula}di. We call {a mathematical formula}πσ the regression plan for P when it has actions {a mathematical formula}aiπ corresponding to the actions {a mathematical formula}ai in σ such that:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}aiπ also starts at time {a mathematical formula}ti,
       </list-item>
       <list-item label="•">
        {a mathematical formula}aiπ has duration {a mathematical formula}di if {a mathematical formula}ai is controllable,
       </list-item>
       <list-item label="•">
        otherwise the duration of {a mathematical formula}aiπ is unspecified.
       </list-item>
      </list>
      <paragraph>
       Analogously, we call {a mathematical formula}σπ the projection plan for R of a strong plan π for P obtained by fixing the duration of each uncontrollable action in π to its maximum.
      </paragraph>
     </section>
     <section label="B.2">
      <section-title>
       Plan execution
      </section-title>
      <paragraph>
       Given a temporal plan, an execution{a mathematical formula}ϵX of a temporal planning instance X, is a set of changes applied to the variables in time: {a mathematical formula}ϵ=˙{(t1,f1,v1),⋯(tn,fn,vn)}.
      </paragraph>
      <paragraph>
       An element {a mathematical formula}(ti,fi,vi)∈ϵX means that at time {a mathematical formula}ti the variable {a mathematical formula}fi takes value {a mathematical formula}vi. Analogously to ANML, we take the view that at time {a mathematical formula}ti the change is not yet visible: the value {a mathematical formula}vi is taken immediately after {a mathematical formula}ti. Such an element of {a mathematical formula}ϵX can be caused by either: (1) an initial condition (i.e. {a mathematical formula}ti=0); (2) by a Timed Initial Literal or (3) by an action effect. Therefore, for the rest of this proof we refer to execution elements as either initial conditions, timed initial literals or action effects. Moreover, {a mathematical formula}ϵX(f,t) represents the value v of f at time t during the execution {a mathematical formula}ϵX.
      </paragraph>
      <paragraph>
       Given a strong plan π for P, we have a set of possible executions, one for each possible duration of each uncontrollable action in π. For a given execution {a mathematical formula}ϵP, then {a mathematical formula}ϵP(f,t) indicates the value of variable f at time t during this particular execution {a mathematical formula}ϵP.
      </paragraph>
      <paragraph>
       We now need to compare the executions of plans for P and R. The next theorem states that if σ is a valid plan for R and its corresponding regression plan for R is {a mathematical formula}πσ, then the variables in each pair of executions are aligned at each time in which {a mathematical formula}fσ is equal to f during the execution of R.
      </paragraph>
      <paragraph label="Lemma 2">
       Given a valid plan σ for R and its corresponding regression plan{a mathematical formula}πσ, for each execution{a mathematical formula}ϵPof{a mathematical formula}πσ: if{a mathematical formula}ϵR(fσ,t)=ϵR(f,t), then{a mathematical formula}ϵR(f,t)=ϵP(f,t), for each variable{a mathematical formula}f∈Land each{a mathematical formula}t∈R≥0.
      </paragraph>
      <paragraph label="Proof">
       For the sake of contradiction, let us focus on an execution {a mathematical formula}ϵP in which there is {a mathematical formula}t∈R≥0 such that {a mathematical formula}ϵR(fσ,t)=ϵR(f,t) but {a mathematical formula}ϵR(f,t)≠ϵP(f,t).Let {a mathematical formula}EfσR=˙(tσR,fσ,vσR), {a mathematical formula}EfR=˙(tR,f,vR) and {a mathematical formula}EfP=˙(tP,f,vP) be the latest execution elements involving {a mathematical formula}fσ and f in {a mathematical formula}ϵR and {a mathematical formula}ϵP. By our hypothesis, {a mathematical formula}vR≠vP. Moreover, due to the translation constraints, we know that {a mathematical formula}vσR=vR and {a mathematical formula}tσR≤tR. In fact, each time we change f in R we also change {a mathematical formula}fσ either at the same time or at the beginning of an uncertain interval d and we prevent any other change on {a mathematical formula}fσ until d is over.We prove that this hypothesis is impossible by considering all possible cases.
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}EfR and {a mathematical formula}EfP are both initial conditions: since all the initial conditions are copied from P to R, we must have {a mathematical formula}vP=vR.
       </list-item>
       <list-item label="2.">
        {a mathematical formula}EfR and {a mathematical formula}EfP are both timed initial literals (TIL): since all TILs are copied from P to R, either {a mathematical formula}vP=vR or there are two TILs at the same time on the variable f, which is not allowed.
       </list-item>
       <list-item label="3.">
        {a mathematical formula}EfR is either a TIL or an initial condition and {a mathematical formula}EfP is the effect of action a:
       </list-item>
       <list-item label="4.">
        {a mathematical formula}EfP is either a TIL or an initial condition and {a mathematical formula}EfR is an action effect: since TIL are copied from P to R, there is a TIL analogous to {a mathematical formula}EfP in R. Hence {a mathematical formula}tR≥tσR&gt;tP. However, since {a mathematical formula}tR and {a mathematical formula}tσR are the two extremes of an uncertainty interval, there must be another effect on f in P during this interval. Hence, {a mathematical formula}EfP is not the last effect changing f in P.
       </list-item>
       <list-item label="5.">
        {a mathematical formula}EfP and {a mathematical formula}EfR are both effects of two action instances a and {a mathematical formula}a′; there are four possible sub-cases:
       </list-item>
      </list>
      <paragraph label="Proof">
       Given a strong plan π for P and its corresponding projection plan{a mathematical formula}σπfor R, let{a mathematical formula}ϵRbe the execution of{a mathematical formula}σπ. For each variable{a mathematical formula}f∈L, each{a mathematical formula}t∈R≥0and each execution of P: if{a mathematical formula}ϵR(fσ,t)=ϵR(f,t)then{a mathematical formula}ϵR(f,t)=ϵP(f,t),We apply the same reasoning as in the proof of the previous lemma. Cases 1 and 2 are identical to the previous proof, the other cases are changed as follows.
      </paragraph>
      <list>
       <list-item label="3.">
        {a mathematical formula}EfR is either a TIL or an initial condition and {a mathematical formula}EfP is the effect of an action a.
       </list-item>
       <list-item label="4.">
        {a mathematical formula}EfP is either a TIL or an initial condition and {a mathematical formula}EfR is an action effect. Since TILs are copied from P to R, there must be a TIL analogous to {a mathematical formula}EfP in R. Hence {a mathematical formula}tR≥tσR&gt;tP. But there are two executions of P in which {a mathematical formula}tR=tP and {a mathematical formula}tσR=tP ({a mathematical formula}tR and {a mathematical formula}tσR are the extremes of an uncertainty interval). Hence, {a mathematical formula}EfP is not the last effect changing f in P.
       </list-item>
       <list-item label="5.">
        {a mathematical formula}EfP and {a mathematical formula}EfR are both effects of two action instances a and {a mathematical formula}a′.Four sub-cases are possible:
       </list-item>
      </list>
      <paragraph label="Theorem 4">
       Soundness and completenessLet{a mathematical formula}P=˙〈V,I,T,G,A〉be a planning instance and{a mathematical formula}R=˙〈V′,I′,T′,G′,A′〉be its translation. P has a strong plan π if and only if R has a temporal plan σ.
      </paragraph>
      <paragraph label="Proof">
       Let π be a strong plan for P. {a mathematical formula}σπ is a valid temporal plan for R because:
       <list>
        It achieves the goal {a mathematical formula}G′ of R, because all the original goals in G are achieved by π and by σ in the same way, and the goals on the shadow variables must be achieved because π is a strong plan. In fact, π achieves the goals regardless of the concrete durations of the actions, therefore it achieves them outside of the uncertainty intervals, where the variables and the shadow variables are aligned because of Lemma 3.Each action {a mathematical formula}a′ is executable in R, because each {a mathematical formula}a∈π is executable in P regardless of the action durations. Thus the possible uncertainty introduced by the durations is irrelevant for the executability of a (all the conditions are satisfied and variables and the shadow variables are aligned because of Lemma 3). In the translated instance R, all the conditions are also satisfied because the conditions are imposed via the χ function that only checks that both the variable and its shadow fulfill the original condition.No conflicting effects are possible because of the conditions added in {a mathematical formula}Ca′E that prevents any modification of the interested shadow variables during the uncertainty intervals.Similarly, let
       </list>
       <paragraph>
        σ be a plan for R. Then {a mathematical formula}πσ is a valid strong temporal plan for P because:
       </paragraph>
       <list>
        <list-item label="•">
         It achieves the goal G, because σ achieves the goal {a mathematical formula}G′ that is a super-set of G, and the variables are aligned because of Lemma 2.
        </list-item>
        <list-item label="•">
         Each action a is executable in P regardless of the action duration, because the variables are aligned because of Lemma 2, {a mathematical formula}a′∈σ is executable in R and the conditions in the translated actions are a super-set of the ones in the original action, because of the χ function.
        </list-item>
        <list-item label="•">
         No conflicting effects are possible regardless of the uncertain duration, because each effect at time t can be uncertain only between {a mathematical formula}λ(t) and {a mathematical formula}ν(t) and we guarantee no other effect is possible in that interval by means of {a mathematical formula}Ca′E. □
        </list-item>
       </list>
      </paragraph>
     </section>
    </section>
   </appendices>
  </root>
 </body>
</html>