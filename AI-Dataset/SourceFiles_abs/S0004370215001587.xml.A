<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Voting rules as error-correcting codes.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Social choice theory develops and analyzes methods for aggregating the opinions of individuals into a collective decision. The prevalent approach is motivated by situations in which opinions are subjective, such as political elections, and focuses on the design of voting rules that satisfy normative properties [1].
     </paragraph>
     <paragraph>
      An alternative approach, which was proposed by the marquis de Condorcet in the 18th Century, had confounded scholars for centuries (due to Condorcet's ambiguous writing) until it was finally elucidated by Young [34]. The underlying assumption is that the alternatives can be objectively compared according to their true quality. In particular, it is typically assumed that there is a ground truth ranking of the alternatives. Votes can be seen as noisy estimates of the ground truth, drawn from a specific noise model. For example, Condorcet proposed a noise model where — roughly speaking — each voter (hereinafter, agent) compares every pair of alternatives, and orders them correctly (according to the ground truth) with probability {a mathematical formula}p&gt;1/2; today an equivalent model is attributed to Mallows [26]. Here, it is natural to employ a voting rule that always returns a ranking that is most likely to coincide with the ground truth, that is, the voting rule should be a maximum likelihood estimator (MLE).
     </paragraph>
     <paragraph>
      Although Condorcet could have hardly foreseen this, his MLE approach is eminently applicable to crowdsourcing and human computation systems, which often employ voting to aggregate noisy estimates; EteRNA [24] is a wonderful example, as explained by Procaccia et al. [30]. Consequently, the study of voting rules as MLEs has been gaining steam in the last decade [16], [15], [19], [33], [32], [25], [30], [2], [3], [4], [27], [12], [13].
     </paragraph>
     <paragraph>
      Despite its conceptual appeal, a major shortcoming of the MLE approach is that the MLE voting rule is specific to a noise model, and that noise model — even if it exists for a given setting — may be difficult to pin down [27]. Caragiannis et al. [12], [13] have addressed this problem by relaxing the MLE constraint: they only ask that the probability of the voting rule returning the ground truth go to one as the number of votes goes to infinity. This allows them to design voting rules that uncover the ground truth in a wide range of noise models; however, they may potentially require an infinite amount of information.
     </paragraph>
     <paragraph>
      Our approach. In this paper, we propose a fundamentally different approach to aggregating noisy votes. Instead of assuming probabilistic noise, we assume a known upper bound on the “total noise” in the input votes, and allow the input votes to be adversarial subject to the upper bound. We emphasize that in potential application domains there is no adversary that actively inserts errors into the votes; we choose an adversarial error model to be able to correct errors even in the worst case. This style of worst-case analysis — where the worst case is assumed to be generated by an adversary — is prevalent in many branches of computer science, e.g., in the analysis of online algorithms [10], and in machine learning [23], [9].
     </paragraph>
     <paragraph>
      We wish to design voting rules that do well in this worst-case scenario. From this viewpoint, our approach is closely related to the extensive literature on error-correcting codes. One can think of the votes as a repetition code: each vote is a transmitted noisy version of a “message” (the ground truth). The task of the “decoder” is to correct adversarial noise and recover the ground truth, given an upper bound on the total error. The question is: how much total error can this “code” allow while still being able to recover the ground truth?
     </paragraph>
     <paragraph>
      In more detail, let d be a distance metric on the space of rankings. As an example, the well-known Kendall tau (KT) distance between two rankings measures the number of pairs of alternatives on which the two rankings disagree. Suppose that we receive n votes over the set of alternatives {a mathematical formula}{a,b,c,d}, for an even n, and we know that the average KT distance between the votes and the ground truth is at most 1/2. Can we always recover the ground truth? No: in the worst-case, exactly {a mathematical formula}n/2 agents swap the two highest-ranked alternatives and the rest report the ground truth. In this case, we observe two distinct rankings (each {a mathematical formula}n/2 times) that only disagree on the order of the top two alternatives. Both rankings have an average distance of 1/2 from the input votes, making it impossible to determine which of them is the ground truth.
     </paragraph>
     <paragraph>
      Let us, therefore, cast a larger net. Inspired by list decoding of error-correcting codes (see, e.g., [20]), our main research question is: Fix a distance metric d. Suppose that we are given n noisy rankings, and that the average distance between these rankings and the ground truth is at most t. We wish to recover a ranking that is guaranteed to be at distance at most k from the ground truth. How small can k be, as a function of n and t?
     </paragraph>
     <paragraph>
      Our results. We observe that for any metric d, one can always recover a ranking that is at distance at most 2t from the ground truth, i.e., {a mathematical formula}k≤2t. We also show that one can pick, in polynomial time, a ranking from the given noisy rankings that provides a weaker 3t upper bound. We complement the upper bounds by providing a lower bound of (roughly) {a mathematical formula}k≥t/2 that holds for every distance metric. We also show that an extremely mild assumption on the distance metric improves the lower bound to (roughly) {a mathematical formula}k≥t. In addition, we consider the four most popular distance metrics used in the social choice literature, and prove a tight lower bound of (roughly) {a mathematical formula}k≥2t for each metric. This lower bound is our main theoretical result; the construction makes unexpected use of Fermat's Polygonal Number Theorem.
     </paragraph>
     <paragraph>
      The worst-case optimal voting rule in our framework is defined with respect to a known upper bound t on the average distance between the given rankings and the ground truth. However, we show that the voting rule which returns the ranking minimizing the total distance from the given rankings — which has strong theoretical support in the literature — serves as an approximation to our worst-case optimal rule, irrespective of the value of t. We leverage this observation to provide theoretical performance guarantees for our rule in cases where the error bound t given to the rule is an underestimate or overestimate of the tightest upper bound.
     </paragraph>
     <paragraph>
      Finally, we test our worst-case optimal voting rules against many well-known voting rules, on two real-world datasets [27], and show that the worst-case optimal rules exhibit superior performance as long as the given error bound t is a reasonable overestimate of the tightest upper bound.
     </paragraph>
     <paragraph>
      Related work. Our work is related to the extensive literature on error-correcting codes that use permutations (see, e.g., [5], and the references therein), but differs in one crucial aspect. In designing error-correcting codes, the focus is on two choices: i) the codewords, a subset of rankings which represent the “possible ground truths”, and ii) the code, which converts every codeword into the message to be sent. These choices are optimized to achieve the best tradeoff between the number of errors corrected and the rate of the code (efficiency), while allowing unique identification of the ground truth. In contrast, our setting has fixed choices: i) every ranking is a possible ground truth, and ii) in coding theory terms, our setting constrains us to the repetition code. Both restrictions (inevitable in our setting) lead to significant inefficiencies, as well as the impossibility of unique identification of the ground truth (as illustrated in the introduction). Our research question is reminiscent of coding theory settings where a bound on adversarial noise is given, and a code is chosen with the bound on the noise as an input to maximize efficiency (see, e.g., [21]).
     </paragraph>
     <paragraph>
      List decoding (see, e.g., [20]) relaxes classic error correction by guaranteeing that the number of possible messages does not exceed a small quota; then, the decoder simply lists all possible messages. The motivation is that one can simply scan the list and find the correct message, as all other messages on the list are likely to be gibberish. In the voting context, one cannot simply disregard some potential ground truths as nonsensical; we therefore select a ranking that is close to every possible ground truth.
     </paragraph>
     <paragraph>
      Our model is also reminiscent of the distance rationalizability framework from the social choice literature [28]. In this framework, there is a fixed set of “consensus profiles” that admit an obvious output. Given a profile of votes, one finds the closest consensus profile (according to some metric), and returns the obvious output for that profile. Our model closely resembles the case where the consensus profiles are strongly unanimous, i.e., they consist of repetitions of a single ranking (which is also the ideal output). The key difference in our model is that instead of focusing solely on the closest ranking (strongly unanimous profile), we need to consider all rankings up to an average distance of t from the given profile — as they are all plausible ground truths — and return a single ranking that is at distance at most k from all such rankings.
     </paragraph>
     <paragraph>
      A bit further afield, Procaccia et al. [31] study a probabilistic noisy voting setting, and quantify the robustness of voting rules to random errors. Their results focus on the probability that the outcome would change, under a random transposition of two adjacent alternatives in a single vote from a submitted profile, in the worst-case over profiles. Their work is different from ours in many ways, but perhaps most importantly, they are interested in how frequently common voting rules make mistakes, whereas we are interested in the guarantees of optimal voting rules that avoid mistakes.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Preliminaries
     </section-title>
     <paragraph>
      Let A be the set of alternatives, and {a mathematical formula}|A|=m. Let {a mathematical formula}L(A) be the set of rankings over A. A vote σ is a ranking in {a mathematical formula}L(A), and a profile {a mathematical formula}π∈L(A)n is a collection of n rankings. A voting rule{a mathematical formula}f:L(A)n→L(A) maps every profile to a ranking.{sup:1}
     </paragraph>
     <paragraph>
      We assume that there exists an underlying ground truth ranking {a mathematical formula}σ⁎∈L(A) of the alternatives, and the votes are noisy estimates of {a mathematical formula}σ⁎. We use a distance metric d over {a mathematical formula}L(A) to measure errors; the error of a vote σ with respect to {a mathematical formula}σ⁎ is {a mathematical formula}d(σ,σ⁎), and the average error of a profile π with respect to {a mathematical formula}σ⁎ is {a mathematical formula}d(π,σ⁎)=(1/n)⋅∑σ∈πd(σ,σ⁎). We consider four popular distance metrics over rankings in this paper.
     </paragraph>
     <list>
      <list-item label="•">
       The Kendall tau (KT) distance, denoted {a mathematical formula}dKT, measures the number of pairs of alternatives over which two rankings disagree. Equivalently, it is also the minimum number of swaps of adjacent alternatives required to convert one ranking into another.
      </list-item>
      <list-item label="•">
       The (Spearman's) Footrule (FR) distance, denoted {a mathematical formula}dFR, measures the total displacement of all alternatives between two rankings, i.e., the sum of the absolute differences between their positions in two rankings.
      </list-item>
      <list-item label="•">
       The Maximum Displacement (MD) distance, denoted {a mathematical formula}dMD, measures the maximum of the displacements of all alternatives between two rankings.
      </list-item>
      <list-item label="•">
       The Cayley (CY) distance, denoted {a mathematical formula}dCY, measures the minimum number of swaps (not necessarily of adjacent alternatives) required to convert one ranking into another.
      </list-item>
     </list>
     <paragraph>
      All four metrics described above are neutral: A distance metric is called neutral if the distance between two rankings is independent of the labels of the alternatives; in other words, choosing a relabeling of the alternatives and applying it to two rankings keeps the distance between them invariant.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Worst-case optimal rules
     </section-title>
     <paragraph>
      Suppose we are given a profile π of n noisy rankings that are estimates of an underlying true ranking {a mathematical formula}σ⁎. In the absence of any additional information, any ranking could potentially be the true ranking. However, because essentially all crowdsourcing methods draw their power from the often-observed fact that individual opinions are accurate on average, we can plausibly assume that while some agents may make many mistakes, the average error is fairly small. An upper bound on the average error may be inferred by observing the collected votes, or from historical data (but see the next section for the case where this bound is inaccurate).
     </paragraph>
     <paragraph>
      Formally, suppose we are guaranteed that the average distance between the votes in π and the ground truth {a mathematical formula}σ⁎ is at most t according to a metric d, i.e., {a mathematical formula}d(π,σ⁎)≤t. With this guarantee, the set of possible ground truths is given by the “ball” of radius t around π.{a mathematical formula} Note that we have {a mathematical formula}σ⁎∈Btd(π) given our assumption; hence, {a mathematical formula}Btd(π)≠∅. We wish to find a ranking that is as close to the ground truth as possible. Since our approach is worst case in nature, our goal is to find the ranking that minimizes the maximum distance from the possible ground truths in {a mathematical formula}Btd(π). For a set of rankings {a mathematical formula}S⊆L(A), let its minimax ranking, denoted {a mathematical formula}MiniMaxd(S), be defined as follows.{sup:2}{a mathematical formula} Let the minimax distance of S, denoted {a mathematical formula}kd(S), be the maximum distance of {a mathematical formula}MiniMaxd(S) from the rankings in S according to d. Thus, given a profile π and the guarantee that {a mathematical formula}d(π,σ⁎)≤t, the worst-case optimal voting rule {a mathematical formula}OPTd returns the minimax ranking of the set of possible ground truths {a mathematical formula}Btd(π). That is, for all profiles {a mathematical formula}π∈L(A)n and {a mathematical formula}t&gt;0,{a mathematical formula} Furthermore, the output ranking is guaranteed to be at distance at most {a mathematical formula}kd(Btd(π)) from the ground truth. We overload notation, and denote {a mathematical formula}kd(t,π)=kd(Btd(π)), and{a mathematical formula} While {a mathematical formula}kd is explicitly a function of t, it is also implicitly a function of n. Hereinafter, we omit the superscript d whenever the metric is clear from context. Let us illustrate our terminology with a simple example.
     </paragraph>
     <paragraph label="Example 1">
      Note that even with identical (scaled) error bounds, different distance metrics lead to different sets of possible ground truths as well as different optimal rankings. This demonstrates that the choice of the distance metric is important.
     </paragraph>
     <section label="3.1">
      <section-title>
       Upper bound
      </section-title>
      <paragraph>
       Given a distance metric d, a profile π, and that {a mathematical formula}d(π,σ⁎)≤t, we can bound {a mathematical formula}k(t,π) using the diameter of the set of possible ground truths {a mathematical formula}Bt(π). For a set of rankings {a mathematical formula}S⊆L(A), denote its diameter by {a mathematical formula}D(S)=maxσ,σ′∈S⁡d(σ,σ′).
      </paragraph>
      <paragraph label="Lemma 1">
       {a mathematical formula}12⋅D(Bt(π))≤k(t,π)≤D(Bt(π))≤2t.
      </paragraph>
      <paragraph label="Proof">
       Let {a mathematical formula}σˆ=MiniMax(Bt(π)). For rankings {a mathematical formula}σ,σ′∈Bt(π), we have {a mathematical formula}d(σ,σˆ),d(σ′,σˆ)≤k(t,π) by definition of {a mathematical formula}σˆ. By the triangle inequality, {a mathematical formula}d(σ,σ′)≤2k(t,π) for all {a mathematical formula}σ,σ′∈Bt(π). Thus, {a mathematical formula}D(Bt(π))≤2k(t,π).Next, the maximum distance of {a mathematical formula}σ∈Bt(π) from all rankings in {a mathematical formula}Bt(π) is at most {a mathematical formula}D(Bt(π)). Hence, the minimax distance {a mathematical formula}k(t,π)=k(Bt(π)) cannot be greater than {a mathematical formula}D(Bt(π)).Finally, let {a mathematical formula}π={σ1,…,σn}. For rankings {a mathematical formula}σ,σ′∈Bt(π), the triangle inequality implies {a mathematical formula}d(σ,σ′)≤d(σ,σi)+d(σi,σ′) for every {a mathematical formula}i∈{1,…,n}. Averaging over these inequalities, we get {a mathematical formula}d(σ,σ′)≤t+t=2t, for all {a mathematical formula}σ,σ′∈Bt(π). Thus, we have {a mathematical formula}D(Bt(π))≤2t, as required. □
      </paragraph>
      <paragraph>
       Lemma 1 implies that {a mathematical formula}k(t)=maxπ∈L(A)n⁡k(t,π)≤2t for all distance metrics and {a mathematical formula}t&gt;0. In words:
      </paragraph>
      <paragraph label="Theorem 1">
       Given n noisy rankings at an average distance of at most t from an unknown true ranking{a mathematical formula}σ⁎according to a distance metric d, it is always possible to find a ranking at distance at most 2t from{a mathematical formula}σ⁎according to d.
      </paragraph>
      <paragraph>
       Importantly, the bound of Theorem 1 is independent of the number of votes n. Most statistical models of social choice restrict profiles in two ways: i) the average error should be low because the probability of generating high-error votes is typically low, and ii) the errors should be distributed almost evenly (in different directions from the ground truth), which is why aggregating the votes works well. These assumptions are mainly helpful when n is large, that is, performance may be poor for small n (see, e.g., [12]). In contrast, our model restricts profiles only by making the first assumption (explicitly), allowing voting rules to perform well as long as the votes are accurate on average, independently of the number of votes n.
      </paragraph>
      <paragraph>
       We also remark that Theorem 1 admits a simple proof, but the bound is nontrivial: while the average error of the profile is at most t (hence, the profile contains a ranking with error at most t), it is generally impossible to pinpoint a single ranking within the profile that has error at most 2t with respect to the ground truth in the worst-case (i.e., with respect to every possible ground truth in {a mathematical formula}Bt(π)). That said, it can be shown that there exists a ranking in the profile that always has distance at most 3t from the ground truth. Further, one can pick such a ranking in polynomial time, which stands in sharp contrast to the usual hardness of finding the optimal ranking (see the discussion on the computational complexity of our approach in Section 6).
      </paragraph>
      <paragraph label="Theorem 2">
       Given n noisy rankings at an average distance of at most t from an unknown true ranking{a mathematical formula}σ⁎according to a distance metric d, it is always possible to pick, in polynomial time, one of the n given rankings that has distance at most 3t from{a mathematical formula}σ⁎according to d.
      </paragraph>
      <paragraph label="Proof">
       Consider a profile π consisting of n rankings such that {a mathematical formula}d(σ⁎,π)≤t. Let {a mathematical formula}x=minσ∈L(A)⁡d(σ,π) be the minimum distance any ranking has from the profile. Then, {a mathematical formula}x≤d(σ⁎,π)≤t. Let {a mathematical formula}σˆ=argminσ∈πd(σ,π) be the ranking in π which minimizes the distance from π among all rankings in π. An easy-to-verify folklore theorem says that {a mathematical formula}d(σˆ,π)≤2x. To see this, assume that ranking τ has the minimum distance from the profile (i.e., {a mathematical formula}d(τ,π)=x). Now, the average distance of all rankings in π from π is{a mathematical formula} where the second transition uses the triangle inequality. Now, {a mathematical formula}σˆ has the smallest distance from π among all rankings in π, which cannot be greater than the average distance {a mathematical formula}(1/n)∑σ∈πd(σ,π). Hence, {a mathematical formula}d(σˆ,π)≤2t. Finally,{a mathematical formula} where the first transition uses the triangle inequality and the second transition uses the fact that {a mathematical formula}d(σˆ,π)≤2t and {a mathematical formula}d(π,σ⁎)≤t. It is easy to see that {a mathematical formula}σˆ can be computed in {a mathematical formula}O(n2) time. □
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Lower bounds
      </section-title>
      <paragraph>
       The upper bound of 2t (Theorem 1) is intuitively loose — we cannot expect it to be tight for every distance metric. However, we can complement it with a lower bound of (roughly speaking) {a mathematical formula}t/2 for all distance metrics. Formally, let {a mathematical formula}d↓(r) denote the greatest feasible distance under distance metric d that is less than or equal to r. Next, we prove a lower bound of {a mathematical formula}d↓(t)/2.
      </paragraph>
      <paragraph label="Theorem 3">
       For a distance metric d,{a mathematical formula}k(t)≥d↓(t)/2.
      </paragraph>
      <paragraph label="Proof">
       If {a mathematical formula}d↓(t)=0, then the result trivially holds. Assume {a mathematical formula}d↓(t)&gt;0. Let σ and {a mathematical formula}σ′ be two rankings at distance {a mathematical formula}d↓(t). Consider profile π consisting of only a single instance of ranking σ. Then, {a mathematical formula}σ′∈Bt(π). Hence, {a mathematical formula}D(Bt(π))≥d↓(t). Now, it follows from Lemma 1 that {a mathematical formula}k(t)≥D(Bt(π))/2≥d↓(t)/2. □
      </paragraph>
      <paragraph>
       Recall that Theorem 1 shows that {a mathematical formula}k(t)≤2t. However, {a mathematical formula}k(t) is the minimax distance under some profile, and hence must be a feasible distance under d. Thus, Theorem 1 actually implies a possibly better upper bound of {a mathematical formula}d↓(2t). Together with Theorem 3, this implies {a mathematical formula}d↓(t)/2≤k(t)≤d↓(2t). Next, we show that imposing a mild assumption on the distance metric allows us to improve the lower bound by a factor of 2, thus reducing the gap between the lower and upper bounds.
      </paragraph>
      <paragraph label="Theorem 4">
       For a neutral distance metric d,{a mathematical formula}k(t)≥d↓(t).
      </paragraph>
      <paragraph label="Proof">
       For a ranking {a mathematical formula}σ∈L(A) and {a mathematical formula}r≥0, let {a mathematical formula}Br(σ) denote the set of rankings at distance at most r from σ. Neutrality of the distance metric d implies {a mathematical formula}|Br(σ)|=|Br(σ′)| for all {a mathematical formula}σ,σ′∈L(A) and {a mathematical formula}r≥0. In particular, {a mathematical formula}d↓(t) being a feasible distance under d implies that for every {a mathematical formula}σ∈L(A), there exists some ranking at distance exactly {a mathematical formula}d↓(t) from σ.Fix {a mathematical formula}σ∈L(A). Consider the profile π consisting of n instances of σ. It holds that {a mathematical formula}Bt(π)=Bt(σ). We want to show that the minimax distance {a mathematical formula}k(Bt(σ))≥d↓(t). Suppose for contradiction that there exists some {a mathematical formula}σ′∈L(A) such that all rankings in {a mathematical formula}Bt(σ) are at distance at most {a mathematical formula}t′ from {a mathematical formula}σ′, i.e., {a mathematical formula}Bt(σ)⊆Bt′(σ′), with {a mathematical formula}t′&lt;d↓(t). Since there exists some ranking at distance {a mathematical formula}d↓(t)&gt;t′ from {a mathematical formula}σ′, we have {a mathematical formula}Bt(σ)⊆Bt′(σ′)⊊Bt(σ′), which is a contradiction because {a mathematical formula}|Bt(σ)|=|Bt(σ′)|. Therefore, {a mathematical formula}k(t)≥k(t,π)≥d↓(t). □
      </paragraph>
      <paragraph>
       The bound of Theorem 4 holds for all {a mathematical formula}n,m&gt;0 and all {a mathematical formula}t∈[0,D], where D is the maximum possible distance under d. It can be checked easily that the bound is tight given the neutrality assumption, which is an extremely mild — and in fact, a highly desirable — assumption for distance metrics over rankings.
      </paragraph>
      <paragraph>
       Theorem 4 improves the bounds on {a mathematical formula}k(t) to {a mathematical formula}d↓(t)≤k(t)≤d↓(2t) for a variety of distance metrics d. However, for the four special distance metrics considered in this paper, the next result, which is our main theoretical result, closes this gap by establishing a tight lower bound of {a mathematical formula}d↓(2t), for a wide range of values of n and t.
      </paragraph>
      <paragraph label="Theorem 5">
       If{a mathematical formula}d∈{dKT,dFR,dMD,dCY}, and the maximum distance allowed by the metric is{a mathematical formula}D∈Θ(mα), then there exists{a mathematical formula}T∈Θ(mα)such that:
      </paragraph>
      <list>
       <list-item label="1.">
        For all{a mathematical formula}t≤Tand even n, we have{a mathematical formula}k(t)≥d↓(2t).
       </list-item>
       <list-item label="2.">
        For all{a mathematical formula}L≥2,{a mathematical formula}t≤Twith{a mathematical formula}{2t}∈(1/L,1−1/L), and odd{a mathematical formula}n≥Θ(L⋅D), we have{a mathematical formula}k(t)≥d↓(2t). Here,{a mathematical formula}{x}=x−⌊x⌋denotes the fractional part of{a mathematical formula}x∈R.
       </list-item>
      </list>
      <paragraph>
       The impossibility result of Theorem 5 is weaker for odd values of n (in particular, covering more values of t requires larger n), which is reminiscent of the fact that repetition (error-correcting) codes achieve greater efficiency with an odd number of repetitions; this is not merely a coincidence. Indeed, an extra repetition allows differentiating between tied possibilities for the ground truth; likewise, an extra vote in the profile prevents us from constructing a symmetric profile that admits a diverse set of possible ground truths.
      </paragraph>
      <paragraph label="Proof of Theorem 5">
       We denote {a mathematical formula}{1,…,r} by {a mathematical formula}[r] in this proof. We use {a mathematical formula}σ(a) to denote the rank (position) of alternative a in ranking σ. First, we prove the case of even n for all four distance metrics. We later provide a generic argument to prove the case of large odd n. First, we need a simple observation.
      </paragraph>
      <paragraph label="Observation 1">
       If{a mathematical formula}(r2)≤⌊2t⌋and{a mathematical formula}t≥0.5, then{a mathematical formula}r≤4t.
      </paragraph>
      <paragraph label="Proof">
       Note that {a mathematical formula}(r−1)2≤r⋅(r−1)≤2⋅⌊2t⌋≤4t. Hence, {a mathematical formula}r≤2t+1. We also have {a mathematical formula}t≥0.5, i.e., {a mathematical formula}1≤2t. This implies {a mathematical formula}1≤2t. Thus, we have {a mathematical formula}r≤2t+2t=(2+2)t≤4t. □
      </paragraph>
      <paragraph>
       The Kendall tau distance: Let d be the Kendall tau distance; thus, {a mathematical formula}D=(m2) and {a mathematical formula}α=2. Let n be even. For a ranking {a mathematical formula}τ∈L(A), let {a mathematical formula}τrev be its reverse. Assume {a mathematical formula}t=(1/2)⋅(m2), and fix a ranking {a mathematical formula}σ∈L(A). Every ranking must agree with exactly one of σ and {a mathematical formula}σrev on a given pair of alternatives. Hence, every {a mathematical formula}ρ∈L(A) satisfies {a mathematical formula}d(ρ,σ)+d(ρ,σrev)=(m2). Consider the profile π consisting of {a mathematical formula}n/2 instances of σ and {a mathematical formula}n/2 instances of {a mathematical formula}σrev. Then, the average distance of every ranking from rankings in π would be exactly t, i.e., {a mathematical formula}Bt(π)=L(A). It is easy to check that {a mathematical formula}k(L(A))=(m2)=2t=d↓(2t) because every ranking has its reverse ranking in {a mathematical formula}L(A) at distance exactly 2t.
      </paragraph>
      <paragraph>
       Now, let us extend the proof to {a mathematical formula}t≤(m/12)2. If {a mathematical formula}t&lt;0.5, then {a mathematical formula}dKT↓(2t)=0, which is a trivial lower bound. Hence, assume {a mathematical formula}t≥0.5. Thus, {a mathematical formula}d↓(2t)=⌊2t⌋. We use Fermat's Polygonal Number Theorem (see, e.g., [22]). A special case of this remarkable theorem states that every natural number can be expressed as the sum of at most three “triangular” numbers, i.e., numbers of the form {a mathematical formula}(k2). Let {a mathematical formula}⌊2t⌋=∑i=13(mi2). From Observation 1, it follows that {a mathematical formula}0≤mi≤4t for all {a mathematical formula}i∈{1,2,3}. Hence, {a mathematical formula}∑i=13mi≤12t≤m.
      </paragraph>
      <paragraph>
       Partition the set of alternatives A into four disjoint groups {a mathematical formula}A1, {a mathematical formula}A2, {a mathematical formula}A3, and {a mathematical formula}A4 such that {a mathematical formula}|Ai|=mi for {a mathematical formula}i∈{1,2,3}, and {a mathematical formula}|A4|=m−∑i=13mi. Let {a mathematical formula}σA4 be an arbitrary ranking of the alternatives in {a mathematical formula}A4; consider the partial order {a mathematical formula}PA=A1≻A2≻A3≻σA4 over alternatives in A. Note that a ranking ρ is an extension of {a mathematical formula}PA iff it ranks all alternatives in {a mathematical formula}Ai before any alternative in {a mathematical formula}Ai+1 for {a mathematical formula}i∈{1,2,3}, and ranks alternatives in {a mathematical formula}A4 according to {a mathematical formula}σA4. Choose arbitrary {a mathematical formula}σAi∈L(Ai) for {a mathematical formula}i∈{1,2,3} and define{a mathematical formula}
      </paragraph>
      <paragraph>
       Note that both σ and {a mathematical formula}σ′ are extensions of {a mathematical formula}PA. Once again, take the profile π consisting of {a mathematical formula}n/2 instances of σ and {a mathematical formula}n/2 instances of {a mathematical formula}σ′. It is easy to check that a ranking disagrees with exactly one of σ and {a mathematical formula}σ′ on every pair of alternatives that belong to the same group in {a mathematical formula}{A1,A2,A3}. Hence, every ranking {a mathematical formula}ρ∈L(A) satisfies{a mathematical formula} Clearly an equality is achieved in Equation (1) if and only if ρ is an extension of {a mathematical formula}PA. Thus, every extension of {a mathematical formula}PA has an average distance of {a mathematical formula}⌊2t⌋/2≤t from π. Every ranking ρ that is not an extension of {a mathematical formula}PA achieves a strict inequality in Equation (1); thus, {a mathematical formula}d(ρ,π)≥(⌊2t⌋+1)/2&gt;t. Hence, {a mathematical formula}Bt(π) is the set of extensions of {a mathematical formula}PA.
      </paragraph>
      <paragraph>
       Given a ranking {a mathematical formula}ρ∈L(A), consider the ranking in {a mathematical formula}Bt(π) that reverses the partial orders over {a mathematical formula}A1, {a mathematical formula}A2, and {a mathematical formula}A3 induced by ρ. The distance of this ranking from ρ would be at least {a mathematical formula}∑i=13(mi2)=⌊2t⌋, implying {a mathematical formula}k(Bt(π))≥⌊2t⌋. (In fact, it can be checked that {a mathematical formula}k(Bt(π))=D(Bt(π))=⌊2t⌋.)
      </paragraph>
      <paragraph>
       We now proceed to prove the case of an even number of agents for the other three distance metrics. First, if M is the minimum distance between two distinct rankings under a distance metric d and {a mathematical formula}t&lt;M/2, then we have {a mathematical formula}d↓(2t)=0, which is a trivial lower bound. Hence, we assume {a mathematical formula}t≥M/2.
      </paragraph>
      <paragraph>
       The footrule distance: Let {a mathematical formula}dFR denote the footrule distance; recall that given {a mathematical formula}σ,σ′∈L(A), {a mathematical formula}dFR(σ,σ′)=∑a∈A|σ(a)−σ′(a)|. The proof is along the same lines as the proof for the Kendall tau distance, but uses a few additional clever ideas. It is known that the maximum footrule distance between two rankings over m alternatives is {a mathematical formula}D=⌊m2/2⌋, and is achieved by two rankings that are reverse of each other [17]. Hence, we have {a mathematical formula}α=2; thus, we wish to find {a mathematical formula}T∈Θ(m2) for which the claim will hold. Formally writing the distance between a ranking and its reverse, we get{a mathematical formula}
      </paragraph>
      <paragraph label="Observation 2">
       The footrule distance between two rankings is always an even integer.
      </paragraph>
      <paragraph label="Proof">
       Take rankings {a mathematical formula}σ,τ∈L(A). Note that {a mathematical formula}dFR(σ,τ)=∑a∈A|σ(a)−τ(a)|. Now, {a mathematical formula}|σ(a)−τ(a)| is odd if and only if the positions of a in σ and τ have different parity. Since the number of odd (as well as even) positions is identical in σ and τ, the number of alternatives that leave an even position in σ to go to an odd position in τ equals the number of alternatives that leave an odd position in σ to go to an even position in τ. Thus, the number of alternatives for which the parity of the position changes is even. Equivalently, the number of odd terms in the sum defining the footrule distance is even. Hence, the footrule distance is an even integer. □
      </paragraph>
      <paragraph>
       Hence, Equation (2) implies that {a mathematical formula}dFR↓(2t) equals {a mathematical formula}⌊2t⌋ if {a mathematical formula}⌊2t⌋ is even, and equals {a mathematical formula}⌊2t⌋−1 otherwise. Let {a mathematical formula}r=dFR↓(2t). Hence, r is an even integer. We prove the result for {a mathematical formula}t≤(m/8)2. In this case, we invoke the 4-gonal special case of Fermat's Polygonal Number Theorem (instead of the 3-gonal case invoked in the proof for the Kendall tau distance): Every positive integer can be written as the sum of at most four squares. Let {a mathematical formula}r/2=m12+m22+m32+m42. Hence,{a mathematical formula}
      </paragraph>
      <paragraph>
       It is easy to check that {a mathematical formula}mi≤r/2 for {a mathematical formula}i∈[4]. Thus, {a mathematical formula}∑i=142mi≤8r/2≤8t≤m. Let us partition the set of alternatives A into {a mathematical formula}{Ai}i∈[5] such that {a mathematical formula}|Ai|=2mi for {a mathematical formula}i∈[4] and {a mathematical formula}|A5|=m5=m−∑i=142mi.
      </paragraph>
      <paragraph>
       Fix {a mathematical formula}σA5∈L(A5) and consider the partial order {a mathematical formula}PA=A1≻A2≻A3≻A4≻σA5. Choose arbitrary {a mathematical formula}σAi∈L(Ai) for {a mathematical formula}i∈[4], and let{a mathematical formula} Note that both σ and {a mathematical formula}σ′ are extensions of {a mathematical formula}PA. Consider the profile π consisting of {a mathematical formula}n/2 instances of σ and {a mathematical formula}σ′ each. Unlike the Kendall tau distance, {a mathematical formula}Bt(π) is not the set of extensions of {a mathematical formula}PA. Still, we show that it satisfies {a mathematical formula}k(Bt(π))=D(Bt(π))=dFR↓(2t)=r.
      </paragraph>
      <paragraph>
       Denote by {a mathematical formula}aij the alternative ranked j in {a mathematical formula}σAi. Take a ranking {a mathematical formula}ρ∈L(A). Consider {a mathematical formula}dFR(ρ,σ)+dFR(ρ,σ′). We have the following inequalities regarding the sum of displacement of different alternatives between ρ and σ, and between ρ and {a mathematical formula}σ′. For {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi],{a mathematical formula}
      </paragraph>
      <paragraph>
       Summing all the inequalities, we get{a mathematical formula} where the second transition follows from Equation (2), and the third transition follows from Equation (3).
      </paragraph>
      <paragraph>
       First, we show that {a mathematical formula}ρ∈Bt(π) only if equality in Equation (5) holds. To see why, note that the footrule distance is always even and {a mathematical formula}r=dFR↓(2t)≥⌊2t⌋−1. Hence, if equality is not achieved, then {a mathematical formula}dFR(ρ,σ)+dFR(ρ,σ′)≥r+2≥⌊2t⌋−1+1&gt;2t. Hence, the average distance of ρ from votes in π would be greater than t.
      </paragraph>
      <paragraph>
       On the contrary, if equality is indeed achieved in Equation (5), then the average distance of ρ from votes in π is {a mathematical formula}r/2≤t. Hence, we have established that {a mathematical formula}Bt(π) is the set of rankings ρ for which equality is achieved in Equation (5).
      </paragraph>
      <paragraph>
       For ρ to achieve equality in Equation (5), it must achieve equality in Equation (4) for every {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi], and it must agree with both σ and {a mathematical formula}σ′ on the positions of alternatives in {a mathematical formula}A5 (i.e., {a mathematical formula}σA5 must be a suffix of ρ). For the former to hold, the position of {a mathematical formula}aij in ρ must be between {a mathematical formula}σ(aij) and {a mathematical formula}σ′(aij)=σ(ai2mi+1−j) (both inclusive), for every {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi].
      </paragraph>
      <paragraph>
       We claim that the set of rankings satisfying these conditions are characterized as follows.{a mathematical formula}
      </paragraph>
      <paragraph>
       Note that instead of {a mathematical formula}ρ(aij) and {a mathematical formula}ρ(ai2mi+1−j) both being in the interval {a mathematical formula}[σ(aij),σ(ai2mi+1−j)], we are claiming that they must be the two endpoints. First, consider the middle alternatives in each {a mathematical formula}Ai ({a mathematical formula}i∈[4]), namely {a mathematical formula}aimi and {a mathematical formula}aimi+1. Both must be placed between {a mathematical formula}σ(aimi)=σ′(aimi+1) and {a mathematical formula}σ(aimi+1)=σ′(aimi); but these two numbers differ by exactly 1. Hence,{a mathematical formula} Consider the two adjacent alternatives, namely {a mathematical formula}aimi−1 and {a mathematical formula}aimi+2. Given that the middle alternatives {a mathematical formula}aimi and {a mathematical formula}aimi+1 occupy their respective positions in σ or {a mathematical formula}σ′, the only positions available to ρ for placing the two adjacent alternatives are the endpoints of their common feasible interval {a mathematical formula}[σ(aimi−1),σ(aimi+2)]. Continuing this argument, each pair of alternatives {a mathematical formula}(aij,ai2mi+1−j) must occupy the two positions {a mathematical formula}{σ(aij),σ(ai2mi+1−j)} for every {a mathematical formula}i∈[4] and {a mathematical formula}j∈[mi].
      </paragraph>
      <paragraph>
       That is, ρ can either keep the alternatives {a mathematical formula}aij and {a mathematical formula}ai2mi+1−j as they are in σ, or place them according to {a mathematical formula}σ′ (equivalently, swapping them in σ) for every {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi]. Note that these choices are independent of each other. We established that a ranking ρ is in {a mathematical formula}Bt(π) only if it is obtained in this manner and has {a mathematical formula}σA5 as its suffix.
      </paragraph>
      <paragraph>
       Further, it can be seen that each of these choices (keeping or swapping the pair in σ) maintain {a mathematical formula}dFR(ρ,σ)+dFR(ρ,σ′) invariant. Hence, all such rankings ρ satisfy {a mathematical formula}dFR(ρ,σ)+dFR(ρ,σ′)=r, and thus belong to {a mathematical formula}Bt(π). This reaffirms our original claim that {a mathematical formula}Bt(π) is given by Equation (6).
      </paragraph>
      <paragraph>
       In summary, all rankings in {a mathematical formula}Bt(π) can be obtained by taking σ, and arbitrarily choosing whether to swap the pair of alternatives {a mathematical formula}aij and {a mathematical formula}ai2mi+1−j for each {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi].
      </paragraph>
      <paragraph>
       Note that {a mathematical formula}σ,σ′∈Bt(π) and {a mathematical formula}dFR(σ,σ′)=r (this distance is given by the summation in Equation (5)). Hence, {a mathematical formula}D(Bt(π))≥r. Now, we prove that its minimax distance is at least r as well. Take a ranking {a mathematical formula}ρ∈L(A). We need to show that there exists some {a mathematical formula}τ∈Bt(π) such that {a mathematical formula}dFR(ρ,τ)≥r.
      </paragraph>
      <paragraph>
       Consider alternatives {a mathematical formula}aij and {a mathematical formula}ai2mi+1−j for {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi]. We know that τ must satisfy {a mathematical formula}{τ(aij),τ(ai2mi+1−j)}={σ(aij),σ(ai2mi+1−j)} in order to belong to {a mathematical formula}Bt(π). This allows two possible ways for placing the pair of alternatives. Let τ pick the optimal positions that maximize{a mathematical formula} That is, {a mathematical formula}τi,j(ρ) should equal {a mathematical formula}Mi,j(ρ), which we define as{a mathematical formula} Note that the choice for each pair of alternatives {a mathematical formula}(aij,ai2mi+1−j) can be made independently of every other pair. Further, making the optimal choice for each pair guarantees that {a mathematical formula}dFR(ρ,τ) is at least{a mathematical formula} which we will now show to be at least r.
      </paragraph>
      <paragraph>
       Algorithm 1 describes how to find the optimal ranking {a mathematical formula}τ∈Bt(π) mentioned above, which satisfies {a mathematical formula}τi,j(ρ)=Mi,j(ρ) for every {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi]. It starts with an arbitrary {a mathematical formula}τ∈Bt(π), and swaps every sub-optimally placed pair {a mathematical formula}(aij,ai2mi+1−j) for {a mathematical formula}i∈[4] and {a mathematical formula}j∈[2mi]. In the algorithm, {a mathematical formula}τa↔b denotes the ranking obtained by swapping alternatives a and b in τ.
      </paragraph>
      <paragraph>
       Finally, we show that {a mathematical formula}dFR(ρ,τ)≥r. First, we establish the following lower bound on {a mathematical formula}Mi,j(ρ).{a mathematical formula} where the first transition holds because the maximum of two terms is at least as much as their average, and the second transition uses the triangle inequality on appropriately paired terms. Now, we have{a mathematical formula} where the third transition holds due to Equation (2), and the fourth transition holds due to Equation (3). Hence, the minimax distance of {a mathematical formula}Bt(π) is at least {a mathematical formula}r=dFR↓(2t), as required.
      </paragraph>
      <paragraph>
       The Cayley distance: Next, let {a mathematical formula}dCY denote the Cayley distance. Recall that {a mathematical formula}dCY(σ,τ) equals the minimal number of swaps (of possibly non-adjacent alternatives) required in order to transform σ to τ. It is easy to check that the maximum Cayley distance is {a mathematical formula}D=m−1; hence, it has {a mathematical formula}α=1. We prove the result for {a mathematical formula}t≤m/4. Note that {a mathematical formula}dCY↓(2t)=⌊2t⌋. Define rankings {a mathematical formula}σ,σ′∈L(A) as follows.{a mathematical formula} Let profile π consist of {a mathematical formula}n/2 instances of σ and {a mathematical formula}σ′ each. We claim that {a mathematical formula}Bt(π) has the following structure, which is very similar to the ball for the footrule distance.{a mathematical formula}
      </paragraph>
      <paragraph>
       First, we observe the following simple fact: If rankings τ and ρ mismatch (i.e., place different alternatives) in r different positions, then {a mathematical formula}dCY(τ,ρ)≥r/2. Indeed, consider the number of swaps required to convert τ into ρ. Since each swap can make τ and ρ consistent in at most two more positions, it would take at least {a mathematical formula}r/2 swaps to convert τ into ρ, i.e., {a mathematical formula}dCY(τ,ρ)≥r/2.
      </paragraph>
      <paragraph>
       Now, note that σ and {a mathematical formula}σ′ mismatch in each of first {a mathematical formula}2⌊2t⌋ positions. Hence, every ranking {a mathematical formula}ρ∈L(A) must mismatch with at least one of σ and {a mathematical formula}σ′ in each of first {a mathematical formula}2⌊2t⌋ positions. Together with the previous observation, this implies{a mathematical formula}
      </paragraph>
      <paragraph>
       Every ranking ρ that achieves equality in Equation (8) is clearly in {a mathematical formula}Bt(π) because its average distance from the votes in π is {a mathematical formula}⌊2t⌋/2≤t. Further, every ranking ρ that achieves a strict inequality in Equation (8) is outside {a mathematical formula}Bt(π) because its average distance from the votes in π is at least {a mathematical formula}(⌊2t⌋+1)/2&gt;t. Hence, {a mathematical formula}Bt(π) consists of rankings that satisfy {a mathematical formula}dCY(ρ,σ)+dCY(ρ,σ′)=⌊2t⌋.
      </paragraph>
      <paragraph>
       Now, any ranking ρ satisfying equality in Equation (8) must be consistent with exactly one of σ and {a mathematical formula}σ′ in each of first {a mathematical formula}2⌊2t⌋ positions, and with both σ and {a mathematical formula}σ′ in the later positions. The former condition implies that for every {a mathematical formula}i∈⌊2t⌋, ρ must place the pair of alternatives {a mathematical formula}(ai,a2⌊2t⌋+1−i) in positions i and {a mathematical formula}2⌊2t⌋+1−i, either according to σ or according to {a mathematical formula}σ′. This confirms our claim that {a mathematical formula}Bt(π) is given by Equation (7).
      </paragraph>
      <paragraph>
       We now show that {a mathematical formula}k(Bt(π))≥⌊2t⌋. Take a ranking {a mathematical formula}ρ∈L(A). We construct a ranking {a mathematical formula}τ∈Bt(π) such that τ mismatches with ρ in each of first {a mathematical formula}2⌊2t⌋ positions. Together with our observation that the Cayley distance is at least half of the number of positional mismatches, this would imply that the minimax distance of {a mathematical formula}Bt(π) is at least {a mathematical formula}⌊2t⌋, as required.
      </paragraph>
      <paragraph>
       We construct τ by choosing the placement of the pair of alternatives {a mathematical formula}(ai,a2⌊2t⌋+1−i), independently for each {a mathematical formula}i∈⌊2t⌋, in a way that τ mismatches with ρ in positions i and {a mathematical formula}2⌊2t⌋+1−i both. Let {a mathematical formula}I(X) denote the indicator variable that is 1 if statement X holds, and 0 otherwise. Let {a mathematical formula}r=I(ρ(ai)=i)+I(ρ(a2⌊2t⌋+1−i)=2⌊2t⌋+1−i). Consider the following three cases. {a mathematical formula}r=0:Set {a mathematical formula}τ(ai)=i and {a mathematical formula}τ(a2⌊2t⌋+1−i)=2⌊2t⌋+1−i.{a mathematical formula}r=1:Without loss of generality, assume {a mathematical formula}ρ(ai)=i. Set {a mathematical formula}τ(ai)=2⌊2t⌋+1−i and {a mathematical formula}τ(a2⌊2t⌋+1−i)=i.{a mathematical formula}r=2:Set {a mathematical formula}τ(ai)=2⌊2t⌋+1−i and {a mathematical formula}τ(a2⌊2t⌋+1−i)=i. Finally, set {a mathematical formula}τ(ai)=i for all {a mathematical formula}i&gt;2⌊2t⌋. This yields a ranking τ that is in {a mathematical formula}Bt(π), and mismatches ρ in each of first {a mathematical formula}2⌊2t⌋ positions; hence, {a mathematical formula}dCY(ρ,τ)≥⌊2t⌋, as required.
      </paragraph>
      <paragraph>
       The maximum displacement distance: Finally, let {a mathematical formula}dMD denote the maximum displacement distance. Note that it can be at most {a mathematical formula}D=m−1; hence, it also has {a mathematical formula}α=1. However, this distance metric requires an entirely different technique than the ones used for previous distances. For example, taking any two rankings at maximum distance from each other does not work. We prove this result for {a mathematical formula}t≤m/4. Once again, note that {a mathematical formula}dMD↓(2t)=⌊2t⌋.
      </paragraph>
      <paragraph>
       Consider rankings σ and {a mathematical formula}σ′ defined as follows.{a mathematical formula} where {a mathematical formula}arest is shorthand for {a mathematical formula}a2⌊2t⌋+1≻…≻am. Note that the blocks of alternatives {a mathematical formula}a1 through {a mathematical formula}a⌊2t⌋ and {a mathematical formula}a⌊2t⌋+1 through {a mathematical formula}a2⌊2t⌋ are shifted to each other's positions in the two rankings. Thus, each of {a mathematical formula}a1 through {a mathematical formula}a2⌊2t⌋ have a displacement of exactly {a mathematical formula}⌊2t⌋ between the two rankings. Thus, {a mathematical formula}dMD(σ,σ′)=⌊2t⌋.
      </paragraph>
      <paragraph>
       Consider the profile π consisting of {a mathematical formula}n/2 instances of σ and {a mathematical formula}σ′ each. Clearly, σ and {a mathematical formula}σ′ have an average distance of {a mathematical formula}⌊2t⌋/2≤t from rankings in π. Hence, {a mathematical formula}{σ,σ′}∈Bt(π). Surprisingly, in this case we can show that the minimax distance of {a mathematical formula}Bt(π) without any additional information regarding the structure of {a mathematical formula}Bt(π).
      </paragraph>
      <paragraph>
       Take a ranking {a mathematical formula}ρ∈L(A). The alternative placed first in ρ must be ranked at a position {a mathematical formula}⌊2t⌋ or below in at least one of σ and {a mathematical formula}σ′. Hence, {a mathematical formula}max⁡(dMD(ρ,σ),dMD(ρ,σ′))≥⌊2t⌋. Thus, there exists a ranking in {a mathematical formula}Bt(π) at distance at least {a mathematical formula}⌊2t⌋ from ρ, i.e., the minimax distance of {a mathematical formula}Bt(π) is at least {a mathematical formula}⌊2t⌋, as desired.
      </paragraph>
      <paragraph>
       This completes the proof of the special case of even n for all four distance metrics. Now, consider the case of odd n.
      </paragraph>
      <paragraph>
       Odd n: To extend the proof to odd values of n, we simply add one more instance of σ than {a mathematical formula}σ′. The key insight is that with large n, the distance from the additional vote would have little effect on the average distance of a ranking from the profile. Thus, {a mathematical formula}Bt(π) would be preserved, and the proof would follow.
      </paragraph>
      <paragraph>
       Formally, let {a mathematical formula}L≥2 and {a mathematical formula}t∈(1/L,1−1/L). For the case of even n, the proofs for all four distance metrics proceeded as follows: Given the feasible distance {a mathematical formula}r=d↓(2t), we constructed two rankings σ and {a mathematical formula}σ′ at distance r from each other such that {a mathematical formula}Bt(π) is the set of rankings at minimal total distance from the two rankings, i.e.,{a mathematical formula}
      </paragraph>
      <paragraph>
       Let {a mathematical formula}n≥3 be odd. Consider the profile π that has {a mathematical formula}(n−1)/2 instances of σ and {a mathematical formula}σ′ each, and an additional instance of an arbitrary ranking. In our generic proof for all four distance metrics, we obtain conditions under which {a mathematical formula}Bt(π)=Bt(π′) where {a mathematical formula}π′ is obtained by removing the arbitrary ranking from π (and hence has an even number of votes). We already proved that {a mathematical formula}k(Bt(π′))≥d↓(2t). Hence, obtaining {a mathematical formula}Bt(π)=Bt(π′) would also show the lower bound {a mathematical formula}d↓(2t) for odd n.
      </paragraph>
      <paragraph>
       In more detail, our objective is that every ranking ρ with {a mathematical formula}d(ρ,σ)+d(ρ,σ′)=r (which may have a worst-case distance of D from the additional arbitrary ranking) should be in {a mathematical formula}Bt(π), and every ranking ρ with {a mathematical formula}d(ρ,σ)+d(ρ,σ′)&gt;r should be outside {a mathematical formula}Bt(π).
      </paragraph>
      <paragraph>
       First, let {a mathematical formula}d∈{dKT,dCY,dMD}. If {a mathematical formula}d(ρ,σ)+d(ρ,σ′)&gt;r, then {a mathematical formula}d(ρ,σ)+d(ρ,σ′)≥r+1. The total error incurred by rankings of distance r from π is {a mathematical formula}n−12⋅r, and a distance of D from the additional ranking. This means that{a mathematical formula} For rankings with an error greater than r to be outside {a mathematical formula}Bt(π), we must have{a mathematical formula} Combining the inequalities, we obtain that{a mathematical formula}
      </paragraph>
      <paragraph>
       Choose {a mathematical formula}n≥2LD+1. Then, {a mathematical formula}2D/(n−1)≤1/L&lt;{2t}. Note that{a mathematical formula} where the last equality holds because we showed {a mathematical formula}(2D−2t)/(n−1)&lt;{2t}.
      </paragraph>
      <paragraph>
       In all three distance metrics considered thus far, we had {a mathematical formula}⌊2t⌋=d↓(2t). Let {a mathematical formula}r=⌊2t⌋. We show that {a mathematical formula}r=⌊2t⌋ satisfies Equation (9), thus yielding {a mathematical formula}Bt(π) with minimax distance at least {a mathematical formula}r=d↓(2t), as required. Note that{a mathematical formula} is satisfied by definition from Equation (9). We also have{a mathematical formula} Hence, we have {a mathematical formula}k(t)≥d↓(2t) for {a mathematical formula}n≥2LD+1.
      </paragraph>
      <paragraph>
       Next, consider the footrule distance. If {a mathematical formula}⌊2t⌋ is even (i.e., if {a mathematical formula}⌊2t⌋=d↓(2t)), then the above proof works because {a mathematical formula}r=⌊2t⌋ is a feasible distance. If {a mathematical formula}⌊2t⌋ is odd, then we must choose {a mathematical formula}r=⌊2t⌋−1. However, we have an advantage: since the footrule distance is always even, every ranking ρ with {a mathematical formula}d(ρ,σ)+d(ρ,σ′)&gt;r must have {a mathematical formula}d(ρ,σ)+d(ρ,σ′)≥r+2. Hence, we only need{a mathematical formula}
      </paragraph>
      <paragraph>
       Note that {a mathematical formula}r=⌊2t⌋−1 clearly satisfies the first inequality in Equation (10). For the second inequality, note that r decreased by 1 compared to earlier but {a mathematical formula}1−2D/(n−1) increased to {a mathematical formula}2−2D/(n−1) instead. Hence, the second inequality is still satisfied, and we get {a mathematical formula}Bt(π) with minimax distance at least {a mathematical formula}r=⌊2t⌋−1=d↓(2t), as required. □
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Approximations for unknown average error
     </section-title>
     <paragraph>
      In the previous sections we derived the optimal rules when the upper bound t on the average error is given to us. In practice, the given bound may be inaccurate. We know that using an estimate {a mathematical formula}tˆ that is still an upper bound ({a mathematical formula}tˆ≥t) yields a ranking at distance at most {a mathematical formula}2tˆ from the ground truth in the worst case. What happens if it turns out that {a mathematical formula}tˆ&lt;t? We show that the output ranking is still at distance at most 4t from the ground truth in the worst case.
     </paragraph>
     <paragraph label="Theorem 6">
      For a distance metric d, a profile π consisting of n noisy rankings at an average distance of at most t from the true ranking{a mathematical formula}σ⁎, and{a mathematical formula}tˆ&lt;t,{a mathematical formula}d(OPTd(tˆ,π),σ⁎)≤4t.
     </paragraph>
     <paragraph>
      To prove the theorem, we make a detour through minisum rules. For a distance metric d, let {a mathematical formula}MiniSumd, be the voting rule that always returns the ranking minimizing the sum of distances (equivalently, average distance) from the rankings in the given profile according to d. Two popular minisum rules are the Kemeny rule for the Kendall tau distance ({a mathematical formula}MiniSumdKT) and the minisum rule for the footrule distance ({a mathematical formula}MiniSumdFR), which approximates the Kemeny rule [18].{sup:5} For a distance metric d (dropped from the superscripts), let {a mathematical formula}d(π,σ⁎)≤t. We claim that the minisum ranking {a mathematical formula}MiniSum(π) is at distance at most {a mathematical formula}min⁡(2t,2k(t,π)) from {a mathematical formula}σ⁎. This is true because the minisum ranking and the true ranking are both in {a mathematical formula}Bt(π), and Lemma 1 shows that its diameter is at most {a mathematical formula}min⁡(2t,2k(t,π)).
     </paragraph>
     <paragraph>
      Returning to the theorem, if we provide an underestimate {a mathematical formula}tˆ of the true worst-case average error t, then using Lemma 1,{a mathematical formula} By the triangle inequality, {a mathematical formula}d(MiniMax(Btˆ(π)),σ⁎)≤4t.
     </paragraph>
    </section>
    <section label="5">
     <section-title>
      Experimental results
     </section-title>
     <paragraph>
      We compare our worst-case optimal voting rules {a mathematical formula}OPTd against a plethora of voting rules used in the literature: plurality, Borda count, veto, the Kemeny rule, single transferable vote (STV), Copeland's rule, Bucklin's rule, the maximin rule, Slater's rule, Tideman's rule, and the modal ranking rule (for definitions see, e.g., [13]).
     </paragraph>
     <paragraph>
      Our performance measure is the distance of the output ranking from the actual ground truth. In contrast, for a given d, {a mathematical formula}OPTd is designed to optimize the worst-case distance to any possible ground truth. Hence, crucially, {a mathematical formula}OPTdis not guaranteed to outperform other rules in our experiments.
     </paragraph>
     <paragraph>
      We use two real-world datasets containing ranked preferences in domains where ground truth rankings exist. Mao, Procaccia, and Chen [27] collected these datasets — dots and puzzle — via Amazon Mechanical Turk. For dataset dots (resp., puzzle), human workers were asked to rank four images that contain a different number of dots (resp., different states of an 8-Puzzle) according to the number of dots (resp., the distances of the states from the goal state). Each dataset has four different noise levels (i.e., levels of task difficulty), represented using a single noise parameter: for dots (resp., puzzle), higher noise corresponds to ranking images with a smaller difference between their number of dots (resp., ranking states that are all farther away from the goal state). Each dataset has 40 profiles with approximately 20 votes each, for each of the 4 noise levels. Points in our graphs are averaged over the 40 profiles in a single noise level of a dataset.
     </paragraph>
     <paragraph>
      First, as a sanity check, we verified (Fig. 1) that the noise parameter in the datasets positively correlates with our notion of noise — the average error in the profile, denoted {a mathematical formula}t⁎ (averaged over all profiles in a noise level). Strikingly, the results from the two datasets are almost identical!
     </paragraph>
     <paragraph>
      Next, we compare {a mathematical formula}OPTd and {a mathematical formula}MiniSumd against the voting rules listed above, with distance d as the measure of error. We use the average error in a profile as the bound t given to {a mathematical formula}OPTd, i.e., we compute {a mathematical formula}OPTd(t⁎,π) on profile π where {a mathematical formula}t⁎=d(π,σ⁎). While this is somewhat optimistic, note that {a mathematical formula}t⁎ may not be the (optimal) value of t that achieves the lowest error. Also, the experiments below show that a reasonable estimate of {a mathematical formula}t⁎ also suffices.
     </paragraph>
     <paragraph>
      Figs. 2(a) and 2(b) show the results for the dots and puzzle datasets, respectively, under the Kendall tau distance. It can be seen that {a mathematical formula}OPTdKT (solid red line) significantly outperforms all other voting rules. The three other distance metrics considered in this paper generate similar results; the corresponding graphs are presented in the appendix.
     </paragraph>
     <paragraph>
      Finally, we test {a mathematical formula}OPTd in the more demanding setting where only an estimate {a mathematical formula}tˆ of {a mathematical formula}t⁎ is provided. To synchronize the results across different profiles, we use {a mathematical formula}r=(tˆ−MAD)/(t⁎−MAD), where MAD is the minimum average distance of any ranking from the votes in a profile, that is, the average distance of the ranking returned by {a mathematical formula}MiniSumd from the input votes. For all profiles, {a mathematical formula}r=0 implies {a mathematical formula}tˆ=MAD (the smallest value that admits a possible ground truth) and {a mathematical formula}r=1 implies {a mathematical formula}tˆ=t⁎ (the true average error). In our experiments we use {a mathematical formula}r∈[0,2]; here, {a mathematical formula}tˆ is an overestimate of {a mathematical formula}t⁎ for {a mathematical formula}r∈(1,2] (a valid upper bound on {a mathematical formula}t⁎), but an underestimate of {a mathematical formula}t⁎ for {a mathematical formula}r∈[0,1) (an invalid upper bound on {a mathematical formula}t⁎).
     </paragraph>
     <paragraph>
      Figs. 2(c) and 2(d) show the results for the dots and puzzle datasets, respectively, for a representative noise level (level 3 in previous experiments) and the Kendall tau distance. We can see that {a mathematical formula}OPTdKT (solid red line) outperforms all other voting rules as long as {a mathematical formula}tˆ is a reasonable overestimate of {a mathematical formula}t⁎ ({a mathematical formula}r∈[1,2]), but may or may not outperform them if {a mathematical formula}tˆ is an underestimate of {a mathematical formula}t⁎. Again, other distance metrics generate similar results (see the appendix for details).
     </paragraph>
     <paragraph>
      Comments on the empirical results. It is genuinely surprising that on real-world datasets, {a mathematical formula}OPTd (a rule designed to work well in the worst-case) provides a significantly superior average-case performance compared to most prominent voting rules by utilizing minimal additional information — an approximate upper bound on the average error in the input votes.
     </paragraph>
     <paragraph>
      The inferior performance of methods based on probabilistic models of error is also thought provoking. After all, these models assume independent errors in the input votes, which is a plausible assumption in crowdsourcing settings. But such probabilistic models typically assume a specific structure on the distribution of the noise, e.g., the exponential distribution in Mallows' model [26], and it is almost impossible that noise in practice would follow this exact structure. In contrast, our approach only requires a loose upper bound on the average error in the input votes. In crowdsourcing settings where the noise is highly unpredictable, it can be argued that the principal may not be able to judge the exact distribution of errors, but may be able to provide an approximate bound on the average error.
     </paragraph>
    </section>
    <section label="6">
     <section-title>
      Discussion
     </section-title>
     <paragraph>
      Uniformly accurate votes. Motivated by crowdsourcing settings, we considered the case where the average error in the input votes is guaranteed to be low. Instead, suppose we know that every vote in the input profile π is at distance at most t from the ground truth {a mathematical formula}σ⁎, i.e., {a mathematical formula}maxσ∈π⁡d(σ,σ⁎)≤t. If t is small, this is a stronger assumption because it means that there are no outliers, which is implausible in crowdsourcing settings but plausible if the input votes are expert opinions. In this setting, it is immediate that any vote in the given profile is at distance at most {a mathematical formula}d↓(t) from the ground truth. Moreover, the proof of Theorem 4 goes through, so this bound is tight in the worst case; however, returning a ranking from the profile is not optimal for every profile.
     </paragraph>
     <paragraph>
      Randomization. We did not consider randomized rules, which may return a distribution over rankings. If we take the error of a randomized rule to be the expected distance of the returned ranking from the ground truth, it is easy to obtain an upper bound of t. Again, the proof of Theorem 4 can be extended to yield an almost matching lower bound of {a mathematical formula}d↓(t). While randomized rules provide better guarantees, they are often impractical: low error is only guaranteed when rankings are repeatedly selected from the output distribution of the randomized rule on the same profile; however, most social choice settings see only a single outcome realized.{sup:6}
     </paragraph>
     <paragraph>
      Complexity. A potential drawback of the proposed approach is computational complexity. For example, consider the Kendall tau distance. When t is small enough, only the Kemeny ranking would be a possible ground truth, and {a mathematical formula}OPTdKT or any finite approximation thereof must return the Kemeny ranking, if it is unique. The {a mathematical formula}NP-hardness of computing the Kemeny ranking [6] therefore suggests that computing or approximating {a mathematical formula}OPTdKT is {a mathematical formula}NP-hard.
     </paragraph>
     <paragraph>
      One way to circumvent this computational obstacle is picking a ranking from the given profile, which provides a weaker bound of 3t instead of 2t on the distance from the unknown ground truth (see Theorem 2). However, in practice the optimal ranking can also be computed using various fixed-parameter tractable algorithms, integer programming solutions, and other heuristics, which are known to provide good performance for these types of computational problems (see, e.g., [8], [7]). More importantly, the crowdsourcing settings that motivate our work inherently restrict the number of alternatives to a relatively small constant: a human would find it difficult to effectively rank more than, say, 10 alternatives. With a constant number of alternatives, we can simply enumerate all possible rankings in polynomial time, making each and every computational problem considered in this paper tractable. In fact, this is what we did in our experiments. Therefore, we do not view computational complexity as an insurmountable obstacle.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <section-title>
      Additional experiments
     </section-title>
     <paragraph>
      In the paper, we presented experiments (Fig. 2) that compare our proposed worst-case optimal rule against other voting rules when: i) it receives the true error of a profile {a mathematical formula}t⁎=d(π,σ⁎) as an argument (Figs. 2(a) and 2(b)), and ii) when it receives an estimate {a mathematical formula}tˆ of {a mathematical formula}t⁎ (Figs. 2(c) and 2(d)). In these experiments, we used the Kendall tau distance as the measure of error. In this section we present additional experiments in an essentially identical setting but using the other three distance metrics considered in this paper as the measure of error. These experiments affirm that our proposed rules are superior to other voting rules independent of the error measure chosen. Fig. A.3, Fig. A.4, Fig. A.5 show the experiments for the footrule distance, the Cayley distance, and the maximum displacement distance, respectively.
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>