<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Increasing threshold search for best-valued agents.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      In many multi-agent systems (MAS), it is often necessary to find the agent associated with the best value (lowest or highest, depending on the application) amongst a set of agents, each associated with some value to the searcher. If there are no predefined relationships between the agentsʼ values, state-based search methods like BFS, IDDFA, and A* must probe all agents for their values in order to determine which agent is associated with the best value. The number of agents that need to be probed can be reduced only by using some mechanism that distinguishes the set of agents that comply with some condition. One such mechanism is the publication of a request to all agents to communicate their values to the searcher if they comply with some threshold (i.e., whose values are below/above it). An intuitive search method based on this mechanism, denoted increasing threshold search, publishes a higher (or lower) threshold each time a request fails to yield any replies. A search strategy in this case defines the sequence of thresholds to use until the best-valued agent is found.
     </paragraph>
     <paragraph>
      We illustrate the above by considering a government agency searching for the cheapest contractor to provide a service. The agency can issue a call for bids to all potential contractors, who then prepare and submit their bids to the agency, after which it selects the lowest bid amongst all those it received. While this protocol guarantees finding the lowest bidder, it is not necessarily the most cost-efficient one. For example, consider the case in which there is a cost to the contractors for preparing and submitting their bids and to the agency for processing them. Since the agency only needs to learn the value of the lowest bid and the corresponding bidder, the costs of preparing, submitting, and processing all bids are extraneous. However, it is still necessary to include all potential bidders in the search process in order to guarantee finding the lowest bidder.
     </paragraph>
     <paragraph>
      If the agency is interested in minimizing the expected overall costs to all parties involved, from the social-welfare perspective, or merely in minimizing its own costs, it can apply increasing threshold search instead. The agency publishes a threshold on allowable bids (e.g., a reservation price), requesting that contractors submit their bids only if they are below this threshold. Assuming the contractors can and do estimate what the value of their bids will be once they prepare them, only those whose estimates are below the threshold actually prepare and submit their bids. If the agency does not receive any bids, then it publishes a higher threshold with a similar request. It repeats this process until it obtains a non-empty set of bids, which necessarily includes the lowest bid, and selects the lowest bid from that set. This potentially reduces the number of bids made and the associated costs while ensuring that all bidders are included in the search process. However, if there is a cost to the agency for publishing a call for bids, then additional costs are incurred each time a threshold is published. Despite these additional costs, the right sequence of thresholds can result in lower costs than the original protocol, thereby minimizing search costs to the agency and improving social welfare.
     </paragraph>
     <paragraph>
      Many multi-agent systems can benefit from increasing threshold search. It is applicable in environments in which: (a) each agent is associated with a single value, which it knows, and which may be an intrinsic value associated with the agent or a mapping from a combination of values associated with the agent; and (b) the searcher can publish a request to all other agents. For example, a volunteer ambulance corps dispatcher needs to find the closest volunteer to an emergency. She must page the volunteers and request that they call back to learn their locations. Instead of requesting that all volunteers call back, she can request that only volunteers within a certain distance of the emergency call back, and repeat the request with greater distances until at least one volunteer calls. Similarly, in sensor networks, only extreme values may be of interest [38], [39]. Requesting that all sensors send their data significantly depletes the sensorsʼ power supply. Rather, the user can request only readings above a certain threshold and iteratively decrease the threshold until at least one reply is received.
     </paragraph>
     <paragraph>
      This paper thoroughly analyzes the problem of deriving the optimal threshold-based search sequence in settings similar to those above. It is assumed that all agent values are associated with a common distribution, which is known to the searching agent and remains constant over time [1], [2], [7], [29], [30], [31]. Learning the actual value of an agent incurs some cost to the searcher, the searched agent, or both (e.g., consuming some of the agentsʼ resources for communicating with each other, querying for relevant information, and processing the information received). Such costs are commonly incurred in multi-agent systems in the absence of a central source that can supply full, immediate, and reliable information on the environment and the state of the other agents that can be found [2], [12], [23]. Additionally, there are possible publishing costs, which remain constant throughout the search process.
     </paragraph>
     <paragraph>
      Although the problem of optimizing search sequences has been extensively analyzed in other contexts [3], [7], [8], [10], the results are not applicable to the problem analyzed here, as discussed in Section 4. One important result in this paper is that the thresholds in the optimal search sequence are characterized by a common probabilistic property. This is because of the way in which the costs of potentially terminating a search are balanced with the expected costs of continuing the search. This result is important because it enables the extraction of a distribution-independent solution. This way, one generic solution can be used to extract the optimal strategy for a large set of problems that only differ in the distribution with which the agent values are associated. In addition, distribution-independent observations of the properties of the optimal sequence can be made, such as expected costs and expected number of rounds. In particular, it is proven that the optimal sequence of thresholds contains a single or an infinite number of thresholds. This is significant, since these types of properties are often analyzed for only a few cases in other problems.
     </paragraph>
     <paragraph>
      In the next two sections, we formally introduce and analyze the optimal increasing threshold search for the class of environments described above. In Section 4, we illustrate the properties of the optimal strategy with different values of the problem parameters. The benefits of using the optimal strategy are illustrated by comparing it to adaptations of three well-studied expanding ring strategies [3], [9], [19] to the problem considered in this paper. In Section 5, we extend the analysis to the case where a group of the best-valued agents needs to be found. This, too, has many real-life applications; for example, extending the applications discussed above, a government agency may need to choose a few of the least costly contractors for a project (if it is too big for any single contractor), or an emergency event may require the arrival of several volunteers to a specific location. We show that a similar method of analysis can be applied to this case.
     </paragraph>
     <paragraph>
      In Section 6, we show how increasing threshold search is useful for more than just finding the best-valued agent. It is also applicable to economic search[2], [27], [30], in which the searcher is not necessarily constrained to finding the best-valued agent, but rather attempts to optimize a function that integrates both search costs and the value of the agent ultimately found. Search theory is an important research domain, flourishing in many disciplines, and best known perhaps for its applications to labor markets, marriage markets, monetary economics, and information theory [26], [33], [44]. By finding the lowest valued agent with a minimal search cost, increasing threshold search potentially achieves this goal, and in many settings can lead to a better overall performance than traditional economic search methods from the economic search point of view. We also show how economic search strategies can be combined with threshold-based searches to further reduce overall costs. We conclude the paper with a review of the relevant literature in Section 7 and a discussion of the results in Section 8. Throughout the paper, we illustrate the properties of the various search techniques using data from a synthetic environment.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Model formulation
     </section-title>
     <paragraph>
      This section formally defines the environment in which an increasing threshold search is conducted, the process of conducting an increasing threshold search, and the parameters that define its cost. A summary of the complete set of notations presented in this and all other sections can be found in Appendix A.
     </paragraph>
     <paragraph>
      We consider an agent searching in an environment where N other agents, applicable to its search, can be found. Each of the N agents is characterized by its value to the searcher. Each agent knows its value from the beginning of the search and does not need to consume resources in order to calculate it. As in most search-related models, the values are assumed to be associated with a common continuous distribution described by a PDF {a mathematical formula}f(x) and a CDF {a mathematical formula}F(x), defined over the interval {a mathematical formula}[xmin,xmax][1], [2], [7], [11], [29], [30], [31], [40]. The searcher agent is assumed to be ignorant of the value associated with each of the N agents, but acquainted with the overall distribution of values. The searcher is interested in finding the agent associated with the best value, which, depending on the application, is either the minimum or the maximum value. Without loss of generality, we assume that the best-valued agent is the one associated with the minimum value.
     </paragraph>
     <paragraph>
      In order for the searcher to refine the population of agents whose values it obtains, it can publish a maximum threshold r on the agentsʼ values, denoted a reservation value, requesting to communicate only with agents that comply with that threshold. If at least one agent complies with r and communicates its value to the searcher, the search process terminates. Otherwise, the searcher sets a new reservation value {a mathematical formula}r′&gt;r and repeats the process. This continues until at least one agent replies, after which the agent associated with the minimum value is chosen. No constraints are placed on the number of rounds. Accordingly, a strategy S is either a finite sequence {a mathematical formula}[r1,…,rM] ({a mathematical formula}xmin&lt;ri&lt;ri+1&lt;rM=xmax, {a mathematical formula}∀i&lt;M) or an infinite sequence {a mathematical formula}[r1,r2,…] ({a mathematical formula}xmin&lt;ri&lt;ri+1&lt;xmax, ∀i), where {a mathematical formula}ri denotes the reservation value to be used in the ith search round. Note that {a mathematical formula}rM=rmax in all finite sequences in order to guarantee search completeness, since it necessarily results in the retrieval of all agent values.
     </paragraph>
     <paragraph>
      The process of initiating a search round and publishing the next reservation value is associated with a cost α whose value is fixed (e.g., the cost of issuing a new call for bids or the cost of broadcasting a message). Note that this cost may actually be a function of N, but since N remains constant during the search, we can also consider this cost to be constant. Obtaining the actual value of an agent also incurs some cost. In its most general form, the cost of simultaneously obtaining the values of j other agents is {a mathematical formula}β(j) (where {a mathematical formula}β(0)=0 and {a mathematical formula}β(j) is strictly increasing in j) [4], [15], [32]. The overall cost of a search round i is thus {a mathematical formula}α+β(j), where j is the number of agents that comply with {a mathematical formula}ri. The expected accumulated cost of finding the best-valued agent when using strategy S is denoted {a mathematical formula}V(S). The searcherʼs goal is therefore to derive a strategy {a mathematical formula}S⁎ that minimizes {a mathematical formula}V(S).
     </paragraph>
     <paragraph>
      Table 1 maps the problems described in the introduction to the general model introduced in this section.
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Analysis
     </section-title>
     <paragraph>
      In this section, we formulate the expected cost of using a finite search sequence; show how to derive the optimal sequence when the thresholds can only be selected from a finite set of values; prove that the optimal sequence is an infinite sequence of values with a common probabilistic property when the thresholds can be selected from a continuous range of values; show how to derive such an infinite sequence; and prove some basic properties about the optimal solution.
     </paragraph>
     <paragraph>
      Consider a searcher agent using a strategy {a mathematical formula}S=[r1,…,rM=xmax]. If the agent has to start the ith search round, then there is necessarily no agent whose value is below {a mathematical formula}ri−1. The a priori probability of such a scenario is {a mathematical formula}(1−F(ri−1))N. Furthermore, upon reaching the ith round, the searcher agent can update its beliefs concerning the PDF and CDF of the values of the N agents, as it knows that these are necessarily in the interval {a mathematical formula}(ri−1,xmax]. The PDF of the agentsʼ values after publishing {a mathematical formula}ri−1, denoted {a mathematical formula}f(x|ri−1){a mathematical formula}(0&lt;i⩽M), can thus be calculated as ({a mathematical formula}xmin⩽x⩽xmax):{a mathematical formula} Similarly, the CDF of any of the agentsʼ values after publishing {a mathematical formula}ri−1, denoted {a mathematical formula}F(x|ri−1){a mathematical formula}(0&lt;i⩽M), can be calculated as ({a mathematical formula}xmin⩽x⩽xmax):{a mathematical formula} See Fig. 1 for an example PDF and CDF. The expected cost of the ith round is thus:{a mathematical formula} as it takes into account the cost of initiating the new search round and the expected cost of obtaining any possible number of agent values j{a mathematical formula}(0&lt;j⩽N) in round i. This latter cost is the sum, for all j, of the cost {a mathematical formula}β(j) of obtaining j agent values multiplied by all {a mathematical formula}(Nj) combinations of j agents whose values can be obtained, multiplied by the probability {a mathematical formula}F(ri|ri−1)j(1−F(ri|ri−1))N−j of obtaining exactly j agent values in round i if none were found in previous rounds.
     </paragraph>
     <paragraph>
      The probability of starting round i is {a mathematical formula}(1−F(ri−1))N, which is the probability that no agent values are below the previous reservation value {a mathematical formula}ri−1. The expected cost of using strategy S is thus the sum of the expected cost of each of the M search rounds weighted by the probability of reaching that round:{a mathematical formula} The probability of starting the ith search round can alternatively be formulated as the probability that no values were obtained in each of the {a mathematical formula}i−1 previous rounds, expressed as {a mathematical formula}∏j=1i−1(1−F(rj|rj−1))N. Therefore, (4) transforms into:{a mathematical formula}
     </paragraph>
     <paragraph>
      Note that the probability that the search terminates in round i can be calculated as the probability that all agent values are greater than {a mathematical formula}ri−1, {a mathematical formula}(1−F(ri−1))N, minus the probability that all agent values are greater than {a mathematical formula}ri, {a mathematical formula}(1−F(ri))N. Thus, the expected number of search rounds is{a mathematical formula} in which {a mathematical formula}F(r0)=0 and, by definition, {a mathematical formula}F(rM)=F(rmax)=1. Accordingly, (4) can be understood differently by factoring the term {a mathematical formula}(1−F(ri−1))N into the remainder of the expression, resulting in the equation{a mathematical formula} Here, the first term is the expected contribution of the fixed cost of publishing the threshold to the total search cost, which is α times the expected number of rounds. The second term is the expected cost of obtaining the values of all agents that comply with the last published reservation value. This is calculated by summing the cost of obtaining j values, over {a mathematical formula}1⩽j⩽N, times the probability that j and only j agents comply with the reservation value published in the last search round.
     </paragraph>
     <paragraph>
      For the specific case in which the reservation values are chosen from a finite set of L values {a mathematical formula}{x1,…,xL}, {a mathematical formula}xmin&lt;xi&lt;xi+1&lt;xL=xmax for all i, the optimal strategy can be derived with the following dynamic programming formulation in {a mathematical formula}O(L2N) time:{a mathematical formula} Here, {a mathematical formula}C(l) is the cost of continuing the search if a search using reservation value {a mathematical formula}xl failed to obtain any applicable agent values. {a mathematical formula}C(l) is solved for using backwards induction, each time determining what would be the best reservation value larger than {a mathematical formula}xl to use if {a mathematical formula}xl is part of the search sequence. The optimal sequence and its expected cost is determined by {a mathematical formula}C(0).
     </paragraph>
     <paragraph>
      For the general case in which the interval {a mathematical formula}[xmin,xmax] is continuous, the optimal search strategy must be derived using a different methodology since, as we prove in Theorem 1, the optimal search sequence is either a single search round in which the values of all agents are obtained or an infinite sequence of reservation values.
     </paragraph>
     <paragraph label="Theorem 1">
      The sequence of reservation values that minimizes the expected cost of an iterative threshold search is either{a mathematical formula}[r1=xmax]or an infinite sequence{a mathematical formula}[r1,r2,…],{a mathematical formula}ri&lt;ri+1&lt;xmax,{a mathematical formula}∀i⩾1.
     </paragraph>
     <paragraph label="Proof">
      Assume that the finite sequence {a mathematical formula}S1=[r1,…,rM] is the sequence that minimizes the expected cost. We will show that the assumption {a mathematical formula}V(S1)&lt;V([xmax]) leads to a contradiction, implying that the sequence that minimizes the expected cost is either {a mathematical formula}[xmax] or infinite in length. We use {a mathematical formula}Si=[ri,…,rM] to denote the optimal strategy to be used from round i ({a mathematical formula}1&lt;i⩽M) onwards if no agent is found in round {a mathematical formula}i−1 and denote its expected cost from that point on by {a mathematical formula}V(ri−1)(Si). Using {a mathematical formula}Si, we construct an alternative strategy {a mathematical formula}Si′=[ri′,…,rM′] to be applied from the first round, where {a mathematical formula}F(rj′)=F(rj|ri−1)=Pj′, {a mathematical formula}∀i⩽j⩽M, and for some {a mathematical formula}Pj′ (Fig. 2(a)). The expected cost of the new strategy {a mathematical formula}Si′ is denoted {a mathematical formula}V(Si′). Note that{a mathematical formula} By substituting {a mathematical formula}F(ri|ri−1) with {a mathematical formula}F(ri′|ri−1′) in (5), we obtain {a mathematical formula}V(Si′)=V(ri−1)(Si). Since {a mathematical formula}S1 is the optimal strategy, {a mathematical formula}V(S1)⩽V(Si′).Now consider a new strategy {a mathematical formula}Si″=[r1″,…,rM″] to be applied from round i onwards when {a mathematical formula}ri−1 was applied in round {a mathematical formula}i−1, where {a mathematical formula}F(rj″|ri−1)=F(rj)=Pj″, {a mathematical formula}∀1⩽j⩽M (Fig. 2(b)). According to this, {a mathematical formula}rj″ is the reservation value to be used in round {a mathematical formula}i+j−1 when {a mathematical formula}ri−1 was used in round {a mathematical formula}i−1. We denote the expected cost of {a mathematical formula}Si″ from round i onwards {a mathematical formula}V(ri−1)(Si″). Note that {a mathematical formula}F(rj″|rj−1″)=F(rj|rj−1)=Pj″, as above. According to (5), we obtain {a mathematical formula}V(ri−1)(Si″)=V(S1). Since {a mathematical formula}Si is the optimal strategy from round i onwards, {a mathematical formula}V(ri−1)(Si)⩽V(ri−1)(Si″), resulting in {a mathematical formula}V(S1)⩽V(Si′)=V(ri−1)(Si)⩽V(ri−1)(Si″)=V(S1), which can hold only if {a mathematical formula}V(ri−1)(Si)=V(S1).This logic applies to all search rounds {a mathematical formula}2⩽i⩽M. In particular, this implies that {a mathematical formula}V(S1)=V(rM−1)(SM). However, we necessarily find all agents in the last (Mth) round, since {a mathematical formula}rM=xmax; thus, {a mathematical formula}V(SM)=α+β(N). Therefore, we obtain {a mathematical formula}V(S1)=α+β(N)=V([xmax]), which contradicts the assumption that {a mathematical formula}S1 minimizes the expected cost, unless {a mathematical formula}S1=[xmax].  □
     </paragraph>
     <paragraph label="Corollary 1">
      The argument that {a mathematical formula}V(rj−1)(Sj)=V(S1) holds even for infinite sequences, establishing the following corollary. When the sequence of reservation values that minimizes the expected cost of an iterative threshold search is an infinite sequence, the cost of continuing the search from any round onwards is a constant value.
     </paragraph>
     <paragraph>
      By the same argument, it is clear that the reservation values can be set such that {a mathematical formula}F(ri|ri−1)=P, {a mathematical formula}∀i&gt;1 and some value P. The next theorem establishes that this is necessarily the case.
     </paragraph>
     <paragraph label="Theorem 2">
      When the optimal sequence of reservation values is the infinite sequence{a mathematical formula}[r1,r2,…],{a mathematical formula}xmin&lt;ri&lt;xmax,{a mathematical formula}∀i&gt;0, the values of{a mathematical formula}riare necessarily set such that{a mathematical formula}F(ri+1|ri)=F(r1)=P, for some{a mathematical formula}0&lt;P&lt;1and{a mathematical formula}∀i&gt;0.
     </paragraph>
     <paragraph label="Proof">
      First note that we can formulate the expected cost from any round i onwards as follows:{a mathematical formula} where {a mathematical formula}V⁎ is the expected cost of continuing the search, which is constant according to Corollary 1. We prove that only one value of {a mathematical formula}Pi minimizes this formula by showing that the first derivative with respect to {a mathematical formula}Pi is monotonically increasing, and that this value is the same for all i.Taking the first derivative, we have:{a mathematical formula}The transition from the third line to the fourth line is made by setting {a mathematical formula}k=i−1. The first term in the big square brackets of the last line is a polynomial in {a mathematical formula}s=Pi1−Pi of degree {a mathematical formula}N−1, with vanishing constant term and other coefficients positive. Thus as {a mathematical formula}Pi increases from 0 to 1, causing {a mathematical formula}s=Pi1−Pi to increase monotonically from 0 to ∞, this first term increases monotonically from 0 to ∞. Thus for small {a mathematical formula}Pi, the derivative is less than 0; there is a unique value of {a mathematical formula}Pi, {a mathematical formula}Pi⁎, at which the derivative equals 0; and for {a mathematical formula}Pi&gt;Pi⁎, the derivative is greater than 0. Since all other terms are the same for all values of i, {a mathematical formula}Pi⁎ is also the same for all values of i.  □
     </paragraph>
     <paragraph>
      With these two theorems, it is now possible to show how to derive the optimal strategy. A unique result of the above analysis is that the optimal increasing threshold search strategy can be expressed as a single value {a mathematical formula}0&lt;P⩽1, denoted the reservation probability. Based on this observation, the optimal search strategy can be derived by calculating P and then setting each reservation value {a mathematical formula}ri such that {a mathematical formula}F(r1)=F(ri|ri−1)=P, {a mathematical formula}∀i&gt;1. First we show how to derive the reservation probability P, and then we show how to calculate each {a mathematical formula}ri. Since the optimal sequence is infinite and the expected cost from each round onwards is stationary, the expected cost of using P can be expressed with the following equation:{a mathematical formula} Here, the first term is the fixed cost per round, the second term is the expected cost of obtaining any values, and the last term is the expected cost of continuing the search if necessary. Consequently:{a mathematical formula} The value {a mathematical formula}P=P⁎ that minimizes {a mathematical formula}V(P) in (11) is the optimal reservation probability. If {a mathematical formula}P⁎ cannot be solved for directly, then it can be solved for by numerical approximation. Based on (2), each {a mathematical formula}ri corresponding to {a mathematical formula}P⁎ can be calculated by solving for {a mathematical formula}ri in the equation {a mathematical formula}P⁎=F(ri)−F(ri−1)1−F(ri−1), which yields the equation{a mathematical formula}
     </paragraph>
     <paragraph>
      Just as in (7), (11) can be decomposed into two parts: {a mathematical formula}α1−(1−P)N and {a mathematical formula}∑j=1Nβ(j)(Nj)Pj(1−P)N−j1−(1−P)N, respectively representing the expected contribution of the fixed cost to the total search cost and the expected cost of obtaining the agent values. The expected number of search rounds is {a mathematical formula}11−(1−P)N. The probability of obtaining j agent values is {a mathematical formula}(Nj)Pj(1−P)N−j1−(1−P)N, since this becomes a Bernoulli sampling process with a success probability of {a mathematical formula}1−(1−P)N.
     </paragraph>
     <paragraph>
      An important result of the above analysis is that P is distribution independent. This means that the searcher only needs to solve for P once for fixed values of N, α, and {a mathematical formula}β(j). This also means that certain properties of the optimal strategy, such as the expected cost and the expected number of rounds, do not depend on the probability distribution. P is distribution independent because of the infinite nature of the optimal sequence. P takes the place of the cumulative conditional probability distribution in (5). It is set to a value that balances the cost obtaining several agent values with the expected cost of continuing a search. Since the optimal strategy is an infinite sequence, the searcher is faced with the same problem each round and therefore attempts to make the same tradeoff each round. The infinite nature of the optimal sequence is due to the existence of unlimited opportunities to effect this tradeoff and not incur the full cost of obtaining all agent values.
     </paragraph>
     <paragraph>
      We now analyze several properties of the optimal solution. Proposition 1 establishes when the optimal strategy is to set {a mathematical formula}r1=xmax; specifically, when {a mathematical formula}β(i)=0.
     </paragraph>
     <paragraph label="Proposition 1">
      The optimal strategy is{a mathematical formula}[xmax]if and only if{a mathematical formula}β(i)=0.
     </paragraph>
     <paragraph label="Proof">
      First we prove that {a mathematical formula}[xmax] is the optimal strategy if {a mathematical formula}β(i)=0. Substituting 0 for {a mathematical formula}β(j) in (11) obtains {a mathematical formula}V(P)=α1−(1−P)N. Setting {a mathematical formula}P=1 minimizes this expression, which is equivalent to using {a mathematical formula}xmax in the first search round.Next we prove that it is necessarily the case that {a mathematical formula}β(i)=0 if the optimal strategy is {a mathematical formula}[xmax]. We show that there always exists a value P for which the expected cost of using the infinite sequence is less than the expected cost of using a single search when {a mathematical formula}β(j)&gt;0. Formally, using (11), we need to show the following inequality holds for some value of {a mathematical formula}0&lt;P&lt;1:{a mathematical formula} We multiply both sides by {a mathematical formula}1−(1−P)N, yielding:{a mathematical formula} Notice that {a mathematical formula}β(N) can be written as {a mathematical formula}β(N)(1−P+P)N=β(N)(1−P)N+∑j=1Nβ(N)(Nj)Pj(1−P)N−j. Therefore:{a mathematical formula} Notice that both terms on the right hand side are positive for any P. Therefore, if we prove that there exists a value P for which {a mathematical formula}α(1−P)N=N(β(N)−β(1))P(1−P)N−1 then the inequality holds. If {a mathematical formula}α(1−P)N=N(β(N)−β(1))P(1−P)N−1, we have:{a mathematical formula}{a mathematical formula} The left hand side is positive and finite. {a mathematical formula}P1−P=0 when {a mathematical formula}P=0 and approaches infinity when {a mathematical formula}P→1. Therefore, there must exist such a P.  □
     </paragraph>
     <paragraph>
      In contrast to Proposition 1, Proposition 2 states that the optimal strategy when there is no cost for initiating a new search round ({a mathematical formula}α=0) is to increment the reservation value by the smallest amount possible, such that the expected number of values obtained is minimized.
     </paragraph>
     <paragraph label="Proposition 2">
      If{a mathematical formula}α=0, the optimal strategy is to use{a mathematical formula}P→0, i.e., to increment the reservation value by{a mathematical formula}ϵ→0each round.
     </paragraph>
     <paragraph label="Proof">
      Notice that {a mathematical formula}limP→0β(j)(Nj)Pj(1−P)N−j1−(1−P)N equals {a mathematical formula}β(j) for {a mathematical formula}j=1 and 0 for {a mathematical formula}j&gt;1, according to LʼHôpitalʼs rule. Substituting {a mathematical formula}α=0 in (11), we obtain {a mathematical formula}limP→0V(P)=β(1). Since {a mathematical formula}β(i) is increasing, according to the model assumption, the result obtained is the minimum expected cost possible.  □
     </paragraph>
     <paragraph>
      Finally, Proposition 3 highlights how the tradeoff between obtaining a certain number of agents and continuing a search is affected by P in the case where the cost of obtaining the values of j agents is linear in j.
     </paragraph>
     <paragraph label="Proposition 3">
      When{a mathematical formula}β(j)is linear in j, the reservation probability that minimizes{a mathematical formula}V(P),{a mathematical formula}P=P⁎, satisfies{a mathematical formula}c=(1−P⁎)N−1V(P⁎).
     </paragraph>
     <paragraph label="Proof">
      First, we simplify (11) by substituting {a mathematical formula}β(j) with cj. The expression {a mathematical formula}∑j=1Nj(Nj)Pj(1−P)N−j in the numerator of (11) is the mean of a binomially distributed random variable, which equals NP. Therefore,{a mathematical formula} Differentiating (13) with respect to P and setting it to zero obtains:{a mathematical formula} Notice that {a mathematical formula}V(P)(1−(1−P)N)=α+cNP according to (13). Substituting the latter expression into (14), we observe that the value {a mathematical formula}P⁎ which satisfies the equation is given by {a mathematical formula}cN(1−(1−P)N)−N(1−P)N−1V(P)(1−(1−P)N)=0. Solving for c gets {a mathematical formula}c=(1−P)N−1V(P).  □
     </paragraph>
     <paragraph>
      The explanation of Proposition 3 requires understanding the tradeoff associated with any increase in P. By increasing P, the chance of finding each of the agents increases. Each agent found due to the increased chance will incur a cost c. The benefit is that if the agent found due to the increase is the only agent found in that round, then the increase actually saves the expected cost {a mathematical formula}V(P) associated with continuing the search. The probability that the latter case holds is {a mathematical formula}(1−P)N−1 (i.e., when all other agents are characterized with a value above the reservation value set using (12)). Otherwise, the search just ends. Since the incurred cost c is fixed and the expected benefit {a mathematical formula}(1−P)N−1V(P) decreases as P increases, the optimal P value satisfies {a mathematical formula}(1−P)N−1V(P)=c, i.e., when the additional benefit due to the potential saving is offset by the cost incurred by finding that agent.
     </paragraph>
    </section>
    <section label="4">
     <section-title>
      Comparative illustration
     </section-title>
     <paragraph>
      In this section, we illustrate the behavior and performance of the optimal increasing threshold search strategy derived in the previous section. We show the effect of N, α, and β on the optimal strategy and its associated cost. Additionally, we demonstrate the improvement achieved by the optimal search strategy over several base strategies. The magnitude of improvement in some instances illustrates the importance of choosing the right strategy, while other instances demonstrate how these base strategies can sometimes be close to optimal. Since this problem has not been well addressed in the literature, we adapt three well-studied expanding ring search strategies to our problem [3], [9], [19]. Expanding ring search is used to find routes in ad hoc networking and to locate files in peer-to-peer networking. In this method, the searcher assigns a query a time-to-live (TTL) value, which determines the number of hops the query is forwarded. If the search target is not met, the searcher repeats the query with a larger TTL value. The cost structure of expanding ring search is different than the cost structure of the problem addressed in this paper, since the cost per round increases with the search extent, and the search extents are typically drawn from a range of discrete values. Still, in the absence of more suitable alternatives, expanding ring-based strategies are a natural basis for comparison to increasing threshold search. In the following paragraphs, we describe the three strategies and then compare their performance in our context.
     </paragraph>
     <section label="4.1">
      <section-title>
       Two-step strategy
      </section-title>
      <paragraph>
       If an increasing threshold search is to improve search costs, then a two-step strategy {a mathematical formula}S=[r1,r2=xmax] alone will provide some improvement [9]. The expected total cost when using this strategy is:{a mathematical formula} in which {a mathematical formula}P=F(r1). The first two terms are the costs associated with the use of the first reservation value {a mathematical formula}r1, and the third term is the cost of obtaining all agent values if no values were obtained using {a mathematical formula}r1. The optimal two-step strategy is obtained by determining the value P that minimizes (15).
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Fixed increment strategy
      </section-title>
      <paragraph>
       A common design of a multi-round expanding ring search strategy is to use a fixed increment between search extents, searching up to some cutoff value before searching the entire search range [19]. The search sequence is thus of the form {a mathematical formula}{xmin+δ,xmin+2δ,…,xmin+μδ,xmax}. The expected cost of using such a sequence can be calculated using (4). The increment and cutoff value pair with the lowest expected cost is selected from all possible pairs.
      </paragraph>
     </section>
     <section label="4.3">
      <section-title>
       California split rule strategy
      </section-title>
      <paragraph>
       Another well-studied strategy is the California split rule [3]. According to this strategy, the search extent is doubled each round. We adapt this method to our problem by including a cutoff value above which the reservation value is set to {a mathematical formula}xmax, similar to the fixed increment strategy. The search sequence is thus of the form {a mathematical formula}{xmin+δ,xmin+2δ,…,xmin+2μδ,xmax}. The expected cost of using such a sequence can be calculated using (4). The increment and cutoff value pair with the lowest expected cost is selected from all possible pairs.
      </paragraph>
     </section>
     <section label="4.4">
      <section-title>
       Evaluation
      </section-title>
      <paragraph>
       Since the domination of the reservation probability-based strategy over the different expanding ring-based strategies is unquestionable due to its proven optimality, the goal of this evaluation is merely to demonstrate the effect of different parameters on performance. For this purpose, a synthetic environment is an ideal testbed. In the environment used, the agentsʼ values are associated with a truncated normal distribution of values [18], with {a mathematical formula}μ=0.5 and {a mathematical formula}σ=0.125, over the interval {a mathematical formula}(0,1); that is, {a mathematical formula}f(x)=8ϕ(x−0.50.125)ϕ(1−0.50.125)−ϕ(−0.50.125) for {a mathematical formula}0⩽x⩽1, and 0 otherwise. The cost of simultaneously obtaining the values of j other agents is set to {a mathematical formula}β=0.01w(j), where {a mathematical formula}w(j)∈{log(j),j,(j)2} (denoted “log cost”, “linear cost” and “square cost”, respectively). The use of the three different cost functions enables testing different rates of increase in the marginal cost of obtaining the value of an additional agent. The cost of initiating a search round and publishing the reservation value is set to {a mathematical formula}α∈{0.001,0.01,0.1,1} in order to capture the effects of the magnitude of the ratio {a mathematical formula}α/β(j). Table 2 summarizes these parameters, and Fig. 3 illustrates the truncated normal distribution function {a mathematical formula}f(x) and the set of cost functions assigned to {a mathematical formula}β(j).
      </paragraph>
      <paragraph>
       Note again that the optimal reservation probability and the expected cost of the optimal strategy are distribution independent; only the actual reservation values used are determined by the probability function. We illustrate how the reservation values are derived using the settings {a mathematical formula}N=20, {a mathematical formula}α=0.01, {a mathematical formula}β(j)=0.01i, and {a mathematical formula}f(x) as defined above. Substituting 0.01 for c and 20 for N in (13) and using numerical approximation, we find that the value of P that minimizes (13) is approximately 0.058. In this case, {a mathematical formula}r1=F−1(0.058)≈0.304. Substituting 0.058 for {a mathematical formula}F(r1) in (12) yields {a mathematical formula}r2=F−1(0.058(1−0.058)+0.058)≈0.348. Then substituting 0.112 for {a mathematical formula}F(r2) into (12) yields {a mathematical formula}r3=F−1(0.058(1−0.112)+0.112)≈0.377. This continues indefinitely.
      </paragraph>
      <paragraph>
       Fig. 4 shows the expected cost, the expected number of search rounds, and the 99.9th percentile of the number of search rounds required to find the best-valued agent as a function of the number of agents N, for the different values of α and function assignments to {a mathematical formula}β(j). Note that the scale of the y-axis in the first set of charts varies with α in order to improve visualization. The figure also shows the reservation values to be used in each search round when {a mathematical formula}N=20. As expected, α has a substantial effect on the search strategy and expected cost. The reservation value increases as a function of α, since the tradeoff associated with each reservation value accounts for a greater cost of continuing the search if no agent is found. Although the expected number of search rounds decreases as a consequence, the expected cost still increases, due to the greater cost per round. For large values of α and all {a mathematical formula}β(j) cost functions, the reservation probability is set such that the expected number of search rounds is close to 1 due to the substantial cost of initiating a new search round.
      </paragraph>
      <paragraph>
       Amongst the three cost functions, the expected cost is minimal for the log cost function and maximal for the square cost function, in direct correlation with the order of growth of the three functions. The inverse relationship holds for the reservation values because of the higher cost of finding more than one agent associated with the higher order functions. As a result, the expected cost increases due to the increase in the expected number of rounds.
      </paragraph>
      <paragraph>
       Another important observation from Fig. 4 is that the expected cost increases with the number of agents N. Although the expected number of rounds decreases with N for all reservation probabilities, the expected number of agents found also increases. The increase in cost associated with N indicates that, in these settings, the reduction in the number of search rounds does not offset the cost of finding additional agents.
      </paragraph>
      <paragraph>
       From the graphs of the expected number of search rounds (second row), we observe that the expected number of search rounds is below five for all combinations of parameters. This supports the applicability of the optimal strategy: Despite the fact that it is an infinite sequence, the search time in practice is comparable to search with competitive finite sequences. The third row complements this observation. Each curve shows the upper bound on the number of search rounds required {a mathematical formula}99.9% of the time for each of these settings. We see that even when the fixed cost per round is low ({a mathematical formula}α=0.001) and the cost function is high {a mathematical formula}(β(j)=0.001j2), this number is less than thirty-one.
      </paragraph>
      <paragraph>
       Fig. 5 shows the expected cost of using the (optimal) reservation probability-based strategy and the three expanding ring-based strategies as a function of N, for different values of α and function assignments to {a mathematical formula}β(j). The graphs illustrate the domination of the optimal strategy and the dominance relationships amongst the remaining strategies. The two-step strategy never dominates the fixed increment and California split rule strategies, since it is merely a specific instance of both. Although the fixed increment strategy dominates the California split rule strategy in these settings, it is possible to construct specific settings in which the latter dominates the first. It is interesting that while the expected cost of the optimal strategy always increases with the number of agents, the expected costs of the fixed increment and California split rule strategies decrease in some settings. This is because the increased probability of finding an agent with each reservation value sometimes reduces the inefficiency imposed by the constraints on the patterns of increase in the reservation value. Another interesting observation is that the expected costs of the fixed increment and California split rule strategies converge as α increases.
      </paragraph>
      <paragraph>
       The upper row of graphs in Fig. 5 corresponds to the logarithmic {a mathematical formula}β(j) function. All four strategies use higher reservation values as α increases, as the cost of finding more than one agent in a search round becomes negligible in comparison to the cost of requiring an additional search round. Consequently, the three alternative strategies quickly converge to the same expected cost, as their sequences in those cases contain only two reservation values. The optimally infinite strategy, however, produces observably better results, even for {a mathematical formula}α=0.1. This property, that the California split and fixed increment strategies converge more quickly to the performance of the worst strategy (two step) with respect to α than the optimal solution, occurs for the linear cost (middle row) and the square cost (bottom row) functions as well, for larger values of α. In particular, it is interesting to see that for the square cost function, the fixed increment strategy, which performs quite close to the optimal strategy for small α values, becomes substantially worse as α increases. Overall, in these settings, the improvement of the optimal strategy over the other three methods increases as the order of growth of {a mathematical formula}β(j) is increased. Since the optimal search sequence is not constrained to any pattern, it makes a better tradeoff between the cost of finding more than one agent and initiating additional search rounds.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Multiple agent search
     </section-title>
     <paragraph>
      In various settings, search for multiple agents is preferable and even necessary. For example, a government agency seeking bids for a project may prefer to run a second price auction in order to encourage truthful bidding. In such an auction, the agency awards the lowest bidder with the second lowest bid; thus, the agency must obtain the two lowest bids rather than the lowest bid alone. Alternatively, the agency may request a best and final offer from a set of the top bidders after an initial call for bids. In the case of emergency services, several units may be required to attend to an emergency situation. Likewise, a sink in a sensor network may require readings from several sensors to accurately analyze conditions in the field. In all of these examples, the searcher needs to find several best agents. This section extends the analysis of the single-agent threshold search to a multiple best-valued agents search.
     </paragraph>
     <paragraph>
      We apply the analysis methodology described in Section 3 to the model described in Section 2, except that the searcher is interested in finding the K best agents. Without loss of generality, the K best agents are those associated with the K lowest values. The searcher continues its search as long as only {a mathematical formula}k&lt;K agents have been found so far. The searcherʼs state at the beginning of any round is therefore denoted by the pair {a mathematical formula}(r,k), in which r is the last reservation value the searcher used and k is the number of agents found so far. Accordingly, the initial state is {a mathematical formula}(xmin,0).
     </paragraph>
     <paragraph>
      A search strategy is defined by a function {a mathematical formula}S:(r,k)→r′, {a mathematical formula}r′&gt;r, in which {a mathematical formula}r′ is the reservation value to use in a round with initial state {a mathematical formula}(r,k). Since the reservation value {a mathematical formula}r′ depends on the number of agents found so far, a search strategy cannot be defined a priori by a sequence of reservation values as in the case of a single-agent search. Instead, it can be defined by a decision tree, in which each node represents a state {a mathematical formula}(r,k) and has child nodes for all possible {a mathematical formula}k⩽k′&lt;K total number of agents found by the end of that round. Since many states may be repeated throughout the tree, it can be represented more compactly as a directed graph. The searcher terminates its search when at least {a mathematical formula}K−k agents are found in a round with state {a mathematical formula}(r,k) or when {a mathematical formula}S(r,k)=xmax, in which case all K agents are necessarily found. It is realistically assumed that agents only reply the first time they comply with a reservation value. Therefore, the searcher only searches among the remaining {a mathematical formula}N−k agents that did not comply with any reservation value less than or equal to r. It is assumed that the publishing cost is constant (α) for all k, as opposed to assuming that the publishing cost is a function of k. The ensuing analysis is still valid even if these last two assumptions are not made by substituting N for {a mathematical formula}N−k and {a mathematical formula}α(k) for α. Given these assumptions, the expected cost of continuing the search from state {a mathematical formula}(r,k) when using strategy S, denoted {a mathematical formula}V(r,k)(S), is defined recursively as follows:{a mathematical formula} in which {a mathematical formula}V(r,k)(S)=0 for all {a mathematical formula}k⩾K. The total cost of the search is {a mathematical formula}V(xmin,0)(S).
     </paragraph>
     <paragraph>
      We again divide the problem into the discrete and continuous cases. In the discrete case, the reservation values can only be selected from a finite set of L values {a mathematical formula}{x1,…,xL}, {a mathematical formula}xmin&lt;xi&lt;xi+1&lt;xL=xmax. The optimal strategy can be derived with the following dynamic programming formulation, in which {a mathematical formula}C(l,k) is the cost of continuing the search after using reservation value {a mathematical formula}xl and after a total of k agents have been found so far. The optimal cost is determined by {a mathematical formula}C(0,0). The runtime complexity is {a mathematical formula}O(L2KN).{a mathematical formula}
     </paragraph>
     <paragraph>
      As the following analysis shows, the increasing threshold search strategy that minimizes the expected search costs is based on a set of reservation probabilities {a mathematical formula}S={P0,…,PK−1}, where {a mathematical formula}Pk is the reservation probability to be used in any state {a mathematical formula}(r,k), {a mathematical formula}xmin⩽r&lt;xmax, {a mathematical formula}0⩽k&lt;K. The reservation value {a mathematical formula}r′ in state {a mathematical formula}(r,k) can be calculated from the equation {a mathematical formula}r′=F−1(Pk(1−F(r))+F(r)). As in the single-agent search, we prove that this is the optimal strategy by first establishing that the optimal strategy to apply as long as only {a mathematical formula}k&lt;K agents have been found is an infinite sequence of reservation values.
     </paragraph>
     <paragraph label="Theorem 3">
      The increasing threshold search strategy that minimizes the expected search costs is to use the reservation value{a mathematical formula}r′in any state{a mathematical formula}(r,k)such that{a mathematical formula}F(r′|r)=Pk, for some{a mathematical formula}0&lt;Pk⩽1.
     </paragraph>
     <paragraph label="Proof">
      We prove that the expected cost of continuing the search from any state {a mathematical formula}(r,k) onwards is some value {a mathematical formula}Vk using backwards induction on k. By assuming that this is true for all {a mathematical formula}k′&gt;k, we can prove that the optimal sequence of reservation values to use as long as no new agent values are obtained is the infinite sequence {a mathematical formula}r1,r2,… such that {a mathematical formula}F(r1|r)=F(ri+1|ri)=Pk, for some {a mathematical formula}0&lt;Pk⩽1. This result is in turn used to prove the inductive step, since the expected cost is independent of the actual sequence of reservation values.In the base cases, {a mathematical formula}Vk′=0∀k′⩾K by definition, since the search is terminated in such cases. Consider the finite sequence {a mathematical formula}S1=[r1,…,rM], {a mathematical formula}ri&gt;r∀1⩽i⩽M. The expected cost of using {a mathematical formula}S1 from state {a mathematical formula}(r,k) onwards is:{a mathematical formula} where {a mathematical formula}F(r1|r0)=F(r1|r).Using the same reasoning as in Theorem 1, we can show that the assumption that any finite sequence minimizes the expected cost leads to a contradiction, proving that the optimal sequence is the infinite sequence {a mathematical formula}r1,r2,… . Likewise, we can formulate the expected costs similar to the way we did in Theorem 2 and prove that only one value of P (that is, {a mathematical formula}Pk) minimizes the expected search costs. Finally, just as we did in Eq. (11), we can formulate the expected cost of using this reservation probability as:{a mathematical formula} This expression is independent of any reservation values used during the search, thus completing the inductive step that shows that the expected cost of continuing the search from any state {a mathematical formula}(r,k) is some constant {a mathematical formula}Vk.  □
     </paragraph>
     <paragraph>
      The optimal values of {a mathematical formula}Pk ({a mathematical formula}0⩽k&lt;K) can be calculated using backward induction: Given the optimal {a mathematical formula}Pj for all {a mathematical formula}j&gt;k, calculate {a mathematical formula}Pk ({a mathematical formula}0⩽k&lt;K) with (19). The actual reservation values are derived in a similar manner as in the single-agent search. The first reservation value {a mathematical formula}r0 is calculated with {a mathematical formula}r0=F−1(P0). Then, the reservation value to be used in any state {a mathematical formula}(r,k) is calculated by substituting {a mathematical formula}Pk for {a mathematical formula}P⁎ in (12).
     </paragraph>
     <paragraph>
      We illustrate the properties of the optimal search for multiple agents under the settings in Table 2 and compare it to an alternative strategy based on the single-agent search. In the alternative strategy, the searcher searches for one agent at a time, using the optimal P from (11) for {a mathematical formula}N−k agents when k agents have already been found. That is, the searcher begins by searching for one agent using P from (11). Upon finding {a mathematical formula}k⩾1 agents, the searcher begins a new search for one agent using P from (11), modified to reflect that only {a mathematical formula}N−k agents are left to reply, and that all remaining agent values are above the last reservation value used. This is continued until the total number of values obtained is greater than or equal to K. Fig. 6 shows the optimal values of {a mathematical formula}Pk according to (19) and P according to (11) as functions of the number of agents k already found for {a mathematical formula}N=20; different numbers of agents K that need to be found; {a mathematical formula}α=0.1; and the different {a mathematical formula}β(j) cost functions. As can be observed from the figure, {a mathematical formula}Pk decreases as k increases for the log and linear cost functions and all values of K, at a greater rate for the linear cost function. This can be attributed to two conflicting effects of the increase in k on the search: On one hand, as the number of available agents decreases, the expected number of agents found with any reservation value decreases, possibly supporting an increase in the reservation probability. On the other hand, the probability of finding more than {a mathematical formula}K−k agents with each reservation probability increases, supporting a decrease in the reservation probability. Since the latter effect is more influential than the first, the reservation probability decreases as a function of k.
     </paragraph>
     <paragraph>
      The behavior of the square cost function differs from the other two. The most obvious difference is that the reservation probability is initially small, increases as the number of agents found increases, then decreases. In particular, when all agents need to be found ({a mathematical formula}K=20), the reservation probability is set to a value less than 1, even though no unnecessary agents will be found if it is set to 1. This is because the cost function is convex; thus, there is a high penalty of finding a large number of agents at once. A careful analysis of the data reveals that the reservation probabilities in this case are indeed set such that the expected number of agents found is almost the same each round. However, as the number of remaining agents approaches 0, the reservation probability decreases accordingly to avoid finding unnecessary agents.
     </paragraph>
     <paragraph>
      As expected, the optimal reservation probability {a mathematical formula}Pk for the multi-agent search is substantially greater than the optimal reservation probability for a single-agent search. In most cases, {a mathematical formula}Pk increases as the total number of agents K that need to be found increases. The square cost function is an exception. As evident from Fig. 6, the reservation probability for the case ({a mathematical formula}K=18, {a mathematical formula}k=14) is greater than the one for the case ({a mathematical formula}K=20, {a mathematical formula}k=14). This is attributed to the nature of the cost function, as discussed above. In particular, the tradeoff between the expected number of rounds and agents found differs for the case of ({a mathematical formula}K=20, {a mathematical formula}k=14), since in this case there is no problem of finding more agents than necessary.
     </paragraph>
     <paragraph>
      Fig. 7 shows the percentage by which the optimal strategy reduces the expected cost of the alternative strategy as a function of K, for different cost functions and values of N. The cost reduction highly depends on the cost function {a mathematical formula}β(j) and can be quite substantial, up to {a mathematical formula}20% for the square cost function and {a mathematical formula}80% for the log cost function. Furthermore, the improvement increases as the total number of agents K that need to be found increases, as the savings by finding several agents in one round increases. This improvement is mild for the square cost function for the reasons discussed above. It is noteworthy that N has only a minor effect on the cost reduction. An increase in N results in a small decrease in the cost reduction, at a decreasing rate.
     </paragraph>
    </section>
    <section label="6">
     <section-title>
      Application to economic search
     </section-title>
     <paragraph>
      While the goal of increasing threshold search is to find the best-valued agent, the goal of searchers in many applications may be to find a suitable agent while optimizing the process as a whole [4], [20], [32]. For example, consider a buyer agent that is interested in purchasing a product and that obtaining posted prices from seller agents incurs a cost (e.g., communication costs). The buyer agent can purchase the product from any of the seller agents. As the buyer increases the number of sellers with which it communicates, the price it expects to pay for the product decreases, but its overall communication costs increase. Thus, the optimal search strategy is a trade-off between the marginal saving of each additional price obtained and the cost of obtaining it.
     </paragraph>
     <paragraph>
      The research domain in which such problems are studied is called search theory ([27], [30], and references therein). Within the framework of search theory, two main clusters of search models can be found: (a) the sequential search model and (b) the fixed sample size model. In the sequential search model [27], [36], the searcher obtains a single agent value at a time, allowing multiple search stages. An example of a sequential search is a buyer who checks prices at different stores until the available options are satisfactory, and then returns to the store with the best option. In the fixed sample size model, the searcher obtains a large set of agent values in a single search round [42], and then chooses the agent associated with the best value. This is most applicable when some time constraint limits the searcher to a single search round. For example, when applying to college, one must typically apply to several institutions at the same time and then choose from the best offer after all the applications have been reviewed.
     </paragraph>
     <paragraph>
      While economic search strategies are inapplicable to our problem, as they do not guarantee finding the best-valued agent, increasing threshold search alone and the extensions to it analyzed in this section are useful contributions to economic search theory. This is because increasing threshold search, whenever applicable, can result in an overall reduced cost, even in comparison to the optimal economic search strategy. In this section, we show how the searching agent can benefit from threshold-based searches. We begin by introducing the optimal sequential search and fixed sample strategies as known from search theory. We then show how increasing threshold search can be used as an alternative to sequential search, both on its own and in conjunction with sequential search. Finally, we show how the fixed sample search can be augmented with a threshold-based search to improve performance.
     </paragraph>
     <section label="6.1">
      <section-title>
       Optimal economic search strategies
      </section-title>
      <paragraph>
       In the sequential search model [25], [27] a searcher is given N possible opportunities {a mathematical formula}B={B1,…,BN} (e.g., to buy a product) out of which she can choose only one. Each opportunity {a mathematical formula}Bi encapsulates a value to the searcher (e.g., expense, reward, utility). While this value is unknown to the searcher, she is acquainted with the probability distribution function {a mathematical formula}f(x) with which all the values are associated. The true value of any opportunity {a mathematical formula}Bi can be obtained by paying a fee, denoted c.
      </paragraph>
      <paragraph>
       The searcher can continue to obtain the value of any of the opportunities in B, paying each time the cost c. Once the searcher decides to terminate her search (or once she has obtained the value of all opportunities), she collects the minimum value among those revealed up until that time (assuming that she seeks the minimum value). The goal of the searcher is therefore to find the optimal strategy, i.e., a stopping rule that minimizes the expected expense, defined as the value eventually obtained plus the accumulated costs incurred throughout the process.
      </paragraph>
      <paragraph>
       The optimal search strategy for this model is reservation-value based [30]. Note that the term “reservation value” has a slightly different meaning in this context than in the context of increasing threshold search. The searcher sets a reservation value r (i.e., a threshold) and sequentially obtains the value of different opportunities, incurring a cost c, until revealing a value less than the reservation value (or until the values of all opportunities are obtained). Since all of the opportunities are associated with the same probability distribution function {a mathematical formula}f(x), the searcher can obtain the values in any order. This strategy is preferred in particular when the cost of obtaining the value of j agents is linear or super-linear in j, since the searcher does not benefit from obtaining the value of more than one agent at a time. The optimal reservation value, r, is based on the distribution of agent values and the cost of obtaining a value, c[27], [30], [43]. It is the value by which the searcher is indifferent between terminating the search and obtaining r, and resuming the search. The optimal reservation value in this case is derived from [30]:{a mathematical formula}
      </paragraph>
      <paragraph>
       Search theory focuses merely on the optimal stopping rule and does not place much importance on the expected cost of using this rule. Therefore, to compare increasing threshold search with sequential search, we ought to explicitly develop the expected overall cost V of using the latter method. When there are N agents, the expected overall cost of this process is:{a mathematical formula} where {a mathematical formula}E[X|X⩽r] is the expected value of an agent whose value is known to be in the range {a mathematical formula}[xmin,r], and {a mathematical formula}EN[X|X&gt;r] is the expected minimum value in a sample of size N when the minimum value is in the range {a mathematical formula}(r,xmax). The first two terms in (21) reflect the expected value of the opportunity returned by the search and the third term is the expected cost of obtaining the values. The first term is for when the search terminates with an agent with a value less than r (with probability {a mathematical formula}∑i=1NF(r)(1−F(r))i−1), while the second term is when all of the agent values are above r (with probability {a mathematical formula}(1−F(r))N), in which case the smallest value amongst all N agents is selected. {a mathematical formula}E[X|X⩽r] can be calculated using {a mathematical formula}f(x|x⩽r)=f(x)F(r) and {a mathematical formula}F(x|x⩽r)=F(x)F(r), such that {a mathematical formula}E[X|X⩽r]=∫xminryf(y)F(r)dy=r−1F(r)∫xminrF(y)dy. {a mathematical formula}EN[X] can be calculated using the PDF {a mathematical formula}fN(x) and CDF {a mathematical formula}FN(x) of the minimum of an N-size sample. {a mathematical formula}FN(x) is the probability that at least one agent in a sample of size N has the value x or less, which can be expressed as {a mathematical formula}FN(x)=1−(1−F(x))N. Thus, {a mathematical formula}EN[X] can be calculated as follows, using integration by parts in the second step:{a mathematical formula}{a mathematical formula}EN[X|X&gt;r] can be calculated by replacing {a mathematical formula}F(x) with {a mathematical formula}F(x|x&gt;r) and {a mathematical formula}xmin with r in (22).
      </paragraph>
      <paragraph>
       As opposed to the sequential search, in the fixed sample size model [42], the searcher is limited to the selection of one sample of agents overall in a single period of time. The searcher then selects the agent with the lowest value from this sample. The expected cost of this strategy as a function of the number of agents simultaneously sampled, {a mathematical formula}0&lt;K⩽N, is given by:{a mathematical formula}
      </paragraph>
      <paragraph>
       The optimal sample size is the value of K that minimizes (23). For general {a mathematical formula}β(i), we need to check {a mathematical formula}K=1,…,N for the value with the lowest expected cost. If {a mathematical formula}β(i) is linear in i (that is, {a mathematical formula}β(i)=ci) then it is only necessary to solve for K in the equation {a mathematical formula}EK[X]−EK+1[X]=c and then choose {a mathematical formula}⌊K⌋[42].
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       Increasing threshold-limiting sequential search
      </section-title>
      <paragraph>
       Increasing threshold search by itself may be a good alternative to economic search. Since increasing threshold search is only applicable when multiple search rounds are allowed, its most straightforward use is as an alternative to sequential search [27], [36]. The expected cost of the increasing threshold search under the economic search model is composed of the expected cost of search (from (11)) and the expected minimum value obtained (from (22)):{a mathematical formula}
      </paragraph>
      <paragraph>
       The performance of increasing threshold search when used as an alternative to economic search can be improved by processing the agents found using sequential search. According to this improvement, called “increasing threshold-limiting sequential search” from here on, the searcher publishes the thresholds as before until at least one agent responds. Then, instead of processing all of the responses, the searcher processes the responses sequentially as long as the revealed value so far is above some reservation value. Since the responses are all associated with the same probability distribution function, they can be processed in any order, as explained above. In some ways, the searcher is following the original sequential search method; however, its sample space is more targeted, as it is limited by the last threshold to which agents comply. The expected cost of applying a strategy {a mathematical formula}S=[r1,…,rm=xmax] is thus similar to (4), except that {a mathematical formula}β(j) is replaced with the cost {a mathematical formula}V(j,ri−1,ri) of conducting the optimal sequential economic search on j items whose values are between the last two reservation values used, {a mathematical formula}ri−1 and {a mathematical formula}ri. In this case, Theorem 1 and the resulting solution relying on a fixed reservation probability may no longer be applicable, since the transformation from {a mathematical formula}S2 to {a mathematical formula}S1′ and like transformations may not be possible. The complexity of deriving the optimal solution is beyond the scope of this paper. Instead, we show how to solve a discrete version of the problem, in which the reservation values are chosen from a finite set {a mathematical formula}{x1,…,xL}, {a mathematical formula}xmin&lt;xi&lt;xi+1&lt;xL=xmax, just as in Section 3. Replacing {a mathematical formula}β(j) with {a mathematical formula}V(j,xi,xl) in (8) results in the following dynamic programming formulation:{a mathematical formula} For any pair of values {a mathematical formula}xi and {a mathematical formula}xl, r and {a mathematical formula}V(j,xi,xl) can be calculated using (20), (21), respectively, replacing {a mathematical formula}F(x) with {a mathematical formula}F(x)−F(xi)F(xl)−F(xi), {a mathematical formula}xmin with {a mathematical formula}xi, and {a mathematical formula}xmax with {a mathematical formula}xl.
      </paragraph>
      <paragraph>
       In Fig. 8, we illustrate the properties and benefits of using increasing threshold search and its improved form as an alternative to sequential search. We use the synthetic environment described in Section 4 and Table 2, except that agent values are associated with the uniform distribution ({a mathematical formula}f(x)=1 for {a mathematical formula}0⩽x⩽1 and {a mathematical formula}f(x)=0 otherwise). Fig. 8 shows the overall cost of all three strategies (sequential, increasing threshold, and increasing threshold-limiting sequential search) as a function of the number of agents in the environment (horizontal axis), for different values of the ratio {a mathematical formula}α/β(1), different cost functions (linear, logarithmic, and square), and different values of the coefficient c in {a mathematical formula}β(i). As can be observed from the figure, increasing threshold-limiting sequential search results in a lower overall cost than increasing threshold search, and this improvement increases as a function of α. While this characteristic always holds for linear and convex cost functions, it may not hold when the cost is concave (e.g., logarithmic), since the benefit of evaluating all agents found might outweigh the savings obtained by evaluating only part of the set one by one. Overall, both forms of increasing threshold search perform better than sequential search for low α and c values. In these cases, the improvement in value of the selected agent is greater than the additional costs α incurred during the search. Whenever the ratio between the fixed cost of each search iteration and the cost of evaluating an agent ({a mathematical formula}α/β(1)) is sufficiently low, increasing threshold search results in a lower expected overall cost than sequential search. This is a result of the low search costs due to the low {a mathematical formula}α/β(1) ratio. As α increases, the advantages of the threshold-based methods diminish because the sequential search does not incur the cost α.
      </paragraph>
      <paragraph>
       One interesting observation is that while the expected search cost of increasing threshold search increases as a function of the available agents N (see Fig. 4), its overall cost (search cost and value obtained) decreases as N increases. This is because the reduction in the expected minimum value due to the additional agents outweighs the increased search costs. Likewise, we observe that as N increases, the two increasing threshold-based searches dominate sequential search for large {a mathematical formula}α/β(1) ratios.
      </paragraph>
      <paragraph>
       Finally, we note that the difference between the sequential search and the increasing threshold-limiting sequential search does not depend on the cost function {a mathematical formula}β(j). This is because both methods process agent values sequentially, incurring a cost {a mathematical formula}β(1) for each agent sample. This property is especially advantageous for these search methods if the cost function {a mathematical formula}β(j) is convex (e.g., square cost).
      </paragraph>
     </section>
     <section label="6.3">
      <section-title>
       Combined fixed sample size and threshold search
      </section-title>
      <paragraph>
       The fixed sample size search [42] can also benefit from threshold-based searches. While the restriction to a single search round precludes the use of an increasing threshold search to its full extent, the searcher can still improve expected search costs by publishing a single reservation value r besides sampling a fixed number of agent values, K. By publishing a reservation value, the searcher reduces the expected minimum value found by sampling alone, although with the additional expected cost of a one round threshold search. Sampling is still necessary, since it is possible that no agents will comply with the published reservation value. Because only one search round is allowed, both the threshold-based sampling and fixed size sampling must be conducted simultaneously. Returning to the example of contract bidding, this is like a case in which the agency must make a decision in the length of time it takes for contractors to prepare and submit their bids. The agency can simultaneously post a call for all bids under some threshold while soliciting bids from select contractors, and then choose the lowest of all bids. The expected cost in this case is:{a mathematical formula}
      </paragraph>
      <paragraph>
       The first three terms in the above equation reflect the search costs, while the last two terms reflect the expected value of the agent found. The first term is the cost of sampling K elements; the next two terms are for the expected cost of performing a threshold search on the remaining {a mathematical formula}N−K elements; the fourth term is the expected value of the agent found if its value is below the search threshold r, which will be found either by the sample or the threshold search; and the fifth term is the expected value of the agent if its value is above r, in which case it is necessarily one of the K agents sampled. {a mathematical formula}EN[X|X⩽r] can be calculated using {a mathematical formula}fN(x|x⩽r)=fN(x)FN(r) as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       Fig. 9 shows the overall cost of the optimal fixed sample size search and combined fixed sample size and threshold search, using the same settings as in the previous section, as a function of the number of agents in the environment (horizontal axis) for different values of the ratio {a mathematical formula}α/β(1), different cost functions (linear, logarithmic, and square), and different values of the coefficient c in {a mathematical formula}β(i). The combined search substantially improves performance when the ratio {a mathematical formula}α/β(1) or the value of c is small. In these cases, the improvement from possibly finding a more targeted set of agents (that comply with the threshold) is greater than the additional cost α incurred. As α increases, the benefit of the combined search diminishes, and for large α values, there is no benefit to the combined search. This is also true for large values of c, since the expected number of samples obtained according to the optimal strategy is reduced, resulting in an increase in the expected value obtained. Similar to increasing threshold-limiting sequential search, the accumulated search cost of the combined search decreases as a function of N. In contrast, the difference in cost between the combined search and the fixed sample size search highly depends on the cost function used. The improvement is greater for convex functions, such as the square cost function, because the combined search uses a small fixed sample and sets the reservation value to minimize the number of agents found.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Related work
     </section-title>
     <paragraph>
      While relevant literature is extensively cited throughout the paper whenever applicable, we use this section to introduce some additional work that may seem relevant to increasing threshold search and emphasize the differences between these works and ours.
     </paragraph>
     <paragraph>
      Search by iterative expanding extents is used in many contexts; the distinguishing factor in determining optimal search sequences is the cost model. Iterative deepening [24], [41] and iterative broadening [17] are used to find goal states in artificial intelligence. Expanding ring search is used for route discovery in mobile networks, data discovery in sensor networks, and file location in peer-to-peer networks [3], [7], [8], [9], [10], [13], [19], [22], [28], [34], [45]. Iterative deepening, iterative broadening, and expanding ring search share the same cost model: The cost of each round includes the cost of revisiting all previously visited nodes as well as the cost of visiting new nodes. The cost model differs in peer-to-peer networking, since queries are processed only once by each node, but may be forwarded multiple times as the TTL value is increased [45]. Blocking expanding ring search [35] has a similar cost model, since nodes only forward messages once, waiting long enough to allow the source to stop the search if the target was found.
     </paragraph>
     <paragraph>
      The expected search costs were modeled for many of these techniques, but optimal search sequences were primarily analyzed in the context of expanding ring search. Chang and Liu [7] show how to solve the problem optimally using dynamic programming for arbitrary cost and probability distribution functions that are known a priori. They also prove that the optimal strategy when the probability distribution of the minimum hop count to the target is not known a priori is a randomized strategy, derive such a strategy, and prove that it has a tight worst-case approximation factor of e[8]. Baryshnikov, et al. [3], prove that the California split rule is the optimal deterministic strategy when the probability distribution is not known, which has a tight worst-case approximation factor of 4. Cheng and Heinzelman [10] design a novel heuristic called ring splitting to optimize search sequences for multiple targets. The peer-to-peer networking community has employed a technique called dynamic querying in multi-target queries [22], in which the searcher uses intermediate results to determine the next TTL value. The results of all these studies are inapplicable to the problem addressed in this paper because, as stated throughout, the cost models differ.
     </paragraph>
     <paragraph>
      A remarkably long list of articles has been dedicated to variations of the “secretary problem” [14], which is a classical optimal-stopping online problem. Yet, the latter does not involve search costs and the goal is to maximize the probability of finding the best candidate rather than minimizing cost.
     </paragraph>
     <paragraph>
      As discussed in Section 6 the problem of a searcher operating in a costly environment, seeking to maximize its long-term utility, is widely addressed in classical economic search theory ([27], [30], [36] and references therein). Many variants of this model were considered, differing in the decision horizon (finite versus infinite) [27], the presence of the recall option [30], and the distribution of values. Some model variants assume findings are valid for a limited time, and with some probability may become obsolete and irrelevant for the search [25]. Over the years, several attempts were made to adopt search theory concepts for agent-based environments associated with search costs [12], [21], [23]. A few studies attempted to extend the search problem beyond a single search goal, e.g., attempting to purchase several commodities while facing imperfect information concerning prices [5], [6], [16], and to physical domains where the search cost derives from the agentʼs location along the search [20]. Some even considered multi-agent cooperative search for multiple goals [37]. Other work considered the benefit of sequential search as an alternative or a complementary means to mechanism design [1], [29]. For example, McAfee and McMillan [29] showed that a combination of reservation-price search and auction is, with costly communication, the optimal procurement mechanism of a monopolist, when the potential sellers have different production costs. In this case the monopolist sets a reservation value (reservation price) and sequentially offers the firms at this reservation price. If the set of potential bidders is exhausted without anyone accepting, then an auction is held. This idea was extended to the case where there is discounting and several homogeneous units are sought [1]. The main difference between economic search models and the model presented in this paper is that economic-search strategies attempt to find a suitable agent while optimizing the process as a whole, taking into consideration both the value of the agent found and the costs associated along the search, and do not guarantee finding the best-valued agent; thus, they are inapplicable to our problem. Instead, as demonstrated in Section 6, increasing threshold search is useful to economic search theory. To the best of our knowledge, no attempt has been made in search theory literature to use increasing threshold search as an alternative to or as a complementary mechanism to economic search strategies.
     </paragraph>
    </section>
    <section label="8">
     <section-title>
      Discussion and conclusion
     </section-title>
     <paragraph>
      As illustrated throughout the paper, increasing threshold search is highly effective in settings in which the cost of finding the agent associated with either the maximum or minimum value of any specific property needs to be minimized. This problem often arises in MAS, mostly due to their distributed nature. Despite its wide applicability, this method has not received adequate attention in the literature. Most research of techniques utilizing expanding search extents, as discussed in Sections 1 Introduction, 4 Comparative illustration, 7 Related work, has focused on models in which the costs associated with the search are correlated with the extent of search (rather than with the number of agents applicable to the extent used, as in our case). Consequently, the strategies most studied in those domains are very different from the optimal strategy to our problem, both in structure and quality of the solution obtained.
     </paragraph>
     <paragraph>
      The paper introduces a solution to the problem in both the discrete and continuous domains. While the first uses a standard dynamic programming method, the analysis of the latter domain is quite non-standard: By correlating the reservation values to the respective probabilities in the proof of Theorem 1, the essence of the optimal solution in the form of a single reservation probability is revealed, enabling a solution to the problem. Furthermore, both the optimal reservation probability, from which the appropriate thresholds can be calculated, and the corresponding expected cost of search are distribution independent. This means that the solution to one problem instance can be used to derive the optimal search sequence for any other instance that only differs in its distribution of values by merely applying a simple transformation. It also enables making distribution-independent observations given the remaining parameters, such as the expected cost of the optimal strategy and expected number of rounds.
     </paragraph>
     <paragraph>
      The same analysis methodology is replicated for the important and often necessary case of searching for multiple agents. Here, the single reservation probability property is preserved to the extent of any number of agents already found, and all the remaining advantages of the method (e.g., distribution-independence) hold.
     </paragraph>
     <paragraph>
      As evident in Section 6, increasing threshold search can also be useful in economic search settings where the searcher is not constrained to finding the best-valued agent. This result is interesting, since increasing threshold search is by definition constrained by the need to find the best-valued agent. In economic search settings, increasing threshold search can either be used as an alternative to traditional economic search methods (e.g., sequential search), possibly resulting in lower expected overall cost, or to directly augment those methods, making use of the threshold publication aspect as part of or alongside the regular search routine. This has many implications in the evolving research area known also as search theory[30]. The paper defines and demonstrates the effectiveness of two such extensions to economic search, though many more can be considered. The determination of which amongst these search strategies will result in the lowest cost is setting dependent. Yet, given the probability distribution function, the search cost function, and the number of agents available, a searcher facing an economic search problem can follow the analysis given in this paper to calculate the expected cost of each method and choose accordingly.
     </paragraph>
     <paragraph>
      Future work can consider more general assumptions regarding costs and cooperation of the different players. This may require modification of the analysis. In some cases, it may also impose external modeling challenges and even require the integration of buyersʼ strategic behavior. For example, the values of the agents can change in time. This requires external modeling of the way the distributions that characterize the agentsʼ values change over time. We note that in such a case, one may find it more beneficial to use a search technique that is based on increasing and decreasing thresholds. Such a strategy may be useful in cases in which agent values may actually decrease with time. Another example is the possibility that agents do not know their true value and will not readily calculate their value. (The current model assumes that agents know their values or are willing to calculate them—taxi drivers will always know their locations, sensors will know their readings). For example, if the threshold on a call for bids is very low, some contractors may decide that it is not worth preparing a bid and hence will not know their actual value. This requires modeling of the a priori value distribution of different agents, based on which their decision is made. More important, the strategic behavior of the agents, in terms of willingness to prepare a bid based on the threshold they receive, should be modeled and taken into consideration. Another possible extension of this work includes the investigation of competition and cooperation models for two or more searchers when operating in settings where search is costly and one or more of them is capable of using increasing threshold search.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <paragraph>
      {a mathematical formula}
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>