<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Filtering AtMostNValue with difference constraints: Application to the shift minimisation personnel task scheduling problem.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      The problem of minimising the number of distinct values among a set of variables subject to difference constraints occurs in many real-life contexts, where an assignment of resources to tasks has to be optimised. For instance, in transports, crews have to be assigned to trips [42]. In schools, classes have to be assigned to rooms [12]. In airports, maintenance tasks have to be assigned to ground crew employees [16], [17]. In some factories, fixed jobs have to be assigned to machines [23], [24], [38]. In a more theoretical context, one may need to colour a graph, such that adjacent vertices have distinct colours and not every colour can be taken by every node [28], [30]. In order to illustrate our contribution, we consider the Shift Minimisation Personnel Task Scheduling Problem (SMPTSP) [36]. This problem belongs to the set of personnel scheduling problems [19], [57]. It arises when a set of tasks, fixed in time, have to be assigned to a set of shifts so that overlapping tasks are not assigned to the same shift. Each shift is associated with a given subset of assignable tasks. The objective is to minimise the number of used shifts. This problem typically occurs as the second step of decomposition methods which handle the creation of shifts in a first step. With this kind of methods, side constraints related to personnel roster design are considered in the first step only, whence the simplicity of the SMPTSP formulation. Nonetheless, current exact approaches relying on Mixed Integer Programming (MIP) fail to solve large scale instances [36], [43]. This is the main motivation for investigating a Constraint-Programming (CP) approach.
     </paragraph>
     <paragraph>
      CP is a programming paradigm which belongs to the wide field of Artificial Intelligence (AI). It is a declarative language which enables to model both satisfaction and optimisation problems through variables, domains, and constraints [52]. Each variable is associated with a domain representing its possible values. The constraints are defined over variables to model the properties which must hold. Therefore, a solution is an assignment of values to variables which satisfies every constraint of the model. From a technical point of view, a constraint is equipped with at least one propagator which filters infeasible values from variable domains. Each time a variable domain is reduced, the propagators associated with this variable are scheduled for further filtering. This leads to series of filtering steps, called propagation [54]. A propagator is monotonic [55] when the smaller the domains before filtering, the smaller the domains after filtering, under the inclusion. Furthermore, it is idempotent [55] if applying its filtering algorithm twice in a row leads to no further inference. Overall, the solving process relies on a backtrack algorithm which alternates filtering steps to make inference and branching decisions to perform hypothesis.
     </paragraph>
     <paragraph>
      The core idea of CP is to design independent constraints that can be combined through shared variables, in order to model constrained problems. However, in case of optimisation problem, such independent constraints often lead to a poor bounding of the objective function compared to a MIP approach. This restrains the deployment of CP into industrial applications [39]. Therefore, it is often more interesting to design global constraints [4]. These constraints are able to consider a larger part of the problem, hence their filtering impact is increased. For instance, the AllDifferent global constraint is the conjunction over a clique of binary difference constraints, and it has been proved highly relevant within CP solvers [50]. However, developing effective global constraints is often difficult, and it also tends to make CP solver maintenance more expensive, which is one of the greatest concerns of the CP community [47]. Consequently, from a practical point of view, one would rather adapt existing constraints than to implement brand new ones, in order to capitalise over previous work. In this paper we investigate the interest of considering difference constraints when filtering the well known AtMostNValue constraint [3], [7], [48]. We introduce a new propagator whose implementation is based on the state-of-the-art AtMostNValue propagator [7]. Furthermore, we provide a bold search strategy which relies on constraint reification to attempt strong search space reduction. A wide range of experiments shows that our contribution significantly improves the CP model, so that it competes with the most recent SMPTSP dedicated approaches.
     </paragraph>
     <paragraph>
      The remainder of the paper is organised as follows: Section 2 is devoted to the description of the SMPTSP, in Section 3 we show how the straightforward CP model of the SMPTSP can be improved with a new propagator. Then, a branching scheme suited to solve the SMPTSP is presented in Section 4. Our approach is validated by an extensive experimental study in Section 5, followed by our conclusions.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Description of the SMPTSP
     </section-title>
     <paragraph>
      This section first introduces the notations that are used in the paper. Then, some simple complexity results are mentioned to give insight over our case study. Finally, it provides the state-of-the-art mathematical formulation of the problem.
     </paragraph>
     <section label="2.1">
      <section-title>
       Notations
      </section-title>
      <paragraph>
       In the following, {a mathematical formula}T and {a mathematical formula}S respectively refer to the set of tasks and shifts. Note that a shift may be seen as a worker with specific skills and potentially a working time window [36]. Given a task {a mathematical formula}t∈T, we refer to the set of shifts that can be assigned to t as {a mathematical formula}St⊆S. Therefore, the SMPTSP consists of assigning to each task {a mathematical formula}t∈T, a shift {a mathematical formula}s∈St, with a minimum total number of shifts, and such that overlapping tasks have different shifts. As tasks are fixed in time, finding all maximal sets of overlapping tasks, referred to as {a mathematical formula}C is polynomial [29]. It amounts to finding the set of maximal cliques in an interval graph. The size of the largest clique, referred to as {a mathematical formula}LB≠, provides a trivial lower bound on the required number of shifts.
      </paragraph>
      <paragraph>
       Fig. 1 introduces the running example of the paper. The input instance data is displayed in Fig. 1a. It includes a set of 5 tasks {a mathematical formula}T={t1,..,t5} and a set of 5 shifts {a mathematical formula}S={s1,..,s5}. Each task, represented by a rectangle, is associated with a set of compatible shifts, e.g.{a mathematical formula}St1={s2,s3,s4}. Starting and ending time of tasks give {a mathematical formula}C={K1,K2,K3} with {a mathematical formula}K1={t1,t2,t3}, {a mathematical formula}K2={t1,t3,t4}, {a mathematical formula}K3={t4,t5}. Therefore, {a mathematical formula}LB≠ =3. An optimal solution involving shifts {a mathematical formula}{s1,s2,s3} is given in Fig. 1b. This example will be used all along the article to illustrate our points.
      </paragraph>
     </section>
     <section label="2.2">
      <section-title>
       Complexity
      </section-title>
      <paragraph>
       The SMPTSP is similar to many problems such as the Fixed Job Scheduling Problem [23], [24], the Interval Scheduling Problem [34], [35], the Class-Room Assignment Problem [12], the Graph Colouring Problem [28] and the List Colouring Problem [18]. Therefore, many complexity results of the literature are relevant to our case study. For instance, when shifts are identical ({a mathematical formula}∀t∈T,St=S), the SMPTSP can be seen as a Graph Colouring Problem,{sup:1} where vertices correspond to tasks, shifts correspond to colours and two vertices are connected whenever their corresponding tasks overlap in time. While this problem is NP-hard in general, it is polynomial for interval graphs, which is our case because the graph is generated from a set of time intervals (each task is associated with a fixed time interval) [25]. Nevertheless, the SMPTSP generally involves restrictions over allowed shift-task assignments, i.e., shifts are not identical. The previously mentioned colouring problem has to be changed so that not every colour can be taken by every vertex. Instead, each vertex is associated with a subset of feasible colours. This problem is known as the List Colouring Problem [18], and it is NP-hard, even for interval graphs [25]. Therefore, the complexity of the SMPTSP stems from shift heterogeneity.
      </paragraph>
     </section>
     <section label="2.3">
      <section-title>
       Mathematical formulation
      </section-title>
      <paragraph>
       The SMPTSP may be stated in Mathematical Programming by using binary variables {a mathematical formula}xt,s and {a mathematical formula}ys, which respectively specify if the task t is assigned to the shift s and if the shift s is used. Based on these variables, the number of used shifts is given by (1) and the assignment of tasks to compatible shifts is ensured by (2). The purpose of the constraint (3) is twofold: First, it prevents shifts to be assigned to overlapping tasks. Second, it ensures that shifts assigned to at least one task are counted as used. We refer to this model as MIP model:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
     </section>
    </section>
    <section label="3">
     A CP model based on the AtMostNValue constraint
     <paragraph>
      This section first introduces a straightforward CP formulation of the SMPTSP. Next, it recalls the former AtMostNValue propagator our approach is based on, and provides a new formalism to define propagators of the same family. Then, it introduces a new propagator which filters AtMostNValue while considering a set of difference constraints. We show how to improve and diversify its impact on variables. Finally, we discuss the case of dynamic difference constraints and provide some implementation guidelines.
     </paragraph>
     <section label="3.1">
      <section-title>
       A straightforward CP formulation
      </section-title>
      <paragraph>
       The SMPTSP can be formulated within CP with a set of {a mathematical formula}|T| integer variables {a mathematical formula}X and one objective variable z. {a mathematical formula}X represents task-shift assignments: More precisely, if we note {a mathematical formula}d(x) the domain of a variable {a mathematical formula}x∈X, then {a mathematical formula}d(xi)={j} means that task {a mathematical formula}ti is assigned to shift {a mathematical formula}sj and {a mathematical formula}d(z) gives the number of shifts assigned to at least one task. We refer to this model as CP model:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph>
       The expressive language offered by CP enables to model the problem through two global constraints. In (7), AllDifferent constraints [50] are used to forbid the assignment of overlapping tasks to the same shift. In (8), the AtMostNValue constraint [7] is used to restrict the number of shifts that are involved in the schedule. Then, variable initial domain definitions are given by (9) and (10). Trivial lower and upper bounds for z are respectively the maximum number of overlapping tasks ({a mathematical formula}LB≠, the number of variables in the largest AllDifferent constraint) and the number of available shifts.
      </paragraph>
      <paragraph>
       From a sementical point of view, constraints (7) are equivalent to one single SomeDifferent constraint. This constraint has been introduced in [51] to model a set of disequalities, in order to solve a workforce management problem [2]. A propagator establishing the Generalised Arc Consistency (GAC) on SomeDifferent has been introduced in [51]. Since its worst case runtime complexity is {a mathematical formula}O(n3βn), with {a mathematical formula}β≈3.5, Richter et al. suggests various modifications to improve its runtime on their industrial benchmarks [2], [51]. Nevertheless, their study shows that their algorithm is not suited to instances whose disequalities are numerous and form a graph which consists of few big connected components. This is unfortunately the case of SMPTSP instances, for which the graph of overlapping tasks is presumably connected. Furthermore, as AllDifferent constraints are detected in polynomial time, then CP model already has a good propagation of disequalities. Therefore, we do not use SomeDifferent in CP model.
      </paragraph>
      <paragraph>
       To get a higher level of abstraction, we now consider the SMPTSP as the problem of assigning a minimum number of values to variables, which are subject to some difference constraints.
      </paragraph>
     </section>
     <section label="3.2">
      State-of-the-art filtering of the AtMostNValue constraint
      <paragraph label="Definition 3">
       The AtMostNValue constraint belongs to the Number of Distinct Values constraint family [3]. It has been introduced in [48] to specify music programs but the first filtering algorithm was provided in [3]. Then, the AtMostNValue constraint has been widely investigated in [7], where the authors proved that enforcing the GAC on AtMostNValue is NP-hard, and provide various filtering algorithms. According to this study, the greedy propagator they introduced provides a good tradeoff between filtering and runtime. Thus, we use it as the reference propagator for filtering the AtMostNValue constraint. Before describing this propagator we need to recall a few definitions: The intersection graph of a set of variables {a mathematical formula}X, {a mathematical formula}GI(X)=(V,EI), is defined by a vertex set V where each variable {a mathematical formula}xi∈X is associated with a vertex {a mathematical formula}i∈V, and an edge set {a mathematical formula}EI representing domain intersections: For any {a mathematical formula}(i,j)∈V2, there is an edge {a mathematical formula}(i,j)∈EI if and only if {a mathematical formula}d(xi)∩d(xj)≠∅.An independent set in a graph {a mathematical formula}G=(V,E) is a subset, {a mathematical formula}A⊆V, of disjoint vertices, i.e., for any {a mathematical formula}(i,j)∈A2 such that {a mathematical formula}i≠j, {a mathematical formula}(i,j)∉E.A maximum independent set in a graph G is an independent set whose cardinality is maximum. The independence number of a graph G, noted {a mathematical formula}α(G), is the cardinality of a maximum independent set in G. The set of all independent sets in a graph G, is referred to as {a mathematical formula}IS(G).
      </paragraph>
      <paragraph>
       The filtering algorithm proposed in [7] stems from the search of a maximum independent set in {a mathematical formula}GI(X). Since this problem is NP-hard [27], it actually computes an independent set A in {a mathematical formula}GI(X), in a greedy way, by selecting nodes of minimum degree first [31]. This heuristic is referred to as MD. Then, the propagator filters according to the following rules:
      </paragraph>
      <list>
       <list-item label="–">
        {a mathematical formula}R1: {a mathematical formula}z̲←max(z̲,|A|)
       </list-item>
       <list-item label="–">
        {a mathematical formula}R2: {a mathematical formula}|A|=z¯⇒∀i∈V,d(xi)←d(xi)∩⋃a∈Ad(xa)
       </list-item>
      </list>
      <paragraph>
       Where {a mathematical formula}z̲ and {a mathematical formula}z¯ respectively refer to the lower bound and the upper bound of the variable z. {a mathematical formula}R1 states that the cardinality of A is a valid lower bound for z. {a mathematical formula}R2 states that whenever the cardinality of the independent set A is equal to the upper bound of z, then variables in {a mathematical formula}X have to take their values among the subset of values induced by A. Indeed, variables associated with an independent set of an intersection graph take different values, by definition. Thus, using a value outside of this subset of values would lead to use at least {a mathematical formula}|A|+1 values, which is a contradiction.
      </paragraph>
      <paragraph>
       Regarding the time complexity of these filtering rules, {a mathematical formula}R1 clearly runs in constant time whereas {a mathematical formula}R2 requires a finer study. Let the number of variables and the number of values be respectively referred to as {a mathematical formula}n=|X| and {a mathematical formula}l=|S|. We assume that the intersection, as well as the union, of two variable domains can be computed in {a mathematical formula}O(log(l)) worst case time with bit vector operations. The computation of {a mathematical formula}⋃a∈Ad(xa) requires at most n domain unions. As it does not depend on i, it can be computed once and for all in {a mathematical formula}O(nlog(l)) worst case time. Then, n domain intersections are performed. Thus, {a mathematical formula}R2 is propagated in {a mathematical formula}O(nlog(l)) worst case time.
      </paragraph>
      <paragraph>
       Overall, the greedy propagator of AtMostNValue takes a graph G as input, calls a function F to compute independent sets in G and then filters variable domains with a set of rules {a mathematical formula}R. Therefore, we introduce the notation {a mathematical formula}AMNV〈G|F|R〉 to define such a family of propagators. Consequently, the greedy propagator introduced in [7] is referred to as {a mathematical formula}AMNV〈GI|MD|R1,2〉. In the following, we suggest improvement for G, F and {a mathematical formula}R, leading to a new propagator which filters AtMostNValue and a set of difference constraints.
      </paragraph>
      <paragraph>
       To illustrate the state-of-the-art propagator, we now apply it to our running example in Fig. 2, with {a mathematical formula}d(z)={1}. This state might occur during the resolution. Because of variable domain definitions, the intersection graph corresponding to our example, is a complete graph. Thus, MD selects only one node, {a mathematical formula}x3 for instance. Next, {a mathematical formula}R1 states that the number of values is at least one, which provides no information because {a mathematical formula}d(z)={1}. Then, {a mathematical formula}R2 states that values {a mathematical formula}2,4 and 5 must be removed from the domain of the variables (Fig. 2a). Consequently, the edges {a mathematical formula}(x1,x5) and {a mathematical formula}(x5,x4) have to be removed in order to obtain the new intersection graph. Based on this new graph, if we assume that {a mathematical formula}x1 and {a mathematical formula}x5 are then used as a new independent set (Fig. 2b) then {a mathematical formula}R1 states that the number of values is at least two, leading to fail.
      </paragraph>
     </section>
     <section label="3.3">
      Embedding difference constraints into AtMostNValue
      <paragraph label="Definition 4">
       As the SMPTSP only considers two kinds of constraints (AtMostNValue and AllDifferent), filtering their conjunction may be very profitable. For that purpose, this section introduces an implied propagator, in the form {a mathematical formula}AMNV〈G|F|R〉, which considers difference constraints. This work stems from the very simple observation that, if a disequality states that two variables {a mathematical formula}xi and {a mathematical formula}xj of {a mathematical formula}X must take different values, then for every solution, there is no edge between vertex i and vertex j in {a mathematical formula}GI(X). However, such an edge might exist during search. If so, then it would presumably lower the propagation strength, because the more edges in {a mathematical formula}GI(X), the smaller independent sets in {a mathematical formula}GI(X). Hence, we should remove those edges as soon as possible. Consequently, we introduce the constrained intersection graph (Definition 4), to be used instead of the intersection graph of variables. Given a set of variables {a mathematical formula}X and a set of difference constraints {a mathematical formula}D, the constrained intersection graph, {a mathematical formula}GCI(X,D)=(V,ECI), of {a mathematical formula}X and {a mathematical formula}D is defined by a vertex set V where each variable {a mathematical formula}xi∈X is associated with a vertex {a mathematical formula}i∈V, and an edge set {a mathematical formula}ECI representing possible classes of equivalence: For any {a mathematical formula}(i,j)∈V2, there is an edge {a mathematical formula}(i,j)∈ECI if and only if {a mathematical formula}d(xi)∩d(xj)≠∅ and {a mathematical formula}neq(xi,xj)∉D.
      </paragraph>
      <paragraph label="Proof">
       In this paper, we consider a single set of variables {a mathematical formula}X and a single set of difference constraints {a mathematical formula}D, thus, for the sake of clarity {a mathematical formula}GCI(X,D) and {a mathematical formula}GI(X) will be respectively noted {a mathematical formula}GCI and {a mathematical formula}GI. {a mathematical formula}GCI can be computed by removing from {a mathematical formula}GI any edge which is associated with a disequality. It is worth noticing that {a mathematical formula}GCI⊆GI. {a mathematical formula}IS(GI)⊆IS(GCI), hence{a mathematical formula}α(GI)≤α(GCI).Let {a mathematical formula}AI be an independent set in {a mathematical formula}GI. Since {a mathematical formula}GCI and {a mathematical formula}GI are based on the same variable set, they share the same vertex set, so {a mathematical formula}AI is also a subset of vertices of {a mathematical formula}GCI. Since vertices of {a mathematical formula}AI are pairwise disjoint in {a mathematical formula}GI (by assumption) and since all edges of {a mathematical formula}GCI also belong to {a mathematical formula}GI, then vertices of {a mathematical formula}AI are also pairwise disjoint in {a mathematical formula}GCI. Consequently, {a mathematical formula}AI is an independent set in {a mathematical formula}GCI. Thus, all independent sets in {a mathematical formula}GI are independent sets in {a mathematical formula}GCI, so {a mathematical formula}maxI∈IS(GI)|I|≤maxIc∈IS(GCI)|Ic|, hence {a mathematical formula}α(GI)≤α(GCI).  □
      </paragraph>
      <paragraph>
       Note that a maximum independent set in {a mathematical formula}GI, is not necessarily maximal in {a mathematical formula}GCI. For instance, one may consider a non-empty set of variables with identical domains and with a difference constraint over each pair of distinct variables. Then {a mathematical formula}GI is a complete graph, whereas there are no edges, but loops, in {a mathematical formula}GCI. Consequently, {a mathematical formula}α(GI)=1 whereas {a mathematical formula}α(GCI)=|V|. It is worth noticing that in our context, the bigger the independent set, the higher the chance to filter variable domains. Thus, using {a mathematical formula}GCI is presumably better than using {a mathematical formula}GI to filter AtMostNValue when difference constraints figure in the model (Proposition 2).
      </paragraph>
      <paragraph>
       To illustrate the interest of {a mathematical formula}GCI, we now use it on our example, with {a mathematical formula}d(z)={1,2,3}, in Fig. 3. Because of difference constraints, {a mathematical formula}GCI is sparser than {a mathematical formula}GI (Fig. 3a). Thus, MD is now able to compute a larger independent set, leading to find a better lower bound for z. For instance, if we consider the independent set {a mathematical formula}{x1,x2,x3} (Fig. 3b), then {a mathematical formula}R1 and {a mathematical formula}R2 respectively state that the number of values is at least three and that the value 5 can be removed from the variable domains.
      </paragraph>
      <paragraph label="Proof">
       Following [15], a propagator A is stronger than a propagator B if and only if, in any propagation, any value filtered by B is also filtered by A. Furthermore, A is strictly stronger than B if and only if A is stronger than B and there exists at least one problem instance for which a value is filtered by A and not by B, during a propagation step. Given an oracle O which computes all maximum independent sets of any graph, then{a mathematical formula}AMNV〈GCI|O|R1,2〉is strictly stronger than{a mathematical formula}AMNV〈GI|O|R1,2〉.First of all, since O is able to compute all maximum independent sets of any graph, then the lower bound given by {a mathematical formula}R1 in {a mathematical formula}GCI is equal to {a mathematical formula}α(GCI) whereas the lower bound given by {a mathematical formula}R1 in {a mathematical formula}GI is equal to {a mathematical formula}α(GI). Since {a mathematical formula}α(GI)≤α(GCI) (Proposition 1), then {a mathematical formula}AMNV〈GCI|O|R1〉 is stronger than {a mathematical formula}AMNV〈GI|O|R1〉. Second, since O is able to compute all maximum independent sets of any graph, and since {a mathematical formula}IS(GI)⊆IS(GCI) (Proposition 1), then values filtered by {a mathematical formula}AMNV〈GI|O|R2〉 are also filtered by {a mathematical formula}AMNV〈GCI|O|R2〉. Consequently, {a mathematical formula}AMNV〈GCI|O|R2〉 is stronger than {a mathematical formula}AMNV〈GI|O|R2〉. Examples given on Fig. 2, Fig. 3 illustrate a case where {a mathematical formula}α(GCI)&gt;α(GI). Therefore {a mathematical formula}AMNV〈GCI|O|R1,2〉 is strictly stronger than {a mathematical formula}AMNV〈GI|O|R1,2〉.  □Given an independent set A in{a mathematical formula}GCIsuch that{a mathematical formula}|A|=z¯, any solution of the conjunction of AtMostNValue and{a mathematical formula}Dsatisfies the following formula:{a mathematical formula}∀i∈V\A,{a mathematical formula}∃a∈Ais.t.{a mathematical formula}xi=xa, where{a mathematical formula}Aidenotes{a mathematical formula}{a∈A|(i,a)∈ECI}.Given an independent set A in {a mathematical formula}GCI such that {a mathematical formula}|A|=z¯. Let's assume that there exists a solution S to the conjunction of AtMostNValue and {a mathematical formula}D such that there exists a vertex {a mathematical formula}i∈V\A for which {a mathematical formula}∀a∈Ai,xi≠xa. Thus, S is solution of the conjunction of AtMostNValue and {a mathematical formula}D∪{neq(xi,xa)|a∈Ai}. Consequently, {a mathematical formula}A∪{i} is a valid independent set in {a mathematical formula}GCI. Then {a mathematical formula}R1 states that {a mathematical formula}z̲←|A∪{i}|, i.e., {a mathematical formula}z̲←z¯+1 which is not possible. Consequently, such a solution S does not exist, hence Proposition 3 holds.  □ From a filtering perspective, Proposition 3 leads to consider the following rule:
      </paragraph>
      <list>
       <list-item label="–">
        {a mathematical formula}R3: {a mathematical formula}|A|=z¯⇒∀i∈V\A{d(xi)←d(xi)∩⋃a∈Aid(xa)Ai={a}⇒d(xa)←d(xa)∩d(xi)
       </list-item>
      </list>
      <paragraph>
       This rule is actually a refined variant of {a mathematical formula}R2. While this change is quite simple, it may have a significant impact in practice, especially on large scale problems were, for any {a mathematical formula}i∈V\A, {a mathematical formula}|Ai| is presumably small compared to {a mathematical formula}|A|. Note the particular case that occurs when, for some node {a mathematical formula}i∈V\A, {a mathematical formula}Ai={a} enables to learn the valid equality {a mathematical formula}xi=xa. This way, it is possible to filter the domain of the variable {a mathematical formula}xa of the independent set as well. From a theoretical point of view {a mathematical formula}R3 is also stronger than {a mathematical formula}R2 (Proposition 4). However, such filtering comes at a price. As it depends on i, {a mathematical formula}⋃a∈Aid(xa) must be computed for every {a mathematical formula}i∈V\A. This raises the worst case time complexity of {a mathematical formula}R3 to {a mathematical formula}O(n2log(l)).
      </paragraph>
      <paragraph label="Proof">
       To illustrate this rule, we now apply it on our example, with {a mathematical formula}d(z)={1,2,3}, in Fig. 4. If we consider the independent set {a mathematical formula}{x1,x3,x4}, then {a mathematical formula}R1 deduces that {a mathematical formula}d(z)={3} but {a mathematical formula}R2 cannot filter {a mathematical formula}X domains (Fig. 4a), because the set of values induced by the independent set is {a mathematical formula}{1,2,3,4,5}. However, {a mathematical formula}R3 (Fig. 4b) enables to filter the value 5, which is not included in {a mathematical formula}d(x1)∪d(x3)={1,2,3,4}, from the domain of {a mathematical formula}x5. It also removes values 1 and 2, which do not figure in {a mathematical formula}d(x4)={3,4,5}, from the domain of {a mathematical formula}x2. Finally, it learns the valid equality {a mathematical formula}x2=x4, which allows to remove values 4 and 5 from the domain of {a mathematical formula}x4. Given a deterministic heuristic H which computes an independent set A in{a mathematical formula}GCI, then{a mathematical formula}AMNV〈GCI|H|R3〉is strictly stronger than{a mathematical formula}AMNV〈GCI|H|R2〉.Since {a mathematical formula}AMNV〈GCI|H|R3〉 and {a mathematical formula}AMNV〈GCI|H|R2〉 use the same deterministic heuristic H in the same graph {a mathematical formula}GCI, then they filter with the same independent set A. Since, for any node {a mathematical formula}i∈V, {a mathematical formula}Ai={a∈A|(i,a)∈ECI}, then {a mathematical formula}Ai⊆A. Consequently, any value filtered by {a mathematical formula}R2 is also filtered by {a mathematical formula}R3. The example given on Fig. 4 illustrates a case where {a mathematical formula}AMNV〈GCI|H|R3〉 filtrates more than {a mathematical formula}AMNV〈GCI|H|R2〉. Therefore, {a mathematical formula}AMNV〈GCI|H|R3〉 is strictly stronger than {a mathematical formula}AMNV〈GCI|H|R2〉. □
      </paragraph>
     </section>
     <section label="3.4">
      <section-title>
       Diversifying filtering
      </section-title>
      <paragraph label="Proof">
       CP frameworks traditionally perform a fix point over constraints at each branching node [54]. This implies that our model may compute thousands of independent sets during the search process. Thus, it is advised to use a greedy algorithm, such as MD, to filter the AtMostNValue constraint [7]. This heuristic is efficient but it lacks diversification for both its bound and the resulting filtering, which depend on the computed independent set. If we assume ties (of equal degree vertices) are broken in a lexicographic way, then MD is deterministic. This may lead to unfortunate results when the considered graph does not suit this heuristic. Given two functions{a mathematical formula}F1and{a mathematical formula}F2which compute a set of independent sets in{a mathematical formula}GCI, respectively noted{a mathematical formula}A1and{a mathematical formula}A2. If{a mathematical formula}F1and{a mathematical formula}F2are such that, for any{a mathematical formula}A1induced by{a mathematical formula}F1and for any{a mathematical formula}A2induced by{a mathematical formula}F2,{a mathematical formula}maxI2∈A2∖A1|I2|&lt;maxI1∈A1|I1|, then{a mathematical formula}AMNV〈GCI|F1|R1,3〉is strictly stronger than{a mathematical formula}AMNV〈GCI|F2|R1,3〉.First, {a mathematical formula}maxI2∈A2∖A1|I2|&lt;maxI1∈A1|I1| implies that {a mathematical formula}maxI2∈A2|I2|≤maxI1∈A1|I1|, hence {a mathematical formula}AMNV〈GCI|F1|R1〉 is stronger than {a mathematical formula}AMNV〈GCI|F2|R1〉. Second, let's now assume that a value is removed from a domain of a variable in {a mathematical formula}X by {a mathematical formula}AMNV〈GCI|F2|R3〉. If this filtering occurs while considering an independent set of {a mathematical formula}A1∩A2, then the same filtering is performed by {a mathematical formula}AMNV〈GCI|F1|R1,3〉. Else, this filtering occurs when considering an independent set {a mathematical formula}I2 of {a mathematical formula}A2∖A1. A necessary condition so that {a mathematical formula}R3 triggers filtering is that, {a mathematical formula}|I2|=z¯. As {a mathematical formula}|I2|&lt;maxI1∈A1|I1|, then the problem is actually infeasible, which is captured by {a mathematical formula}AMNV〈GCI|F1|R1〉. Thus, {a mathematical formula}AMNV〈GCI|F1|R1,3〉 is stronger than {a mathematical formula}AMNV〈GCI|F2|R1,3〉. Let {a mathematical formula}F1=MD and {a mathematical formula}F2=FV respectively denote the minimum degree heuristic and a (bad) heuristic which selects only the first vertex. We assume ties are broken in a lexicographic way, i.e., in case of a complete graph, both heuristics output the same singleton independent set, hence both approaches are equivalent. If the graph is not complete, then there exists at least a vertex pair {a mathematical formula}(u,v)∈GCI with no edge, hence any independent set computed by MD will have at least two vertices. Thus, {a mathematical formula}AMNV〈GCI|MD|R1,3〉 is strictly stronger than {a mathematical formula}AMNV〈GCI|FV|R1,3〉. Therefore, if {a mathematical formula}F1 and {a mathematical formula}F2 are such that, for any {a mathematical formula}A1 induced by {a mathematical formula}F1 and for any {a mathematical formula}A2 induced by {a mathematical formula}F2, {a mathematical formula}maxI2∈A2∖A1|I2|&lt;maxI1∈A1|I1|, then {a mathematical formula}AMNV〈GCI|F1|R1,3〉 is strictly stronger than {a mathematical formula}AMNV〈GCI|F2|R1,3〉.  □
      </paragraph>
      <paragraph>
       As suggested in [3], [7], and highlighted by Proposition 5, it may be interesting to obtain several independent sets to apply filtering rules over a greater set of variables. In particular, if all maximal independent sets were known, {a mathematical formula}R1,3 could then be used optimally, i.e., all values that could be filtered by {a mathematical formula}R1,3 would actually be filtered. One way to find all maximal independent sets is to adapt the algorithm of Bron–Kerbosch, an exact algorithm which computes all maximal cliques in an undirected graph [10]. However, as the underlying problem is NP-hard, performing the Bron–Kerbosch algorithm at each propagation would presumably be very time consuming. On our large data, it turned out that the improved filtering provided by this algorithm is not worth the overhead. Therefore, we suggest to keep the philosophy of MD and to get diversification through a fast algorithm. The simplest way would be to randomly break ties of MD. However, this does not bring enough diversification to improve results. Thus, we introduce the {a mathematical formula}Rk algorithm (Algorithm 1).
      </paragraph>
      <paragraph>
       The {a mathematical formula}Rk heuristic performs k iterations, each one computes an independent set randomly. Each independent set is computed by successively selecting a node randomly and removing it along with its neighbours, until all nodes are removed. It thus provides a set of k independent sets, each one being maximal under inclusion. However, these independent sets are not necessarily all distincts (random node selections might lead to same results). As it relies on randomness, such propagator is neither idempotent nor monotonic. From a theoretical point of view, this approach presents several interesting properties. First, it offers control over its runtime complexity and its expected quality. Second, computing independent sets randomly tends to impact variable domains homogeneously. Note that, when {a mathematical formula}k→∞, then the method tends to enumerate and filter with all maximum independent sets, which is optimal with the given filtering rules. However, from a practical point of view, one has to bound the number of iterations in order to get a reasonable runtime. We suggest to keep k between 20 and 100 as a default setting, which seems to perform better than MD, on average, without introducing a significant overhead. Regarding the probability distribution of {a mathematical formula}Rk, two options may be considered: A uniform distribution or a weighted distribution where small-degree vertices are more likely to be selected. The second option may be seen as a random adaptation of MD. Based on practical experiments, and because MD offers a good approximation ratio [31], we recommend to use a uniform-distribution {a mathematical formula}Rk together with MD.
      </paragraph>
     </section>
     <section label="3.5">
      <section-title>
       The case of dynamic difference constraints
      </section-title>
      <paragraph label="Proof">
       By definition of a constrained intersection graph, an independent set represents variables that are either already different or constrained to be.  □
      </paragraph>
      <paragraph>
       From Proposition 6, we derive a new filtering rule for AtMostNValue which calls a filtering algorithm of AllDifferent over variables corresponding to the independent set A it has computed:
      </paragraph>
      <list>
       <list-item label="–">
        {a mathematical formula}R4: {a mathematical formula}AllDifferent({xi∈X|i∈A})
       </list-item>
      </list>
      <paragraph>
       Note that this rule can either directly call a filtering algorithm of AllDifferent over the appropriate subset of variables or post dynamically an AllDifferent constraint into the solver. The first option is the simplest one, but cannot filter incrementally, so a bound-consistent (BC) filtering algorithm of AllDifferent, such as the one presented in [44], would presumably be more relevant than the GAC one [50]. Note that the subset of variables to be different is lost right after filtering and the next propagation may involve a worse independent set. Instead, the second option can involve incremental GAC AllDifferent constraints which would remain in the current search branch. However, since each independent set can post an AllDifferent constraint, it has the drawback of leading to a potential explosion over the number of such constraints. Thus, one needs to set up a constraint pool to manage those constraints, by retaining only the most interesting constraints and removing dominated ones. One can see a parallel with Cut pools of MIP solvers [1]. For solver maintenance simplicity purposes, we recommend the first option.
      </paragraph>
      <paragraph>
       Note that {a mathematical formula}R4 is only relevant when disequalities arise during search. It is useless in the case of the SMPTSP, because all maximal AllDifferent constraints are already preprocessed in polynomial time. Overall, {a mathematical formula}R4 can be seen as a dynamic generalisation of a common good practice, which consists in reformulating a set of disequalities into AllDifferent constraints during preprocessing [30].
      </paragraph>
     </section>
     <section label="3.6">
      <section-title>
       Implementation
      </section-title>
      <paragraph>
       So far, we have seen that it was possible to tune the original greedy AtMostNValue propagator. We now suggest a simple and generic pseudocode (Algorithm 2).
      </paragraph>
      <paragraph>
       The constrained intersection graph is stored as a backtrackable structure which is updated at the beginning of the filtering algorithm, i.e., after potentially many domain modifications. This turns out to be much faster than updating {a mathematical formula}GCI incrementally after every domain modification or rebuilding it entirely from scratch. Once the graph has been updated, the propagator computes a set of independent sets with a function F. For each independent set, the propagator filters the lower bound of z and filters {a mathematical formula}X with a set of rules {a mathematical formula}R.
      </paragraph>
      <paragraph>
       It is worth noticing that no assumption is made on the set of difference constraints {a mathematical formula}D which can thus grow during the resolution process. For instance, {a mathematical formula}D can be modified by the user or other constraints. Note also that, as long as domain union and intersection operations are defined, no assumption is made about the kind of variables in {a mathematical formula}X. This means Algorithm 2 can be used to filter the AtMostNVector constraint [13], a variant of AtMostNValue which holds on continuous vector variables instead of integer variables. Indeed, continuous domains are represented by floating intervals, hence union and intersection operations are straightforward. Overall, one can see that this propagator is both flexible and easy to implement and maintain.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Designing a search heuristic for the SMPTSP
     </section-title>
     <paragraph>
      This section describes the search process that is used within our CP approach. It embeds some cost-based reasonings (bottom–up optimisation strategy and tailored value selection), domain reduction reasonings (heuristic symmetry breaking and variable selection) and finally a bit of learning (throught last-conflict[41]).
     </paragraph>
     <section label="4.1">
      <section-title>
       Optimisation strategy
      </section-title>
      <paragraph>
       The classical optimisation strategy of a CP solver consists of enumerating improving solutions. If the search completes, the last solution found is proved to be optimal. This process is known as the top–down approach. However, the filtering of {a mathematical formula}AMNV〈G|F|R〉 is related to the lower bounding of the problem. Therefore, the lower the objective upper bound, the stronger the filtering. Hence, we naturally employed a bottom–up minimisation strategy. It tries to compute a solution involving k values, where k is initialised to the root lower bound of z and incremented by one each time the solver proves unsatisfiability. Thus, the first solution found is optimal. This is done by simply branching on the objective variable and assigning it its current lower bound.
      </paragraph>
      <paragraph>
       The search heuristic that is used over {a mathematical formula}X is the following: The variable associated with the smallest domain is selected first [32], and then fixed to the first value in its domain that is already assigned to another variable. If no such value exists, then the variable is fixed to its lower bound. Thus, the value selection naturally tends to use few different values. This branching scheme is reinforced by the last-conflict heuristic [41] which aims at identifying critical variables.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       When search tries its luck
      </section-title>
      <paragraph>
       In [21], we employed a two-step search strategy that first finds a subset of z allowed values and then assign a value to every decision variable {a mathematical formula}x∈X. The first step requires to associate every shift {a mathematical formula}sj∈S with a new binary variable {a mathematical formula}yj∈Y to tell whether or not the value j must be assigned to a variable in {a mathematical formula}X. However, this approach makes the model heavier because of additional variables and channelling constraints. Moreover, branching on {a mathematical formula}Y first might not be appropriate for every instance. If so, compelling the search to follow this scheme may decrease performances. Therefore, while keeping the general idea of a two-step search strategy, we now suggest a lighter and more flexible branching scheme.
      </paragraph>
      <paragraph>
       It is worth noticing that if shifts were all equivalent, i.e., if values of assignment variables were all interchangeable, then the problem would be polynomial to solve. From a modelling perspective, we could force to use any arbitrary set of z values. More precisely, we could use the first z values. Assuming that values are consecutive and start at one, we could add the constraint {a mathematical formula}maximum(X)=z. This symmetry breaking constraint [26] may dramatically reduce the search space. Unfortunately, values are generally not interchangeable, so we cannot post such a hard constraint directly. Nevertheless, it may occur in some instances that values are nearly interchangeable, in the sense that finding a valid subset of values to be used is a minor issue compared to finding a valid variable-value assignment. In other words, if {a mathematical formula}z⁎ denotes the optimum value, then the problem admits a solution for numerous value subsets of size {a mathematical formula}z⁎. For this reason, we introduce a binary variable {a mathematical formula}breif to reify [5] the above symmetry breaking constraint. The search heuristic first fixes {a mathematical formula}breif to 1 in order to propagate this constraint and reduce the search space [20]. In case no solution exists, a backtrack fixes it to 0 and turns the constraint into its opposite i.e., {a mathematical formula}maximum(X)≠z, so that the approach remains exact. This is a full reification. However, the filtering of the right branch will be weak, so a half-reification [22] of the constraint {a mathematical formula}maximum(X)=z would be sufficient to reproduce our approach. Note that the initial set of shifts may be randomly shuffled to handle the case where it is ordered in a specific way. One can see this search trick as a way to perform symmetry breaking from search. However, as the model is unlikely to contain such symmetries, it is rather a heuristic gamble. More precisely, there are {a mathematical formula}(|S|z⁎) different value sets of the size of the optimal value. Let K be the number of different value sets that belong to at least one optimal solution. We have {a mathematical formula}0≤K≤(|S|z⁎). The probability of the value set {a mathematical formula}{1,2,...,z⁎} to belong to an optimal solution is therefore {a mathematical formula}P(breif=1)=K(|S|z⁎).
      </paragraph>
      <paragraph>
       To illustrate the use of {a mathematical formula}breif we now apply it on our running example, with {a mathematical formula}d(z)={3} (the optimum) in Fig. 5. For the sake of clarity, the shift set of the example has not been shuffled, hence a value {a mathematical formula}i∈[1,5] corresponds to the shift {a mathematical formula}si. However, in practice, we randomly shuffle the initial shift set to reduce bias, so values 1, 2 and 3 might refer to shifts {a mathematical formula}s2, {a mathematical formula}s4 and {a mathematical formula}s5 for instance. When {a mathematical formula}breif is set to 1, the constraint {a mathematical formula}maximum(X)=z leads to remove values 4 and 5 from {a mathematical formula}X domains. This is a lucky guess, because optimal solutions use the value sets {a mathematical formula}{1,2,3} and {a mathematical formula}{1,3,4}, i.e., {a mathematical formula}K=2. Therefore, the constraint {a mathematical formula}maximum(X)=z has a probability to hold on optimal solutions of {a mathematical formula}2(53)=0.2. This illustrates why it has to be reified.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Experimental study
     </section-title>
     <paragraph>
      In order to evaluate the interest of our contribution, we perform extensive tests. First, Section 5.1 introduces and motivates a new benchmark data set for the SMPTSP. Next, in Section 5.2, we focus on the objective lower bound quality at root node. Section 5.3 highlights the potential benefit of strengthening and diversifying the filtering. Section 5.4 investigates the interest of adding the reification of a symmetry breaking constraint. Section 5.5 focuses on the scalability issue, i.e., it evaluates the ability of our approach to compute tight bounds, even on large instances. Finally, in Section 5.6 we compare our approach to the best known results on the state-of-the-art SMPTSP instances.
     </paragraph>
     <paragraph>
      Our algorithms have been implemented in JAVA, we have used Choco 3-1-1 [14] to implement CP model and Cplex 12.4 with default settings to implement MIP model. Note that we have used the automatic tunning tool of Cplex to get the best setting, which turned out to be the default one. All our implementations are available online at [40]. In the following we respectively note {a mathematical formula}z⁎ and {a mathematical formula}z̲r the optimal objective and the objective lower bound at root node. Finally, a CP model using a propagator {a mathematical formula}AMNV〈G|F|R〉, is noted {a mathematical formula}↓AMNV〈G|F|R〉 when used within a top–down minimisation strategy and {a mathematical formula}↑AMNV〈G|F|R〉 when used within a bottom–up minimisation strategy.
     </paragraph>
     <section label="5.1">
      <section-title>
       A new set of challenging SMPTSP instances
      </section-title>
      <paragraph>
       Very recently, Smet et al. have shown in [56] that the 137 instances provided by Krishnamoorthy and Ernst in [37] admit a feasible solution with an objective value equal to {a mathematical formula}LB≠. Since worker skills are taken into account in [37], this result is somehow surprising: One may expect that considering worker skills would have an impact on the optimum, but actually, it only makes it harder to find a feasible solution. Consequently, these instances do not provide much challenge regarding to the search of interesting lower bounds. Therefore, we propose a new set of challenging instances whose maximal number of overlapping tasks does not provide a good lower bound.
      </paragraph>
      <paragraph>
       In order to generate this new benchmark we use a dedicated procedure based on some of the empirical results presented in [37] and [56]. First of all, it is specified in [37] that the average tightness, defined as the sum of processing times over the sum of shift lengths should be close to 90% in order to obtain challenging instances. Another hardness analysis [56] shows that the smaller the average task processing time, the more difficult instances are to solve. Based on these two conclusions, we designed a dedicated procedure able to generate a new set of challenging instances. The procedure which is given in details in [40] generates randomly a set of tasks ranging from 15 minutes to 2 hours. We consider random skills and six different time windows to generate shifts. The first three aim at splitting a working day into 8 hours time intervals, which is very common in personnel scheduling [57]. The other three are obtained from the previous ones by introducing an offset to their starting time, so that each task is entirely contained in at least one time interval. Based on this simple procedure, we provide 100 new instances with a number of tasks ranging from 70 to 1600 and a number of available shifts ranging from 60 to 950. These instances along with our generator are available online [40]. In the following, we refer to the instances of Krishnamoorthy et al. as Data_137, and our generated instances as Data_100. In order to apprehend the differences between Data_137 and Data_100, we now provide some comparisons between those two data sets.
      </paragraph>
      <paragraph>
       As a first step, we show the ratios {a mathematical formula}|S||T| and {a mathematical formula}z⁎|T| on every instance (represented as a mark) in Fig. 6. Both {a mathematical formula}|S| and {a mathematical formula}|T| are input data, whereas {a mathematical formula}z⁎ is known (or at least well approximated) after resolution. This enables to highlight both input and output characteristics of these instances. As can be seen, the two instance sets form two disjoint clusters. It is interesting to notice that instances of the same data set can then be split into sub-clusters, revealing some patterns in their generator. The main difference between the two data sets is related to {a mathematical formula}z⁎|T|, which has an average value of {a mathematical formula}39% and {a mathematical formula}83%, respectively for Data_100 and Data_137. Regarding input data only, {a mathematical formula}|S||T| is 2.2 times bigger in Data_100 than in Data_137. Thus, Data_100 instances have on average more available shifts per task than Data_137, but they use a significantly smaller percentage of these shifts in optimal solutions. Therefore, finding a shift set which corresponds to an optimal solution may be more difficult.
      </paragraph>
      <paragraph>
       As a second step, we investigate the homogeneity of shifts. In order to evaluate this characteristic, we use a normalised Hamming distance: Given an instance i, the distance {a mathematical formula}dH(s1,s2) between two shifts {a mathematical formula}s1 and {a mathematical formula}s2 is equal to the number of tasks that belong to one and only one of the shifts, divided by the total number of tasks within i. To measure the homogeneity of shifts we compute this distance for every pair of shifts in all instances. The analysis of these data relies then on the use of quartiles. As illustrated in Fig. 7, it turned out that the median distance between shifts is on average relatively similar from Data_137 ({a mathematical formula}44.5%) to Data_100 ({a mathematical formula}46.6%). However, the first and third quartiles of this distance are on average quite different from one data set to another: Many shifts in Data_100 are either very similar or quite different, whereas shifts in Data_137 are always a bit different. This difference of homogeneity mainly comes from the use of 8 hours shifts within Data_100: Shifts that belong to the same time interval are relatively close whereas shifts that belong to different time intervals are completely different.
      </paragraph>
     </section>
     <section label="5.2">
      Impact of {a mathematical formula}GCI on root node
      <paragraph>
       Basically, using {a mathematical formula}GCI instead of {a mathematical formula}GI aims at reducing the number of edges to obtain larger independent sets, hence a better filtering. As a first step to measure the interest of {a mathematical formula}GCI, we evaluate the ratio {a mathematical formula}|ECI||EI|. On Data_137, this ratio ranges between 35% and 85% with a mean value of 65%. On Data_ 100, the trend is different since the minimum and the maximum ratio are respectively 67% and 75%, with a mean value of 71%. Note also that this ratio tends to increase on Data_137, whereas it is constant on Data_100. These differences surely come from the strengthened structure of Data_100 compared to Data_137. Overall, {a mathematical formula}GCI has significantly less edges than {a mathematical formula}GI. (See Fig. 8.)
      </paragraph>
      <paragraph>
       We then compare the value of the root lower bound, {a mathematical formula}z̲r, obtained with {a mathematical formula}AMNV〈GCI|MD|R1〉 and {a mathematical formula}AMNV〈GI|MD|R1〉, on both data sets. {a mathematical formula}LB≠ is used as a baseline comparison. Results are reported on Fig. 9. The horizontal axis represents instances, sorted by increasing value of {a mathematical formula}LB≠. On both data sets, using {a mathematical formula}AMNV〈GCI|MD|R1〉 instead of {a mathematical formula}AMNV〈GI|MD|R1〉 dramatically improves the value of {a mathematical formula}z̲r. On Data_137, the use of {a mathematical formula}GCI allows to get a relative gap between {a mathematical formula}LB≠ and {a mathematical formula}z̲r of about 6%. As {a mathematical formula}LB≠ is always equal to {a mathematical formula}z⁎ on Data_137, this means that {a mathematical formula}z̲r is already very close to {a mathematical formula}z⁎. On Data_100, the use of {a mathematical formula}GCI allows to get values of {a mathematical formula}z̲r that are more than twice {a mathematical formula}LB≠. On both data sets, our approach scales much better than the classical one which is not able to increase {a mathematical formula}z̲r whatever the size of the instance. More precisely the lower bound given by {a mathematical formula}AMNV〈GI|MD|R1〉 turns around 1 (respectively 6), which corresponds to the different time windows on Data_137 (respectively Data_100). Actually, this is not really surprising since {a mathematical formula}AMNV〈GI|MD|R1〉 is blind to AllDifferent constraints, which represent a big part of the problem. Using {a mathematical formula}GCI instead of {a mathematical formula}GI makes these AllDifferent constraints visible to AtMostNValue, hence the increased of {a mathematical formula}z̲r.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Managing the tradeoff between filtering and runtime
      </section-title>
      <paragraph>
       As explained in Section 3.4, using the algorithm {a mathematical formula}Rk is a simple and effective way to obtain diversification in filtering. The parameter k enables to manage the tradeoff between expected filtering power and runtime. Since {a mathematical formula}Rk is suggested as a complement to MD, it must be seen as an improvement opportunity. Back to our case, many values of k, together with various filtering rules have been tested, within a time limit of 5 minutes. Within these experiments, the search heuristic does not branch on {a mathematical formula}breif, which will be evaluated in the next section.
      </paragraph>
      <paragraph>
       Impact of AMNV back-propagation
      </paragraph>
      <paragraph>
       In order to evaluate the influence of the back-propagation of AMNV on performances, we compare the number of optima proved by CP model with filtering rules {a mathematical formula}R1, {a mathematical formula}R1,2 and {a mathematical formula}R1,3 (Fig. 10). {a mathematical formula}R1,2 introduces a slight overhead compared to {a mathematical formula}R1 only, without providing much more domain reductions. Thus, {a mathematical formula}R1 is generally more efficient than {a mathematical formula}R1,2 on Data_137. Instead, {a mathematical formula}R3 has a strong impact on Data_137: It enables to solve 26 more instances within the time limit. Note that a minimum number of iterations is required before {a mathematical formula}R3 brings a significant improvement. However, results are more qualified on Data_100. Overall, {a mathematical formula}R3 is worth the overhead. Thus, the interest of {a mathematical formula}Rk not only lies in finding larger independent sets ({a mathematical formula}R1), but also in diversifying the filtering ({a mathematical formula}R3).
      </paragraph>
      <paragraph>
       Interestingly, the best setting for k changes quite a lot from one data set to another, hence using an automatic algorithm configuration program [33] seems relevant to get the best results. About Data_137, a few dozens of iterations enable to enhance performances, with a best value for k around 120. On the contrary, hundreds and even thousands of iterations are required to solve Data_100 instances. In particular, performing 5000 iterations on Data_100 is still much better than performing none. This means that the benefit of {a mathematical formula}Rk is absolutely worth the induced overhead. The optimal setting seems to be around 2000. Note that within 5 minutes, the best configuration of CP model is able to solve around 80% of Data_137, compared to only half of Data_100.
      </paragraph>
      <paragraph>
       Impact of AllDifferent propagation
      </paragraph>
      <paragraph>
       In this section, we investigate the interest of {a mathematical formula}R4. As explained in Section 3.5, this rule is not relevant to the SMPTSP, because all maximal AllDifferent constraints are already known. Nevertheless, it may be worthwhile when disequalities appear dynamically. To get insight into the behaviour of {a mathematical formula}R4, while preserving the SMPTSP as an illustration, we remove all the AllDifferent constraints of CP model and replace them by cliques of binary disequalities (suffixed with a {a mathematical formula}⁎). This enables to measure the filtering ability stemming from {a mathematical formula}R4, which only makes sense if maximal AllDifferent constraints are not in the original model.
      </paragraph>
      <paragraph>
       Thus, the semantic of the problem remains the same while the global view of the AllDifferent constraints is lost. Note that, we no longer use {a mathematical formula}LB≠ as an initial lower bound, because it corresponds to the size of the largest AllDifferent constraint. Given this new model, we compare the number of optima respectively proved by {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉⁎ and {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3,4〉⁎, for different values of k, after a resolution of 5 minutes (Fig. 11). As justified in Section 3.5, {a mathematical formula}R4 calls the AllDifferent BC filtering algorithm on every independent set.
      </paragraph>
      <paragraph>
       As a baseline comparison, we also display the results of {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉, which includes AllDifferent constraints.{sup:2} Therefore, Fig. 11 enables to evaluate the role of {a mathematical formula}R4 when AllDifferent constraints are not given, but also to compare the good propagation of AllDifferent constraints with the naive propagation of binary disequalities.
      </paragraph>
      <paragraph>
       Two main observations can be made on Data_137 results. First, the good propagation of AllDifferent constraints only makes a difference once the AMNV filtering is strong enough, i.e., when {a mathematical formula}k&gt;0. For instance, with {a mathematical formula}k=120, it enables to find 118 optima, whereas {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉⁎ and {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3,4〉⁎ respectively solve 101 and 99 instances to optimality. Second, {a mathematical formula}R4 has a low impact on results. A slight improvement can be noticed for small k values, but this trend reverses when k increases. This means {a mathematical formula}R4 is unfortunately not able to get back the good tradeoff between filtering and runtime of the original model, which has AllDifferent constraints in it.
      </paragraph>
      <paragraph>
       Surprisingly, with {a mathematical formula}k&lt;1000, {a mathematical formula}R4 leads to even better results than the original model on Data_100. It provides a better tradeoff between filtering and runtime. However, increasing k even more introduces a strong overhead. Interestingly, it can be seen that {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉 and {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉⁎ lead to very similar results. This means that achieving a high level of consistency over AllDifferent constraints or simply propagating binary disequalities does not really matter on this data set. The difficulty of such instances mainly stems in the lower bounding of the problem. Perhaps the AMNV propagation must be improved before AllDifferent constraint propagations play a key role.
      </paragraph>
     </section>
     <section label="5.4">
      Impact of branching on {a mathematical formula}breif
      <paragraph>
       We now evaluate the interest of branching on {a mathematical formula}breif (Fig. 12), as suggested in Section 4. This binary variable reifies the constraint {a mathematical formula}maximum(X)=z, which breaks symmetries arising from the case where all shifts are equivalent. We mention that no instance satisfies such an assumption. Hence, branching on {a mathematical formula}breif is a totally heuristic choice, aiming at reducing the search space. Results show that {a mathematical formula}breif is very well suited to Data_137. It enables to solve 136 instances in less than 5 minutes (with {a mathematical formula}k=20). This may come from the {a mathematical formula}z⁎|S| ratio and the homogeneous repartition of task-shift compatibilities: Any set of {a mathematical formula}z⁎ shifts is very likely to cover all tasks. Nevertheless, it is worth mentioning that, on this data set, no two shifts are identical. Unfortunately, {a mathematical formula}breif does not help solving Data_100 instances, which have more structure in the design of shifts, to the contrary. We observe a slight performance loss. Note that the possibility to use constraint reification within search is a powerful feature of CP.
      </paragraph>
     </section>
     <section label="5.5">
      <section-title>
       Scalability study
      </section-title>
      <paragraph>
       We now evaluate the ability of our approach to provide good bounds even on large scale instances. For that, we evaluate the relative gap {a mathematical formula}(z¯–z̲)/z¯ depending on the running model. Both MIP model and CP model are run with a time limit of 6 minutes. Default values for {a mathematical formula}z̲ and {a mathematical formula}z¯ are respectively 0 and {a mathematical formula}|S|, i.e., {a mathematical formula}LB≠ is not used. Therefore, a run which times out without computing any bound leads to a relative gap of {a mathematical formula}100%. In order to get tight bounds, CP model is first run 3 minutes in a bottom–up approach to compute a good lower bound and then, if no optimum has been found, 3 other minutes in a top–down mode to get a good upper bound. Given the size of the instances, finding a feasible solution may be difficult. As the AtMostNValue propagation relies on lower bounding, we can expect a strong propagation during the bottom–up step. This is no longer expectable in a top–down approach, for which the faster propagation the better. Therefore, the filtering of {a mathematical formula}↓AMNV〈GCI|MD,Rk|R1,3〉 is lightened by setting k to 0. Furthermore, as enforcing {a mathematical formula}maximum(X)=z removes feasible solutions, {a mathematical formula}breif is set to 0 as well.
      </paragraph>
      <paragraph>
       Fig. 13 gives general trends regarding the ability to scale of MIP model and CP model. It shows that MIP model fails to solve about half of instances on both data sets: It is not able to provide either lower bounds or upper bounds ({a mathematical formula}100% gap). On Data_137, there are 12 instances for which it is able to compute a lower bound, but no upper bound ({a mathematical formula}70%–95% gap). This indicates that embedding the linear relaxation of the problem within a global constraint is not promising at all on these large scale instances. Regarding this scalability issue, the top–down and bottom–up CP approaches perform very well. The relative gap is on average {a mathematical formula}0.1% and {a mathematical formula}1.4%, with a maximum of {a mathematical formula}2.9% and {a mathematical formula}5.7%, for respectively Data_137 and Data_100. Thus, the relative gap does not increase much with the instance size. Consequently, using {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉 and {a mathematical formula}↓AMNV〈GCI|MD|R1,3〉 leads to finding tight bounds for z, even on large instances. This makes CP model a more reliable approach than MIP model to bound the objective in a short time.
      </paragraph>
     </section>
     <section label="5.6">
      <section-title>
       A competitive approach
      </section-title>
      <paragraph>
       In order to estimate the quality of our approach, we now compare it to the state-of-the-art SMPTSP approaches, on instances of the literature (Data_137). The first two SMPTSP approaches were given by Krishnamoorthy et al., who introduced both MIP model and a dedicated metaheuristic [36]. Next, Smet et al. provided a metaheuristic based on a local branching improvement heuristic [56]. Finally, and very recently, Lin and Ying proposed a three-phase exact approach [43]: The first phase builds an initial solution with a constructive heuristic, the second one improves it with an iterated greedy algorithm, and the third one solves MIP model, initialized with the best solution found.
      </paragraph>
      <paragraph>
       We compare the performances of CP model with existing approaches. This comparison is based on their ability to reach an optimal solution in a short time. For CP model, we used {a mathematical formula}↑AMNV〈GCI|MD,R40|R1,3〉, the best configuration on Data_137. Regarding the results of [43], it occurs that their last phase times out on instances for which the input solution (computed in phases one and two) is optimal. Presumably, they were not aware that {a mathematical formula}LB≠ is optimal on Data_137, which was first pointed out by Smet et al. Therefore, to have a fair evaluation of their method, we consider that it stops whenever one of the three phases has found an optimal solution. This slightly shorten the running time of [43].
      </paragraph>
      <paragraph>
       As illustrated in Fig. 14, both CP model and [56] dominate other approaches. They are comparable in the sense that they both find all optimal solutions within the given time limit. Nevertheless, [56] focuses on finding good solutions and its only lower bounding procedure is {a mathematical formula}LB≠. Therefore, this approach is not able to prove optimality in general, whereas CP model is able to provide optimality certificates. We point out that the results of CP model are better than those presented in [21]. This comes from slight code refactoring along with the use of {a mathematical formula}breif (see Section 4).
      </paragraph>
      <paragraph>
       As the SMPTSP often occurs as a subproblem of a more general method, it seems critical to provide a good lower bound in a short time. To evaluate the capacity of {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉 to provide quickly a good value of {a mathematical formula}z̲, we compare {a mathematical formula}z̲r and its required runtime with those of the lower bounding procedure given in [36]. This procedure is based on a Lagrangian relaxation, therefore, we refer to its lower bound as {a mathematical formula}z̲L. For a full resolution, {a mathematical formula}↑AMNV〈GCI|MD,R40|R1,3〉 gives the best results on Data_137. However, if the purpose is to design an effective lower bounding procedure, it may be interesting to use a much higher value of k, which may reduce the gap to optimality with a small overhead. Consequently, we compare {a mathematical formula}z̲L with {a mathematical formula}z̲r for two different settings of k: 40 and 1000. To ease the reading, {a mathematical formula}z̲r will be noted {a mathematical formula}z̲r40 when obtained with {a mathematical formula}k=40 and {a mathematical formula}z̲r1000 when obtained with {a mathematical formula}k=1000. To have a fair comparison, we do not use {a mathematical formula}LB≠ in our model, since it gives the optimal value on the state-of-the-art instances.
      </paragraph>
      <paragraph>
       As illustrated in Fig. 15, {a mathematical formula}z̲r40 and {a mathematical formula}z̲r1000 are much closer to {a mathematical formula}z⁎ than {a mathematical formula}z̲L. More precisely, {a mathematical formula}z̲r1000 is always equal to {a mathematical formula}z⁎ and {a mathematical formula}z̲r40 is on average more than ten times closer to {a mathematical formula}z⁎ than {a mathematical formula}z̲L. Moreover, the empirical worst-case gap of {a mathematical formula}z̲r40 (2.26%) is also better than the one of {a mathematical formula}z̲L (10.17%). Finally, as illustrated by Fig. 16, the runtime of {a mathematical formula}z̲r40 and {a mathematical formula}z̲r1000 are much smaller than the one of {a mathematical formula}z̲L: The average runtime of {a mathematical formula}z̲r40 turns around half a second compared to more than one hundred seconds for {a mathematical formula}z̲L. Note that the average runtime of {a mathematical formula}z̲r1000 is less than twice as big as the one of {a mathematical formula}z̲r40, which highlights the interest of increasing k when searching a good lower bound. On the whole, the root node provided by {a mathematical formula}↑AMNV〈GCI|MD,Rk|R1,3〉 is very close to the optimum, and it can be computed quickly, even on large scale instances.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Conclusions
     </section-title>
     <paragraph>
      In this paper, we have introduced a CP approach to solve the SMPTSP, along with a new set of challenging instances. This model outperforms previous exact approaches on state-of-the-art benchmarks. Furthermore, it provides very good lower and upper bounds, even on large instances, in a short time. Thus, the CP approach competes with both exact and metaheuristic state-of-the-art approaches.
     </paragraph>
     <paragraph>
      Furthermore, we have provided the notation {a mathematical formula}AMNV〈G|F|R〉, to describe a family of AtMostNValue propagators. In particular, we introduced a new propagator, {a mathematical formula}AMNV〈GCI|MD,Rk|R1,3〉, to filter the conjunction of an AtMostNValue constraint and disequalities. This propagator keeps close to the existing AtMostNValue propagator because it is fast to propagate, but also to capitalise over previous work in order to reduce implementation and maintenance issues. {a mathematical formula}AMNV〈GCI|MD,Rk|R1,3〉 relies on a more appropriate graph structure ({a mathematical formula}GCI), as well as refined filtering rules ({a mathematical formula}R3), and a simple way to diversify filtering ({a mathematical formula}Rk), in order to improve the overall approach. Moreover, this propagator gives control over the tradeoff between filtering and runtime. As it is simple to implement, effective and relevant for many applications, we believe that this propagator would benefit the CP community.
     </paragraph>
     <paragraph>
      Nevertheless, the maximum independent set is not a tight relaxation for AtMostNValue, and there are several leads to achieve a stronger filtering. One of these is the Lovász number [45], a real number introduced in Graph Theory as an upper bound over the Shannon capacity of a graph. Lovász's sandwich theorem indicates that the Lovász number of {a mathematical formula}GCI provides a valid lower bound over the number of distinct values to be taken by {a mathematical formula}X, which is greater or equal to the maximum independent set relaxation. This number can be approximated with Semi Definite Programming (SDP) solvers (e.g.[8], [11]), which are unfortunately not yet fast enough to allow an integration into a global constraint. Therefore, future improvement in SDP may have a positive impact on CP applications related to the SMPTSP. Another research perspective would be to investigate the application of this propagator in the context of dynamic difference constraints, which occurs in many disjunctive scheduling problems.
     </paragraph>
     <paragraph>
      Finally, we introduced an original way to enhance search by introducing and reifying a global constraint. The success of this dedicated and naive attempt draw new perspectives regarding search heuristics. We believe this concept may be generalised toward new black-box search strategies [9], [46], [49], based on global constraint reification. This may reduce the need of designing dedicated search procedures [53], which still restricts the diffusion of CP. Past work on both symmetry breaking [26] and global constraint learning [6] may be a good lead.
     </paragraph>
    </section>
   </content>
  </root>
 </body>
</html>