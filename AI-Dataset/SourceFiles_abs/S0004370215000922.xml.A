<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Measuring inconsistency in probabilistic logic: rationality postulates and Dutch book interpretation.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      “when you can measure what you are speaking about, you know something about it; but when you cannot […] your knowledge is of a meagre and unsatisfactory kind;” — Lord Kelvin [45]
     </paragraph>
     <paragraph>
      Measuring has been a prominent activity in advancing scientific and technological development. Not all measures are alike and good measures express intuitive notions in a useful way. In the field of deductive logical reasoning, one usually has an intuition expressing that one theory is more inconsistent than other, capturing the idea that the “effort” to restore consistency is greater in one case than the other. Also, no effort is required to restore the consistency of a consistent theory.
     </paragraph>
     <paragraph>
      Based on those intuitions, there are several proposals for measuring inconsistency in knowledge bases over purely logical languages [19]. Some of these proposals involved attaching probabilities to formulas [29], or the combination of inconsistency factors [20]. Some of these measures are discrete or even qualitative, while others are more like distances, but all these measures have to behave like an information measure[6]. And to adhere to certain intuitions, a series of postulates for inconsistency measures for purely logical knowledge bases were proposed [21], [22]; for example, the consistency postulate states that the inconsistency measure of a consistent base is 0.
     </paragraph>
     <paragraph>
      Purely logical bases are known to be expressively limited in representing uncertainty required for real-world applications. In this work, we are interested in measuring the inconsistency of knowledge bases over logical probabilistic languages, which combine the deductive power of logical systems with the well-founded theory of probability. This kind of extension of purely logical systems can be traced back to the work of Boole [2], but has gained attention of AI researchers since the work of Nilsson [33], and has been extended to conditional probabilistic logic [37].
     </paragraph>
     <paragraph>
      In AI, one of the main uses of measuring inconsistency in a knowledge base is to guide the consolidation of inconsistent pieces of information. Within propositional logic, Grant and Hunter [13] showed how inconsistency measures can be used to direct the stepwise resolution of conflicts via the weakening or the discarding of formulas.
     </paragraph>
     <paragraph>
      In probabilistic bases, inconsistencies are rather common, specially when knowledge is gathered from different sources. To fix these probabilistic knowledge bases, one can, for instance, delete pieces of information, or change the probabilities' numeric values (or intervals). In this case, an inconsistency measure helps one to detect if a change approximates consistency or not. In other areas, inconsistency measures for probabilistic logic have found applications in merging conflicting opinions, leading to an increased predictive power [47], [25], and in quantifying the incoherence of procedures from classical statistical hypothesis testing [41].
     </paragraph>
     <paragraph label="Example 1.1">
      Consider we are devising an expert system to assist medical diagnosis. Suppose a group of experts on a disease D is required to quantify the relationship between D and its symptoms. Suppose three conditional probabilities are presented:
     </paragraph>
     <list>
      <list-item label="•">
       the probability of a patient exhibiting symptom {a mathematical formula}S1 given he/she has disease D is {a mathematical formula}50%;
      </list-item>
      <list-item label="•">
       the probability of a patient exhibiting symptom {a mathematical formula}S2 given he/she exhibits symptom {a mathematical formula}S1 and has disease D is {a mathematical formula}80%;
      </list-item>
      <list-item label="•">
       the probability of a patient exhibiting symptom {a mathematical formula}S2 given he/she has disease D is {a mathematical formula}30%.
      </list-item>
     </list>
     <paragraph>
      The issue of measuring inconsistency in probabilistic bases has more recently been tackled by Thimm [44], Muiño [31] and Potyka [34], who developed measures based on distance minimization, tailored to the probabilistic case. Potyka focused on computational aspects, looking for efficiently computable measures [34]. Muiño was driven by the CADIAG-2 knowledge base, presenting its infinitesimal inconsistency degree, however based on a different semantics [31]. Thimm [44] adapted Hunter and Konieczny's [22] desirable properties for inconsistency measures to the probabilistic setting, developing measures that satisfy a set of rationality postulates.
     </paragraph>
     <paragraph>
      It was Thimm [44] who realized the importance of continuity as a Postulate for the probabilistic case, namely the property that a small change in the probability associated to formula (absent in the purely logical case) should lead only to small changes in the inconsistency measure. It was just natural that, (conditional) probabilistic logic being an extension of the classical cases, the continuity postulate was simply added to the postulates defining classical inconsistency measures.
     </paragraph>
     <paragraph>
      In this work, we argue that continuity cannot hold together with classical postulates such as consistency and independence, and some of these postulates must be abandoned or exchanged for other ones that restore joint satisfiability. So the first contribution of this work is that we identify and fix the possible problem with the postulates proposed by Thimm [44].
     </paragraph>
     <paragraph>
      Another contribution lies in showing that these measures of inconsistency have a direct counterpart in formal epistemology research over the coherence of an agent's degrees of belief. It is known that inconsistent probabilistic beliefs correspond to a set of bets with guaranteed loss to the agent, which is called a “Dutch Book” [8], [27]. This agent's incoherence has been measured by formalizing the intuition that the greater the inconsistency the greater the corresponding sure loss, and vice versa [40], [43]. Thus we interpret these incoherence measures via guaranteed losses as inconsistency measures, showing that existing measures based on distance minimization correspond to guaranteed losses that quantify an agent's incoherence. To the best of our knowledge, no clear link has been shown between these two areas.
     </paragraph>
     <paragraph>
      Here is a bird's-eye view of how we achieve these goals.
     </paragraph>
     <paragraph>
      After introducing probabilistic knowledge bases in Section 2, this paper develops three main contributions, in three different sections, dealing closely with three other works. In the following, we overview such contributions, together with the organization of the paper and their relation to the existing literature.
     </paragraph>
     <paragraph>
      Inconsistency measures for probabilistic knowledge bases were analyzed via rationality postulates by Thimm [44]. In Section 3, we argue for the incompatibility of such desirable properties. Firstly, we introduce the problematic postulates: consistency, independence and continuity. The independence postulate claims that a free conditional — a (conditional) probability assignment that does not belong to any minimal inconsistent set — can be rule out without changing the degree of inconsistency. We also present the MIS-separability property, which deals with decomposability (through Minimal Inconsistent Sets) and implies independence. As Thimm's work regards precise probabilities, these four concepts are then introduced in this way. In a second step, Section 3 brings the first contribution of this work: the presented postulates are shown to be incompatible.
     </paragraph>
     <paragraph>
      In Section 4, we search for a reasonable way to reconcile the incompatible postulates. First of all, we argue that independence is the requirement to be weakened, together with the stronger property of MIS-separability. Afterwards, the concept of free conditional is analyzed, for independence is based on it. We find that free conditional is a notion linked to classical consolidation and contraction (i.e., discarding formulas to reach consistency), and it is not suitable for probabilistic bases. The innocuous conditional concept is introduced, by investigating a natural consolidation procedure for probabilities: through widening their intervals, instead of ruling them out. The i-independence postulate is put forward based on innocuous conditionals. In a similar way, we observe that MIS (minimal inconsistent set) is a notion that fails to capture all causes of inconsistency in the probabilistic knowledge bases. We define the alternative concept of inescapable conflict, which yields the IC-separability property. We show that innocuous conditionals are to inescapable conflicts as free conditionals are to minimal inconsistent sets. At the end of Section 4, the second main contribution of this paper emerges when i-independence and IC-separability are shown to be compatible with consistency and continuity, besides other desirable properties from the literature that are then presented.
     </paragraph>
     <paragraph>
      Once a consistent package of postulates is laid out, a myriad of inconsistency measures can still be considered rational. Hence, in Section 5, further criteria to evaluate inconsistency measures are discussed: computational efficiency and meaningful interpretation. On the one hand, two inconsistency measures computable through linear programs are adapted to imprecise probabilities from the work of Potyka [34]. It is shown that both measures satisfy the core postulates, and we present the additional desirable properties each one satisfies. On the other hand, we review two measures from Schervish, Kadane and Seidenfeld that quantify the incoherence of an agent using the betting concept of Dutch book [40], under the operational interpretation that her degrees of belief (probabilities) determine her gambling behavior. The third main contribution of this paper lies in showing the connection between inconsistency measures for probabilistic knowledge bases and incoherence measures for agents from formal epistemology. We prove that the two measures adapted from Potyka that are computable through linear programs are equivalent to two measures from Schervish et al. — that is, these two measures are rather efficient and have a meaningful interpretation. The final part of the section reviews other measures from the work of Schervish et al., showing that they also satisfy the postulates and are computationally feasible.
     </paragraph>
     <paragraph>
      As several families of inconsistency measures are discussed throughout the paper, Table 1 compiles their notation, the section in which they are defined and a short explanation of each.
     </paragraph>
    </section>
    <section label="2">
     <section-title>
      Preliminaries
     </section-title>
     <paragraph>
      A propositional logical language is a set of formulas formed by atomic propositions combined with logical connectives, possibly with punctuation elements (parentheses). We assume a finite set of symbols {a mathematical formula}Xn={x1,x2,x3,…,xn} corresponding to atomic propositions (atoms). Formulas are constructed inductively with connectives ({a mathematical formula}¬,∧,∨,→) and atomic propositions as usual. The set of all these well-formed formulas is the propositional language over {a mathematical formula}Xn, denoted by {a mathematical formula}LXn. Additionally, ⊤ denotes {a mathematical formula}xi∨¬xi for some {a mathematical formula}xi∈Xn, and ⊥ denotes ¬⊤.
     </paragraph>
     <paragraph>
      Given a signature {a mathematical formula}Xn, a possible world w is a conjunction of {a mathematical formula}|Xn|=n atoms containing either {a mathematical formula}xi or {a mathematical formula}¬xi for each {a mathematical formula}xi∈Xn. We denote by {a mathematical formula}WXn={w1,…,w2n} the set of all possible worlds over {a mathematical formula}Xn and say a {a mathematical formula}w∈WXnentails a {a mathematical formula}xi∈Xn ({a mathematical formula}w⊨xi) iff {a mathematical formula}xi is not negated in w. This entailment relation can be extended to all {a mathematical formula}φ∈LXn as usual.
     </paragraph>
     <paragraph>
      A probabilistic conditional (or simply conditional) is a statement of the form {a mathematical formula}(φ|ψ)[q_,q¯], with the underlying meaning “the probability that φ is true given that ψ is true lies within the interval {a mathematical formula}[q_,q¯]”, where {a mathematical formula}φ,ψ∈LXn are propositional formulas and {a mathematical formula}q_,q¯∈[0,1] are real numbers. Note that we do not assume {a mathematical formula}q_≤q¯, since we are going to measure inconsistency. If ψ is a tautology, a conditional like {a mathematical formula}(φ|ψ)[q_,q¯] is called an unconditional probabilistic assessment, usually denoted by {a mathematical formula}(φ)[q_,q¯]. We say a conditional in the format {a mathematical formula}(.)[q,q] is precise and denote it by {a mathematical formula}(.)[q].
     </paragraph>
     <paragraph>
      A probabilistic interpretation{a mathematical formula}π:WXn→[0,1], with {a mathematical formula}∑jπ(wj)=1, is a probability mass over the set of possible worlds, which induces a probability measure {a mathematical formula}Pπ:LXn→[0,1] by means of {a mathematical formula}Pπ(φ)=∑{π(wj)|wj⊨φ}. A conditional {a mathematical formula}(φ|ψ)[q_,q¯] is satisfied by π iff {a mathematical formula}Pπ(φ∧ψ)≥q_Pπ(ψ) and {a mathematical formula}Pπ(φ∧ψ)≤q¯Pπ(ψ). Note that when {a mathematical formula}Pπ(ψ)&gt;0, a probabilistic conditional {a mathematical formula}(φ|ψ)[q_,q¯] is constraining the conditional probability of φ given ψ; but any π with {a mathematical formula}Pπ(ψ)=0 trivially satisfies the conditional {a mathematical formula}(φ|ψ)[q_,q¯] (this semantics is adopted by Halpern [15], Frisch and Haddawy [11] and Lukasiewicz [30], for instance). A knowledge base is a finite set Γ of probabilistic conditionals such that, if {a mathematical formula}(φ|ψ)[q_,q¯],(φ|ψ)[q_′,q¯′]∈Γ, then {a mathematical formula}[q_,q¯]=[q_′,q¯′]. That is, for each pair {a mathematical formula}φ,ψ, only one probability interval can be assigned to {a mathematical formula}(φ|ψ) in a knowledge base.{sup:3} A knowledge base Γ is consistent (or satisfiable) if there is a probability mass satisfying all conditionals {a mathematical formula}(φ|ψ)[q_,q¯]∈Γ. It is precise if all intervals are singletons.
     </paragraph>
     <paragraph>
      The problem of verifying the consistency of a knowledge base is called probabilistic satisfiability (or PSAT) [12]. Probabilistic satisfiability has been rediscovered several times, and an analytical and unconditional version was actually proposed by Boole [2]. Hailperin [14], Bruno and Gilio [3], and Nilsson [33] suggested solutions via linear programs. This linear programming approach can be easily extended to handle conditional probabilities under the semantics we are using [16]. Recent advances in algorithms for PSAT solving can be found in [17], [9], [28].
     </paragraph>
     <paragraph>
      If any probability mass π satisfying {a mathematical formula}(φ|ψ)[q_,q¯] implied {a mathematical formula}Pπ(ψ)&gt;0, in an alternative semantics, the latter restriction could be added to the program, although losing the linear program standard format; this is the semantics adopted by Muiño [31], for instance. De Finetti proposed an alternative setting in which the conditional probability is fundamental [8] and the satisfaction of probabilistic conditionals does not trivialize when the conditioning event has null probability. In such scenario, the consistency is called coherence, and its checking demands solving a sequence of linear programs [5].
     </paragraph>
     <paragraph>
      When all interval bounds are rational numbers, PSAT is an NP-complete problem [12]; if there is a solution, there is a solution with only {a mathematical formula}m+1 possible worlds receiving positive probability mass, where m is the knowledge base size. Nevertheless, column generation methods can handle large problems [26], [24], and several approaches have recently appeared [28], [9], [17], [7]. Note that this linear programming approach can be applied to other probabilistic logics (see, for instance, [1] and [23]).
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      Proposed postulates for inconsistency measures
     </section-title>
     <paragraph>
      Approaches to measuring inconsistency in probabilistic knowledge bases have been put forward by Muiño [31], Thimm [44] and Potyka [34], with different semantics for the conditionals. We follow the one adopted by Thimm and Potyka, in which a conditional is also satisfied by any measure assigning null probability to the conditioning formula. Thimm has done a groundlaying work [44], extending Hunter's postulates for inconsistency measures to the probabilistic case, which is our starting point. Potyka suggests feasible measures [34] we will review in Section 5.1, after investigating carefully the postulates. In this section, we begin with some desirable properties proposed by Thimm and then argue against their joint satisfiability.
     </paragraph>
     <section label="3.1">
      <section-title>
       Postulates
      </section-title>
      <paragraph>
       Let {a mathematical formula}K ({a mathematical formula}Kprec) be the set of all (precise) knowledge bases. An inconsistency measure for knowledge bases is a function {a mathematical formula}I:K→[0,∞). Thimm's investigation is restricted to measures {a mathematical formula}I:Kprec→[0,∞) over knowledge bases with precise probabilities, to what we narrow our focus in this section. The author proposes some desirable properties such a function should satisfy, following Hunter and Konieczny's work for classical logic [20]. Although Thimm investigates a total of ten postulates, we describe in this section only four of these properties that we consider problematic. The first one claims that an inconsistency measure must at least discriminate between consistent and inconsistent bases:
      </paragraph>
      <paragraph label="Postulate 3.1">
       Consistency{a mathematical formula}I(Γ)=0iff Γ is consistent.
      </paragraph>
      <paragraph>
       A second desirable property has to do with probabilistic conditionals one can ignore while measuring inconsistency, since they are not involved with the unsatisfiability, in some sense. Some notation is needed to formalize it.
      </paragraph>
      <paragraph label="Definition 3.2">
       A set Γ of probabilistic conditionals is a minimal inconsistent set (MIS) if Γ is inconsistent and every set {a mathematical formula}Γ′⊊Γ is consistent.
      </paragraph>
      <paragraph>
       Minimal inconsistent sets can be considered the purest form of inconsistency [21], capturing its causes. The focus on MISes is derived from the seminal work of Reiter [36] on the diagnosis problem. Reiter investigated how formulas from a base could be ruled out in order to restore consistency, by choosing at least one element from each MIS, computing thusly a hitting set of their collection.
      </paragraph>
      <paragraph>
       Let {a mathematical formula}MIS(Γ) denote the collection of all MISes in Γ. Now we can define the central concept of free probabilistic conditional, following Thimm [44]:
      </paragraph>
      <paragraph label="Definition 3.3">
       A free probabilistic conditional of Γ is a probabilistic conditional {a mathematical formula}α∈Γ such that, for all {a mathematical formula}Δ∈MIS(Γ), {a mathematical formula}α∉Δ.
      </paragraph>
      <paragraph>
       Analogously, a free probabilistic conditional of Γ is in all its maximal consistent subsets. The postulate of independence then claims that ruling out a free probabilistic conditional from a knowledge base should not change its inconsistency degree [44].
      </paragraph>
      <paragraph label="Postulate 3.4">
       IndependenceIf α is a free probabilistic conditional of Γ, then{a mathematical formula}I(Γ)=I(Γ∖{α}).
      </paragraph>
      <paragraph>
       A stronger condition, also introduced by Hunter and Konieczny and adopted by Thimm, deals with a sort of decomposability of the inconsistency measure through its minimal inconsistent sets. We call it a property, saving the name “postulate” to the most basic properties required from every measure. The version we present is tailored from Hunter and Konieczny's work [20]:
      </paragraph>
      <paragraph label="Property 3.5">
       MIS-separabilityIf{a mathematical formula}Γ=Δ∪Ψ,{a mathematical formula}Δ∩Ψ=∅and{a mathematical formula}MIS(Γ)=MIS(Δ)∪MIS(Ψ), then{a mathematical formula}I(Γ)=I(Δ)+I(Ψ).
      </paragraph>
      <paragraph>
       The idea behind this property is that the inconsistency of the whole knowledge base should be the sum of the inconsistency of its parts, whenever the partition does not break any minimal inconsistent set. For instance, consider {a mathematical formula}Δ={(x1)[0.5],(¬x1)[0.6]}, {a mathematical formula}Ψ={(x2)[0.7],(x2∧x3)[0.8]} and {a mathematical formula}Γ=Δ∪Ψ. It is clear that Δ and Ψ are the only minimal inconsistent sets in Γ. MIS-separability posits that the measure of inconsistency of Γ is obtained by summing the measures of Δ and Ψ; formally, {a mathematical formula}I(Γ)=I(Δ)+I(Ψ). MIS-separability is stronger than independence [44]:
      </paragraph>
      <paragraph label="Proposition 3.6">
       If{a mathematical formula}Isatisfies MIS-separability, then{a mathematical formula}Isatisfies independence.
      </paragraph>
      <paragraph>
       These properties can be found in Hunter and Konieczny's work [21], in the definition of a “MinInc” separable basic inconsistency measure for knowledge bases over classical propositional logic. The measures they introduce are shown to fit such desiderata. Thimm revises the adaptation of these classical inconsistency measures to the probabilistic case and convincingly argues that they are not suitable to the quantitative nature of probabilities, since classical logic is qualitative.
      </paragraph>
      <paragraph>
       To motivate the search for new inconsistency measures for probabilistic knowledge bases, while dispensing with measures from classical logic, Thimm puts forward the postulate of continuity. Intuitively, one expects that small changes in the probabilities of a knowledge base yield small changes in its degree of inconsistency. To formalize the continuity concept in precise knowledge bases, we introduce some notation, following Thimm [44].
      </paragraph>
      <paragraph>
       That work studies precise knowledge bases of the form {a mathematical formula}Γ={(φi|ψi)[qi]|1≤i≤m}. For each precise knowledge base Γ, there is a characteristic function{a mathematical formula}ΛΓ:[0,1]|Γ|→Kprec that, roughly speaking, changes the probabilities {a mathematical formula}qi in the base; i.e., {a mathematical formula}ΛΓ(〈q1′,q2′,…,qm′〉)={(φi|ψi)[qi′]|1≤i≤m}. To handle the (consistent) empty knowledge base, we define {a mathematical formula}Λ∅:{∅}→{∅}. Thimm imposes some order on the set Γ, building a sequence, for the function {a mathematical formula}ΛΓ be unique and well-defined. For simplicity, we just suppose there is some order (say, lexicographic) over the probabilistic conditionals used to uniquely specify {a mathematical formula}ΛΓ.{sup:4} Now the continuity postulate can be enunciated, with ∘ denoting function composition:
      </paragraph>
      <paragraph label="Postulate 3.7">
       Continuity (for precise probabilities)For all{a mathematical formula}Γ∈Kprec, the function{a mathematical formula}I∘ΛΓ:[0,1]|Γ|→[0,∞)is continuous.
      </paragraph>
      <paragraph>
       To find inconsistency measures holding the desirable properties, including continuity, Thimm introduces a family of measures based on distance minimization, taking into account the numerical value of the probabilities. The basic idea is to quantify the inconsistency through the minimum changes, according to some distance, one has to apply on the probabilities to make the base consistent. The compatibility of consistency, independence and continuity is implicitly stated when it is proved that this whole family of inconsistency measures based on distance minimization satisfies them; and another family is proved to hold MIS-separability as well [44].
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       The postulates' incompatibility
      </section-title>
      <paragraph>
       The work done by Thimm [44] has carefully analyzed the problem of measuring inconsistency in knowledge bases over probabilistic logic. Desirable properties were borrowed from classical logic [20], and the crucial postulate of continuity was added. To attend these properties, measures based on distance minimization were introduced and some important results were proved. However, under a closer examination, the proposed postulates are incompatible.
      </paragraph>
      <paragraph label="Proof">
       There is no inconsistency measure{a mathematical formula}I:Kprec→[0,∞)that satisfies consistency, independence and continuity.To prove by contradiction, suppose there is a measure {a mathematical formula}I satisfying consistency, independence and continuity. Consider the following knowledge bases:{a mathematical formula}{a mathematical formula} We are going to use {a mathematical formula}I to measure the inconsistency of Δ when {a mathematical formula}ε→0. To apply independence, we are going to show that α is free in Δ; we prove that Γ is the only MIS in Δ. Note that {a mathematical formula}{(x1∧x2)[0.5+ε],(x1)[0.8]} is consistent for any {a mathematical formula}ε∈(0,0.1], for such set is satisfied by the probability measure induced by the following probability mass: {a mathematical formula}π1(x1∧x2)=0.5+ε,π1(x1∧¬x2)=0.3−ε,π1(¬x1∧x2)=π1(¬x1∧¬x2)=0.1. To prove that {a mathematical formula}{(x1∧¬x2)[0.5],(x1)[0.8]} is consistent, consider the following probability mass: {a mathematical formula}π2(x1∧x2)=0.3,π2(x1∧¬x2)=0.5,π2(¬x1∧x2)=π2(¬x1∧¬x2)=0.1. Hence, all MISes of Δ must contain {a mathematical formula}Γ={(x1∧x2)[0.5+ε],(x1∧¬x2)[0.5]}, for other subsets are all consistent. Furthermore, note that Γ is inconsistent and minimal, so it is a MIS. We can conclude that Γ is the only MIS in Δ, for any value of {a mathematical formula}0&lt;ε≤0.1. As α is a free probabilistic conditional of Δ, we can apply independence:{a mathematical formula} for any {a mathematical formula}0&lt;ε≤0.1.To exploit the continuity of {a mathematical formula}I, we need the characteristic function of Δ, {a mathematical formula}ΛΔ:[0,1]3→Kprec, to be well-defined; so, we need an order over the probabilistic conditionals. Suppose that Γ and Δ are ordered as they were defined in (1) and (2). Let {a mathematical formula}q⁎ be the vector {a mathematical formula}〈0.5,0.5,0.8〉. It follows that {a mathematical formula}ΛΔ(q⁎) differs from Δ only in its first conditional, which becomes {a mathematical formula}(x1∧x2)[0.5]. Now we prove that {a mathematical formula}ΛΔ(q⁎) is inconsistent. For any probability measure {a mathematical formula}Pπ, {a mathematical formula}Pπ(x1∧x2)=Pπ(x1∧¬x2)=0.5 implies {a mathematical formula}Pπ(x1)=1, contradicting {a mathematical formula}α={(x1)[0.8]}. As {a mathematical formula}I satisfies consistency,{a mathematical formula} By the continuity of {a mathematical formula}I, the function {a mathematical formula}I∘ΛΔ:[0,1]3→[0,∞) must be continuous, so there must be a limit at the point {a mathematical formula}q⁎, and such limit must be unique for any path approaching {a mathematical formula}q⁎:{a mathematical formula} By independence, we also have:{a mathematical formula} As {a mathematical formula}I satisfies continuity and {a mathematical formula}{(x1∧x2)[0.5],(x1∧¬x2)[0.5]} is satisfiable, the consistency of {a mathematical formula}I implies{a mathematical formula} The continuity of {a mathematical formula}I requires that {a mathematical formula}I∘ΛΓ(q⁎)=limq→q⁎⁡I∘ΛΓ(q), which by (3) and (4) is a contradiction, finishing the proof.  □
      </paragraph>
      <paragraph label="Corollary 3.9">
       There is no inconsistency measure{a mathematical formula}I:Kprec→[0,∞)that satisfies consistency, MIS-separability and continuity.
      </paragraph>
      <paragraph>
       Looking at the counterexample given in the proof of Theorem 3.8 may shed some light on what is the cause of such conflict among the desirable properties. The only minimal inconsistent set in Δ is Γ, and so independence forces the degree of inconsistency of Δ to be the same as that of Γ, but this is not generally the case when inconsistency is measured via probability changing. This happens due to the fact that changing the probabilities in Γ to some consistent setting does not in general imply that Δ becomes consistent. Although Γ is the only minimal inconsistent set of Δ, there is another way to prove the contradiction. Note that Γ implies {a mathematical formula}(x1)[1+ε], with {a mathematical formula}ε&gt;0, which contradicts a probability axiom, but also contradicts {a mathematical formula}α=(x1)[0.8]. While {a mathematical formula}ε=0 consolidates Γ, consolidating Δ requires a bigger change in probabilities, which is ignored by independence. By demanding {a mathematical formula}I(Δ)=I(Γ) for {a mathematical formula}ε&gt;0, the postulate of consistency forces a discontinuity on {a mathematical formula}ε=0. When {a mathematical formula}ε→0, the inconsistency degree of Γ tends to zero (by continuity), and independence requires the same from Δ. But this contradicts continuity, given consistency, for {a mathematical formula}{(x1∧x2)[0.5],(x1∧¬x2)[0.5]} would still contradict {a mathematical formula}(x1)[0.8], and Δ would be inconsistent.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Reconciling the postulates
     </section-title>
     <paragraph>
      The findings from the previous section suggest that in order to drive the rational choice of an inconsistency measure for knowledge bases, we must abandon at least one postulate among consistency, independence and continuity. We claim that a weakening of the desired properties can restore their compatibility, and in this section we investigate paths to achieve that goal. After reconciling the problematic postulates, we review other proposed properties for inconsistency measures and extend them to the general case of knowledge bases with imprecise probabilities, showing some measures to satisfy them.
     </paragraph>
     <paragraph>
      The consistency postulate seems to be indisputable, since the least one can expect from an inconsistency measure is that it separates inconsistent from consistent cases, or some inconsistency from none. The answer to the question of which property we should relax to restore compatibility is thus reduced to either independence or continuity. Hunter and Konieczny have already noted problems with independence in knowledge bases over classical logic, proposing to relax it [22]. Intuition shall be inclined towards keeping continuity, for it reflects the particular quantitative nature of probabilistic reasoning. A pragmatic reason to give up independence (and so MIS-separability) is simply to keep continuity, given consistency, to save inconsistency measures based on distance minimization. In the sequel, the withdrawal of independence within probabilistic logic is argued for in a more compelling way.
     </paragraph>
     <paragraph>
      The notion of free conditional and the postulate of independence are strongly related to the idea that minimal inconsistent sets are the causes of inconsistencies, as suggested by Hunter and Konieczny [20]. Thimm says that free conditionals are “harmless”, in some sense, to the consistency of a knowledge base [44]. What is behind these notions is the classical way of handling inconsistency through ruling out formulas, as Reiter proposed in his diagnosis problem [36] and as the standard AGM paradigm of belief revision defines base contraction (see [18] for a general view of the AGM paradigm). Reiter's hitting sets technique views a repair of some inconsistency set of formulas as giving up of at least one element from each minimal inconsistent set. For such repair to be minimal, no free formula should be discarded. In the AGM paradigm, the consolidation process of a belief base can be interpreted as the contraction of ⊥, the contradiction. The inclusion postulate claims that the result of a contraction is a subset of the belief base in question, and the relevance postulate forces the contraction of ⊥ to contain all free formulas of the base.
     </paragraph>
     <paragraph>
      When we move from classical to probabilistic logic, there is a natural way to relax formulas without completely losing their information. Note that ruling out a probabilistic conditional {a mathematical formula}(φ|ψ)[q_,q¯] is semantically equivalent to changing it to {a mathematical formula}(φ|ψ)[0,1], so it is a particular (and extreme) case of widening the probability interval. If we need to give up the belief on {a mathematical formula}(φ|ψ)[q_,q¯] to restore consistency, perhaps there are some {a mathematical formula}q_′≤q_ and {a mathematical formula}q¯′≥q¯ such that {a mathematical formula}(φ|ψ)[q_′,q¯′] can still be consistently believed. When inconsistency is measured continuously, through changes in probabilities, it is this more general kind of consolidation process that is being suggested. As it is indicated in the proof of Theorem 3.8, consolidating all minimal inconsistent sets (Γ) through probability changing does not imply consolidating the whole base (Δ). We can conclude that the concepts of free conditional and minimal inconsistent set are not suitable to analyze continuous inconsistency measures based on distance minimization.
     </paragraph>
     <paragraph>
      Furthermore, it seems that the definition of free conditional, and so independence, can be refined to be suitable for analyzing continuous measures, while continuity is a harder definition to be contrived to be compatible with independence. Hence, we can try to weaken independence, and perhaps MIS-separability, by modifying the notion of free conditional, instead of fully forgetting this postulate.
     </paragraph>
     <paragraph>
      As both independence and MIS-separability are defined via minimal inconsistent sets, in order to weaken these properties to reach compatibility with consistency and continuity, it seems reasonable to replace MIS by an alternative concept that could reconcile the desirable properties altogether. However, to do it in a principled way, we first analyze the concept of free probabilistic conditional as to the corresponding consolidation procedure and then modify it to save independence. Afterwards, a related notion of conflict that also fixes MIS-separability is introduced.
     </paragraph>
     <section label="4.1">
      <section-title>
       Refining the free probabilistic conditional concept
      </section-title>
      <paragraph>
       A weaker form of independence has already been suggested in the literature. Thimm [44] defines a safe conditional as one whose atomic propositions are disjoint from those in the rest of the base. We also demand that the conditional be satisfiable in order to be safe.{sup:5} The weak independence postulate then posits that ruling a (satisfiable) safe conditional out should not change the inconsistency measure of a base. Hunter and Konieczny have suggested the same weakening for independence, in the classical setting, when they acknowledge that independence may be too strong a property to require [22]. Weak independence is compatible with consistency and continuity, since Potyka's measures satisfy them [34]. Although safe conditionals are easily recognizable, we expect that they be rare in practice, due to the natural logical dependencies among propositions within a base. We are looking for a stronger, more useful notion of independence, between the safe-based and the free-based ones, hence we look for a concept between safe and free.
      </paragraph>
      <paragraph>
       Besides defining free probabilistic conditional through minimal inconsistent sets, one could equivalently do it via the notion of consolidation as giving up conditionals to restore consistency. Let us formalize this concept.
      </paragraph>
      <paragraph label="Definition 4.1">
       Let Γ be a knowledge base in {a mathematical formula}K. An abrupt repair of Γ is any set {a mathematical formula}Δ⊆Γ such that {a mathematical formula}Γ′=Γ∖Δ is consistent — we call {a mathematical formula}Γ′ an abrupt consolidation. If an abrupt repair Δ is such that, for every {a mathematical formula}Ψ⊊Δ, {a mathematical formula}Γ∖Ψ is inconsistent, Δ is a minimal abrupt repair — and {a mathematical formula}Γ′=Γ∖Δ is a maximal abrupt consolidation.
      </paragraph>
      <paragraph>
       We can now prove{sup:6} a result that states different ways to define a free probabilistic conditional, as being part of no minimal abrupt repairs (of all maximal consistent sets) or being consistent with any abrupt repair. We say a conditional α is consistent with a knowledge base Γ if there is a probability mass π that satisfies α and Γ.
      </paragraph>
      <paragraph label="Theorem 4.2">
       Consider a knowledge base{a mathematical formula}Γ∈Kand a probabilistic conditional{a mathematical formula}α∈Γ. The following statements are equivalent:
      </paragraph>
      <list>
       <list-item label="1.">
        There is no minimal abrupt repair Δ of Γ such that{a mathematical formula}α∈Δ.
       </list-item>
       <list-item label="2.">
        For all maximal abrupt consolidation{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
       </list-item>
       <list-item label="3.">
        If{a mathematical formula}Γ′=Γ∖Δis an abrupt consolidation of Γ (equivalently, Δ is an abrupt repair of Γ), then α is consistent with{a mathematical formula}Γ′.
       </list-item>
       <list-item label="4.">
        There is no minimal inconsistent set{a mathematical formula}Δ⊆Γsuch that{a mathematical formula}α∈Δ.
       </list-item>
      </list>
      <paragraph>
       Note that the fourth statement above is the definition of free probabilistic conditional given in Section 3.1. The first and the second statements are clearly dual to each other, so we have presented two new ways of equivalently defining a free probabilistic conditional without mentioning minimal inconsistent sets, but using abrupt repair and abrupt consolidation. As it is suggested in the previous section, ruling a conditional out is equivalent to widening the corresponding interval to {a mathematical formula}[0,1] — that is why we call it an abrupt repair. However, a probabilistic logic allows for a more general notion of consolidation, formalized below. To save notation, we write {a mathematical formula}(φ|ψ)[q_,q¯]⊆(φ|ψ)[q_′,q¯′] if {a mathematical formula}q_′≤q_ and {a mathematical formula}q¯′≥q¯; and ⊊ is defined from ⊆ as usual.
      </paragraph>
      <paragraph label="Definition 4.3">
       Let Γ be a knowledge base in {a mathematical formula}K. {a mathematical formula}Γ′∈K is a widening of Γ if there is a bijection {a mathematical formula}f:Γ→Γ′ such that {a mathematical formula}α⊆f(α) for all {a mathematical formula}α∈Γ; furthermore, if a widening {a mathematical formula}Γ′ is consistent, we say it is a consolidation of Γ.
      </paragraph>
      <paragraph>
       In other words, a consolidation of Γ is the result of widening the probability intervals of its conditionals to a consistent setting. Analogously to the maximal abrupt consolidation, related to a minimal abrupt repair, we can define a sort of consolidation with minimal changes, we call dominant.
      </paragraph>
      <paragraph label="Definition 4.4">
       A consolidation {a mathematical formula}Γ′ of Γ is a dominant consolidation (or simply a d-consolidation) of Γ if, for all consolidations Ψ of Γ, if {a mathematical formula}Γ′ is a widening of Ψ, then {a mathematical formula}Γ′=Ψ.
      </paragraph>
      <paragraph>
       A d-consolidation {a mathematical formula}Γ′ of Γ is such that if some probability interval of Γ were less widened, fixing the others, the resulting base would not be consistent. In other words, it is not possible to give up strictly less information than a d-consolidation while restoring consistency; for an interval to be less widened, another must be more enlarged. In these sense, the changes in the probability bounds are minimal, and the consolidation is maximal.
      </paragraph>
      <paragraph>
       From these concepts, two new definitions for free probabilistic conditional could be derived: a conditional is free if it is in any d-consolidation; or a conditional is free if it is consistent with any consolidation. We can prove these definitions are actually equivalent:
      </paragraph>
      <paragraph label="Lemma 4.5">
       Consider a knowledge base{a mathematical formula}Γ∈Kand a probabilistic conditional{a mathematical formula}α∈Γ. The following statements are equivalent:
      </paragraph>
      <list>
       <list-item label="1.">
        For all d-consolidations{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
       </list-item>
       <list-item label="2.">
        If{a mathematical formula}Γ′is a consolidation of Γ, then α is consistent with{a mathematical formula}Γ′.
       </list-item>
      </list>
      <paragraph>
       A modification of the free probabilistic conditional concept is suggested by the comparison of Lemma 4.5 with Theorem 4.2, which would yield a different postulate of independence. To not overload the concept of free conditional, we say these probabilistic conditionals are innocuous, for they are consistent with any consolidation of the knowledge base.
      </paragraph>
      <paragraph label="Definition 4.6">
       An innocuous probabilistic conditional of Γ is a probabilistic conditional {a mathematical formula}α∈Γ such that, for every dominant consolidation {a mathematical formula}Γ′ of Γ, {a mathematical formula}α∈Γ′.
      </paragraph>
      <paragraph>
       The difference between free and innocuous conditionals can be seen in the knowledge base from the proof of Theorem 3.8, as the following example shows.
      </paragraph>
      <paragraph label="Example 4.7">
       Consider the following knowledge base:{a mathematical formula} As it was claimed in the proof of Theorem 3.8, {a mathematical formula}{(x1∧x2)[0.6],(x1∧¬x2)[0.5]} is the only minimal inconsistent set of Δ; so {a mathematical formula}α=(x1)[0.8] is a free probabilistic conditional. Nonetheless, Δ has no innocuous probabilistic conditional. This can be noted through the following dominant consolidation of Δ:{a mathematical formula}{a mathematical formula}Δ′ is consistent and any consolidation {a mathematical formula}Ψ≠Δ′ has at least one wider probability interval; so {a mathematical formula}Δ′ is dominant. But no original conditional of Δ is in {a mathematical formula}Δ′, so none is innocuous. Equivalently, any {a mathematical formula}β∈Δ is inconsistent with {a mathematical formula}Δ′. An example of innocuous conditional can be given in the knowledge base {a mathematical formula}Ψ=Δ∪{(x2)[0.3,0.8]}, since {a mathematical formula}(x2)[0.3,0.8] would be consistent with any consolidation of Ψ.
      </paragraph>
      <paragraph>
       An innocuous probabilistic conditional of Γ is consistent with any abrupt consolidation of Γ, since it is semantically equivalent to a consolidation with {a mathematical formula}[0,1] probability intervals; furthermore, a safe conditional of Γ is clearly consistent with any consolidation of Γ:
      </paragraph>
      <paragraph label="Proposition 4.8">
       Consider a probabilistic conditional{a mathematical formula}α∈Γ. If α is safe, it is innocuous; if α is innocuous, it is free.
      </paragraph>
      <paragraph>
       As to the independence postulate, we modify it in a corresponding way:
      </paragraph>
      <paragraph label="Postulate 4.9">
       i-IndependenceIf α is an innocuous probabilistic conditional of Γ, then{a mathematical formula}I(Γ)=I(Γ∖{α}).
      </paragraph>
      <paragraph>
       From Proposition 4.8 follows the relation among weak independence, i-independence and independence:
      </paragraph>
      <paragraph label="Corollary 4.10">
       If{a mathematical formula}Isatisfies independence, then{a mathematical formula}Isatisfies i-independence. If{a mathematical formula}Isatisfies i-independence, then{a mathematical formula}Isatisfies weak independence.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Refining the minimal conflict concept
      </section-title>
      <paragraph>
       To redefine MIS-separability, we need a new notion of minimal conflict, related to the consolidation we introduced. Note that the union of minimal inconsistent sets is equal to the union of minimal abrupt repairs of a knowledge base, so that it forms the complement of the set of free probabilistic conditionals. To be consistent, we should provide a definition of conflicting sets such that their union is complementary to the set of innocuous conditionals. A set with all probabilistic conditionals that are not innocuous would be inconsistent when not empty, but would not have the minimality we are looking for. Such a set would be analogous to the union of all minimal inconsistent sets, but we search for a more fundamental notion of conflict, that can be derived by analyzing the consolidation properties of minimal inconsistent sets.
      </paragraph>
      <paragraph>
       A minimal inconsistent set is minimal regarding set inclusion, and this is related to the abrupt consolidation:
      </paragraph>
      <paragraph label="Proposition 4.11">
       A knowledge base Γ is a minimal inconsistent set iff Γ is inconsistent and there are no{a mathematical formula}Δ1,…,Δk⊊Γ, with{a mathematical formula}k≥1, such that:
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}⋃i=1kΔi=Γ;
       </list-item>
       <list-item label="2.">
        For every{a mathematical formula}Γ′⊆Γ, if{a mathematical formula}Γ′∩Δiis an abrupt consolidation of{a mathematical formula}Δifor all{a mathematical formula}1≤i≤k, then{a mathematical formula}Γ′is an abrupt consolidation of Γ.
       </list-item>
      </list>
      <paragraph>
       Intuitively, a minimal inconsistent set Γ is a conflict that cannot be analyzed in smaller subsets such that abruptly consolidating them implies abruptly consolidating Γ. Starting with a single inconsistent base Γ, we can find smaller subsets {a mathematical formula}Δi satisfying both items of 4.11. We can do this recursively on the inconsistent sets {a mathematical formula}Δi until we reach unanalyzable conflicts, which happens to be minimal inconsistent sets. So, abruptly consolidating these sets is abruptly consolidating Γ. Substituting consolidation for abrupt consolidation, we have an analogous definition of conflict:
      </paragraph>
      <paragraph label="Definition 4.12">
       A knowledge base Γ is an inescapable conflict if Γ is inconsistent and there are no {a mathematical formula}Δ1,…,Δk⊊Γ, with {a mathematical formula}k≥1, such that:
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}⋃i=1kΔi=Γ;
       </list-item>
       <list-item label="2.">
        If {a mathematical formula}Δi′ is a consolidation of {a mathematical formula}Δi for all {a mathematical formula}1≤i≤k and {a mathematical formula}⋃i=1kΔi′ is a widening of Γ, then {a mathematical formula}⋃i=1kΔi′ is a consolidation of Γ.
       </list-item>
      </list>
      <paragraph>
       The extra condition in the second item of Definition 4.12 forces consolidations of different knowledge bases {a mathematical formula}Δi,Δj⊊Γ with some probabilistic conditional in common to agree in that probability interval; otherwise, {a mathematical formula}⋃i=1kΔi′ would not be a knowledge base. In other words, the second item says that if we widen the probability intervals of Γ making each {a mathematical formula}Δi consistent, then Γ becomes consistent. Inescapable conflicts could equivalently be defined in an alternative way:
      </paragraph>
      <paragraph label="Lemma 4.13">
       A knowledge base Γ is an inescapable conflict iff there is a widening{a mathematical formula}Γ′of Γ such that{a mathematical formula}Γ′is a minimal inconsistent set.
      </paragraph>
      <paragraph>
       Lemma 4.13 captures the intuition behind the proof of Theorem 3.8, where there is a widening that consolidates any proper subset of the knowledge base without consolidating the whole base. As it happens with abrupt consolidation and MISes, to consolidate Γ, one only needs to widen its probability intervals in such a way that each inescapable conflict is solved.
      </paragraph>
      <paragraph label="Corollary 4.14">
       Consider two knowledge bases{a mathematical formula}Γ,Γ′∈Ksuch that{a mathematical formula}Γ′is a widening of Γ. If for every inescapable conflict{a mathematical formula}Δ⊆Γits widening{a mathematical formula}{β∈Γ′|α∈Δandα⊆β}is consistent, then{a mathematical formula}Γ′is a consolidation of Γ.
      </paragraph>
      <paragraph>
       As all abrupt consolidations can be viewed as consolidations and each knowledge base is a widening of itself, an inescapable conflict is something weaker than a minimal inconsistent set:
      </paragraph>
      <paragraph label="Corollary 4.15">
       If Δ is a minimal inconsistent set, then Δ is an inescapable conflict.
      </paragraph>
      <paragraph label="Example 4.16">
       Consider again the knowledge base from Example 4.7:{a mathematical formula} As it was already shown, {a mathematical formula}{(x1∧x2)[0.6],(x1∧¬x2)[0.5]} is the only minimal inconsistent set of Δ — and, by Corollary 4.15, it is an inescapable conflict. Nevertheless, it can be proved that the whole Δ is an inescapable conflict as well.Suppose, by contradiction, there are {a mathematical formula}Δ1,…,Δk⊊Δ such that {a mathematical formula}⋃i=1kΔi=Δ and, if {a mathematical formula}Δi′ is a consolidation of {a mathematical formula}Δi for all {a mathematical formula}1≤i≤k and {a mathematical formula}⋃i=1kΔi′ is a widening of Δ, then {a mathematical formula}⋃i=1kΔi′ is a consolidation of Δ. To build {a mathematical formula}⋃i=1kΔi′, we pick a consolidation {a mathematical formula}Δi′ for each {a mathematical formula}Δi⊊Δ. There are two cases: (a) {a mathematical formula}(x1∧x2)[0.6]∈Δi; and (b) {a mathematical formula}(x1∧x2)[0.6]∉Δi. In case (a), we construct {a mathematical formula}Δi′ by widening the probability interval of the conditional {a mathematical formula}(x1∧x2)[0.6] to {a mathematical formula}(x1∧x2)[0.5,0.6]; formally, {a mathematical formula}Δi′=(Δi∖{(x1∧x2)[0.6]})∪{(x1∧x2)[0.5,0.6]}. In case (b), we choose the trivial consolidation {a mathematical formula}Δi′=Δi. Even though the proof is omitted, we claim that each {a mathematical formula}Δi′ is consistent. Consider then the following knowledge base:{a mathematical formula} By the premises, {a mathematical formula}Δ′ is a consolidation of Δ, but it is inconsistent, since {a mathematical formula}Δ′∖{(x1)[0.8]} implies {a mathematical formula}(x1)[1] (as shown in Section 3.2). Finally, there cannot exist such {a mathematical formula}Δ1,…,Δk⊊Δ, and Δ is an inescapable conflict.
      </paragraph>
      <paragraph>
       We can now change MIS-separability to respect inescapable conflicts (IC) instead of minimal inconsistent sets. Let {a mathematical formula}IC(Γ) denote the collection of all inescapable conflicts of Γ.
      </paragraph>
      <paragraph label="Property 4.17">
       IC-separabilityIf{a mathematical formula}Γ=Δ∪Ψ,{a mathematical formula}Δ∩Ψ=∅and{a mathematical formula}IC(Γ)=IC(Δ)∪IC(Ψ), then{a mathematical formula}I(Γ)=I(Δ)+I(Ψ).
      </paragraph>
      <paragraph>
       As inescapable conflict is a weaker concept than MIS, MIS-separability is stronger than IC-separability.
      </paragraph>
      <paragraph label="Corollary 4.18">
       If{a mathematical formula}Isatisfies MIS-separability, then{a mathematical formula}Isatisfies IC-separability.
      </paragraph>
      <paragraph>
       Recall that a free probabilistic conditional is defined in the standard way as not belonging to any minimal inconsistent set. We prove the analogous result for innocuous conditionals and inescapable conflicts, linking all concepts introduced in this section.
      </paragraph>
      <paragraph label="Theorem 4.19">
       The following statements are equivalent:
      </paragraph>
      <list>
       <list-item label="1.">
        For all d-consolidation{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
       </list-item>
       <list-item label="2.">
        If{a mathematical formula}Γ′is a consolidation of Γ, then α is consistent with{a mathematical formula}Γ′.
       </list-item>
       <list-item label="3.">
        There is no inescapable conflict Δ in Γ such that{a mathematical formula}α∈Δ.
       </list-item>
       <list-item label="4.">
        α is an innocuous probabilistic conditional in Γ.
       </list-item>
      </list>
      <paragraph>
       A result analogous to Proposition 3.6 follows:
      </paragraph>
      <paragraph label="Corollary 4.20">
       If{a mathematical formula}Isatisfies IC-separability, then{a mathematical formula}Isatisfies i-independence.
      </paragraph>
      <paragraph>
       As already mentioned, inescapable conflicts are to consolidations as minimal inconsistent sets are to abrupt consolidations. If consolidation via conditionals withdrawal, as in Reiter's and AGM approaches, can focus on the collection of minimal inconsistent sets (ignoring free conditionals), consolidation through widening probability intervals can be done by watching only for the inescapable conflicts (ignoring innocuous conditionals). All these relations among free and innocuous probabilistic conditionals, minimal inconsistent sets and inescapable conflicts argue in favor of the new proposed postulates, whose compatibility with consistency and continuity we will prove.
      </paragraph>
     </section>
     <section label="4.3">
      <section-title>
       Compatible postulates for imprecise probabilities
      </section-title>
      <paragraph>
       To replace the postulate of independence and the property of MIS-separability, we propose the weaker pair of i-independence and IC-separability towards building a compatible package together with consistency and continuity. Before proving such compatibility, the postulates have to be generalized to imprecise knowledge bases. To generalize consistency, i-independence and IC-separability is straightforward, we just enlarge their intended scope from knowledge bases in {a mathematical formula}Kprec to bases in {a mathematical formula}K, but the continuity postulate demands some notation.
      </paragraph>
      <paragraph>
       Let {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m} be a knowledge base. The characteristic function of Γ can be generalized as a function {a mathematical formula}ΛΓ:[0,1]2m→K that changes both upper and lower bounds of each probabilistic conditional in Γ; formally, {a mathematical formula}ΛΓ(〈q_1′,q¯1′,…,q_m′,q¯m′〉)={(φi|ψi)[q_i′,q¯i′]|1≤i≤m}. Now the continuity postulate can be generalized, with ∘ denoting function composition:
      </paragraph>
      <paragraph label="Postulate 4.21">
       ContinuityFor all{a mathematical formula}Γ∈K, the function{a mathematical formula}I∘ΛΓ:[0,1]2|Γ|→[0,∞)is continuous.
      </paragraph>
      <paragraph>
       Note that the postulate above implies Postulate 3.7, which defines continuity for precise probabilities. Given a base Γ of size m, Postulate 3.7 considers a function {a mathematical formula}f:[0,1]m→Kprec (the characteristic function when probabilities are precise) such that {a mathematical formula}f(〈q1′,q2′,…,qm′〉)=ΛΓ(〈q1′,q1′,q2′,q2′,…,qm′,qm′〉) and requires that {a mathematical formula}I∘f be continuous. But note that, if {a mathematical formula}I∘ΛΓ is continuous, so is {a mathematical formula}I∘f. Therefore, Theorem 3.8 and Corollary 3.9 also hold within the imprecise probability framework.
      </paragraph>
      <paragraph>
       Hunter and Konieczny proposed another basic postulate for inconsistency measures [20] that was also adopted by Thimm [44].
      </paragraph>
      <paragraph label="Postulate 4.22">
       MonotonicityFor any knowledge bases{a mathematical formula}Γ,(Γ∪{α})∈K,{a mathematical formula}I(Γ∪{α})≥I(Γ).
      </paragraph>
      <paragraph>
       Thimm actually suggests a stronger principle, super-additivity, which implies monotonicity. Since super-additivity is incompatible with normalization [44] — as also is IC-separability —, we state them as properties, and not postulates.
      </paragraph>
      <paragraph label="Property 4.23">
       Super-additivityFor any knowledge base{a mathematical formula}Γ∪Δ∈K, if{a mathematical formula}Γ∩Δ=∅, then{a mathematical formula}I(Γ∪Δ)≥I(Γ)+I(Δ).
      </paragraph>
      <paragraph label="Property 4.24">
       NormalizationFor any knowledge base{a mathematical formula}Γ∈K,{a mathematical formula}I(Γ)∈[0,1].
      </paragraph>
      <paragraph label="Definition 4.25">
       To attend the desirable properties, we generalize the inconsistency measures based on distance minimization proposed by Thimm [44] to the case of imprecise probabilities. Muiño introduced similar ideas under a different semantics for conditional probabilities [31]. Firstly, we define a family of p-norms. Consider a (positive) {a mathematical formula}m∈N&gt;0 and a {a mathematical formula}p∈N&gt;0∪{∞}. Given a vector {a mathematical formula}q=〈q1,q2,…,qm〉 over the real numbers, the p-norm of q is {a mathematical formula}‖q‖p=∑i=1m|qi|pp if p is finite; otherwise it is {a mathematical formula}‖q‖∞=maxi⁡|qi|.
      </paragraph>
      <paragraph>
       Thimm defines a family {a mathematical formula}Ip of inconsistency measures based on the p-norms, which we modify to also consider {a mathematical formula}p=∞ and handle the empty base.
      </paragraph>
      <paragraph label="Definition 4.26">
       Consider a {a mathematical formula}p∈N&gt;0∪{∞} and a {a mathematical formula}Γ∈K. The function {a mathematical formula}Ip:K→[0,∞) is the {a mathematical formula}dp-inconsistency measure, defined as{a mathematical formula} for any non-empty Γ, and {a mathematical formula}Ip(∅)=0.
      </paragraph>
      <paragraph>
       Finally, we are in a position to show inconsistency measures satisfying the wanted properties. We extend Thimm's results to prove that all {a mathematical formula}dp-inconsistency measures satisfy the reconciled postulates and that some of them hold additional properties. Muiño has similar results, though under a different semantics [31].
      </paragraph>
      <paragraph label="Theorem 4.27">
       For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipis well-defined and satisfies the postulates of consistency, continuity, i-independence and monotonicity.
      </paragraph>
      <paragraph>
       The compatibility of IC-separability and super-additivity with consistency, continuity, monotonicity and i-independence is confirmed by the {a mathematical formula}I1 measure:
      </paragraph>
      <paragraph label="Lemma 4.28">
       {a mathematical formula}Ipsatisfies super-additivity and IC-separability iff{a mathematical formula}p=1.
      </paragraph>
      <paragraph label="Lemma 4.29">
       If normalization is required, we can use the following result due to Muiño [31]: {a mathematical formula}Ipsatisfies normalization iff{a mathematical formula}p=∞.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Feasible principled inconsistency measures
     </section-title>
     <paragraph>
      Although we have compatible postulates to drive the rational choice of inconsistency measures, these desirable properties are satisfied by a myriad of functions. We may use other arguments to pick some particular inconsistency measures among those obeying the postulates. This section investigates computational aspects of measuring inconsistency through distance minimization, reviewing and generalizing measures proposed by Potyka [34] that can be handled via linear programming. In a second moment, we show how the concrete measures introduced can be justified by means of Dutch books, displaying the maximum guaranteed loss an agent would be exposed to, if stakes are limited. We also show that Dutch books offer other interesting measures.
     </paragraph>
     <section label="5.1">
      <section-title>
       Measuring inconsistency with linear programs
      </section-title>
      <paragraph>
       In order to better understand the connection between Potyka's inconsistency measures and incoherence measures based on Dutch books, it is worth detailing the construction of the corresponding linear programs. Furthermore, due to such link, every property we prove for Potyka's inconsistency measures shall be inherited by the equivalent Dutch book measures presented in the next section.
      </paragraph>
      <paragraph>
       To check the consistency of a knowledge base, one can use the well-known formulation of PSAT as a linear program [16]. Consider a knowledge base {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}. Under the semantics adopted, each assessment {a mathematical formula}(φi|ψi)[q_i,q¯i] is equivalent to the pair {a mathematical formula}Pπ(φi∧ψi)−q_iPπ(ψi)≥0 and {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤0 of restrictions on {a mathematical formula}Pπ. The knowledge base is consistent iff these 2m restrictions can be jointly satisfied by a probability measure {a mathematical formula}Pπ induced by a probability mass π. Consider two ({a mathematical formula}m×2n)-matrices, {a mathematical formula}A=[aij] and {a mathematical formula}B=[bij], with {a mathematical formula}aij=Iwj(φi∧ψi)−q_iIwj(ψi) and {a mathematical formula}bij=Iwj(φi∧ψi)−q¯iIwj(ψi), in which {a mathematical formula}Iwj:LXn→{0,1} is the indicator function of the set {a mathematical formula}{φ∈LXn|wj⊨φ} — {a mathematical formula}Iwj is the valuation relative to the possible world {a mathematical formula}wj. The knowledge base Γ is satisfiable iff there is a {a mathematical formula}(2n×1)-vector π satisfying the system:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph>
       Restrictions in (5) correspond to {a mathematical formula}Pπ(φi|ψi)≥q_i, and those in (6) codify {a mathematical formula}Pπ(φi|ψi)≤q¯i; Constraints (7) and (8) force π to be a probability mass over the possible worlds {a mathematical formula}w1,w2,…,w2n. As all constraints are linear, this system can be solved by linear programming techniques as Simplex. Despite the exponential number of columns, column generation methods can be used to handle them implicitly [26], [24], keeping the computation efficient enough to solve large knowledge bases (thousands of probabilities in [17], [10]).
      </paragraph>
      <paragraph>
       To measure inconsistency using distance minimization with {a mathematical formula}Ip, we can add to the system variables {a mathematical formula}ε_i≥0 ({a mathematical formula}ε¯i≥0) corresponding to decrements (increments) in lower (upper) bounds of each probability interval. Any conditional {a mathematical formula}(φi|ψi)[q_i,q¯i] yields a pair of restrictions {a mathematical formula}Pπ(φi∧ψi)−q_iPπ(ψi)≥−ε_iPπ(ψi) and {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤ε¯iPπ(ψi). Computing the {a mathematical formula}Ip measure is thus reduced to minimizing the p-norm of the vector {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉.{sup:7} Nonetheless, the constraints contain non-linear terms (from {a mathematical formula}ε_iPπ(ψi) and {a mathematical formula}ε¯iPπ(ψi)), and Potyka points out that these programs have (non-global) local optima [34], so convex optimization techniques cannot be directly applied. Thus, computing {a mathematical formula}Ip is typically less efficient than deciding PSAT, as empirical results indicate [34].
      </paragraph>
      <paragraph>
       Potyka emphasizes this impracticability and suggests a new family of inconsistency measures, the minimal violation measures[34], which we adapt here to the case of imprecise probabilities. In order to keep constraints linear, “violation” variables {a mathematical formula}ε_i,ε¯i≥0 are inserted in the right-hand side of {a mathematical formula}Pπ(φi∧ψi)−q_iPπ(ψi)≥0 and {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤0, yielding {a mathematical formula}Pπ(φi∧ψi)−q_iPπ(ψi)≥−ε_i and {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤εi¯. Potyka's minimal violation measures are obtained when the p-norm of {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉 is minimized with such constraints. We denote by {a mathematical formula}Ipε the optimal value from the following program, where {a mathematical formula}ε_=[ε_i] and {a mathematical formula}ε¯=[ε¯i] are ({a mathematical formula}m×1)-vectors:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph>
       The restrictions are all linear, and non-linear terms may appear only within the objective function. We can ignore the monotone function {a mathematical formula}.p within the p-norm definition, applying it only after the minimization stops. The degree of each term in the new objective function is p, and for {a mathematical formula}p=1 a linear program is recovered, since {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m,ε¯m〉‖1=∑i=1mε_i+ε¯i. Hence, one can apply the standard Simplex and column generation methods to compute {a mathematical formula}I1ε with practically the same efficiency as deciding PSAT [34].
      </paragraph>
      <paragraph>
       For any finite p different from 1, the system (9), (10), (11), (12), (13) has non-linear terms in its objective function, but this is not the case when we consider {a mathematical formula}p=∞. The ∞-norm is equivalent to take the maximum of the vector {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉, but this is the same as considering all {a mathematical formula}ε_i,ε¯i equal to a single scalar {a mathematical formula}ε≥0. The measure {a mathematical formula}I∞ε is the solution of the following program [34], in which {a mathematical formula}ε_=ε¯=[εε…ε]T are ({a mathematical formula}m×1)-vectors:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph>
       The system (14), (15), (16), (17), (18) is also a linear program, like (9), (10), (11), (12), (13) when {a mathematical formula}p=1, but has a lesser number of variables. However, Potyka remarks that the variable ε in (14), (15), (16), (17), (18) is involved in 2m restrictions, while each variable {a mathematical formula}ε_i,ε¯i appears in only one constraint in (9), (10), (11), (12), (13); therefore, the computation of {a mathematical formula}I∞ε may in practice be slightly less efficient than computing {a mathematical formula}I1ε[34].
      </paragraph>
      <paragraph>
       For sets of unconditional probabilistic assessments, when all conditioning events {a mathematical formula}ψi are equivalent to ⊤, the inconsistency measures {a mathematical formula}Ip and {a mathematical formula}Ipε are extensionally identical for all p. The reason is that the restriction on {a mathematical formula}Pπ and {a mathematical formula}ε_i,ε¯i corresponding to a conditional is the same when computing both measures. For instance, any constraint {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤0 becomes equivalent to {a mathematical formula}Pπ(φi)−q¯i≤0 when {a mathematical formula}ψi is a tautology, and inserting an error to the probability bound, {a mathematical formula}Pπ(φi)−(q¯i+ε¯i)≤0, is the same as placing it in the right-hand side.
      </paragraph>
      <paragraph label="Proposition 5.1">
       Potyka has proved that these measures, {a mathematical formula}Ipε with {a mathematical formula}p∈N&gt;0∪{∞}, besides being computable via linear programming, satisfy the postulates of consistency, continuity and monotonicity for the case of precise probabilities [34]: For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipε:Kprec→[0,∞)is well-defined and satisfies consistency, continuity, weak independence and monotonicity.{a mathematical formula}I1εalso satisfies super-additivity.
      </paragraph>
      <paragraph>
       We can generalize the result above to encompass probability intervals and the new postulates we introduced:
      </paragraph>
      <paragraph label="Theorem 5.2">
       For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipε:K→[0,∞)is well-defined and satisfies consistency, continuity, i-independence and monotonicity.{a mathematical formula}I1εalso satisfies super-additivity and IC-separability; and{a mathematical formula}I∞εsatisfies normalization.
      </paragraph>
      <paragraph>
       Now we have a set of compatible postulates for inconsistency measures and two particular measures satisfying them that can be computed rather efficiently using linear programming techniques. On the one hand, {a mathematical formula}I1ε also satisfies super-additivity and IC-separability; on the other hand, {a mathematical formula}I∞ε additionally satisfies normalization. Nonetheless, one can argue that these measures lack some proper justification, despite satisfying some postulates and being feasible, as Capotorti, Regoli and Vattari did [4]. They claim that distances between conditional probabilities are meaningless, being only geometrical measures. This might be the case, but it would only undermine the {a mathematical formula}Ip family. For {a mathematical formula}Ipε measures, distances between probabilities are computed weighting by the probabilities of the conditioning formulas, so to speak, allowing some operational interpretation. In the next section, we provide a rationale for {a mathematical formula}I1ε and {a mathematical formula}I∞ε based on Dutch books.
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       Inconsistency measures and Dutch books
      </section-title>
      <paragraph>
       In formal epistemology, there is an interest in measuring the incoherence of an agent whose beliefs are given as probabilities or lower previsions over propositions or random variables — a Bayesian agent. If we have propositions from classical logic, the formalized problem at hand is exactly the one we are investigating. When the agent's degrees of belief are represented by a knowledge base, to measure the agent's incoherence is to measure the inconsistency of such knowledge base. Schervish, Kadane and Seidenfeld [39], [40], [38] have proposed ways to measure incoherence of an agent based on Dutch books.
      </paragraph>
      <paragraph>
       Dutch book arguments are based on the agent's betting behavior induced by her degrees of belief, typically used to show their irrationality. To introduce the concept of Dutch book, we start with the unconditional case. Dutch book arguments rely on an operational interpretation of (imprecise) degrees of belief, in which their lower/upper bounds are defined through bet buying/selling prices. Suppose an agent believes that the probability of proposition {a mathematical formula}φi being true lies within {a mathematical formula}[q_i,q¯i], for {a mathematical formula}1≤i≤m. Consider a bet ticket on the proposition {a mathematical formula}φi that returns a prize (from the ticket seller) of {a mathematical formula}λi≥0 if {a mathematical formula}φi is the case, and is worthless if {a mathematical formula}φi is not the case. Dutch book arguments generally use a willingness-to-bet assumption that this agent is willing to buy such a bet ticket on {a mathematical formula}φi for {a mathematical formula}q_iλi≥0 and to sell it for {a mathematical formula}q¯iλi≥0, for any {a mathematical formula}λi≥0. Then, if a bettor can buy and/or sell a set of bet tickets from/to the agent that will cause her a sure loss no matter which possible world is the case, we say she is exposed to a Dutch book. This set of bet tickets that causes a guaranteed loss to the agent is called a Dutch book.
      </paragraph>
      <paragraph label="Example 5.3">
       Alice (the agent) and Bob (the bettor) are flying to the beach. To spend the time on the plane, they discuss and gamble on the destination weather, to be checked on arrival — will it be sunny and/or hot (say, at least {a mathematical formula}20∘C)? Alice assigns probability intervals for three propositions, formed by the atoms {a mathematical formula}x1=“the weather is sunny” and {a mathematical formula}x2=“the weather is hot”:
      </paragraph>
      <list>
       Note that, no matter how is the weather when they arrive and pay the prizes, the total quantity Alice can receive from Bob is at most $10. Since she was losing $11 before landing and checking the weather, she will lose at least $1 in the end. Given this sure loss scenario, this set of three bets is said to be a Dutch book.
      </list>
      <paragraph>
       Instead of the agent (the bettor) paying for a bet ticket and eventually getting its prize back from the bettor (the agent), we can view this whole operation as a single contract between these two players.
      </paragraph>
      <paragraph label="Definition 5.4">
       A gamble on {a mathematical formula}φ∈LXn is an agreement between the agent and the bettor with two parameters, the stake{a mathematical formula}λ∈R and the relative price{a mathematical formula}q∈[0,1], stating that:
      </paragraph>
      <list>
       <list-item label="•">
        the agent pays {a mathematical formula}λ×q to the bettor if φ is false;
       </list-item>
       <list-item label="•">
        the bettor pays {a mathematical formula}λ×(1−q) to the agent if φ is true.
       </list-item>
      </list>
      <paragraph>
       A gamble on φ with stake {a mathematical formula}λ≥0 and relative price q is equivalent to the agent buying from the bettor a bet ticket for {a mathematical formula}λ×q that returns λ only if φ is the case; if the stake λ is negative, the gamble is equivalent to the bettor buying the same ticket from the agent. The willingness-to-bet assumption translates to gambles in the following way: if an agent believes that the probability of a proposition φ being true lies within {a mathematical formula}[q_,q¯], she finds acceptable gambles on φ with any stake {a mathematical formula}λ≥0 and relative price {a mathematical formula}q_ and gambles with any stake {a mathematical formula}λ≤0 and relative price {a mathematical formula}q¯. In Example 5.3, the tickets trading is equivalent to a set of three gambles: a gamble on {a mathematical formula}x1 with stake $10 and relative price 0.7; a gamble on {a mathematical formula}x2 with stake $10 and relative price 0.5; and a gamble on {a mathematical formula}x1∧x2 with stake {a mathematical formula}$−10 and relative price 0.1.
      </paragraph>
      <paragraph>
       A gamble on φ can be generalized to consider a conditioning event ψ. Consider a bet ticket that, when ψ is true, pays a prize of λ if φ is the case and returns 0 if φ is false. In other words, this bet ticket works as a gamble on φ when ψ is the case. However, suppose this bet ticket pays back to the agent the same amount that was spent in its buying if ψ is false — that is, the gamble is canceled. The following generalization of gambles capture these “conditional bets”:
      </paragraph>
      <paragraph label="Definition 5.5">
       A (conditional) gamble on {a mathematical formula}φ|ψ∈LXn|LXn is an agreement between the agent and the bettor with two parameters, the stake{a mathematical formula}λ∈R and the relative price{a mathematical formula}q∈[0,1], stating that:
      </paragraph>
      <list>
       <list-item label="•">
        the agent pays {a mathematical formula}λ×q to the bettor if ψ is true and φ is false;
       </list-item>
       <list-item label="•">
        the bettor pays {a mathematical formula}λ×(1−q) to the agent if ψ is true and φ is true;
       </list-item>
       <list-item label="•">
        the gamble is called off, causing neither profit nor loss to the involved parts, if ψ is false.
       </list-item>
      </list>
      <paragraph>
       Accordingly, we generalize the willingness-to-bet assumption: if an agent believes that the probability of a proposition φ being true given that another proposition ψ is true lies within {a mathematical formula}[q_,q¯], she finds acceptable gambles on {a mathematical formula}φ|ψ with stake {a mathematical formula}λ≥0 and relative price {a mathematical formula}q_ and gambles with stake {a mathematical formula}λ≤0 and relative price {a mathematical formula}q¯. A Dutch book is a set of (conditional) gambles that the agent sees as fair, under the willingness-to-bet assumption, that causes her a guaranteed loss no matter which possible world is the case. We assume Dutch books contain exactly two gambles on {a mathematical formula}(φi|ψi) per each conditional {a mathematical formula}(φi|ψi)[q_i,q¯i]∈Γ, the base formalizing the agent's beliefs: one with stake {a mathematical formula}λ_i≥0 and the other with stake {a mathematical formula}−λ¯i≤0. This is not restrictive, since gambles on the same {a mathematical formula}(φi|ψi) with the same relative price can be merged by summing the stakes, and the absence of a gamble is equivalent to a stake equal to zero. We can thus denote a Dutch book simply by the absolute value of its stakes {a mathematical formula}λ_1,λ¯1,…,λ_m,λ¯m≥0, where {a mathematical formula}m=|Γ|. Actually, any set of gambles involving an agent whose epistemic state is represented by Γ can be represented by these 2m (absolute value of) stakes, since the relative prices are set in Γ.
      </paragraph>
      <paragraph>
       If the set of probabilistic conditionals that represents an agent's epistemic state turns out to be inconsistent, then she is exposed to a Dutch book, and vice-versa [32]. In other words, an agent sees as fair a set of gambles that causes her a guaranteed loss if, and only if, the knowledge base codifying her (conditional) degrees of belief is inconsistent. We can check this connection in Example 5.3: {a mathematical formula}(x1)[0.7,0.8] and {a mathematical formula}(x2)[0.5,0.6] imply a probability of at least 0.2 for {a mathematical formula}x1∧x2, which Alice violates. Consequently, she is exposed to a Dutch book, for her three probability interval assignments are not jointly satisfiable. In this way, Dutch book arguments were introduced to show that degrees of belief must obey the axioms of probability and are a standard proof of incoherence (introductions to Dutch books and their relation to incoherence can be found in [42] and [8]). Hence, a natural approach to measuring an agent's degree of incoherence is through the magnitude of the sure loss she is vulnerable to. The intuition says that, the more incoherent an agent is, the greater the guaranteed loss that can be imposed on her through a Dutch book. Nevertheless, with no bounds on the stakes, such loss would also be unlimited for incoherent agents. For instance, in Example 5.3, if stakes were $100, $100 and {a mathematical formula}$−100, Alice would have a net loss of at least $10, instead of $1, regardless of the weather on arrival. To better understand the loss a Dutch book causes to an agent, we formalize it in the following.
      </paragraph>
      <paragraph>
       Consider the knowledge base {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m} representing an agent's epistemic state. Let {a mathematical formula}λ_i,λ¯i≥0 denote gambles on {a mathematical formula}(φi|ψi), the first with relative price {a mathematical formula}q_i and stake {a mathematical formula}λ_i≥0, the second with relative price {a mathematical formula}q¯i and stake {a mathematical formula}−λ¯i≤0, for {a mathematical formula}1≤i≤m. A set of gambles can then be represented by the vector {a mathematical formula}〈λ_1,λ¯1,…,λ_m,λ¯m〉. If a possible world {a mathematical formula}wj is the case, the net profit for the agent regarding a bet on {a mathematical formula}φ|ψ with stake λ and relative price q can be computed via{a mathematical formula} in which {a mathematical formula}Iwj:LXn→{0,1} is the indicator function of the set {a mathematical formula}{φ∈LXn|wj⊨φ} — a valuation. For a gamble on {a mathematical formula}(φi|ψi) with stake {a mathematical formula}λ_i (or {a mathematical formula}−λ¯i), the agent's net profit in a possible word {a mathematical formula}wj is {a mathematical formula}λ_i(Iwj(φi∧ψi)−q_iIwj(ψi)) (or {a mathematical formula}−λ¯i(Iwj(φi∧ψi)−q¯iIwj(ψi))). Recall (from (5), (6), (7), (8)) that {a mathematical formula}aij=Iwj(φi∧ψi)−q_iIwj(ψi) and {a mathematical formula}bij=Iwj(φi∧ψi)−q¯iIwj(ψi). If a given possible world {a mathematical formula}wj is the case, the set of gambles {a mathematical formula}〈λ_1,λ¯1,…,λ_m,λ¯m〉 gives the agent a profit of {a mathematical formula}∑i=1maijλ_i+∑i=1m−bijλ¯i. Let ℓ be the sure loss (−ℓ is profit) a set of gambles yields to the agent; i.e., no matter which possible world is the case, the agent loses at least ℓ. Thus, ℓ is such that {a mathematical formula}∑i=1maijλ_i+∑i=1m−bijλ¯i≤−ℓ for all possible worlds {a mathematical formula}wj. When there is no restriction on the stakes, to find the set of gambles {a mathematical formula}〈λ_1,λ¯1,…,λ_m,λ¯m〉 that maximizes the sure loss is to solve the following linear program:{a mathematical formula}{a mathematical formula}{a mathematical formula}
      </paragraph>
      <paragraph>
       The linear program above can be viewed as the dual of that in lines (5), (6), (7), (8), which checks the consistency of Γ, if we consider that 0 is the function being minimized in the latter, since we are interested only in its feasibility (for duality theory in linear programing, see, for instance, [46]). Note that, in (5), (6), (7), (8), {a mathematical formula}Bπ≤0 is equivalent to {a mathematical formula}−Bπ≥0 and {a mathematical formula}∑π=1 can be inserted into A as a line of 1's. By duality theory, as the program above is feasible, it is unbounded iff (5), (6), (7), (8) is infeasible. That is, if Γ is inconsistent, sure loss via Dutch book is unlimited.
      </paragraph>
      <paragraph>
       Different strategies to circumvent this in order to measure incoherence as a finite loss are found in the formal epistemology literature. Schervish et al. propose a flexible formal approach to limiting these stakes generating a family of incoherence measures for upper and lower previsions on bounded random variables [40]. In this section, we are interested in two of them, which we simplify to our case.
      </paragraph>
      <paragraph>
       Their whole family of incoherence measures is based on the maximum guaranteed loss an agent is exposed to via a Dutch book, varying only on how stakes are limited. The first incoherence measure Schervish et al. introduce that concerns us is when the sum of the absolute values of the stakes is lesser than or equal to one, {a mathematical formula}∑iλ_i+λ¯i≤1. The second incoherence measure we investigate is defined as the maximum guaranteed loss when each stake have absolute value no greater than one, or {a mathematical formula}λ_i,λ¯i≤1.{sup:8} We define the inconsistency measures {a mathematical formula}ISSKsum:K→[0,∞) and {a mathematical formula}ISSKmax:K→[0,∞) on knowledge bases as these two incoherence measures on the corresponding agents represented by these knowledge bases. That is, we equate {a mathematical formula}ISSKsum(Γ) (and {a mathematical formula}ISSKmax(Γ)), for any {a mathematical formula}Γ∈K, to the maximum sure loss an agent whose epistemic state is represented by Γ is exposed to through a Dutch book when the sum (maximum) of the stakes' absolute values is at most one.
      </paragraph>
      <paragraph label="Example 5.6">
       Recall Example 5.3, in which there are three gambles, with stakes $10, $10 and {a mathematical formula}$−10. These gambles guarantee a loss of at least $1 to Alice. But now suppose that Bob, while choosing the gambles, must do it so that the absolute values of the stakes sum up to one. He could so arrange the same gambles but changing the stakes to 1/3, 1/3 and {a mathematical formula}−1/3. In this new scenario, Alice would have a sure loss of 1/30. Similarly, if the absolute value of each stake is limited to the interval {a mathematical formula}[0,1], stakes could be 1, 1 and −1, yielding a guaranteed loss of 1/10 to Alice. In fact, it can be checked (by solving the linear programs) that 1/30 and 1/10 are the greatest amount one can take for sure from Alice via Dutch book if stakes have absolute values summing up to one or are all in {a mathematical formula}[0,1], respectively. Formalizing, with {a mathematical formula}Γ={(x1)[0.7,0.8],(x2)[0.5,0.6],(x1∧x2)[0,0.1]} codifying Alice's epistemic state, we have {a mathematical formula}ISSKsum(Γ)=1/30 and {a mathematical formula}ISSKmax(Γ)=1/10.
      </paragraph>
      <paragraph>
       Even though incoherence measures based on Dutch books from the formal epistemology community and inconsistency measures based on distance minimization from Artificial Intelligence researchers may seem unrelated at first, they are actually two sides of the same coin. The programs that compute the maximum guaranteed loss an agent is exposed to are technically dual to those that minimize distances to measure inconsistency. Nau has already investigated this matter, mentioning results similar to the following [32]:
      </paragraph>
      <paragraph label="Proof">
       For any{a mathematical formula}Γ∈K,{a mathematical formula}ISSKsum(Γ)=I∞ε(Γ).Just add the constraint {a mathematical formula}λ_1+λ¯1+⋯+λ_m+λ¯m≤1 to the linear program (19), (20), (21). The dual of this new program would become the program (14), (15), (16), (17), (18), which computes {a mathematical formula}I∞ε(Γ). So, by the strong duality theorem, {a mathematical formula}ISSKsum(Γ)=I∞ε(Γ), for both programs are always feasible.  □
      </paragraph>
      <paragraph>
       Recall that {a mathematical formula}I∞ε is exactly one of the two feasible measures proposed by Potyka [34]. Far from meaningless, such measure quantifies the maximum sure loss an agent is exposed to when the sum of the stakes is no greater than one — or, equivalently, fixed at one.
      </paragraph>
      <paragraph>
       As to Potyka's other feasible proposal, {a mathematical formula}I1ε, duality in linear programming provides a correspondence with the second incoherence measure we presented from Schervish et al.:
      </paragraph>
      <paragraph label="Proof">
       For any{a mathematical formula}Γ∈K,{a mathematical formula}ISSKmax(Γ)=I1ε(Γ).Similarly to the proof of Theorem 5.7, insert the constraints {a mathematical formula}λ_i,λ¯i≤1, for {a mathematical formula}1≤i≤m, into the linear program (19), (20), (21). The dual of this new program would become the program (9), (10), (11), (12), (13), with {a mathematical formula}p=1, which computes {a mathematical formula}I1ε(Γ). Again, by the strong duality theorem, {a mathematical formula}ISSKmax(Γ)=I1ε(Γ), since both programs are always feasible.  □
      </paragraph>
      <paragraph>
       Theorem 5.8 states the extensional identity between {a mathematical formula}I1ε and {a mathematical formula}ISSKmax. Within the unconditional probabilities scenario, this means that the Manhattan distance between the agent's probabilities and the closest consistent probabilities is equal to the maximum sure loss she is exposed to when stakes' absolute values are not higher than one.
      </paragraph>
      <paragraph>
       Theorem 5.7 and Theorem 5.8 give an operational interpretation for the inconsistency measures {a mathematical formula}I∞ε and {a mathematical formula}I1ε based on betting behavior. It was remarked in Section 5.1 that {a mathematical formula}Ipε and {a mathematical formula}Ip give the same inconsistency degrees to unconditional knowledge bases. Thus, Dutch books with limited stakes ({a mathematical formula}λ_i,λ¯i≤1 or {a mathematical formula}∑iλ_i+λ¯i≤1) can be used to rationalize also {a mathematical formula}I1 and {a mathematical formula}I∞ in the unconditional setting. However, when we take into account conditional probabilities, only {a mathematical formula}I1ε and {a mathematical formula}I∞ε measure the maximum guaranteed loss an agent would be exposed to, when stakes are limited via {a mathematical formula}λ_i,λ¯i≤1 or {a mathematical formula}∑iλ_i+λ¯i≤1, respectively.
      </paragraph>
      <paragraph>
       Different strategies for bounding stakes can lead to different inconsistency measures, but our motivation in this section was not to use Dutch books to determine which measures should be adopted — that is the reason of the postulates. The point here is that these two measures ({a mathematical formula}I1ε and {a mathematical formula}I∞ε), besides satisfying the postulates and being computable through linear programs, have a meaningful interpretation. In the next section, we show that other measures based on Dutch books have these qualities as well.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Other feasible principled measures
      </section-title>
      <paragraph>
       In order to measure incoherence as the greatest guaranteed loss in a Dutch book, Schervish et al. have firstly proposed two different ways of normalizing such loss: by limiting either the agent's or the bettor's resources [39]. The authors introduce the concept of escrow as the amount committed into a gamble by the agent (or the bettor). For instance, consider a gamble on {a mathematical formula}φi|ψi with stake {a mathematical formula}λ_i≥0 and relative price {a mathematical formula}q_i. The agent might lose {a mathematical formula}q_iλ_i with this gamble, while the bettor is exposed to a loss of {a mathematical formula}(1−q_i)λ_i. Now consider a gamble on the same conditional with stake {a mathematical formula}−λ¯i≤0 and relative price {a mathematical formula}q¯i. The agent might have to pay {a mathematical formula}(1−q¯i)λ¯i to the bettor, whilst the bettor might lose {a mathematical formula}q¯iλ¯i≥0 to the agent. Schervish et al. call these quantities the agent's and the bettor's escrows. Equivalently, the agent's (or bettor's) escrow for a gamble is how much she (he) has to commit from her (his) resources to cover an eventual loss.
      </paragraph>
      <paragraph>
       Instead of bounding the sum of the stakes, an agent's degree of incoherence can be measured, as the maximum guaranteed loss in a Dutch book, by limiting the agent's (or the bettor's) total escrow to one.{sup:9} In other words, we are limiting how much the agent (or the bettor) could lose in case that every gamble resolves unfavorably, inflicting a loss to her (him). Schervish et al. give market situations that justifies these choices [39]. We denote by {a mathematical formula}ISSKa,sum:K→[0,∞) and {a mathematical formula}ISSKb,sumK→[0,∞)∪{∞}{sup:10} the inconsistency measures corresponding to these two incoherence measures, when the agent's or the bettor's total escrow is at most one, respectively.
      </paragraph>
      <paragraph>
       Formally, starting with the linear program of lines (19), (20), (21), {a mathematical formula}ISSKa,sum(Γ) and {a mathematical formula}ISSKb,sum(Γ) are obtained via the maximization of ℓ by adding further constraints. Let {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m} be a knowledge base. To compute {a mathematical formula}ISSKa,sum(Γ), one need to insert the restriction {a mathematical formula}∑i=1mq_iλ_i+(1−q¯i)λ¯i≤1 into (19), (20), (21). Similarly, {a mathematical formula}ISSKg,sum(Γ) is the solution (on ℓ) of the program (19), (20), (21) incremented with the constraint {a mathematical formula}∑i=1m(1−q_i)λ_i+q¯iλ¯i≤1.
      </paragraph>
      <paragraph>
       The fact that {a mathematical formula}ISSKg,sum may be unbounded is acknowledged by Schervish et al. [39]. For instance, consider an agent whose belief state is given by {a mathematical formula}Γ={(φ)[1],(¬φ)[1]}. The agent finds acceptable pairs of gambles on (φ and ¬φ) in which the bettor has escrows equal to zero ({a mathematical formula}λ_i(1−q_i)=0, for {a mathematical formula}q_i=1), and sure loss can be scaled arbitrarily up. In such cases, we define {a mathematical formula}ISSKb,sum(Γ)=∞.
      </paragraph>
      <paragraph label="Example 5.9">
       Recall Example 5.3, its three gambles, with stakes $10, $10 and {a mathematical formula}$−10, and the implied loss of at least $1 to Alice. But now suppose that Bob has to choose gambles in such a way that his (or Alice's) total escrow sum up to 1. Note that, with stakes $10, $10 and {a mathematical formula}$−10, his total escrow is {a mathematical formula}$10×(1−0.7)+$10×(1−0.5)+$10×0.1=$9 (Alice's is {a mathematical formula}$10×0.7+$10×0.5+$10×(1−0.1)=$21). He could then arrange the same gambles but changing the stakes to 10/9, 10/9 and {a mathematical formula}−10/9 (or 10/21, 10/21 and {a mathematical formula}−10/21) in order to his (Alice's) total escrow be equal to one. In this new scenario, Alice would have a sure loss of 1/9 (or 1/21). Once again, one could verify (by solving the linear programs) that 1/9 and 1/21 are the greatest amount one can take for sure from Alice via Dutch book if Bob's or Alice's total escrow is no greater than 1, respectively. Formalizing, with {a mathematical formula}Γ={(x1)[0.7,0.8],(x2)[0.5,0.6],(x1∧x2)[0,0.1]} codifying Alice's epistemic state, we have {a mathematical formula}ISSKb,sum(Γ)=1/9 and {a mathematical formula}ISSKa,sum(Γ)=1/21.
      </paragraph>
      <paragraph>
       Schervish et al. contemplate in detail a whole spectrum of ways to bound the agent's escrows, the bettor's, or their sum in order to measure the maximum sure loss [40]. For each of these three quantities, the author note that the two extreme functions in their framework used to normalize the guaranteed loss are the maximum and the sum, from which six different inconsistency measures arise [38]. Note that the sum of the agent's and the bettor's escrows for a single gamble is equal to the absolute value of its stake, so {a mathematical formula}ISSKsum and {a mathematical formula}ISSKmax are two inconsistency measures from this same framework. To build the remaining two measures, escrows could be bounded via their maximum, instead of their total. Intuitively, this corresponds to limiting the quantity the agent (or the bettor) accepts to eventually lose in each individual gamble.
      </paragraph>
      <paragraph>
       We define the inconsistency measure {a mathematical formula}ISSKa,max:K→[0,∞) (and {a mathematical formula}ISSKb,maxK→[0,∞)∪{∞}) on knowledge bases as the degree of incoherence of the corresponding agents measured via the maximum sure loss she is exposed through a Dutch book if the agent's (the bettor's) escrow for each gamble in no greater than one. To compute {a mathematical formula}ISSKa,max(Γ), for {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}, we may again use the linear program (19), (20), (21) and compute the maximum value of ℓ with extra constraints {a mathematical formula}q_iλ_i≤1 and {a mathematical formula}(1−q¯i)λ¯i≤1, for {a mathematical formula}1≤i≤m. Similarly, {a mathematical formula}ISSKb,max(Γ) is the solution (on ℓ) to the program formed by inserting the restrictions {a mathematical formula}(1−q_i)λ_i≤1 and {a mathematical formula}q¯iλ¯i≤1, for {a mathematical formula}1≤i≤m, into (19), (20), (21). As with {a mathematical formula}ISSKb,sum, we define {a mathematical formula}ISSKb,max(Γ)=∞ when such program is unbounded.
      </paragraph>
      <paragraph label="Example 5.10">
       Remember the scenario from Example 5.3, in which three gambles are considered, with stakes $10, $10 and {a mathematical formula}$−10, and Alice has a guaranteed loss of at least $1. Now suppose that Bob can only choose gambles in which his (Alice's) eventual loss — the escrow — is lesser than or equal to one. In other words, his (her) maximum escrow is no greater than 1. With these constraints, Bob can choose the same three gambles, but with stakes 2, 2 and −2: his escrows are {a mathematical formula}2×(1−0.7)=0.6, {a mathematical formula}2×(1−0.5)=1 and {a mathematical formula}2×0.1=0.2 (with stakes 10/9, 10/9 and {a mathematical formula}−10/9, Alice's escrow are {a mathematical formula}(10/9)×0.7=7/9, {a mathematical formula}10/9×0.5=5/9 and {a mathematical formula}10/9×(1−0.1)=1). Note that Bob (Alice) can eventually lose at most 1 in a single gamble. In this new setting, Alice would have a guaranteed loss of 1/5 (or 1/9). By solving the corresponding linear programs, we would find that 1/5 and 1/9 are the greatest amount one can take for sure from Alice via Dutch book if Bob's or Alice's maximum escrow is no greater than 1, respectively. Formalizing, with {a mathematical formula}Γ={(x1)[0.7,0.8],(x2)[0.5,0.6],(x1∧x2)[0,0.1]} codifying Alice's epistemic state, we have {a mathematical formula}ISSKb,max(Γ)=1/5 and {a mathematical formula}ISSKa,max(Γ)=1/9.
      </paragraph>
      <paragraph>
       These four inconsistency measures ({a mathematical formula}ISSKa,sum, {a mathematical formula}ISSKb,sum, {a mathematical formula}ISSKa,max and {a mathematical formula}ISSKb,max) based on limiting the escrows have most of the desirable properties we presented.
      </paragraph>
      <paragraph label="Theorem 5.11">
       {a mathematical formula}ISSKa,sum,{a mathematical formula}ISSKb,sum,{a mathematical formula}ISSKa,maxand{a mathematical formula}ISSKb,maxare well-defined and satisfy consistency, i-independence and monotonicity.{a mathematical formula}ISSKa,maxand{a mathematical formula}ISSKb,maxalso satisfy super-additivity and IC-separability.
      </paragraph>
      <paragraph label="Lemma 5.12">
       {a mathematical formula}ISSKa,sum,{a mathematical formula}ISSKa,max,{a mathematical formula}ISSKb,sumand{a mathematical formula}ISSKb,maxare continuous for probabilities within{a mathematical formula}(0,1).
      </paragraph>
      <paragraph label="Lemma 5.13">
       {a mathematical formula}ISSKa,sumsatisfies normalization.
      </paragraph>
      <paragraph>
       Altogether, {a mathematical formula}ISSKa,sum, {a mathematical formula}ISSKb,sum, {a mathematical formula}ISSKa,max and {a mathematical formula}ISSKb,max are all computable through linear programs, have the core desirable properties and can be given an operational interpretation. {a mathematical formula}ISSKa,max and {a mathematical formula}ISSKb,max also satisfy super-additivity and IC-separability, while {a mathematical formula}ISSKa,sum is normalized. These measures can be good alternatives, depending on the context, as the market scenarios described by Schervish et al. [39].
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Conclusions and future work
     </section-title>
     <paragraph>
      Handling inconsistency has been receiving increased attention in the AI community since most inference methods rely on the consistency of the premises; and such requirement is commonly violated in large bases of probabilistic knowledge. A reasonable start point to deal with the inconsistency in probabilistic bases is to know how severe it is, and how this severity changes with the probabilities. In this work, we studied different ways of measuring inconsistency in probabilistic knowledge bases. Three aspects were discussed: postulates the measures should satisfy, the efficiency of the methods used to compute the measures, and possible meaningful interpretations for them. As it was argued for, the independence postulate shall be abandoned in favor of continuity. The causes of such incompatibility were analyzed, and a modification of independence was proposed to restore compatibility. Inconsistency measures that can be computed using linear programs were reviewed and proved to satisfy the postulates, and we gave them a rational by means of Dutch books. Finally, we showed that other measures in the literature based on Dutch books, and computable through linear programming, also satisfy the postulates.
     </paragraph>
     <paragraph>
      By restoring the compatibility of the postulates for measuring inconsistency in probabilistic knowledge bases, we put forward a new pair of properties one can use to formulate or evaluate measures: i-independence and IC-separability. These desirable properties are based on two new concepts: innocuous conditional and inescapable conflicts. Besides measuring inconsistency, these concepts may be useful for formalizing inference from inconsistent bases or performing probabilistic belief revision/update, for instance. Both concepts are derived from a specific consolidation procedure — the widening of probability intervals. If other consolidation methods are considered, one can define analogous concepts, even in a different logical formalism.
     </paragraph>
     <paragraph>
      In AI, inconsistency measures for probabilistic knowledge bases have been based on distance minimization, while in Formal Epistemology incoherence measures for Bayesian agents were focused on Dutch books vulnerability. The connections here established can help both communities to investigate their corresponding problems under a different angle.
     </paragraph>
     <paragraph>
      The introduced concepts of innocuous conditional and inescapable conflict might have practical use in measuring inconsistency only if their instances are recognizable in a reasonable time. Nothing was said here about the complexity of the computational task of finding innocuous conditionals and inescapable conflicts within a knowledge base, but they are clearly very hard problems. Thus, future work includes investigating these problems aiming at devising algorithms to solve them. It would also be interesting to propose concrete procedures to consolidate knowledge bases, as done in [35] for instance. To achieve that, one could rely on the same triplet: rationality postulates, efficiency of computation and meaningful interpretation. Another intended continuation of this work is to study principled ways of inferring probabilistic conclusions from inconsistent bases, using the ideas here presented. For instance, this could be done by defining the set of models of an inconsistent base as the set containing all models of each closest consistent base, construed as the consolidations corresponding to some inconsistency measure here studied.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <section-title>
      Proofs of technical results
     </section-title>
     <paragraph label="Theorem 4.2">
      If{a mathematical formula}Isatisfies MIS-separability, then{a mathematical formula}Isatisfies independence.Let Γ be a knowledge base and {a mathematical formula}α∈Γ a free conditional. By MIS-separability, as α is free and all MISes of Γ are in {a mathematical formula}Γ∖{α}, we have {a mathematical formula}I(Γ)=I(Γ∖{α})+I(α).  □There is no inconsistency measure{a mathematical formula}I:Kprec→[0,∞)that satisfies consistency, MIS-separability and continuity.It follows directly from Theorem 3.8 and Proposition 3.6.  □Consider a knowledge base{a mathematical formula}Γ∈Kand a probabilistic conditional{a mathematical formula}α∈Γ. The following statements are equivalent:
     </paragraph>
     <list>
      <list-item label="1.">
       There is no minimal abrupt repair Δ of Γ such that{a mathematical formula}α∈Δ.
      </list-item>
      <list-item label="2.">
       For all maximal abrupt consolidation{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
      </list-item>
      <list-item label="3.">
       If{a mathematical formula}Γ′=Γ∖Δis an abrupt consolidation of Γ (equivalently, Δ is an abrupt repair of Γ), then α is consistent with{a mathematical formula}Γ′.
      </list-item>
      <list-item label="4.">
       There is no minimal inconsistent set{a mathematical formula}Δ⊆Γsuch that{a mathematical formula}α∈Δ.
      </list-item>
     </list>
     <paragraph label="Lemma 4.5">
      The first two items are clearly dual, and the fourth one is the definition of free conditional. Suppose α is free in Γ. Note that all abrupt consolidations {a mathematical formula}Γ′ of Γ are consistent with α. As {a mathematical formula}Γ′ is consistent, it has no MIS, and adding α cannot create a MIS, for it is free. Thus, if an abrupt consolidation does not contain α, it is not maximal. Now suppose there is a maximal abrupt consolidation {a mathematical formula}Γ′ such that {a mathematical formula}α∉Γ′. For {a mathematical formula}Γ′ is maximal, α cannot be consistent with it. As {a mathematical formula}Γ′ is consistent, it has no MIS, and adding α creates a MIS (that contains α), which also is a MIS of Γ — hence, α cannot be free.  □Consider a knowledge base{a mathematical formula}Γ∈Kand a probabilistic conditional{a mathematical formula}α∈Γ. The following statements are equivalent:
     </paragraph>
     <list>
      <list-item label="1.">
       For all d-consolidation{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
      </list-item>
      <list-item label="2.">
       If{a mathematical formula}Γ′is a consolidation, then α is consistent with{a mathematical formula}Γ′.
      </list-item>
     </list>
     <paragraph label="Proof">
      Suppose all d-consolidations of Γ contain α. For any consolidation Ψ, there is a d-consolidation {a mathematical formula}Ψ′ such that, for each {a mathematical formula}β′∈Ψ′, there is a {a mathematical formula}β∈Ψ such that {a mathematical formula}β′⊆β. Therefore, any probability mass π satisfying {a mathematical formula}Ψ′ must also satisfies Ψ, and {a mathematical formula}α∈Ψ′ implies π satisfies α as well. Now suppose there is a d-consolidation Ψ that does not contain α. As {a mathematical formula}α∈Γ, there is a {a mathematical formula}β∈Ψ such that {a mathematical formula}α⊊β. For Ψ is dominant, {a mathematical formula}(Ψ∖{β})∪{α} cannot be a consolidation and thus is inconsistent. Finally, α is not consistent with Ψ.  □Consider a probabilistic conditional{a mathematical formula}α∈Γ. If α is safe, it is innocuous; if α is innocuous, it is free.If {a mathematical formula}Γ={α}, then α is safe, innocuous and free iff it is satisfiable, thus we focus on {a mathematical formula}Γ≠{α}. Let Γ be built over the set of atoms {a mathematical formula}Xn={x1,…,xn}. Suppose α is safe and, without loss of generality, the set of atoms appearing in α is {a mathematical formula}Xα={x1,…,xm}, for some {a mathematical formula}m&lt;n. As α is satisfiable, there is a probability mass {a mathematical formula}πα:WXα→[0,1] satisfying it, where {a mathematical formula}WXα is the set containing the {a mathematical formula}2m possible worlds with atoms from {a mathematical formula}Xα. The base {a mathematical formula}Γ′=Γ∖{α} is built over the set of atoms {a mathematical formula}XΓ′=Xn∖Xα. Any consolidation Ψ of {a mathematical formula}Γ′ must also be formed by atoms in {a mathematical formula}XΓ′. If Δ is a consolidation of Γ, there is a consolidation Ψ of {a mathematical formula}Γ′ such that {a mathematical formula}Δ=Ψ∪{β}, for some β such that {a mathematical formula}α⊆β. Let {a mathematical formula}πΨ:WXΓ′→[0,1] be the probability mass satisfying Ψ, where {a mathematical formula}WXΓ′ is the set containing the {a mathematical formula}2n−m possible worlds with atoms from {a mathematical formula}XΓ′. Consider the probability mass {a mathematical formula}π:WXn→[0,1] such that {a mathematical formula}π(wi∧wj)=πα(wi)×πΨ(wj) for any pair {a mathematical formula}(wi,wj)∈WXα×WXΓ′. Note that π satisfies Ψ and α, thus π satisfies Ψ and β. Therefore, α is consistent with any consolidation {a mathematical formula}Δ=Ψ∪{β} of Γ and is innocuous by Lemma 4.5.Now suppose α is innocuous. Any abrupt consolidation {a mathematical formula}Δ⊆Γ is equivalent (and equisatisfiable) to a consolidation {a mathematical formula}Δ′∈Γ such that {a mathematical formula}Δ′=Δ∪{(φ|ψ)[0,1]|(φ|ψ)[q_,q¯]∈Γ∖Δ}. As α is innocuous, it is consistent with any consolidation {a mathematical formula}Δ′ and, consequently, any abrupt consolidation Δ. Finally, by Theorem 4.2, α is free.  □If{a mathematical formula}Isatisfies independence, then{a mathematical formula}Isatisfies i-independence. If{a mathematical formula}Isatisfies i-independence, then{a mathematical formula}Isatisfies weak independence.It follows directly from the definitions and Proposition 4.8.  □
     </paragraph>
     <paragraph label="Proposition 4.11">
      A knowledge base Γ is a minimal inconsistent set iff Γ is inconsistent and there are no{a mathematical formula}Δ1,…,Δk⊊Γ, with{a mathematical formula}k≥1, such that:
     </paragraph>
     <list>
      <list-item label="1.">
       {a mathematical formula}⋃i=1kΔi=Γ;
      </list-item>
      <list-item label="2.">
       For every{a mathematical formula}Γ′⊆Γif{a mathematical formula}Γ′∩Δiis an abrupt consolidation of{a mathematical formula}Δifor all{a mathematical formula}1≤i≤k, then{a mathematical formula}Γ′is an abrupt consolidation of Γ.
      </list-item>
     </list>
     <paragraph label="Proof">
      (→) Suppose Γ is a MIS and there are {a mathematical formula}Δ1,…,Δk⊊Γ satisfying both items. For any {a mathematical formula}1≤i≤k, as {a mathematical formula}Δi⊊Γ is consistent, {a mathematical formula}Γ∩Δi is an abrupt consolidation of {a mathematical formula}Δi. Thus, by the second item, Γ is an abrupt consolidation of itself, which contradicts the fact that Γ is inconsistent.(←) Now suppose Γ is inconsistent but not a MIS. Let {a mathematical formula}MIS(Γ)={Δ1,…,Δm} be the set of MISes in Γ, for some {a mathematical formula}m≥1. Let {a mathematical formula}Δm+1 denote the set of free formulas in Γ. Clearly, {a mathematical formula}⋃i=1m+1Δi=Γ. Now consider a set {a mathematical formula}Γ′⊆Γ such that {a mathematical formula}Γ′∩Δi is consistent for any {a mathematical formula}1≤i≤m+1. If {a mathematical formula}Γ′ was inconsistent, it would contain a MIS {a mathematical formula}Δi∈MIS(Γ) and {a mathematical formula}Γ′∩Δi would be inconsistent — a contradiction. Thus {a mathematical formula}Γ′ is an abrupt consolidation of Γ.  □A knowledge base Γ is an inescapable conflict iff there is a widening{a mathematical formula}Γ′of Γ such that{a mathematical formula}Γ′is a minimal inconsistent set.(←) Consider a minimal inconsistent set {a mathematical formula}Γ′ that is a widening of Γ. To prove by contradiction, suppose Γ is not an inescapable conflict. As its widening {a mathematical formula}Γ′ is inconsistent, Γ also is, for each conditional in {a mathematical formula}Γ′ is implied by a conditional in Γ. Hence, as Γ is not an inescapable conflict, there must be {a mathematical formula}Δ1,…,Δk⊊Γ such that {a mathematical formula}⋃i=1kΔi=Γ and, if {a mathematical formula}Δi′ is a consolidation of {a mathematical formula}Δi, for all {a mathematical formula}1≤i≤k, and {a mathematical formula}⋃i=1kΔi′ is a widening of Γ, then {a mathematical formula}⋃i=1kΔi′ is a consolidation of Γ. Consider such collection {a mathematical formula}Δ1,…,Δk⊊Γ. Note that, for each {a mathematical formula}Δi, there is a widening {a mathematical formula}Ψi⊊Γ′, defined via {a mathematical formula}Ψi={β∈Γ′|α∈Δi and α⊆β}, for {a mathematical formula}1≤i≤k. Furthermore any {a mathematical formula}Ψi⊊Γ′ is consistent, for {a mathematical formula}Γ′ is a minimal inconsistent set. As {a mathematical formula}⋃i=1kΨi is equal to {a mathematical formula}Γ′, it is a widening of Γ. As each {a mathematical formula}Ψi is consistent, {a mathematical formula}Γ′ must be a consolidation of Γ and, thus, {a mathematical formula}Γ′ is consistent. This is a contradiction, which proves that Γ is an inescapable conflict.(→) Let {a mathematical formula}Γ={α1,α2,…,αm} be an inescapable conflict and define {a mathematical formula}Δi=Γ∖{αi}, for {a mathematical formula}1≤i≤m. Note that {a mathematical formula}Δ1,…,Δm⊊Γ such that {a mathematical formula}⋃i=1mΔi=Γ. Let {a mathematical formula}Δi′ denote an arbitrary consolidation of {a mathematical formula}Δi, for {a mathematical formula}1≤i≤m. If every set {a mathematical formula}{Δ1′,Δ2′,…,Δm′|⋃i=1mΔi′ is a widening of |Γ} is such that {a mathematical formula}⋃i=1mΔi′ is a consolidation of Γ, Γ would not be an inescapable conflict. So, there are consolidations {a mathematical formula}Δi′ for each {a mathematical formula}Δi ({a mathematical formula}≤′i≤m) such that {a mathematical formula}⋃i=1mΔi′=Γ′ is widening of Γ but is not consistent. As {a mathematical formula}Γ′ is a widening of Γ, {a mathematical formula}Γ′={α1′,α2′,…,αm′} for some {a mathematical formula}αi⊆αi′ for {a mathematical formula}1≤i≤m. As {a mathematical formula}Δi=Γ∖{αi}, {a mathematical formula}Δi′=Γ′∖{αi′}, for {a mathematical formula}1≤i≤m. Hence, {a mathematical formula}Δ1′,…,Δm′ are the maximal proper subsets of Γ, and every proper subset of {a mathematical formula}Γ′ is consistent. Thus, {a mathematical formula}Γ′ is a minimal inconsistent set.  □
     </paragraph>
     <paragraph label="Proof">
      Consider two knowledge bases{a mathematical formula}Γ,Γ′∈Ksuch that{a mathematical formula}Γ′is a widening of Γ. If for every inescapable conflict{a mathematical formula}Δ⊆Γits widening{a mathematical formula}{β∈Γ′|α∈Δandα⊆β}is consistent, then{a mathematical formula}Γ′is a consolidation of Γ.We will prove via the contrapositive: given Γ and its widening {a mathematical formula}Γ′, if {a mathematical formula}Γ′ is not a consolidation of Γ, then there is an inescapable conflict {a mathematical formula}Δ⊆Γ such that the set {a mathematical formula}{β∈Γ′|α∈Δ and α⊆β} is inconsistent.If {a mathematical formula}Γ′ is not a consolidation of Γ, {a mathematical formula}Γ′ is inconsistent and must contain at least one minimal inconsistent set, that we denote by {a mathematical formula}Δ′. Let Δ be the set {a mathematical formula}{α∈Γ|β∈Δ′ and α⊆β} — that is, {a mathematical formula}Δ′⊆Γ′ is a widening of {a mathematical formula}Δ⊆Γ. By Lemma 4.13, Δ is an inescapable conflict.  □
     </paragraph>
     <paragraph label="Proof">
      If Δ is a minimal inconsistent set, then Δ is an inescapable conflict.Just note that Δ is a widening of itself. By Lemma 4.13, Δ is an inescapable conflict.  □If{a mathematical formula}Isatisfies MIS-separability, then{a mathematical formula}Isatisfies IC-separability.If follows directly from the definitions and Corollary 4.15.  □
     </paragraph>
     <paragraph label="Theorem 4.19">
      The following statements are equivalent:
     </paragraph>
     <list>
      <list-item label="1.">
       For all d-consolidation{a mathematical formula}Γ′of Γ,{a mathematical formula}α∈Γ′.
      </list-item>
      <list-item label="2.">
       If{a mathematical formula}Γ′is a consolidation of Γ, then α is consistent with{a mathematical formula}Γ′.
      </list-item>
      <list-item label="3.">
       There is no inescapable conflict Δ in Γ such that{a mathematical formula}α∈Δ.
      </list-item>
      <list-item label="4.">
       α is an innocuous probabilistic conditional in Γ.
      </list-item>
     </list>
     <paragraph label="Proof">
      By the definition of innocuous conditionals and Lemma 4.5, the first, the second and the fourth statements are equivalent. It remains to prove that α is innocuous iff there is no inescapable conflict Δ in Γ such that {a mathematical formula}α∈Δ.(→) Let α be innocuous in Γ. Suppose there is an inescapable conflict {a mathematical formula}Δ⊆Γ such that {a mathematical formula}α∈Δ. Consider the base {a mathematical formula}Ψ=Δ∖{α}. Let {a mathematical formula}Ψ′ be a consolidation of Ψ. Thus, {a mathematical formula}Γ′=Ψ′∪{(φ|ψ)[0,1]|(φ|ψ)[q_,q¯]∈Γ∖Ψ} is consistent and it is a consolidation of Γ. Due to the fact that α is innocuous, α is consistent with {a mathematical formula}Γ′ (by Lemma 4.5) and, therefore, with {a mathematical formula}Ψ′. Consequently, {a mathematical formula}Ψ′∪{α} is a consolidation of Δ for any consolidation {a mathematical formula}Ψ′ of Ψ. Furthermore, if {a mathematical formula}{β} is a consolidation of {a mathematical formula}{α} (i.e., {a mathematical formula}α⊆β), {a mathematical formula}Ψ′∪{β} is a consolidation of Δ. As {a mathematical formula}Ψ,{α}⊊Δ are such that {a mathematical formula}Ψ∪{α}=Δ, and any consolidations {a mathematical formula}Ψ′ and {a mathematical formula}{β} of theirs are such that {a mathematical formula}Ψ′∪{β} is a consolidation of Δ, Δ is not an inescapable conflict, which is a contradiction.(←) Suppose there is no inescapable conflict Δ in Γ such that {a mathematical formula}α∈Δ. Consider the base {a mathematical formula}Ψ=Γ∖{α}. Every consolidation {a mathematical formula}Γ′ of Γ can be written as {a mathematical formula}Γ′=Ψ′∪{β}, where {a mathematical formula}Ψ′ is a consolidation of Ψ and {a mathematical formula}α⊆β. As all inescapable conflicts of Γ are in Ψ, by Corollary 4.14, {a mathematical formula}Ψ′∪{α} is consistent. Hence, α is consistent with any consolidation {a mathematical formula}Γ′=Ψ′∪{β} and α is innocuous by Lemma 4.5.  □
     </paragraph>
     <paragraph label="Proof">
      If{a mathematical formula}Isatisfies IC-separability, then{a mathematical formula}Isatisfies i-independence.Let Γ be a knowledge base and {a mathematical formula}α∈Γ an innocuous conditional. As α is innocuous, all inescapable conflicts of Γ are in {a mathematical formula}Γ∖{α} by Lemma 4.19. By IC-separability, we have {a mathematical formula}I(Γ)=I(Γ∖{α})+I(α).  □For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipis well-defined and satisfies the postulates of consistency, continuity, i-independence and monotonicity.To show that {a mathematical formula}Ip is well-defined, we use results from the proof of Theorem 1 in [44]. For any {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}, Thimm shows that the set {a mathematical formula}QΓ={〈q1,…,qm〉∈Rm|ΛΓ(〈q1,q1,…,qm,qm〉) is consistent} is compact and closed, where {a mathematical formula}ΛΓ:[0,1]2m→K is the characteristic function of Γ. Let {a mathematical formula}h:R2→R be a function such that {a mathematical formula}h(a,b)=max⁡(0,a−b) for any {a mathematical formula}a,b∈R. The measure {a mathematical formula}Ip is the minimum of {a mathematical formula}‖fq_,q¯(q)‖p with {a mathematical formula}q∈QΓ, where {a mathematical formula}fq_,q¯:Rm→R2m is a function such that {a mathematical formula}fq_,q¯(〈q1,…,qm〉)=〈h(q_1−q1),h(q1−q¯1),…,h(q_m−qm),h(qm−q¯m)〉. Intuitively, {a mathematical formula}fq_,q¯(q) measures, for each point {a mathematical formula}qi, how much the lower and the upper bounds have to change for we have {a mathematical formula}qi∈[q_i,q¯i]. Finally, {a mathematical formula}Ip is well defined, for {a mathematical formula}QΓ is closed and compact [44].Consistency: By definition, a p-norm is never negative, thus {a mathematical formula}Ip(Γ)≥0. Suppose {a mathematical formula}Γ=ΛΓ(q) is consistent. A vector {a mathematical formula}q′=q is such that {a mathematical formula}‖q′−q‖p=0 for any {a mathematical formula}p∈N&gt;0∪{∞}, thus {a mathematical formula}Ip(Γ)=0. Now suppose {a mathematical formula}Γ=ΛΓ(q) is inconsistent. For every {a mathematical formula}q′∈QΓ, {a mathematical formula}q′≠q, then {a mathematical formula}‖q′−q‖p&gt;0 and {a mathematical formula}Ip(Γ)&gt;0 for any {a mathematical formula}p∈N&gt;0∪{∞}.Continuity: Given a base {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}, its characteristic function {a mathematical formula}ΛΓ:[0,1]2m→K and a fixed {a mathematical formula}q∈QΓ, define the function {a mathematical formula}gq:R2m→R such that {a mathematical formula}gq(〈q_1,q¯1,…,q_m,q¯m〉)=‖fq_,q¯(q)‖p. Note that {a mathematical formula}Ip∘ΛΓ(〈q_1,q¯1,…,q_m,q¯m〉) is computed as the minimum of {a mathematical formula}{gq(〈q_1,q¯1,…,q_m,q¯m〉)|q∈QΓ}. Each {a mathematical formula}gq is continuous, and the minimum of continuous functions is continuous, hence {a mathematical formula}Ip∘ΛΓ is continuous.Monotonicity: Let {a mathematical formula}ΛΓ(q′) be a consolidation of {a mathematical formula}Γ=ΛΓ(q) such that {a mathematical formula}‖q′−q‖p is minimized, for a {a mathematical formula}p∈N&gt;0∪{∞}, and {a mathematical formula}Ip(Γ)=‖q′−q‖p. To prove by contradiction, suppose {a mathematical formula}I(Γ∪{α})&lt;Ip(Γ), for some {a mathematical formula}Ψ=Γ∪{α}∈K. Hence, there is a consolidation {a mathematical formula}Ψ′=ΛΨ(r′) of {a mathematical formula}Ψ=ΛΨ(r) such that {a mathematical formula}‖r′−r‖p&lt;‖q′−q‖p. Consider the base {a mathematical formula}Γ′=Ψ′∖{β}, such that {a mathematical formula}α⊆β. As {a mathematical formula}Ψ′ is consistent, {a mathematical formula}Γ′=ΛΓ(q″) also is, and it is a consolidation of Γ. Since q and {a mathematical formula}q″ are projections (subsets, in sense) of r and {a mathematical formula}r′, {a mathematical formula}q″−q is a projection of {a mathematical formula}r′−r and {a mathematical formula}‖q″−q‖p≤‖r′−r‖p&lt;‖q′−q‖p. Finally, it would follow that {a mathematical formula}Ip(Γ)≤‖q″−q‖p&lt;‖q′−q‖p=Ip(Γ), which is a contradiction.i-Independence: Consider the bases {a mathematical formula}Γ=ΛΓ(r) and {a mathematical formula}Ψ=Γ∖{α} in {a mathematical formula}K, where {a mathematical formula}α=(φ|ψ)[q_,q¯] is innocuous in Γ. We are going to prove that {a mathematical formula}Ip(Γ)≤Ip(Ψ), and the desired result follows from monotonicity. Let {a mathematical formula}Ψ′=ΛΨ(q′) be a consolidation of {a mathematical formula}Ψ=ΛΨ(q) such that {a mathematical formula}‖q′−q‖p is minimized, for a {a mathematical formula}p∈N&gt;0∪{∞}, and {a mathematical formula}Ip(Ψ)=‖q′−q‖p. Note that {a mathematical formula}Γ′=Ψ′∪{(φ|ψ)[0,1]} is a consolidation of Γ. As {a mathematical formula}α=(φ|ψ)[q_,q¯] is innocuous, α is consistent with {a mathematical formula}Γ′ and {a mathematical formula}Ψ′. Hence, {a mathematical formula}Ψ′∪{α}=ΛΓ(r′) is a consolidation of Γ. Note that {a mathematical formula}r′−r is {a mathematical formula}q′−q with two extra 0's (from alpha). Finally, {a mathematical formula}Ip(Γ)≤‖r′−r‖p=‖q′−q‖p=Ip(Ψ).  □
     </paragraph>
     <paragraph label="Proof">
      {a mathematical formula}Ipsatisfies super-additivity and IC-separability iff{a mathematical formula}p=1.(→) To note that super-additivity and IC-separability do not hold if {a mathematical formula}p&gt;1, consider the bases {a mathematical formula}Ψ={(⊤)[0.9]},Δ={(⊥)[0.1]},Γ=Ψ∪Δ. By the definition of d-consolidation, if {a mathematical formula}Ip(Γ)=d, then there is d-consolidation {a mathematical formula}ΛΓ(q′) of {a mathematical formula}Γ=ΛΓ(q) such that {a mathematical formula}‖q′−q‖p=d. The only d-consolidations of {a mathematical formula}Ψ,Δ,Γ are {a mathematical formula}Ψ′={(⊤)[0.9,1]},Δ′={(⊥)[0,0.1]},Γ′=Ψ′∪Δ′, for changing the lower bound in Ψ and the upper bound in Δ is useless to reach consistency. For any finite p, {a mathematical formula}Ip(Ψ)=Ip(Δ)=0.1pp=0.1, and {a mathematical formula}Ip(Γ)=0.1p+0.1pp=0.12p. For {a mathematical formula}p=∞, {a mathematical formula}Ip(Ψ)=Ip(Δ)=max⁡〈0.1〉=0.1 and {a mathematical formula}Ip(Γ)=max⁡〈0.1,0.1〉=0.1. Therefore, for any {a mathematical formula}p&gt;1∈N∪{∞}, {a mathematical formula}Ip(Γ)&lt;0.2=Ip(Ψ)+Ip(Δ), and both super-additivity and IC-separability fail.(←) Now fix {a mathematical formula}p=1. To prove that super-additivity holds, suppose there are bases {a mathematical formula}Ψ,Δ,Γ=Ψ∪Δ in {a mathematical formula}K such that {a mathematical formula}Ψ∩Δ=∅. Let {a mathematical formula}Ψ′=ΛΨ(q′),Δ′=ΛΔ(r′),Γ′=ΛΓ(s′) be d-consolidations of {a mathematical formula}Ψ=ΛΨ(q),Δ=ΛΔ(r),Γ=ΛΓ(s) that minimize {a mathematical formula}‖q′−q‖1,‖r′−r‖1,‖s′−s‖1, corresponding to {a mathematical formula}I1(Ψ),I1(Δ),I1(Γ). Clearly, {a mathematical formula}Γ′ can be partitioned into {a mathematical formula}Ψ″∪Δ″ in such a way that {a mathematical formula}Ψ″=ΛΨ(sΨ′),Δ″=ΛΔ(sΔ′) are consolidations of {a mathematical formula}Ψ,Δ. By the construction of {a mathematical formula}sΨ′ and {a mathematical formula}sΔ′, {a mathematical formula}‖s′−s‖1=‖sΨ′−q‖1+‖sΔ′−r‖1. Hence, for {a mathematical formula}I1(Ψ)≤‖sΨ′−q‖1 and {a mathematical formula}I1(Δ)≤‖sΔ′−r‖1, it follows that {a mathematical formula}I(Γ)=‖s′−s‖1≥I1(Ψ)+I1(Δ).To prove that IC-separability holds, suppose there are bases {a mathematical formula}Ψ,Δ,Γ=Ψ∪Δ in {a mathematical formula}K such that {a mathematical formula}Ψ∩Δ=∅, {a mathematical formula}IC(Γ)=IC(Ψ)∪IC(Δ). Let {a mathematical formula}Ψ′=ΛΨ(q′),Δ′=ΛΔ(r′), be consolidations of {a mathematical formula}Ψ=ΛΨ(q),Δ=ΛΔ(r) that minimize {a mathematical formula}‖q′−q‖1,‖r′−r‖1, corresponding to {a mathematical formula}I1(Ψ),I1(Δ). As {a mathematical formula}Γ′=Ψ′∪Δ′=ΛΓ(s′) is a widening of {a mathematical formula}Γ=ΛΓ(s) such that, for each {a mathematical formula}Φ∈IC(Γ)=IC(Ψ)∪IC(Δ), the base {a mathematical formula}{β∈Γ′|α∈Φ and α⊆β} is consistent (all inescapable conflicts are solved), {a mathematical formula}Γ′ is a consolidation of Γ by Corollary 4.14. As {a mathematical formula}‖s′−s‖1=‖q′−q‖1+‖r′−r‖1=I1(Ψ)+I1(Δ), it follows that {a mathematical formula}I1(Γ)≤I1(Ψ)+I1(Δ). By super-additivity, {a mathematical formula}I1(Γ)≥I1(Ψ)+I1(Δ), thus {a mathematical formula}I1(Γ)=I1(Ψ)+I1(Δ).  □
     </paragraph>
     <paragraph label="Proof">
      {a mathematical formula}Ipsatisfies normalization iff{a mathematical formula}p=∞.(→) To note that normalization does not hold if p is finite, consider the base {a mathematical formula}Γ={(⊤)[0],(⊥)[1]}. The only d-consolidation of Γ is {a mathematical formula}Γ′={(⊤)[0,1],(⊥)[0,1]}, for changing the lower bound in {a mathematical formula}(⊤)[0] and the upper bound in {a mathematical formula}(⊥)[1] is useless to reach consistency. For any finite p, {a mathematical formula}Ip(Γ)=1p+1pp=2p&gt;1, and normalization fails.(←) By definition, {a mathematical formula}I∞(Γ) is the minimum of {a mathematical formula}‖q′−q‖∞ subject to {a mathematical formula}Γ=ΛΓ(q) and {a mathematical formula}ΛΓ(q′) being consistent. As the vectors {a mathematical formula}q,q′ are in {a mathematical formula}[0,1]2|Γ|, {a mathematical formula}‖q′−q‖∞∈[0,1], since {a mathematical formula}|qi′−qi|∈[0,1] for all elements {a mathematical formula}qi,qi′ of {a mathematical formula}q,q′.  □For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipε:K→[0,∞)is well-defined and satisfies consistency, continuity, weak independence and monotonicity.{a mathematical formula}I1εalso satisfies super-additivity.See Section 4 in [34].  □
     </paragraph>
     <paragraph label="Proof">
      For any{a mathematical formula}p∈N&gt;0∪{∞},{a mathematical formula}Ipε:K→[0,∞)is well-defined and satisfies consistency, continuity, i-independence and monotonicity.{a mathematical formula}I1εalso satisfies super-additivity and IC-separability; and{a mathematical formula}I∞εsatisfies normalization.For well-definedness, consistency, i-independence, monotonicity, super-additivity and IC-separability, see the proof of Theorem 5.11. For continuity, see Lemma 5.12.For normalization, we note that {a mathematical formula}I∞ε(Γ)=ISSKsum(Γ) for any {a mathematical formula}Γ∈K, by Theorem 5.7. When we are computing {a mathematical formula}ISSKsum, we limit the sum of the absolute values of the stakes to one. As the agent cannot lose more than the absolute value of the stake in each gamble in a Dutch book, and they sum up to one, {a mathematical formula}ISSKsum=I∞ε satisfy normalization.  □
     </paragraph>
     <paragraph label="Proof">
      {a mathematical formula}ISSKa,sum,{a mathematical formula}ISSKb,sum,{a mathematical formula}ISSKa,maxand{a mathematical formula}ISSKb,maxare well-defined and satisfy consistency, i-independence and monotonicity.{a mathematical formula}ISSKa,maxand{a mathematical formula}ISSKb,maxalso satisfy super-additivity and IC-separability.Let {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m} be an arbitrary knowledge base in {a mathematical formula}K and {a mathematical formula}γ_i,γ¯i be non-negative real parameters, for {a mathematical formula}1≤i≤m. Consider the following program, with {a mathematical formula}p∈N&gt;0∪{∞}, where {a mathematical formula}ε_γ ({a mathematical formula}ε¯γ) is a ({a mathematical formula}m×1)-vector whose elements are {a mathematical formula}ε_iγ_i ({a mathematical formula}ε¯iγ¯i), for {a mathematical formula}1≤i≤m:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}Define the inconsistency measure {a mathematical formula}Ipγ:K→[0,∞)∪∞ in such a way that {a mathematical formula}Ipγ(Γ) is the minimum of the objective function of the program above; or ∞ if it is infeasible. If {a mathematical formula}γ_i=γ¯i=1 for all {a mathematical formula}1≤i≤m, {a mathematical formula}Ipγ(Γ)=Ipε(Γ), for any {a mathematical formula}p∈N&gt;0∪{∞}.When {a mathematical formula}p=1, if {a mathematical formula}γ_i=q_i and {a mathematical formula}γ¯i=1−q¯i for {a mathematical formula}1≤i≤m, the program above is the dual of that formed by adding the constraints {a mathematical formula}q_iλ_i≤1 and {a mathematical formula}(1−q¯i)λ¯i≤1, for {a mathematical formula}1≤i≤m, into the program (19), (20), (21). That is, {a mathematical formula}I1γ(Γ)=ISSKa,max(Γ). Analogously, if {a mathematical formula}γ_i=1−q_i and {a mathematical formula}γ¯i=q¯i for {a mathematical formula}1≤i≤m, {a mathematical formula}I1γ(Γ)=ISSKg,max(Γ).When {a mathematical formula}p=∞, in all restrictions we can replace {a mathematical formula}ε_i,ε¯i by a single scalar ε, as it was done in (14), (15), (16), (17), (18), creating an equivalent new linear program {a mathematical formula}P that minimizes ε, computing {a mathematical formula}I∞γ(Γ). If {a mathematical formula}γ_i=q_i and {a mathematical formula}γ¯i=1−q¯i for {a mathematical formula}1≤i≤m, the program {a mathematical formula}P is the dual of that formed by adding the constraints {a mathematical formula}∑i=1mq_iλ_i+(1−q¯i)λ¯i≤1 into (19), (20), (21). That is, P computes {a mathematical formula}I∞γ(Γ)=ISSKa,sum(Γ). Analogously, if {a mathematical formula}γ_i=1−q_i and {a mathematical formula}δ¯i=q¯i for {a mathematical formula}1≤i≤m, P computes {a mathematical formula}I∞γ(Γ)=ISSKg,sum(Γ).Note that the linear restrictions in the program (A.1), (A.2), (A.3), (A.4), (A.5), when it is feasible, define a convex, closed region of feasible points (a simplex). The p-norm is a continuous function, so the minimum of the objective function in (A.1) is well-defined for any {a mathematical formula}p∈N&gt;0∪{∞}. If the program (A.1), (A.2), (A.3), (A.4), (A.5) is infeasible for some {a mathematical formula}Γ∈K, {a mathematical formula}Ipγ(Γ) is (well-)defined as ∞.Consistency: Note that a p-norm is never negative. The base Γ is consistent iff the program (5), (6), (7), (8) is feasible; and such program is feasible iff the program (A.1), (A.2), (A.3), (A.4), (A.5) has a feasible solution with {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉=〈0,0,…,0〉; which is the case iff {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m,ε¯m〉‖p=0 is the minimum of the objective function in (A.1).Monotonicity: Consider the program {a mathematical formula}P from lines (A.1), (A.2), (A.3), (A.4), (A.5), corresponding to the computation of {a mathematical formula}Ipγ(Γ), for some {a mathematical formula}Γ∈K. Let {a mathematical formula}Ψ=Γ∪{α} be a knowledge base. For any {a mathematical formula}p∈N&gt;0∪{∞} and parameters {a mathematical formula}γ_1,γ¯1,…,γ_m,γ¯m≥0, the program (A.1), (A.2), (A.3), (A.4), (A.5) whose solution gives {a mathematical formula}Ipγ(Ψ) has two extra constraints in comparison with {a mathematical formula}P. Thus, the program that computes {a mathematical formula}Ipγ(Ψ) cannot reach a smaller value for {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m,ε¯m〉‖p, the objective function being minimized by {a mathematical formula}P. Furthermore, {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m+1,ε¯m+1〉‖p≥‖〈ε_1,ε¯1,…,ε_m,ε¯m〉‖p, for any {a mathematical formula}p∈N&gt;0∪{∞} and parameters {a mathematical formula}γ_1,γ¯1,…,γ_m,γ¯m≥0. Hence, {a mathematical formula}Ipγ(Γ∪{α})≥Ipγ(Γ), for any {a mathematical formula}p∈N&gt;0∪{∞}.i-independence: Let {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m} be a knowledge base in {a mathematical formula}K and {a mathematical formula}α=(φm|ψm)[q_m,q¯m] be an innocuous conditional in Γ, and define {a mathematical formula}Ψ=Γ∖{α}. Suppose {a mathematical formula}Ipγ(Ψ) is finite. The solution on {a mathematical formula}〈ε_1,ε¯1,…,ε_m−1,ε¯m−1〉 to the program (A.1), (A.2), (A.3), (A.4), (A.5) that computes {a mathematical formula}Ipγ(Ψ) corresponds to a consolidation of Ψ given by {a mathematical formula}Ψ′={(φi|ψi)[q_i−γ_iε_i,q¯i+γ¯iε¯i]|1≤i≤m−1}. For α is innocuous in Γ, it is consistent with {a mathematical formula}Ψ′∪(φm|ψm)[0,1] (a consolidation of Γ) and {a mathematical formula}Ψ′∪{α} is a consolidation of Γ. Hence, {a mathematical formula}〈ε_1,ε¯1,…,ε_m−1,ε¯m−1,0,0〉 corresponds to a feasible solution to the program (A.1), (A.2), (A.3), (A.4), (A.5) computing {a mathematical formula}Ipγ(Γ). As {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m−1,ε¯m−1〉‖p is equal to {a mathematical formula}‖〈ε_1,ε¯1,…,ε_m−1,ε¯m−1,0,0〉‖p for any {a mathematical formula}p∈N&gt;0∪{∞}, {a mathematical formula}Ipγ(Γ)≤Ipγ(Ψ). By monotonicity, {a mathematical formula}Ipγ(Γ)=Ipγ(Ψ).Now suppose {a mathematical formula}Ipγ(Ψ) is infinite. Thus, the program (A.1), (A.2), (A.3), (A.4), (A.5) that computes {a mathematical formula}Ipγ(Ψ) is infeasible. Constraints in such program are inherited by the program that computes {a mathematical formula}Ipγ(Γ)=Ipγ(Ψ∪{α}) together with the infeasibility, hence {a mathematical formula}Ipγ(Γ)=∞ by definition.Super-additivity: Suppose there are bases {a mathematical formula}Ψ,Δ,Γ=Ψ∪Δ in {a mathematical formula}K such that {a mathematical formula}Ψ∩Δ=∅. Without loss of generality, let {a mathematical formula}Ψ={(φi|ψi)[q_i,q¯i]|1≤i≤k}, {a mathematical formula}Δ={(φi|ψi)[q_i,q¯i]|k+1≤i≤m} and {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}. If {a mathematical formula}I1γ(Γ)=∞, super-additivity trivially holds, then consider {a mathematical formula}I1γ(Γ) is finite. Let {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉 be part of a solution (that includes π) to the program (A.1), (A.2), (A.3), (A.4), (A.5) that computes {a mathematical formula}I1γ(Γ), minimizing the objective function. As {a mathematical formula}Γ′={(φi|ψi)[q_i−ε_iγ_i,q¯i+ε¯iγ¯i]|1≤i≤m} is consistent, so are {a mathematical formula}Ψ′={(φi|ψi)[q_i−ε_iγ_i,q¯i+ε¯iγ¯i]|1≤i≤k} and {a mathematical formula}Δ′={(φi|ψi)[q_i−ε_iγ_i,q¯i+ε¯iγ¯i]|k+1≤i≤m}, which are consolidations of Ψ and Δ. Thus, {a mathematical formula}〈ε_1,ε¯1,…,ε_k,ε¯k〉 and {a mathematical formula}〈ε_k+1,ε¯k+1,…,ε_m,ε¯m〉 correspond to feasible solutions to the programs that compute {a mathematical formula}I1γ(Ψ) and {a mathematical formula}I1γ(Δ), respectively. It follows that {a mathematical formula}I1γ(Ψ)≤‖〈ε_1,ε¯1,…,ε_k,ε¯k〉‖1 and {a mathematical formula}I1γ(Δ)≤‖〈ε_k+1,ε¯k+1,…,ε_m,ε¯m〉‖1. Finally, {a mathematical formula}I1γ(Δ)+I1γ(Ψ)≤(∑i=1kε_i+ε¯i)+(∑i=k+1mε_i+ε¯i)=∑i=1mε_i+ε¯i=I1γ(Γ).IC-separability: To prove that IC-separability holds, suppose there are bases {a mathematical formula}Ψ,Δ,Γ=Ψ∪Δ in {a mathematical formula}K such that {a mathematical formula}Ψ∩Δ=∅, {a mathematical formula}IC(Γ)=IC(Ψ)∪IC(Δ). Without loss of generality, let {a mathematical formula}Ψ={(φi|ψi)[q_i,q¯i]|1≤i≤k}, {a mathematical formula}Δ={(φi|ψi)[q_i,q¯i]|k+1≤i≤m} and {a mathematical formula}Γ={(φi|ψi)[q_i,q¯i]|1≤i≤m}. If {a mathematical formula}I1γ(Ψ)=∞ or {a mathematical formula}I1γ(Δ)=∞, then {a mathematical formula}I1γ(Γ)=∞ by monotonicity, and IC-separability holds, considering that ∞ plus any non-negative number yields ∞; thus, we assume {a mathematical formula}I1γ(Ψ),I1γ(Δ)&lt;∞. Let {a mathematical formula}〈ε_1,ε¯1,…,ε_k,ε¯k〉 and {a mathematical formula}〈ε_k+1,ε¯k+1,…,ε_m,ε¯m〉 be solutions (on {a mathematical formula}ε_,ε¯) to the programs in the form (A.1), (A.2), (A.3), (A.4), (A.5) that compute {a mathematical formula}I1γ(Ψ) and {a mathematical formula}I1γ(Δ), respectively, minimizing their objective functions. As all inescapable conflicts of Γ are either in Ψ or in Δ, the union of consolidations of Ψ and Δ is a consolidation of Γ, by Corollary 4.14. Hence, {a mathematical formula}〈ε_1,ε¯1,…,ε_m,ε¯m〉 correspond to a feasible solution to the program in the form (A.1), (A.2), (A.3), (A.4), (A.5) that computes {a mathematical formula}I1γ(Γ) and {a mathematical formula}I1γ(Γ)≤‖〈ε_1,ε¯1,…,ε_m,ε¯m〉‖1=(∑i=1kε_i+ε¯i)+(∑i=k+1mε_i+ε¯i)=I1γ(Ψ)+I1γ(Δ). By super-additivity, {a mathematical formula}I1γ(Γ)=I1γ(Ψ)+I1γ(Δ).  □
     </paragraph>
     <paragraph label="Proof">
      {a mathematical formula}ISSKa,sum,{a mathematical formula}ISSKa,max,{a mathematical formula}ISSKb,sumand{a mathematical formula}ISSKb,maxare continuous for probabilities within{a mathematical formula}(0,1).Consider the inconsistency measure {a mathematical formula}Ipγ defined in the proof of Theorem 5.11, the knowledge base {a mathematical formula}Γ={(φi|ψi)[q_i′,q¯i′]|1≤i≤m} and the vector {a mathematical formula}q=〈q_1,q¯1,…,q_m,q¯m〉. Note that, for any measure {a mathematical formula}Ipε, the parameters {a mathematical formula}γ_1,γ¯1,…,γ_m,γ¯m are positive (for {a mathematical formula}ISSKa,sum, {a mathematical formula}ISSKa,max, {a mathematical formula}ISSKb,sum and {a mathematical formula}ISSKb,max, they are positive if {a mathematical formula}q∈(0,1)2m). When these parameters are positive, every probability mass {a mathematical formula}π:WXn→[0,1] defines a vector {a mathematical formula}επ(q)=〈ε_1,ε¯1,…,ε_m,ε¯m〉 for each q in the following way: {a mathematical formula}ε_i=−min⁡{0,(1/γ_i)(Pπ(φi∧ψi)−q_iPπ(ψi))} and {a mathematical formula}ε¯i=max⁡{0,(1/γ¯i)(Pπ(φi∧ψi)−q_iPπ(ψi))} for every {a mathematical formula}1≤i≤m and {a mathematical formula}q∈[0,1]2m (or {a mathematical formula}q∈(0,1)2m). Note that the pair {a mathematical formula}π,επ(q) is a feasible solution to the program (A.1), (A.2), (A.3), (A.4), (A.5) that computes {a mathematical formula}Ipγ(ΛΓ(q)) for any {a mathematical formula}q∈[0,1]2m (or {a mathematical formula}q∈(0,1)2m), since {a mathematical formula}Pπ(φi∧ψi)−q_iPπ(ψi)≥−ε_iγ_i and {a mathematical formula}Pπ(φi∧ψi)−q¯iPπ(ψi)≤ε¯iγ¯i for all {a mathematical formula}1≤i≤m. Thus, every π yields a value for the objective function {a mathematical formula}hπ(q)=‖επ(q)‖ of the program (A.1), (A.2), (A.3), (A.4), (A.5), for any {a mathematical formula}q∈[0,1]2m (or {a mathematical formula}q∈(0,1)2m). As {a mathematical formula}γ_1=γ¯1=⋯=γ_m=γ¯m=1 for {a mathematical formula}Ipε and any {a mathematical formula}q∈[0,1]2m, {a mathematical formula}επ(q) is continuous on {a mathematical formula}q∈[0,1]2m, and as any p-norm is a continuous function, {a mathematical formula}hπ:[0,1]2m→[0,∞) also is for any π. (For {a mathematical formula}ISSKa,sum, {a mathematical formula}ISSKa,max, {a mathematical formula}ISSKb,sum and {a mathematical formula}ISSKb,max, {a mathematical formula}q∈(0,1)2m implies positive parameters {a mathematical formula}γ_i,γ¯i; furthermore, such parameters change continuously — linearly — with {a mathematical formula}q∈(0,1)2m. Thus, {a mathematical formula}hπ:(0,1)2m→[0,∞) is continuous on {a mathematical formula}q∈(0,1)2m). To compute {a mathematical formula}Ipγ(ΛΓ(q)) for a particular q, one needs to take the minimum in π of {a mathematical formula}{hπ(q)|π:WXn→[0,1] is a probability mass}. As the minimum of continuous functions is continuous, {a mathematical formula}Ipγ∘ΛΓ:[0,1]2m→[0,∞)∪{∞} (or {a mathematical formula}Ipγ∘ΛΓ:(0,1)2m→[0,∞)∪{∞}) is continuous for any {a mathematical formula}p∈N&gt;0∪{∞}.  □{a mathematical formula}ISSKa,sumsatisfy normalization.When we are computing {a mathematical formula}ISSKa,sum, the maximum sure loss when limiting the agent's total escrows to one. As the agent cannot lose more her total escrow in a Dutch book, {a mathematical formula}ISSKa,sum is trivially normalized.  □
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>