<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    A quality assuring, cost optimal multi-armed bandit mechanism for expertsourcing.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Nowadays, crowdsourcing has emerged as an attractive tool for various organizations to obtain the services or ideas from the Internet. These organizations post their jobs on an online platform where they can hire anonymous workers online to complete the tasks and compensate the workers suitably. Though these types of crowdsourcing practices seem to be cost effective, it is often noticed that in many situations like building of wikipedia pages, hiring of anonymous workers results in extraordinary costs. In such cases, “anti-credentialism and anonymity result in uncertainty, irresponsibility, the development of cliques and the growing importance of pseudo-legal competencies for conflict resolution” [1]. Thus, it is prudent to employ professional experts, especially for specialist tasks, rather than employ anonymous workers online.
     </paragraph>
     <paragraph>
      This work considers the problem of expertsourcing where experts are required to perform a task like developing customized software applications, technology forecasting, financial consultancy, medical image labeling and diagnosis, labeling legal documents and getting legal advice, patent search services, etc. In such expertsourcing problems, the requester (one who posts the tasks) faces many challenges. Many of these expertsourced projects are needed to be performed with high accuracy. Thus, unlike the crowdsourcing of micro-tasks, these tasks require highly skilled people in the specific domain of expertise. These experts further demand different prices for their services. These prices may depend on many parameters like their skill level, reputation, experience, or perhaps mere individual expectations.
     </paragraph>
     <paragraph>
      There are many practical examples where expertsourcing find its use. The problem of Technology Forecasting (TF) is “concerned with the investigation of new trends, radically new technologies, and new forces which could arise from the interplay of factors such as new public concerns, national policies and scientific discoveries” [2]. TF is used to take many decisions such as product development, competition, or technology investments. These forecasts are particularly helpful for end users in predicting product development, anticipate competitors' technical capabilities, and to avoid technology surprises. In such technology forecasts, accuracy plays an important role and it becomes important for the end users to know how accurate the forecasts are. Fye et al. [3], compare the expert sourcing solution with other quantitative methods for technology forecast where experts were hired to provide their opinion on an event in technology forecast. Among these opinions, an opinion with majority voting is considered. The authors found that the experts are best at predicting if an event will occur or not while other quantitative methods are best at predicting when an event will occur.
     </paragraph>
     <paragraph>
      Another example where expertsourcing finds its use is for a company which provides financial advice to its clients on whether or not to invest in a particular security. In order to provide such advice to each client, the company has a pool of financial consultants or experts. The company has two conflicting business requirements, first to keep the costs low, and second, to provide an advice that meets a minimum threshold accuracy level.
     </paragraph>
     <paragraph>
      Expertsourcing is also emerging as a useful tool in the area of healthcare services like medical diagnosis [4] or public health surveillance [5]. Medical diagnosis is an area that requires a high level of accuracy. An experiment conducted by Mavandadi et al. [4] revealed that even highly trained medical experts are not always self-consistent in their diagnostic decisions and various experts may disagree among themselves even for binary decisions (like whether a cell is infected or not). Thus, in order to improve the accuracy of diagnosis, it is often required to consult multiple medical experts and combine their decisions together using an efficient algorithm like the one proposed in [4].
     </paragraph>
     <paragraph>
      Motivated by the above examples, we consider an expertsourcing problem where a requester has a sequence of homogeneous tasks. For example, identifying whether or not human red blood cells are infected by malaria. By homogeneous tasks, we mean that the quality of any given individual expert does not change from one task to another. There is a pool of experts; each expert has different quality that is fixed but unknown. These qualities denote the skill sets of an expert, for example, in medical diagnosis, the quality depicts the probability with which an expert will provide the correct diagnosis. Each expert incurs a fixed cost to perform a task that is his private information. The quality and cost of each expert depend on the expertise and other exogenous parameters. Mavandadi et al. [4] demonstrated that combined opinion of a group of experts can significantly boost the accuracy of the final diagnostic decision as compared to the best individual of the group. Motivated by this, we aim to select a subset of the strategic experts incurring minimum total cost to achieve a desired accuracy for each task by aggregating the opinions from the selected experts, at the same time giving the correct incentives to the experts so that they report their costs truthfully. The target accuracy level parameter provides a handle on the trade-off between cost and accuracy. A high value of the target accuracy enhances the probability of getting an accurate opinion but at the same time could call for a larger number of experts, leading to increased costs. Therefore, one can choose a suitable target accuracy level depending on the task sensitivity.
     </paragraph>
     <paragraph>
      In the absence of strategic play (with known costs), the setting reduces to a machine learning problem. Though the requester can learn the qualities of the experts over a period of time by observing their performance on similar tasks, selecting a set of low quality experts repeatedly may incur significant costs. Thus, the requester faces a dilemma of exploration (learning the qualities of the experts) versus exploitation (choosing the experts optimally based on the learnt qualities). A natural solution to this problem can be explored using techniques developed for the multi-armed bandit (MAB) problems [6]. Many existing works have considered learning qualities in non-strategic crowdsourcing settings via MAB framework [7], [8]. In [9], authors have solved the problem of non-strategic expertsourcing with limited budget using techniques from MAB algorithms. However, an important new challenge in our setting is the need to ensure the accuracy constraint which in turn depends on unknown qualities. Thus, there is a need to develop a new framework to address the accuracy constraint.
     </paragraph>
     <paragraph>
      An additional challenge arises when the costs of the experts are private and they could manipulate the learning algorithm by misreporting their costs so as to benefit themselves. Thus, we have the additional task of eliciting the true costs using a suitable mechanism. Since the qualities are unknown, classical mechanism such as VCG (Vickery–Clarke–Groves) cannot be applied directly [10]. In short, we need to blend techniques from machine learning and game theory (in particular, mechanism design) that would ensure honest behavior of the experts while the requester learns the qualities. Often such mechanisms are referred to as Multi-Armed Bandit Mechanisms or simply MAB mechanisms[10], [11], [12], [13]. Previous works on MAB mechanisms, however, are not designed to achieve a target accuracy level. The MAB mechanism proposed in this paper also achieves required target accuracy level.
     </paragraph>
     <section label="1.1">
      <section-title>
       Contributions
      </section-title>
      <paragraph>
       The above discussion brings forth the need to design a new approach to solve the problem of selecting a subset of strategic experts to achieve a target accuracy level in a cost optimal way. We model this problem in the MAB mechanism framework by considering two versions: (1) a non-strategic version: the costs are known and the qualities have to be learnt and (2) a strategic version: the costs have to be truthfully elicited as well. Our specific contributions are:
      </paragraph>
      <list>
       <list-item label="•">
        We propose a novel framework, Assured Accuracy Bandit (AAB) where we formulate an optimization problem to select a cost optimal subset of experts subject to the assured accuracy constraint for each task (Section 3).
       </list-item>
       <list-item label="•">
        We provide a lower bound on the regret that any MAB algorithm in the AAB framework will suffer (Theorem 3.1).
       </list-item>
      </list>
      <paragraph>
       Non-strategic version
      </paragraph>
      <list>
       <list-item label="•">
        We design a novel algorithm, the Non-Strategic Constraint Confidence Bound (CCB-NS) for the AAB framework (Algorithm 1). Though the true qualities are not known, our algorithm guarantees that the accuracy constraint is satisfied with high probability (Theorem 4.1).
       </list-item>
       <list-item label="•">
        We provide an upper bound on the number of times the algorithm selects a suboptimal expert set for a given problem, which depends on the target accuracy level and the true qualities (Theorem 4.2). This upper bound matches the lower bound up to a constant factor.
       </list-item>
      </list>
      <paragraph>
       Strategic version
      </paragraph>
      <list>
       <list-item label="•">
        In strategic version, the experts may not report their costs truthfully; we modify the CCB-NS algorithm to an adaptive exploration separated algorithm, which we call the Strategic Constrained Confidence Bound (CCB-S) and prove that the allocation rule provided by the CCB-S is ex-post monotone (Theorem 5.2) in terms of the cost. The ex-post monotonicity facilitates existing techniques [11] to be adopted to obtain an ex-post truthful and ex-post individually rational mechanism (Corollary 5.3).
       </list-item>
       <list-item label="•">
        We extend the CCB-S algorithm as a non-exploration separated algorithm by exploiting the specific structure of a particular optimization problem. We also show the efficacy of our algorithms and compare the performance of the algorithm with that of a variant of {a mathematical formula}εt-greedy algorithm [14], through simulations (Section 6). To the best of our knowledge, the proposed mechanism is the first of its kind that has all the following features: (a) learns the qualities of strategic experts (b) elicits cost information from the experts truthfully, and (c) guarantees a specified target accuracy level for each task in a cost optimal way.
       </list-item>
      </list>
     </section>
    </section>
    <section label="2">
     <section-title>
      Related work
     </section-title>
     <section>
      <section>
       <section-title>
        Learning in crowdsourcing
       </section-title>
       <paragraph>
        A similar setting with an assured quality is considered in [15]. However, they dealt with a specific error probability function with a uniform and known cost of the experts. With multiple homogeneous quality experts, the problem of selecting an optimal cluster to satisfy accuracy constraint for a micro-task is considered in [16]. In a general setting, assumption of a cluster having sufficient number of homogeneous quality experts may not hold. Our setting is more general where an optimal subset of experts, with heterogeneous qualities, needs to be selected at one go for a given micro-task. A heterogeneous setting with experts having different costs and qualities is considered in [9], where authors designed an MAB algorithm for efficient selection of capacitated experts in the expertsourcing setting. For each task, a single non-strategic expert is selected as opposed to the subset selection of strategic experts. A model with different quality experts for each variety of task is considered in [17]. Improving the quality of answers while minimizing the cost is considered in [18]. Work in [19] considers learning a classifier while learning the qualities of the experts [20]. A Bayesian approach to learn the class label with noisy observations from experts is considered in [21]. Though, the models proposed [21], [20], [19] work well experimentally, there are no analytic guarantees on the predicted outcome. None of the above papers addresses the challenge in meeting the target accuracy level on each task in a heterogeneous, strategic cost model.
       </paragraph>
      </section>
      <section>
       <section-title>
        Mechanism design in crowdsourcing
       </section-title>
       <paragraph>
        A majority of the literature on mechanism design in crowdsourcing involves design of pricing strategies with online experts. An MAB mechanism to determine an optimal pricing mechanism for a crowdsourcing problem having homogeneous qualities within a specified budget is considered in [22]. When costs are private information, [23] proposes a posted price mechanism to elicit the true costs from the users using MAB mechanisms while maintaining a budget constraint. Mechanism design in online procurement auctions [22], [23], [24], [25] considers homogeneous quality experts. In our setting, an auction mechanism is considered to elicit the true costs from the experts with heterogeneous qualities.
       </paragraph>
       <paragraph>
        Private and strategic qualities with public costs model is considered in [26], [27]. Another line of work involves incentivizing people to work with their true qualities, when the qualities are privately held by the experts [28] in peer prediction markets. Cavallo and Jain [29] analyze crowdsourcing tasks as winner take it all auctions in game theoretic settings. They assume that only one expert gets paid and do not try to learn the qualities over period. [30], [31] adopt techniques from online mechanism design for eliciting the expert preferences but do not address the task accuracy problem.
       </paragraph>
       <paragraph>
        Mechanism design theory in crowdsourcing either elicit the costs of the experts where qualities are homogeneous and known or elicit the qualities of the experts assuming the costs to be known. Our work addresses the setting where the qualities of heterogeneous experts are to be learnt and the heterogeneous costs are to be elicited.
       </paragraph>
      </section>
      <section>
       <section-title>
        MAB algorithms
       </section-title>
       <paragraph>
        Our problem belongs to the stochastic MAB setting, where the reward of each arm is fixed but unknown. A recent survey by Bubeck and Cesa-Bianchi [32] compiles several variations on stochastic and non-stochastic MAB problems. The setting that is closest to ours is considered in [33] where a general bandit problem with concave rewards and convex constraints is solved. A specific case of this problem with linear rewards and global constraints is considered in [34]. Our problem setting is a further generalization, as the constraints in AAB are not convex. Moreover, the constraints need to be satisfied cumulatively across multiple rounds in [33] as opposed to our work, where the constraint needs to be satisfied at each round. Our learning algorithm may appear closely related to the PAC learning setting [35], [36], [37] but it differs in a subtle but important way. The solution obtained from any PAC algorithm is approximately correct with high probability after arms are pulled for a certain number of rounds, which depends on the provided approximation factor and the confidence. In our setting, the goal is to select an optimal set with high probability since a constraint needs to be satisfied with respect to stochastic qualities. Moreover, the number of exploration steps are adaptive that depends on the true qualities and the target accuracy level as opposed to the fixed number of exploration rounds in the PAC setting. The combinatorial MAB problem is further considered in many works [38], [39], [40], [41], [42] where the objective is to identify an optimal subset from given feasible subsets. However, in our setting collection of feasible sets is not given and has to be learnt over time and this makes our work different in the non-strategic setting. Problem with constraints in each round is considered in [43] but the problem of choosing a distribution over arms is considered instead of subset selection.
       </paragraph>
      </section>
      <section>
       <section-title>
        Stochastic MAB mechanisms
       </section-title>
       <paragraph>
        Multi-armed Bandit mechanisms in the forward setting as applied to sponsored search auction are recent advancements. Any deterministic truthful MAB mechanism must be exploration separated and thus the regret of any such algorithm is at least {a mathematical formula}O(T2/3) with T being the number of rounds [10], [12]. The results are also extended to multiple pull multi-armed bandits [44], [13]. However, these works do not consider combinatorial, constrained multi-armed bandit setting. A general transformation which outputs a randomized truthful mechanism with any monotone allocation rule is designed in [11]. As an application of this transformation, an MAB mechanism that is ex-post incentive compatible and ex-post individual rational with regret of {a mathematical formula}O(T1/2) is proposed. We use this transformation and propose an ex-post monotone allocation rule in the case of a reverse auction in a constrained multi-armed bandit setting. The mechanism in [45] can be translated in this setting. However, the authors considered single worker selection and do not cater to the final accuracy of the task. When the strategic agents are asked to chose the arms instead of a learning algorithm, then the problem of incentivizing the agents to explore the arms inorder to maximize the expected reward is considered in [46], [47].
       </paragraph>
       <paragraph>
        Our preliminary results in [48] considered only a certain type of error probability function. This current paper represents a significant improvement over our previous paper and the techniques developed in this paper are applicable to a general class of error probability functions.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="3">
     <section-title>
      The model
     </section-title>
     <paragraph>
      Let {a mathematical formula}N be a set of n experts available for working on T homogeneous expertsourcing tasks. Each expert i has an associated quality {a mathematical formula}qi, which is the probability that the opinion given by him is correct. The quality of any expert i is assumed to be independent of the qualities of other experts. An expert i incurs a cost {a mathematical formula}ci∈R which is privately held and can be reported strategically. Let {a mathematical formula}1−α be the target accuracy level (α is the threshold level) provided by the requester. This parameter determines the trade-off between the cost and the accuracy to be achieved for a particular task. The error on a task with inputs from the experts depends on the qualities of the experts and the rule to aggregate these opinions. We abstract this as error probability function which we describe in the following subsection.
     </paragraph>
     <section label="3.1">
      <section-title>
       Error probability function
      </section-title>
      <paragraph>
       Let {a mathematical formula}fS(q):[0,1]n→[0,1] be any error probability function (hence {a mathematical formula}(1−fS(q)) is the accuracy) when a set S is selected with quality profile {a mathematical formula}q=(q1,q2,…,qn). Our goal is to minimize the cost and at the same time satisfy the constraint that {a mathematical formula}fS(q)&lt;α where {a mathematical formula}(1−α) is the target accuracy. Depending on the aggregation rule and the requester requirements, different error probability functions could be defined. Our framework and the solution approach are general and work for any error probability function that satisfies the following properties:
      </paragraph>
      <list>
       <list-item label="•">
        Monotonicity:{a mathematical formula}fS(q) is monotone if for all quality profiles q and {a mathematical formula}q′ such that if {a mathematical formula}∀i∈N,qi′≤qi,we have,{a mathematical formula} That is, an increase in quality of each expert can only increase the accuracy or decrease the error probability.
       </list-item>
       <list-item label="•">
        Bounded smoothness:{a mathematical formula}fS(q) satisfies bounded smoothness if there exists a strictly increasing, continuous (hence, invertible) function h such that if{a mathematical formula} That is, the difference in error probability function with respect to close quality profiles is bounded by a monotone continuous function h.
       </list-item>
      </list>
      <paragraph>
       These properties are similar to the ones in [38] for reward function and are satisfied by various error probability functions.
      </paragraph>
      <paragraph label="Example 3.1">
       With majority voting rule as the aggregation rule, the average probability of error is [49]:{a mathematical formula}Here, S is the selected set with players {a mathematical formula}{1,2,…,s} with the quality profile q. For binary labeling tasks, let {a mathematical formula}y˜i∈{−1,1} are the reported labels that we get from the expert {a mathematical formula}i∈{1,2,…,s} and {a mathematical formula}y˜(S)=(y˜1,y˜2,…,y˜s) are the vector of reported labels from the experts set S. Then, the predicted label {a mathematical formula}yˆ with majority voting rule is:{a mathematical formula} One can verify that {a mathematical formula}fS(q) is monotone and satisfies bounded smoothness property. If the qualities satisfy {a mathematical formula}12+ϵ≤qi≤1∀i, then:{a mathematical formula}
      </paragraph>
      <paragraph>
       One can also define similar error probability function with other types of aggregation rules such as weighted majority voting rule which also satisfies monotonicity and bounded smoothness. In the example of software development, one can define the error probability function as the probability with which at least one code will be correct from the hired experts. It is easy to see that even this error probability function satisfies monotonicity and bounded smoothness properties. We now describe the framework with optimization problem.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Assured Accuracy Bandit (AAB) framework
      </section-title>
      <paragraph>
       Recall that a task {a mathematical formula}t∈{1,…,T} needs to be completed with an assured accuracy with the optimal cost in a sequential fashion. Hence for each task t, the following optimization problem needs to be solved.{a mathematical formula} Here, the qualities of the experts are not known a priori and hence need to be learnt by giving tasks repeatedly to the experts. Also, solving the optimization problem, the requester has to make sure that the constraint in (2) is satisfied with respect to the true qualities with high confidence. We refer to this novel framework as Assured Accuracy Bandits (AAB).
      </paragraph>
      <paragraph>
       Note that in the above optimization problem we use error probability function {a mathematical formula}fS(q). In Example 3.1 function {a mathematical formula}fS(q) gives an upper bound on the error but not the real aggregation error. Since, in order to solve the optimization problem we need a functional form on the error, we have formulated the optimization problem with respect to this upper bound and we refer to the solution of this optimization problem with respect to true qualities as the optimal solution in our paper.
      </paragraph>
      <section label="3.2.1">
       <section-title>
        Regret in AAB framework
       </section-title>
       <paragraph>
        Regret in an MAB framework is defined to be the reward difference between the learning algorithm and the optimal algorithm. We will see later that our algorithm satisfies the constraint given by (2) for each task t with probability {a mathematical formula}(1−μ), where μ is the confidence parameter with which constraint is satisfied. Let {a mathematical formula}S⁎ and {a mathematical formula}St denote the optimal set and set selected at time t respectively. Then the regret of an algorithm {a mathematical formula}A if the constraint is satisfied is given as:{a mathematical formula} Since the constraint is satisfied with probability {a mathematical formula}(1−μ):{a mathematical formula} where L is the cost that is incurred by the requester if the constraint fails to satisfy. We consider a setting with large value of L, and the requester would not want to violate the constraint. However, due to stochasticity involved in learning the qualities, there is a small probability (μ) with which the constraint can be violated. With {a mathematical formula}μ=1/T, we get:{a mathematical formula}
       </paragraph>
      </section>
     </section>
     <section label="3.3">
      <section-title>
       Lower bound on the regret
      </section-title>
      <paragraph>
       We first start with an important property called as Δ-separated property that we assume any quality profile q satisfies. The property is given as follows:
      </paragraph>
      <paragraph label="Definition 3.1">
       Δ-Separated propertyWe say that q is Δ-Separated with respect to the threshold α if {a mathematical formula}∃Δ&gt;0 such that, {a mathematical formula}Δ=infS⊆N⁡|fS(q)−α|. That is, no set of experts, S, has probability of error {a mathematical formula}fS(q)∈(α−Δ,α+Δ).
      </paragraph>
      <paragraph>
       Given a quality profile q that satisfies Δ-separated property, we now provide a lower bound on the regret that any algorithm in AAB framework has to suffer.
      </paragraph>
      <paragraph label="Theorem 3.1">
       Let{a mathematical formula}nS(A)denotes the number of times an expert set S is selected till time T by an algorithm{a mathematical formula}A. Consider any algorithm that solves the optimization problem in Equation(2)and satisfies{a mathematical formula}E[nS(A)]=o(Ta)∀a&gt;0for all subset of experts S which is not optimal. Then:{a mathematical formula}where,{a mathematical formula}Δ=infS⊆N⁡|fS(q)−α|and{a mathematical formula}h(.)is the bounded smooth function.
      </paragraph>
      <paragraph label="Proof">
       The proof follows similar steps to the proof of the lower bound for classical MAB problem [32], [6]. For {a mathematical formula}p1,p2∈[0,1], denote {a mathematical formula}kl(p1,p2) the Kullback–Leibler divergence between a Bernoulli of parameter {a mathematical formula}p1 and a Bernoulli of parameter {a mathematical formula}p2 defined as:{a mathematical formula}It is easy to see that the function {a mathematical formula}x↦kl(p1,x) is a continuous function.
      </paragraph>
      <list>
       <list-item label="•">
        Consider two experts with quality profile, {a mathematical formula}q=(q1,q2) with {a mathematical formula}f{1}(q)&lt;α&lt;f{2}(q) and {a mathematical formula}c1&gt;c2. Since, kl divergence is a continuous function and error probability function f is monotone, for any {a mathematical formula}ϵ&gt;0, one can find quality profile {a mathematical formula}q′=(q1,q2′) such that {a mathematical formula}f{1}(q′)&lt;f{2}(q′)&lt;α and {a mathematical formula}kl(q2,q2′)≤(1+ϵ)kl(q2,1−α). Thus, expert 1 is optimal with quality profile q but expert 2 is optimal with quality profile {a mathematical formula}q′. Denote {a mathematical formula}P,E as the probability, expectation taken with respect to random variables generated with quality profile q and {a mathematical formula}P′,E′ as the probability, expectation taken with respect to random variables generated with quality profile {a mathematical formula}q′.
       </list-item>
       <list-item label="•">
        Denote {a mathematical formula}X2,1,X2,2,…,X2,T as the sequence of successes obtained when allocating tasks to expert 2 where successes are coming from quality profile q. For any {a mathematical formula}t∈{1,2,…,T}, let{a mathematical formula}Also, {a mathematical formula}E[klˆn2(A)]=n2(A)kl(q2,q2′). We also have the following identity for any event B in the σ-algebra generated by {a mathematical formula}X2,1,…,X2,T:{a mathematical formula}
       </list-item>
       <list-item label="•">
        Now, consider the event {a mathematical formula}CT={n2(A)&lt;1−ϵkl(q2,q2′)ln⁡(T)andklˆn2(A)≤(1−ϵ2)ln⁡(T)}. We will prove that {a mathematical formula}P(CT)→0 as {a mathematical formula}T→∞. From Equation (5):{a mathematical formula} Let {a mathematical formula}fT=1−ϵkl(q2,q2′)ln⁡(T). Then using Markov's inequality we have,{a mathematical formula}Since there are only two experts here, {a mathematical formula}T−n2(A)=n1(A). With respect to quality profile {a mathematical formula}q′ since expert 1 is sub-optimal, we have:{a mathematical formula}Consider {a mathematical formula}a&lt;ϵ/2 then we get {a mathematical formula}P(CT)→0 as {a mathematical formula}T→∞.
       </list-item>
       <list-item label="•">
        Now, we will prove that {a mathematical formula}P(n2(A)&lt;fT)→0 as {a mathematical formula}T→∞. We have,{a mathematical formula} Using the maximal version of the strong law of large numbers and since {a mathematical formula}kl(q2,q2′)&gt;0 and {a mathematical formula}1−ϵ/21−ϵ&gt;1, we get:{a mathematical formula} Thus, from the previous point we get {a mathematical formula}P(n2(A)&lt;fT)→0 as {a mathematical formula}T→∞. Thus, we get,{a mathematical formula} Using the fact that {a mathematical formula}kl(p1,p2)≤(p1−p2)2p2(1−p2) and expert 2 is suboptimal with quality profile q we get:{a mathematical formula}
       </list-item>
       <list-item label="•">
        Since, {a mathematical formula}(1−α) is the target accuracy, {a mathematical formula}fS(1−α)=α, for any subset S. From the bounded smoothness property, {a mathematical formula}|f{2}(q)−f{2}(1−α)|≤h(q2−(1−α))⇒(q2−(1−α))2≥(h−1(|f{2}(q)−α|))2. If we choose {a mathematical formula}q1 and {a mathematical formula}q2 such that {a mathematical formula}Δ=|f{2}(q)−α| then we get {a mathematical formula}E[R](A)]&gt;(1−ϵ1+ϵ)α(1−α)ln⁡(T)(h−1(Δ))2(c2−c1), yielding the lower bound. □
       </list-item>
      </list>
      <paragraph>
       The above theorem proves that, in order to reach to the optimal solution in AAB framework, it is required to pull a sub-optimal arm at least {a mathematical formula}O(ln⁡(T)(h−1(Δ))2) number of times. Here, Δ depends on the problem instance.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Non-strategic version
     </section-title>
     <paragraph>
      In this setting, we solve the optimization problem in Equation (2) with unknown qualities and known costs. Since the experts give their opinions according to the true and unknown qualities, the constraint has to be satisfied with respect to the true qualities with high probability. Note that our algorithm works in a general setting and uses the aggregation rule as a black box.
     </paragraph>
     <paragraph label="Definition 4.1">
      AggregateAn aggregate function takes the noisy opinions of the selected set of experts as input and produces an opinion which best captures the opinion of the selected set. The aggregate function should ensure that the resulting error probability function satisfies the properties of monotonicity and bounded smoothness. For example, if the majority voting rule is used for binary labeling tasks, the aggregated label {a mathematical formula}yˆ is computed using the equation (1).
     </paragraph>
     <section label="4.1">
      <section-title>
       CCB-NS algorithm
      </section-title>
      <paragraph>
       The CCB-NS algorithm (presented in Algorithm 1) works on the principle of the UCB algorithm [14] and ensures that the constraint in (2) is satisfied with high confidence μ. Input to the algorithm is parameter α, the target accuracy (which is assumed to be same for all the tasks), the number of tasks T, the number of experts n, and confidence level μ with which the constraint in (2) is required to be satisfied. The output of the algorithm will be the subset {a mathematical formula}St and predicted opinion {a mathematical formula}yˆt for each task t. The predicted opinion {a mathematical formula}yˆt is decided based on an aggregation function (AGGREGATE) in Definition 4.1 with noisy opinions {a mathematical formula}y˜(St) collected from the expert set {a mathematical formula}St as input.
      </paragraph>
      <paragraph>
       Initially all the experts are selected to have some estimate about the qualities (Step 2). Their reported opinions are aggregated and an opinion is predicted. We assume that if the complete set of experts is selected then the accuracy is always met. This assumption implies that we have enough number of good quality experts. Next, the algorithm updates the mean quality estimates, the upper and lower confidence bounds. In certain examples like intraday trading market or in a coding project, the correct opinion or the correctness of the code is revealed immediately. In such cases, the mean quality updates can be made based on the true opinion observed. However, when there is no known ground truth, then the aggregated opinion can be assumed as the true opinion since we are assuring a high accuracy level. Note that in cases like weighted majority voting rule where a bias is used for the aggregated opinion, the error probability function is also a function of weights [49]. If the weights, in turn, depend on the unknown qualities of the experts then for our algorithm to work, the error probability function should be monotone with respect to the weights. If the error probability function is monotone with respect to the weights (which in turn depends on the qualities), then for aggregation, lower confidence bound of qualities should be used as the weights. This would ensure that the predicted label satisfies the accuracy constraint with respect to true qualities as well with high probability (due to monotonicity).
      </paragraph>
      <paragraph>
       Let {a mathematical formula}ni(t) denote the number of times the ith expert is assigned the task and {a mathematical formula}qˆi(t) denote the estimate on quality parameter {a mathematical formula}qi. Similar to the UCB algorithm [14], the algorithm maintains upper confidence and lower confidence bounds on qualities. These bounds are given as:{a mathematical formula}
      </paragraph>
      <paragraph>
       By Hoeffding's inequality, one can prove that the true quality {a mathematical formula}qi lies between {a mathematical formula}qˆi−(t) and {a mathematical formula}qˆi+(t) with probability {a mathematical formula}1−μn for any task t and for any expert i. The bounds used by UCB1 algorithm given in [14] is given by: {a mathematical formula}qˆi+(t)=qˆi(t)+2ln⁡tni(t), {a mathematical formula}qˆi−(t)=qˆi(t)−2ln⁡tni(t). Since, we want to extend the algorithm to the strategic setting, we are using a constant term {a mathematical formula}2nμ in the bounds instead of t. We initialize {a mathematical formula}qˆi+(t) and {a mathematical formula}qˆi−(t) by 1 and 0 respectively as the true qualities of the experts lie between {a mathematical formula}[0,1]. In the algorithm, we represent {a mathematical formula}qˆi, {a mathematical formula}qˆi+ and {a mathematical formula}qˆi− to be the estimates till t number of tasks. Since, the true qualities lie between upper and lower confidence bound with high probability, one can think of an algorithm that solves the optimization problem given in Equation (2) with lower confidence bound on qualities. However, this strategy will not work as high quality experts may not be explored in this approach. The key idea is, till we have identified the optimal subset of experts, we solve the optimization problem using the upper confidence bound on the qualities which gives a cost effective subset. However, this subset need not meet the desired accuracy. Hence we add another subset of the experts from the remaining experts (using subroutine MINIMAL) that combined together ensures that the target accuracy is met even when we use the lower estimates, that is {a mathematical formula}qˆ− in the constraints. The fact that {a mathematical formula}qi≥qˆi− with probability at least {a mathematical formula}1−μn and the monotonicity of the error function ensures that the target accuracy level is achieved in each round with high probability. Once the algorithm finds a subset that is optimal with respect to the upper confidence bound and achieves the target accuracy even when using the lower confidence on qualities, the algorithm stops learning and uses this set for the remaining tasks. We prove (Lemma 4.1) that this is the required optimal set with high probability. Note that, in Step 9 if the MINIMAL function cannot find a set satisfying the target accuracy level using the lower confidence bound, then it simply returns {a mathematical formula}N which meets the target accuracy level by our assumption.
      </paragraph>
      <paragraph>
       We first see that the algorithm CCB-NS satisfies the constraint at each round with high probability. Note that by Hoeffding's inequality, for each i, {a mathematical formula}qˆi−≤qi≤qˆi+ with probability {a mathematical formula}1−μn. Since the experts make error independently, we have, {a mathematical formula}∀i∈Nqˆi−≤qi≤qˆi+ with probability {a mathematical formula}(1−μn)n≥(1−μ) by Bernoulli's inequality. Thus, {a mathematical formula}∀i∈Nqˆi−≤qi≤qˆi+ with probability greater then {a mathematical formula}1−μ. For brevity of notation, in the rest of the paper we will use {a mathematical formula}qˆ−≤q≤qˆ+ to represent {a mathematical formula}qˆi−≤qi≤qˆi+∀i∈N. Thus from monotonicity of {a mathematical formula}f(.),{a mathematical formula}
      </paragraph>
      <paragraph label="Theorem 4.1">
       The CCB-NS algorithm satisfies the accuracy constraint with probability at least{a mathematical formula}(1−μ)at every round t.
      </paragraph>
      <paragraph label="Proof">
       If all the experts are selected, the constraint is always satisfied (by assumption). Now, if set {a mathematical formula}St is returned by CCB-NS, then, {a mathematical formula}fSt(qˆ−)&lt;α⇒fSt(q)&lt;α with probability {a mathematical formula}1−μ (from Equation (6)).  □
      </paragraph>
      <paragraph label="Proof">
       We now show that if the algorithm exits the while loop in Step 17 then the set {a mathematical formula}St⁎=S⁎ (the optimal set) with probability at least {a mathematical formula}1−μ. For simplicity, we assume that there exists a unique optimal set {a mathematical formula}S⁎, though the results can be easily generalized when there are multiple optimal sets. Set{a mathematical formula}St⁎returned by the CCB-NS algorithm is an optimal set with probability (w.p.) at least{a mathematical formula}1−μ. That is,{a mathematical formula}C(St⁎)=C(S⁎)w.p.{a mathematical formula}1−μ.Since {a mathematical formula}fS⁎(q)&lt;α, we have {a mathematical formula}fS⁎(qˆ+)&lt;αw.p.1−μ (from Equation (6)). As CCB-NS returns the solution {a mathematical formula}St⁎ when the constraint is satisfied with lower confidence bound, {a mathematical formula}C(St⁎)≤C(S⁎) and {a mathematical formula}fSt⁎(qˆ−)&lt;α. Thus, {a mathematical formula}fSt⁎(q)≤fSt⁎(qˆ−)&lt;α with probability at least 1−μ. Thus, {a mathematical formula}C(St⁎)=C(S⁎).  □
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Regret analysis of CCB-NS
      </section-title>
      <paragraph label="Definition 4.2">
       Non-optimal subsetAt round t, a set {a mathematical formula}St selected by the algorithm is a non-optimal subset, if {a mathematical formula}St≠S⁎.
      </paragraph>
      <paragraph label="Definition 4.3">
       Non-optimal roundA round t is a non-optimal round if the selected set {a mathematical formula}St is not the optimal set {a mathematical formula}S⁎.
      </paragraph>
      <paragraph>
       Since the algorithm selects a set which satisfies the constraint for each task with high probability, we can bound the overall regret by bounding the number of rounds in which the algorithm selects a sub-optimal set {a mathematical formula}St i.e. {a mathematical formula}C(St)&gt;C(S⁎). If {a mathematical formula}C(St)=C(S⁎), then we get zero regret for those rounds with probability {a mathematical formula}(1−μ). We will show that the number of non-optimal rounds depends on the value of Δ where {a mathematical formula}Δ=infS⊆N⁡|fS(q)−α|. The value of Δ is typically unknown to the requester since qualities are unknown but our algorithm does not require the value of Δ beforehand and thus, CCB-NS is adaptive in nature.
      </paragraph>
      <paragraph label="Lemma 4.2">
       If{a mathematical formula}∀i∈N, number of times an expert i is selected till tasks t,{a mathematical formula}ni(t)≥2(h−1(Δ))2ln⁡(2nμ), then ∀t,
      </paragraph>
      <list>
       <list-item label="1.">
        {a mathematical formula}∀S⊆N,S≠S⁎,{a mathematical formula}fS(q)&gt;α⇒fS(qˆ+)&gt;αwith probability{a mathematical formula}1−μ.
       </list-item>
       <list-item label="2.">
        {a mathematical formula}fS⁎(qˆ−)&lt;αwith probability{a mathematical formula}1−μ.
       </list-item>
      </list>
      <paragraph label="Proof">
       Let {a mathematical formula}l=2(h−1(Δ))2ln⁡(2nμ). By Hoeffding's inequality, {a mathematical formula}qˆi+−qi≤212ni(t)ln⁡(2nμ)≤212lln⁡(2nμ),∀ni(t)≥l,w.p.1−μn. Thus, {a mathematical formula}qˆi+−qi≤h−1(Δ)w.p.1−μn. Thus, {a mathematical formula}qˆ+−q≤h−1(Δ) with probability {a mathematical formula}1−μ. From bounded smoothness and monotonicity, {a mathematical formula}∀S⊆N, {a mathematical formula}fS(q)−fS(qˆ+)≤h(h−1(Δ))≤Δ and {a mathematical formula}fS(qˆ−)−fS(q)≤Δ with probability {a mathematical formula}1−μ. Thus, {a mathematical formula}fS(qˆ+)≥fS(q)−Δ and {a mathematical formula}fS⁎(qˆ−)≤fS⁎(q)+Δ. The proof statements then follows from Δ-separated property.  □
      </paragraph>
      <paragraph label="Lemma 4.3">
       If a non-optimal set{a mathematical formula}Stis selected for the task t then there exists an expert{a mathematical formula}i∈Stsuch that{a mathematical formula}ni(t)≤2(h−1(Δ))2ln⁡(2nμ)with probability{a mathematical formula}1−μ.
      </paragraph>
      <paragraph label="Proof">
       A non-optimal subset {a mathematical formula}St could be selected in two ways: (a) {a mathematical formula}fSt(qˆ+)&lt;α but {a mathematical formula}fSt(q)&gt;α or (b) {a mathematical formula}fS⁎(qˆ−)&gt;α.From Lemma 4.2, if {a mathematical formula}ni(t)≥2(h−1(Δ))2ln⁡(2nμ)∀i∈St, then, both the conditions are violated and thus a non-optimal subset is not selected. □
      </paragraph>
      <paragraph label="Proof">
       The number of non-optimal rounds by the CCB-NS algorithm is bounded by{a mathematical formula}2n(h−1(Δ))2ln⁡(2nμ)with probability{a mathematical formula}1−μ.Lemma 4.1 shows that the CCB-NS exploitation rounds are optimal rounds. A new parameter {a mathematical formula}ui(t) is associated with each expert. Whenever a set {a mathematical formula}St is selected then, {a mathematical formula}ui(t)=ui(t)+1s.ti∈Standi=arg⁡minj∈Stuj(t). Every time a non-optimal subset {a mathematical formula}St is selected, {a mathematical formula}ui(t) of only one expert is updated with the lowest value of {a mathematical formula}ui(t) so far, such that {a mathematical formula}i∈St. Thus, {a mathematical formula}ui(t)≤ni(t)∀i∈N∀t∈{1,…,T}. Thus, from Lemma 4.3, the number of exploration rounds is bounded by {a mathematical formula}2n(h−1(Δ))2ln⁡(2nμ) with probability {a mathematical formula}1−μ.  □
      </paragraph>
      <paragraph label="Corollary 4.3">
       The total expected regret is bounded by{a mathematical formula}where L is the loss incurred by the requester if the constraint is not satisfied.
      </paragraph>
      <paragraph>
       The above corollary can be obtained by substituting {a mathematical formula}μ=1/T. We see that the regret by CCB-NS algorithm matches the lower bound in AAB framework up to a constant factor. We next address the strategic version.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Strategic version
     </section-title>
     <section label="5.1">
      <section-title>
       The model
      </section-title>
      <paragraph>
       Denote the true cost of an expert i by {a mathematical formula}ci and the reported cost by {a mathematical formula}cˆi. Thus, the valuation of an expert i is {a mathematical formula}vi=−ci. We denote the requester as expert 0 and his valuation when the task is allocated to the expert set S, by:{a mathematical formula}R denotes the reward that the requester gets for satisfying the constraint and L is the loss he incurs if the accuracy constraint is not satisfied. Note that the requester is not considered to be strategic. Social welfare {a mathematical formula}W(S) is given by:{a mathematical formula}
      </paragraph>
      <paragraph>
       A mechanism {a mathematical formula}M is denoted by the pair {a mathematical formula}(A,P), where {a mathematical formula}A=(A1,A2,…,An) is the allocation vector where {a mathematical formula}Ai represents number of tasks allocated to expert i and {a mathematical formula}P=(P1,P2,…,Pn) is the payment vector where {a mathematical formula}Pi denotes the total payment made to the expert i which depends on the reported cost profile {a mathematical formula}cˆ. We work in a quasi-linear setting where the utility of every expert is given by:{a mathematical formula}
      </paragraph>
      <paragraph>
       We consider the problem where a heavy penalty is incurred for providing the wrong answer and thus, the parameter L is large.
      </paragraph>
      <paragraph>
       An important characterization for truthful mechanisms provided by Myerson [50] states that for a mechanism to be truthful, the allocation rule should be monotone in terms of reported bids by the players. Babaioff et al. [11] provide a generic transformation that takes any monotone allocation rule and outputs a mechanism which is truthful and individually rational. We can use this generic transformation to design the mechanism in our setting.
      </paragraph>
      <paragraph>
       Since there is randomness involved due to learnt qualities, let us first define every possible random seed. The random variables are the opinions provided by the experts and can affect the learnt qualities and thus the allocation rule.
      </paragraph>
      <paragraph label="Definition 5.1">
       Success realizationA success realization is a matrix {a mathematical formula}ρ∈{0,1}n×T, where each parameter {a mathematical formula}ρit is an independent Bernoulli random variable with parameter {a mathematical formula}qi. Thus, for any time t,{a mathematical formula}
      </paragraph>
      <paragraph>
       Note that depending on the allocation rule, only a part of success realization is observed, for example, if task t is given to expert i then {a mathematical formula}ρit=1 if his opinion matches with the aggregated opinion and is 0 otherwise. We now define desirable game theoretic notions in our setting. Note that, the allocation and payment rule will depend on success realizations when the true qualities are not known.
      </paragraph>
      <paragraph label="Definition 5.2">
       Ex-post incentive compatibilityA mechanism is ex-post incentive compatible if all the bidders are truthful for every success realization irrespective of the bids of other experts, i.e., {a mathematical formula}∀i∈N,∀ρ∈{0,1}n×T,∀cˆi∈[0,1],∀cˆ−i∈[0,1]n−1{a mathematical formula}
      </paragraph>
      <paragraph label="Definition 5.3">
       Ex-post individual rationalityA mechanism is ex-post individual rational if for every success realization, truth telling does not give negative utility to any player corresponding to any bids of other players,{a mathematical formula}
      </paragraph>
      <paragraph label="Definition 5.4">
       Ex-post monotone allocation ruleIf the allocation rule is monotone with respect to every success realization then we say that it is ex-post monotone, i.e., {a mathematical formula}∀i∈N,∀t∈{1,2,…,T},∀cˆi≥ci,∀ρ{a mathematical formula}
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       The CCB-S algorithm
      </section-title>
      <paragraph>
       From [50], monotonicity of an allocation rule is required for incentive compatibility. In Step 7 of CCB-NS, if the set {a mathematical formula}St does not satisfy the constraint with {a mathematical formula}qˆ−, in Step 9, we add experts to satisfy the constraint. This step does not consider strategic costs and may lead to a violation of monotonicity.
      </paragraph>
      <paragraph>
       In order to ensure truthfulness, we modify the CCB-NS algorithm to select all the experts instead of minimal set of experts, if the constraint is not satisfied with respect to the lower confidence bound (Step 9). We show that the allocation rule then becomes ex-post monotone. Thus, we can apply results from [11] to achieve an ex-post incentive compatible and ex-post individual rational mechanism. Before going to the formal analysis of CCB-S, we first formally present an important result in [11], which is relevant in our setting:
      </paragraph>
      <paragraph label="Theorem 5.1">
       [11]Let{a mathematical formula}Abe an ex-post monotone MAB allocation rule. There exists a transformation such that the mechanism{a mathematical formula}Mobtained by applying the transformation to the allocation rule{a mathematical formula}Asatisfies the following properties: (a){a mathematical formula}Mis ex-post truthful, and ex-post individually rational. (b) For each success realization, the difference in expected welfare between{a mathematical formula}Aand{a mathematical formula}Mis at most γn where{a mathematical formula}0&lt;γ&lt;1is the parameter provided to the transformation.
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Analysis of CCB-S
      </section-title>
      <paragraph>
       Note that, we cannot apply the VCG payment scheme in this algorithm as computing VCG payments requires the computation of an allocation rule in the absence of expert i which cannot be determined by the algorithm since learning stops after computing the optimal set. In order to design an ex-post incentive compatible and ex-post individual rational mechanism, we apply transformation from Theorem 5.1 and design an ex-post monotone allocation rule. We first present this transformation in the next subsection.
      </paragraph>
      <section label="5.3.1">
       <section-title>
        Generic transformation for truthful mechanisms
       </section-title>
       <paragraph>
        Note that to get the truthfulness it is sufficient to design the following payment rule for any success realization ρ if the allocation rule is monotone [50]:{a mathematical formula} The challenge here is to compute the integral as the allocation depends on how the successes are observed. To compute this integral, a sampling procedure is used. The sampling procedure takes the bids and produces two random vectors χ and ψ. The vector χ is used for determining the allocation rule and the payments are derived using the vector ψ. For deriving truthful mechanisms, we need sampling procedure to satisfy certain properties which we describe below:
       </paragraph>
       <paragraph label="Definition 5.5">
        Self-resampling procedureA self-resampling procedure with support {a mathematical formula}I=[c_i,c‾i] and resampling probability {a mathematical formula}μ∈(0,1) is a randomized algorithm that outputs random vectors {a mathematical formula}χ∈I and {a mathematical formula}ψ∈I given the input bid vector {a mathematical formula}cˆ∈I and satisfies the following properties, {a mathematical formula}∀i∈K:
       </paragraph>
       <list>
        <list-item label="1.">
         {a mathematical formula}χi(cˆi) and {a mathematical formula}ψi(cˆi) are non-decreasing functions of {a mathematical formula}cˆi.
        </list-item>
        <list-item label="2.">
         (A) With probability {a mathematical formula}(1−μ), {a mathematical formula}χi(cˆi)=ψi(cˆi)=cˆi.(B) With probability μ, {a mathematical formula}c_i≥χi(cˆi)≥ψi(cˆi)&gt;cˆi.
        </list-item>
        <list-item label="3.">
         {a mathematical formula}P[χi(cˆi)&gt;ai|ψi(cˆi)=cˆi′]=P[χi(cˆi′)&gt;ai]∀ai≥cˆi′&gt;cˆi.
        </list-item>
        <list-item label="4.">
         The function {a mathematical formula}F(ai,cˆi)=P[ψi(cˆi)&lt;ai|ψi(cˆi)&gt;cˆi] is called the distribution function of the self resampling procedure. For each {a mathematical formula}cˆi, the function {a mathematical formula}F(.,cˆi) is differentiable and strictly increasing on the interval {a mathematical formula}I∩(−∞,cˆi).
        </list-item>
       </list>
       <paragraph>
        We use the sampling procedure given in Algorithm 2.
       </paragraph>
       <paragraph label="Lemma 5.1">
        [51]The procedure inAlgorithm 2is a self-resampling procedure with distribution{a mathematical formula}F(ai,cˆi)=ai−cˆic‾i−cˆi.
       </paragraph>
       <paragraph>
        The mechanism that outputs the transformed allocation and the payment is now described in Algorithm 3.
       </paragraph>
       <paragraph label="Theorem 5.2">
        We will now show that our algorithm produces an ex-post monotone allocation rule. The allocation rule given by the CCB-S algorithm ({a mathematical formula}ACCB−S) is ex-post monotone.
       </paragraph>
       <paragraph label="Proof">
        For notation brevity, let us denote {a mathematical formula}ACCB−S by {a mathematical formula}A. In order to prove monotonicity, we need to prove the following {a mathematical formula}∀cˆi≥ci,∀ρ:{a mathematical formula} For a fixed success realization ρ, let us denote {a mathematical formula}Ait(cˆi,c−i;ρ) by {a mathematical formula}Ait(cˆi,c−i) for notation brevity. Since task {a mathematical formula}t=1 is given to all the experts irrespective of their bids, we have {a mathematical formula}Aj1(cˆi,c−i)=Aj1(ci,c−i)=1∀j∈N. Let t be the largest time step such that, ∀j, {a mathematical formula}Ajt−1(cˆi,c−i)=Ajt−1(ci,c−i)=t−1 (exploration round with {a mathematical formula}cˆi and {a mathematical formula}ci) and ∃i such that, {a mathematical formula}Ait(cˆi,c−i)≠Ait(ci,c−i).Since other costs and quality estimates are the same, this can happen only when in one case expert i is selected, while in the other case expert i is not selected. Let the two sets of experts selected with {a mathematical formula}ci and {a mathematical formula}cˆi be {a mathematical formula}S(ci) and {a mathematical formula}S(cˆi) respectively. Since the optimization problem involves cost minimization and quality updates are the same:{a mathematical formula} Since {a mathematical formula}i∉S(cˆi), the selected set {a mathematical formula}S(cˆi) satisfies the lower confidence bound too (exploitation round with bid {a mathematical formula}cˆi) and thus for the rest of the tasks, only {a mathematical formula}S(cˆi) is selected and thus we have, {a mathematical formula}Ait(cˆi,c−i)≤Ait(ci,c−i). □
       </paragraph>
       <paragraph label="Corollary 5.3">
        The transformation mechanism inAlgorithm 3is ex-post incentive compatible and ex-post individual rational mechanism[45].
       </paragraph>
      </section>
      <section>
       <section-title>
        Regret analysis
       </section-title>
       <paragraph>
        The proposed algorithm is adaptive exploration separated and the number of suboptimal rounds for CCB-S is bounded by {a mathematical formula}2(h−1(Δ))2ln⁡(2nμ). In Lemma 5.2, we prove that after {a mathematical formula}l=2(h−1(Δ))2ln⁡(2nμ) steps, there is no set S which satisfies the constraint with respect to upper confidence bound and its cost is less then the optimal cost. Moreover, after {a mathematical formula}l=2(h−1(Δ))2ln⁡(2nμ) steps, we have {a mathematical formula}fS⁎(qˆ−)&lt;α with probability {a mathematical formula}1−μ.
       </paragraph>
       <paragraph label="Lemma 5.2">
        A.1 After{a mathematical formula}l=2(h−1(Δ))2ln⁡(2nμ)number of uniform exploration rounds,
       </paragraph>
       <list>
        <list-item label="1.">
         for all sets{a mathematical formula}S≠S⁎,{a mathematical formula}fS(q)&gt;α⇒fS(qˆ+)&gt;αwith probability{a mathematical formula}1−μ
        </list-item>
        <list-item label="2.">
         {a mathematical formula}fS⁎(qˆ−)&lt;αwith probability{a mathematical formula}1−μ.
        </list-item>
       </list>
       <paragraph>
        The proof follows from Lemma 4.2 as after l uniform exploration rounds, we have {a mathematical formula}ni(t)≥l,∀i∈N.  □
       </paragraph>
       <paragraph>
        As a result of Lemma 4.1, Lemma 5.2, we have the following theorem which gives us the bound on the number of non-optimal rounds:
       </paragraph>
       <paragraph label="Proof">
        The number of non-optimal rounds of the CCB-S algorithm is bounded by{a mathematical formula}2(h−1(Δ))2ln⁡(2nμ)with probability{a mathematical formula}1−μ.
       </paragraph>
       <list>
        <list-item label="•">
         From Lemma 4.1, the CCB-S exploitation rounds are optimal rounds.
        </list-item>
        <list-item label="•">
         From Lemma 5.2, the number of exploration rounds is bounded by {a mathematical formula}2(h−1(Δ))2ln⁡(2nμ) with probability {a mathematical formula}1−μ.
        </list-item>
       </list>
       <paragraph>
        Remark (1): The number of exploration steps in algorithm CCB-S is adaptive unlike the algorithms presented in [12], [44] and bounds on the number of exploration steps depend on the parameters Δ and μ.
       </paragraph>
       <paragraph>
        Remark (2): When the value of Δ is very small compared to T i.e. {a mathematical formula}(h−1(Δ))2&lt;1Tln⁡(2nμ), then the algorithm might not converge before T time steps. In a classical MAB algorithm, for example UCB1, there is an inverse dependence on {a mathematical formula}Δ⁎ (difference between sub-optimal arm and optimal arm). If {a mathematical formula}Δ⁎ is low, then UCB1 suffers a large regret. For practical situations, where Δ is very low, the requester could provide a range for target accuracy to circumvent high regret. More details are given in Section 6.3.
       </paragraph>
       <paragraph label="Corollary 5.5">
        The total expected regret is bounded by{a mathematical formula}where L is the loss incurred by the requester if the constraint is not satisfied.
       </paragraph>
      </section>
     </section>
    </section>
    <section label="6">
     <section-title>
      Practical aspects and experimental results
     </section-title>
     <paragraph>
      Until now, our focus was on a combinatorial framework that solves a general optimization problem. A naive implementation of the CCB-NS algorithm and the CCB-S algorithm could have two problems: 1) high computational complexity of the underlying optimization problem 2) high cost of exploration for the CCB-S algorithm.
     </paragraph>
     <paragraph>
      Often, the underlying optimization problems are well studied combinatorial problems. Due to this, we may still be able to use the AAB framework to address the complexity concerns through efficient approximation algorithms that satisfy monotonicity that we define later. In this section, we consider the majority rule as the aggregation rule and solve Example 3.1 by formulating it as a minimum knapsack problem. The minimum knapsack problem is NP-hard, however, there exists polynomial time greedy approximate algorithm that yields a factor of 2 approximation for this problem.
     </paragraph>
     <paragraph>
      To ensure truthfulness, CCB-S selects all the experts in the exploration steps and this might result in very high cost when n is large. In general, it is difficult to eliminate the low quality or high cost experts due to the combinatorial nature of the problem. However, if there exists a structure to the optimization problem, it is often possible to eliminate the experts. In the approximate solution of the minimum knapsack problem, we show that it is possible to identify early and eliminate experts of high cost and low quality in the CCB-S algorithm. This elimination avoids high cost of exploration.
     </paragraph>
     <section label="6.1">
      <section-title>
       Working with approximate solutions
      </section-title>
      <paragraph>
       The key to incorporating an approximate algorithm in the AAB framework is to show its monotonicity with respect to cost. We show that the CCB-S algorithm that uses the solution returned by the monotone approximate algorithm gives a monotone allocation rule.
      </paragraph>
      <paragraph label="Definition 6.1">
       Monotone algorithmAn algorithm is said to be monotone if the allocation {a mathematical formula}A returned by the algorithm is monotone in cost i.e. if two input instances are {a mathematical formula}(c,q) and {a mathematical formula}(c+,q) such that {a mathematical formula}ci&lt;ci+, for some i and {a mathematical formula}cj=cj+∀j≠i, then {a mathematical formula}Ai(c+,q)=1⇒Ai(c,q)=1.
      </paragraph>
      <paragraph label="Definition 6.2">
       {a mathematical formula}(β,γ) Approximate algorithmAn algorithm is said to be a {a mathematical formula}(β,γ) approximate algorithm, if for some {a mathematical formula}β≥1 and {a mathematical formula}γ≤1, the solution set S returned by the algorithm is such that {a mathematical formula}P[C(S)≤βC(S⁎)]≥γ. Here, {a mathematical formula}S⁎ is the solution returned by optimal algorithm.
      </paragraph>
      <paragraph label="Proposition 6.1">
       If there exists a{a mathematical formula}(β,γ)approximation algorithm that is monotone, then, incorporating that{a mathematical formula}(β,γ)approximation scheme in the CCB-S algorithm will result in an ex-post monotone allocation rule.
      </paragraph>
      <paragraph>
       This is easy to see from Theorem 5.2. Note that, all the experts are selected in the exploration rounds, and in exploitation rounds, if an expert i is selected with a certain cost, he will also be selected with a lower cost due to the monotonicity property of the approximate algorithm.
      </paragraph>
      <paragraph>
       Note: One can define the approximate notion of regret in this setting by incorporating the approximation factors β and γ similar to the notion defined in [52]. We define this notion for the specific example of minimum knapsack problem in the next section.
      </paragraph>
      <paragraph>
       We now present an example of the minimum knapsack optimization problem and a greedy solution of the problem. In the greedy solution, it is possible to eliminate the experts without violating monotonicity condition, thus, avoiding high cost of exploration. We present the elimination strategy for this example.
      </paragraph>
     </section>
     <section label="6.2">
      <section-title>
       An illustrative example with low regret
      </section-title>
      <paragraph>
       From Example 3.1, if all the experts have qualities of at least {a mathematical formula}23, i.e. {a mathematical formula}qi&gt;2/3 and {a mathematical formula}ϵ=1/6, then the optimization problem of minimizing cost and satisfying the accuracy constraint of α can be formulated as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       This turns out to be the minimum knapsack problem when {a mathematical formula}ci≥0 and {a mathematical formula}2qi−1≥0∀i. Denote {a mathematical formula}ai=2qi−1 and {a mathematical formula}M=6ln⁡(1α), we have the following optimization problem:{a mathematical formula}
      </paragraph>
      <section label="6.2.1">
       <section-title>
        Greedy algorithm (GA)
       </section-title>
       <paragraph>
        The minimum knapsack problem has a greedy deterministic algorithm which gives a {a mathematical formula}(2,1)-approximate solution [53]. The algorithm denoted by GA is described in Algorithm 4:
       </paragraph>
       <paragraph label="Lemma 6.1">
        [53]. Let,{an inline-figure}and{a mathematical formula}S⁎be the solutions returned by the algorithm GA and optimal algorithm respectively. The greedy algorithm GA gives a solution which is{a mathematical formula}(2,1)-approximate i.e.{an inline-figure}
       </paragraph>
       <paragraph label="Lemma 6.2">
        The allocation rule given by greedy algorithm is monotone in cost i.e. if expert i gets a task with cost{a mathematical formula}ci, he also gets a task with cost{a mathematical formula}ci−when the costs and the qualities of the other experts are fixed and{a mathematical formula}ci−&lt;ci.
       </paragraph>
       <paragraph label="Proof">
        Let expert i be selected with the cost {a mathematical formula}ci. Call the sets {a mathematical formula}S0,S1,…,Sq as small sets and the elements of these sets as small elements since the constraint is not satisfied with these elements. Similarly, the sets {a mathematical formula}B0,B1,…,Bq are called as big sets and the elements of these sets are called as big elements. Let the set returned by the algorithm be {a mathematical formula}S0∪S1∪…∪Sq∪{j} where, {a mathematical formula}j∈Bq with cost {a mathematical formula}ci. Now, consider following cases:
       </paragraph>
       <list>
        <list-item label="1.">
         With cost {a mathematical formula}ci, expert i belongs to set {a mathematical formula}Sl where {a mathematical formula}l≤q: Now consider the following cases when the cost of expert i is decreased from {a mathematical formula}ci to {a mathematical formula}ci−:
        </list-item>
        <list-item label="2.">
         With cost {a mathematical formula}ci, expert {a mathematical formula}j=i. Thus, i is a big element with cost {a mathematical formula}ci. Again, consider the following cases when expert i changes his bid to {a mathematical formula}ci−:
        </list-item>
       </list>
      </section>
      <section label="6.2.2">
       Elimination strategy with greedy algorithm GA
       <paragraph>
        We now provide an algorithm with elimination strategy where all the experts need not be selected in exploration rounds. We call this strategy as CCB-SE and is provided in Algorithm 5.
       </paragraph>
       <paragraph>
        The algorithm CCB-SE maintains an active set denoted by {an inline-figure}. For a task t, we first solve the optimization problem with respect to upper confidence bound by calling the Greedy algorithm. We then check if the constraint is satisfied with respect to lower confidence bound or not. If the constraint is satisfied with LCB then we return the selected set for all the future rounds. However, if the constraint is not satisfied then we call the greedy algorithm with respect to lower confidence bounds and eliminate experts intelligently. If for some task t, the set {a mathematical formula}St is selected by the algorithm, then the set {a mathematical formula}St satisfies the constraint with respect to the lower confidence bounds (since the algorithm GA is called with respect to lower confidence bounds). Let us assume that the set returned by algorithm GA with lower confidence bound is denoted by {an inline-figure}. Further, if there exists an expert {an inline-figure} such that {a mathematical formula}ckaˆk−≤craˆr+ and {an inline-figure}, then expert r can be discarded “safely”. By safely, we mean that with qualities known perfectly, GA algorithm has a candidate solution of cost less than or equal to any candidate solution containing r with probability {a mathematical formula}(1−μ) and there is no need to consider expert r for the future tasks. In the next Lemma, we prove the correctness of CCB-SE.
       </paragraph>
       <paragraph label="Proof">
        If an expert r does not belong to{an inline-figure}for some task t in CCB-SE, then, with known qualities, GA algorithm has a candidate solution of cost less than or equal to any candidate solution containing r with probability{a mathematical formula}(1−μ).With true qualities, in GA algorithm, the elements {a mathematical formula}1,…,k precedes r due to {a mathematical formula}ckaˆk−≤craˆr+ with probability {a mathematical formula}(1−μ).As {a mathematical formula}{1,…,k} meets the accuracy constraint with LCB, they meet it with true qualities also (with high probability). Therefore, there exists a {a mathematical formula}p∈{1,…,k}, which belongs to a big set in the run of GA with true qualities. Any candidate set with p in the run will be of the form {a mathematical formula}∪i=1qSi∪{p}. Any candidate set with r will be of the form {a mathematical formula}∪i=1lSi∪{r} with {a mathematical formula}l≥q. Therefore, in the run of GA, we can ignore any candidate solutions with r and hence r can be dropped safely. This is because {a mathematical formula}C(∪i=1qSi∪{p})≤C(∪j=1lSj∪{r}) as {a mathematical formula}∪i=1qSi⊆∪j=1lSj and {a mathematical formula}cp≤cr. □
       </paragraph>
       <paragraph label="Proof">
        CCB-SE produces monotone allocation rule.In the exploration phase, if the expert i reduces his cost, he can be eliminated at a later stage only. Thus the number of allocations in the exploration phase increases. In exploitation phase, the monotonicity is immediate from Lemma 6.2. □
       </paragraph>
      </section>
      <section label="6.2.3">
       <section-title>
        Regret analysis of CCB-SE
       </section-title>
       <paragraph label="Definition 6.3">
        Since, with known qualities also we will solve the optimization problem in the approximate sense, we first define the approximate regret in this setting. Approximate regret of CCB-SEThe approximate regret of CCB-SE when the accuracy constraint is satisfied with probability at least μ is given as:{a mathematical formula} where {a mathematical formula}S⁎ is the optimal set with minimum cost and L is the loss incurred by the requester if the constraint is not satisfied.
       </paragraph>
       <paragraph label="Proof">
        We now have the following theorem that bounds the approximate regret of CCB-SE The approximate regret of CCB-SE is bounded by{a mathematical formula}Let the subset selected with quality profile q by GA algorithm be denoted by {a mathematical formula}SGA(q) and the optimal subset with quality profile {a mathematical formula}qˆ+ be {a mathematical formula}S⁎(qˆ+). Let the optimal subset with true qualities be denoted by {a mathematical formula}S⁎. If the algorithm goes inside the If loop for task {a mathematical formula}t⁎ in Step 9, then we prove that {a mathematical formula}C(St⁎)≤2C(S⁎). From, Lemma 6.3, we never eliminate the worker that can be a part of GA algorithm with respect to true qualities i.e. {an inline-figure}. We ensure this by ensuring that we never eliminate the worker that is a part of GA algorithm with respect to UCB on qualities. Thus we also have {an inline-figure}. By the property of GA algorithm, we also have {a mathematical formula}C(SGA(qˆ+))≤2C(S⁎(qˆ+)). And by monotonicity of error probability function we have {a mathematical formula}C((S⁎(qˆ+))≤C(S⁎). Since the constraint is satisfied with respect to UCB by {a mathematical formula}St⁎, we have {a mathematical formula}St⁎=SGA(qˆ+). Thus, {a mathematical formula}C(St⁎)≤2C(S⁎(qˆ+))≤2C(S⁎). Thus, it is enough to bound the number of tasks {a mathematical formula}t⁎. One can bound {a mathematical formula}t⁎ using the similar steps as is done in Theorem 4.2. Note that since we are eliminating the experts, the CCB-SE is uniform exploration algorithm with elimination. Thus, similar to strategic setting, in the regret expression n does not appear in the numerator.  □
       </paragraph>
      </section>
     </section>
     <section label="6.3">
      <section-title>
       Simulation results
      </section-title>
      <paragraph>
       We now compare the efficacy of the proposed algorithms via simulations. We use the minimum knapsack problem described in the previous section solved using GA algorithm. We compare the regret of four algorithms namely, CCB-NS, CCB-S, CCB-SE and a variant of the {a mathematical formula}εt-greedy algorithm. The {a mathematical formula}εt-greedy algorithm [14] solves the classical multi-armed bandit problem which involves the selection of the single best arm. In the classical version, a random arm is explored with probability {a mathematical formula}εt and the optimal arm (with the highest empirical mean) is selected with probability {a mathematical formula}1−εt. We extend the algorithm to the AAB setting by exploring all the experts with probability {a mathematical formula}εt and selecting minimum cost expert subset meeting the constraint with empirically estimated qualities with probability {a mathematical formula}(1−εt). The parameter {a mathematical formula}εt=min⁡{1,100t} decreases with time to give more weight to exploitation than exploration. Note that, the {a mathematical formula}εt algorithm is not strategyproof.
      </paragraph>
      <paragraph>
       In the simulations, we have selected the number of experts to be 1100. To emphasize the fact that the CCB-SE algorithm identifies bad experts early, out of the 1100 experts, 600 experts are chosen with cost as 20 and quality as 2/3 whereas, the other 500 experts are chosen with the costs uniformly drawn between 10 and 20 and the quality uniformly drawn between 2/3 and 1. The required target accuracy is chosen to be 0.9 with {a mathematical formula}α=0.1. Since the value of Δ can be arbitrarily low, we adopt the following strategy for the implementation. We solve the optimization problem with UCB for a target accuracy of 0.95 but check the lower confidence bound with target accuracy 0.9. This ensures that the constraint is never violated, however, it may result in extra cost of experts for the rest of the rounds. Since the costs of the experts are not adversarially chosen, the expected difference between the optimal set with accuracy 0.9 and 0.95 is not large. In general, if the requester gives a target accuracy range of {a mathematical formula}(1−α,1−α+ξ) such that the upper confidence bound is solved using accuracy {a mathematical formula}1−α+ξ but the lower bound is checked with accuracy {a mathematical formula}1−α, then it is possible to control the number of non-optimal rounds and it can be shown that the number of non-optimal rounds is at most {a mathematical formula}min⁡(116(h−1(ξ))2ln(2nμ),2(h−1(Δ))2ln(2nμ)). In the {a mathematical formula}εt-greedy algorithm, the expert set is chosen such that the target accuracy of 0.9 is achieved with respect to the estimated qualities. For simulations, we have chosen T to be 10{sup:4}. However, if T is large, one can choose a smaller value of ξ. Over 1200 runs of simulations, we observed that none of the four algorithms violated the stochastic constraint with respect to the true qualities. With {a mathematical formula}ξ=0.05, the comparison of the average regret and the negative social welfare is given in Figs. 1a and 1b respectively. The regret is compared against the greedy solution returned by GA algorithm with true qualities. We ran 1000 samples to generate the graphs. We see that the algorithm CCB-NS converges much faster when compared to the {a mathematical formula}εt-greedy algorithm. We also see that the cost of CCB-SE algorithm reduces significantly in a few iterations only. We also compare the total cost between CCB-NS algorithm and {a mathematical formula}εt-greedy algorithm with change in the number of experts (Fig. 1c). The simulations show that the CCB-NS algorithm outperforms the {a mathematical formula}εt-greedy algorithm even when there are fewer number of experts.
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Summary and future work
     </section-title>
     <paragraph>
      We considered the problem of selecting an optimal subset of the experts so as to ensure a certain target accuracy for each task. We proposed a novel framework, Assured Accuracy Bandit (AAB) and developed an algorithm, Strategic Constrained Confidence Bound (CCB-S) for the same, which also leads to an ex-post incentive compatible and ex-post individually rational mechanism. We have provided bounds on the number of exploration steps that depends on the target accuracy level and the true qualities. Often, the optimization problem to be solved for each task inherently has exponential time complexity. In most cases, there exist efficient approximate algorithms for solving the optimization problem. If these algorithms are monotone, then the algorithms can be combined with CCB-S algorithm to provide a truthful, IR mechanism.
     </paragraph>
     <paragraph>
      An interesting line of future research could be to improve the convergence rate of CCB-S. The slow convergence of CCB-S can be attributed to the algorithm being exploration separated. If there exists a structure to the algorithm for solving the combinatorial optimization problem, then some strategy for eliminating experts in the strategic setting can be adapted. We have seen a strategy in one example. A generalization of this to all possible optimization problem may require more assumption on the function {a mathematical formula}fS(q) and forms an interesting future direction. Working with soft constraint formulation of this problem forms another extension for the future.
     </paragraph>
    </section>
   </content>
  </root>
 </body>
</html>