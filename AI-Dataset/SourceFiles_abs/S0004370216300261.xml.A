<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    One-pass AUC optimization.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      The Area Under the ROC (Receiver Operating Characteristics) Curve, or simply AUC [22], [37], has been an important performance measure in many learning tasks such as class-imbalanced learning, cost-sensitive learning, information retrieval, etc., [10], [15], [34], [40]. AUC is preferable to accuracy as an evaluation measure in various real applications. For example, some categories may have more instances than others in class-imbalanced tasks such as face detection and collaborative filtering, and the level of imbalance (ratio of size of majority category to minority category) can be as high as 10{sup:6}[49]; therefore, accuracy is not suitable in such cases since the majority classifier will always perform well in terms of accuracy. AUC has also been used to measure the quality of ranking positive instances over negative ones for information retrieval and ranking problems. Many approaches have been developed to optimize AUC [17], [24], [29], [31], [42], [52].
     </paragraph>
     <paragraph>
      In this work, we focus on AUC optimization that requires only one pass over training examples with storage independent of the data size. This is particularly important for applications involving big data or streaming data in which a large volume of data arrives in a short time period, making it infeasible to store the entire dataset in memory before an optimization procedure is applied. Although many online learning algorithms have been developed to find the optimal solution for certain performance measures by scanning the training data only once [8], few efforts address one-pass AUC optimization.
     </paragraph>
     <paragraph>
      Unlike the classical classification and regression problems where the loss function can be calculated on a single training example, AUC is measured by the losses defined over pairs of instances from different classes, making it challenging to develop algorithms for one-pass optimization. An online AUC optimization algorithm was proposed by Zhao et al. [52]. It is based on the idea of reservoir sampling, and achieves a regret bound by storing {a mathematical formula}T instances, where T is the number of training examples. Wang et al. [47] suggested an online learning algorithm with fixed-size buffer via a FIFO strategy, while Kar et al. [30] made use of the reservoir idea and replacement-subsampling technique to develop another online algorithm for pairwise loss functions. Ideally, for one-pass approaches, the storage required by the learning process should be independent of the amount of training data, which is the goal of this work.
     </paragraph>
     <section label="1.1">
      <section-title>
       Our contributions
      </section-title>
      <paragraph>
       This work develops the one-pass AUC algorithms, and verifies the effectiveness of the proposed algorithms both theoretically and empirically. The main contributions can be summarized as follows:
      </paragraph>
      <list>
       <list-item label="•">
        We propose a regression-based algorithm for one-pass AUC optimization where the least square loss is used to measure the ranking error between two instances from different classes. The main advantage of using the least square loss lies in the fact that we only need to store the first and second-order statistics over the received training examples. Consequently, the storage requirement is reduced to {a mathematical formula}O(d2), where d is the dimension of data, independent of the number of training examples.
       </list-item>
       <list-item label="•">
        For high-dimensional dense data, we make use of the frequent direction algorithm [33] to approximate the covariance matrix by a low-rank matrix. For high-dimensional sparse data, we introduce another deterministic algorithm, called sparse matrix algorithm, where the basic idea is to approximate the covariance matrix by a sparse matrix that nullifies smaller elements.
       </list-item>
       <list-item label="•">
        Theoretically, the pairwise least square loss is proved to be consistent with AUC in finite instance spaces. Then, we present regret bounds with respect to pairwise least square loss when the covariance matrices are provided and approximated, respectively. Finally, we present new generalization and online-to-batch bounds for the proposed algorithms.
       </list-item>
       <list-item label="•">
        Extensive experiments show the effectiveness of the proposed methods.
       </list-item>
      </list>
      <paragraph>
       A preliminary version of this work appeared in a conference paper [17]. Compared with the original version, we introduce two new approaches for high-dimensional tasks, i.e., the frequent direction [33] and the sparse approach are proposed to approximate the covariance matrices for dense and sparse datasets, respectively. We also give new regret, generalization and online-to-batch bounds for the proposed algorithms, and present better empirical performance.
      </paragraph>
     </section>
     <section label="1.2">
      <section-title>
       Related work
      </section-title>
      <paragraph>
       The study of AUC dates back to the 1970s in signal detection theory [13]. AUC has been an important measure used in the machine learning literature [9], [10], [14], [15], [20], [27], [39], [40]. AUC can be estimated under parametric [53], semi-parametric [26] or non-parametric [21] settings. The non-parametric estimation of AUC has been popular in machine learning since it is equivalent to the Wilcoxon–Mann–Whitney (WMW) statistic test of ranks [21].
      </paragraph>
      <paragraph>
       Various algorithms have been developed to optimize AUC, such as boosting [16], [42], SVM [7], [28], [29], and a gradient descent algorithm [24]. Moreover, Kotlowski et al. [31] studied the use of univariate losses and Zhao et al. [52] proposed the first online algorithm for AUC optimization. All those approaches require to store the entire or partial training data and scan the data multiple times.
      </paragraph>
      <paragraph>
       Much theoretical work has been devoted to understanding the generalization of AUC approaches [2], [3], [9], [11], [30], [42], [46], [47]. Agarwal and Roth [4] presented separately a sufficient and necessary condition for AUC learnability. Gao and Zhou [18] further proved stability as an equivalent condition. The consistency of AUC pairwise and univariate optimization has been studied in [19], [36] and [1], [31], respectively.
      </paragraph>
     </section>
     <section label="1.3">
      <section-title>
       Organization
      </section-title>
      <paragraph>
       Section 2 introduces some preliminaries. Sections 3 proposes the OPAUC (One-Pass AUC) framework. Section 4 presents the approximated OPAUC approaches for high-dimensional tasks. Section 5 provides theoretical justifications. Section 6 gives detailed proofs. Section 7 shows extensive experiments, and Section 8 concludes this work.
      </paragraph>
     </section>
    </section>
    <section label="2">
     <section-title>
      Preliminaries
     </section-title>
     <paragraph>
      Let {a mathematical formula}X⊂Rd and {a mathematical formula}Y={+1,−1} be the instance and label space, respectively. Denote {a mathematical formula}D by an unknown (underlying) distribution over the product space {a mathematical formula}X×Y. Let {a mathematical formula}S={(x1,y1),(x2,y2),…,(xT,yT)} be a training sample, where each element is drawn identically and independently (i.i.d.) from distribution {a mathematical formula}D. For an integer {a mathematical formula}n&gt;0 and a real {a mathematical formula}α&gt;0, let {a mathematical formula}[n]={1,2,…,n}, and denote {a mathematical formula}⌊α⌋ by the largest integer which is no more than α. For a set {a mathematical formula}A, let {a mathematical formula}|A| denote its cardinality.
     </paragraph>
     <paragraph>
      Let {a mathematical formula}f:X→R be a real-valued function. Given a sample {a mathematical formula}S, the AUC of function f is defined as{a mathematical formula} where {a mathematical formula}I[⋅] is the indicator function which returns 1 if the argument is true and 0 otherwise. Here{a mathematical formula}
     </paragraph>
     <paragraph>
      Direct optimization of AUC often yields an NP-hard problem since it can be cast into a combinatorial optimization problem. A feasible solution in practice is to optimize some pairwise surrogate losses as follows:{a mathematical formula} where {a mathematical formula}ℓ:R→R+ is a convex function such as exponential loss {a mathematical formula}ℓ(t)=e−t, hinge loss {a mathematical formula}ℓ(t)=max⁡(0,1−t), logistic loss {a mathematical formula}ℓ(t)=log⁡(1+e−t), etc. The loss function {a mathematical formula}ℓ(yi(f(xi)−f(xj)) is also called pairwise surrogate loss since it involves two instances from different classes.
     </paragraph>
     <paragraph>
      Any distribution {a mathematical formula}D can be specified exactly by the triplet {a mathematical formula}(D+,D−,p) as in [36], where {a mathematical formula}D+(x)=Pr⁡[x|y=+1], {a mathematical formula}D−(x)=Pr⁡[x|y=−1] and {a mathematical formula}p=Pr⁡[y=+1]. The expectation over {a mathematical formula}S can be further decomposed into an expectation over random draws of {a mathematical formula}TS+ and {a mathematical formula}TS− from Binomial({a mathematical formula}T,p), followed by an expectation over draw of samples from {a mathematical formula}D+ and {a mathematical formula}D−, respectively. Based on this decomposition, we have
     </paragraph>
     <paragraph label="Proposition 1">
      Define the surrogate loss{a mathematical formula}L(f,D)=ES[L(f,S)]with respect to distribution{a mathematical formula}D. We have{a mathematical formula}{a mathematical formula}
     </paragraph>
     <paragraph>
      The detailed proof is given in Section 6.1.
     </paragraph>
     <paragraph>
      Many learning approaches and studies fall into this formulation [2], [7], [10], [24], [42]. There has been previous work of [30], [47], which considered the following formulation:{a mathematical formula} Notice that{a mathematical formula} Thus, our formulation is different from the work of [30], [47]. Ying and Zhou [50] considered the least square loss as surrogate loss and presented an online pairwise algorithm with kernels. However, this work requires to store the entire training sample for kernel tricks and follows the optimization formulation (given by Eqn. (3)) as in the work of [30], [47].
     </paragraph>
    </section>
    <section label="3">
     <section-title>
      OPAUC
     </section-title>
     <paragraph>
      To address the challenge of one-pass AUC optimization, we propose to use the least square loss {a mathematical formula}ℓ(t)=(1−t)2, and focus on a linear space {a mathematical formula}W⊆Rd. Given a sample {a mathematical formula}S, we consider the following pairwise least square loss:{a mathematical formula} where λ is a regularization parameter that controls the model complexity, and the constant 1/2 is introduced for simplicity. Further, we define the pairwise least square loss with respect to distribution {a mathematical formula}D as{a mathematical formula}
     </paragraph>
     <paragraph>
      The main advantage of using the least square loss lies in the fact that it is sufficient to store the first and second-order statistics over training examples for optimization, leading to a memory requirement of {a mathematical formula}O(d2), which is independent of the number of training examples. Another advantage is that the least square loss is consistent with AUC in finite instance spaces (Theorem 1 in Section 5), whereas loss functions such as hinge loss are proven to be inconsistent with AUC [19].
     </paragraph>
     <paragraph label="Proposition 2">
      In the online/stochastic setting, we will optimize a variant of the objective in Eqn. (4) that can be written as a sum of losses for individual training instance{a mathematical formula} It is easy to see that {a mathematical formula}Lt(w) is an unbiased estimator of {a mathematical formula}L(w,D) by the following proposition. The detailed proof is given in Section 6.2. We have{a mathematical formula}L(w,D)=E(x1,y1),…,(xt,yt)∼Dt[Lt(w)].
     </paragraph>
     <paragraph>
      Another main difference from [30], [47] is the normalization term {a mathematical formula}|{i∈[t−1]:yiyt=−1}|, which is dependent on the received data {a mathematical formula}St, and it is essential to the derivations of first and second-order statistics. In [30], [47], however, this normalization term is fixed by {a mathematical formula}1/t, which is only dependent on the time step t.
     </paragraph>
     <paragraph>
      Let {a mathematical formula}Tt+ and {a mathematical formula}Tt− denote the cardinalities of positive and negative instances in {a mathematical formula}St, respectively. Further, we define {a mathematical formula}Lt(w)=0 for {a mathematical formula}Tt+Tt−=0. If {a mathematical formula}yt=1, we calculate the gradient as{a mathematical formula} It is easy to observe that{a mathematical formula} correspond to the mean and covariance matrix of negative instances, respectively; therefore, Eqn. (6) can be further simplified as{a mathematical formula} In a similar manner for {a mathematical formula}yt=−1, we calculate the following gradient:{a mathematical formula} where{a mathematical formula} denote the mean and covariance matrix of positive instances, respectively.
     </paragraph>
     <paragraph>
      The storage cost for keeping the class means ({a mathematical formula}ct+ and {a mathematical formula}ct−) and covariance matrices ({a mathematical formula}St−1+ and {a mathematical formula}St−1−) is {a mathematical formula}O(d2). Once we compute the gradient {a mathematical formula}∇Lt(w), by the theory of gradient descent, the classifier can be updated by{a mathematical formula} where {a mathematical formula}ηt is the stepsize in the t-th iteration.
     </paragraph>
     <paragraph>
      Algorithm 1 presents a generic algorithm, which highlights the key steps. We initialize {a mathematical formula}Γ0−=Γ0+=[0]d×d, where {a mathematical formula}u=d. At each iteration, we denote {a mathematical formula}Γt+=St+ and {a mathematical formula}Γt−=St−. In Line 6, we update {a mathematical formula}Γt−=Γt−1− and{a mathematical formula} whereas in Line 11, we update {a mathematical formula}Γt+=Γt−1+ and{a mathematical formula} Finally, the gradient {a mathematical formula}gˆt(wt−1) of Lines 7 and 12 in Algorithm 1 are given by {a mathematical formula}∇Lt(wt−1) that are calculated by Eqs. (7) and (8), respectively.
     </paragraph>
     <paragraph>
      Notice that {a mathematical formula}Γt+=St+ and {a mathematical formula}Γt−=St− are only specific to this section. Throughout this work, {a mathematical formula}St+ and {a mathematical formula}St− denote the covariance matrices of positive and negative instances, respectively, whereas {a mathematical formula}Γt+ and {a mathematical formula}Γt− take different values for different approximation algorithms in Section 4.
     </paragraph>
    </section>
    <section label="4">
     <section-title>
      Handling high dimensions
     </section-title>
     <paragraph>
      One limitation of the OPAUC algorithm is the {a mathematical formula}O(d2) storage for two covariance matrices {a mathematical formula}St+ and {a mathematical formula}St−, making it unsuitable for high-dimensional data. A natural idea is to first project the high-dimensional data into a low-dimensional space by dimensionality reduction (PCA, hashing, random projection, etc.), and then apply the OPAUC algorithm. This strategy, however, does not work empirically (Section 7) because much information is lost in dimensionality reduction.
     </paragraph>
     <paragraph>
      Let {a mathematical formula}Xt+ and {a mathematical formula}Xt− denote the matrices of positive and negative instances in {a mathematical formula}St={(x1,y1),(x2,y2),…,(xt,yt)}, respectively. Then, we have{a mathematical formula} Therefore, it suffices to approximate {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤ since we can store the class means {a mathematical formula}ct+ and {a mathematical formula}ct− in memory. In this section, we will introduce two deterministic methods to approximate covariance matrices for high-dimensional dense and sparse tasks, respectively.
     </paragraph>
     <section label="4.1">
      <section-title>
       High-dimensional dense data
      </section-title>
      <paragraph>
       For high-dimensional dense data, we make use of the frequent direction method [33] to approximate the covariance matrices, because this method works well in practice, and takes faster convergence rate for approximation error than random projection, hashing, etc. The basic idea is to maintain two {a mathematical formula}d×τ sketch matrices {a mathematical formula}Zt+ and {a mathematical formula}Zt−, and use {a mathematical formula}Zt+[Zt+]⊤ and {a mathematical formula}Zt−[Zt−]⊤ to approximate {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤, respectively. Here τ is the sketch size.
      </paragraph>
      <paragraph>
       More specifically, we receive an example {a mathematical formula}(xt,yt) in the t-th iteration, and assume {a mathematical formula}yt=+1 (a similar procedure works for {a mathematical formula}yt=−1). If there are unfilled columns in {a mathematical formula}Zt+, then we add {a mathematical formula}xt as a column vector to {a mathematical formula}Zt+; otherwise, we nullify half of the columns in {a mathematical formula}Zt+ and then add {a mathematical formula}xt as the {a mathematical formula}⌊τ/2⌋+1 column in {a mathematical formula}Zt+. The nullification procedure can be decomposed as (i) apply singular value decomposition (SVD) to compute the singular values and vectors of {a mathematical formula}Zt+, and (ii) ‘shrink’ columns such that at least half of columns in {a mathematical formula}Zt+ are zeros and therefore open to be filled.
      </paragraph>
      <paragraph>
       Algorithm 2 presents a description of frequent direction. Let {a mathematical formula}SVD(Z)=[U,Σ,V] be the singular value decomposition, i.e., {a mathematical formula}Z=UΣV⊤, {a mathematical formula}U⊤U=Id, {a mathematical formula}V⊤V=Iτ, and Σ is a rectangular diagonal matrix of size {a mathematical formula}d×τ with nonnegative diagonal elements {a mathematical formula}σ1,σ2,…,στ in non-increasing magnitude order. Here, {a mathematical formula}Iτ and {a mathematical formula}Id denote the identity matrix of size {a mathematical formula}τ×τ and {a mathematical formula}d×d, respectively. Let {a mathematical formula}Id×τ denote a rectangular diagonal matrix whose diagonal elements are all 1. To shrink at least half of columns of Z, we set {a mathematical formula}Σˆ=(max⁡(Σ2−Id×τσ⌊τ/2⌋2,[0]d×τ))1/2 and output {a mathematical formula}UΣˆ. Here {a mathematical formula}[0]d×τ denotes an {a mathematical formula}d×τ matrix of zeros and {a mathematical formula}max⁡(⋅) denotes an element-wise maximum. Algorithm 2 outputs {a mathematical formula}UΣˆ rather than {a mathematical formula}UΣˆV⊤ since we have, by {a mathematical formula}V⊤V=Iτ,{a mathematical formula} Moreover, the matrix {a mathematical formula}UΣˆ maintains at least half of zero columns.
      </paragraph>
      <paragraph>
       Let {a mathematical formula}Zt+ and {a mathematical formula}Zt− be updated according to Algorithm 2, and we approximate covariance matrices {a mathematical formula}St+ and {a mathematical formula}St− by{a mathematical formula}{a mathematical formula} Based on approximated covariance matrices {a mathematical formula}Sˆt+ and {a mathematical formula}Sˆt−, the online optimization algorithm essentially tries to minimize {a mathematical formula}∑t=1TLˆt(w), where{a mathematical formula} if {a mathematical formula}yt=1; otherwise,{a mathematical formula} We do not intend to calculate and store the approximated covariance matrices {a mathematical formula}Sˆt+ and {a mathematical formula}Sˆt− explicitly, but to maintain the matrices {a mathematical formula}Zt+ and {a mathematical formula}Zt− in memory. This is because the gradient {a mathematical formula}gˆt(w) based on the approximate covariance matrices can be computed from {a mathematical formula}Zt+ and {a mathematical formula}Zt− directly, i.e.,{a mathematical formula} if {a mathematical formula}yt=1; otherwise{a mathematical formula} We require a memory of {a mathematical formula}O(τd) instead of {a mathematical formula}O(d2) to calculate {a mathematical formula}gˆt(w) by using the trick {a mathematical formula}A[A]⊤w=A([A]⊤w), where {a mathematical formula}A∈Rd×1 or {a mathematical formula}Rd×τ.
      </paragraph>
      <paragraph>
       To implement the approximate approach, we initialize {a mathematical formula}Γ0−=Γ0+=[0]d×τ in Algorithm 1. In Line 6 of Algorithm 1, we update {a mathematical formula}Γt−=Γt−1−, and update {a mathematical formula}Γt+ by Algorithm 2 with inputs {a mathematical formula}xt and {a mathematical formula}Γt−1+; in Line 11, we update {a mathematical formula}Γt+=Γt−1+, and update {a mathematical formula}Γt− by Algorithm 2 with inputs {a mathematical formula}xt and {a mathematical formula}Γt−1−. We calculate the gradient {a mathematical formula}gˆt(wt−1) of Lines 7 and 12 by Eqs. (14) and (15), respectively.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       High-dimensional sparse data
      </section-title>
      <paragraph>
       In this section, we introduce a matrix sparsification algorithm to handle high-dimensional sparse vectors, which shows better performance than random projection, hashing and frequent direction. Our basic idea is to seek two sparse PSD matrices {a mathematical formula}Zt+ and {a mathematical formula}Zt− which minimize{a mathematical formula} where {a mathematical formula}‖A‖F denotes the Frobenius norm of matrix A, and nnz(A) denotes the cardinality of non-zero elements in matrix A. It is easy to find that the optimal solutions for the above problem are two sparse matrices {a mathematical formula}Zt+ and {a mathematical formula}Zt− which maintain dτ largest element in {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤, respectively.
      </paragraph>
      <paragraph>
       We will take {a mathematical formula}Γt+ and {a mathematical formula}Γt− as approximations for {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤, respectively. Specifically, we receive an example {a mathematical formula}(xt,yt) in the t-th iteration, and assume {a mathematical formula}yt=+1 (a similar procedure works for {a mathematical formula}yt=−1). We first update {a mathematical formula}Γt+=Γt−1++xt[xt]⊤, and then sparsify {a mathematical formula}Γt+ by only keeping the largest dτ elements in {a mathematical formula}Γt+. Therefore, the covariance matrices {a mathematical formula}St+ and {a mathematical formula}St− can be approximated, respectively, by{a mathematical formula} Based on approximated covariance matrices {a mathematical formula}Sˆt+ and {a mathematical formula}Sˆt−, the gradient {a mathematical formula}gˆt(w) can be computed as{a mathematical formula} for {a mathematical formula}yt=1; otherwise{a mathematical formula}
      </paragraph>
      <paragraph>
       The detailed algorithm is described in Algorithm 3. We calculate the gradient {a mathematical formula}gˆt(wt−1) of Lines 10 and 18 in Algorithm 3 by Eqs. (16) and (17), respectively.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Theoretical analysis
     </section-title>
     <paragraph>
      Section 5.1 provides the theoretical justification for pairwise least square loss. Sections 5.2 and 5.3 present regret bounds for the proposed algorithms based on covariance matrices and approximated covariance matrices, respectively. Section 5.4 gives new generalization and online-to-batch bounds.
     </paragraph>
     <section label="5.1">
      <section-title>
       Consistency analysis
      </section-title>
      <paragraph label="Definition 1">
       Many pairwise surrogate losses have been developed for AUC optimization as mentioned in Section 2. An important theoretical problem: what extent minimizing such a pairwise surrogate loss improves actual AUC; in other words, does the expected risk of learning with pairwise surrogate losses converge to the Bayes risk of AUC? Consistency implies that optimizing with a pairwise surrogate loss will yield an optimal solution. Formally, we define the AUC consistency as follows. The pairwise surrogate loss {a mathematical formula}ℓ(f(x)−f(x′)) is said to be consistent with AUC if for every sequence {a mathematical formula}{f〈n〉(x)}n≥1, the following holds over all distributions {a mathematical formula}D on {a mathematical formula}X×Y{a mathematical formula} where the infimum takes over all measurable functions.
      </paragraph>
      <paragraph>
       AUC consistency is defined on all measurable functions as in the work of [1], [31], [36]. An interesting problem is to study AUC consistency on linear function spaces for further work.
      </paragraph>
      <paragraph>
       Gao and Zhou [19] gave a sufficient condition and a necessary condition for AUC consistency based on minimizing pairwise surrogate losses, but it remains open for pairwise least square loss. Menon and Williamson [36] presented a general consistent analysis by composing sigmoidal link functions, whereas pairwise least square loss cannot be composed with a sigmoidal link. Therefore, previous studies did not provide the consistent analysis on pairwise least square loss.
      </paragraph>
      <paragraph label="Theorem 1">
       We show the consistency of pairwise least square loss for finite instance spaces. The detailed proof is given in Section 6.3. For finite instance spaces and least square loss{a mathematical formula}ℓ(t)=(1−t)2, the pairwise surrogate loss{a mathematical formula}ℓ(f(x)−f(x′))is consistent with AUC.
      </paragraph>
     </section>
     <section label="5.2">
      <section-title>
       Regret bounds with full covariance matrices
      </section-title>
      <paragraph label="Theorem 2">
       Let {a mathematical formula}w⁎ and {a mathematical formula}L⁎ be defined, respectively, as{a mathematical formula} We provide the worst-case regret bounds when the full covariance matrices are provided, and it does not require a stochastic (data) sequence. The detailed proof is given in Section 6.4. Let{a mathematical formula}‖xt‖≤1, and let{a mathematical formula}w⁎,L⁎be defined in Eqn.(18). We have{a mathematical formula}by setting the learning rate{a mathematical formula}ηt=1/(4+λ+(4+λ)2+(4+λ)λTL⁎.
      </paragraph>
      <paragraph>
       Theorem 2 theoretically shows that the performance of the OPAUC algorithm converges to the performance of a batch algorithm which observes all instances (in hindsight). This theorem gives an {a mathematical formula}O(1/T) bound when {a mathematical formula}L⁎=0, and an {a mathematical formula}O(1/T) bound for worst cases, whereas Zhao et al. [52] achieved at most {a mathematical formula}O(1/T). Our algorithm and regret bounds are independent of the ratio of positive and negative instances, while previous work [31], [52] is heavily dependent. Wang et al. [47], [48] also obtained {a mathematical formula}O(1/T) and {a mathematical formula}O(1/T) regret bounds despite of different formulations and different techniques.
      </paragraph>
      <paragraph>
       The faster convergence rate of our proposed algorithm owes to the smoothness of least square loss, an important property that has been explored in some studies of stochastic learning [41] and generalization error bound analysis [45]. It is interesting to further exploit the λ-strongly convexity of {a mathematical formula}Lt(w), which can lead to a tighter {a mathematical formula}O(ln⁡T/T) convergence rate by setting {a mathematical formula}ηt=1/λt as shown in [23].
      </paragraph>
     </section>
     <section label="5.3">
      <section-title>
       Regret bounds with approximated covariance matrices
      </section-title>
      <paragraph>
       This section studies the regret bounds when the covariance matrices are approximated. Recall that the covariance matrices are given by{a mathematical formula} where {a mathematical formula}Xt+ and {a mathematical formula}Xt− denote the matrices of positive and negative instances, respectively. We try to approximate {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤ as done in Algorithm 2, Algorithm 3, since it is easy to store the means {a mathematical formula}ct+ and {a mathematical formula}ct− in memory.
      </paragraph>
      <paragraph>
       To unify our analysis, let {a mathematical formula}Zˆt+ and {a mathematical formula}Zˆt− denote two positive semi-definite (PSD) matrices approximating {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤, respectively. We write{a mathematical formula} and denote{a mathematical formula} if {a mathematical formula}yt=1; otherwise,{a mathematical formula} Notice that {a mathematical formula}Lˆt(w) is an approximation of {a mathematical formula}Lt(w). Let {a mathematical formula}wˆ⁎ be given by{a mathematical formula} We define the stable rank of positive and negative instances, respectively, as{a mathematical formula} and further denote{a mathematical formula} We assume that the stable rank r is small in this work.
      </paragraph>
      <paragraph label="Theorem 3">
       We will present a general result where we assume that there exists a non-increasing function {a mathematical formula}g(τ) such that{a mathematical formula} where τ is a parameter related to approximated methods. We will later instantiate {a mathematical formula}g(τ) for the frequent direction method (Algorithm 2). The following theorem presents the worst-case regret bounds for approximated covariance matrices, and it does not require a stochastic (data) sequence. Suppose{a mathematical formula}‖w⁎‖≤Band{a mathematical formula}‖xt‖≤1. Let{a mathematical formula}L⁎,{a mathematical formula}g(τ)and r be defined as in Eqns.(18),(21)and(20), respectively. Denote{a mathematical formula}β=1+rg(τ)/λ,{a mathematical formula}κ=4+λand select{a mathematical formula}ηt=1/(κ+(κ2+κTL⁎/β/B2). We have{a mathematical formula}
      </paragraph>
      <paragraph>
       The proof involves bounding the difference between the optimal model {a mathematical formula}w⁎ and optimal approximated model {a mathematical formula}wˆ⁎, and then translate this to a bound on the difference between the cumulative losses of {a mathematical formula}Lt(w⁎) and {a mathematical formula}Lˆt(wˆ⁎). The detailed proof is given in Section 6.5.
      </paragraph>
      <paragraph>
       Theorem 3 theoretically shows the gap between the performance of an algorithm with approximated sample covariance matrices and the performance of a batch algorithm (in hindsight) under the assumption on {a mathematical formula}g(τ). This theorem gives comparable regret bounds with Theorem 2 for {a mathematical formula}L⁎=0 or for small {a mathematical formula}rg(τ)L⁎/λ. Also, the additional term {a mathematical formula}rg(τ)L⁎/λ can be viewed as the cost of using low-dimensional approximations to covariance matrices.
      </paragraph>
      <paragraph label="Lemma 1">
       The function {a mathematical formula}g(τ) depends on the choice of the approximated algorithm. We first investigate the approximations of {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤ by frequent direction [33], i.e., {a mathematical formula}Xt+[Xt+]⊤ and {a mathematical formula}Xt−[Xt−]⊤ are approximated by {a mathematical formula}Zt+[Zt+]⊤ and {a mathematical formula}Zt−[Zt−]⊤, respectively. Here {a mathematical formula}Zt+ and {a mathematical formula}Zt− are updated by Algorithm 2 (frequent direction). It is necessary to introduce a helpful lemma from [33] as follows: If{a mathematical formula}Zt+and{a mathematical formula}Zt+are the outputs of applying the frequent direction method to matrices{a mathematical formula}Xt+and{a mathematical formula}Xt−, respectively, then we have{a mathematical formula}where τ is the sketch size.
      </paragraph>
      <paragraph label="Corollary 1">
       Therefore, we have {a mathematical formula}g(τ)=2/τ for frequent direction. Combining Theorem 3 with Lemma 1, we derive the regret bounds when the covariance matrices are approximated by frequent direction. Suppose{a mathematical formula}‖w⁎‖≤Band{a mathematical formula}‖xt‖≤1. Let{a mathematical formula}L⁎and r be defined in Eqns.(18)and(20), respectively, and let τ be the sketch size inAlgorithm 2. Set{a mathematical formula}β=1+2r/τλ,{a mathematical formula}κ=4+λand{a mathematical formula}ηt=1/(κ+(κ2+κTL⁎/β/B2). We have{a mathematical formula}
      </paragraph>
      <paragraph>
       For matrix sparsification of Algorithm 3, it is not easy to give specific expression of {a mathematical formula}g(τ). However, we can observe empirically that {a mathematical formula}g(τ) is much smaller than {a mathematical formula}2/τ from Fig. 4 (Section 7.3).
      </paragraph>
     </section>
     <section label="5.4">
      <section-title>
       Generalization analysis
      </section-title>
      <paragraph>
       Our framework and normalization are different from [30], [47] as mentioned in Sections 2 and 3, and the normalization is data-dependent, which makes it difficult to extend the analysis of [30], [47] to our work. This section presents new generalization bounds for our proposed algorithm, and an online-to-batch conversion follows from the generalization analysis.
      </paragraph>
      <paragraph label="Theorem 4">
       Suppose that {a mathematical formula}W is a compact function space, and let {a mathematical formula}N(W,ϵ) be the ϵ-covering number with respect to the {a mathematical formula}L2 norm. We denote {a mathematical formula}p=Pr(x,y)∼D⁡[y=1] to be the ratio of positive examples under distribution {a mathematical formula}D, and assume {a mathematical formula}p&lt;1/2 without loss of generality. Throughout this section, we denote{a mathematical formula} where {a mathematical formula}B1=((1+2B)2+λB2)/2 and {a mathematical formula}B2=16(1+(λ+2)B). We haveLet{a mathematical formula}W={w:‖w‖≤B},{a mathematical formula}‖x‖≤1and{a mathematical formula}T0=⌊T/2⌋. Suppose that{a mathematical formula}wT0,…,wT∈Ware models output by OPAUC. For any{a mathematical formula}ϵ&gt;0and sufficiently large T, the following holds with probability at least{a mathematical formula}1−δ(δ is defined in Eqn.(22)) over an i.i.d. sequence{a mathematical formula}S={(x1,y1),(x2,y2),…,(xT,yT)}{a mathematical formula}
      </paragraph>
      <paragraph>
       The proof involves the decomposition of the excess risk into a martingale difference sequence and a residual term as in [30], [47]. The martingale sequence converges based on the Azuma–Hoeffding inequality, and the residual term is bounded by uniform convergence with cover numbers [12], [42].
      </paragraph>
      <paragraph>
       We cannot make use of the techniques of [47] to prove Theorem 4 directly, because the normalization {a mathematical formula}|{i∈[t−1]:yiyt=−1}| is data-dependent, which may cause large variations of cumulative losses. For example, if {a mathematical formula}|{i∈[t−1]:yiyt=−1}| is very small even for large t, then the cumulative losses have large variations by randomly replacing an example, and some classical concentrations cannot be applied.
      </paragraph>
      <paragraph>
       Our strategy is to partition the problems into two cases (based on) whether the fraction of positive instances (in the given sequence) is close to {a mathematical formula}p=Pr(x,y)∼D⁡[y=1] or not. We use the Hoeffding's inequality to deal with the case when the fraction of positive instances is far from p; this includes the special situation that {a mathematical formula}|{i∈[t−1]:yiyt=−1}| is small even for large t. For the other case, we show that the variations of cumulative losses are bounded. We finally combine the two cases by the law of total probability. The detailed proof is deferred to Section 6.6.
      </paragraph>
      <paragraph>
       Theorem 4 presents theoretical analysis on the generalization performance of our proposed OPAUC algorithm. This theorem can be easily generalized to other bounded losses such as hinge loss, exponential loss, etc. In addition, this theorem considers the average of the last {a mathematical formula}T−T0 losses and the first {a mathematical formula}T0 losses are discarded because of technical reasons, and a similar strategy has been made in [47].
      </paragraph>
      <paragraph>
       Another relevant work [30] presents the generalization error bounds based on generalized Rademacher complexity. However, our work cannot make similar extensions easily, because the normalization of cumulative losses is data-dependent, while previous normalizations of Rademacher complexities are all defined data-independently. In addition, it is difficult to make comparisons between the generalization bounds of Theorem 4 and those of [30], [47] because of different framework and normalization.
      </paragraph>
      <paragraph>
       In the following, we will derive the online-to-batch bounds for OPAUC algorithm. First, we say that an online learning algorithm has a regret bound {a mathematical formula}RT if {a mathematical formula}wT0,wT0+1,…,wT−1 are such that{a mathematical formula} From Theorem 2, we can observe {a mathematical formula}RT=O(1/T) for the OPAUC algorithm. This definition is helpful to derive the online-to-batch bounds from generalization bounds, and it has been used in [30].
      </paragraph>
      <paragraph label="Theorem 5">
       Let {a mathematical formula}w⁎⁎=arg⁡minw∈W⁡L(w,D) denote the risk minimizer over the whole distribution {a mathematical formula}D. Similarly to the proof of Theorem 4, we have{a mathematical formula} with probability at least {a mathematical formula}1−δ. Based on Theorem 4 and Eqns. (23) and (24), we have Let{a mathematical formula}W={w:‖w‖≤B},{a mathematical formula}‖x‖≤1and{a mathematical formula}T0=⌊T/2⌋. Suppose that{a mathematical formula}wT0,…,wT−1∈Ware output models by OPAUC with a regret bound{a mathematical formula}RT. For any{a mathematical formula}ϵ&gt;0and sufficient large T, the following holds with probability at least{a mathematical formula}1−2δ(δ is defined in Eqn.(22)) over i.i.d. sequence{a mathematical formula}S={(x1,y1),(x2,y2),…,(xT,yT)},{a mathematical formula}
      </paragraph>
      <paragraph label="Corollary 2">
       This theorem presents the online-to-batch bounds for the OPAUC algorithm, and it is interesting to explore other techniques for the online-to-batch conversion. Based on this theorem, we present theoretical analysis on choosing a random stopping time as follows: Let{a mathematical formula}W={w:‖w‖≤B},{a mathematical formula}‖x‖≤1and{a mathematical formula}T0=⌊T/2⌋. Suppose that{a mathematical formula}wT0,…,wT−1∈Ware output models by OPAUC with a regret bound{a mathematical formula}RT. For any{a mathematical formula}ϵ&gt;0and sufficient large T, if we randomly select{a mathematical formula}T0≤t&lt;T, then the following holds with probability at least{a mathematical formula}2/3−2δ(δ is defined in Eqn.(22)) over i.i.d. sequence{a mathematical formula}S={(x1,y1),(x2,y2),…,(xT,yT)},{a mathematical formula}
      </paragraph>
      <paragraph>
       This corollary shows that the output model could have good performance by a random stopping time, and the probability is about 2/3 for sufficient large T. In practice, we pick up the last output model {a mathematical formula}wT as in [32], [44], which gives good empirical performance by experiments (Section 7). The proof follows the technique of [44], and we present the details for completeness in Section 6.7.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Proofs
     </section-title>
     <paragraph>
      In this section, we will present detailed proofs for our main results.
     </paragraph>
     <section label="6.1">
      Proof of Proposition 1
      <paragraph>
       We first have{a mathematical formula} The distribution {a mathematical formula}D can be specified exactly by the triplet {a mathematical formula}(D+,D−,p), and assume that {a mathematical formula}x1,…,xTS+ are selected i.i.d. from distribution {a mathematical formula}D+, and {a mathematical formula}xˆ1,…,xˆTS− are selected i.i.d. from distribution {a mathematical formula}D−.
      </paragraph>
      <paragraph>
       Because the expectation over {a mathematical formula}S can be decomposed into an expectation over random draws of {a mathematical formula}TS+ and {a mathematical formula}TS− from Binomial({a mathematical formula}T,p), followed by an expectation over {a mathematical formula}D+ and {a mathematical formula}D−, respectively, we have{a mathematical formula} where the outer expectation is over {a mathematical formula}TS+∼Binomial(T,p) and {a mathematical formula}TS−=T−TS+. By the linearity of expectation, we have{a mathematical formula} which completes the proof of Eqn. (1) since {a mathematical formula}Exi∼D+,xˆj∼D−ℓ(f(xi)−f(xˆj)) have the same values for all {a mathematical formula}i∈[TS+] and {a mathematical formula}j∈[TS−], and the denominator {a mathematical formula}TS+TS− can be canceled. For Eqn. (2), we have{a mathematical formula} which completes the proof.  □
      </paragraph>
     </section>
     <section label="6.2">
      Proof of Proposition 2
      <paragraph>
       Let {a mathematical formula}x1,…,xTSt−1+ and {a mathematical formula}xˆ1,…,xˆTSt−1− be drawn i.i.d. from distributions {a mathematical formula}D+ and {a mathematical formula}D−, respectively. Recall that {a mathematical formula}p=Pr(x,y)∼D⁡[y=1]. We have{a mathematical formula} which completes the proof. □
      </paragraph>
     </section>
     <section label="6.3">
      Proof of Theorem 1
      <paragraph>
       We assume a finite instance space {a mathematical formula}X={x1,x2,…,xn} with marginal probability {a mathematical formula}pi=Pr⁡[xi] and conditional probability {a mathematical formula}ξi=Pr⁡[y=+1|xi]. The expected surrogate risk is given by{a mathematical formula} where {a mathematical formula}ℓ(t)=(1−t)2, and {a mathematical formula}C0 and {a mathematical formula}C1 are constants and irrelevant to f. Notice that our proof does not rely on the scaled loss function, i.e., the property of consistency also holds for scaled loss function {a mathematical formula}γℓ(⋅) of any constant {a mathematical formula}γ&gt;0, since scaled loss function {a mathematical formula}γℓ(⋅) corresponds to {a mathematical formula}γC1, which does not affect the optimal solution.
      </paragraph>
      <paragraph>
       According to the analysis of [19], it suffices to prove that, for every optimal solution f such that {a mathematical formula}L(f,D)=inff′⁡L(f′,D), we have {a mathematical formula}f(xi)&gt;f(xj) for {a mathematical formula}ξi&gt;ξj (equivalent to {a mathematical formula}f(xi)&lt;f(xj) for {a mathematical formula}ξi&lt;ξj by swapping i and j).
      </paragraph>
      <paragraph>
       If {a mathematical formula}n=2, i.e., {a mathematical formula}X={x1,x2}, then Eqn. (25) gives the expected risk as{a mathematical formula} Minimizing Eqn. (26) gives the optimal solution {a mathematical formula}f=(f(x1),f(x2)) such that{a mathematical formula} Therefore, we have {a mathematical formula}f(x1)&gt;f(x2) if {a mathematical formula}ξ1&gt;ξ2; otherwise {a mathematical formula}f(x1)&lt;f(x2). This shows the consistency of pairwise least square loss.
      </paragraph>
      <paragraph>
       If {a mathematical formula}n≥3 and {a mathematical formula}ξi(1−ξi)=0 for each {a mathematical formula}i∈[n], then each conditional probability satisfies{a mathematical formula} Combining this with Eqn. (25), we have{a mathematical formula} Minimizing {a mathematical formula}L(f,D) gives the optimal solution {a mathematical formula}f=(f(x1),f(x2),⋯,f(xn)) such that{a mathematical formula} which also shows the consistency of pairwise least square loss.
      </paragraph>
      <paragraph>
       If {a mathematical formula}n≥3 and there exists some {a mathematical formula}i0 s.t. {a mathematical formula}ξi0(1−ξi0)≠0, then the subgradient conditions give optimal solution {a mathematical formula}f=(f(x1),f(x2),…,f(xn)) such that{a mathematical formula} Solving the above n linear equations, we obtain{a mathematical formula} where Γ is a polynomial in {a mathematical formula}ξk1+ξk2−2ξk1ξk2 for {a mathematical formula}1≤k1,k2≤n. In the following, we will give the specific expression for {a mathematical formula}Γ(s1,s2,⋯,sn). Let {a mathematical formula}A={i:si≥1} and {a mathematical formula}B={i:si=0}={b1,b2,⋯,b|B|}.
      </paragraph>
      <list>
       <list-item label="•">
        If {a mathematical formula}|A|=1, i.e., {a mathematical formula}A={i1} for some {a mathematical formula}1≤i1≤n, then{a mathematical formula}
       </list-item>
       <list-item label="•">
        If {a mathematical formula}|A|=2, i.e., {a mathematical formula}A={i1,i2} for some {a mathematical formula}1≤i1,i2≤n, then we denote{a mathematical formula} where {a mathematical formula}{sik⊙ik} denotes the multi-set {a mathematical formula}{ik,ik,…,ik} of size {a mathematical formula}sik for {a mathematical formula}k=1,2. It is clear that {a mathematical formula}|B|=|A1|=n−2. Further, we denote {a mathematical formula}G(A1) by the set of all permutations of {a mathematical formula}A1. Therefore, we have{a mathematical formula}
       </list-item>
       <list-item label="•">
        If {a mathematical formula}|A|&gt;2, then, for {a mathematical formula}i1≠i2 and {a mathematical formula}i1,i2∈A, we denote the multi-set{a mathematical formula} and it is easy to derive {a mathematical formula}|A1|=|B|. Further, we denote {a mathematical formula}G(A∖{i1,i2}) and {a mathematical formula}G(A1) by the set of all permutations of {a mathematical formula}A∖{i1,i2} and {a mathematical formula}A1, respectively. Therefore, we set{a mathematical formula} and we have{a mathematical formula} where {a mathematical formula}B={b1,b2,…,b|B|}.
       </list-item>
      </list>
      <paragraph>
       Since there is an {a mathematical formula}i0 s.t. {a mathematical formula}ξi0(1−ξi0)≠0, we have{a mathematical formula} Therefore, we have {a mathematical formula}f(xi)&gt;f(xj) if {a mathematical formula}ξi&gt;ξj, and this theorem holds.  □
      </paragraph>
     </section>
     <section label="6.4">
      Proof of Theorem 2
      <paragraph label="Definition 2">
       First, we introduce the notion of smoothness as follows. Given a linear function space {a mathematical formula}W⊆Rd, a function {a mathematical formula}f:W→R is said to be μ-smooth if{a mathematical formula}
      </paragraph>
      <paragraph label="Lemma 2">
       For smooth functions, we have a helpful lemma from [38, Theorem 2.1.5] as follows. If f is μ-smooth, then, for every{a mathematical formula}w,w′∈W, we have{a mathematical formula}
      </paragraph>
      <paragraph label="Proof of Theorem 2">
       We will exploit the smoothness to prove this theorem. The proof technique is motivated from the work of [43], [45], and the detailed proof is presented for completeness.We have defined {a mathematical formula}Lt(w)=0 for {a mathematical formula}Tt+Tt−=0 in Section 3, and it is easy to analyze such cases; therefore, we consider {a mathematical formula}Tt+Tt−≠0 in the rest of our proof. Recall that{a mathematical formula} and it is easy to derive{a mathematical formula} For {a mathematical formula}w,w′∈W and {a mathematical formula}‖xt‖≤1, we have{a mathematical formula} which implies that {a mathematical formula}Lt is {a mathematical formula}(4+λ)-smooth. Denote{a mathematical formula} and this gives {a mathematical formula}∇Lt(wt⁎)=0 from the convex and differentiable loss {a mathematical formula}Lt. Based on Lemma 2 and {a mathematical formula}Lt(wt⁎)≥0, we have{a mathematical formula} From the convexity of function {a mathematical formula}Lt−1, we have{a mathematical formula} Therefore, we have{a mathematical formula} This implies that, by using Eqs. (27) and (28),{a mathematical formula} Summing over {a mathematical formula}t=1,…,T and rearranging, we obtain{a mathematical formula} By setting {a mathematical formula}ηt=η, we have{a mathematical formula} from {a mathematical formula}w0=0 and {a mathematical formula}‖w⁎‖≤1/λ, and we finally get{a mathematical formula} By setting{a mathematical formula} and simple calculations, the theorem holds as desired. □
      </paragraph>
     </section>
     <section label="6.5">
      Proof of Theorem 3
      <paragraph>
       It is sufficient to consider {a mathematical formula}Tt+Tt−≠0 as in the proof of Theorem 2. We rewrite {a mathematical formula}L(w;S)=1T∑t=1TLt(w) as{a mathematical formula} where{a mathematical formula} Similarly, we rewrite {a mathematical formula}Lˆ(w;S)=1T∑t=1TLˆt(w) as{a mathematical formula} where{a mathematical formula} and {a mathematical formula}Sˆt+ and {a mathematical formula}Sˆt− are defined by Eqn. (19). The optimal solutions minimizing {a mathematical formula}L(w;S) and {a mathematical formula}Lˆ(w;S) are given, respectively, by{a mathematical formula} From the assumption that {a mathematical formula}g(τ) is a non-increasing function such that{a mathematical formula} we have{a mathematical formula} Denote {a mathematical formula}Ω=(A1+A2)1/2(A˜1+A2)−1(A1+A2)1/2−Id, and it is easy to get{a mathematical formula} which implies, from {a mathematical formula}‖w⁎‖≤B, that{a mathematical formula} where {a mathematical formula}β=1+g(τ)r/λ. In addition, we have{a mathematical formula} which yields that{a mathematical formula} Finally, we have{a mathematical formula} The second term in the above can be bounded by Eqn. (32). Similarly to the proof of Theorem 2, we have, by setting {a mathematical formula}ηt=1/(κ+(κ2+κTL⁎/β/B2),{a mathematical formula} where the last inequality holds from Eqn. (33). This completes the proof.  □
      </paragraph>
     </section>
     <section label="6.6">
      Proof of Theorem 4
      <paragraph label="Theorem 6">
       Let{a mathematical formula}W={w:‖w‖≤B},{a mathematical formula}‖x‖≤1and{a mathematical formula}T0=⌊T/2⌋. Suppose that{a mathematical formula}wT0,…,wT−1∈Ware models output by OPAUC. For any{a mathematical formula}ϵ&gt;0and{a mathematical formula}T≥max⁡{256,16/p2ln⁡(64B1/ϵ),(2ln⁡8/p2)4/3,(256B1/ϵ/min⁡{p,2−3p})4}, the following holds with probability at least{a mathematical formula}1−δ(δ is defined in Eqn.(22)) over an i.i.d. sample{a mathematical formula}S={(x1,y1),(x2,y2),…,(xT,yT)}{a mathematical formula}
      </paragraph>
      <paragraph>
       This theorem can be viewed as a detailed version of Theorem 4 by presenting the exact expression that T needs to exceed.
      </paragraph>
      <paragraph label="Proof">
       We begin with an intermediate loss{a mathematical formula} as in the work of [30], [47]. We have{a mathematical formula} For {a mathematical formula}‖xt‖≤1 and {a mathematical formula}‖wt−1‖≤B, it is easy to see that{a mathematical formula} Throughout this section, we denote by {a mathematical formula}Et[⋅]=E(xt,yt)∼D[⋅]. Our proof includes four parts as follows.Step 1: Bounding the martingale differenceWe first observe that {a mathematical formula}{(L¯t(wt−1)−Lt(wt−1))/(T−T0)}t≥T0 is a martingale sequence, and it is bounded by {a mathematical formula}2B1/(T−T0). Based on the Hoeffding–Azuma inequality [6], we have{a mathematical formula}Step 2: Symmetrization by a ghost sampleWe begin with a ghost sample {a mathematical formula}S˜T={(x˜1,y˜1),(x˜2,y˜2),…,(x˜T,y˜T)} drawn i.i.d. from distribution {a mathematical formula}D, and denote by{a mathematical formula} We further bound Eqn. (35) as follows: For{a mathematical formula}T≥max⁡{256,(2ln⁡8/p2)4/3,8/p2ln⁡(64B1/ϵ),(256B1/ϵ/min⁡{p,2−3p})4}, we have{a mathematical formula}Recall that {a mathematical formula}p≤1/2, and thus {a mathematical formula}min⁡{p,2−3p}&gt;0. Before the proof of Lemma 3, we first set {a mathematical formula}T1=⌊T3/4⌋, and denote by{a mathematical formula} For any fixed {a mathematical formula}S˜T1, we can see that {a mathematical formula}E[Et[L˜t(wt−1)]|S˜T1] converges to {a mathematical formula}L(wt−1,D) for sufficiently large T as follows: For{a mathematical formula}T≥max⁡(256,8/p2ln⁡(64B1/ϵ),(256B1/ϵ/min⁡{p,2−3p})4), we have{a mathematical formula}where{a mathematical formula}Et[⋅]=E(xt,yt)∼D[⋅]and{a mathematical formula}E[⋅]=E(x˜T1+1,y˜T1+1),…,(x˜T,y˜T)∼DT−T1[⋅].It is easy to observe that, from Eqn. (36),{a mathematical formula} and{a mathematical formula} Thus, we have{a mathematical formula} For {a mathematical formula}‖xt‖≤1 and {a mathematical formula}‖wt−1‖≤B, we have {a mathematical formula}(1−yt(xt−x˜i)⊤wt−1)2/2≤B1, and{a mathematical formula} We complete the proof by combining with Lemma 5.  □For{a mathematical formula}T≥max⁡(256,8/p2ln⁡(64B1/ϵ),(256B1/ϵ/min⁡{p,2−3p})4), we have{a mathematical formula}where{a mathematical formula}T1=⌊T3/4⌋and{a mathematical formula}T0=⌊T/2⌋.Let {a mathematical formula}S˜T1+1:T0={(x˜T1+1,y˜T1+1),(x˜T1+2,y˜T1+2),…,(x˜T0,y˜T0)}. Denote the set{a mathematical formula} Based on the Hoeffding's inequality [25], we have{a mathematical formula} for {a mathematical formula}T&gt;max⁡(256,8/p2ln⁡(64B1/ϵ)). For {a mathematical formula}S˜T1+1:T0∉A, we have{a mathematical formula} for {a mathematical formula}T&gt;256. Therefore, it holds that, for {a mathematical formula}T≥(256B1/ϵ/min⁡{p,2−3p})4,{a mathematical formula} By the law of total expectation, i.e.,{a mathematical formula} we have{a mathematical formula} which completes the proof. □It is easy to see that{a mathematical formula} and the lemma holds if{a mathematical formula} Denote the set{a mathematical formula} From Hoeffding's inequality [25], we have{a mathematical formula} By the law of total probability, we have{a mathematical formula} For {a mathematical formula}T≥max⁡(256,8/p2ln⁡(64B1/ϵ),(256B1/ϵ/min⁡{p,2−3p})4), it holds that, from Lemma 4,{a mathematical formula} which yields that{a mathematical formula} If {a mathematical formula}S˜T1∉A, then each {a mathematical formula}Et[L˜t(wt−1)|S˜T1] changes by at most {a mathematical formula}2B1/min⁡{p,2−3p}/T3/4 by randomly replacing any example {a mathematical formula}(x˜t,y˜t) for {a mathematical formula}t≥T1. Based on the work of [12, Theorem 9.3], we have{a mathematical formula} for {a mathematical formula}T&gt;(256B1/ϵ/min⁡{p,2−3p})4&gt;(16B1/ϵ2/(min⁡{p,2−3p})2)2. This completes the proof.  □Step 3: Uniform convergenceFor any fixed {a mathematical formula}w∈W, we have For{a mathematical formula}t≥T0,{a mathematical formula}w∈Wand{a mathematical formula}T≥16/p2ln⁡(128B1/ϵ), we have{a mathematical formula}Given {a mathematical formula}T2=⌊T/4⌋, let{a mathematical formula} i.e., the first {a mathematical formula}T2 examples in {a mathematical formula}S˜T and {a mathematical formula}ST, respectively. Denote the sets{a mathematical formula} By using the Hoeffding inequality [25] again, we have{a mathematical formula} For simplicity, we denote {a mathematical formula}Δ=Et[L˜t(w)−Lt(w)]. By the law of total probability, we have{a mathematical formula} It is easy to observe {a mathematical formula}L(w,D)=E[Et[L˜t(w)]]=E[Et[Lt(w)]], and we have{a mathematical formula} and by the law of total expectation, it holds that{a mathematical formula} This yields that, for {a mathematical formula}T≥16/p2ln⁡(ϵ/128B1),{a mathematical formula} which implies{a mathematical formula} Therefore, we have{a mathematical formula} For {a mathematical formula}S˜T2∉A1 and {a mathematical formula}ST2∉A2, Δ has a bounded variation of {a mathematical formula}16B1/min⁡{p,2−3p}/T if each {a mathematical formula}(x˜t,y˜t) and {a mathematical formula}(xt,yt) vary for {a mathematical formula}t&gt;T2. By using the McDiarmid's inequality [35], we have{a mathematical formula} where the last inequality holds for {a mathematical formula}t&lt;T. □We next use uniform convergence techniques based on cover numbers; as a first step, we show that the objective is Lipschitz as follows:{a mathematical formula} for {a mathematical formula}w1∈W and {a mathematical formula}w2∈W. Let {a mathematical formula}m=N(W,ϵ/16(1+(λ+2)B)), and assume that {a mathematical formula}w1,w2,…,wm is a covering of {a mathematical formula}W, i.e., for any {a mathematical formula}w∈W, there is {a mathematical formula}wk s.t. {a mathematical formula}‖wk−w‖≤ϵ/16(1+(λ+2)B)). Therefore, we have{a mathematical formula} where the last inequality holds from Lemma 6.Step 4: Putting it all togetherBased on previous analyses, we have{a mathematical formula} where the first inequality holds from Eqn. (35) and Step 1, and the second inequality holds from Lemma 3. We complete the proof by combining Eqn. (37) with {a mathematical formula}m=N(W,ϵ/16(1+(λ+2)B)). □
      </paragraph>
     </section>
     <section label="6.7">
      Proof of Corollary 2
      <paragraph>
       We first define a random variable{a mathematical formula} where the randomness is over the selection of {a mathematical formula}T0≤t≤T. It is easy to observe that {a mathematical formula}ψ≥0 from the definition of {a mathematical formula}w⁎⁎, and{a mathematical formula} By Markov inequality, we have{a mathematical formula} which completes the proof by combining Theorem 5 with Eqn. (38). □
      </paragraph>
     </section>
    </section>
    <section label="7">
     <section-title>
      Experiments
     </section-title>
     <paragraph>
      In this section, we evaluate the performance of OPAUC on benchmark datasets in Section 7.1, and present an evaluation on high-dimensional dense and sparse datasets in Sections 7.2 and 7.3, respectively. Finally, we analyze the parameter influence in Section 7.4.
     </paragraph>
     <section label="7.1">
      <section-title>
       Comparisons on benchmark data
      </section-title>
      <paragraph>
       We conduct our experiments on sixteen benchmark datasets{sup:1}{sup:,}{sup:2}{sup:,}{sup:3} as summarized in Table 1. Some datasets have been used in previous studies on AUC optimization, whereas the others are large datasets requiring a one-pass procedure. The features have been scaled to {a mathematical formula}[−1,1] for all datasets. Multi-class datasets have been transformed into binary ones by randomly partitioning classes into two groups, where each group contains the same number of classes.
      </paragraph>
      <paragraph>
       We compare with a series of approaches as follows:
      </paragraph>
      <list>
       <list-item label="•">
        OAMseq: An online AUC optimization with a sequential updating method [52];
       </list-item>
       <list-item label="•">
        OAMgra: An online AUC optimization with a gradient descent updating method [52];
       </list-item>
       <list-item label="•">
        Online Uni-Exp: An online gradient descent algorithm which optimizes the (weighted) univariate exponential loss [31];
       </list-item>
       <list-item label="•">
        Online Uni-Log: An online gradient descent algorithm which optimizes the (weighted) univariate logistic loss [31];
       </list-item>
       <list-item label="•">
        Online Uni-Squ: An online gradient descent algorithm which optimizes the (weighted) univariate least square loss;
       </list-item>
       <list-item label="•">
        SVM-perf: A batch algorithm which directly optimizes AUC [28];
       </list-item>
       <list-item label="•">
        Batch SVM-OR: A batch algorithm which optimizes the pairwise hinge loss [29];
       </list-item>
       <list-item label="•">
        Batch LS-SVM: A batch algorithm which optimizes the pairwise least square loss;
       </list-item>
       <list-item label="•">
        Batch Uni-Log: A batch algorithm which optimizes the (weighted) univariate logistic loss [31];
       </list-item>
       <list-item label="•">
        Batch Uni-Squ: A batch algorithm which optimizes the (weighted) univariate least square loss.
       </list-item>
      </list>
      <paragraph>
       Here the weighted univariate losses mean that the losses are weighted by class priors as done in [31].
      </paragraph>
      <paragraph>
       All experiments are performed with Matlab 7 on a node of compute cluster with 16 CPUs (Intel Xeon Due Core 3.0 GHz) running RedHat Linux Enterprise 5 with 48 GB main memory. Due to memory limitation, we uniformly select 8000 training examples at random (without replacement) over the whole training data for batch algorithms if training size exceeds 8000, whereas only 2000 training examples are selected in a similar manner for the epsilon dataset because of its high dimension. For all online approaches, we go through the entire training data only once.
      </paragraph>
      <paragraph>
       Five-fold cross-validation is executed on training sets to determine the learning rate {a mathematical formula}ηt∈2[−12:10] for online algorithms, the regularized parameter {a mathematical formula}λ∈2[−10:2] for OPAUC and {a mathematical formula}λ∈2[−10:10] for batch algorithms. For OAMseq and OAMgra, the buffer sizes are fixed to be 100 as done in [52]. Theorem 2 shows that the optimal learning rate {a mathematical formula}ηt depends on the optimal loss {a mathematical formula}L⁎ yet it is unknown. Practically, we can set {a mathematical formula}ηt to be {a mathematical formula}O(1/T) or a small constant as in [51] to approach to the optimal learning rate, because our algorithm is insensitive to smaller {a mathematical formula}ηt (e.g., {a mathematical formula}ηt&lt;1/16) as shown in Fig. 5, and this also keeps the one-pass property. In the following, cross-validation is executed to select {a mathematical formula}ηt because we try to make fair comparisons with the first online AUC optimization work [52].
      </paragraph>
      <paragraph>
       The performances of the compared methods are evaluated by five trials of 5-fold cross validation, where the AUC values are obtained by averaging over these 25 runs. Table 2 shows that OPAUC is significantly better than the other four online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, particularly for large datasets. The win/tie/loss counts show that OPAUC is clearly superior to these online algorithms, as it wins for most times and never loses.
      </paragraph>
      <paragraph>
       Table 3 shows that OPAUC is highly competitive to the other five batch learning algorithms; this is impressive because these batch algorithms require storing the whole/partial training dataset whereas OPAUC does not store training data. We also notice that those batch algorithms use smaller datasets because of memory limitation, and have potential for better performance if there are much larger memory. Additionally, batch LS-SVM which optimizes the pairwise least square loss is comparable to the other batch algorithms, verifying our argument that least square loss is effective for AUC optimization.
      </paragraph>
      <paragraph>
       We also compare the running time of OPAUC and the online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, and the average CPU time (in seconds) are shown in Fig. 1. As expected, online Uni-Squ and online Uni-Exp take the least time cost because they optimize on single-instance (univariate) loss, whereas the other algorithms work by optimizing pairwise loss. On most datasets, the running time of OPAUC is competitive to OAMseq and OAMgra, except on the mnist and epsilon datasets which have the highest dimension in Table 1.
      </paragraph>
     </section>
     <section label="7.2">
      <section-title>
       Comparisons on high-dimensional dense data
      </section-title>
      <paragraph>
       In this section, we study the empirical performance for high-dimensional dense datasets. For convenience, we denote OPAUCfd by the OPAUC algorithm where the covariance matrices are approximated by frequent direction algorithm as shown in Algorithm 2, and recall that OPAUCs represents the OPAUC algorithm where the covariance matrices are approximated by sparse matrices as illustrated in Section 4.2.
      </paragraph>
      <paragraph>
       To verify the effectiveness of OPAUCfd on high-dimensional dense data, we select five datasets that have a small number of features in Table 1, i.e., fourclass, letter, magic04, acoustic and ijcnn1, and then add 50,000 extra features using random Fourier features [5].
      </paragraph>
      <paragraph>
       Besides four online algorithms OAMseq, OAMgra, online Uni-Exp and online Uni-Squ, as mentioned in the previous section, we also evaluate three variants of OPAUC, whose basic idea is to project high-dimensional data to low-dimensional data and then work with OPAUC as mentioned in Section 4. In addition, we also compare with two algorithms where the covariance matrices are approximated by random projection and hashing, respectively. The detailed description is given as follows.
      </paragraph>
      <list>
       <list-item label="•">
        OPAUC: Randomly selects 1000 features, and then works with OPAUC;
       </list-item>
       <list-item label="•">
        OPAUC: Projects into a 1000-dim feature space by random projection, and then works with OPAUC;
       </list-item>
       <list-item label="•">
        OPAUC: Projects into a 1000-dim feature space by principle component analysis, and then works with OPAUC.
       </list-item>
       <list-item label="•">
        OPAUCr: The OPAUC algorithm where the covariance matrices are approximated by random projection, which has been suggested in our preliminary work [17];
       </list-item>
       <list-item label="•">
        OPAUCh: The OPAUC algorithm where the covariance matrices are approximated by using hashing technique.
       </list-item>
      </list>
      <paragraph>
       Similar to Section 7.1, five-fold cross validation is executed on training sets to determine the learning rate {a mathematical formula}ηt∈2[−12:10] and the regularization parameter {a mathematical formula}λ∈2[−10:2]. Due to the memory and computational limit, the buffer sizes are set to 50 for OAMseq and OAMgra, and the sketch size τ is also set to 50 for OPAUCfd, OPAUCs, OPAUCr and OPAUCh. The performance of the methods is evaluated by five trials of 5-fold cross validation, where the AUC values are obtained by averaging over these 25 runs.
      </paragraph>
      <paragraph>
       The comparison results are summarized in Table 4, and we can see clearly that the proposed OPAUCfd approach is superior to the other compared methods, since the pairwise t-test shows that OPAUCfd wins most times and never loses. Compared with Table 2, we find that the performance can be significantly improved by using random Fourier features [5]. The average CPU time (in seconds) is shown in Fig. 2. As can be seen, OPAUC{sup:pca} takes the highest cost in time, and it runs out of memory for larger datasets such as magic04, acoustic and ijcnn1. The proposed OPAUCfd approach takes higher cost in time than other methods but with best performance.
      </paragraph>
     </section>
     <section label="7.3">
      <section-title>
       Comparison on high-dimensional sparse data
      </section-title>
      <paragraph>
       Now we investigate the empirical performance for high-dimensional sparse tasks. Eight real sparse datasets{sup:4}{sup:,}{sup:5} are shown in Table 5. The news20.binary dataset contains two classes, different from news20 dataset. The original news20 and sector are multi-class datasets; in our experiments, we randomly group the multiple classes into two meta-classes each containing the same number of classes, and we also use the sector.lvr dataset which regards the largest class as positive and the union of other classes as negative. The original ecml2012 and rcv1v2 are multi-label datasets; in our experiments, we only consider the largest label and remove the features in ecml2012 dataset that take zero values for all instances.
      </paragraph>
      <paragraph>
       Similar to Section 7.2, five-fold cross validation is executed on training sets to decide the learning rate {a mathematical formula}ηt∈2[−12:10] and the regularization parameter {a mathematical formula}λ∈2[−10:2]. Due to memory and computational limit, the buffer sizes are set to 50 for OAMseq and OAMgra, and the sketch size τ is also set to 50 for OPAUCfd, OPAUCs, OPAUCr and OPAUCh. The performance of the methods is evaluated by five trials of 5-fold cross validation, where the AUC values are obtained by averaging over these 25 runs.
      </paragraph>
      <paragraph>
       The comparison results are summarized in Table 6 and the average CPU time (seconds) is shown in Fig. 3. These results clearly show that our approximate OPAUCs approach is superior to the other compared methods. Compared with OAMseq, OAMgra, OPAUCfd, OPAUCr and OPAUCh, the time costs are comparable whereas the performance of OPAUCs is better. Online Uni-Squ and Uni-Exp are more efficient than OPAUCs because they optimize a univariate loss, but the performance of OPAUCs is highly competitive or better, except on real-sim, rcv and rcv1v2, the three datasets with less than 50,000 features and with class balance between positive and negative instances. Compared with the three variants, OPAUC{sup:f} and OPAUC{sup:rp} are more efficient, but with much worse performances. OPAUC{sup:pca} achieves a worse performance on all datasets; particularly, on the two datasets with the largest number of features, OPAUC{sup:pca} cannot return results even after running out 10{sup:6} seconds (almost 11.6 days). These observations validate the effectiveness of OPAUCs for handing high-dimensional sparse data.
      </paragraph>
      <paragraph>
       Finally, we try to understand why OPAUCs works better than OPAUCfd, OPAUCr and OPAUCh on high-dimensional sparse datasets, although the basic idea for those approaches is to use low-rank matrices to approximate the covariance matrices. We measure the approximation error of each method by Frobenius norm. More precisely, for original matrix A and output sketch matrix B, the empirical performance is measured by {a mathematical formula}‖A⊤A−B‖F for OPAUCs, and {a mathematical formula}‖A⊤A−B⊤B‖F for OPAUCfd, OPAUCr and OPAUCh.
      </paragraph>
      <paragraph>
       Fig. 4 shows the approximation error comparisons on datasets sector, news20 and real-sim. As can be seen, our proposed sparse algorithm (shown in Section 4.2) takes the best approximation to positive/negative covariance matrices, and those are rather stable. Frequent direction has better performance than random projection and hashing. This verifies the effectiveness of our sparse algorithms to high-dimensional sparse datasets.
      </paragraph>
     </section>
     <section label="7.4">
      <section-title>
       Parameter influence
      </section-title>
      <paragraph>
       We study the influence of parameters in this section. Fig. 5 shows that stepsize {a mathematical formula}ηt should not be set to values bigger than 1, whereas there is a relatively big range between {a mathematical formula}[2−12,2−4] where OPAUC achieves good results. Figs. 6 shows that OPAUC is not sensitive to the value of regularization parameter λ given that it is not set with a big value. Fig. 7 studies the influence of the iterations for OPAUC, OAMseq and OAMgra, and it is observable that OPAUC converges faster than the other two algorithms, which verifies our theoretical argument in Section 5.
      </paragraph>
     </section>
    </section>
    <section label="8">
     <section-title>
      Conclusion
     </section-title>
     <paragraph>
      This paper investigates the one-pass AUC optimization that requires going through the training data only once, without storing the entire dataset. Here, a big challenge lies in the fact that AUC is measured by a sum of losses defined over pairs of instances from different classes. We propose the OPAUC approach, which employs the least square loss and requires the storing of only the first and second-statistics for the received training examples. A nice property of OPAUC is that its storage requirement is O({a mathematical formula}d2), where d is the dimension of data, independent of the number of training examples. To handle high-dimensional tasks, we develop two deterministic strategies to approximate the covariance matrices for dense and sparse datasets, respectively. The effectiveness of our proposed approach is verified both theoretically and empirically. In particular, the performance of OPAUC is significantly better than online AUC optimization approaches, and is even competitive to batch learning approaches; the approximate OPAUC is significantly better than all compared methods. An interesting future issue is to develop one-pass AUC optimization approaches not only with a performance comparable to batch approaches, but also with an efficiency comparable to univariate loss optimization approaches.
     </paragraph>
    </section>
   </content>
  </root>
 </body>
</html>