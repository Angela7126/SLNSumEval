<?xml version="1.0" encoding="utf-8"?>
<html>
 <body>
  <root>
   <title>
    Adversarial patrolling with spatially uncertain alarm signals.
   </title>
   <content>
    <section label="1">
     <section-title>
      Introduction
     </section-title>
     <paragraph>
      Security Games model the task of protecting physical environments as a non-cooperative game between a Defender and an Attacker[1]. These games usually take place under a Stackelberg (a.k.a. leader–follower) paradigm [2], where the Defender (leader) commits to a strategy and the Attacker (follower) first observes such commitment and then best responds to it. As discussed in the seminal work [3], finding a leader–follower equilibrium is computationally tractable in games with one follower and complete information, while it becomes hard in Bayesian games with different types of Attacker. The availability of such computationally tractable aspects of Security Games led to the development of algorithms capable of scaling up to large problems, making them deployable in the security enforcing systems of several real-world applications. The first notable examples are the deployment of police checkpoints at the Los Angels International Airport [4] and the scheduling of federal air marshals over the U.S. domestic airline flights [5]. More recent case studies include the positioning of U.S. Coast Guard patrols to secure crowded places, bridges, and ferries [6] and the arrangement of city guards to stop fare evasion in Los Angeles Metro [7]. Finally, a similar approach is being tested and evaluated in Uganda, Africa, for the protection of wildlife [8]. Thus, Security Games emerged as an interesting game theoretical tool and then showed their on-the-field effectiveness in a number of real security scenarios.
     </paragraph>
     <paragraph>
      We focus on a specific class of security games, called Patrolling Security Games. These games are modeled as infinite-horizon extensive-form games in which the Defender controls one or more patrollers moving within an environment, represented as a finite graph. The Attacker, besides having knowledge of the strategy to which the Defender committed to, can observe the movements of the patrollers at any time and use such information in deciding the most convenient time and target location to attack [9]. When multiple patrollers are available, coordinating them at best is in general a hard task which, besides computational aspects, must also keep into account communication issues [10]. However, the patrolling problem is tractable, even with multiple patrollers, in border security (e.g., line and cycle graphs), when patrollers have homogeneous moving and sensing capabilities and all the vertices composing the border share the same features [11]. Scaling this model involved the study of how to compute patrolling strategies in scenarios where the Attacker is allowed to perform multiple attacks [12]. Similarly, coordination strategies among multiple defenders are investigated in [13]. In [14], the authors study the case in which there is a temporal discount on the targets. Extensions are discussed in [15], where coordination strategies between defenders are explored, in [16], where a resource can cover multiple targets, and in [17] where attacks can be detected at different stages with different associated utilities. Finally, some theoretical results about properties of specific patrolling settings are provided in [18]. In the present paper, we provide a new model of Patrolling Security Games in which the Defender is supported by an alarm system deployed in the environment.
     </paragraph>
     <section label="1.1">
      <section-title>
       Motivating scenarios
      </section-title>
      <paragraph>
       Often, in large environments, a constant surveillance of every area is not affordable while focused inspections triggered by alarms are more convenient. Real-world applications include UAVs surveillance of large infrastructures [19], wildfires detection with CCD cameras [20], agricultural fields monitoring [21], surveillance based on wireless sensor networks [22], and border patrolling [23]. Alarm systems are in practice affected by detection uncertainty, e.g., missed detections and false positives, and localization (a.k.a. spatial) uncertainty, e.g., the alarm system is uncertain about the exact target under attack. We summarily describe two practical security problems that can be ascribed to this category. We report them as examples, presenting features and requirements that our model can properly deal with. In the rest of the paper we will necessarily take a general stance, but we encourage the reader to keep in mind these two cases as reference applications for a real deployment of our model.
      </paragraph>
      <section label="1.1.1">
       <section-title>
        Fight to illegal poaching
       </section-title>
       <paragraph>
        Poaching is a widespread environmental crime that causes the endangerment of wildlife in several regions of the world. Its devastating impact makes the development of surveillance techniques to contrast this kind of activities one of the most important matters in national and international debates. Poaching typically takes place over vast and savage areas, making it costly and ineffective to solely rely on persistent patrol by ranger squads. To overcome this issue, recent developments have focused on providing rangers with environmental monitoring systems to better plan their inspections, concentrating them in areas with large likelihood of spotting a crime. Such systems include the use of UAVs flying over the area, alarmed fences, and on-the-field sensors trying to recognize anomalous activities.{sup:1} In all these cases, technologies are meant to work as an alarm system: once the illegal activity is recognized, a signal is sent to the rangers base station from where a response is undertaken. In the great majority of cases, a signal corresponds to a spatially uncertain localization of the illegal activity. For example, a camera-equipped UAV can spot the presence of a pickup in a forbidden area but cannot derive the actual location to which poachers are moving. In the same way, alarmed fences and sensors can only transmit the location of violated entrances or forbidden passages. In all these cases a signal implies a restricted, yet not precise, localization of the poaching activity. The use of Security Games in this particular domain is not new (see, for example, [8]). However, our model allows the computation of alarm response strategies for a given alarm system deployed on the field. This can be done by adopting a discretization of the environment, where each target corresponds to a sector, values are related to the expected population of animals in that sector, and deadlines represent the expected completion time of illegal hunts (these parameters can be derived from data, as discussed in [8]).
       </paragraph>
      </section>
      <section label="1.1.2">
       <section-title>
        Safety of fair sites
       </section-title>
       <paragraph>
        Fairs are large public events attended by thousands of visitors, where the problem of guaranteeing safety for the hosting facilities can be very hard. For example, Expo 2015, the recent Universal Exposition hosted in Milan, Italy, saw an average of about 100,000 visits per day. This poses the need for carefully addressing safety risks, which can also derive from planned act of vandalism or terrorist attacks. Besides security guards patrols, fair sites are often endowed with locally installed monitoring systems. Expo 2015 employed around 200 baffle gates and 400 metal detectors at the entrance of the site. The internal area was constantly monitored by 4000 surveillance cameras and by 700 guards. Likely, when one or more of these devices/personnel identified a security breach, a signal was sent to the control room together with a circumscribed request of intervention. This approach is required because, especially in this kind of environments, detecting a security breach and neutralizing it are very different tasks. The latter one, in particular, usually requires a greater effort involving special equipment and personnel whose employment on a demand basis is much more convenient. Moreover, the detecting location of a threat is in many cases different from the location where it could be neutralized, making the request of intervention spatially uncertain. For instance, consider a security guard or a surveillance camera detecting the visitors' reactions to a shooting rampage performed by some attacker. In examples like these, we can restrict the area where the security breach happened but no precise information about the location can be gathered since the attacker will probably have moved. Our model could be applied to provide a policy with which schedule interventions upon a security breach is detected in some particular section of the site. In such case, targets could correspond to buildings or other installations where visitors can go. Values and deadlines can be chosen according to the importance of targets, their expected crowding, and the required response priority.
       </paragraph>
      </section>
     </section>
     <section label="1.2">
      <section-title>
       Alarms and security games
      </section-title>
      <paragraph>
       While the problem of managing a sensor network to optimally guard security-critical infrastructures has been investigated in restricted domains, e.g. [24], the problem of integrating alarm signals together with adversarial patrolling is almost completely unexplored. The only work that can be classified under this scope is [25]. The paper proposes a skeleton model of an alarm system where sensors have no spatial uncertainty in detecting attacks on single targets. The authors analyse how sensory information can improve the effectiveness of patrolling strategies in adversarial settings. They show that, when sensors are not affected by false negatives and false positives, the best strategy prescribes that the patroller just responds to an alarm signal rushing to the target under attack without patrolling the environment. As a consequence, in such cases the model treatment becomes trivial. On the other hand, when sensors are affected only by false negatives, the treatment can be carried out by means of an easy variation of the algorithm for the case without sensors [9]. In the last case, where false positives are admitted, the problem becomes computationally intractable. To the best of our knowledge, no previous result dealing with spatial uncertain alarm signals in adversarial patrolling is present in the literature.
      </paragraph>
      <paragraph>
       Effectively exploiting an alarm system and determining a good deployment for it (e.g., selecting the location where to install sensors) are complementary but radically different problems. The results we provide in this work lie in the scope of the first one while the treatment of the second one is left for future works. In other words, we assume that a deployed alarm system is given and we deal with the problem of strategically exploiting it at best. Any approach to search for the optimal deployment should know, in principle, how to evaluate possible deployments. In such sense, our problem needs to be addressed before one might deal with the deployment one.
      </paragraph>
     </section>
     <section label="1.3">
      <section-title>
       Contributions
      </section-title>
      <paragraph>
       In this paper, we propose the first Security Game that integrates a spatially uncertain alarm system in game-theoretic settings for patrolling.{sup:2} An alarm signal carries the information about the set of targets that can be under attack and it is described by the probability of being generated when each target is attacked. The analysis and the main results we propose in this work are devoted to the basic game model where the Defender can control a single patroller and the alarm system is immune to false positives and false negatives, making spatial uncertainty its only limitation. As our results show, such assumptions do not play down the significance of the arising computational challenges whose resolution is a prerequisite for more complex settings. Indeed, extensions of this model that generalize to multi-resource settings [27] and that consider false negatives [28] are built on the basic result provided in this work. The game we consider can be decomposed in a finite number of finite-horizon subgames, each called Signal Response Game from v (SRG-v) and capturing the situation in which the Defender is in a vertex v and the Attacker attacked a target, and an infinite-horizon game, called Patrolling Game (PG), in which the Defender moves in absence of any alarm signal. We show that SRG-v is {a mathematical formula}FNP-hard for tree-based topologies and that, for arbitrary graphs, is {a mathematical formula}APX-hard. We provide two exact algorithms. The first one, based on dynamic programming, performs a breadth-first search, while the second one, based on branch-and-bound approach, performs a depth-first search. We use the same two approaches to design two approximation algorithms.
      </paragraph>
      <paragraph>
       Then, we study the PG, showing that when no false positives and no missed detections are present, the optimal Defender strategy is to stay in a fixed location, wait for a signal, and respond to it at best. This strategy keeps being optimal even when non-negligible missed detection rates are allowed. We experimentally evaluate the scalability of our exact algorithms and we compare them with the approximation ones in terms of solution quality and compute times, investigating in hard instances the gap between our hardness results and the theoretical guarantees of our approximation algorithms. We show that our approximation algorithms provide very high quality solutions even in hard instances. Finally, we provide an example of resolution for a realistic instance, based on Expo 2015, and we show that our exact algorithms can be applied for such kind of settings. Moreover, in our realistic instance we assess how the optimal patrolling strategy coincides with a static placement even when allowing a false negative rate of less or equal to {a mathematical formula}30%.
      </paragraph>
     </section>
     <section label="1.4">
      <section-title>
       Paper structure
      </section-title>
      <paragraph>
       In Section 2, we introduce our game model. In Section 3, we study the problem of finding the strategy of the Defender for responding to an alarm signal. In Section 4, we study the patrolling problem. In Section 5, we experimentally evaluate our algorithms. In Section 6, we briefly discuss the main Security Games research directions that have been explored in the last decades. Finally, Section 7 concludes the paper. Appendix A includes the most technical proofs of the paper while Appendix B discusses some particular results obtained for special classes of instances. Appendix C reports some additional experimental results and Appendix D provides a table summarizing the notation symbols used in the paper.
      </paragraph>
     </section>
    </section>
    <section label="2">
     <section-title>
      Problem statement
     </section-title>
     <paragraph>
      In this section we formalize the problem we study. More precisely, in Section 2.1 we describe the patrolling setting and the game model, while in Section 2.2 we state the computational questions we shall address in this work.
     </paragraph>
     <section label="2.1">
      <section-title>
       Game model
      </section-title>
      <paragraph>
       Initially, in Section 2.1.1, we introduce a basic patrolling security game model integrating the main features from models currently studied in literature. Next, in Section 2.1.2, we extend our game model by introducing alarm signals. In Section 2.1.3, we depict the game tree of our patrolling security game with alarm signals and we decompose it in notable subgames to facilitate its study. To ease presentation, we summarized our notation symbols in Table D.3.
      </paragraph>
      <section label="2.1.1">
       <section-title>
        Basic patrolling security game
       </section-title>
       <paragraph>
        As is customary in the Artificial Intelligence literature [9], [14], we deal with discrete, both in terms of space and time, patrolling settings, representing an approximation of a continuous environment. Specifically, we model the environment to be patrolled as an undirected connected graph {a mathematical formula}G=(V,E), where vertices represent different areas connected by various corridors/roads represented through the edges. Time is discretized in turns. Edges are assigned weights representing the number of time steps needed to traverse them. If not stated otherwise, we shall assume unitary weights. With {a mathematical formula}ωi,j⁎ we shall denote the shortest time to go from i to j. We define {a mathematical formula}T⊆V the subset of sensible vertices, called targets, that must be protected from possible attacks. Each target {a mathematical formula}t∈T is characterized by a value {a mathematical formula}π(t)∈(0,1] and a penetration time {a mathematical formula}d(t)∈N+, which measures the number of turns needed to complete an attack to t.
       </paragraph>
       <paragraph label="Example 1">
        We report in Fig. 1 an example of patrolling setting. Here, {a mathematical formula}V={v0,v1,v2,v3,v4}, {a mathematical formula}T={t1,t2,t3,t4} where {a mathematical formula}ti=vi for {a mathematical formula}i∈{1,2,3,4}. All the targets t present the same value {a mathematical formula}π(t) and the same penetration time {a mathematical formula}d(t).
       </paragraph>
       <paragraph>
        At each turn, an Attacker{a mathematical formula}A and a Defender{a mathematical formula}D play simultaneously having the following available actions:
       </paragraph>
       <list>
        <list-item label="•">
         if {a mathematical formula}A has not attacked in the previous turns, it can observe the position of {a mathematical formula}D in the graph G{sup:3} and decide whether to attack a target or to wait for a turn. The attack is instantaneous, meaning that there is no delay between the decision to attack and the actual presence of a threat in the selected target{sup:4};
        </list-item>
        <list-item label="•">
         {a mathematical formula}D has no information about the actions undertaken by {a mathematical formula}A in previous turns and selects the next vertex to patrol among those adjacent to the current one; each movement is a non-preemptive traversal of a single edge {a mathematical formula}(v,v′)∈E.
        </list-item>
       </list>
       <paragraph>
        The game may conclude in correspondence of any of the two following events. The first one is when {a mathematical formula}D patrols a target t that is under attack by {a mathematical formula}A from less than {a mathematical formula}d(t) turns. In such case the attack is prevented and {a mathematical formula}A is captured. The second one is when target t is attacked and {a mathematical formula}D does not patrol t during the {a mathematical formula}d(t) turns that follow the beginning of the attack. In such case, the attack is successful and {a mathematical formula}A escapes without being captured. When {a mathematical formula}A is captured, {a mathematical formula}D receives a utility of 1 and {a mathematical formula}A receives a utility of 0. When an attack to t has success, {a mathematical formula}D receives {a mathematical formula}1−π(t) and {a mathematical formula}A receives {a mathematical formula}π(t). The game may not conclude if {a mathematical formula}A decides to wait for every observed position of {a mathematical formula}D, thus never attacking. In such case, {a mathematical formula}D receives 1 and {a mathematical formula}A receives 0. (Another intuitive way to think at this payoff structure is to assume that {a mathematical formula}D receives an initial utility of 1 and then loses {a mathematical formula}π(t) whenever target t is successfully compromised.) Notice that the game is constant sum and therefore it is equivalent to a zero-sum game through a positive affine transformation.
       </paragraph>
       <paragraph>
        The above game model is in extensive form (being played sequentially), with imperfect information ({a mathematical formula}D not observing the actions undertaken by {a mathematical formula}A), and with infinite horizon ({a mathematical formula}A being in the position to wait forever). The fact that {a mathematical formula}A can observe the actions undertaken by {a mathematical formula}D before acting makes the leader–follower equilibrium the natural solution concept for our problem, where {a mathematical formula}D is the leader and {a mathematical formula}A is the follower. Since we focus on zero-sum games, the leader's strategy at the leader–follower equilibrium is its maxmin strategy and it can be found by employing linear mathematical programming, which requires polynomial time in the number of actions available to the players [31].
       </paragraph>
      </section>
      <section label="2.1.2">
       <section-title>
        Introducing alarm signals
       </section-title>
       <paragraph>
        We extend the game model described in the previous section by introducing a spatial uncertain alarm system that can be exploited by {a mathematical formula}D. The basic idea is that an alarm system uses a number of sensors spread over the environment to gather information about possible attacks and raises an alarm signal at any time an attack occurs. The alarm signal provides some information about the location (target) where the attack is ongoing, but it is affected by uncertainty. In other words, the alarm system detects an attack but it is uncertain about the target under attack. Formally, the alarm system is defined as a pair {a mathematical formula}(S,p), where {a mathematical formula}S={s1,⋯,sm} is a set of {a mathematical formula}m≥1signals and {a mathematical formula}p:S×T→[0,1] is a function that specifies the probability of having the system generating a signal s given that target t has been attacked, we denote such probability with {a mathematical formula}p(s|t). With a slight abuse of notation, for a signal s we define {a mathematical formula}T(s)={t∈T|p(s|t)&gt;0} and, similarly, for a target t we have {a mathematical formula}S(t)={s∈S|p(s|t)&gt;0}. In this work, we assume that:
       </paragraph>
       <list>
        <list-item label="•">
         the alarm system is not affected by false positives (signals generated when no attack has occurred). Formally, {a mathematical formula}p(s|△)=0, where △ indicates that no targets are under attack;
        </list-item>
        <list-item label="•">
         the alarm system is not affected by false negatives (signals not generated even though an attack has occurred). Formally, {a mathematical formula}p(⊥|t)=0, where ⊥ indicates that no signals have been generated; in Section 4 we will show that the optimal strategies we compute under this assumption can preserve optimality even in presence of non-negligible false negatives rates.
        </list-item>
       </list>
       <paragraph label="Example 2">
        We report two examples of alarm systems for the patrolling setting depicted in Fig. 1. The first example is reported in Fig. 2(a). It is a low-accuracy alarm system that generates the same signal anytime a target is under attack and therefore that does not provide any information about the target under attack. The second example is reported in Fig. 2(b). It provides more accurate information about the localization of the attack than the previous example. Here, the reception of a signal {a mathematical formula}si implies, under a uniform strategy of {a mathematical formula}A, a high probability of an attack on target {a mathematical formula}ti. Namely, when {a mathematical formula}ti is attacked the alarm system generates {a mathematical formula}si with high probability and a different signal otherwise.
       </paragraph>
       <paragraph>
        Given the presence of an alarm system defined as above, the game mechanism changes in the following way. At each turn, before deciding its next move, {a mathematical formula}D observes whether or not a signal has been generated by the alarm system and then makes its decision considering such information. This introduces in our game a node of chance implementing the non-deterministic selection of signals.
       </paragraph>
      </section>
      <section label="2.1.3">
       <section-title>
        The game tree and its decomposition
       </section-title>
       <paragraph>
        Here we depict the game tree of our game model, decomposing it in some recurrent subgames. A portion of the game is depicted in Fig. 3. Such tree can be read along the following steps.
       </paragraph>
       <list>
        <list-item label="•">
         Root of the tree.{a mathematical formula}A decides whether to wait for a turn (this action is denoted as △ to indicate that no target is attacked) or to attack a target {a mathematical formula}t∈T (this action is denoted by the label t of the attacked target).
        </list-item>
        <list-item label="•">
         Second level of the tree.{a mathematical formula}N denotes the alarm system, represented by a nature-type player. Its behavior is a priori specified by the conditional probability mass function p, which determines the generated signal given the attack performed by {a mathematical formula}A. In particular, it is useful to distinguish between two cases:
        </list-item>
        <list-item label="•">
         Third level of the tree.{a mathematical formula}D observes the signal generated by the alarm system and decides the next vertex to patrol among those adjacent to the current one (the current vertex is initially chosen by {a mathematical formula}D).
        </list-item>
        <list-item label="•">
         Fourth level of the tree and on. It is useful to distinguish between two cases:
        </list-item>
       </list>
       <paragraph>
        Such game tree can be decomposed in a number of finite recurrent subgames such that the best strategies of the agents in each subgame are independent from those in other subgames. This decomposition allows us to apply a divide et impera approach, simplifying the resolution of the problem of finding an equilibrium. More precisely, we denote with Γ one of these subgames. We define Γ as a game subtree that can be extracted from the tree of Fig. 3 as follows. Given {a mathematical formula}D's current vertex {a mathematical formula}v∈V, select a decision node for {a mathematical formula}A and call it i. Then, extract the subtree rooted in i discarding the branch corresponding to action Δ (no attack).{sup:5} Intuitively, such subgame models the players' interaction when the Defender is in some given vertex v and the Attacker will perform an attack. As a consequence, each Γ obtained in such way is finite (once an attack on t started, the maximum length of the game is {a mathematical formula}d(t)). Moreover, the set of different Γs we can extract is finite since we have one subgame for each possible current vertex for {a mathematical formula}D. As a consequence, we can extract at most {a mathematical formula}|V| different subgames. Notice that, due to the infinite horizon, each subgame can recur an infinite number of times along the game tree. However, being such repetitions independent and the game zero-sum, we only need to solve one subgame to obtain the optimal strategy to be applied in each of its repetitions. In other words, when assuming that an attack will be performed, the agents' strategies can be split in a number of independent strategies solely depending on the current position of {a mathematical formula}D. The reason why we discarded the branch corresponding to action Δ in each subgame is that we seek to deal with such complementary case exploiting a simple backward induction approach, as explained later.
       </paragraph>
       <paragraph>
        First, we call Signal Response Game from v the subgame Γ defined as above and characterized by a vertex v representing the current vertex of {a mathematical formula}D (for brevity, we shall use SRG-v). In an SRG-v, the goal of {a mathematical formula}D is to find the best strategy starting from vertex v to respond to any alarm signal. All the SRG-vs are independent and thus the best strategy in each subgame does not depend on the strategies of the other subgames. The intuition is that the best strategy in an SRG-v does not depend on the vertices visited by {a mathematical formula}D before the attack. Given an SRG-v, we denote by {a mathematical formula}σv,sD the strategy of {a mathematical formula}D once observed signal s, by {a mathematical formula}σvD the strategy profile {a mathematical formula}σvD=(σv,s1D…,σv,smD) of {a mathematical formula}D, and by {a mathematical formula}σvA the strategy of {a mathematical formula}A. Let us notice that in an SRG-v, given a signal s, {a mathematical formula}D is the only agent that plays and therefore each sequence of moves can be collapsed in a single action. Thus, SRG-v is essentially a two-level game in which {a mathematical formula}A decides the target to attack and {a mathematical formula}D decides the sequence of moves on the graph.
       </paragraph>
       <paragraph>
        Then, according to classical backward induction arguments [32], once we have found the best strategies of each SRG-v, we can substitute the subgames with the agents' equilibrium utilities and then we can find the best strategy of {a mathematical formula}D for patrolling the vertices whenever no alarm signal has been raised and the best strategy of attack for {a mathematical formula}A. We call this last problem Patrolling Game (for conciseness, we shall use PG). We denote by {a mathematical formula}σD and {a mathematical formula}σA the strategies of {a mathematical formula}D and {a mathematical formula}A, respectively, in the PG.
       </paragraph>
      </section>
     </section>
     <section label="2.2">
      <section-title>
       The computational questions we pose
      </section-title>
      <paragraph>
       Our contributions focus on the design of algorithms to find an equilibrium for our game and develop along four central questions. The first one stems directly from our problem definition.
      </paragraph>
      <paragraph label="Question 1">
       Which is the best patrolling strategy for{a mathematical formula}Dmaximizing its expected utility?
      </paragraph>
      <paragraph>
       Clearly, this problem is related to what we called PG in our game decomposition. In order to build an answer, we pose other three questions that, instead, involve the other subgame called SRG-v.
      </paragraph>
      <paragraph label="Question 2">
       Given a starting vertex v and a signal s, is there any strategy allowing{a mathematical formula}Dto visit all the targets in{a mathematical formula}T(s), each within its deadline?
      </paragraph>
      <paragraph label="Question 3">
       Given a starting vertex v and a signal s, is there any pure strategy giving{a mathematical formula}Dan expected utility of at least k?
      </paragraph>
      <paragraph label="Question 4">
       Given a starting vertex v and a signal s, is there any mixed strategy giving{a mathematical formula}Dan expected utility of at least k?
      </paragraph>
      <paragraph>
       These questions are not independent from each other. In particular, answering to the last three is a prerequisite to solving the first one. For this reason, we shall take a bottom-up approach answering the above questions starting from the last three and then dealing with the first one at the whole-game level. Also, Question 3, Question 4 are not easier than Question 2 so hardness results for this last one can be extended to the others.
      </paragraph>
     </section>
    </section>
    <section label="3">
     <section-title>
      Signal response game
     </section-title>
     <paragraph>
      In this section we start by dealing with the resolution of SRG-v. Specifically, in Section 3.1 we prove the hardness of the problem, analyzing its computational complexity. Then, in Section 3.2 and in Section 3.3 we propose two algorithms, the first based on dynamic programming (breadth-first search) while the second adopts a branch and bound (depth-first search) paradigm. Furthermore, we provide a variation for each algorithm, approximating the optimal solution. For the sake of presentation, the most technical proofs are reported in Appendix A.
     </paragraph>
     <section label="3.1">
      <section-title>
       Complexity results
      </section-title>
      <paragraph>
       The aim of this section is to assess the computational complexity of finding an exact or approximate equilibrium for our game model. Furthermore, we aim at identifying the source of hardness of our problem and the most efficient algorithm for solving it.
      </paragraph>
      <paragraph>
       Each SRG-v is characterized by {a mathematical formula}|T| actions available to {a mathematical formula}A, each corresponding to a target t, and by {a mathematical formula}O(|V|maxt⁡{d(t)}) decision nodes of {a mathematical formula}D. The portion of game tree played by {a mathematical formula}D can be safely reduced by observing that {a mathematical formula}D will move between any two targets along a shortest path. This allows us to discard from the tree all the decision nodes where {a mathematical formula}D occupies a non-target vertex. Nevertheless, this reduction keeps the size of the game tree exponential in the parameters of the game, specifically {a mathematical formula}O(|T||T|).{sup:6} Notice that, the exponential size of the game tree does not constitute a proof that finding the equilibrium strategies of an SRG-v requires exponential time in the parameters of the game because it does not exclude the existence of some compact representation of {a mathematical formula}D's strategies, e.g., Markovian strategies. The first result we provide implies that such a representation is very unlikely to exist or that, if it exists, it unlikely can be computed in polynomial time. Call {a mathematical formula}gv the expected utility of {a mathematical formula}A from SRG-v ({a mathematical formula}1−gv is then the corresponding utility for {a mathematical formula}D). We define the following problem.
      </paragraph>
      <paragraph label="Definition 1">
       {a mathematical formula}k–SRG-vThe decision problem k–SRG-v is defined as:INSTANCE: an instance of SRG-v;QUESTION: is there any {a mathematical formula}σD such that, when {a mathematical formula}A plays its best response, it holds that {a mathematical formula}gv≤k?
      </paragraph>
      <paragraph label="Theorem 1">
       k–SRG-v is{a mathematical formula}NP-hard even when{a mathematical formula}|S|=1and the graph is a tree.{sup:7}
      </paragraph>
      <paragraph>
       The above result shows that w.r.t. tree graphs:
      </paragraph>
      <list>
       <list-item label="•">
        answering to Question 1 is {a mathematical formula}FNP-hard,
       </list-item>
       <list-item label="•">
        answering to Question 2, Question 3, Question 4 is {a mathematical formula}NP-hard.
       </list-item>
      </list>
      <paragraph>
       For the sake of completeness, notice that a maxmin strategy with support upper bounded by {a mathematical formula}|T| (that is, the number of actions available to the min player {a mathematical formula}A) always exists [33].
      </paragraph>
      <paragraph>
       Now, given that we established that the main source of hardness of the problem is computing the strategy space of {a mathematical formula}D, we focus on the problem of finding an efficient representation for it. We start with some definitions.
      </paragraph>
      <paragraph label="Definition 2">
       RouteGiven a starting vertex v and a signal s, a route r is a finite sequence of vertices where, called {a mathematical formula}r(i) the i-th vertex, {a mathematical formula}r(0)=v and {a mathematical formula}r(i)∈T(s) for any {a mathematical formula}i&gt;0. With a slight overload of notation, call {a mathematical formula}T(r) the set of targets from the sequence.
      </paragraph>
      <paragraph>
       We restrict our attention to a special class of routes that we call covering. For a route r and {a mathematical formula}i&gt;0, define {a mathematical formula}Ar(r(i))=∑h=0i−1ωr(h),r(h+1)⁎. Such value gives the time needed by {a mathematical formula}D to arrive at target {a mathematical formula}r(i) after following a graph walk along the shortest paths between consecutive vertices of the sequence {a mathematical formula}r(0),r(1),…,r(i).
      </paragraph>
      <paragraph label="Definition 3">
       Covering routeA covering route is a route r where {a mathematical formula}Ar(t)≤d(t) for any {a mathematical formula}t∈T(r).
      </paragraph>
      <paragraph>
       Covering routes are abstractions for {a mathematical formula}D's available pure strategies when the current vertex is v and a signal s has been generated. If r is a covering route for vertex v and signal s and {a mathematical formula}T(r)⊆T(s) is the set of targets in r, then we can always instantiate r to a graph walk for {a mathematical formula}D (a sequence of moves on G) that guarantees to capture {a mathematical formula}A on any target in {a mathematical formula}T(r). Such walk is simply obtained by starting from {a mathematical formula}r(0)=v and then covering any shortest path between {a mathematical formula}r(i) and {a mathematical formula}r(i+1). The total temporal cost of such walk is expressed by {a mathematical formula}c(r)=Ar(r(|T(r)|)). We shall informally refer to such process as walking a route r.
      </paragraph>
      <paragraph>
       Covering routes then constitute the action space for {a mathematical formula}D is a SRG-v game. Even when considering a single signal s, the number such of such routes is {a mathematical formula}O(|T(s)||T(s)|) in the worst case. However, some covering routes will never be played by {a mathematical formula}D due to any of the following two dominance arguments [34] and discarding dominated routes is crucial in the design of an efficient algorithm.
      </paragraph>
      <paragraph label="Definition 4">
       Intra-set dominanceGiven a starting vertex v, a signal s and two different covering routes {a mathematical formula}r,r′ such that {a mathematical formula}T(r)=T(r′), if {a mathematical formula}c(r)≤c(r′) then r dominates {a mathematical formula}r′.
      </paragraph>
      <paragraph label="Definition 5">
       Inter-set dominanceGiven a starting vertex v, a signal s and two different covering routes {a mathematical formula}r,r′, if {a mathematical formula}T(r)⊃T(r′) then r dominates {a mathematical formula}r′.
      </paragraph>
      <paragraph label="Definition 6">
       Furthermore, it is convenient to introduce the concept of covering set, which is strictly related to the concept of covering route. It is defined as follows. Covering setGiven a starting vertex v and a signal s, a covering set (covset) Q is a subset of {a mathematical formula}T(s) such that there exists a covering route r with {a mathematical formula}T(r)=Q.
      </paragraph>
      <paragraph>
       Let us focus on Definition 4. It suggests that we can safely use only one route per covering set. Covering sets suffice for describing all the outcomes of the game, since the agents' payoffs depend only on the fact that {a mathematical formula}A attacks a target t that is covered by {a mathematical formula}D or not, and in the worst case are {a mathematical formula}O(2|T(s)|), with a remarkable reduction of the search space w.r.t. {a mathematical formula}O(|T(s)||T(s)|). However, any algorithm restricting on covering sets should be able to determine whether or not a set of targets is a covering one, which is a difficult problem as well.
      </paragraph>
      <paragraph label="Definition 7">
       The decision problem COV-SET is defined as:INSTANCE: an instance of SRG-v with a target set T;QUESTION: is T a covering set? (Equivalently, does T admit any covering route r?)
      </paragraph>
      <paragraph label="Theorem 2">
       COV-SET is{a mathematical formula}NP-complete.
      </paragraph>
      <paragraph>
       Therefore, computing a covering route for a given set of targets (or deciding that no covering route exists) is not doable in polynomial time unless {a mathematical formula}P=NP. This shows that, while covering sets suffice for defining the payoffs of the game and therefore the size of the payoffs matrix can be bounded by the number of covering sets, in practice we also need covering routes to certify that a given subset of targets is covering. The impossibility to confine our algorithms to the space of covering sets seems to suggest a complexity worse than {a mathematical formula}O(2|T(s)|). However, in the next section we provide an algorithm with complexity {a mathematical formula}O(2|T(s)|) (neglecting polynomial terms) to enumerate all and only the covering sets and, for each of them, the associated covering route with minimum cost.
      </paragraph>
      <paragraph>
       Let us focus on Definition 5. Inter-Set dominance can be leveraged to introduce the concept of maximal covering sets (and routes) which could enable a further reduction in the set of actions available to {a mathematical formula}D.
      </paragraph>
      <paragraph label="Definition 8">
       MAXIMALITYGiven a covering set {a mathematical formula}Q=T(r) for some r, we say that Q and r are maximal if there is no other covering route {a mathematical formula}r′ such that {a mathematical formula}Q⊂T(r′).
      </paragraph>
      <paragraph>
       In the best case, when there is a route covering all the targets, the number of maximal covering sets is 1 (and we can safely restrict to a single minimum cost covering route over that set), while the number of covering sets (including the non-maximal ones) is {a mathematical formula}2|T(s)|. Thus, considering only maximal covering sets allows an exponential reduction of the payoffs matrix. In the worst case, when all the possible subsets composed of {a mathematical formula}|T(s)|/2 targets are maximal covering sets, the number of maximal covering sets is {a mathematical formula}O(2|T(s)|−2), while the number of covering sets is {a mathematical formula}O(2|T(s)|−1), allowing a reduction of the payoffs matrix by a factor of 2. Furthermore, if we knew a priori that Q is a maximal covering set, we could avoid searching for covering routes for any set of targets that strictly contains Q. When designing an algorithm to solve this problem, Definition 5 could then be exploited to introduce pruning techniques to save average compute time. However, the following result shows that deciding if a covering set is maximal is hard.
      </paragraph>
      <paragraph label="Definition 9">
       The decision problem MAX–COV-SET is defined as:INSTANCE: an instance of SRG-v with a target set T and a covering set {a mathematical formula}T′⊂T;QUESTION: is {a mathematical formula}T′ maximal?
      </paragraph>
      <paragraph label="Theorem 3">
       There is no polynomial-time algorithm for MAX–COV-SET unless{a mathematical formula}P=NP.
      </paragraph>
      <paragraph>
       Nevertheless, we show hereafter that there exists an algorithm computing all and only the maximal covering sets and one route for each of them (which potentially leads to an exponential reduction of the time needed for solving the linear program) with only an additional polynomial cost w.r.t. the enumeration of all the covering sets. Therefore, neglecting polynomial terms, our algorithm has a complexity of {a mathematical formula}O(2|T(s)|).
      </paragraph>
      <paragraph>
       Finally, we focus on the complexity of approximating the best solution in an SRG-v. When {a mathematical formula}D restricts its strategies to be pure, the problem is clearly not approximable in polynomial time even when the approximation ratio depends on {a mathematical formula}|T(s)|. The basic intuition is that, if a game instance admits the maximal covering route that covers all the targets and the value of all the targets is 1, then either the maximal covering route is played returning a utility of 1 to {a mathematical formula}D or any other route is played returning a utility of 0, but no polynomial-time algorithm can find the maximal covering route covering all the targets, unless {a mathematical formula}P=NP. On the other hand, it is interesting to investigate the case in which no restriction to pure strategies is present. We show that the problem keeps being hard.
      </paragraph>
      <paragraph label="Theorem 4">
       The optimization version of k–SRG-v, say OPT–SRG-v, is{a mathematical formula}APX-hard even in the restricted case in which the graph is metric, there is only one signal s, all targets{a mathematical formula}t∈T(s)have the same penetration time{a mathematical formula}d(t), and there exists a maximal covering route covering all the targets.
      </paragraph>
      <paragraph>
       The above theorem allows us to make two important remarks.
      </paragraph>
      <paragraph label="Remark 1">
       The above result does not exclude the existence of constant-ratio approximation algorithms for OPT–SRG-v. We conjecture that it is unlikely. OPT–SRG-v presents similarities with the (metric) DEADLINE–TSP, where the goal is to find the longest path of vertices each traversed before its deadline. The DEADLINE–TSP does not admit any constant-ratio approximation algorithm [35] and the best-known approximation algorithm has logarithmic approximation ratio [36]. The following observations can be produced about the relationships between OPT–SRG-v and DEADLINE–TSP:
      </paragraph>
      <list>
       <list-item label="•">
        when the maximal route covering all the targets in the OPT–SRG-v exists, the optimal solution of the OPT–SRG-v is also optimal for the DEADLINE–TSP applied to the same graph;
       </list-item>
       <list-item label="•">
        when the maximal route covering all the targets in the OPT–SRG-v does not exist, the optimal solutions of the two problems are different, even when we restrict us to pure-strategy solutions for the OPT–SRG-v;
       </list-item>
       <list-item label="•">
        approximating the optimal solution of the DEADLINE–TSP does not give a direct technique to approximate OPT–SRG-v, since we should enumerate all the subsets of targets and for each subset of targets we would need to execute the approximation of the DEADLINE–TSP, but this would require exponential time. We notice in addition that even the total number of sets of targets with logarithmic size is not polynomial, being {a mathematical formula}Ω(2log2⁡(|T|)), and therefore any algorithm enumerating them would require exponential time;
       </list-item>
       <list-item label="•">
        when the optimal solution of the OPT–SRG-v is randomized, examples of optimal solutions in which maximal covering routes are not played can be produced, showing that at the optimum it is not strictly necessary to play maximal covering routes, but even approximations suffice.
       </list-item>
      </list>
      <paragraph label="Remark 2">
       If it were possible to map DEADLINE–TSP instances to OPT–SRG-v instances where the maximal covering route covering all the targets exists, then it would trivially follow that OPT–SRG-v does not admit any constant-approximation ratio. We were not able to find such a mapping and we conjecture that, if there is an approximation-preserving reduction from DEADLINE–TSP to OPT–SRG-v, then we cannot restrict to such instances. The study of instances of OPT–SRG-v where mixed strategies may be optimal make the treatment very challenging.
      </paragraph>
     </section>
     <section label="3.2">
      <section-title>
       Dynamic-programming algorithm
      </section-title>
      <paragraph>
       We start by presenting two algorithms. The first one is exact, while the second one is an approximation algorithm. Both algorithms are based on a dynamic programming approach.
      </paragraph>
      <section label="3.2.1">
       <section-title>
        Exact algorithm
       </section-title>
       <paragraph>
        In this section we provide an algorithm to compute the strategies available to {a mathematical formula}D when v is the current vertex and signal s has been generated by the alarm system. The idea is to adopt a dynamic programming method that enumerates covering sets of increasing cardinalities. Each covering set is obtained by a sequence of expansions that, starting from the empty set, add one target at each iteration. We denote a covering set by {a mathematical formula}Qv,tk where k indicates its cardinality while v and t denote the starting vertex of {a mathematical formula}D and the last target added to the set, respectively. The algorithm operates in such a way that the sequence of targets corresponding to the expansions made to obtain {a mathematical formula}Qv,tk is a covering route for that set. Informally, we shall call it the generative route of {a mathematical formula}Qv,tk and we will denote with {a mathematical formula}c(Qv,tk) its temporal cost. We choose to obtain this by requiring any expansion to be admissible with respect to three conditions. Given a set {a mathematical formula}Qv,tk a new set {a mathematical formula}Qv,wk+1=Qv,tk∪{w} can be obtained if:
       </paragraph>
       <list>
        <list-item label="1.">
         w is not covered in the current covering set, that is {a mathematical formula}w∈T(s)∖Qv,tk;
        </list-item>
        <list-item label="2.">
         w can be covered by {a mathematical formula}d(w) by extending the generative route of {a mathematical formula}Qv,tk with a shortest walk from t to w, that is {a mathematical formula}d(w)≥c(Qv,tk)+ωt,w⁎;
        </list-item>
        <list-item label="3.">
         call {a mathematical formula}t′ a target visited by a shortest path from t to w, if {a mathematical formula}t′∉Qv,tk then it cannot be covered, that is {a mathematical formula}d(t′)&lt;c(Qv,tk)+ωt,t′⁎.
        </list-item>
       </list>
       <paragraph>
        Conditions 1 and 2 require any expansion to form a new covering set consistent with Definition 6, thus ensuring the algorithm's soundness. Condition 3 requires {a mathematical formula}Qv,tk to be a proper descriptor of its generative route, meaning that such route, once walked, covers uniquely the targets included in {a mathematical formula}Qv,tk and not targets outside it. This last requirement is an operational choice to reduce the number of expansions made in each iteration of the algorithm. Consider for instance a graph with degree bounded by 3, Condition 3 allows us to generate in the worst case 3 new covering sets at each expansion round instead of {a mathematical formula}|T|. Notice that under Condition 3 the algorithm can still generate any maximal covering set.
       </paragraph>
       <paragraph label="Lemma 5">
        Any maximal covering set can be generated from the empty set with a sequence of admissible expansions.
       </paragraph>
       <paragraph label="Proof sketch">
        Consider an expansion which, by adding a target w, violates Condition 3 for a target {a mathematical formula}t′. Such expansion can always be split in two admissible ones. The first adding {a mathematical formula}t′, the second adding w. The same rationale works for multiple expansions and multiple {a mathematical formula}t′ and clearly applies to maximal covering sets which are a subset of covering sets. □
       </paragraph>
       <paragraph>
        Condition 3 can be exploited to reduce the required compute time but, rigorously speaking, it presents a drawback. To establish if target w can be added to set {a mathematical formula}Qv,tk the algorithm needs to check every shortest path from t to w, and such paths can be, in the worst case, exponentially many. We can cope with this by adopting the following simplification. We fix a set of canonical shortest paths by running the Floyd–Warshall algorithm. Then, given t and w, we fetch the canonical shortest path between them and we check Condition 3 assuming that such path is unique. If the condition is not verified under this assumption then it is also not verified in its original definition. If otherwise, the condition is verified, then the algorithm (assuming validity of Conditions 1 and 2) might obtain a covering set {a mathematical formula}Q¯v,wk+1 which is not a proper one, meaning that by walking its generative route at least one target {a mathematical formula}t′∉Q¯v,wk+1 gets covered. Let us assume that this is the case and, w.l.o.g., that {a mathematical formula}t′ is the only invalidating target. The algorithm's current solution representation (the set {a mathematical formula}Q¯v,wk+1) would then be inconsistent with the actual solution (the generative route). By Lemma 5 though, we know that the algorithm would generate also set {a mathematical formula}Qv,wk+2 making two admissible expansions with {a mathematical formula}t′ and w to {a mathematical formula}Qv,tk. Since {a mathematical formula}Qv,wk+2=Q¯v,wk+1∪{t′} the non-proper covering set {a mathematical formula}Q¯v,wk+1 is removable by inter-set dominance (Definition 5). Obviously this workaround comes at an additional cost: the algorithm unnecessarily generates the set {a mathematical formula}Q¯v,wk+1 which under the proper definition of Condition 3 would have been avoided. Still, the above solution turned out very convenient since exponential multiplicity of shortest paths is very unlikely in graphs representing real environments.
       </paragraph>
       <paragraph>
        In Algorithm 1 we provide full technical details. Covering sets obtained by the algorithm are grouped in collections: {a mathematical formula}Cv,tk denotes the collection of all covering sets of cardinality k where the last expansion added target t. After the required initialization steps (Lines 1 and 2) for any generated {a mathematical formula}Qv,tk−1 we compute the set of admissible expansions {a mathematical formula}Q+ (Line 6) and we apply each one of them (Line 8). In Step 9, we make use of a procedure called {a mathematical formula}Search(Q,C) where Q is a covering set and {a mathematical formula}C is a collection of covering sets. The procedure outputs Q if {a mathematical formula}Q∈C and ∅ otherwise. (We adopted an efficient implementation of such procedure which can run in {a mathematical formula}O(|T(s)|). More precisely, we represent a covering set Q as a binary vector of length {a mathematical formula}|T(s)| where the i-th component is set to 1 if target {a mathematical formula}ti∈Q and 0 otherwise. A collection of covering sets C can then be represented as a binary tree with depth {a mathematical formula}|T(s)|. The membership of a covering set Q to collection C is represented with a branch of the tree in such a way that if {a mathematical formula}ti∈Q then we have a left edge at depth {a mathematical formula}i−1 on such branch. We can easily determine if {a mathematical formula}Q∈C by checking if traversing a left (right) edge in the tree each time we read a 1 (0) in Q's binary vector we reach a leaf node at depth {a mathematical formula}|T(s)|. The insertion of a new covering set in the collection can be done in the same way by traversing existing edges and expanding the tree where necessary.) If the newly generated covering set is not present in its collection or is already present with a higher cost (Step 10), then collection and cost are updated (Steps 11 and 12).
       </paragraph>
       <paragraph>
        After Algorithm 1 completed its execution, for any arbitrary {a mathematical formula}T′⊆T we can easily obtain the temporal cost of its shortest covering route as{a mathematical formula} where {a mathematical formula}Y|T′|=∪t∈T′{Search(T′,Cv,t|T′|)} (notice that if {a mathematical formula}T′ is not a covering set then {a mathematical formula}c⁎(T′)=∞). For the sake of simplicity, Algorithm 1 does not specify how to carry out two sub-tasks we describe in the following.
       </paragraph>
       <paragraph>
        The first one is the annotation of dominated covering sets. Each time Steps 11 and 12 are executed, a covering set is added to some collection. Let us call it Q and assume it has cardinality k. Each time a new Q has to be included at cardinality k, we mark all the covering sets at cardinality {a mathematical formula}k−1 that are dominated by Q (Definition 5). The number of sets that can be dominated is in the worst case {a mathematical formula}|Q| since each of them has to be searched in collection {a mathematical formula}Cv,tk−1 for each feasible terminal t and, if found, marked as dominated. The number of terminal targets and the cardinality of Q are at most n and, as described above, the {a mathematical formula}Search procedure takes {a mathematical formula}O(|T(s)|). Therefore, dominated covering sets can be annotated with a {a mathematical formula}O(|T(s)|3) extra cost at each iteration of Algorithm 1. We can only mark and not delete dominated covering sets since they can generate non-dominated ones in the next iteration.
       </paragraph>
       <paragraph>
        The second task is the generation of routes. To do this we maintain a list of generating routes by iteratively appending terminal vertex w to the generative route of {a mathematical formula}Qv,tk−1 when set {a mathematical formula}Qv,tk−1∪{w} is included in its corresponding collection. At the end of the algorithm only routes that correspond to non-dominated covering sets are returned. Maintaining such a list introduces a {a mathematical formula}O(1) cost.
       </paragraph>
       <paragraph label="Theorem 6">
        Algorithm 1is an exact algorithm and has worst-case complexity of{a mathematical formula}O(|T(s)|22|T(s)|)since it has to compute covering sets up to cardinality{a mathematical formula}|T(s)|. With annotations of dominances and routes generation the whole algorithm yields a worst-case complexity of{a mathematical formula}O(|T(s)|52|T(s)|).
       </paragraph>
       <paragraph>
        Notice that the algorithm is exact since it is based on an enumeration procedure.
       </paragraph>
       <paragraph label="Example 3">
        We provide a simple example of execution of Algorithm 1. Consider a problem instance with a single signal, arbitrary target values while topology and penetration times are as follow:{a mathematical formula}We report the expansions made by the algorithm for increasing cardinalities (value of k) in the following table.{a mathematical formula}Notice that Constraint 3 intervenes both when expanding covering sets with {a mathematical formula}k=1 and {a mathematical formula}k=2. In the table, c indicates the temporal cost of the relative covset while the covset marked with ⧫ dominates the one marked with ◊ while the covset marked with ■ dominates the one marked with □.
       </paragraph>
      </section>
      <section label="3.2.2">
       <section-title>
        Approximation algorithm
       </section-title>
       <paragraph>
        The dynamic programming algorithm presented in the previous section cannot be directly adopted to approximate the maximal covering routes. We notice that even in the case we introduce a logarithmic upper bound over the size of the covering sets generated by Algorithm 1, we could obtain a number of routes that is {a mathematical formula}O(2log2⁡(|T(s)|)), and therefore exponential. Thus, our goal is to design a polynomial-time algorithm that generates a polynomial number of good covering routes. We observe that if we have a total order over the vertices and we work over a complete graph of the targets where each edge corresponds to the shortest path, we can find in polynomial time the maximal covering routes subject to the constraint that, given any pair of targets {a mathematical formula}t,t′ in a route, t can precede {a mathematical formula}t′ in the route only if t precedes {a mathematical formula}t′ in the order. We call monotonic a route satisfying a given total order. Algorithm 2 returns the maximal monotonic covering routes when the total order is lexicographic (trivially, to change the order, it is sufficient to re-label the targets).
       </paragraph>
       <paragraph>
        Algorithm 2 is based on dynamic programming and works as follows. {a mathematical formula}R(k,l) is a matrix storing in each cell one route, while {a mathematical formula}L(k,l) is a matrix storing in each cell the maximum lateness of the corresponding route (see below for the meaning of k and l). The maximum lateness of a route r captures the maximum delay between a target's first visit and its deadline. Formally, it is defined as {a mathematical formula}maxt∈T(s)⁡Ar(t)−d(t). The route stored in {a mathematical formula}R(k,l) is the one with the minimum lateness among all the monotonic ones covering l targets where {a mathematical formula}tk is the first visited target. Thus, basically, when {a mathematical formula}l=1, {a mathematical formula}R(k,l) contains the route {a mathematical formula}〈v,tk〉, while, when {a mathematical formula}l&gt;1, {a mathematical formula}R(k,l) is defined appending to {a mathematical formula}R(k,1) the best (in terms of minimizing the maximum lateness) route {a mathematical formula}R(k′,l−1) for every {a mathematical formula}k′&gt;k, in order to satisfy the total order. The whole set of routes in R are returned.{sup:8} The complexity of Algorithm 2 is {a mathematical formula}O(|T(s)|3), except the time needed to find all the shortest paths.
       </paragraph>
       <paragraph>
        We use different total orders (breaking ties randomly) over the set of targets, collecting all the routes generated using each total order:
       </paragraph>
       <list>
        <list-item label="•">
         increasing order {a mathematical formula}ωv,t⁎: the rationale is that targets close to v will be visited before targets far from v;
        </list-item>
        <list-item label="•">
         increasing order {a mathematical formula}d(t): the rationale is that targets with short deadlines will be visited before targets with long deadlines;
        </list-item>
        <list-item label="•">
         increasing order {a mathematical formula}d(t)−ωv,t⁎ (we call this quantity excess time): the rationale is that targets with short excess time will be visited before targets with long excess time.
        </list-item>
       </list>
       <paragraph>
        In addition, we use a random restart generating random permutations over the targets.
       </paragraph>
       <paragraph label="Theorem 7">
        Algorithm 2provides an approximation with ratio{a mathematical formula}Ω(1|T(s)|).
       </paragraph>
       <paragraph label="Proof sketch">
        The worst case for the approximation ratio of our algorithm occurs when the covering route including all the targets exists and each covering route returned by our heuristic algorithm visits only one target. In that case, the optimal expected utility of {a mathematical formula}D is 1. Our algorithm, in the worst case in which {a mathematical formula}π(t)=1 for every target t, returns an approximation ratio {a mathematical formula}Ω(1|T(s)|). It is straightforward to see that, in other cases, the approximation ratio is larger. □
       </paragraph>
      </section>
     </section>
     <section label="3.3">
      <section-title>
       Branch-and-bound algorithms
      </section-title>
      <paragraph>
       The dynamic programming algorithm presented in the previous section essentially implements a breadth-first search. In some specific situations, depth-first search could outperform breadth-first search, e.g., when penetration times are relaxed and good heuristics lead a depth-first search to find in a brief time the maximal covering route, avoiding to scan an exponential number of routes as the breadth-first search would do. In this section, we adopt the branch-and-bound approach to design both an exact algorithm and an approximation algorithm. In particular, in Section 3.3.1 we describe our exact algorithm, while in Section 3.3.2 we present the approximation one.
      </paragraph>
      <section label="3.3.1">
       <section-title>
        Exact algorithm
       </section-title>
       <paragraph>
        Our branch-and-bound algorithm (see Algorithm 3) is a tree-search based algorithm working on the space of the covering routes and returning a set of covering routes R. It works as follows.
       </paragraph>
       <paragraph>
        Initial step. We exploit two global set variables, {a mathematical formula}CLmin and {a mathematical formula}CLmax initially set to empty (Steps 1–2 of Algorithm 3). These variables contain closed covering routes, namely covering routes which cannot be further expanded without violating the penetration time of at least one target during the visit. {a mathematical formula}CLmax contains the covering routes returned by the algorithm, while {a mathematical formula}CLmin is used for pruning as discussed below. Given a starting vertex v and a signal s, for each target {a mathematical formula}t∈T(s) such that {a mathematical formula}ωv,t⁎≤d(t) we generate a covering route {a mathematical formula}r=〈v,t〉 with {a mathematical formula}r(0)=v and {a mathematical formula}r(1)=t (Steps 5 of Algorithm 3). Thus, {a mathematical formula}D has at least one covering route per target that can be covered in time from v. Notice that if, for some t, such minimal route does not exist, then target t cannot be covered (even the shortest path from the starting vertex v cannot guarantee capture). This does not guarantee that {a mathematical formula}A will attack t with full probability since, depending on the values π, {a mathematical formula}A could find more profitable to randomize over a different set of targets. The meaning of parameter ρ (used in Line 5 of Algorithm 3) is described below.
       </paragraph>
       <paragraph>
        Route expansions. The subsequent steps essentially evolve on each branch according to a depth-first search with backtracking limited by ρ. The choice of ρ directly influences the behavior of the algorithm and consequently its complexity. Each node in the search tree represents a route r built so far starting from an initial route {a mathematical formula}〈v,t〉. At each iteration, route r is expanded by inserting a new target at a particular position. We denote with {a mathematical formula}r+(q,p) the route obtained by inserting target q after the p-th target in r. Notice that every expansion of r will preserve the relative order with which targets already present in r will be visited. The collection of all the feasible expansions {a mathematical formula}r+s (i.e., the ones that are covering routes) is denoted by {a mathematical formula}R+ and it is ordered according to a heuristic that we describe below. Algorithm 6, described below, is used to generate {a mathematical formula}R+ (Step 1 of Algorithm 4). In each open branch (i.e., {a mathematical formula}R+≠∅), if the depth of the node in the tree is smaller or equal to {a mathematical formula}⌈ρ⋅|T(s)|⌉ then backtracking is disabled (Steps 7–10 of Algorithm 4), while, if the depth is larger than such value, is enabled (Steps 5–6 of Algorithm 4). This is equivalent to fix the relative order of the first (at most) {a mathematical formula}⌈ρ⋅|T(s)|⌉ inserted targets in the current route. In this case, with {a mathematical formula}ρ=0 we do not rely on the heuristics at all, full backtracking is enabled, the tree is fully expanded and the returned R is complete, i.e., it contains all the non-dominated covering routes. Route r is repeatedly expanded in a greedy fashion until no insertion is possible. As a result, Algorithm 4 generates at most {a mathematical formula}|T(s)| covering routes.
       </paragraph>
       <paragraph>
        Pruning.Algorithm 5 is in charge of updating {a mathematical formula}CLmin and {a mathematical formula}CLmax each time a route r cannot be expanded and, consequently, the associated branch must be closed. We call {a mathematical formula}CLmin the minimal set of closed routes. This means that a closed route r belongs to {a mathematical formula}CLmin only if {a mathematical formula}CLmin does not already contain another {a mathematical formula}r′⊆r. Steps 1–4 of Algorithm 5 implement such condition: first, in Steps 2–3 any route {a mathematical formula}r′ such that {a mathematical formula}r′⊇r is removed from {a mathematical formula}CLmin, then route r is inserted in {a mathematical formula}CLmin. Routes in {a mathematical formula}CLmin are used by Algorithm 6 in Steps 2 and 6 for pruning during the search. More precisely, a route r is not expanded with a target q at position p if there exists a route {a mathematical formula}r′∈CLmin such that {a mathematical formula}r′⊆r+(q,p). This pruning rule is safe since by definition if {a mathematical formula}r′∈CLmin, then all the possible expansions of {a mathematical formula}r′ are unfeasible and if {a mathematical formula}r′⊆r then r can be obtained by expanding from {a mathematical formula}r′. This pruning mechanism explains why once a route r is closed is always inserted in {a mathematical formula}CLmin without checking the insertion against the presence in {a mathematical formula}CLmin of a route {a mathematical formula}r″ such that {a mathematical formula}r″⊆r. Indeed, if such route {a mathematical formula}r″ would be included in {a mathematical formula}CLmin we would not be in the position of closing r, having r being pruned before by Algorithm 6.
       </paragraph>
       <paragraph>
        We use {a mathematical formula}CLmax to maintain a set of the generated maximal closed routes. This means that a closed route r is inserted here only if {a mathematical formula}CLmax does not already contain another {a mathematical formula}r′ such that {a mathematical formula}r′⊇r. This set keeps track of closed routes with maximum number of targets. Algorithm 5 maintains this set by inserting a closed route r in Step 12 only if no route {a mathematical formula}r′⊇r is already present in {a mathematical formula}CLmax. Once the whole algorithm terminates, {a mathematical formula}CLmax contains the final solution.
       </paragraph>
       <paragraph>
        Heuristic function. A key component of this algorithm is the heuristic function that drives the search. The heuristic function is defined as {a mathematical formula}hr:{T(s)∖T(r)}×{1…|T(r)|}→Z, where {a mathematical formula}hr(t′,p) evaluates the cost of expanding r by inserting target {a mathematical formula}t′ after the p-th target of r. The basic idea, inspired by [37], is to adopt a conservative approach, trying to preserve feasibility. Given a route r, let us define the possible forward shift of r as the minimum temporal margin in r between the arrival at a target t and {a mathematical formula}d(t):{a mathematical formula}
       </paragraph>
       <paragraph>
        The extra mileage{a mathematical formula}er(t′,p) for inserting target {a mathematical formula}t′ after position p is the additional traveling cost to be paid:{a mathematical formula}
       </paragraph>
       <paragraph>
        The advance time that such insertion gets with respect to {a mathematical formula}d(t′) is defined as:{a mathematical formula}
       </paragraph>
       <paragraph>
        Finally, {a mathematical formula}hr(t′,p) is defined as:{a mathematical formula}
       </paragraph>
       <paragraph>
        We partition the set {a mathematical formula}T(s) in two sets {a mathematical formula}Ttight and {a mathematical formula}Tlarge, where {a mathematical formula}t∈Ttight if {a mathematical formula}d(t)&lt;δ⋅ωv,t⁎ and {a mathematical formula}t∈Tlarge otherwise ({a mathematical formula}δ∈R is a parameter). The previous inequality is a non-binding choice we made to discriminate targets with a tight penetration time from those with a large one. Initially, we insert all the tight targets and only subsequently we insert the non-tight targets. We use the two sets according to the following rules (see Algorithm 6):
       </paragraph>
       <list>
        <list-item label="•">
         the insertion of a target belonging to {a mathematical formula}Ttight is always preferred to the insertion of a target belonging to {a mathematical formula}Tlarge, independently of the insertion position;
        </list-item>
        <list-item label="•">
         insertions of {a mathematical formula}t∈Ttight are ranked according to h considering first the insertion position and then the target;
        </list-item>
        <list-item label="•">
         insertions of {a mathematical formula}t∈Tlarge are ranked according to h considering first the target and then the insertion position.
        </list-item>
       </list>
       <paragraph>
        The rationale behind this rule is that targets with a tight penetration time should be inserted first and at their best positions. On the other hand, targets with a large penetration time can be covered later. Therefore, in this last case, it is less important which target to cover than when to cover it.
       </paragraph>
       <paragraph label="Theorem 8">
        Algorithm 3with{a mathematical formula}ρ=0is an exact algorithm and has an exponential computational complexity since it builds a full tree of covering routes, with worst-case size{a mathematical formula}O(|T(s)||T(s)|).
       </paragraph>
      </section>
      <section label="3.3.2">
       <section-title>
        Approximation algorithm
       </section-title>
       <paragraph>
        Since ρ determines the completeness degree of the generated tree, we can exploit Algorithm 3 tuning ρ to obtain an approximation algorithm that is faster w.r.t. the exact one.
       </paragraph>
       <paragraph>
        In fact, when {a mathematical formula}ρ&lt;1 completeness is not guaranteed in favor of a less computational effort. In this case, the only guarantees that can be provided for each covering route {a mathematical formula}r∈CLmax, once the algorithm terminates are:
       </paragraph>
       <list>
        <list-item label="•">
         no other {a mathematical formula}r′∈CLmax dominates r;
        </list-item>
        <list-item label="•">
         no other {a mathematical formula}r′∉CLmax such that {a mathematical formula}r⊆r′ dominates r. Notice this does not prevent the existence of a route {a mathematical formula}r″ not returned by the algorithm that visits targets {a mathematical formula}T(r) in a different order and that dominates r.
        </list-item>
       </list>
       <paragraph>
        When ρ is chosen as {a mathematical formula}k|T(s)| (where {a mathematical formula}k∈N is a parameter), the complexity of generating covering routes becomes polynomial in the size of the input. We can state the following theorem, whose proof is analogous to that one of Theorem 7.
       </paragraph>
       <paragraph label="Theorem 9">
        Algorithm 4with{a mathematical formula}ρ=k|T(s)|provides an approximation with ratio{a mathematical formula}Ω(1|T(s)|)and runs in{a mathematical formula}O(|T(s)|3)given that heuristic{a mathematical formula}hrcan be computed in{a mathematical formula}O(|T(s)|2).
       </paragraph>
      </section>
     </section>
     <section label="3.4">
      Solving SRG-v
      <paragraph>
       Now we can formulate the problem of computing the optimal signal–response strategy for {a mathematical formula}D. Let us denote with {a mathematical formula}σv,sD(r) the probability with which {a mathematical formula}D plays route r under signal s and with {a mathematical formula}Rv,s the set of all the routes available to {a mathematical formula}D generated by some algorithm. We introduce function {a mathematical formula}UA(r,t), representing the utility function of {a mathematical formula}A and defined as follows:{a mathematical formula}
      </paragraph>
      <paragraph>
       The best {a mathematical formula}D's strategy (i.e., the maxmin strategy) can be found by solving the following linear mathematical programming problem:{a mathematical formula}
      </paragraph>
      <paragraph>
       The size of the mathematical program is composed of {a mathematical formula}|T|+|S| constraints (excluded ≥0 constraints) and {a mathematical formula}O(|V||S|maxv,s⁡{|Rv,s|}) variables. This shows that the hardness is due only to {a mathematical formula}maxv,s⁡{|Rv,s|}, which, in its turn, depends only on {a mathematical formula}|T(s)|. We provide the following remark.
      </paragraph>
      <paragraph label="Remark 3">
       We observe that the discretization of the environment as a graph is as accurate as the number of vertices is large, corresponding to reduce the size of the areas associated with each vertex, as well as to reduce the temporal interval associated with each turn of the game. Our algorithms show that increasing the accuracy of the model in terms of number of vertices requires polynomial time.
      </paragraph>
     </section>
    </section>
    <section label="4">
     <section-title>
      Patrolling game
     </section-title>
     <paragraph>
      In this section, we focus on the PG. Specifically, in Section 4.1 we state our main result showing that patrolling is not necessary when an alarm system is present, in Section 4.2 we propose the algorithm to deal with the PG, in Section 4.3 we summarize the complexity results about Question 1, Question 2, Question 3, Question 4.
     </paragraph>
     <section label="4.1">
      <section-title>
       Stand still
      </section-title>
      <paragraph>
       We focus on the problem of finding the best patrolling strategy given that we know the best signal–response strategy for each vertex v in which {a mathematical formula}D can place. Given the current vertex of {a mathematical formula}D and the sequence of the last, say n, vertices visited by {a mathematical formula}D (where n is a tradeoff between effectiveness of the solution and computational effort), a patrolling strategy is usually defined as a randomization over the next adjacent vertices [9]. We define {a mathematical formula}v⁎=argminv∈V{gv}, where {a mathematical formula}gv is the value returned by the optimization problem described in Section 3.4, as the vertex that guarantees the maximum expected utility to {a mathematical formula}D over all the SRG-vs. We show that the maxmin equilibrium strategy in PG prescribes that {a mathematical formula}D places at {a mathematical formula}v⁎, waits for a signal, and responds to it.
      </paragraph>
      <paragraph label="Theorem 10">
       Without false positives and missed detections, if{a mathematical formula}∀t∈Twe have that{a mathematical formula}|S(t)|≥1, then any patrolling strategy is dominated by the placement in{a mathematical formula}v⁎.
      </paragraph>
      <paragraph label="Proof">
       Any patrolling strategy different from the placement in {a mathematical formula}v⁎ should necessarily visit a vertex {a mathematical formula}v′≠v⁎. Since the alarm system is not affected by missed detections, every attack will raise a signal that, in turn, will raise a response yielding an utility of {a mathematical formula}gx where x is the current position of {a mathematical formula}D at the moment of the attack. Since {a mathematical formula}A can observe the current position of {a mathematical formula}D before attacking, {a mathematical formula}x=argmaxv∈P{gv} where P is the set of the vertices patrolled by {a mathematical formula}D. Obviously, for any {a mathematical formula}P⊇{v⁎} we would have that {a mathematical formula}gx≥gv⁎ and therefore placing at {a mathematical formula}v⁎ and waiting for a signal is the best strategy for {a mathematical formula}D. □
      </paragraph>
      <paragraph>
       The rationale is based upon the fact that, without false positives and missed detections, the signal response strategy solely depends on the current vertex occupied by {a mathematical formula}D and on the generated signal (not depending then on previously visited vertices). So, if the patrolling strategy of {a mathematical formula}D prescribes to patrol a set of vertices, say {a mathematical formula}V′, then, since {a mathematical formula}A can observe the position of {a mathematical formula}D, the best strategy of {a mathematical formula}A is to wait for {a mathematical formula}D being in {a mathematical formula}v′=argmaxv∈V′{gv} and then to attack. Thus, by definition of {a mathematical formula}gv⁎, if {a mathematical formula}D leaves {a mathematical formula}v⁎ to patrol additional vertices the expected utility it receives is no larger than that it receives from staying in {a mathematical formula}v⁎.
      </paragraph>
      <paragraph>
       The validity of Theorem 10 goes beyond the model studied in this work. Indeed, it can be easily shown how such results keep valid when having multiple resource controlled by {a mathematical formula}D. Also, a deeper analysis of Theorem 10 can show that its scope does include cases where missed detections are present up to a non-negligible extent. For such cases, placement-based strategies keep being optimal even in the case when the alarm systems fails in detecting an attack. We encode the occurrence of this robustness property in the following proposition, which we shall prove by a series of examples.
      </paragraph>
      <paragraph label="Proposition 1">
       There exist Patrolling Games where staying in a vertex, waiting for a signal, and responding to it is the optimal patrolling strategy for{a mathematical formula}Deven with a missed detection rate{a mathematical formula}α=0.5.
      </paragraph>
      <paragraph label="Proof">
       The expected utility for {a mathematical formula}D given by the placement in {a mathematical formula}v⁎ is {a mathematical formula}(1−α)(1−gv⁎), where {a mathematical formula}(1−α) is the probability with which the alarm system correctly generates a signal upon an attack and {a mathematical formula}(1−gv⁎) denotes {a mathematical formula}D's payoff when placed in {a mathematical formula}v⁎. A non-placement-based patrolling strategy will prescribe, by definition, to move between at least two vertices. From this simple consideration, we observe that an upper bound to the expected utility of any non-placement strategy is entailed by the case where {a mathematical formula}D alternately patrols vertices {a mathematical formula}v⁎ and {a mathematical formula}v2⁎, where {a mathematical formula}v2⁎ is the second best vertex in which {a mathematical formula}D can statically place. Such scenario gives us an upper bound over the expected utility of non-placement strategies, namely {a mathematical formula}1−gv2⁎. It follows that a sufficient condition for the placement in {a mathematical formula}v⁎ being optimal is given by the following inequality:{a mathematical formula}To prove Proposition 1, it then suffices to provide a Patrolling Game instance where Equation (1) holds under some non-null missed detection rate α. In Fig. 4(a) and Fig. 4(b), we report two of such examples. The depicted settings have unitary edges except where explicitly indicated. For both, without missed detections, the best patrolling strategy is a placement {a mathematical formula}v⁎=4. When allowing missed detections, in Fig. 4(a) it holds that {a mathematical formula}gv⁎=0 and {a mathematical formula}gv2⁎=0.75, where {a mathematical formula}v⁎=4 and {a mathematical formula}v2⁎=1. Thus, by Equation (1), placement {a mathematical formula}v⁎=4 is the optimal strategy for {a mathematical formula}α≤0.25. Under the same reasoning scheme, in Fig. 4(b) we have that {a mathematical formula}gv⁎=0 and {a mathematical formula}gv2⁎=0.5, making the placement {a mathematical formula}v⁎=4 optimal for any {a mathematical formula}α≤0.5. □
      </paragraph>
      <paragraph>
       It is reasonable to expect that a similar result holds also for the case with false positives. However, dealing with false positives is much more intricate than handling false negatives and requires new models. For example, {a mathematical formula}D could respond to an alarm signal only with a given probability and with the remaining probability could stay in the current vertex. For this reason, we leave the treatment of false positives and a more accurate treatment of false negatives to future works.
      </paragraph>
     </section>
     <section label="4.2">
      <section-title>
       Computing the best placement
      </section-title>
      <paragraph>
       Under the absence of false positives and missed detections, Theorem 10 simplifies the computation of the patrolling strategy by reducing it to the problem of finding {a mathematical formula}v⁎. To such aim, we must solve a SRG-v for each possible starting vertex v and select the one with the maximum expected utility for {a mathematical formula}D. Algorithm 7 depicts the solving algorithm. Function {a mathematical formula}SolveSRG(v) returns the optimal value {a mathematical formula}1−gv⁎. The complexity is linear in {a mathematical formula}|V|, once {a mathematical formula}gv has been calculated for every v.
      </paragraph>
      <paragraph>
       Since all the vertices are possible starting points, we should face this hard problem (see Theorem 1) {a mathematical formula}|V| times, computing, for each signal, the covering routes from all the vertices. To avoid this issue, we ask whether there exists an algorithm that in the worst case allows us to consider a number of iterations such that solving the problem for a given starting vertex v could help us finding the solution for another starting vertex {a mathematical formula}v′. In other words, considering a specific set of targets, we wonder whether a solution for COV-SET with starting vertex v can be used to derive, in polynomial time, a solution to COV-SET for another starting vertex {a mathematical formula}v′. This would allow us to solve an exponential-time problem only once instead of solving it for each vertex of the graph. To answer this question, we resort to hardness results for reoptimization, also called locally modified problems [38]. We show that, even if we know all the covering routes from a starting vertex, once we changed the starting vertex selecting an adjacent one, finding the covering routes from the new starting vertex is hard.
      </paragraph>
      <paragraph label="Definition 10">
       lm–COV–ROUTEA locally modified covering route (lm–COV–ROUTE) problem is defined as follows:INSTANCE: graph {a mathematical formula}G=(V,E), a set of targets T with penetration times d, two starting vertices {a mathematical formula}v1 and {a mathematical formula}v2 that are adjacent, and a covering route {a mathematical formula}r1 with {a mathematical formula}r1(0)=v1 such that {a mathematical formula}T(r1)=T.QUESTION: is there {a mathematical formula}r2 with {a mathematical formula}r2(0)=v2 and {a mathematical formula}T(r2)=T?
      </paragraph>
      <paragraph label="Theorem 11">
       lm–COV–ROUTE is{a mathematical formula}NP-complete.
      </paragraph>
      <paragraph>
       This shows that iteratively applying Algorithm 1 to SRG-v for each starting vertex v and then choosing the vertex with the highest utility is the best we can do in the worst case.
      </paragraph>
     </section>
     <section label="4.3">
      <section-title>
       Summary of results
      </section-title>
      <paragraph>
       We summarize our computational results about Question 1, Question 2, Question 3, Question 4 in Table 1, including also results about the resolution of the PG. We use ‘?’ for the problems remained open in this paper.
      </paragraph>
     </section>
    </section>
    <section label="5">
     <section-title>
      Experimental evaluation
     </section-title>
     <paragraph>
      We implemented our algorithms in MATLAB and we used a 2.33 GHz LINUX machine to run our experiments. For a better analysis, we provide two different experimental evaluations. In Section 5.1, we apply our algorithms to worst-case instances, in order to evaluate the worst-case performance of the algorithms and to investigate experimentally the gap between our {a mathematical formula}APX-hardness result and the theoretical guarantees of our approximation algorithms. In Section 5.2, we apply our algorithms to a specific realistic instance we mentioned in Section 1, Expo 2015.
     </paragraph>
     <section label="5.1">
      <section-title>
       Worst-case instances analysis
      </section-title>
      <paragraph>
       We evaluate the scalability of Algorithm 1 and the quality of the solution returned by our approximation algorithms for a set of instances of SRG-v. We do not include results on the evaluation of the algorithm to solve completely a PG, given that it trivially requires asymptotically {a mathematical formula}|V| times the effort required by the resolution of a single instance of SRG-v. In the next section we describe our experimental setting, in Section 5.1.2 we provide a quantitative analysis of the exact algorithms while in Section 5.1.3 we evaluate the quality of our approximations.
      </paragraph>
      <section label="5.1.1">
       <section-title>
        Setting
       </section-title>
       <paragraph>
        We can build hard instances for our problem from instances of HAMILTONIAN-PATH (HP). More precisely, these worst-case instances can be easily reduced from any instance of (HP) showing how they admit a covering route for all the targets if and only if the corresponding instance of HP admits an Hamiltonian path. They are defined as follows:
       </paragraph>
       <list>
        <list-item label="•">
         all the vertices are targets;
        </list-item>
        <list-item label="•">
         edge costs are set to 1;
        </list-item>
        <list-item label="•">
         there is only one signal;
        </list-item>
        <list-item label="•">
         penetration times are set to {a mathematical formula}|T|−1;
        </list-item>
        <list-item label="•">
         values are drawn from {a mathematical formula}(0,1] with uniform probability for all the targets;
        </list-item>
        <list-item label="•">
         the number of edges is drawn from a normal distribution with mean ϵ, said edge density and defined as {a mathematical formula}ϵ=|E|/|T|(|T|−1)2;
        </list-item>
        <list-item label="•">
         starting vertex v is drawn among the targets of T with uniform probability.
        </list-item>
       </list>
       <paragraph>
        We explore two parameter dimensions: the number of targets {a mathematical formula}|T| and the value of edge density ϵ. In particular, we use the following values:{a mathematical formula} For each combination of values of {a mathematical formula}|T| and ϵ, we randomly generate 100 instances with the constraint that, if {a mathematical formula}ϵ|T|22&lt;|T|, we introduce additional edges in order to assure the graph connectivity. The suitability of our worst-case analysis is corroborated by the results obtained with a realistic setting (see Section 5.2), which present hard subproblems characterized by the features listed above.
       </paragraph>
      </section>
      <section label="5.1.2">
       <section-title>
        Exact algorithms scalability
       </section-title>
       <paragraph>
        We report in Fig. 5 the compute time (averaged over 100 SRG-v instances) required by our exact dynamic programming algorithm (Algorithm 1), with the annotation of dominated covering sets and the generation of the routes, as {a mathematical formula}|T| and ϵ vary. We report in Appendix C the boxplots showing the statistical significance of the results. It can be observed that the compute times are exponential in {a mathematical formula}|T|, the curves being lines in a semilogarithmic plot, and the value of ϵ determines the slope of the line. Notice that with {a mathematical formula}ϵ∈{0.05,0.10,0.25} the number of edges is almost the same when {a mathematical formula}|T|≤16 due to the constraint of connectivity of the graph, leading thus to the same compute times. Beyond 16 targets, the compute times of our exact dynamic programming algorithm are excessively long (with only {a mathematical formula}ϵ=0.25, the compute time when {a mathematical formula}|T|=20 is lower than 10{sup:4} seconds). Interestingly, the compute time monotonically decreases as ϵ decreases. This is thanks to the fact that the number of covering sets generated by Algorithm 1 dramatically reduces as ϵ reduces.
       </paragraph>
       <paragraph>
        We do not report any plot of the compute times of our exact branch-and-bound algorithm, since it requires more than 10{sup:4} seconds when {a mathematical formula}|T|&gt;8 even with {a mathematical formula}ϵ=0.25, resulting thus non-applicable in practice. This is because the branch-and-bound algorithm has a complexity {a mathematical formula}O(|T||T|), while the dynamic programming algorithm has a complexity {a mathematical formula}O(2|T|).
       </paragraph>
       <paragraph>
        Fig. 6 shows the impact of discarding dominated actions from the game when {a mathematical formula}ϵ=0.25. It depicts the trend of some performance ratios for different metrics. We shall call {a mathematical formula}G the complete game including all {a mathematical formula}D's dominated actions and {a mathematical formula}GR the reduced game; CCS will denote the full version of Algorithm 1 and LP will denote the linear program to solve SRG-v. Each instance is solved for a random starting vertex v; we report average ratios for 100 instances. “n. covsets” is the ratio between the number of covering sets in {a mathematical formula}GR and in {a mathematical formula}G. As it can be seen, non-dominated actions constitute a small percentage, decreasing with the number of targets. This result indicates that the structure of the problem exhibits a non-negligible degree of redundancy. LP times (iterations) report the ratio between {a mathematical formula}GR and {a mathematical formula}G for the time (iterations) required to solve the maxmin linear program. A relative gain directly proportional to the percentage of dominated covering sets is observable (LP has less variables and constraints). A similar trend is not visible when considering the same ratio for the total time, that is LP+CCS. Indeed, the time needed by CCS largely exceed LP's and removal of dominated actions determines a polynomial additional cost, which can be seen in the slightly increasing trend of the curve. The relative gap between LP and CCS compute times can be assessed by looking at the LP/CCS curve: when more targets are considered, the time taken by LP is negligible w.r.t. CCS's. This shows that removing dominated actions is useful, allowing a small improvement in the average case, and assuring an exponential improvement in the worst case.
       </paragraph>
       <paragraph>
        Fig. 7 shows the game value for {a mathematical formula}D, {a mathematical formula}1−gv, as {a mathematical formula}|T| and ϵ vary (averaged over 100 instances). It can be observed that the game value is almost constant as {a mathematical formula}|T| varies for {a mathematical formula}ϵ∈{0.05,0.10,0.25} and it is about 0.87. This is because all these instances have a similar number of edges, very close to the minimum number necessary for having connected graphs. With a larger number of edges, the game value increases. Interestingly, fixed a value of ϵ, there is a threshold of {a mathematical formula}|T| such that beyond the threshold the game value increases as {a mathematical formula}|T| increases. This suggests that the minimum game value is obtained for connected graphs with the minimum number of edges.
       </paragraph>
       <paragraph>
        In Table 2, we report compute times with multiple signals, where the targets covered by a signal and the probability that a target triggers a signal are randomly chosen according to a uniform distribution. Values are averages over 100 random instances and give insights on the computation effort along the considered dimensions. The results show that the problem is computationally challenging even for a small number of targets and signals.
       </paragraph>
      </section>
      <section label="5.1.3">
       <section-title>
        Approximation algorithms
       </section-title>
       <paragraph>
        We evaluate the empirical approximation ratios obtained with our approximation algorithms as {a mathematical formula}(1−gˆv)/(1−gv), where {a mathematical formula}gv is the expected utility of {a mathematical formula}A at the equilibrium considering all the covering sets and {a mathematical formula}gˆv is the expected utility of {a mathematical formula}A at the equilibrium when covering sets are generated by our heuristic algorithm. We execute our approximation dynamic programming algorithm with a different number, say RandRes, of randomly generated orders from {a mathematical formula}{10,20,30,40,50}, in addition to the 3 heuristics discussed in Section 3.2.2. We executed our approximation branch and bound algorithm with constant values of ρ from {a mathematical formula}{0.25,0.50,0.75,1.00} (we recall that with {a mathematical formula}ρ=1.00 backtracking is completely disabled).
       </paragraph>
       <paragraph>
        Fig. 8 and Fig. 9 report the empirical approximation ratios (averaged over 100 instances) obtained with our approximation algorithms for different values of {a mathematical formula}|T|∈{6,8,10,12,14,16}, i.e., the instances for which we know the optimal game value, and {a mathematical formula}ϵ∈{0.05,0.10,0.25,0.50,0.75,1.00}. We remark that the ratios obtained with the approximation branch-and-bound algorithm for some values of ρ are omitted. This is because the compute time needed by the algorithm is over 10{sup:4} seconds. The algorithm always terminates by the deadline for only {a mathematical formula}ρ∈{0.75,1.00}.
       </paragraph>
       <paragraph>
        We focus on the ratios obtained with the dynamic programming algorithm. Given a value of ϵ, as {a mathematical formula}|T| increases, the ratio decreases up to a given threshold of {a mathematical formula}|T| and then it is a constant. The threshold increases as ϵ decreases, while the constant decreases as ϵ decreases. The value of the constant is high for every ϵ, being larger than 0.8. Although the ratios increase as RandRes increases, it is worth noting that the increase is not very significant, being of the order of 0.05 between 10 RandRes and 50 RandRes. We focus on the ratios obtained with the branch-and-bound algorithm. Given a value of ϵ, as {a mathematical formula}|T| increases, the ratio decreases up to a given threshold of {a mathematical formula}|T| and then it increases approaching a ratio of 1. The threshold increases as ϵ decreases, while the minimum ratio decreases as ϵ decreases. Interestingly, ratios with {a mathematical formula}ρ=1.00 are very close to ratios with {a mathematical formula}ρ=0.75, showing that performing even significant backtracking around the solution found with {a mathematical formula}ρ=1.00 does not lead to a significant improvement of the solution. The solution can be effectively improved only with {a mathematical formula}ρ=0.25, but it is not affordable due to the excessive required compute time. This shows that the heuristic performs very well. Comparing the ratios of the two algorithms, it can be observed that the approximation dynamic programming algorithm performs better than the approximation branch-and-bound algorithm although this last one turned out to be slightly better in a limited number of cases (see Fig. 10). While the dynamic programming one always provides a ratio larger than 0.8, the branch-and-bound one provides for combinations of {a mathematical formula}|T| and ϵ ratios lower than 0.4.
       </paragraph>
       <paragraph>
        Fig. 10 reports the game values obtained with the approximation dynamic programming algorithm for every value of RandRes and with the approximation branch-and-bound algorithm when {a mathematical formula}|T|∈{20,25,30,35,40,45,50} only for {a mathematical formula}ρ=1.00. Indeed, with {a mathematical formula}ρ=0.75 the compute time is excessive and, as shown above, the purely heuristic solution cannot be significantly improved for {a mathematical formula}ϵ≥0.75. We report experimental results only for {a mathematical formula}ϵ∈{0.05,0.25}. We notice that for these instances we do not have the optimal game value. However, since the optimal game value cannot be larger than 1 by construction of the instances, the game value obtained with our approximation algorithms represents a lower bound to the actual approximation ratio. It can be observed that, given a value of ϵ, the ratios obtained with the dynamic programming algorithm are essentially constant as {a mathematical formula}|T| increases and this constant reduced as ϵ reduces. Surprisingly, after a certain value of {a mathematical formula}|T|, the game values obtained with the branch and bound algorithm are higher than those obtained with the dynamic programming algorithm. This is because, fixed a value of ϵ, as {a mathematical formula}|T| increases, the problem becomes easier and the heuristic used by the branch and bound algorithm performs well finding the best covering routes. This shows that there is not an algorithm outperforming the other for every combination of parameters {a mathematical formula}|T| and ϵ. Furthermore, the above result shows that the worst cases for the approximation algorithms are those in which {a mathematical formula}ϵ=O(1|T|), corresponding to instances in which the number of edges per vertex is a constant in {a mathematical formula}|T|. It is not clear from our experimental analysis whether increasing {a mathematical formula}|T| with {a mathematical formula}ϵ=ν|T| for some {a mathematical formula}ν&gt;1 the game value approaches to 0 or to a strictly positive value. However, our approximation algorithms provide a very good approximation even with a large number of targets and a small value of ϵ.
       </paragraph>
       <paragraph>
        Fig. 11 reports the compute times required by the approximation dynamic programming algorithms. As it can be seen, the required time slightly increases when adopting a larger number of randomly generated orders with respect to the baseline with {a mathematical formula}ρ=1.00.
       </paragraph>
      </section>
     </section>
     <section label="5.2">
      <section-title>
       Real case study
      </section-title>
      <paragraph>
       In Section 1.1.2 we presented a motivating scenario describing the fair site of Expo 2015. We now formalize an instance for our problem inspired by such scenario to derive important insights on how our techniques operate in real cases. Expo 2015 has been a large setting which, as we anticipated, underwent a remarkable deployment of security resources with about 700 guards operating on the field. This experiment addresses a worst-case scenario where we stress our route-generation algorithms by assuming that each guard has to protect the whole environment. The resolution of this problem is necessary even when admitting multiple defending resources for which no environment partition is pre-assigned (see [27] for a more detailed discussion).
      </paragraph>
      <paragraph>
       Fig. 12 shows a graph representation of the Expo 2015 site. We manually build a discretized version of the site map by exploiting publicly available knowledge of the event.{sup:9} We identify ≈170 sensible locations which correspond to an equal number of targets in our graph. More specifically, we identify ≈130 targets located at the entrances of each pavilion and in the surroundings of those areas which could be of interest for a high number of visitors. Some targets (≈35) are located over the main roads, being these critical mainly due to their high crowd. Such roads also define our set of edges which resulted in a density of ≈0.02. Fig. 12 reports a graphical representation of chosen deadlines {a mathematical formula}d(⋅) and values {a mathematical formula}π(⋅), respectively. To determine such values in a reasonable way we apply a number of simple rules of thumb. First, to ease our task, we discretize the spaces of possible deadlines and values in four different levels. To assign a value to a target, we estimate the interest (in terms of popularity and expected crowd) of the corresponding area in the fair site. The higher the interest, the higher the value (actual values are reported in the figure). To assign deadlines we estimate the time an attacker should spend to escape from the attacked target after some malicious activity is started (for example, blending into the crowd without leaving any trace). In particular, we estimate a smaller escape time for those locations lying near the external border of the fair site while for locations that are more central we estimated a larger time. The smaller the escape time, the tighter the deadline for that target. Actual values are extracted from a normal distribution where {a mathematical formula}σ2=1 and μ is set according to the chosen level. The maximum distance between any two target locations is about 1.5 km which we assume can be covered in about 7.5 minutes (we imagined a crowded scenario). Given such reference scenario, our means span from 5 minutes (very tight) to 7.5 minutes (very large). To derive our alarm system model we assume to have a number of panoramic cameras deployed in the environment at locations we manually choose in order to cover the whole environment and to guarantee a wide area of view for each camera (i.e., trying to keep, in general, more than one target under each camera's view). To map our set of cameras over the alarm system model, we adopt this convention: each group of cameras sharing an independent partial view of a target t is associated to a signal {a mathematical formula}s∈S(t); if target t is covered by k signals then each signal is generated with probability {a mathematical formula}1/k once t is attacked. Obviously, a deeper knowledge of the security systems deployed on the site can enable specific methods to set the parameters of our model. This is why we encourage involving agencies in charge of security when dealing with such task.
      </paragraph>
      <paragraph>
       We first show a qualitative evaluation of our method. Fig. 13 depicts the best placement for the Defender (the circle in the figure) and the attacked targets (the squares in the figure, these are the actions played by the Attacker with non-null probability at the equilibrium). As intuition would suggest, the best location from where any signal response should start is a central one w.r.t. the whole fair site. Our simulations show that the optimal patrolling strategy coincides with such fixed placement even under false negatives rates of at least ≈0.3. Notice that such false negatives value can be considered unrealistically pessimistic for alarm systems deployed in structured environment like the one we are dealing with. Attacked targets correspond to areas, which exhibit rather high interest and small escape time. Fig. 14 reports an example of signal response strategy for a given starting vertex (the small circle in the figure) and a given signal (whose covered targets are depicted with the large circle in the figure). The table lists the computed covering sets and the probabilities with which the Defender plays the corresponding covering routes.
      </paragraph>
      <paragraph>
       Boxplots of Fig. 15(a) provide some quantitative insights on the computational effort we measured in solving such realistic instance. Given a signal, we report the statistical distribution of the time required by Algorithm 1 to compute covering routes from each possible start vertex. In general, we observe a high variance in each boxplot. Indeed, once fixed a signal s in our realistic instance, it is easy to identify starting vertices from which computing covering routes is likely to be very easy or, instead, much harder. For the easy case, consider a starting vertex lying very much far away from the group of targets covered by s. In such case, Algorithm 1 will soon stop iterating through covering set cardinalities being not able to further generate feasible sets. Such feature is induced by the large distance of the starting vertex from the targets covered by s together with the low edge density and the spatial locality shared among targets covered by the same signal (these last two are, indeed, features that frequently recur in realistic scenarios). For the harder case, just consider a situation in which the distance of the starting vertex from the targets covered by s is such that a large number of covering routes is available. An example of this kind can be inspected in Fig. 14. Interestingly, a similar high variance trend is not always observed when depicting the statistical distribution of the compute time per starting vertex. The boxplot of Fig. 15(b) shows an example of the distribution of compute time from a given starting vertex (the sample here is the composed by compute times associated to the resolution from that starting vertex with respect to each signal). Such distribution (characterized by a lower variance with respect to what can be observed in Fig. 14) suggests that there can be starting vertices posing easy resolution and, similarly, others posing only hard ones.
      </paragraph>
     </section>
    </section>
    <section label="6">
     <section-title>
      Related works
     </section-title>
     <paragraph>
      In the last few years, Security Games received an increasing interest from the Artificial Intelligence scientific community, leading to the exploration of a large number of research directions around this topic. In this section, we briefly discuss what we deem to be the most significant ones, starting from the game theoretical foundations on which these models are built.
     </paragraph>
     <paragraph>
      Computing solution concepts is the central problem upon which the real applicability of these game theoretical models is based. A lot of works concentrated on algorithmic studies of this topic, analysing the relationships holding among different kinds of solution concepts and their computational complexity. In [39] the relationship between Stackelberg, Nash and min–max equilibria is studied, while in [40] some refinements of the Stackelberg equilibrium are proposed. Many efforts have been made to develop tractable algorithms for finding Stackelberg equilibria in Bayesian games [41]. Furthermore, in [42], the authors analysed scenarios in which the Defender has multiple objectives, searching for the Pareto curve of the Stackelberg equilibria.
     </paragraph>
     <paragraph>
      Besides fundamental works like the ones cited above, a more recent research line devoted efforts towards the definition of game model refinements in the attempt to overcome some of their ideal assumptions. One remarkable issue belonging to this scope is how to model the behavior of the Attacker. In the attempt to have a more realistic behavior, some works considered bounded rationality and defined algorithms to deal with it. In [43] different models of the Attacker are analysed while in [44], [45] the Attacker is allowed to have different observation and planning capabilities. Moreover, in [46] Quantal–Best Response is used to model the behavior of the Attacker and in [47] algorithms that scale up with bounded rational adversaries are proposed. In our paper, we assume that the attacker is rational.
     </paragraph>
     <paragraph>
      Other model refinements focused on those cases in which games exhibit specific structures that can be leveraged in the design of algorithms to compute the Stackelberg equilibrium. For instance, the study of the spread of contagion over a network is investigated in [48]. When no scheduling constraints are present and payoffs exhibit a special form, the computation of a Stackelberg equilibrium can be done very efficiently enabling the resolution of remarkably big scenarios [49]. In [50], realistic aspects of infrastructures to be protected are taken into account.
     </paragraph>
    </section>
    <section label="7">
     <section-title>
      Conclusions and future research
     </section-title>
     <paragraph>
      In this paper we provide the first Security Game for large environments surveillance, e.g., for fair sites protection, that can exploit an alarm system with spatially uncertain signals. To monitor and protect large infrastructure such as stations, airports, and cities, a two-level paradigm is commonly adopted: a broad area surveillance phase, where an attack is detected but only approximately localized due to the spatially uncertainty of the alarm system, triggers a local investigation phase, where guards have to find and clear the attack. Abstracting away from technological details, we propose a simple model of alarm systems that can be widely adopted with every specific technology and we include it in the state-of-art patrolling models, obtaining a new security game model. We show that the problem of finding the best patrolling strategy to respond to a given alarm signal is {a mathematical formula}FNP-hard on trees and {a mathematical formula}APX-hard with arbitrary graphs. Then, we provide two exponential-time exact algorithms to find the best patrolling strategy to respond to a given alarm signal. The first algorithm performs a breath-first search by exploiting a dynamic programming approach, while the second algorithm performs a depth-first approach by exploiting a branch-and-bound approach. We provide also a variation of these two algorithms to find an approximate solution. We experimentally evaluate our exact and approximation algorithms both in worst-case instances, to evaluate empirically the gap between our hardness results and the theoretical guarantees of our approximation algorithms, and in one realistic instance. The limit of our exact algorithms is about 16 targets with worst-case instances while we were able to compute an optimal solution for a realistic instance with ≈170 targets. On the other side, our approximation algorithms provide a very effective approximation even with worst-case instances. Finally, we focus on the problem of patrolling the environment, showing that if every target is alarmed and no false positives nor missed detections are present, then the best patrolling strategy prescribes that the patroller stays in a given place waiting for an alarm signal. Furthermore, we show that such a strategy may be optimal even for missed detection rates up to 50%.
     </paragraph>
     <paragraph>
      Besides the solutions we studied, a number of open problems have been posed for future research. The main theoretical issue is the closure of the approximation gap of SRG-v. We believe that investigating the relationship between our model and the DEADLINE–TSP could help in closing the gap. Another interesting problem is the study of approximation algorithms for tree graphs. Our {a mathematical formula}NP-hardness result does not exclude the existence of a PTAS (i.e., polynomial time approximation scheme), even if we conjecture that the existence is unlikely. A number of extensions of our model are worth being explored, we identify two prominent ones. The first is to enrich our model with false positives and missed detections, requiring patrolling even in the absence of alarm signals. A second extension is to consider settings with multiple patrollers. We deem that the techniques presented in this work can play a fundamental role in scaling to multi-patroller settings. In [27] we give some preliminary contributions along this direction, discussing different arising subproblems, showing how some properties like the one given in Theorem 10 can be generalized, and leveraging the algorithms presented here for the resolution of multi-patroller games under different coordination assumptions.
     </paragraph>
    </section>
   </content>
   <appendices>
    <section label="Appendix A">
     <section-title>
      Proofs
     </section-title>
     <section label="A.1">
      Proof of Theorem 1
      <paragraph>
       We first define a special class of trees we call special 2-level stars (S2L–STAR). See Fig. A.16 for an example.
      </paragraph>
      <paragraph label="Definition 11">
       S2L–STARSpecial 2-level star graph instances (S2L–STAR) are:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}V={v0,v1,v2,…,v2n}, where {a mathematical formula}v0 is the starting position;
       </list-item>
       <list-item label="•">
        {a mathematical formula}T=V∖{v0}, where vertices {a mathematical formula}vi with {a mathematical formula}i∈{1,…,n} are called inner targets, while vertices {a mathematical formula}vi with {a mathematical formula}i∈{n+1,…,2n} are called outer targets;
       </list-item>
       <list-item label="•">
        {a mathematical formula}E={(v0,vi),(vi,vn+i):∀i∈{1,…,n}} and we refer to the pair of edges {a mathematical formula}((v0,vi),(vi,vn+i)) as the i-th branch;
       </list-item>
       <list-item label="•">
        travel costs are {a mathematical formula}c(v0,vi)=c(vi,vn+i)=γi for every {a mathematical formula}i∈{1,…,n}, where {a mathematical formula}γi∈N+;
       </list-item>
       <list-item label="•">
        penetration times are, for {a mathematical formula}i∈{1,…,n}, {a mathematical formula}d(t)={6H−3γit=vi10H−2γi,t=vn+i, where {a mathematical formula}H=∑i=1nγi2;
       </list-item>
       <list-item label="•">
        {a mathematical formula}π(t)=1 for every {a mathematical formula}t∈T.
       </list-item>
      </list>
      <paragraph label="Lemma 12">
       Initially, we show a property of S2L–STAR instances that we shall use below. If an instance of S2L–STAR admits a maximal covering route r that covers all the targets, then the branches can be partitioned in two sets{a mathematical formula}C1and{a mathematical formula}C2such that:
      </paragraph>
      <list>
       <list-item label="•">
        all the branches in{a mathematical formula}C1are visited only once while all the branches in{a mathematical formula}C2are visited twice;
       </list-item>
       <list-item label="•">
        {a mathematical formula}∑i∈C1γi=∑i∈C2γi=H.
       </list-item>
      </list>
      <paragraph label="Proof">
       Initially, we observe that, in a feasible solution, the visit of a branch can be of two forms. If branch i is visited once, then {a mathematical formula}D will visit the inner target before time {a mathematical formula}6H−3γi and immediately after the outer target. {a mathematical formula}C1 denotes the set of all the branches visited according to this form. If branch i is visited twice, then {a mathematical formula}D will visit at first the inner target before time {a mathematical formula}6H−3γi, coming back to {a mathematical formula}v0 immediately after, and subsequently in some time after {a mathematical formula}6H−3γi, but before {a mathematical formula}10H−2γi, {a mathematical formula}D will visit again the inner target and immediately after the outer target. {a mathematical formula}C2 denotes the set of all the branches that are visited according to this form. All the other forms of visits (e.g., three or more visits, different order visits, and visits at different times) are useless and any route in which some branch is not neither in {a mathematical formula}C1 nor in {a mathematical formula}C2 can be modified such that all the branches are either in {a mathematical formula}C1 or in {a mathematical formula}C2 strictly decreasing the cost of the solution as follows:
       <list>
        if branch i is visited only once and the visit of the inner target is after time {a mathematical formula}6H−3γi, then the solution is not feasible;if branch i is visited twice and the first visit of the inner target is after time {a mathematical formula}6H−3γi, then the solution is not feasible;if branch i is visited twice and the second visit of the inner target is before time {a mathematical formula}6H−3γi, then the first visit of the branch can be omitted saving {a mathematical formula}2γi;if branch i is visited twice and the outer target is visited during the first visit, then the second visit of the branch can be omitted saving {a mathematical formula}≥2γi;if branch i is visited three or more times, all the visits except the first one in which the inner target is visited and the first one in which the outer target is visited can be omitted saving {a mathematical formula}≥2γi.We assume that, if there is a maximal covering route
       </list>
       <paragraph>
        r that covers all the targets, then the visits are such that {a mathematical formula}C1∪C2={1,…,n} and therefore that each branch is visited either once or twice as discussed above. We show below that in S2L–STAR instances such an assumption is always true. Since r covers all the targets, we have that the following conditions are satisfied:{a mathematical formula}{a mathematical formula} Constraint (A.1) requires that the cost of visiting entirely all the branches in {a mathematical formula}C1 and partially (only the inner target) all the branches in {a mathematical formula}C2 is not larger than the penetration times of the inner targets. Notice that this holds only when the last inner target is first-visited on a branch in {a mathematical formula}C1. We show below that such assumption is always verified. Constraint (A.2) requires that the cost of visiting entirely all the branches in {a mathematical formula}C1 and at first partially and subsequently entirely all the branches in {a mathematical formula}C2 is not larger than the penetration times of the outer targets. We can simplify the above pair of constraints as follows:{a mathematical formula} obtaining:{a mathematical formula} since, by definition, {a mathematical formula}∑i∈C1γi+∑i∈C2γi=2H, it follows that:{a mathematical formula} Therefore, if r covers all the targets and it is such that all the branches belong either to {a mathematical formula}C1 or to {a mathematical formula}C2, we have that r visits the last outer target exactly at its penetration time. This is because Constraints (A.1) and (A.2) hold as equalities. Thus, as shown above, in any route in which a branch is neither in {a mathematical formula}C1 nor in {a mathematical formula}C2, we can change the visits such that all the branches are in either {a mathematical formula}C1 or {a mathematical formula}C2, strictly reducing the total cost. It follows that no route with at least one branch that is not neither in {a mathematical formula}C1 nor in {a mathematical formula}C2 can have a total cost equal to or smaller than the penetration time of the outer targets. Similarly, from the above equality it follows that any solution where the last inner target is first-visited on a {a mathematical formula}C2 branch can be strictly improved by moving such branch to {a mathematical formula}C1 and therefore no route in which the last inner target is first-visited on a {a mathematical formula}C2 branch can have a total cost equal to or smaller than the penetration time of the outer targets. □
       </paragraph>
      </paragraph>
      <paragraph>
       We can now prove Theorem 1.
      </paragraph>
      <paragraph label="Definition 12">
       For the sake of clarity, we divide the proof in steps.Reduction. We map an instance of PARTITION to an instance of k–SRG-v on S2L–STAR graphs as follows
       <list>
        {a mathematical formula}S={s},{a mathematical formula}n=l (i.e., the number of branches in S2L–STAR equals the number of elements in PARTITION);{a mathematical formula}γi=ai for every {a mathematical formula}i∈I;{a mathematical formula}H=B,{a mathematical formula}k=0.If.
       </list>
       <paragraph>
        From Lemma 12 we know that, if there is the maximal covering route that covers all the targets in a k–SRG-v on a S2L–STAR graph, then the branches can be partitioned in two sets {a mathematical formula}C1,C2 such that {a mathematical formula}∑i∈C1γi=∑i∈C2γi=H. By construction {a mathematical formula}γi=ai and {a mathematical formula}H=B. So, if there is the maximal covering route that covers all the targets in a k–SRG-v on a S2L–STAR graph, then there is partition of set I in two subsets {a mathematical formula}I′=C1 and {a mathematical formula}I″=C2 such that {a mathematical formula}∑i∈C1γi=∑i∈I′ai=H=B=∑i∈C2γi=∑i∈I″ai.Only if. If PARTITION admits a feasible solution, then, once assigned {a mathematical formula}I′=C1 and {a mathematical formula}I″=C2, it is straightforward to see that the route visits all the targets by their penetration times and therefore that the route is a maximal covering route. □
       </paragraph>
      </paragraph>
      <paragraph>
       As a final remark, let us notice that this result does not exclude the existence of an FPTAS, i.e., Fully Polynomial Time Approximation Scheme (in fact, PARTITION admits an FPTAS).
      </paragraph>
     </section>
     <section label="A.2">
      Proof of Theorem 2
      <paragraph>
       The theorem immediately follows from the same proof given for Theorem 1 and reported in the previous section.
      </paragraph>
     </section>
     <section label="A.3">
      Proof of Theorem 3
      <paragraph label="Proof">
       Assume that, for simplicity, {a mathematical formula}S={s1} and that {a mathematical formula}T(s1)=T. Initially, we observe that MAX–COV-SET is in co-{a mathematical formula}NP. Indeed, any covering route r such that {a mathematical formula}T(r)⊃T′ is a NO certificate for MAX–COV-SET, placing it in co-{a mathematical formula}NP. (Notice that, trivially, any covering route has length bounded by {a mathematical formula}O(|T|2); also, notice that due to Theorem 2, having a covering set would not suffice given that we cannot verify in polynomial time whether it is actually covering unless {a mathematical formula}P=NP.)Let us suppose we have a polynomial-time algorithm for MAX–COV-SET, called A. Then (since {a mathematical formula}P⊆NP∩co-NP) we have a polynomial algorithm for the complement problem, i.e., deciding whether all the covering routes for {a mathematical formula}T′ are dominated. Let us consider the following algorithm. Given an instance for COV-SET specified by graph {a mathematical formula}G=(V,E), a set of target T with penetration times d, and a starting vertex v:
      </paragraph>
      <list>
       <list-item label="1.">
        assign to targets in T a lexicographic order {a mathematical formula}t1,t2,…,t|T|;
       </list-item>
       <list-item label="2.">
        for every {a mathematical formula}t∈T, verify if {a mathematical formula}{t} is a covering set in {a mathematical formula}O(|T|) time by comparing {a mathematical formula}ωv,t⁎ and {a mathematical formula}d(t); if at least one is not a covering set, then output NO and terminate; otherwise set {a mathematical formula}Tˆ={t1} and {a mathematical formula}k=2;
       </list-item>
       <list-item label="3.">
        apply algorithm A on the following instance: graph {a mathematical formula}G=(V,E), target set {a mathematical formula}{Tˆ∪{tk},dˆ} (where {a mathematical formula}dˆ is d restricted to {a mathematical formula}Tˆ∪{tk}), start vertex v, and covering set {a mathematical formula}Tˆ;
       </list-item>
       <list-item label="4.">
        if A's output is YES (that is, {a mathematical formula}Tˆ is not maximal) then set {a mathematical formula}Tˆ=Tˆ∪{tk}, {a mathematical formula}k=k+1 and restart from step 3; if A's output is NO and {a mathematical formula}k=|T| then output YES, if A's output is NO and {a mathematical formula}k&lt;|T| then output NO.
       </list-item>
      </list>
     </section>
     <section label="A.4">
      Proof of Theorem 4
      <paragraph label="Proof">
       We produce an approximation-preserving reduction from TSP({a mathematical formula}1,2) that is known to be {a mathematical formula}APX-hard [51]. For the sake of clarity, we divide the proof in steps.TSP({a mathematical formula}1,2) instance. An instance of undirected TSP({a mathematical formula}1,2) is defined as follows:
       <list>
        a set of vertices {a mathematical formula}VTSP;a set of edges composed of an edge per pair of vertices;a symmetric matrix {a mathematical formula}CTSP of weights, whose values can be 1 or 2, each associated with an edge and representing the cost of the shortest path between the corresponding pair of vertices.Reduction
       </list>
       <paragraph>
        . We map an instance of TSP({a mathematical formula}1,2) to a specific instance of SRG-v as follows:
       </paragraph>
       <list>
        <list-item label="•">
         there is only one signal s;
        </list-item>
        <list-item label="•">
         {a mathematical formula}T(s)=VTSP;
        </list-item>
        <list-item label="•">
         {a mathematical formula}wt,t′⁎=CTSP(t,t′), for every {a mathematical formula}t,t′∈T(s);
        </list-item>
        <list-item label="•">
         {a mathematical formula}π(t)=1, for every {a mathematical formula}t∈T(s);
        </list-item>
        <list-item label="•">
         {a mathematical formula}wv,t⁎=1, for every {a mathematical formula}t∈T(s);
        </list-item>
        <list-item label="•">
         {a mathematical formula}d(t)={OPTTSPifOPTTSP=|VTSP|OPTTSP−1ifOPTTSP&gt;|VTSP|, for every {a mathematical formula}t∈T(s).
        </list-item>
       </list>
       <paragraph label="Proof">
        In this reduction, we use the value of {a mathematical formula}OPTTSP even if there is no polynomial-time algorithm solving exactly TSP({a mathematical formula}1,2), unless {a mathematical formula}P=NP. We show below that with an additional polynomial-time effort we can deal with the lack of knowledge of {a mathematical formula}OPTTSP.OPT–SRG-v optimal solution. By construction of the SRG-v instance, there is a covering route starting from v and visiting all the targets {a mathematical formula}t∈T(s), each within its penetration time. This route has a cost of exactly {a mathematical formula}d(t) and it is {a mathematical formula}〈v,t1,…,t|T(s)|〉, where {a mathematical formula}〈t1,…,t|T(s)|,t1〉 corresponds to {a mathematical formula}OPTSOLTSP with the constraint that {a mathematical formula}wt|T(s)|,t1⁎=2 if {a mathematical formula}OPTTSP&gt;|VTSP| (essentially, we transform the tour in a path by discarding one of the edges with the largest cost). Therefore, the optimal solution of SRG-v, say {a mathematical formula}OPTSOLSRG, prescribes to play the maximal route with probability one and the optimal value, say {a mathematical formula}OPTSRG, is 1.OPT–SRG-v approximation. Let us denote by {a mathematical formula}APXSOLSRG and {a mathematical formula}APXSRG an approximate solution of OPT–SRG-v and its value, respectively. We assume there is a polynomial-time approximation algorithm with {a mathematical formula}APXSRG/OPTSRG≥β where {a mathematical formula}β∈(0,1). Let us notice that {a mathematical formula}APXSOLSRG prescribes to play a polynomially upper bounded number of covering routes with strictly positive probability. We introduce a lemma that characterizes such covering routes.The longest covering route played with strictly positive probability in{a mathematical formula}APXSOLSRGvisits at least{a mathematical formula}β|T(s)|targets.Assume by contradiction that the longest route visits {a mathematical formula}β|T(s)|−1 targets. The best case in terms of maximization of the value of OPT–SRG-v is, due to reasons of symmetry (all the targets have the same value), when there is a set of {a mathematical formula}|T(s)| covering routes of length {a mathematical formula}β|T(s)|−1 such that each target is visited exactly by {a mathematical formula}β|T(s)|−1 routes. When these routes are available, the best strategy is to randomize uniformly over the routes. The probability that a target is covered is {a mathematical formula}β−1|T(s)| and therefore the value of {a mathematical formula}APXSRG is {a mathematical formula}β−1|T(s)|. This leads to a contradiction, since the algorithm would provide an approximation strictly smaller than β.  □TSP({a mathematical formula}1,2) approximation from OPT–SRG-v approximation. We use the above lemma to show that we can build a {a mathematical formula}(3−2β)-approximation for TSP({a mathematical formula}1,2) from a β-approximation of OPT–SRG-v. Given an {a mathematical formula}APXSOLSRG, we extract the longest covering route played with strictly positive probability, say {a mathematical formula}〈v,t1,…,tβ|T(s)|〉. The route has a cost of at most {a mathematical formula}d(t), it would not cover {a mathematical formula}β|T(s)| targets otherwise. Any tour {a mathematical formula}〈t1,…,tβ|T(s)|,tβ|T(s)|+1,…,t|T(s)|,t1〉 has a cost not larger than {a mathematical formula}d(t)−1+2(1−β)|T(s)|=OPTTSP−1+2(1−β)|VTSP| (under the worst case in which all the edges in {a mathematical formula}〈tβ|T(s)|,tβ|T(s)|+1,…,t|T(s)|,t1〉 have a cost of 2). Given that {a mathematical formula}OPTTSP≥|VTSP|, we have that such a tour has a cost not larger than {a mathematical formula}OPTTSP−1+2(1−β)|VTSP|≤OPTTSP(3−2β). Therefore, the tour is a {a mathematical formula}(3−2β)-approximation for TSP({a mathematical formula}1,2). Since TSP({a mathematical formula}1,2) is not approximable in polynomial time for any approximation ratio smaller than α, we have the constraint that {a mathematical formula}3−2β≥α, and therefore that {a mathematical formula}β≤3−α2. Since {a mathematical formula}α&gt;1, we have that {a mathematical formula}3−α2&lt;1 and therefore that there is no polynomial-time approximation algorithm for OPT–SRG-v when {a mathematical formula}β∈(3−α2,1), unless {a mathematical formula}P=NP.{a mathematical formula}OPTTSPoracle. In order to deal with the fact that we do not know {a mathematical formula}OPTTSP, we can execute the approximation algorithm for OPT–SRG-v using a guess over {a mathematical formula}OPTTSP. More precisely, we execute the approximation algorithm for every value in {a mathematical formula}{|VTSP|,…,2|VTSP|} and we return the best approximation found for TSP({a mathematical formula}1,2). Given that {a mathematical formula}OPTTSP∈{|VTSP|,…,2|VTSP|}, there is an execution of the approximation algorithm that uses the correct guess.  □
       </paragraph>
      </paragraph>
     </section>
     <section label="A.5">
      Proof of Theorem 11
      <paragraph label="Proof">
       We divide the proof in two steps, membership and hardness.Membership. Given a YES certificate constitutes by a route, the verification is easy, requiring one to apply the route and check whether each target is visited by its deadline. It requires linear time in the number of targets.Hardness. Let us consider the Restricted Hamiltonian Circuit problem (RHC) which is known to be {a mathematical formula}NP-complete. RHC is defined as follows: given a graph {a mathematical formula}GH=(VH,EH) and an Hamiltonian path {a mathematical formula}P=〈h1,…,hn〉 for {a mathematical formula}GH such that {a mathematical formula}hi∈VH and {a mathematical formula}(h1,hn)∉EH, find an Hamiltonian cycle for {a mathematical formula}GH. From such instance of RHC, following the approach of [38], we build the following instance for lm–COV–ROUTE:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}V=VH∪{v1,v2,vt};
       </list-item>
       <list-item label="•">
        {a mathematical formula}T=VH∪{vt};
       </list-item>
       <list-item label="•">
        {a mathematical formula}E=EH∪{(hn,vt),(hi,vs):i∈{1,…,n}};
       </list-item>
       <list-item label="•">
        {a mathematical formula}d(vt)=n+1 and {a mathematical formula}d(t)=n for any {a mathematical formula}t∈T with {a mathematical formula}t≠vt;
       </list-item>
       <list-item label="•">
        {a mathematical formula}wv,v′={1if v=hn,v′=vt1if v=hi,v′=hj,∀i,j∈{1,…n}1if v=v1,v′=h12if v=v1,v′=hn−1≥2if v=v1,v′=hi,∀i∈{1,…n−2,n}≥2if v=v1,v′=vt2if v=v2,v′=h11if v=v2,v′=hn−1≥2if v=v2,v′=hi,∀i∈{1,…n−2,n}≥2if v=v2,v′=vt;
       </list-item>
       <list-item label="•">
        {a mathematical formula}r1=〈v1,h1,⋯,hn,vt〉.
       </list-item>
      </list>
     </section>
    </section>
    <section label="Appendix B">
     <section-title>
      Additional results for special topologies
     </section-title>
     <paragraph>
      In this section we show that for some special classes of graphs we can give a polynomial-time algorithm for answering Question 2.
     </paragraph>
     <section label="B.1">
      <section-title>
       Line and cycle graphs
      </section-title>
      <paragraph>
       Let us first concentrate on line graphs for which an example is depicted in Fig. B.18(a). Consider a modified version of Algorithm 1 where, when deciding on admissible expansions, we add to Conditions 1–3 the following one: the cost of the newly formed covering set must be smaller than or equal to the penetration time of any target not included in such set. Given {a mathematical formula}Qv,tk, the expansion {a mathematical formula}Qv,wk+1 is admissible only if for any {a mathematical formula}t∈T(s)∖Qv,wk the inequality {a mathematical formula}d(t)≥c(Qv,wk+1) holds. Such modified algorithm runs in polynomial time on line graph instances. To see this, notice that any covering set enumerated has only two possible expansions and can be compactly represented by two vertices: a left one and a right one. All the targets between the two extremes are covered by the covering set. This makes the number of expansions performed by the algorithm {a mathematical formula}O(|T(s)|2).
      </paragraph>
      <paragraph>
       The soundness of the algorithm can simply be determined by noticing that the new condition we imposed on admissible expansions prevents Algorithm 1 from generating only those that would never led to the covering set including all the targets. This implies that we can answer Question 2 in polynomial time for this class of instances. Notice that this results can be easily extended to cycle graphs, see Fig. B.18(b) and to tree graphs where the number of leaves is fixed.
      </paragraph>
      <paragraph>
       Assessing the computational complexity of finding the maxmin equilibrium in line graphs is a problem left open in this paper. While when searching for a route covering all targets we can safely consider only covering sets defined by two extremes, this is not longer true when searching for an equilibrium. The main reason is that we cannot safely discard routes traversing targets whose penetration time is expired and this does not allow one to provide a polynomially bounded representation of the covering sets. We conjecture that the problem is {a mathematical formula}FNP-hard. To support our conjecture, we provide a class of instances whose non-dominated covering sets rises exponentially in {a mathematical formula}|T| for the values of {a mathematical formula}|T| such that the problem can be solved in reasonable time. More precisely, we empirically observed that the number of non-dominated covering sets of these instances is {a mathematical formula}Ω(2|T|−12) for {a mathematical formula}|T|≤23. With {a mathematical formula}|T|≥25, Algorithm 1 requires too long time to solve the problem and therefore we could not evaluate the number of non-dominated covering sets (a formal proof that the number of covering sets is exponential does not seem straightforward). While this is not a hardness proof, we believe that it could be an evidence and we report such instances because they could be useful for any researcher interested in the study of line graphs. The instances are defined as follow: given the starting vertex v, there are {a mathematical formula}(|T|−1)/2 targets at the left of v and {a mathematical formula}(|T|−1)/2 targets at the right of v. The cost of each edge is 1. The value of {a mathematical formula}d(t) is the square of the cost of the shortest path between t and v. In these instances, there are non-dominated routes continuously oscillating from the left to the right of the starting vertex v and vice versa.
      </paragraph>
      <paragraph>
       Let us now consider a star graph, as shown in Fig. B.19, defined as follows.
      </paragraph>
      <paragraph label="Definition 13">
       SIMPLE–STARSimple star graph instances (SIMPLE–STAR) are:
      </paragraph>
      <list>
       <list-item label="•">
        {a mathematical formula}V={v0,v1,v2,…,vn}, where {a mathematical formula}v0 is the starting vertex of {a mathematical formula}D;
       </list-item>
       <list-item label="•">
        {a mathematical formula}T=V∖{v0};
       </list-item>
       <list-item label="•">
        {a mathematical formula}E={(v0,vi),∀i∈{1,…,n}};
       </list-item>
       <list-item label="•">
        travel costs are {a mathematical formula}c(v0,vi)=γi, where {a mathematical formula}γi∈N+;
       </list-item>
       <list-item label="•">
        penetration times {a mathematical formula}d(t) and values {a mathematical formula}π(t) can be any.
       </list-item>
      </list>
      <paragraph>
       We can state the following theorem, whose proof is not direct as in the case of line and cycle graphs and thus more details are necessary.
      </paragraph>
      <paragraph label="Theorem 14">
       If the maximal covering route r covering all the targets exists, the Earliest Due Date algorithm returns r in polynomial time once applied to SIMPLE–STAR graph instances.
      </paragraph>
      <paragraph label="Proof">
       The Earliest Due Date [52] (EDD) algorithm is an optimal algorithm for synchronous (i.e., without release times) aperiodic scheduling with deadlines. It executes (without preemption) the tasks in ascending order according to the deadlines, thus requiring polynomial complexity in the number of tasks. Any SIMPLE–STAR graph instance can be easily mapped to a synchronous aperiodic scheduling problem: each target {a mathematical formula}ti is an aperiodic task {a mathematical formula}Ji, the computation time of {a mathematical formula}Ji is equal to {a mathematical formula}2γi, the deadline of task {a mathematical formula}Ji is {a mathematical formula}d(ti)+γi. It is straightforward to see that, if EDD returns a feasible schedule, then there is the maximal covering route, and, if EDD returns a non-feasible schedule, then there is not any maximal covering route.  □
      </paragraph>
      <paragraph>
       The above result shows that Question 2 can be answered in polynomial time.
      </paragraph>
      <paragraph label="Theorem 15">
       We focus on Question 3, showing that also this question can be answered in polynomial time for the above special instances. Given a signal s, the best pure strategy of{a mathematical formula}Din an SRG-v game on line graph, cycle graph, and SIMPLE–STAR graph instances can be found in polynomial time.
      </paragraph>
      <paragraph label="Proof">
       For the sake of clarity, we describe the algorithm in the simplified case in which there is only one signal s. The extension to the general case is straightforward. The algorithm works as follows:
      </paragraph>
      <list>
       <list-item label="1.">
        apply the algorithm searching for the route covering all the targets,
       </list-item>
       <list-item label="2.">
        if the maximal covering route exists, then return it,
       </list-item>
       <list-item label="3.">
        else remove the target t with the smallest {a mathematical formula}π(t) from {a mathematical formula}T(s),
       </list-item>
       <list-item label="4.">
        go to Point 1.
       </list-item>
      </list>
      <paragraph>
       Notice that the above results can be easily extended to tree graphs where the number of leaves is fixed.
      </paragraph>
     </section>
    </section>
    <section label="Appendix C">
     <section-title>
      Additional experimental results
     </section-title>
     <paragraph>
      We report in Fig. C.20 the boxplots of the results depicted in Fig. 5. They show that the variance of the compute times drastically reduces as ϵ increases. This is because the number of edges increases as ϵ increases and so the number of covering sets increases approaching {a mathematical formula}2|T|. On the other hand, with small values of ϵ, the number of covering sets of different instances can be extremely different.
     </paragraph>
    </section>
    <section label="Appendix D">
     <section-title>
      Notation
     </section-title>
     <paragraph>
      We report in Table D.3 the symbols used along the paper.
     </paragraph>
    </section>
   </appendices>
  </root>
 </body>
</html>