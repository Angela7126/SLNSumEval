<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:219">
</head>
<body bgcolor="white">
<a href="#0" id="0">We show that the mirror-descent dynamics converges to an approximate equilibrium in nonatomic congestion games.</a>
<a href="#1" id="1">We do this by observing that the dynamics corresponds to a mirror-descent process on a convex potential function of such a game and then proving that the process converges to the minimum of the function.</a>
<a href="#2" id="2">Moreover, we provide bounds on the outcome quality achieved by our dynamics in terms of two social costs: the average individual cost and the maximum individual cost.</a>
<a href="#3" id="3">Finally, we propose a new family of bandit algorithms and show that when each player adopt such an algorithm in an atomic congestion game, their actual joint strategy profile quickly approaches an approximate Nash equilibrium.</a>
<a href="#4" id="4">There may be other no-regret or even other learning algorithms which could guarantee nice convergence properties or simply good quality of outcomes.</a>
<a href="#5" id="5">There are more learning algorithms and dynamics to be explored in repeated games, while classes of games are even more numerous.</a>
<a href="#6" id="6">Beyond learning, there is still a variety of different dynamics to consider in repeated games.</a>
<a href="#7" id="7">A different line of future work would be to consider appropriate bandit scenarios for market equilibrium problems and to see if generalized mirror-descents with approximate gradients also work there.</a>
<a href="#8" id="8">Yet another line of work could be extending our framework to other partial-information models by other suitable gradient estimation methods.</a>
</body>
</html>