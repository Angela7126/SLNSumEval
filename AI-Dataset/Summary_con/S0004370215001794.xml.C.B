<html>
<head>
<meta name="TextLength" content="SENT_NUM:15, WORD_NUM:541">
</head>
<body bgcolor="white">
<a href="#0" id="0">With infinite computational power, infinite time and unlimited memory, perhaps anything could be simulated, from the bottom up, much as Pierre Simon Laplace [37] once imagined,</a>
<a href="#1" id="1">An intellect which at a certain moment would know all forces that set nature in motion, and all positions of all items of which nature is composed, if this intellect were also vast enough to submit these data to analysis, it would embrace in a single formula the movements of the greatest bodies of the universe and those of the tiniest atom; for such an intellect nothing would be uncertain and the future just like the past would be present before its eyes.</a>
<a href="#2" id="2">But in the real world, computational power is finite, decisions must be made in finite time, and memory resources are limited.</a>
<a href="#3" id="3">Neither the mind nor an automated problem solver can hope to model the interactions of everyday objects, let alone the interactions of complex agents like human beings, by simulations that originate at a quantum or even a molecular level.</a>
<a href="#4" id="4">Instead, real-world simulations that run in realistic time with reasonable resources must use approximations and idealization at a higher level of abstraction.</a>
<a href="#5" id="5">In many cases, setting up the simulation – choosing the approximations and idealizations appropriate to the problem – and interpreting the output of the simulation – deciding how accurate the results of the simulation are likely to be, which parts of the simulation are valid, and which parts are artifacts of the idealization – can be much more difficult than executing the simulation.</a>
<a href="#6" id="6">It is simply naïve to imagine that, for example, an automated reasoner could infer all that it needs to know about physics by running a Newtonian physical simulator on every entity that it encountered.</a>
<a href="#7" id="7">With the many examples that we have reviewed in this paper, we hope to have made clear that the full-simulation view of cognition is entirely unrealistic and by the same token that simulation, however precise, is equally unlikely to solve the problems of automated commonsense physical reasoning.</a>
<a href="#8" id="8">At this juncture, it is difficult or impossible to quantify what fraction of the physical reasoning that would be needed for general artificial intelligence or for specific applications such as household robots or narrative understanding could be carried out using simulation.</a>
<a href="#9" id="9">We have argued, however, that the range of examples we have presented in this paper suggests that there are significant limits to the use of simulation.</a>
<a href="#10" id="10">In particular, although we have suggested that simulation is effective for physical reasoning when the task is prediction, when complete information is available, when a reasonably high quality theory is available, and when the range of spatial or temporal scale involved is moderate, in many other cases simulation is to some extent problematic.</a>
<a href="#11" id="11">In particular, physical reasoning often involves tasks other than prediction and information is often partial.</a>
<a href="#12" id="12">Moreover, even when these conditions hold, there are many cases in which it would appear that alternative non-simulative modes of reasoning are likely to be easier, faster, or more robust.</a>
<a href="#13" id="13">Finally, setting up and interpreting a simulation requires modes of physical reasoning that are not themselves simulation.</a>
<a href="#14" id="14">For all these reasons, we suggest that non-simulative forms of reasoning are not an optional extra in automated physical reasoners but are centrally important.</a>
</body>
</html>