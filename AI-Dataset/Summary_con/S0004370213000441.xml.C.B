<html>
<head>
<meta name="TextLength" content="SENT_NUM:37, WORD_NUM:894">
</head>
<body bgcolor="white">
<a href="#0" id="0">The Machiavellian intelligence hypothesis [38] on the evolution of theory of mind predicts that there are competitive settings in which the use of higher-order theory of mind presents individuals with an evolutionary advantage.</a>
<a href="#1" id="1">But the benefits of making use of higher-order theory of mind may not always outweigh the costs.</a>
<a href="#2" id="2">For example, in settings in which a pure-strategy Nash equilibrium exists, individuals that make use of theory of mind are unlikely to outperform individuals that play the Nash strategy without explicitly reasoning about their opponentʼs mental states.</a>
<a href="#3" id="3">In other cases, simple heuristics may be superior to methods that rely on sophisticated cognitive abilities like theory of mind [70], [71].</a>
<a href="#4" id="4">However, humans possess the ability to make use of higher-order theory of mind, which suggests that there may be settings in which this cognitively demanding skill is useful.</a>
<a href="#5" id="5">For example, in using secret codes or negotiating climate change control, heuristics alone may not be enough.</a>
<a href="#6" id="6">In this paper, we have used agent-based models to show how the ability to make use of theory of mind can present individuals with an advantage over opponents that lack such an ability in certain competitive settings.</a>
<a href="#7" id="7">The advantage was found to be qualitatively similar across the four competitive games we discussed, which included repeated single-shot games rock–paper–scissors, elemental rock–paper–scissors, rock–paper–scissors–lizard–Spock, and the repeated extensive form game limited bidding.</a>
<a href="#8" id="8">To our surprise, the results show diminishing returns on higher orders of theory of mind.</a>
<a href="#9" id="9">Although both first-order and second-order theory of mind agents clearly outperform opponents that are more limited in their abilities to represent mental content of others, third-order theory of mind agents only marginally outperform second-order theory of mind opponents.</a>
<a href="#10" id="10">Fourth-order theory of mind was only found to be beneficial under specific circumstances.</a>
<a href="#11" id="11">These diminishing returns on higher orders of theory of mind were found not to be related to the number of actions available to the agents.</a>
<a href="#12" id="12">Increasing the action space from which agents choose did not increase performance of a third-order theory of mind agent in competition with a second-order theory of mind opponent.</a>
<a href="#13" id="13">Although theory of mind allows agents to outperform opponents that are more limited in their ability to explicitly represent mental states, theory of mind may not always be an efficient use of memory capacity.</a>
<a href="#14" id="14">Additional experiments show that in simple games such as rock–paper–scissors, an agent seems to benefit more from remembering past behaviour of his opponent rather than representing her mental states.</a>
<a href="#15" id="15">However, for more complex games such as Limited Bidding, theory of mind appears to have benefits that go beyond remembering past opponent behaviour.</a>
<a href="#16" id="16">Agents that are capable of both associative learning strategies and theory of mind strategies may therefore choose not to use their theory of mind when the task is simple.</a>
<a href="#17" id="17">Tasks may need to be sufficiently complex to elicit a theory of mind response.</a>
<a href="#18" id="18">In our model, we have assumed that agents choose what action to perform rationally.</a>
<a href="#19" id="19">That is, agents choose to perform the action that they believe to yield them the highest possible payoff.</a>
<a href="#20" id="20">This results in a predictability that benefits theory of mind agents, as shown by our results in the game of rock–paper–scissors–lizard–Spock.</a>
<a href="#21" id="21">When an opponent is indifferent between two actions in the sense that both actions maximize the expected payoff, the effectiveness of theory of mind suffers.</a>
<a href="#22" id="22">However, when there is a slight asymmetry between the two actions, such that one action appears to be a slightly better alternative than the other, this creates a focal point [72] for agents.</a>
<a href="#23" id="23">In this case, the opponent will choose the action that she believes to yield the better payoff.</a>
<a href="#24" id="24">However, this behaviour can be predicted by higher-order theory of mind agents.</a>
<a href="#25" id="25">An agent of a lower order of theory of mind may therefore be able to avoid falling victim to an opponent capable of theory of mind of a higher order when he does not choose what action to play completely rationally.</a>
<a href="#26" id="26">For example, agents could choose the action to perform with a probability proportional to the expected payoff.</a>
<a href="#27" id="27">Similarly, utility proportional beliefs [73] may benefit the effectiveness of theory of mind agents, through the belief that opponents choose an action proportionally to its utility.</a>
<a href="#28" id="28">In this case, the theory of mind agent is less reliant on his opponent playing completely rationally.</a>
<a href="#29" id="29">Future research may reveal how a balance can be achieved between exploiting weaknesses in the opponentʼs actions, while remaining unpredictable enough to avoid exploitation.</a>
<a href="#30" id="30">In our model, a zero-order theory of mind agent does not believe that his opponent behaves randomly [10], [11], but attempts to model the opponentʼs behaviour by assuming her past actions predict what she will do in the future.</a>
<a href="#31" id="31">A higher-order theory of mind agent therefore simultaneously updates his model of the mental content of the opponent and his belief about the opponentʼs theory of mind abilities.</a>
<a href="#32" id="32">It would be interesting to compare the effectiveness of theory of mind in direct competition with more classical strategies and heuristics.</a>
<a href="#33" id="33">In future work, we aim to investigate whether theory of mind is effective in more complex interaction settings including various partners as well.</a>
<a href="#34" id="34">Theory of mind may play an important role in cooperative settings, for example in teamwork, as well as mixed-motive settings such as negotiations (cf.</a>
<a href="#35" id="35">[37]).</a>
<a href="#36" id="36">This may provide further insights for automated agents that share their environment with human agents, such as in automated negotiation [3], [4].</a>
</body>
</html>