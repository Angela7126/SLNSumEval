<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:183">
</head>
<body bgcolor="white">
<a href="#0" id="0">We present a novel method for hierarchical topic detection where topics are obtained by clustering documents in multiple ways.</a>
<a href="#1" id="1">Specifically, we model document collections using a class of graphical models called hierarchical latent tree models (HLTMs).</a>
<a href="#2" id="2">The variables at the bottom level of an HLTM are observed binary variables that represent the presence/absence of words in a document.</a>
<a href="#3" id="3">The variables at other levels are binary latent variables that represent word co-occurrence patterns or co-occurrences of such patterns.</a>
<a href="#4" id="4">Each latent variable gives a soft partition of the documents, and document clusters in the partitions are interpreted as topics.</a>
<a href="#5" id="5">Latent variables at high levels of the hierarchy capture long-range word co-occurrence patterns and hence give thematically more general topics, while those at low levels of the hierarchy capture short-range word co-occurrence patterns and give thematically more specific topics.</a>
<a href="#6" id="6">In comparison with LDA-based methods, a key advantage of the new method is that it represents co-occurrence patterns explicitly using model structures.</a>
<a href="#7" id="7">Extensive empirical results show that the new method significantly outperforms the LDA-based methods in term of model quality and meaningfulness of topics and topic hierarchies.</a>
</body>
</html>