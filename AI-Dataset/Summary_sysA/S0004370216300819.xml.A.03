<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:227">
</head>
<body bgcolor="white">
<a href="#0" id="0">The model {a mathematical formula}Dm is the one on which a planning algorithm would compute a plan to execute in the real domain.</a>
<a href="#1" id="1">We will then let the agent perform RL over {a mathematical formula}Dr.</a>
<a href="#2" id="2">We define this function formally as follows: let {a mathematical formula} Π (L) be the set of minimal plans of cost (in our case length) up to L for a given planning problem, then{a mathematical formula} is the partial policy that returns, for each state in the MDP, the set of actions that belong to at least one minimal plan in the corresponding state of the model.</a>
<a href="#3" id="3">The agent can learn a policy for the reduced MDP {a mathematical formula}Dr, expanding it when necessary if the system transitions into a state where no action is available.</a>
<a href="#4" id="4">It follows that:{a mathematical formula} That is, an action a is available to the agent in a state s if and only if its value in the model for the abstract state {a mathematical formula}o(s) is close to the optimal value by more than the threshold.</a>
<a href="#5" id="5">1, with the agent starting at {a mathematical formula} 〈 10,0 〉 .</a>
<a href="#6" id="6">The P and PRL agents do planning with answer set programming over the same model, and for the PRL agent we always set {a mathematical formula} Μ =1.5 as the parameter for the threshold on plan length.</a>
</body>
</html>