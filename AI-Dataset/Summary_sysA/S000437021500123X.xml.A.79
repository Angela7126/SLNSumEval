<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:207">
</head>
<body bgcolor="white">
<a href="#0" id="0">Both plans start with three assumptive actions, first establishing the category of a room, then assuming the existence of the type of target object in that room, and finally placing a virtual object there, so that there is a concrete instance of “ magazine ” that the planner can reason about.</a>
<a href="#1" id="1">To these we add a set of observation actions{a mathematical formula}oi, which are used to check if the simulated execution results in the same state sequence as that originally experienced by the robot.</a>
<a href="#2" id="2">Thus, the planning problem has a solution only if the planner can find a sequence of assumptions that allow all the original physical actions to be executed in sequence, and which results in expected and actual observations {a mathematical formula}si matching.</a>
<a href="#3" id="3">To test the explanation performance of our system, we analyzed the generated explanations for three perception failure runs of the find test condition outlined before and an additional seven runs under a specifically designed explain test condition, where the object was hidden on a shelf in the meeting room.</a>
<a href="#4" id="4">But unlike the current paper, neither of these approaches explicitly reason about the fact that sensing actions can increase the size of the planning domain, nor the benefits of this for goal achievement.</a>
</body>
</html>