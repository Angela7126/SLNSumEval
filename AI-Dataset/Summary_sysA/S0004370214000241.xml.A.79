<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:275">
</head>
<body bgcolor="white">
<a href="#0" id="0">They differ in the method agents use to decide whether to replace their current value assignments to their variables, e.g., in the max gain messages (MGM) algorithm [15], the agent that can improve its state the most in its neighborhood replaces its assignment.</a>
<a href="#1" id="1">Some of the complete algorithms mentioned above use a tree structure and, like in the framework we propose in this paper, aggregate information to the root agent in order to allow it to make a global decision on the optimal solution.</a>
<a href="#2" id="2">Recently, this approach of using monotonic local search algorithms in small local environments in order to produce quality guarantees on the solution was extended to environments dependent on the distance of nodes in the constraint network [21] and environments that are bounded both by distance and size [35].</a>
<a href="#3" id="3">The main goal of the ALS_DCOP framework is to enhance a distributed local search algorithm with the anytime property (i.e., that the cost of the solution held by the algorithm at the end of the run would monotonically decrease if the algorithm is allowed to run for additional steps [25]).</a>
<a href="#4" id="4">The standard use of local search algorithms for DisCSPs and DCOPs prior to the proposal of the ALS_DCOP framework includes running an algorithm for some number of steps (m) and reporting the complete assignment (solution) held by the agents after the mth step.</a>
<a href="#5" id="5">Our investigation of this algorithm revealed that for specific problems it is possible to use constant probabilities for making the same decisions made by agents in DSA-SDP, i.e., the decisions on whether to replace a value assignment for the best alternative or to periodically change to a non-improving value assignment.</a>
</body>
</html>