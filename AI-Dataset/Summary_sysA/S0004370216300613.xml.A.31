<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:189">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our approach consists of shallow local features complemented by three types of word representation (clustering) features: Brown clusters [10], Clark clusters [15] and K-means clusters on top of the word vectors obtained by using the Skip-gram algorithm [39].</a>
<a href="#1" id="1">We demonstrate that combining and stacking different clustering features induced from various data sources (Reuters, Wikipedia, Gigaword, etc.)</a>
<a href="#2" id="2">allows to cover different and more varied types of named entities without manual feature tuning.</a>
<a href="#3" id="3">Even though our approach is much simpler than most, we obtain the best results for Dutch, Spanish and English and comparable results in German (on CoNLL 2002 and 2003).</a>
<a href="#4" id="4">We have shown how to develop robust NERC systems across languages and datasets with minimal human intervention, even for languages with inflected named entities.</a>
<a href="#5" id="5">This is based on adequately combining word representation features on top of shallow and general local features.</a>
<a href="#6" id="6">Crucially, we have empirically demonstrate how to effectively combine various types of simple word representation features depending on the source data available.</a>
<a href="#7" id="7">This has resulted in a clear methodology for using the three types of clustering features which produces very competitive results in both in-domain and out-of-domain settings.</a>
</body>
</html>