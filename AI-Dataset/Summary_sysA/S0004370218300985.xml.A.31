<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:278">
</head>
<body bgcolor="white">
<a href="#0" id="0">Derivation of the system</a>
<a href="#1" id="1">The simplest case correspond to a linear {a mathematical formula}A[1,1,1] architecture (Fig.</a>
<a href="#2" id="2">10).</a>
<a href="#3" id="3">Let us denote by {a mathematical formula}a1 and {a mathematical formula}a2 the weights in the first and second layer, and by {a mathematical formula}c1 the random weight of the learning channel.</a>
<a href="#4" id="4">In this case, we have {a mathematical formula}O(t)=a1a2I(t) and the learning equations are given by:{a mathematical formula} When averaged over the training set:{a mathematical formula} where {a mathematical formula} Α =E(IT) and {a mathematical formula} Β =E(I2).</a>
<a href="#5" id="5">With the proper scaling of the learning rate ({a mathematical formula} Η = Δ t) this leads to the non-linear system of coupled differential equations for the temporal evolution of {a mathematical formula}a1 and {a mathematical formula}a2 during learning:{a mathematical formula} Note that the dynamic of {a mathematical formula}P=a1a2 is given by:{a mathematical formula} The error is given by:{a mathematical formula} and:{a mathematical formula} the last equality requires {a mathematical formula}ai ≠ 0.</a>
<a href="#6" id="6">Derivation of the system</a>
<a href="#7" id="7">In the case of a linear {a mathematical formula}A[1,1,1,1] architecture, for notational simplicity, let us denote by {a mathematical formula}a1,a2 and {a mathematical formula}a3 the forward weights, and by {a mathematical formula}c1 and {a mathematical formula}c2 the random weights of the learning channel (note the index is equal to the target layer).</a>
<a href="#8" id="8">RBP equations</a>
<a href="#9" id="9">Note that in the case of RBP with backward matrices {a mathematical formula}C1, … ,CL − 1, as opposed to SRBP, one has the system of differential equations:{a mathematical formula} By letting {a mathematical formula}Bi=Ci … CL − 1 one obtains the SRBP equations however the size of the layers may impose constraints on the rank of the matrices {a mathematical formula}Bi.</a>
</body>
</html>