<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:243">
</head>
<body bgcolor="white">
<a href="#0" id="0">Although they also employ a physics engine for their simulations, they consider actions such as picking up an object only at a very abstract level, whereas we focus on the physical details of such actions in order to recognize qualitative phenomena occurring during their execution.</a>
<a href="#1" id="1">There are three ways of asserting an entity: either by naming the entity, if it is already known by the knowledge base including its physical specifications that are needed by the simulator; by providing the physical specifications of a previously unknown entity explicitly; or by providing an object type that can be generated by the object model factory.envision(Scenario, Plan(Params), Timeline)performs a simulation-based temporal projection for an asserted scenario and a fully instantiated robot control program/plan, and returns an ID of the projected timeline.</a>
<a href="#2" id="2">The main limitations of these approaches in the context of robotics are threefold: (a) important details such as positions of manipulators and objects are abstracted away; (b) variants of problems such as manipulating an object with different physical properties cannot be handled without extending the logical theory; and (c) consequences of concurrent actions and events are very difficult to foresee with pure symbolic reasoning, e.g., what does a robot see when turning its camera while navigating through its environment?</a>
<a href="#3" id="3">In future work, we will continue our research on how we can extract information from human demonstrations performed in a virtual manipulation environment to automatically determine the parameter space of robot manipulation actions from timelines [38].</a>
</body>
</html>