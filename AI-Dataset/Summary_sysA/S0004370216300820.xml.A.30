<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:216">
</head>
<body bgcolor="white">
<a href="#0" id="0">Word Sense Disambiguation.</a>
<a href="#1" id="1">We proposed a simple framework for a knowledge-rich unsupervised disambiguation system.</a>
<a href="#2" id="2">Our system obtained state-of-the-art results on multilingual All-Words Word Sense Disambiguation using Wikipedia as sense inventory, evaluated on the SemEval-2013 dataset [95], and on English All-Words Word Sense Disambiguation using WordNet as sense inventory, evaluated on the SemEval-2007 [111] and SemEval-2013 [95] datasets.</a>
<a href="#3" id="3">Additionally, we performed an experiment to measure the reliability of our semantic representations for named entities, obtaining the best results among all unsupervised systems and near state-of-the-art performance on the SemEval-2015 WSD dataset [88].</a>
<a href="#4" id="4">Throughout this section on the tasks based on semantic similarity, Nasarilexical and Nasariunified represent the systems based on the lexical and unified vectors, respectively.</a>
<a href="#5" id="5">Finally, we evaluated our embedded representations on the word to sense semantic similarity task.</a>
<a href="#6" id="6">Recall from Section 4.2 that our embedded vector representations share the same space with word embeddings.</a>
<a href="#7" id="7">Therefore, in order to calculate the similarity between a word and a sense, we only have to compute the cosine similarity between their respective vector representations.</a>
<a href="#8" id="8">In this experiment, we take the BabelNet sense representation of a word sense if it is modeled by Nasari.</a>
<a href="#9" id="9">Otherwise, in order to increase the coverage of our system, we simply take the word embedding of the lemma of the word sense as its representation.</a>
</body>
</html>