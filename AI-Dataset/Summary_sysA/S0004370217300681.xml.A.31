<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:204">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this work, we develop a model for robust visual semantic structure discovery and interpretation by employing both visual features and available sparse/incomplete text tags associated with the videos/images.</a>
<a href="#1" id="1">The contributions of this work are as follows: (I) We formulate a novel approach capable of effectively extracting and fusing information from ambiguous/noisy visual features and sparse/incomplete textual tags for precisely discovering and mining the inherent visual semantic structures.</a>
<a href="#2" id="2">This is made possible by introducing a new Hierarchical-Multi-Label Random Forest (HML-RF) model with a reformulated information gain function that allows to model the interactions between visual features and incomplete tags simultaneously.</a>
<a href="#3" id="3">Specifically, our model is designed to minimise the uncertainty of tag distributions in an “ abstract-to-specific ” hierarchical fashion so as to exploit the high-order skeletal guidance knowledge embedded in tag hierarchy structure.</a>
<a href="#4" id="4">(II) We introduce a unified tag dependency based algorithm to cope with the tag sparseness and incompleteness problem.</a>
<a href="#5" id="5">In particular, we formulate a principled way of locally integrating multiple statistical correlations (co-occurrence and mutual-exclusion) among tags during model optimisation.</a>
<a href="#6" id="6">(III) We develop a data clustering method based on the proposed HML-RF model by measuring pairwise similarity between visual samples for accurately discovering the semantic global group structure of all visual data.</a>
</body>
</html>