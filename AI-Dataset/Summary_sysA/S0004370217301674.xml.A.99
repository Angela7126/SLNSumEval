<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:173">
</head>
<body bgcolor="white">
<a href="#0" id="0">Also, note that state space could be reduced for practical effects, {a mathematical formula}Agentx could eventually work without observing {a mathematical formula}y ˙ speed, as well as {a mathematical formula}Agenty without observing {a mathematical formula}x ˙ speed.</a>
<a href="#1" id="1">So, a simplified 3DMC could be modeled as a fully decentralized problem with two individual agents with their own independent state vectors, {a mathematical formula}sx=[x,x ˙ ,y],sy=[x,y,y ˙ ].</a>
<a href="#2" id="2">In our DRL-CA approach, we replace such term by a cooperative adaptive factor Σ defined as{a mathematical formula}</a>
<a href="#3" id="3">The main principle of DRL-CA is supported on this cooperative factor that adapts a global learning rate on-line, which is based on a simple estimation of the partial quality of the joint policy performed.</a>
<a href="#4" id="4">So, Σ is computed from the probability of selected action ({a mathematical formula}Pa ⁎ ), according to the “ weakest ” among the M agents.</a>
<a href="#5" id="5">Additionally, since in DRL an agent can be decomposed into several separate agents, real-time communication and observation among those individual agents is not an issue unlike many of the MAS.</a>
</body>
</html>