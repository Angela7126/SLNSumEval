<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:186">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our first algorithm, state abstraction from demonstration (AfD) learns a policy for an MDP by building an abstract space {a mathematical formula}S 품 and using reinforcement learning to find an optimal policy that can be represented in {a mathematical formula}S 품 .</a>
<a href="#1" id="1">AfD obtains {a mathematical formula}S 품 by selecting a subset of features from the original state space S with which it can predict the action that a human teacher has taken in a set of demonstrations H. Learning in {a mathematical formula}S 품 can be significantly more efficient because a linear reduction in the number of features leads to an exponential reduction in the size of the state space.</a>
<a href="#2" id="2">AfD, shown in Algorithm 1, is composed of two steps.</a>
<a href="#3" id="3">To determine which features are relevant to a particular subtask, we measure the mutual information between each state feature and the action taken by a human teacher in a set of demonstrations.</a>
<a href="#4" id="4">Once the state space is decomposed into different subtasks, the agent can learn and represent a compact policy by focusing only on the features that are relevant at each part of the task.</a>
</body>
</html>