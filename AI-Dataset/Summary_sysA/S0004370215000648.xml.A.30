<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:146">
</head>
<body bgcolor="white">
<a href="#0" id="0">In order to encode the set of constraints {a mathematical formula}{ Φ k} that underlie both the learning and the inference problems, it is convenient to first introduce a background knowledge of predicates expressing facts about the relative positioning of blocks.</a>
<a href="#1" id="1">To this end we add a fresh predicate {a mathematical formula}left(i,j), that encodes the fact that “ a generic block of index i touches a second block j from the left ” , defined as follows:{a mathematical formula} Similarly, we add analogous predicates for the other directions: {a mathematical formula}right(i,j), {a mathematical formula}below(i,j), {a mathematical formula}over(i,j) (see Fig.</a>
<a href="#2" id="2">Finally, we encode the cost function {a mathematical formula}cost=w1dx2+w2dy2, completing the description of the optimization problem.</a>
<a href="#3" id="3">In the following we will see that the definition of the cost function implicitly defines also the set of features, or equivalently the set of soft constraints, of the LMT problem.</a>
</body>
</html>