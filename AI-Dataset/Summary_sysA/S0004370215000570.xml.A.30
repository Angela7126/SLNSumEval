<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:183">
</head>
<body bgcolor="white">
<a href="#0" id="0">In particular, POMDPs are beneficial if a particular problem has some of the following characteristics: 1) the problem requires weighting the value of information gathering versus collecting immediate rewards such as lifting objects to get a better view on other objects, 2) the world model is uncertain and thus it should be updated, for example when some objects are harder to grasp than others, or 3) the sequence of actions matters such as when objects occlude each other even partially.</a>
<a href="#1" id="1">The robot has to consider at each time step, whether the information gain from lifting a cup yields more reward in the long run than executing an action which may yield higher immediate reward.</a>
<a href="#2" id="2">Of course, because of the uncertainty in actions and observations, the real decision making problem can be even more complicated than this simple example implies.</a>
<a href="#3" id="3">Consequently, our hypothesis is that a heuristic greedy manipulation approach is not sufficient and that planning several time steps into the future is needed.</a>
<a href="#4" id="4">In order to study this hypothesis, we experimentally compared heuristic manipulation and the proposed POMDP approach with different planning horizons.</a>
</body>
</html>