<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:194">
</head>
<body bgcolor="white">
<a href="#0" id="0">A problem closely related to algorithm selection is the algorithm configuration problem: given a parameterized algorithm A, a set of problem instances I and a performance measure m, find a parameter setting of A that optimizes m on I (see [52] for a formal definition).</a>
<a href="#1" id="1">In contrast to ASlib, it is infeasible in AClib to store performance data for all possible parameter configurations, which often number more than 10{sup:50}.</a>
<a href="#2" id="2">Therefore, an experiment on AClib includes new (expensive) runs of the target algorithms with different configurations and hence, experiments on AClib are a lot more costly than experiments on ASlib, where no new algorithm runs are necessary.</a>
<a href="#3" id="3">Some algorithm selectors do not select a single algorithm, but compute a schedule of several algorithms: they apply a to i for a resource budget {a mathematical formula}r âˆˆ R (e.g., CPU time), evaluate the performance metric, evaluate a stopping criterion, and repeat as necessary, taking observations made during the run of a into account.</a>
<a href="#4" id="4">Most of our scenarios were taken from publications that report performance improvements through algorithm selection and consist of algorithms where the virtual best solver (VBS){sup:5} is significantly better than the single best solver.</a>
</body>
</html>