<html>
<head>
<meta name="TextLength" content="SENT_NUM:3, WORD_NUM:172">
</head>
<body bgcolor="white">
<a href="#0" id="0">The main challenges of applying RL in robotic domains include the multidimensional state and action spaces that incur high computational costs, the physical constraints that make acting in the real world much more difficult than in simulated worlds, the uncertainty due to partial observability of the physical environments and inherent noise in the sensor measurements, and the difficulty in tailoring the feedback or reward functions to guide intelligent behavior of the robots [7].</a>
<a href="#1" id="1">Most of these methods attempt to transfer structure and experiential knowledge in the forms of low level knowledge such as task instances, action-value pairs, full policies, full task models, prior distributions, or high level knowledge such as relevant action sets, partial policies, rules, relevant feature sets, or proto-value functions.</a>
<a href="#2" id="2">While they are able to show many advantages of their approach with the offline learning fitted Q-iteration algorithm [59] on several experiments, a potential drawback is the need of a large number of samples in all the source tasks, and the strong assumptions on the similarity amongst the different tasks.</a>
</body>
</html>