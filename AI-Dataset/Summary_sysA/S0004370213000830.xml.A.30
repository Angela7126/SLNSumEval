<html>
<head>
<meta name="TextLength" content="SENT_NUM:12, WORD_NUM:281">
</head>
<body bgcolor="white">
<a href="#0" id="0">Next, we present a semi-supervised version of our feature labeling algorithm which assumes that an unlabeled set of instances is present during training.</a>
<a href="#1" id="1">The semi-supervised setting for feature labeling incorporates knowledge from three sources: a small labeled training set, the feature labels provided by the end user and information from the implicit structure of the unlabeled data.</a>
<a href="#2" id="2">We evaluate our semi-supervised algorithm using both oracle feature labels and end-user feature labels from the user study mentioned above.</a>
<a href="#3" id="3">Our feature labeling algorithm is one of the best performing algorithms with oracle feature labels and the best performer with lower quality feature labels from end users.</a>
<a href="#4" id="4">Having presented results for the supervised feature labeling setting, we now present results for the semi-supervised setting when an unlabeled pool of data was available during training.</a>
<a href="#5" id="5">As before, we will first show results for the oracle study and then show results for feature labels harvested from real users during the user study.</a>
<a href="#6" id="6">Our new supervised LWLR-FL algorithm expands LWLR to take feature labeling into account.</a>
<a href="#7" id="7">Our results show that LWLR-FL was among the best performing supervised feature labeling algorithms under ideal conditions in an oracle study.</a>
<a href="#8" id="8">In our user study, we allowed ordinary end users to select any features for labeling directly from text documents.</a>
<a href="#9" id="9">LWLR-FL and MNB/Priors both were robust against lower quality feature labels in this more realistic setting, with MNB/Priors being the best performing algorithm overall.</a>
<a href="#10" id="10">Furthermore, our sensitivity analysis showed that LWLR-FL was robust to different parameter settings.</a>
<a href="#11" id="11">Taken together, these results demonstrate that feature labeling by end users, especially in the supervised learning setting, is an overall effective solution for augmenting the learning process to use knowledge beyond labeled training instances.</a>
</body>
</html>