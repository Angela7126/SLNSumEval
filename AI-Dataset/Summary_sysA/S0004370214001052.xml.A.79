<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:191">
</head>
<body bgcolor="white">
<a href="#0" id="0">This is achieved by building a tree of information sets (sets of states indistinguishable from one player's view point) rather than individual states, and dealing with the increased branching factor by restricting each MCTS iteration to a random determinization (a state sampled at random from the current information set).</a>
<a href="#1" id="1">In this paper we use the MO-ISMCTS version of the algorithm, which deals with games that have partially observable moves by constructing a separate search tree (a “ projection ” of the underlying game tree) to reflect each player's observation of the game.</a>
<a href="#2" id="2">Each step of the playout uses the policy function Α to choose an action a, depending on the current move history {a mathematical formula}[h] ⌣ Ρ (s) for the player about to act from state s, the current information mapping Θ , and the set of available actions {a mathematical formula}A(s) (line 11).</a>
<a href="#3" id="3">If EPIC is combined with the baseline algorithm using sequential combination then during simulation, subset-armed UCB1 selection is applied according to the current position-in-episode (EPIC-4): effectively this means that the simulation policy for the overall search is provided by the tree policy in the episode trees.</a>
</body>
</html>