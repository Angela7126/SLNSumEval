<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:345">
</head>
<body bgcolor="white">
<a href="#0" id="0">We define the ad hoc agent's knowledge about its teammates' behaviors as{a mathematical formula} where {a mathematical formula}1 ≤ s ≤ n is the state, {a mathematical formula}1 ≤ t ≤ k specifies a teammate, {a mathematical formula}TrueActiont(s) is the ground truth action distribution for teammate t for state s, and {a mathematical formula}PredActiont(s) is the action distribution that the ad hoc agent predicts that teammate t will select for state s.</a>
<a href="#1" id="1">We assume that {a mathematical formula}PredActiont(s) is the uniform distribution if the agent has no information about teammate t's actions in state s. Thus, if the ad hoc agent has better information about its teammates' behaviors, the distance between the distributions will be smaller and TeamK will be higher.</a>
<a href="#2" id="2">Therefore, the ad hoc agent must observe its teammates to determine their behaviors.</a>
<a href="#3" id="3">Once it knows the behaviors its teammates exhibit, the ad hoc agent can adapt accordingly.</a>
<a href="#4" id="4">To speed up the process of determining the teammates' behaviors, the ad hoc agent can draw upon its observations of past teammates, exploiting similarities between the current and past teammates' behaviors.</a>
<a href="#5" id="5">In this article, we consider scenarios in which the ad hoc agent has different amounts of prior knowledge of its teammates.</a>
<a href="#6" id="6">To capture the notion that the ad hoc agent is expected to have extensive prior general domain expertise (as is assumed in the ad hoc teamwork setting), though not with the specific teammates at hand, we pre-train the ad hoc agent with observations of a pool of past teammates.</a>
<a href="#7" id="7">A common approach to the problem is to determine which source data set (previous teammate) is the most similar to the target data set (current teammate) and transfer knowledge from only this source data set, where the similarity refers to the probability of the teammates taking the same actions from the same states.</a>
<a href="#8" id="8">To capture the notion that the ad hoc agent is expected to have extensive prior general domain expertise (as is assumed in the ad hoc teamwork setting), though not with the specific teammates at hand, PLASTIC-Model observes a number of past teammates.</a>
</body>
</html>