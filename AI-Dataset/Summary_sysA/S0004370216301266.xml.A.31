<html>
<head>
<meta name="TextLength" content="SENT_NUM:18, WORD_NUM:365">
</head>
<body bgcolor="white">
<a href="#0" id="0">This section describes how teammate models are learned in the LearnAboutPriorTeammate function of Algorithm 3.</a>
<a href="#1" id="1">The previous sections described how the ad hoc agent can select the most accurate model and use it for planning, but they did not specify the source of these models.</a>
<a href="#2" id="2">One option is that the ad hoc agent is given hand-coded models from human experts, as shown in Line 2 of Algorithm 2 and in Fig.</a>
<a href="#3" id="3">5.</a>
<a href="#4" id="4">However, there may not always be a source of these models, or the models may be imperfect.</a>
<a href="#5" id="5">Therefore, a more general solution is for the ad hoc agent to learn the models.</a>
<a href="#6" id="6">Learning allows the agent to gain a good set of diverse models over its lifespan, allowing better performance with arbitrary new teammates.</a>
<a href="#7" id="7">The ad hoc agent builds models of past teammates' behaviors offline and then selects from these learned models online while cooperating with new teammates.</a>
<a href="#8" id="8">It is expected that the past teammates are representative of the distribution of future teammates, though the future teammates have not yet been seen.</a>
<a href="#9" id="9">Once again, strategies 1 and 2 serve as baselines and require knowledge of the current teammates true behaviors.</a>
<a href="#10" id="10">This section showed that PLASTIC-Model enables ad hoc team agents to cooperate with a variety of hand-coded and externally-created teammates in the pursuit domain.</a>
<a href="#11" id="11">PLASTIC-Model gets good results when given a set of hand-coded behaviors as HandCodedKnowledge or when it has experienced a number of previous teammates as PriorTeammates.</a>
<a href="#12" id="12">PLASTIC-Model performs well even when it has never seen the current teammates before if the ad hoc agent has experience with previous teammates that exhibit similar behaviors.</a>
<a href="#13" id="13">Furthermore, transfer learning can learn new models quickly, allowing PLASTIC-Model to quickly adapt to new teammates.</a>
<a href="#14" id="14">Specifically, combining models learned from TwoStageTransfer with the models of past teammates outperforms the other approaches considered.</a>
<a href="#15" id="15">PLASTIC-Model allows the ad hoc agent to adapt to a variety of teammates.</a>
<a href="#16" id="16">Also, the agent's behavior differs greatly when cooperating with different teammates, indicating that it is not just following a single policy with all teammates.</a>
<a href="#17" id="17">These results show that PLASTIC-Model allows agents to reuse knowledge about previous teammates to quickly adapt by exploiting similarities to observed teammates' behaviors in the pursuit domain.</a>
</body>
</html>