<html>
<head>
<meta name="TextLength" content="SENT_NUM:5, WORD_NUM:287">
</head>
<body bgcolor="white">
<a href="#0" id="0">With the above notation, curiosity-driven skill acquisition problem can be formalized as an optimization problem with the objective that: Given a fixed set of input exploratory options {a mathematical formula}Oe, find a target-option set {a mathematical formula}OL, such that the number of target options learned at any time t is maximized:{a mathematical formula} under the constraints,{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}</a>
<a href="#1" id="1">Therefore, the number of learnable target options is equal to the total number of learnable abstractions, which is at most equal to the number of input exploratory options:{a mathematical formula} To enable continual learning[29], the number of skills acquired by the agent should not necessarily be bounded and the agent needs to reuse the previously acquired skills to learn more complex skills.</a>
<a href="#2" id="2">Therefore, continual curiosity-driven skill acquisition learning problem is a slightly modified version of the above formulation, such that the target options learned form a basis for new input exploratory options:{a mathematical formula} where {a mathematical formula}F(.)</a>
<a href="#3" id="3">If the estimation error of any already learned abstraction modules for the incoming observations is lower than threshold Δ , the exploratory-option's policy is learned using Least-Squares Policy Iteration Technique (LSPI; [53]), with an estimation of the transition model actively updated over the option's state-space {a mathematical formula}Iie ⊆ S Φ , and an estimated reward function that rewards high estimation errors.</a>
<a href="#4" id="4">5 illustrates the architecture of Curious Dr. MISFA, which includes (a) a reinforcement learning (RL) agent that generates an observation-stream selection policy based on intrinsic rewards, (b) an adaptive Incremental Slow Feature Analysis coupled with Robust Online Clustering (IncSFA-ROC) module that updates an abstraction based on the incoming observations, and (c) a gating system that prevents encoding observations that have been previously encoded.</a>
</body>
</html>