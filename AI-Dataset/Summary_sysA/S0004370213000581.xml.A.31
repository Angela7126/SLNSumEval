<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:172">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this work, we categorize the MIC methods according to how the information existent in the MI data is exploited (see Fig.</a>
<a href="#1" id="1">4).</a>
<a href="#2" id="2">In the Instance-Space (IS) paradigm, the discriminative information is considered to lie at the instance-level.</a>
<a href="#3" id="3">Therefore, the discriminative learning process occurs at this level: a discriminative instance-level classifier {a mathematical formula}f(x → ) is trained to separate the instances in positive bags from those in negative ones (see Fig.</a>
<a href="#4" id="4">1).</a>
<a href="#5" id="5">Based on it, given a new bag X the bag-level classifier {a mathematical formula}F(X) is obtained by simply aggregating instance-level scores {a mathematical formula}f(x → ), {a mathematical formula}x → ∈ X.</a>
<a href="#6" id="6">We say that this type of paradigm is based on local, instance-level information, in the sense that the learning process considers the characteristics of individual instances, without looking at more global characteristics of the whole bag.</a>
<a href="#7" id="7">In any categorization we will always find methods that fall close to the boundaries of two categories.</a>
<a href="#8" id="8">For example, in our taxonomy this happens with the BARTMIP method (see Section 7.6).</a>
</body>
</html>