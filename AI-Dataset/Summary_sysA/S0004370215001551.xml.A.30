<html>
<head>
<meta name="TextLength" content="SENT_NUM:7, WORD_NUM:163">
</head>
<body bgcolor="white">
<a href="#0" id="0">A new reinforcement learning algorithm, logistic regression RL (loreRL), that applies mDAGL on a CMDP to learn the transition models by automatically focusing on the relevant features in the environment; and</a>
<a href="#1" id="1">We address three main technical challenges in this framework: First, the transition model {a mathematical formula}T(S,A,S) is task specific, which is probably a reason why there have not been many studies that transfer the transition model.</a>
<a href="#2" id="2">Second, learning or updating a view or a transition model online in a complex and feature-rich environment is computationally expensive.</a>
<a href="#3" id="3">Our main task is to turn transition model learning into the learning of conditional distributions {a mathematical formula}P(E|s,f(s),a) using multinomial logistic regression for which attention to relevant features can be efficiently implemented online via mDAGL.</a>
<a href="#4" id="4">2.</a>
<a href="#5" id="5">LWT: the robot has first experienced Environment 2, and then uses that knowledge (transition model) to learn the action policy and run on Environment 3.</a>
<a href="#6" id="6">The robot does not update its knowledge of the transition model in the new environment.</a>
</body>
</html>