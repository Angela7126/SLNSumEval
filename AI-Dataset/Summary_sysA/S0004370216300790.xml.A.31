<html>
<head>
<meta name="TextLength" content="SENT_NUM:8, WORD_NUM:214">
</head>
<body bgcolor="white">
<a href="#0" id="0">a belief state that includes a priori common-sense knowledge and mental models of each of the agents involved (the robot and its human partners).</a>
<a href="#1" id="1">reuses the same set of affordances and inferences, together with explicit contextual reasoning on humans and robot abilities, to generate human – robot shared plans.</a>
<a href="#2" id="2">Monitoring human activity is needed by the execution controllers to track the engagement of the human and the progress of their actions.</a>
<a href="#3" id="3">It is also needed to synchronise seamlessly its own actions with the human actions.</a>
<a href="#4" id="4">Full human action and activity recognition is a task that requires knowledge and reasoning both on high-level facts like goals, intentions and plans, as well as bottom-up data from human and object motions.</a>
<a href="#5" id="5">Spark implements a set of simple temporal and geometric heuristics on human hand trajectories and possible objects placements to recognise simple elementary actions.</a>
<a href="#6" id="6">As HATP is a generic symbolic task planner and does not enforce any abstraction level for the planning domain, we have designed a planning domain made of top-level tasks whose semantics are close to the one used in the human – robot dialogue: the planner domain effectively contains concepts like Give, table, isOn.</a>
<a href="#7" id="7">This leads to an effective mapping between the knowledge extracted from the situation assessment or the dialogue, and the planner.</a>
</body>
</html>