<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:182">
</head>
<body bgcolor="white">
<a href="#0" id="0">In this case, the problem requires no multi-step planning, and the heuristic policy of moving all cups that appear dirty into the dishwasher is sufficient.</a>
<a href="#1" id="1">In contrast to a greedy approach, a POMDP may select actions that gather information, but do not yield immediate reward, when the problem so requires.</a>
<a href="#2" id="2">In the multi-object manipulation experiments, the robot had to decide between lifting objects to gather information or moving objects that appear dirty into the dishwasher.</a>
<a href="#3" id="3">We presented a POMDP model for multi-object manipulation of unknown objects in a crowded environment.</a>
<a href="#4" id="4">Because objects are occluded, their attributes are harder to observe and they are harder to manipulate.</a>
<a href="#5" id="5">To address this, our POMDP model uses an occlusion ratio to define how much an object occludes another one.</a>
<a href="#6" id="6">We use the occlusion ratio as a parameter in the observation and grasp probabilities of objects.</a>
<a href="#7" id="7">In addition to occlusion specific grasp probabilities, our model also includes automatically adapting object specific grasp probabilities.</a>
<a href="#8" id="8">To compute compact policies for the computationally complex POMDP model, we presented a new POMDP method that optimizes a policy graph using particle filtering.</a>
</body>
</html>