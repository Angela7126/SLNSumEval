<html>
<head>
<meta name="TextLength" content="SENT_NUM:2, WORD_NUM:169">
</head>
<body bgcolor="white">
<a href="#0" id="0">As a meta-network induces a log likelihood, a constrained meta-network induces a constrained log likelihood (CLL):{a mathematical formula} To learn the parameters of a Bayesian network, subject to equivalence constraints, we seek to obtain those estimates Θ maximizing Equation (3).</a>
<a href="#1" id="1">This leads to the following approximation of the constrained log likelihood, that also factorizes according to the examples i:{a mathematical formula} Here, {a mathematical formula}Pr Θ , Λ denotes the distribution of the base network, which is now determined by two sets of parameters: (1) the parameter estimates Θ of the Bayesian network that we seek to learn, and (2) the parameters Λ of the soft observations {a mathematical formula}vi that are used to compensate for the relaxed equivalence constraints {a mathematical formula}C. Note that we use two sets of compensations {a mathematical formula} Λ 1 and {a mathematical formula} Λ 2, to approximate {a mathematical formula}P(D,C| Θ ) (with the dataset observed in the meta-network) and {a mathematical formula}P(C| Θ ) (with the dataset unobserved in the meta-network).</a>
</body>
</html>