<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:175">
</head>
<body bgcolor="white">
<a href="#0" id="0">Example 4.2</a>
<a href="#1" id="1">Continuing the text categorization example, we can assume to have some external knowledge about the categories: {a mathematical formula} ∀ dA(d) ∨ B(d) expressing that any document must belong to class A or B.</a>
<a href="#2" id="2">Example 5.1</a>
<a href="#3" id="3">In our text categorization example, let us assume that {a mathematical formula}d1 belongs to class A and {a mathematical formula}d2 does not.</a>
<a href="#4" id="4">This can be expressed by stating that {a mathematical formula}d1 is a positive supervised example: {a mathematical formula}PA(d1)=true, while {a mathematical formula}PA(d2)=false.</a>
<a href="#5" id="5">We can then express the rule: {a mathematical formula} ∀ d(PA(d) ∧ A(d)) ∨ (¬PA(d) ∧ ¬A(d)) to incorporate the labeled data into the learning task.</a>
<a href="#6" id="6">The following constraint results from the fuzzy FOL generalization of the formulas using the minimum t-norm and after substituting the document identifiers with their feature representations and the query predicates with the corresponding functions to estimate:{a mathematical formula}Fig.</a>
<a href="#7" id="7">1 shows the network which is encoded when performing this simple learning task.</a>
<a href="#8" id="8">2.</a>
<a href="#9" id="9">an MFLN contains one feature for each possible grounding of each formula {a mathematical formula}Fh.</a>
</body>
</html>