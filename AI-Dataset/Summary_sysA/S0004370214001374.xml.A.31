<html>
<head>
<meta name="TextLength" content="SENT_NUM:12, WORD_NUM:260">
</head>
<body bgcolor="white">
<a href="#0" id="0">Our main motivation to use models with contextual policy search is two-fold.</a>
<a href="#1" id="1">First, we want to improve the data-efficiency of the model-free REPS using artificial rollouts.</a>
<a href="#2" id="2">Second, we want to obtain an accurate estimate of the expected reward {a mathematical formula}Rs Ω for a given context-policy parameter pair to avoid the bias in the sample-based REPS formulation.</a>
<a href="#3" id="3">Note that in the model-based formulation we use solely the artificial samples to update the policy.</a>
<a href="#4" id="4">Thus, in case of unbiased models, we can avoid the possibly noisy reward samples evaluated on the real system and, hence, eliminate the risk sensitive bias inherent to the REPS algorithm.</a>
<a href="#5" id="5">Additionally, we can increase the number of artificial samples significantly {a mathematical formula}N ≪ M to further improve the accuracy of policy updates.</a>
<a href="#6" id="6">Due to the recent success of using Gaussian Process models to reduce the model bias when learning complex system dynamics [9], we use GP models to learn the forward models of the robot and its environment.</a>
<a href="#7" id="7">Therefore, our method is called Gaussian Process Relative Entropy Policy Search (GPREPS).</a>
<a href="#8" id="8">With simulated and real robot experiments, we demonstrated that GPREPS significantly reduces the required amount of measurement data to learn high quality policies compared to state-of-the-art model free contextual policy search approaches.</a>
<a href="#9" id="9">Moreover, the GP models are able to incorporate the model uncertainty and produce accurate trajectory distributions.</a>
<a href="#10" id="10">Thus, with GPREPS we avoid the risk of learning from noisy reward samples that results in a bias in the model-free REPS formulation.</a>
<a href="#11" id="11">The increased data efficiency makes GPREPS applicable to learning contextual policies in real-robot tasks.</a>
</body>
</html>