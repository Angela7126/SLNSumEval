<html>
<head>
<meta name="TextLength" content="SENT_NUM:3, WORD_NUM:196">
</head>
<body bgcolor="white">
<a href="#0" id="0">The key contributions of this framework are threefold: (1) kLog is a language that allows users to declaratively specify relational learning tasks in a similar way as statistical relational learning and inductive logic programming approaches but it is based on kernel methods rather than on probabilistic modeling; (2) kLog compiles the relational domain and learning task into a graph-based representation using a technique called graphicalization; and (3) kLog uses a graph kernel to construct the feature space where eventually the learning takes place.</a>
<a href="#1" id="1">This enables the application of several supervised learning algorithms that construct linear functions in the feature space {a mathematical formula}F. In this context, {a mathematical formula} Φ (z) can be either computed explicitly or defined implicitly, via a kernel function {a mathematical formula}K(z,z ′ )= 〈 Φ (z), Φ (z ′ ) 〉 .</a>
<a href="#2" id="2">However, since it is hard to limit the type of graph produced by the graphicalization procedure (e.g., cases with very high vertex degree are possible as in general an entity atom may play a role in an arbitrary number of relationship atoms), we prefer an approximate solution with efficiency guarantees based on topological distances similar in spirit to [46].</a>
</body>
</html>