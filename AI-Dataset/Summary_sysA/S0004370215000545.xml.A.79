<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:273">
</head>
<body bgcolor="white">
<a href="#0" id="0">It is based on A* [2] and uses an evaluation function {a mathematical formula}f(s)=g(s)+wh(s) to rank a state s in the search frontier, where {a mathematical formula}g(s) represents the cost incurred to reach s, {a mathematical formula}h(s) is a (heuristic) estimate of the true cost to reach a solution from s, and the weight w is a real value greater than or equal to one.</a>
<a href="#1" id="1">We assume familiarity with the A* algorithm [2]: {a mathematical formula}g(s) denotes the cost of the path from the start state to s, and {a mathematical formula}f(s) is defined as {a mathematical formula}g(s)+h(s).</a>
<a href="#2" id="2">In fact, assume the agent is in state s and that we want to construct a learning space of size k around s. The next theorem states that the region built by expanding k nodes using A* is the one that maximizes the increase of the h-value of s. In other words, such a region maximizes learning in s. Let k be a natural number, h be a consistent heuristic, and{a mathematical formula}s ∈ Sbe such that{a mathematical formula}sgis at least at k edges away from s. Furthermore, let{a mathematical formula} Δ h(s,L)denote the amount by which the h-value of s increases after learning (i.e.</a>
<a href="#3" id="3">Note that since h is consistent,{a mathematical formula} Also due to the fact that h is consistent, we have that{a mathematical formula} because the f-values of expanded states cannot decrease through execution using consistent heuristics.On the other hand, since {a mathematical formula}t ∈ ∂ I,{a mathematical formula} In addition, {a mathematical formula}dL(s,t)=dI(s,t) because t was expanded via an optimal path (because h is consistent) and I contains such a path.</a>
</body>
</html>