<html>
<head>
<meta name="TextLength" content="SENT_NUM:4, WORD_NUM:168">
</head>
<body bgcolor="white">
<a href="#0" id="0">To the best of our knowledge, L3 is the only class of TL algorithms for Reinforcement Learning to date that uses the knowledge obtained in one domain as heuristics in another.</a>
<a href="#1" id="1">This characteristic makes L3 robust to negative transfers: if the cases acquired in the source domain are not useful in the target domain, assuming them as heuristics will not speed up the learning procedure but, in the worst case (when every case in the case base is not applicable to the target domain), L3 will be as efficient as the original RL algorithm that it is based.</a>
<a href="#2" id="2">In other words, if the case base contains no useful (or even misleading) information for the target domain, the agent is still able to learn the optimal policy for the domain using the RL component of the algorithm.</a>
<a href="#3" id="3">As the value of the heuristic defined in Equation (4) is bounded, after a finite number of learning iterations, the correct value of the value function in that state will be learned.</a>
</body>
</html>