<html>
<head>
<meta name="TextLength" content="SENT_NUM:14, WORD_NUM:348">
</head>
<body bgcolor="white">
<a href="#0" id="0">Team Knowledge: Does the ad hoc agent know what its teammates' actions will be for a given state, before interacting with them?</a>
<a href="#1" id="1">Reactivity of teammates: How much does the ad hoc agent's actions affect those of its teammates?</a>
<a href="#2" id="2">[47], but we consider the ad hoc agent's ability to change the actions of its teammates rather than the environment state.</a>
<a href="#3" id="3">In all of the scenarios in this article, TeamK is still relatively high given the ad hoc agent's previous experiences and the fact that the current teammate types are similar to the past teammates.</a>
<a href="#4" id="4">While the agents do react to the ad hoc agent's actions, they do not learn from it over time.</a>
<a href="#5" id="5">The ad hoc agent's actions have limited effects on its teammates; hence, the values of Reactivity are low to moderate for the domains in the article.</a>
<a href="#6" id="6">We believe that future research into teammates that learn about the ad hoc agent is needed; ad hoc agents should be able to deal with higher amounts of teammate reactivity.</a>
<a href="#7" id="7">In this variant, the ad hoc agent learns a policy to cooperate with each of its past teammates, selects which policies best match how to cooperate with its current teammates, and then selects actions using these policies.</a>
<a href="#8" id="8">When an agent has a good model of its environment, it can use this model to plan good actions using a limited number of interactions with the environment.</a>
<a href="#9" id="9">For an ad hoc agent to plan, it also needs to model its teammates; therefore, it is useful for the ad hoc agent to build models of its teammates' behaviors.</a>
<a href="#10" id="10">Given that learning new models online takes many samples, it is useful to reuse information learned from past teammates.</a>
<a href="#11" id="11">This section describes PLASTIC-Model, a variant of the PLASTIC approach that learns models of prior teammates and selects which models best predict its current teammates.</a>
<a href="#12" id="12">An overview of this approach is given in Fig.</a>
<a href="#13" id="13">PLASTIC-Model(CorrectLearned) evaluates the performance of the learning algorithm, where PLASTIC-Model knows which teammates the agent is cooperating with and uses its past observations of these teammates to learn a model of them.</a>
</body>
</html>