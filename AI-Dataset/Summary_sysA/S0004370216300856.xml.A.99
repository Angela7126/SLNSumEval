<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:326">
</head>
<body bgcolor="white">
<a href="#0" id="0">Furthermore, our analysis reveals that the issue is not just the amount of data, but insufficient exposure of attack surface[45], [55] in the initial rounds which prevents the defender from collecting sufficient information about adversary responses to various strategies and learn a reliable model.</a>
<a href="#1" id="1">Here we define an attack surface as the n-dimensional feature space used to model the attacker's behavior (detailed definition in Section 8).</a>
<a href="#2" id="2">While researchers often use imputation and sampling techniques to fill missing data due to participant attrition [78], [36], [23], for our repeated measures study of comparing human behavior models this may result in extremely biased estimates of the modeling parameters due to the influence of the retained participants' game plays and therefore may generate biased defender strategies.</a>
<a href="#3" id="3">Using this data collected in a particular round, the defender computes her utility of playing each pure strategy k (Line 3).</a>
<a href="#4" id="4">More specifically, this utility is computed for each pure strategy as the reward that would result to the defender given the observed adversary response if the defender were playing only this pure strategy.</a>
<a href="#5" id="5">The reinforcement of playing each pure strategy is then computed as the difference between the corresponding utility and the minimum possible utility over all the pure strategies (Line 4).</a>
<a href="#6" id="6">The defender then updates her propensities of playing each pure strategy by adding the reinforcements to the propensities computed in the earlier round (Line 5).</a>
<a href="#7" id="7">Due to the differences in animal densities, if we start from a uniform mixed strategy, it would leave many of the targets of high animal density to be attacked in round 1 (as evidenced from other human subject experiments conducted in the past [66]) and that would result in a defender utility which is much lower than the cumulative utility for any of our models over five rounds (see Section 12 for details).</a>
<a href="#8" id="8">Therefore, for our experiment with the RL approach, we assumed that the defender starts with the robust Maximin strategy in round 1.</a>
</body>
</html>