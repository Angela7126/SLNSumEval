<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:272">
</head>
<body bgcolor="white">
<a href="#0" id="0">3.</a>
<a href="#1" id="1">The actions of the agent are now expanded to be {a mathematical formula}B={A,Ba}.</a>
<a href="#2" id="2">The normal state transition dynamics can still occur based only on A, but now the action space also must include an affective “ how ” for the delivery “ what ” of an action.</a>
<a href="#3" id="3">Finally, a set of variables X represents the state of the system (e.g.</a>
<a href="#4" id="4">the state of the computer application or interface).</a>
<a href="#5" id="5">We do not assume that this system state is directly observable, and so also use sets of observation variables {a mathematical formula} Ω x.</a>
<a href="#6" id="6">The state space described by X may also include affective elements.</a>
<a href="#7" id="7">We have found that a fixed affective policy may work well for some affective identities, but not for others, whereas the actions suggested by BayesAct work well across the different identities that the client may have.</a>
<a href="#8" id="8">For example, if the client really does have the affective identity of a “ patient ” , then always issuing the prompts with an {a mathematical formula}EPA=[0.15,0.32,0.06] (the affective rating of the behaviour “ prompt ” in the ACT database) and otherwise simply “ minding ” the client ({a mathematical formula}EPA=[0.86,0.17, − 0.16]) leads to the client completing the task in an equal number of steps as BayesAct, and always completing the task within 50 steps.</a>
<a href="#9" id="9">However, if the client has an affective identity that is more “ good ” ({a mathematical formula}EPA=[1.67,0.01, − 1.03], corresponding to “ elder ” ) or more powerful ({a mathematical formula}EPA=[0.48,2.16,0.94], corresponding to “ boss ” ), then this particular fixed policy does significantly worse.</a>
<a href="#10" id="10">Example simulations and more complete results are shown in Appendix E.</a>
</body>
</html>