<html>
<head>
<meta name="TextLength" content="SENT_NUM:11, WORD_NUM:279">
</head>
<body bgcolor="white">
<a href="#0" id="0">An assumption common to many IRL methods is that the learner knows the expert's transition function.</a>
<a href="#1" id="1">Let Ψ : {a mathematical formula}S×A → S map an observed robot's transition from state s given action a to a particular next state, {a mathematical formula}s ′ .</a>
<a href="#2" id="2">The function Ψ gives the intended outcome of each action from each state.</a>
<a href="#3" id="3">We may view Ψ as a deterministic transition function.</a>
<a href="#4" id="4">Actions taken by the agent may not always result in the intended outcome leading instead to some other state.</a>
<a href="#5" id="5">We therefore focus on learning the probability of transitioning to the intended next state given a state-action pair for an observed robot I, {a mathematical formula}TI(s,a, Ψ (s,a)), and this probability is estimated from the available trajectory data.</a>
<a href="#6" id="6">The remaining probability mass, {a mathematical formula}1 − TI(s,a, Ψ (s,a)) is then distributed according to some error model, such as uniformly among all other states or perhaps to the intended outcomes of other actions.</a>
<a href="#7" id="7">• Known R{a mathematical formula}/T modifies this method by allowing the transition function to be learned using our approach.</a>
<a href="#8" id="8">Under the assumption that the intended state can be recognized from the observed robot's actions and previous state, our experiments conclusively show that the full transition model (dynamics) can be learned despite high degrees of occlusion.</a>
<a href="#9" id="9">Bard [5] used a maximum entropy approach to estimate state probabilities when the probabilities associated with aggregates of states are known.</a>
<a href="#10" id="10">Our technique, mIRL{a mathematical formula}/T ⁎ +Int, is similar to Bard's approach but has several key differences: rather than discrete states we use random variables whose values are unknown during each transition, the presence of occlusion, and our novel extension to learning transition probabilities.</a>
</body>
</html>