<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370214000344</url><title>On the revision of informant credibility orders</title><authors>Luciano H. Tamargo,Alejandro J. García,Marcelo A. Falappa,Guillermo R. Simari</authors><abstract>In this paper we propose an approach to multi-source belief revision where the trust or credibility assigned to informant agents can be revised. In our proposal, the credibility of each informant represented as a strict partial order among informant agents, will be maintained in a repository called credibility base. Upon arrival of new information concerning the credibility of its peers, an agent will be capable of revising this strict partial order, changing the trust assigned to its peers accordingly. Our goal is to formalize a set of change operators over the credibility base: expansion, contraction, prioritized, and non-prioritized revision. These operators will provide the capability of dynamically modifying the credibility of informants considering the reliability of the information. This dynamics will reflect a new perception of trust assigned to the informant, or extend the set of informants by admitting the addition of new informant agents.</abstract><keywords>Multi-agent system;Belief revision;Trust;Credibility orders;Multi-source belief revision</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>In this paper we will consider a set of deliberative agents that participate in a multi-agent system; each agent may play the role of an informant for other agents in the system. In this scenario, each agent could receive information from multiple sources, and the agents' subjective attribution of trust or credibility to a particular informant can be related to the trust attributed to others. Thus, when different agents provide conflicting information, or an agent gives information in conflict with the information the agent maintains, the credibility of the informants can be used to obtain a prevailing conclusion that will allow the agent to update its stored information.</paragraph><paragraph>In Multi-Source Belief Revision (MSBR) [10], [15], [49], a single agent can obtain new beliefs from multiple sources of information. Some proposals found in the literature of MSBR assume an order among sources (or informants), and use this order to decide which information prevails when a contradiction arises.</paragraph><paragraph>In this paper we propose an approach to MSBR where the credibility assigned to informant agents can be revised. To attach some degree of informational or epistemic trust to data received as information from an external source [45], is a common social device for human agents. We are drawing a distinction between epistemic trust and practical trust, making a suggestive analogy with epistemic and practical reasoning; the former being reasoning about what to believe and the latter being reasoning about how to act. Epistemic trust is therefore about the degree of acceptance an agent is willing to attach to a piece of information coming from another agent. Following the analogy, practical trust can be considered as trust in that an agent will act as she has promised to act. Notice that in this case, this is a form of subjective trust or credibility, i.e., trust as perceived and stored by an agent. Here, we will assume that the information received from an agent is as credible as the agent that provides it; this is a simplifying assumption that will be lifted in future investigations. We will also limit the present research to single topic credibility.</paragraph><paragraph>Furthermore, we can distinguish two types of MSBR. Unitary MSBR where an agent can receive from different informant agents an atomic piece of information (a sentence or a belief); and Conjunctive MSBR where the received information is a set of objects, probably provided by one or more sources. Our paper is focused on the first approach. Other works are focused on the second approach where the new information is a set of beliefs. For a more detailed comparison, cf. Section 8.</paragraph><paragraph>We will favor the use of the word credibility to refer to this characteristic of informant agents as this particular word carries an intuitive sense that helps to understand the related problems. We chose to represent credibility as a strict partial order in the set of agents; this choice will give us the capability of representing cases where the credibility of two agents is not related because it has not been established. The examples introduced below will show the usefulness of having this possibility.</paragraph><paragraph>The credibility relation of an agent and its informants will be maintained as a credibility base that will keep the current state of this particular strict partial order relation. As new assessments regarding the credibility of its informants are effected, an agent will be able to change this partial order relation, and in that manner, revise the credibility assigned to its peers accordingly.</paragraph><paragraph>Our goal is therefore to formalize change operators over the credibility base. These operators will provide the capability of dynamically modifying the credibility of informants to reflect a new perception of the informant's trust, or extend the set of informants by admitting the arrival of new informant agents. We will develop an expansion operator for a credibility base, then a contraction operator and finally two versions of revision: prioritized and non-prioritized. Contraction and revision operators will be based on the reliability of the information. Thus, the main contribution is the definition of different belief change operators that use the reliability of the information in order to make decisions regarding what information prevails. Following the approach presented in the AGM model [1], these operators are defined through constructions and representation theorems.</paragraph><paragraph>We will adopt an epistemic model where beliefs are provided by some informant(s). If the agent considers that {a mathematical formula}Informant1is less credible than {a mathematical formula}Informant2 then, in case of conflictive information, the information received from {a mathematical formula}Informant2 will be preferred over the information received from {a mathematical formula}Informant1. That is, the trust assigned to {a mathematical formula}Informant2 is higher than the trust assigned to {a mathematical formula}Informant1; hence, in our proposal, the reliability of a piece of information will reflect the credibility assigned to the informant.</paragraph><paragraph>A common approach to the analysis of the reliability of information is obtained by integrating different sources that rely on the use of some form of a majority principle (see Section 8). In some of those approaches, and oversimplifying the description of the decision mechanism they introduce, when two or more sources provide the same piece of information α, and a single agent gives ¬α, then α will be preferred. It is clear that using majority in the process of deciding is a very useful and computationally efficient approach for many situations, but it might not be appropriated in some complex scenarios that require a qualitative analysis of the information; in domains where there exists an order among informants, it is natural to prefer the information of the more credible one. As an example, consider the situation where an agent seeks information on a particular topic in an internet children's health forum. Reading the forum the agent finds out that four participants provide information α on the subject; but later the agent's pediatrician provides ¬α. If the agent assigns a higher credibility to the pediatrician than the perceived credibility of the other four; then, clearly in this case ¬α should prevail. Thus, our approach can be considered as complementary to those that use majority for taking decisions. This complementarity is important since majorities not always are right; the previous example and our motivating example below is intended to show precisely that.</paragraph><paragraph>Lately, the importance of having trust models have been emphasized in the literature. As stated in [44], two elements have contributed to substantially increase the interest on trust: the introduction of the multi-agent system paradigm and the evolution of e-commerce. The study of trust has many applications in Information and Communication technologies.</paragraph><paragraph>It is clear that some form of trust model is needed in any problem where the adoption of a critical decision depends on the credibility (informational trust) assigned to the information received from other agents. A crucial activity in multi-agent system is the agent's interaction, and through this interaction agents can share different types of information. Significatively, they can share information about the credibility or informational trust they have assigned to their peers; hence, through this interaction, the credibility assigned to their peers could change. In this work we will propose change operators for handling the dynamics in the credibility information.</paragraph><paragraph>In Sabater and Sierra [44], a set of relevant aspects to classify trust models is proposed. In our proposal, we will take into consideration only two of these aspects: information sources and trust reliability measure. They suggest that, sometimes knowing how reliable is the trust value reported, and its relevance to the decision making process, is as important as the value itself. In the model that we will propose, we provide this kind of information through agent identifiers which are the information sources.</paragraph><paragraph>Although there exist relevant works in Multi-Agent Belief Revision [35], [30], [15], [10] and in Trust and Reputation [44], [43], [14], [4], [45], their combination in one formalism and its formalization through representation theorems is novel. Our approach can be applied in any system requiring that trust or credibility of informants will be taken into consideration. For instance, the partial order of informants and the belief change operators we will introduce can be used as a complement for the model of MSBR proposed in [49] where informant agents are used, but a fixed total order was assumed among them. Thus, our proposal improves that model providing not only a less restrictive organization but also a more realistic scenario by incorporating a strict partial order of informants that can be revised dynamically. We will compare the previous approach with the new in the related work section, where we will also compare it with other proposals.</paragraph><paragraph>Some preliminary work related to this paper was reported in [47], where change operators for a partial order were proposed; however, we will extend that work in several ways. As we will explain below, in contrast to [47], the approach we present here will formalize how the agents receive and store information in a credibility base, and also how the reliability of the information is represented. We will specify which information prevails in the revision process, i.e., we will propose a reliability-based criterion to select which information is eliminated upon revision. Based on the reliability of the incoming information a non-prioritized revision operator is also proposed here.</paragraph><paragraph>Ma et al. [37] in a recent paper introduce a prioritized revision of partial pre-orders. However, in that work reliability values are not considered in the revision process (see Section 8).</paragraph><paragraph>Before concluding this introduction, we would like to discuss an example. This example will serve two purposes: to motivate the main ideas of our proposal, and as a running example to be used in the rest of the paper.</paragraph><section label="1.1"><section-title>Motivating example</section-title><paragraph>Consider an agent B that wants to buy a car; this agent can get information from other agents that are not equally credible to him. Agent B can obtain information from three fellow coworkers ({a mathematical formula}F1, {a mathematical formula}F2, and {a mathematical formula}F3) that B considers to have experience in buying cars. Also, B can consult four advisors ({a mathematical formula}A1, {a mathematical formula}A2, {a mathematical formula}A3 and {a mathematical formula}A4) who are specialists in the area. In our approach, the credibility assigned by B to these informants can be revised. As we will describe next, the credibility of each informant agent with respect to the other agents will be represented as a strict partial order, also keeping track of the source where the information comes from. Thus, when B receives new information about credibilities, he is able to revise his partial order, and the source of the information can be used for deciding which information prevails.</paragraph><paragraph>As we will explain in Section 3, the formalism provides a credibility base where the credibility that an agent B assigns to his informants is maintained; the credibility base can be depicted as a directed graph (see Fig. 1). Nodes in this graph represent agents and directed arcs represent the credibility order between agents. An arc from node {a mathematical formula}N1 to {a mathematical formula}N2 labeled with the set of agents {a mathematical formula}{L1,…,Ln} represents the fact that {a mathematical formula}N1 is strictly less credible than {a mathematical formula}N2 and that the information was provided by the agents {a mathematical formula}L1,…,Ln; when the information comes from just one agent L we will not use set notation. Thus, in our approach the label will represent the reliability of “{a mathematical formula}N1 is strictly less credible than {a mathematical formula}N2”.</paragraph><paragraph>Fig. 1 depicts the credibility base of agent B that wants to buy a car. In this particular example, B considers that {a mathematical formula}F2 is less credible than {a mathematical formula}F3. He also has some information from {a mathematical formula}F3 that states that {a mathematical formula}F1 is less credible than {a mathematical formula}F2 and from {a mathematical formula}F2 that states that he (B) is less credible than {a mathematical formula}F1. Agent B and agent {a mathematical formula}F3 both consider that {a mathematical formula}A2 is less credible than {a mathematical formula}A4. Therefore, in this case, the label of the arc is represented as the set {a mathematical formula}{B,F3}. Furthermore, fellow {a mathematical formula}F1 has told agent B that {a mathematical formula}A1 is less credible than {a mathematical formula}A2 and that {a mathematical formula}A1 is less credible than {a mathematical formula}A3. His other fellow {a mathematical formula}F2 has told him that {a mathematical formula}A3 is less credible than {a mathematical formula}A4. Note that the credibility relation is transitive, and therefore, in this particular example, for agent B his informant {a mathematical formula}A1 is currently less credible than {a mathematical formula}A4. The information maintained in a credibility base is not static and can be changed upon the arrival of new information. Consider for instance that agent B obtains new information from {a mathematical formula}F1 that {a mathematical formula}A2 is less credible than {a mathematical formula}F2. This should be represented with an arc labeled {a mathematical formula}F1 from node {a mathematical formula}A2 to node {a mathematical formula}F2. Note that this new information does not contradict the information represented in the graph of Fig. 1, and hence can be added without further consideration.</paragraph><paragraph>Consider now {a mathematical formula}F3 tells B that in his opinion, {a mathematical formula}A4 is less credible than {a mathematical formula}A1. This should be represented with an arc labeled {a mathematical formula}F3 from node {a mathematical formula}A4 to node {a mathematical formula}A1. Clearly, this new information contradicts the information represented in the graph of Fig. 1, because there are two paths in the graph stating that {a mathematical formula}A1 is currently less credible than {a mathematical formula}A4: the path {a mathematical formula}[A1,A3,A4] supported by the informants {a mathematical formula}F1 and {a mathematical formula}F2, and the path {a mathematical formula}[A1,A2,A4] supported by {a mathematical formula}F1, {a mathematical formula}F3 and B himself. Therefore, if B wants to consider this new information (i.e., {a mathematical formula}A4 is less credible than {a mathematical formula}A1), he must revise the credibilities assigned to his informants. Note that the new information is supported by {a mathematical formula}F3, and B considers that {a mathematical formula}F3 is more credible than {a mathematical formula}F1, {a mathematical formula}F2, and himself. In our approach, the credibility assigned to the informant agents will be used in two ways: to decide if the revision is done, and also to decide which information is withdrawn. In other words, the information represented in the agents' credibility partial order will be used to revise the credibility partial order itself.</paragraph><paragraph>The rest of this paper is structured as follows. Section 2 shows some preliminary concepts. In Section 3 a new representation for informant credibility is proposed. Sections 4, 5 and 6 define respectively: expansion, contraction, and prioritized revision for our trust model. Section 7 presents a non-prioritized revision based on a reliability criterion. In Section 8 related work is analyzed. Finally, in Section 9 conclusions are offered and ideas for future work are given. All the proofs for the representation theorems can be found in Appendix A.</paragraph></section></section><section label="2"><section-title>Preliminaries</section-title><paragraph>An analysis of Belief Revision in Multi-Agent Systems was introduced in Liu and Williams [35], [36]. There, a hierarchy that divides Belief Revision in two big areas is proposed: (1) Individual Belief Revision (IBR), and (2) Multi-Agent Belief Revision (MABR), also sometimes referred to as Intelligent Distributed Belief Revision. In [30], [35], [36], [40] different formalizations of MABR have been presented. MABR investigates the overall belief revision behavior of an agent team, or of a society, that in order to accomplish a shared goal its members need to communicate, cooperate, coordinate, and negotiate with each other. In the hierarchy introduced, the first area of Individual Belief Revision, is also divided in two: (1.a) Belief Revision in a single agent environment (called SBR) and (1.b) Individual Belief Revision in a multi-agent environment, also called Multi-Source Belief Revision (MSBR). In MSBR, an individual belief revision process is carried out where the new information may come from multiple sources. MSBR studies individual agent revision behaviors, i.e., when an agent receives information from multiple agents towards whom he has social opinions [36]. Therefore, the approach presented in this paper corresponds to MSBR. In contrast, MABR investigates the overall BR behavior of agent teams or societies.</paragraph><paragraph label="Definition 1">In our formalization, an agent can obtain new beliefs from multiple sources (informants) that are not equally credible, and their credibility can change dynamically. We will consider a universal finite set of informants {a mathematical formula}A={A1,…,An} and a strict partial order defined among these informants. In previous work [47], [46], the basic structure introduced below was proposed; we will recall it here, and in the next section we will extend it by adding the capability of maintaining the source from which each piece of information comes. Credibility order – credibility tupleGiven a finite set of informants {a mathematical formula}A, a credibility order over {a mathematical formula}A is a binary relation on {a mathematical formula}A called {a mathematical formula}O{a mathematical formula}(O⊆A×A). An informant {a mathematical formula}A1∈A is less credible than an informant {a mathematical formula}A2∈A according to {a mathematical formula}O if {a mathematical formula}(A1,A2)∈O⁎, where {a mathematical formula}O⁎ represents the transitive closure of {a mathematical formula}O. The pair {a mathematical formula}(A1,A2) is called a credibility tuple.</paragraph><paragraph>Graphically, a credibility order {a mathematical formula}O is represented as a directed graph, where the informants in {a mathematical formula}A label the nodes, and for each tuple {a mathematical formula}(A1,A2)∈O there is an arc from node {a mathematical formula}A1 to node {a mathematical formula}A2. For example, given the set of informants {a mathematical formula}{C,D,E,F,G,H,I}, Fig. 2 shows the graph representation of the credibility order {a mathematical formula}O1={(C,D),(C,E),(D,F),(E,F),(E,G),(H,I)}.</paragraph><paragraph>Consider for instance, {a mathematical formula}{(C,D),(D,C)}⊆O⁎, this would lead to the belief that both C is less credible than D and that D is less credible than C. Since these beliefs are contradictory, to accept them simultaneously would result in an inconsistent belief status. For this reason we require of the credibility order to be a strict partial order, i.e., the relation must be irreflexive, antisymmetric and transitive. We address this matter in the following definition.</paragraph><paragraph label="Definition 2">Sound credibility orderA credibility order {a mathematical formula}O⊆A×A is said to be sound iff {a mathematical formula}O⁎ is a strict partial order over {a mathematical formula}A.</paragraph><paragraph label="Example 1">The credibility order {a mathematical formula}O1 showed in Fig. 2 is sound. However, {a mathematical formula}O2=O1∪{(F,C)} is not sound because {a mathematical formula}(C,F) and {a mathematical formula}(F,C) are in {a mathematical formula}O2⁎, violating the antisymmetry condition.</paragraph><paragraph>In [47], change operators (expansion, contraction and revision) for {a mathematical formula}O were proposed. Nevertheless, in that work there are some important points that have not been addressed: (a) that model does not formalize how the agents receive and store credibility tuples in order to consider the informant agent; (b) it is not specified which information prevails in the revision process (i.e., it is not specified how to select which information is eliminated upon revision); and (c) the new information always has priority, a situation that can be unrealistic in some scenarios (see [17], [16]). To clarify the last point, consider for instance information coming from different sources, and that a preference among sources can be established, then a non-prioritized method can be more adequate since the information already known might have higher preference.</paragraph><paragraph>We will address in turn the items mentioned above and advance a proposal for each one. In the next section we will formally define the notion of credibility base; this type of base stores credibility tuples together with their associated information source representing the reliability of each piece of information. With this device, we can overcome the drawbacks mentioned above; that is, credibility will be used to decide which information prevails in the revision process. We will also introduce a non-prioritized revision operator that uses a reliability-based criterion to decide whether the new information is accepted or rejected.</paragraph></section><section label="3"><section-title>Representing the credibility of informants</section-title><paragraph>In the scenario described, an agent can receive credibility tuples from other agents in the form of credibility objects. For instance, consider the example proposed in our introduction: agent B (that wants to buy a car and has several informant agents) receives from a fellow coworker {a mathematical formula}F3 the information that the advisor {a mathematical formula}A4 is less credible than {a mathematical formula}A1. In this case, B will receive the credibility object {a mathematical formula}[(A4,A1),F3] representing that the credibility tuple {a mathematical formula}(A4,A1) was provided by {a mathematical formula}F3.</paragraph><paragraph label="Definition 3">Credibility objectLet {a mathematical formula}A be a set of agent identifiers and {a mathematical formula}B,D,S∈A, where {a mathematical formula}S≠B and {a mathematical formula}S≠D. A credibility object is a pair {a mathematical formula}[T,S] which represents that S is the information source of T, where {a mathematical formula}T=(B,D) is a credibility tuple.</paragraph><paragraph>Observe that the definition establishes that in a credibility object {a mathematical formula}[T,S] the source S cannot be in any place in T. A discussion considering the reasons for having this restriction is included in Section 9. Credibility objects will be stored in the agent's credibility base.</paragraph><paragraph label="Definition 4">Credibility baseLet {a mathematical formula}A be a set of agent identifiers. A credibility base of an agent {a mathematical formula}A∈A is a finite set {a mathematical formula}CA of credibility objects.</paragraph><paragraph label="Example 2">Consider again the scenario described in the introduction. The credibility base of the agent B is {a mathematical formula}CB={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A1,A2),F1],[(A1,A3),F1],[(A2,A4),B],[(A2,A4),F3],[(A3,A4),F2]}. Then, for instance, from {a mathematical formula}CB the informant {a mathematical formula}A1 is less credible than {a mathematical formula}A3, {a mathematical formula}A1 is less credible than {a mathematical formula}A4, and {a mathematical formula}A2 and {a mathematical formula}A3 are incomparable. Observe that the credibility objects {a mathematical formula}[(A2,A4),B] and {a mathematical formula}[(A2,A4),F3] both refer to the same credibility tuple but with a different informant. That is, the information that {a mathematical formula}A2 is less credible than {a mathematical formula}A4 was informed by {a mathematical formula}F3 and also known by B. Below it will be clear that this feature will be an advantage in our representation.</paragraph><paragraph>Note that the credibility base {a mathematical formula}CB of an agent B can contain credibility tuples received from other informant agents (e.g., {a mathematical formula}[(F1,F2),F3]) and credibility tuples of the agent B himself as well (e.g., {a mathematical formula}[(F2,F3),B]). Also, note that the owner of the credibility base can be included in credibility tuples of its own credibility base (e.g., {a mathematical formula}[(B,F1),F2]).</paragraph><paragraph>Credibility bases will be depicted as directed graphs with labeled arcs. If a credibility object {a mathematical formula}[(F1,F2),F3] is in the credibility base, then in the associated graph, there will be an arc labeled with {a mathematical formula}F3 from node {a mathematical formula}F1 to node {a mathematical formula}F2. If there is more than one credibility object with the same credibility tuple then, instead of adding several arcs from one node to another, the arc will be labeled with the related set of informants. See for instance Fig. 1 where the graph representation for {a mathematical formula}CB of Example 2 is shown.</paragraph><paragraph>The set {a mathematical formula}C=2(A×A)×A will represent all the possible credibility bases that can be built involving elements of {a mathematical formula}A; notice that we are using square brackets surrounding the credibility objects to make the notation clearer.</paragraph><paragraph>Given a credibility base {a mathematical formula}C, the function Cl defined below, characterizes the agent's strict partial order as the transitive closure of the set of credibility tuples that are contained in the credibility objects of {a mathematical formula}C.</paragraph><paragraph label="Definition 6">Closure functionLet {a mathematical formula}C∈C be a credibility base and {a mathematical formula}O={(B,C):there is A∈A and [(B,C),A]∈C}. The closure function is a function {a mathematical formula}Cl:C→2A×A, such that {a mathematical formula}Cl(C)=O⁎.Sound credibility baseA credibility base {a mathematical formula}C∈C is sound if {a mathematical formula}Cl(C) is sound.</paragraph><paragraph label="Remark 1">Therefore, given a sound credibility base {a mathematical formula}C, {a mathematical formula}Cl(C) represents the credibility strict partial order that the agent will use to compare informants. For instance, from the credibility base {a mathematical formula}CB of Example 2 we obtain that {a mathematical formula}(A1,A4)∈Cl(CB), i.e., for agent B, {a mathematical formula}A1 is less credible than {a mathematical formula}A4. Note also that {a mathematical formula}{(B,F2),(B,F3)}⊆Cl(CB). Given an agent {a mathematical formula}A∈A, we assume its credibility base {a mathematical formula}CA is sound.</paragraph><paragraph>Consider the agents {a mathematical formula}A,B,C,I∈A. As it will be explained in detail below, when an agent A receives a credibility object {a mathematical formula}[(B,C),I] which does not generate cycles in his current credibility base (i.e., {a mathematical formula}(C,B)∉Cl(CA)), then {a mathematical formula}[(B,C),I] can be added to {a mathematical formula}CA and the resulting credibility base will be sound. Note that it may be the case that {a mathematical formula}(B,C)∈Cl(CA); nevertheless, {a mathematical formula}[(B,C),I] will be also added to {a mathematical formula}CA because the credibility of the informant agent I can increase the reliability of {a mathematical formula}(B,C). This design decision implies that in the representation a credibility tuple can appear more than once in a credibility base; but from the point of view of the credibility objects stored in the credibility base there is no redundancy because each credibility object contains a different informant.</paragraph><paragraph>If the received credibility object generates a cycle, then a revision of the credibility base must be effected. With this problem in mind, in the following sections we will define a change theory for credibility bases giving the agents the capability of changing the strict partial order relation that represents the trust on their peers.</paragraph><paragraph label="Definition 7">Let us consider a pair of informants A and B, and a credibility base {a mathematical formula}C such that {a mathematical formula}(A,B)∈Cl(C), and recall our assumption that each agent has a sound credibility base (see Remark 1). The main task of a contraction operator is to obtain a new credibility base {a mathematical formula}C′ in which {a mathematical formula}(A,B)∉Cl(C′), losing as little information as possible. As we will show below, contraction does not mean simply removing from {a mathematical formula}C those credibility objects containing the credibility tuple {a mathematical formula}(A,B). Like in [47], it is necessary to consider every path from A to B, where the usual notion of simple path in an acyclic directed graph is used. We introduce the necessary definitions below. Simple pathLet {a mathematical formula}A,B∈A and {a mathematical formula}C∈C. A simple path P from A to B in {a mathematical formula}C is a subset P of {a mathematical formula}C such that {a mathematical formula}(A,B)∈Cl(P) and there is no proper subset {a mathematical formula}P′ of P such that {a mathematical formula}(A,B)∈Cl(P′).</paragraph><paragraph label="Remark 2">When no confusion is possible, we will refer to simple paths just as paths. Paths setGiven a pair of informants {a mathematical formula}A,B∈A and a credibility base {a mathematical formula}C∈C, we define the paths set from A to B in {a mathematical formula}C, denoted {a mathematical formula}C(A−B), as {a mathematical formula}C(A−B)={P:P is a path from A to B in C}.Consider the credibility base of agent B shown in Example 2 and depicted in Fig. 1, {a mathematical formula}CB={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A1,A2),F1],[(A1,A3),F1],[(A2,A4),B],[(A2,A4),F3],[(A3,A4),F2]}. Then, the paths set from {a mathematical formula}A1 to {a mathematical formula}A4 in {a mathematical formula}CB is {a mathematical formula}CB(A1−A4)={P1,P2,P3}, where:{a mathematical formula}{a mathematical formula}{a mathematical formula}Given {a mathematical formula}C∈C, since {a mathematical formula}Cl(C) is defined over the transitive closure of the credibility order among informants (see Definition 5), then it holds that {a mathematical formula}(B,D)∈Cl(C) if and only if there exists at least one element in {a mathematical formula}C(B−D).</paragraph><paragraph>In the following sections we will develop the expansion operator, then the contraction operator, and finally two versions of revision: prioritized and non-prioritized.</paragraph></section><section label="4"><section-title>Expansion operator using reliability</section-title><paragraph>In this section we will introduce an operator which expands a sound credibility base by a credibility object. This operator, unlike classic expansion operators, will be conditioned in its behavior by maintaining the soundness of the credibility base that is obtained. As we noted in Remark 1, we are restricting our scope to sound credibility bases. At this point, it is also worthwhile to observe that this operator is a true expansion since the resulting credibility base always includes the original elements of the expanded base. That is, even in the case where it is not possible to add the credibility object because the resulting credibility base would not be sound, the operator maintains the original one.</paragraph><section label="4.1"><section-title>Postulates for the expansion operator</section-title><paragraph>We will use “+” to denote a general expansion operator, and we will propose a set of postulates that will characterize a class of expansion operators whose behavior is such that they will preserve the property of soundness of the credibility base. In what follows, we will assume that {a mathematical formula}C∈C is a sound credibility base, {a mathematical formula}A,B,D∈A are three agents, and {a mathematical formula}T∈A×A is a credibility tuple.</paragraph><paragraph>E1 – Relative success: {a mathematical formula}C+[T,A]=C or {a mathematical formula}[T,A]∈C+[T,A].</paragraph><paragraph>This postulate is characterizing the behavior of the operator as a particular expansion where the attempt to augment the credibility base might fail or be successful. It is interesting to observe that in the case of failing in the expansion the credibility base is not altered.</paragraph><paragraph>E2 – Weak success: if {a mathematical formula}(B,A)∉Cl(C) then {a mathematical formula}[(A,B),D]∈C+[(A,B),D].</paragraph><paragraph>This postulate establishes that {a mathematical formula}[(A,B),D] is accepted in the expanded credibility base if there is no pair {a mathematical formula}(B,A) in {a mathematical formula}Cl(C).</paragraph><paragraph>E3 – Inclusion: {a mathematical formula}C⊆C+[T,A].</paragraph><paragraph>This postulate reflects the fact that the agent will not loose information during the expansion.</paragraph><paragraph>E4 – Vacuity: if {a mathematical formula}[T,A]∈C then {a mathematical formula}C+[T,A]=C.</paragraph><paragraph>A particular case of expansion occurs when a credibility base {a mathematical formula}C is expanded by a credibility object {a mathematical formula}[T,A] which is already in {a mathematical formula}C. In this case, expanding {a mathematical formula}C by {a mathematical formula}[T,A] does not generate any change in {a mathematical formula}C. The name vacuity follows the tradition of belief revision literature, showing a case in which the expansion operator does not change anything.</paragraph><paragraph>E5 – Soundness: if {a mathematical formula}C is a sound credibility base then {a mathematical formula}C+[T,A] is a sound credibility base.</paragraph><paragraph>An operator satisfying this postulate will guarantee the preservation of soundness over the resulting expanded credibility base.</paragraph><paragraph>E6 – Minimality: {a mathematical formula}C+[T,A] is the smallest set satisfying E1 to E5.</paragraph><paragraph>Similarly to expansion in AGM [23, p. 51], we require that {a mathematical formula}C+[T,A] does not contain more credibility objects than the ones required by other postulates.</paragraph></section><section label="4.2"><section-title>Construction</section-title><paragraph>We will give now the realization of a credibility based expansion operator for credibility bases called C-expansion using reliability (or CR-expansion for short) that is denoted “⊕”. A CR-expansion operator will add a new credibility object to a credibility base when soundness is preserved or will leave the credibility base unaffected rejecting the addition in case soundness is violated by it.</paragraph><paragraph label="Definition 9">{a mathematical formula}CR-expansionLet {a mathematical formula}C∈C be a sound credibility base, and {a mathematical formula}[(A,B),S] a credibility object. The operator “⊕”, or CR-expansion, is defined as follows:{a mathematical formula}</paragraph><paragraph label="Proposition 1">An expansion operator ⊕ satisfies E1 to E6 if and only if ⊕ is defined according toDefinition 9.</paragraph><paragraph label="Proof">Straightforward. □</paragraph><paragraph label="Example 4">The following example shows a particular feature of our expansion operator. Consider again the credibility base {a mathematical formula}CB of Example 2. Then, {a mathematical formula}CB⊕[(A1,A3),F2]=CB∪{[(A1,A3),F2]} increases the reliability of {a mathematical formula}(A1,A3) since {a mathematical formula}F2 is more credible than {a mathematical formula}F1. Fig. 3 shows (left) the graph for the original credibility base {a mathematical formula}CB and (right) the graph for the resulting credibility base after the expansion by {a mathematical formula}[(A1,A3),F2].</paragraph><paragraph>The reason for preserving all the credibility objects containing the same tuple as opposed to just keeping the one with the most credible informant is motivated in the fact that upon revision it is possible that the credibility order among informants might change, and in that case always the tuple will be informed by the informant that is currently the most credible.</paragraph></section></section><section label="5"><section-title>Contraction operator using reliability</section-title><paragraph>In this section, following [2] and [25], we will define an operator which contracts a credibility base by a credibility tuple. We will introduce the postulates of this operator first, then the construction, and finally the representation theorem.</paragraph><paragraph label="Remark 3">Credibility bases contain credibility objects (i.e., credibility tuples associated to informants); still, when an agent contracts its credibility base the contraction will be done by a credibility tuple, and not by a credibility object. The reason for not including the informant of the credibility tuple is twofold. Firstly, note that some of the credibility tuples that the agent might want to exclude are not provided by another agent but they are introduced in the strict partial order by the transitive closure; thus, these credibility tuples do not have a credibility object associated. Secondly, even in the case the credibility tuple has at least one informant associated, i.e., there is at least a credibility object in the credibility base carrying that tuple, the contraction must erase all the credibility objects that contain it.</paragraph><paragraph>We will adapt the notion of safe element proposed in [2] for contraction. In that article, an order among sentences is considered, and the contraction operator is defined over belief sets, whereas in our approach the contraction operator is defined over credibility bases. Let {a mathematical formula}(D,E) be a credibility tuple that we would like to eliminate from {a mathematical formula}C. We say that a credibility object {a mathematical formula}[(F,G),H] of {a mathematical formula}C is safe with respect to contraction by {a mathematical formula}(D,E) in {a mathematical formula}C if and only if every path from D to E either does not contain {a mathematical formula}[(F,G),H], or the path contains some credibility object {a mathematical formula}[(I,J),K] with {a mathematical formula}(K,H)∈Cl(C). That is to say, {a mathematical formula}[(F,G),H] is safe with respect to contraction by {a mathematical formula}(D,E) in {a mathematical formula}C if and only if there is no path from D to E that contains {a mathematical formula}[(F,G),H], or for every path P from D to E that contains {a mathematical formula}[(F,G),H] then P does contain some credibility object whose source is less credible than H according to {a mathematical formula}C. In the rest of the paper, and only when no confusion arises, we will sometimes write “is safe” instead of “is safe with respect to contraction by{a mathematical formula}(D,E)in{a mathematical formula}C”.</paragraph><paragraph label="Example 5">Let {a mathematical formula}C={[(D,F),J],[(D,H),L],[(F,G),M],[(H,G),M],[(G,E),K],[(J,K),E],[(K,L),G],[(L,M),E]}. Then, the credibility objects {a mathematical formula}[(D,H),L], {a mathematical formula}[(F,G),M], {a mathematical formula}[(H,G),M], {a mathematical formula}[(J,K),E], {a mathematical formula}[(K,L),G], {a mathematical formula}[(L,M),E] are safe with respect to contraction by {a mathematical formula}(D,E) in {a mathematical formula}C; whereas the credibility objects {a mathematical formula}[(D,F),J] and {a mathematical formula}[(G,E),K] are not safe with respect to contraction by {a mathematical formula}(D,E) in {a mathematical formula}C.</paragraph><section label="5.1"><section-title>Postulates for the contraction operator</section-title><paragraph>Let {a mathematical formula}D,E,F,G∈A, let {a mathematical formula}C,C′∈C be two sound credibility bases, and let {a mathematical formula}T1, {a mathematical formula}T2∈A×A be two credibility tuples. We will use “−” to denote a general contractor operator, and we will propose the following postulates for contraction.</paragraph><paragraph>C1 – Success: {a mathematical formula}(D,E)∉Cl(C−(D,E)).</paragraph><paragraph>A tuple cannot be entailed by the credibility base resulting from its contraction.</paragraph><paragraph>C2 – Inclusion: {a mathematical formula}C−(D,E)⊆C.</paragraph><paragraph>Since {a mathematical formula}C−(D,E) follows from withdrawing some credibility objects from {a mathematical formula}C without adding anything, it is natural to think that {a mathematical formula}C−(D,E) does not contain elements that do not belong to {a mathematical formula}C.</paragraph><paragraph>C3 – Safe retainment: {a mathematical formula}[T1,D]∈C−T2 if and only if {a mathematical formula}[T1,D] is a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C.</paragraph><paragraph>The credibility objects which prevail after contraction will be the objects that are safe objects before the contraction, similarly to [2].</paragraph><paragraph>C4 – Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C−(D,E) is sound.</paragraph><paragraph>Since contraction is basically a process of elimination, this operation should not introduce cycles. This postulate is related with C2 as it is shown in the following proposition.</paragraph><paragraph label="Proposition 2">For sound credibility bases, if a contraction operator satisfies C2 – Inclusion then it satisfies C4 – Soundness.</paragraph><paragraph label="Proof">Straightforward. □</paragraph><paragraph>We have not included a postulate similar to uniformity as was introduced by Hansson [24]. The reason is that an adaptation to our approach would be as the following: if for all {a mathematical formula}C′⊆C, {a mathematical formula}(D,E)∈Cl(C′) if and only if {a mathematical formula}(F,G)∈Cl(C′) then {a mathematical formula}C−(D,E)=C−(F,G); but, since contraction receives a tuple and not a credibility object (see Remark 3) this statement will collapse to triviality as it is reflected in Proposition 3.</paragraph><paragraph label="Proposition 3">Let{a mathematical formula}D,E,F,G∈A,{a mathematical formula}C∈C. If for all subsets{a mathematical formula}C′of{a mathematical formula}C,{a mathematical formula}(D,E)∈Cl(C′)if and only if{a mathematical formula}(F,G)∈Cl(C′)then{a mathematical formula}(D,E)={a mathematical formula}(F,G).</paragraph><paragraph label="Proof">See Appendix A. □</paragraph></section><section label="5.2"><section-title>Construction</section-title><paragraph>In this section, we introduce the construction of the contraction operator for credibility bases, called C-contraction using reliability (or CR-contraction for short). Consider again Example 3 where all the paths from {a mathematical formula}A1 to {a mathematical formula}A4 are shown. It is clear from Remark 2 that for the contraction of {a mathematical formula}CB by {a mathematical formula}(A1,A4) we need to eliminate at least one credibility object in every path of {a mathematical formula}CB(A1−A4). In other words, we need to eliminate a set of credibility objects from {a mathematical formula}CB so that no path is left from {a mathematical formula}A1 to {a mathematical formula}A4 in the new credibility base.</paragraph><paragraph>The CR-contraction operator that we will define below is based on the contraction of a credibility order by a credibility tuple {a mathematical formula}(A,B) proposed in [47]. That proposal uses a mechanism, based on [25], to decide which tuples are erased from each path from A to B. Next, this mechanism is adapted for a credibility base.</paragraph><paragraph label="Definition 10">Cut functionLet {a mathematical formula}C be a credibility base, a cut function σ for {a mathematical formula}C is a function such that for all {a mathematical formula}(A,B)∈Cl(C):</paragraph><list><list-item label="1.">{a mathematical formula}σ(C(A−B))⊆⋃(C(A−B)).</list-item><list-item label="2.">For each {a mathematical formula}P∈C(A−B),P∩σ(C(A−B))≠∅.</list-item></list><paragraph>Definition 10 does not specify how the cut function selects the credibility objects that are being discarded from each path; this matter will be addressed using the reliability of the credibility tuples. Thus, the cut function will select the least reliable credibility objects of each path.</paragraph><paragraph>Given a set P of credibility objects, the following function returns all the credibility objects that are associated with identifiers which are not more credible than other identifier associated with a credibility object in P.</paragraph><paragraph label="Definition 11">Minimal sources function{a mathematical formula}minC:C→C, is a function such that for a given credibility base {a mathematical formula}C∈C and {a mathematical formula}P⊆C,{a mathematical formula}</paragraph><paragraph label="Definition 12">Bottom cut functionGiven a paths set {a mathematical formula}C(A−B), {a mathematical formula}σ↓ is a bottom cut function if it is a cut function for {a mathematical formula}C such that{a mathematical formula}</paragraph><paragraph label="Example 6">Consider the credibility base of agent B of Example 2 and the paths set {a mathematical formula}CB(A1−A4)={P1,P2,P3} obtained in Example 3. As stated in Definition 12, {a mathematical formula}σ↓(CB(A1−A4)) will contain those elements from each path whose associated identifier is not greater than any other in the path. Hence, in path {a mathematical formula}P1 the selected credibility object is {a mathematical formula}[(A1,A2),F1] because {a mathematical formula}F1 is less credible than {a mathematical formula}F3; in path {a mathematical formula}P2 the selected credibility object is {a mathematical formula}[(A2,A4),B]; and in path {a mathematical formula}P3 is {a mathematical formula}[(A1,A3),F1]. Therefore, {a mathematical formula}σ↓(CB(A1−A4))={[(A1,A2),F1],[(A2,A4),B],[(A1,A3),F1]}.</paragraph><paragraph>Note that, the cut function can select more than one object from a single path when the reliability of the selected objects is incomparable. In particular, if all the agents associated with the credibility objects in a path are incomparable, then, the bottom cut function selects all of them. Observe that we use the credibility base itself to decide which information prevails. Then, we avoid to have a separate data structure maintaining the measure of reliability. Next, the CR-contraction operator, denoted {a mathematical formula}⊖σ↓, is introduced.</paragraph><paragraph label="Definition 13">{a mathematical formula}CR-contractionLet {a mathematical formula}C∈C, {a mathematical formula}(A,B) a credibility tuple, {a mathematical formula}C(A−B) a paths set, and let {a mathematical formula}σ↓ be a bottom cut function for {a mathematical formula}C(A−B). The operator “{a mathematical formula}⊖σ↓”, called C-contraction using reliability or CR-contraction, is defined as follows:{a mathematical formula}</paragraph><paragraph label="Example 7">Consider the credibility base in Example 2, {a mathematical formula}CB={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A1,A2),F1],[(A1,A3),F1],[(A2,A4),B],[(A2,A4),F3],[(A3,A4),F2]}. Then, suppose B wants to reflect that the advisor {a mathematical formula}A1 is no longer less credible than the advisor {a mathematical formula}A4. That is, B wants to effect a contraction by the credibility tuple {a mathematical formula}(A1,A4) using “{a mathematical formula}⊖σ↓”. As showed in Example 6, {a mathematical formula}σ↓(CB(A1−A4))={[(A1,A2),F1],[(A2,A4),B],[(A1,A3),F1]}. Hence, {a mathematical formula}CB⊖σ↓(A1,A4)=CB∖σ↓(CB(A1−A4))={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A2,A4),F3],[(A3,A4),F2]}. Fig. 4 shows (left) the graph for the original credibility base {a mathematical formula}CB and (right) the graph for the resulting credibility base after the contraction by {a mathematical formula}(A1,A4) where three arcs have been deleted.</paragraph><paragraph>Next, we introduce the Representation Theorem for this new contraction operator (C-contraction using reliability “{a mathematical formula}⊖σ↓”). This theorem proves the correspondence between the set of postulates and the construction.</paragraph><paragraph label="Theorem 1">Given{a mathematical formula}C∈C, “{a mathematical formula}⊖σ↓” is a C-contraction using reliability for{a mathematical formula}Cif and only if it satisfies success (C1), inclusion (C2), and safe retainment (C3).</paragraph><paragraph label="Proof">See Appendix A. □</paragraph><paragraph>The principle of minimal change is an accepted policy in the belief change research community; that is, beliefs should be given up only when one is forced to do so, and even in that situation, as few of them as possible should be given up [27]. In the present formalism, if some particular information (tuple) must be abandoned then all the credibility objects containing that tuple should be erased to achieve that, and that is the minimal possible characterization of the effect. Although our contraction operator can produce a change that is not minimal with respect to the number of credibility objects in the credibility base {a mathematical formula}C, the change is minimal as discussed in [27].</paragraph></section></section><section label="6"><section-title>Prioritized revision operator using reliability</section-title><paragraph>In the existing literature, several prioritized methods for sentences can be found, e.g., partial meet revision[1] and kernel revision from kernel contraction[25]. In these methods, the new information has priority over the beliefs in the base of the receiver agent.</paragraph><paragraph>In this section, following [25], we will define a new prioritized revision operator for credibility bases. This operator makes use of the safe element idea introduced for contraction at the beginning of the previous section, considered now in the context of revision. We will show first the postulates of this operator, then its construction, and finally the representation theorem.</paragraph><section label="6.1"><section-title>Postulates for the prioritized revision operator</section-title><paragraph>Let {a mathematical formula}D,E,F,G,H,I∈A, let {a mathematical formula}C∈C be a sound credibility bases, and let {a mathematical formula}T∈A×A be a credibility tuple. We will use “⁎” to denote a general prioritized revision operator, and we will propose the following postulates for prioritized revision.</paragraph><paragraph>PR1 – Success: {a mathematical formula}[T,D]∈C⁎[T,D].</paragraph><paragraph>Since the revision operator defined here is considered prioritized (the new information has priority), the first postulate establishes that the revision should be successful. That is, the result of revising a credibility base {a mathematical formula}C by a credibility object {a mathematical formula}[T,D] should be a new credibility base that contains {a mathematical formula}[T,D].</paragraph><paragraph>PR2 – Inclusion: {a mathematical formula}C⁎[T,D]⊆C∪{[T,D]}.</paragraph><paragraph>This postulate states that besides {a mathematical formula}[T,D] no other element will be added upon revision of {a mathematical formula}C by {a mathematical formula}[T,D].</paragraph><paragraph>PR3 – Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C⁎[T,D] is sound.</paragraph><paragraph>This postulate guarantees that soundness is preserved in the resulting revised credibility base.</paragraph><paragraph>PR4 – Uniformity: {a mathematical formula}C∩(C⁎[T,D])=C∩(C⁎[T,E]).</paragraph><paragraph>This postulate establishes that {a mathematical formula}C⁎[T,D] preserves from {a mathematical formula}C the same credibility objects as {a mathematical formula}C⁎[T,E].</paragraph><paragraph>PR5 – Safe retainment: {a mathematical formula}[(D,E),F]∈C⁎[(G,H),I] if and only if {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.</paragraph><paragraph>The prevailing credibility objects after revision will be the objects that are safe objects before the revision, similarly to [2].</paragraph></section><section label="6.2"><section-title>Construction</section-title><paragraph>Next, we will give a construction of the prioritized revision operator for credibility bases, called C-revision using reliability (or CR-revision for short), denoted “{a mathematical formula}⊛σ↓”. Consider an agent that has a credibility base {a mathematical formula}C, and that the agent receives the information {a mathematical formula}[(A,B),S], that is, A is less credible than B. The basic task of our prioritized operator is to construct a new credibility base in which {a mathematical formula}(A,B)∈Cl(C) but {a mathematical formula}(B,A)∉Cl(C). When a credibility base {a mathematical formula}C∈C is revised by a credibility object {a mathematical formula}[(A,B),S] there exist two tasks:</paragraph><list><list-item label="1.">to maintain the soundness of {a mathematical formula}C. If {a mathematical formula}(B,A)∈Cl(C) (i.e., the addition of {a mathematical formula}(A,B) generates a cycle in the new credibility base), then is necessary to erase some credibility objects from {a mathematical formula}C to avoid cycles.</list-item><list-item label="2.">to add {a mathematical formula}[(A,B),S] to {a mathematical formula}C. As shown above, if {a mathematical formula}(A,B)∈Cl(C) then this operation might also increase the reliability of {a mathematical formula}(A,B).</list-item></list><paragraph>The first task can be accomplished contracting by {a mathematical formula}(B,A). The second task can be accomplished expanding by {a mathematical formula}[(A,B),S]. This composition is based on the Levi identity[34], [22], [1], which proposes that a revision can be constructed out of two operations: a contraction and an expansion.</paragraph><paragraph label="Definition 14">Prioritized C-revision using reliabilityLet {a mathematical formula}C∈C, {a mathematical formula}[(A,B),S] a credibility object, {a mathematical formula}⊖σ↓ our CR-contraction operator and ⊕ our CR-expansion operator. The operator “{a mathematical formula}⊛σ↓”, called prioritized C-revision using reliability or CR-revision, is defined as follows:{a mathematical formula}</paragraph><paragraph>The representation theorem for this new proposed prioritized revision operator {a mathematical formula}⊛σ↓ is introduced below. This theorem proves the correspondence between postulates and construction.</paragraph><paragraph label="Theorem 2">Given{a mathematical formula}C∈C, “{a mathematical formula}⊛σ↓” is a prioritized revision using reliability for{a mathematical formula}Cif and only if it satisfies success (PR1), inclusion (PR2), soundness (PR3), uniformity (PR4), and safe retainment (PR5).</paragraph><paragraph label="Proof">See Appendix A. □</paragraph><paragraph>The following proposition establishes the relation among contraction, expansion, and prioritized revision.</paragraph><paragraph label="Proposition 4">If “⊕” satisfies E1, E2, E3, E4, E5 and E6, and “{a mathematical formula}⊖σ↓” satisfies C1, C2 and C3, then “{a mathematical formula}⊛σ↓” satisfies PR1, PR2, PR3, PR4, and PR5.</paragraph><paragraph label="Proof">See Appendix A. □</paragraph><paragraph label="Example 8">Consider the credibility base of Example 2, {a mathematical formula}CB={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A1,A2),F1],[(A1,A3),F1],[(A2,A4),B],[(A2,A4),F3],[(A3,A4),F2]}. Then, suppose that the fellow worker {a mathematical formula}F3 tells B that, in his opinion, the advisor {a mathematical formula}A4 is less credible than the advisor {a mathematical formula}A1. That is to say, B has to revise by {a mathematical formula}[(A4,A1),F3] using “{a mathematical formula}⊛σ↓”. Since {a mathematical formula}(A1,A4)∈Cl(CB) then it is first necessary to contract {a mathematical formula}CB by {a mathematical formula}(A1,A4) as shown in Example 7, and then to expand {a mathematical formula}CB⊖σ↓(A1,A4) by {a mathematical formula}[(A4,A1),F3]. Thus, {a mathematical formula}CB⊛σ↓[(A4,A1),F3]={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A2,A4),F3],[(A3,A4),F2],[(A4,A1),F3]}. Fig. 5 shows (left) the graph for the original credibility base {a mathematical formula}CB of Example 2, and (right) the graph for the resulting credibility base after the revision by {a mathematical formula}[(A4,A1),F3] where three arcs have been deleted, and a new arc from {a mathematical formula}A4 to {a mathematical formula}A1 was added.</paragraph></section></section><section label="7"><section-title>Non-prioritized revision operator using reliability</section-title><paragraph>A prioritized revision operator is characterized by the satisfaction of the success postulate by the operator; that is, the incoming information is always accepted, becoming a part of the beliefs of the agent. However, as is mentioned in [17], oftentimes this is an unrealistic feature since actual epistemic agents, when confronted with information that contradicts previous beliefs, choose to reject the recent arrival. For instance, in a multi-agent domain if the information comes from different sources, and these sources are not equally credible, a non-prioritized method could be more adequate. Several models of belief revision have been developed where either the new information is completely accepted or it is completely rejected [26], [39], [28], [12]. In the literature of uncertain evidence revision there exist other proposals that not just simply accept or reject the new information, for instance [17], [9], [38], [32]. In this section, we define a non-prioritized operator which completely accepts or rejects the new information.</paragraph><section label="7.1"><section-title>Postulates for the non-prioritized revision operator</section-title><paragraph>Let {a mathematical formula}A,B,S∈A, {a mathematical formula}C∈C be a credibility base, {a mathematical formula}T∈A×A be a credibility tuple. We will use “⊚⊚” to denote a general non-prioritized revision operator, and we will propose the following postulates for non-prioritized revision.</paragraph><paragraph>NPR1 – Relative success: {a mathematical formula}C⊚⊚[T,S]=C or {a mathematical formula}[T,S]∈C⊚⊚[T,S].</paragraph><paragraph>This postulate, inspired by [28], says that all or nothing is accepted.</paragraph><paragraph>NPR2 – Weak success: if {a mathematical formula}(B,A)∉Cl(C) then {a mathematical formula}[(A,B),S]∈C⊚⊚[(A,B),S].</paragraph><paragraph>This postulate establishes that {a mathematical formula}[(A,B),S] is accepted in the revised credibility base if there is no path in {a mathematical formula}C from B to A.</paragraph><paragraph>NPR3 – Conditional success: {a mathematical formula}[(A,B),S]∈C⊚⊚[(A,B),S] when for all objects {a mathematical formula}[(D,E),F] that are not safe with respect to {a mathematical formula}(B,A) in {a mathematical formula}C it holds that {a mathematical formula}(F,S)∈Cl(C).</paragraph><paragraph>Observe that both NPR1 and NPR2 do not consider the reliability of credibility objects. Nevertheless, NPR3 establishes that a credibility object is accepted when its informant is sufficiently credible. That is, the input will be accepted when the informants of those elements that are not safe with respect to {a mathematical formula}(B,A) in {a mathematical formula}C are less credible than the informant of the new incoming tuple {a mathematical formula}(A,B).</paragraph><paragraph>NPR4 – Inclusion: {a mathematical formula}C⊚⊚[T,D]⊆C∪{[T,D]}.</paragraph><paragraph>This postulate states that besides {a mathematical formula}[T,D] no element will be added upon revision of {a mathematical formula}C by {a mathematical formula}[T,D].</paragraph><paragraph>NPR5 – Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C⊚⊚[T,D] is sound.</paragraph><paragraph>This postulate guarantees that soundness is preserved in the revised credibility base.</paragraph><paragraph>NPR6 – Uniformity: If it holds that {a mathematical formula}[T,D]∈C⊚⊚[T,D] if and only if {a mathematical formula}[T,E]∈C⊚⊚[T,E], then {a mathematical formula}C∩(C⊚⊚[T,D])=C∩(C⊚⊚[T,E]).</paragraph><paragraph>Given a tuple T and two informant agents D and E, if {a mathematical formula}[T,D] is accepted in the revised base whenever {a mathematical formula}[T,E] is accepted in the revised base, then {a mathematical formula}C⊚⊚[T,D] and {a mathematical formula}C⊚⊚[T,E] preserve the same credibility objects.</paragraph><paragraph>NPR7 – Safe retainment: If {a mathematical formula}[(G,H),I]∈C⊚⊚[(G,H),I] then {a mathematical formula}[(D,E),F]∈C⊚⊚[(G,H),I] if and only if {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.</paragraph><paragraph>The credibility objects which prevail after a revision by a credibility object accepted in the revised credibility base, will be the objects that are safe objects before the revision, similarly to [2].</paragraph></section><section label="7.2"><section-title>Construction</section-title><paragraph>This operator is based on the credibility ordering among agents represented as credibility bases. Consider that a credibility base {a mathematical formula}C has to be revised by the credibility object {a mathematical formula}[(A,B),S]. If {a mathematical formula}(A,B) is consistent with {a mathematical formula}Cl(C), i.e., {a mathematical formula}(B,A)∉Cl(C), then an expansion of {a mathematical formula}C will occur. However, if inconsistency arises, i.e., {a mathematical formula}(B,A)∈Cl(C), then the proper credibility base (no other structure is necessary) is used to decide which information prevails. In our approach, {a mathematical formula}[(A,B),S] cannot be accepted when {a mathematical formula}C contains more reliable tuples contradicting {a mathematical formula}(A,B). Thus, an analysis about reliability of tuples is needed. To obtain the reliability of the credibility tuple {a mathematical formula}(B,A), all paths from B to A have to be considered. Since we take a cautious approach, in each path we will consider those tuples whose associated agent identifiers are no more credible than other. Then, to compute the reliability of a credibility tuple, we will use function {a mathematical formula}minC (Definition 11 given in Section 5) and below we will introduce the auxiliary function {a mathematical formula}maxC.</paragraph><paragraph>Given a set P of credibility objects, the following function returns all the credibility objects that are associated with identifiers which are not less credible than other identifier associated with the credibility objects in P.</paragraph><paragraph label="Definition 15">Maximal sources function{a mathematical formula}maxC:C→C, is a function such that for a given credibility base {a mathematical formula}C∈C and {a mathematical formula}P⊆C, {a mathematical formula}maxC(P)={[T,A]:[T,A]∈P and for all [T′,B]∈P,(A,B)∉Cl(C)}.</paragraph><paragraph>Another auxiliary function denoted Sources is introduced next. This function takes a credibility base {a mathematical formula}C and returns the set of agent identifiers which are sources of credibility objects that belong to {a mathematical formula}C.</paragraph><paragraph label="Example 9">Sources functionThe function {a mathematical formula}Sources:C→2A is such that {a mathematical formula}Sources(C)={A: there is T∈A×A and[T,A]∈C}, for a given credibility base {a mathematical formula}C∈C.For the {a mathematical formula}CB in Example 2{a mathematical formula}Sources(CB)={B,F1,F2,F3}.</paragraph><paragraph>Based on a credibility base {a mathematical formula}C, we will define a function {a mathematical formula}Rl((A,B),C) that given a credibility tuple {a mathematical formula}(A,B)∈Cl(C), returns a set of agent identifiers that represent the reliability of {a mathematical formula}(A,B) with respect to {a mathematical formula}C. Recall that the function Sources returns a set of agent identifiers (Definition 16) and that {a mathematical formula}C(A−B) represents the set of all paths from A to B.</paragraph><paragraph label="Definition 17">Reliability functionThe reliability function, {a mathematical formula}Rl:(A×A)×C→2A, is a function such that for a given credibility base {a mathematical formula}C∈C and a credibility tuple {a mathematical formula}(A,B)∈Cl(C):{a mathematical formula}</paragraph><paragraph>Note that the function Rl requires that {a mathematical formula}(A,B) be in {a mathematical formula}Cl(C), and therefore {a mathematical formula}C(A−B)≠∅ (see Remark 2). Observe also that the function {a mathematical formula}maxC can return more than one agent identifier, therefore Rl can return a set of pairwise incomparable agents (see Example 12, Example 13). Below, we show how Rl is used in our non-prioritized operator to analyze the input and decide if the input is rejected or accepted. First, we show how Rl works with our running example.</paragraph><paragraph label="Example 10">Consider the credibility base of agent B given in Example 2, {a mathematical formula}CB={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A1,A2),F1],[(A1,A3),F1],[(A2,A4),B],[(A2,A4),F3],[(A3,A4),F2]}. Suppose that agent B needs to calculate the reliability of the credibility tuple {a mathematical formula}(A1,A4). Next, we show the paths set from {a mathematical formula}A1 to {a mathematical formula}A4 in {a mathematical formula}CB (according to Example 3) and the application of the function {a mathematical formula}minCB to each path in the paths set. {a mathematical formula}CB(A1−A4)={P1,P2,P3}, where:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} Then, {a mathematical formula}maxCB({[(A1,A2),F1],[(A2,A4),B],[(A1,A3),F1]})={[(A1,A2),F1],[(A1,A3),F1]}. From this set, the set containing the agent identifiers is obtained through the function Sources, {a mathematical formula}Sources({[(A1,A2),F1],[(A1,A3),F1]})={F1}. Then, {a mathematical formula}Rl((A1,A4),CB)={F1}.</paragraph><paragraph label="Definition 18">Non-prioritized C-revision using reliabilityLet {a mathematical formula}C be a credibility base in {a mathematical formula}C, and {a mathematical formula}[(A,B),S] a credibility object. Let {a mathematical formula}⊛σ↓ be a prioritized CR-revision operator and ⊕ the CR-expansion operator. The operator “{a mathematical formula}⊚⊚σ↓”, called non-prioritized CR-revision, is defined as follows:{a mathematical formula}</paragraph><paragraph>The first case in Definition 18 states that when no contradiction arises the input is accepted and added (expansion). The second case states that if a contradiction arises ({a mathematical formula}(B,A)∈Cl(C)) then the input will be accepted and added if every agent returned by {a mathematical formula}Rl((B,A),C) is less credible than S. The third case states that the input is rejected when there exists some agent identifier returned by Rl that is incomparable with S or more credible than S.</paragraph><paragraph>The following proposition establishes a relation between this non-prioritized revision operator {a mathematical formula}⊚⊚σ↓ and the postulates presented.</paragraph><paragraph label="Proposition 5">Given{a mathematical formula}C∈C, if “{a mathematical formula}⊚⊚σ↓” is a non-prioritized revision operator using reliability for{a mathematical formula}Cthen “{a mathematical formula}⊚⊚σ↓” satisfies relative success (NPR1), weak success (NPR2), conditional success (NPR3), inclusion (NPR4), soundness (NPR5), uniformity (NPR6), and safe retainment (NPR7).</paragraph><paragraph label="Proof">See Appendix A. □</paragraph><paragraph>Below, we include some examples to show how the non-prioritized operator works in different scenarios. First, our running example is used to show a simple case where Rl returns a singleton.</paragraph><paragraph label="Example 11">Consider the credibility base {a mathematical formula}CB given in Example 10. Suppose first that {a mathematical formula}CB has to be revised by {a mathematical formula}[(A4,A1),B] using “{a mathematical formula}⊚⊚σ↓”. According to Example 10, {a mathematical formula}Rl((A1,A4),CB)={F1}. Since {a mathematical formula}(F1,B)∉Cl(CB), the operator rejects the input according to the third case of the definition of “{a mathematical formula}⊚⊚σ↓”.Consider now that the input is {a mathematical formula}[(A4,A1),F3]. Since {a mathematical formula}Rl((A1,A4),CB)={F1} and {a mathematical formula}(F1,F3)∈Cl(CB), then the input is accepted and {a mathematical formula}CB⊚⊚σ↓[(A4,A1),F3]=CB⊛σ↓[(A4,A1),F3]={[(B,F1),F2],[(F1,F2),F3],[(F2,F3),B],[(A2,A4),F3],[(A3,A4),F2],[(A4,A1),F3]}.</paragraph><paragraph>Next, we introduce two examples where the set returned by Rl contains more than one informant. In Example 12 the input is rejected whereas in Example 13 the input is accepted.</paragraph><paragraph label="Example 12">Consider {a mathematical formula}C={[(D,B),A],[(B,E),H],[(D,E),F],[(A,H),E],[(A,G),B]}, and the input {a mathematical formula}[(E,D),G]. Then, {a mathematical formula}Rl((D,E),C)={A,F}. Since {a mathematical formula}(F,G)∉Cl(C), the operator rejects the input (third case of Definition 18).</paragraph><paragraph label="Example 13">Consider the credibility base of agent D, shown in Fig. 6. {a mathematical formula}CD={[(H,I),F],[(H,L),D],[(H,J),G],[(I,L),G],[(J,L),E],[(J,L),F],[(J,K),D],[(J,K),E],[(K,L),D],[(D,E),G],[(D,F),E],[(E,G),F],[(F,G),D]}.Suppose that agent D receives the credibility object {a mathematical formula}[(L,H),G]. Then, to obtain {a mathematical formula}Rl((H,L),CD) six paths from H to L have to be considered: {a mathematical formula}CD(H−L)={P1,P2,P3,P4,P5,P6} where{a mathematical formula} Thus, {a mathematical formula}maxCD(⋃P∈CD(H−L)minCD(P))={[(H,I),F],[(J,L),E],[(J,L),F]}, and then, {a mathematical formula}Rl((H,L),CD)={E,F} (E and F are incomparable). Since {a mathematical formula}(E,G)∈Cl(CD) and {a mathematical formula}(F,G)∈Cl(CD), then the input is accepted (second case of Definition 18), and {a mathematical formula}CD⊚⊚σ↓[(L,H),G]=CD⊛σ↓[(L,H),G]={[(H,J),G],[(I,L),G],[(J,K),E],[(L,H),G],[(D,E),G],[(D,F),E],[(E,G),F],[(F,G),D]}.</paragraph><paragraph>Following NPR3, in Example 12 the input is not accepted because in the credibility object {a mathematical formula}[(D,E),F] the informant is not less credible than the informant of the input. Nevertheless, in Example 13 the input is accepted because all the withdrawn information has an informant less credible than G.</paragraph><paragraph>Note that operators are defined following the constructive and black box approaches. In the constructive approach a concrete mechanism for change is explicitly defined, and in the black box approach, the properties that an operator should satisfy are specified regardless of how it is actually built [27]. Representation theorems connect the two approaches improving our understanding of the constructions and the postulates. It is important to note that we proved representation theorems just for contraction and prioritized revision because they need the specification of a “selection mechanism” that represents a criteria to define which credibility objects are preserved or discarded. Non-prioritized revision is not fully characterized. The complete characterization is subject of future work.</paragraph></section></section><section label="8"><section-title>Related work</section-title><paragraph>The areas of Trust and Multi-Source Belief Revision (MSBR) have produced research that is relevant to the present work. Still, to the best of our knowledge, the investigation presented here represents a novel contribution combining aspects of both. Next, we will comment on some related works in each of these two areas.</paragraph><paragraph>Different formalisms have been proposed to deal with multi-agent belief revision (MABR) [35], [36], [30], [40] where the overall (global) belief revision of a team of agents is investigated. In contrast to those works, we focused on MSBR in which each agent maintains the consistency of its own belief base. Two other approaches that formalize a kind of MSBR are [10] and [15]. Similarly to our work, they both consider that the credibility of the source affects the reliability of incoming information, and this reliability is used in making decisions. However, these two approaches differ from ours in several important aspects that we discuss below.</paragraph><paragraph>We have identified two types of MSBR: Unitary MSBR and Conjunctive MSBR. Our work is focused on Unitary MSBR, assuming that the epistemic input is a credibility object, i.e., a credibility tuple provided by some informant. There are other works focused in conjunctive Belief Revision; for instance, in [21], [19], [20] the epistemic input is a set of beliefs. In these works, axiomatic representation is proposed where there is no consideration of the origin of every belief. Other forms of change operators that we may identify as conjunctive MSBR are present in the social contraction operators introduced by Booth [7]. The merging operators of Konieczny and Pino Pérez represent another example where multiple sources of information need to be confronted; for instance, in a committee in which not all the participants have the same weight in reaching a decision, it is necessary to weight each belief base to reflect this situation [31].</paragraph><paragraph>In [10], a set of incoming information from a particular source (called scenario) is treated as a whole and not sentence by sentence; therefore, it can be inconsistent. A relation of trustworthiness is introduced over sets of sources and not among single sources. In contrast to our approach, in that work a total order of sources is assumed, and when more than one source provides the same piece of information α, and a single agent gives ¬α, then α will be preferred, that is, the decision is based on majority.</paragraph><paragraph>As we previously observed, using majority in decisions can be very useful in many situations, but can lead to erroneous or non-intuitive results in others. For instance, let us consider Example 14 below.</paragraph><paragraph label="Example 14">Consider the set of agents {a mathematical formula}A={P,F1,F2,F3,M,W1,W2}, where P is a pediatrician, {a mathematical formula}F1, {a mathematical formula}F2, {a mathematical formula}F3 are participants of an internet forum dedicated to comment on children's health, and {a mathematical formula}W1, {a mathematical formula}W2 are two Pediatric sources. Consider now that the credibility base of M is {a mathematical formula}CM={[(F1,P),M],[(F2,P),M],[(F3,P),M],[(W1,W2),F1],[(W1,W2),F2],[(W1,W2),F3]} (see Fig. 7(a)). That is, agent M considers the participants of the internet forum are all less credible than the pediatrician P, and {a mathematical formula}F1, {a mathematical formula}F2, {a mathematical formula}F3 consider that {a mathematical formula}W1 is less credible than {a mathematical formula}W2. Now consider that M receives the credibility object {a mathematical formula}[(W2,W1),P], i.e., the pediatrician informs M that in his opinion {a mathematical formula}W2 is less credible than {a mathematical formula}W1. In an approach based on majority the opinion of {a mathematical formula}F1, {a mathematical formula}F2, {a mathematical formula}F3 will prevail and no change occurs. Nevertheless, in our approach, since it is based on more reliable grounds, the new information will prevail and {a mathematical formula}CM will be revised (see Fig. 7(b)): {a mathematical formula}CM⊚⊚σ↓[(W2,W1),P]={[(F1,P),M],[(F2,P),M],[(F3,P),M],[(W2,W1),P]}.</paragraph><paragraph>In [10], the order in which new information is obtained is not taken in consideration; but, in our approach the order in which beliefs are considered is important. On one hand, if the prioritized operator is used, then the newest information is always accepted. On the other hand, when the non-prioritized revision operator is used, if an agent receives a credibility tuple {a mathematical formula}(A,B) and later receives {a mathematical formula}(B,A) and both have the same reliability, then {a mathematical formula}(B,A) will be rejected.</paragraph><paragraph>In Dragoni et al. [15], additional information is associated to each sentence in a tuple; each tuple contains five elements: 〈Identifier, Sentence, OS, Source, Credibility〉, where OS (Origin Set) is used to record the assumption nodes upon which it really ultimately depends (as derived by a theorem prover). It is clear that their model maintains sentences, whereas our formalism maintains a base of credibility tuples representing a strict partial order among informants. In contrast to their approach, in our model the reliability is not explicitly stored; thus, in our approach when the reliability of some credibility tuple is needed (in the non-prioritized revision process), the reliability function is applied. As shown in Example 15, given a credibility tuple {a mathematical formula}(A,B), its reliability depends on the paths from A to B. Therefore, if one of the credibility objects in these paths changes, the reliability of {a mathematical formula}(A,B) may change.</paragraph><paragraph label="Example 15">Consider a set {a mathematical formula}A={D,E,F,G} where the credibility base of agent D is {a mathematical formula}CD={[(D,E),F],[(E,F),G],[(F,G),E]}. By Definition 17, {a mathematical formula}Rl((D,F),CD)={F}. Now, suppose that D receives the credibility object {a mathematical formula}[(D,E),G]. Now {a mathematical formula}CD={[(D,E),F],[(D,E),G],[(E,F),G],[(F,G),E]} and D has two paths from D to F. Hence {a mathematical formula}Rl((D,F),CD)={G}. Observe that the reliability of {a mathematical formula}(D,F) has increased.</paragraph><paragraph>Dragoni et al. [15] considers that agents detect and store the minimally inconsistent subsets of their knowledge bases in tables, i.e., the nogoods. A good is a subset of the knowledge base that it is consistent (i.e., it is not a superset of a nogood), and if it is augmented with any sentence becomes inconsistent. In contrast with our proposal, they never remove beliefs to avoid a contradiction, they choose which is the preferred good in the knowledge base. That is, they do not propose any contraction or revision operators. Another difference with our approach is that in [15] the order of informants is considered total. It is clear that having a total order represents a strong assumption that even may not be natural in some application domains.</paragraph><paragraph>As in this work, Tamargo et al. [49] have introduced an epistemic model for MSBR that together with sentences considers meta-information representing the credibility of the belief's source. However, in contrast to the present approach, in that article informant agents were ranked using a fixed total order, and the order cannot be modified using incoming information from peers. The approach we have introduced in this paper can be considered as a complement of the mentioned formalism because we have introduced operators handling the dynamics of the strict partial order among agents, making a step forward in the definition of a complete change theory over agents' trust.</paragraph><paragraph>Also, our approach differs from those that use real numbers for representing credibilities. For example, in Benferhat et al. [5], the epistemic state is represented by a possibility distribution which is a mapping from the set of classical interpretations, or worlds, to the real interval {a mathematical formula}[0,1]. Clearly, the use of partially ordered labels to identify the trust level is more general because it gives us the possibility of having some elements that are incomparable; in contrast, when real numbers are used a total order is forced upon the labels.</paragraph><paragraph>In [6], they present a way to revise partial orders, proposing a new definition of faithful assignment that was initially presented by Katsuno and Mendelzon [29]. They also propose an alternate set of postulates characterizing iterated revision operators of partially ordered information, providing a representation theorem for operators complying with these postulates. The paper discusses additional postulates for iterated belief revision ([13], [8]) and proposes two alternate postulates aiming to characterize other types of iterated belief revision. The presentation is completed showing how the results apply to other operators for revising partially ordered information (revision with memory, possibilistic revision and natural belief revision). The main distinction with this research is that in our work we propose an approach to multi-source belief revision where the credibility assigned to informant agents can be revised using a criterion that uses reliability to select which information is eliminated upon revision. Besides that, we introduce a non-prioritized revision operator also based on the reliability of the information.</paragraph><paragraph>In Sabater and Sierra [44], a set of relevant aspects to classify trust models is introduced; they advance the idea that it is possible to classify trust models considering the information sources that they take into account to calculate trust values. Direct experience and witness information are traditional information sources used in computational trust models; there are two types of direct experience, the experience based on the direct interaction with a partner, and the experience based on the observed interaction of other members of the community. Witness information, also called word-of-mouth or indirect information, is the information that comes from other members of the community. Here, we have taken in consideration only two of these aspects: information sources and trust reliability measure; we consider witness information as an information source.</paragraph><paragraph>In [44], it is suggested that a reliable value and its relevance in the final decision making process is as important as the trust value itself. In our approach, we have introduced this type of information through the use of agent identifiers that represent the information sources, avoiding in that way the need of a separate data structure to maintain the measure of reliability.</paragraph><paragraph>Sabater and Sierra, in a previous work [43], in contrast with our proposal, present a model for reputation that takes into account what they call the social dimension and the ontological dimension of reputation. They show how the model relates to other systems and provide initial experimental results about the benefits of using a social view on the modeling of reputation.</paragraph><paragraph>In [47], change operators (expansion, contraction, and prioritized revision) for a credibility order ({a mathematical formula}O) were proposed. Nevertheless, in that work there are some important issues that have not been addressed and that we have solved in the present article. First, in [47] the model does not consider how reliable is the trust and the relevance it deserves in the final decision making process. Here, we have introduced the notion of credibility base. This type of base stores credibility tuples together with their associated information source representing the reliability for each piece of information. Second, in [47] the contraction operator does not specify how the cut function selects the credibility objects being discarded from each path. In the present approach, this was introduced through the use of the reliability of the credibility tuples; thus, the cut function selects the least reliability credibility objects of each path. Finally, in [47] the new information has always priority, situation that can be unrealistic in some scenarios (see [17], [16]). In this article, we have defined a non-prioritized revision operator that uses a reliability criterion to decide if the new information is accepted or rejected. When information comes from different sources, and a preference among sources can be established, then a non-prioritized method could be adequated. In contrast, if an agent always acquires information from the same source, then a prioritized method could be more appropriated.</paragraph><paragraph>In a recent paper [37] the revision of partial pre-orders is considered. There, a partial pre-order representing the prior epistemic state can be revised with another partial pre-order which represents the new input. They propose four different prioritized revision strategies, and show that three of them produce the same revision result. The prioritized revision is recursively conducted on the individual units of partial pre-orders. In contrast to us, reliability values of the incoming information are not considered in the revision process. Since partial pre-orders are revised by a set of units, the revision result depends on the order in which the units from one set are inserted into the other set. Therefore, their revision process requires to produce different extensions, or permutations of the new input, and then to intersect them. In contrast to their approach, our proposal considers a multi-source belief revision setting where the revision process is guided by the credibility of information source and reliability of the stored information. Another difference is that we also propose a non-prioritized revision operator.</paragraph><paragraph>The framework developed in [41], [42] considers the dynamics of trust. The author characterizes trust between two agents A and B, by saying that A trusts B if A is suspicious of the enemies of B. Suspicion is assigned a non negative integer, establishing a complete linear order between agents. Also, Nayak makes the simplifying assumption that the agent A considers the recommendations it receives from other reputable agents to be practically infallible, and A will disregard a recommendation from an unreliable agent. This framework is different from ours in several important points. In our approach, the credibility order among agents is a partial order which allows for the possibility that two agents are unrelated, and, more significatively, in [41], [42] maintains a global linear order whereas in our proposal the order is local to each agent. Furthermore in [41], [42], they disregard information considering only the credibility of the input, whereas in our proposal we consider the complete credibility base of the agent. We do not disregard any information regarding credibility, but instead we keep a credibility base that always obtains the more credible information. Finally, we make no assumption as to how the credibility is assigned, allowing for the modeling of different approaches.</paragraph><paragraph>Other approaches [3], [12] consider a combination of orders. However, our approach is focused on a multi-agent approach where every agent maintains its order and decides its preference individually.</paragraph><paragraph>Screened revision [39] is a way of effecting non prioritized revision where there is a pre-processing of the new information. In general terms, screened revision leads to one of two cases: (i) the screened revision results in a prioritized AGM revision if the new information is consistent with some set A which is a subset of the original set; or, (ii) the original set of beliefs remains unaltered. Makinson presented different possible constructions for screened revision without representation theorems. Hansson et al. generalized in [28] the idea of screened revision considering a set of credible sentences {a mathematical formula}C. This work presents different properties for {a mathematical formula}C, different constructions, and their respective representation theorems in epistemic models based on belief sets or possible worlds. Fermé et al. [18] extended the above proposal to an epistemic model based on belief bases. Our work, as the above mentioned approaches, defines a non prioritized revision operator on credibility bases making use of a pre-processing of the new information. However, unlike those proposals, it produces a new credibility base that can be changed (expanded, contracted, revised) since the new order is reconstructed. That is, our model is suitable for iteration.</paragraph><paragraph>Finally, in an approach that can be considered as relevant, Cholvy [11] studies the evaluation of a piece of information when successively reported by several sources. The paper describes a model for characterizing the plausibility of information when reported by several successive sources; this model is based on Dempster–Shafer's theory where the reported information is attached a plausibility degree. This value depends on the degrees to which the sources are correct and the degrees to which they are wrong. This approach is different from ours in the theoretical level and in the formal tools used to model the evaluation of information. A consequence of attaching a plausibility degree to information is that the information becomes arranged as a total order; in contrast, we have allowed for the possibility that information could not be compared. From this point onwards, these two approaches become different. Furthermore, we have characterized the problem in the area of belief revision producing a formalism that follows the methodology of this area.</paragraph></section><section label="9"><section-title>Conclusions and future work</section-title><paragraph>The importance of having trust models has been emphasized in the literature. As stated in [44], two elements have contributed to substantially increase the interest on trust in this area: the multi-agent system paradigm and the spectacular evolution of e-commerce. The study of trust has many applications in Information and Communication Technologies. For instance, trust has been recognized as a key factor for successful electronic commerce adoption. These systems are used by intelligent software agents as a mechanism to search for trustworthy exchange partners and as an incentive in decision-making about whether or not to honor contracts. Our proposal can be applied to any system requiring that trust or credibility of informants be taken into account.</paragraph><paragraph>In this work, we have introduced a trust model for a multi-agent setting. In this model agents can share information representing trust assigned to its peers (called witness information in the literature). We have defined an epistemic model where credibility objects include not only trust information but also the informant source. These objects are maintained in a credibility base which represents a strict partial order among informant agents together with the source of the information. Thus, upon arrival of new information regarding the credibility of its peers, an agent will be capable of revising this strict partial order, and in this manner change the trust in its peers accordingly.</paragraph><paragraph>In this paper we have introduced four operators for credibility bases: expansion, contraction, prioritized and non-prioritized revision. The contraction operator uses the reliability stored in credibility objects for deciding which information prevails. Then, based on our contraction and expansion operators, a prioritized revision was defined using Levi identity. The non-prioritized revision operator uses the reliability of the input and the information stored in the credibility base in order to decide if the input is accepted or rejected. These operators provide the capability of dynamically modifying the credibility of informants to reflect a new perception of the informant's trust, or when necessary to extend the set of informants by admitting the arrival of new informant agents. These four change operators were defined through construction and postulates.</paragraph><paragraph>Note that the operators were defined following the constructive and black box approaches. In the constructive approach, a concrete mechanism for change was explicitly defined, and in the black box approach, the properties that the operator should satisfy were specified regardless of how the operator will be built [27]. Representation theorems connected the two approaches improving our understanding of the constructions and the postulates. It is important to note that we have proved representation theorems only for contraction and prioritized revision because they need the specification of a “selection mechanism” that represents a criterion used to define which credibility objects are preserved or discarded. Non-prioritized revision is not fully characterized, and its complete characterization is subject of future work.</paragraph><paragraph>We will also consider the broadening of the results obtained here to deal with different contexts. In [44] they offer the following example to show that trust is context dependent: “if we trust a doctor when she is recommending a medicine it does not mean we have to trust her when she is suggesting a bottle of wine”; here we have considered trust in a unique context. Our proposed model was designed to associate a single trust value per agent in the multi-agent system without taking into account the context. Since this last aspect has received little attention in the literature, as future research we propose to extend the results obtained here toward a multi-context model that will have the mechanisms to deal with several contexts simultaneously. Another research line we consider as future work is to extend our operators assuming that the epistemic input is a set of credibility objects {a mathematical formula}{[T1,A1],…,[Tk,Ak]} where {a mathematical formula}Ti is a credibility tuple and {a mathematical formula}Ai is the informant that provides {a mathematical formula}Ti, for every {a mathematical formula}1⩽i⩽k.</paragraph><paragraph>In Definition 3 we have established the restriction that in a credibility object {a mathematical formula}[T,S] the source S cannot appear in any place in T. The motivation for that decision is illustrated by the following example. Let {a mathematical formula}CQ={[(B,A),B]} be the credibility base of an agent Q, that is, agent B regards agent A as more credible than itself. Now consider the revision of {a mathematical formula}CQ by the credibility object {a mathematical formula}[(A,B),A] using the non-prioritized revision operator. The new information expresses that, according to agent A, agent B is more credible than itself. Using the information contained in {a mathematical formula}CQ the new information is accepted and the revised base should be {a mathematical formula}CQ={[(A,B),A]}. This opens the question over if either the old information or the new information should be used for deciding acceptance or rejection.</paragraph><paragraph>However, from a positive point of view, there are particular situations where some interesting examples can be represented if the restriction is lifted. For instance, consider a situation where an agent A interacts with his doctor D. It is natural that D considers himself less credible than a specialist S in some medical topic; consequently, D can inform A the credibility object {a mathematical formula}[(D,S),D]. Consider a situation involving two researchers A and B, and that A has read several articles written by B on a certain topic. Since A regards B as a specialist in the subject in question, he believes that he is less credible than B, i.e., {a mathematical formula}CA={[(A,B),A]}, also A and B are in a situation where they interact with each other. Because B knows that A is well read, he knows that A has read not only his own publications but also is acquainted with other approaches; therefore, B considers that A is more credible than himself in that topic. Then, it is natural that now A accepts himself as more credible than B. If A receives the credibility object {a mathematical formula}[(B,A),B] then according to the non-prioritized operator the agent would accept the new information, and hence, {a mathematical formula}CA={[(B,A),B]}. The discussion above, clearly motivates further research focussed in operators that are able to handle this more general situation.</paragraph><paragraph>Finally, it is interesting to observe the natural phenomenon of retransmission of information is related to our formalism. This was previously considered in the work presented in [33], [48] using a different context. The research reported there can be adapted and expanded using the framework presented here. We will also explore the interesting issues related to this particular action in our future work.</paragraph><section-title>Acknowledgements</section-title></section></content><acknowledgements><paragraph>We would like to thank the anonymous referee for their valuable comments on an earlier version of this paper. This work was partially supported by PGI-UNS (grants 24/N035, 24/N030) and PIP-CONICET (grant 112-201101-01000).</paragraph></acknowledgements><appendices><section label="Appendix A"><paragraph label="Proposition 3">Let{a mathematical formula}D,E,F,G∈A,{a mathematical formula}C∈C. If for all subsets{a mathematical formula}C′of{a mathematical formula}C,{a mathematical formula}(D,E)∈Cl(C′)if and only if{a mathematical formula}(F,G)∈Cl(C′)then{a mathematical formula}(D,E)=(F,G).</paragraph><paragraph label="Proof">By reductio ad absurdum. Suppose that {a mathematical formula}(D,E)≠(F,G). Consider {a mathematical formula}C′={[(D,E),X]} for some {a mathematical formula}X∈A. Therefore, {a mathematical formula}(D,E)∈Cl(C′) and {a mathematical formula}(F,G)∉Cl(C′) showing that the supposition is untenable.Before giving the proofs of the theorems, we introduce an auxiliary result that will be used in the proof of Theorem 1 and Theorem 2. This proposition is adapted from a property proposed in [27]. □</paragraph><paragraph label="Proposition 6">Let{a mathematical formula}D,E,F,G∈A,{a mathematical formula}C∈C,{a mathematical formula}C(D−E)the paths set from D to E in{a mathematical formula}Cand{a mathematical formula}C(F−G)the paths set from F to G in{a mathematical formula}C.{a mathematical formula}C(D−E)=C(F−G)if and only if for all subsets{a mathematical formula}C′of{a mathematical formula}C:{a mathematical formula}(D,E)∈Cl(C′)if and only if{a mathematical formula}(F,G)∈Cl(C′).</paragraph><paragraph label="Proof">By reductio ad absurdum.(⇒) Suppose that there is some subset {a mathematical formula}C′ of {a mathematical formula}C such that {a mathematical formula}(D,E)∈Cl(C′) and {a mathematical formula}(F,G)∉Cl(C′). Then, there is some path P of {a mathematical formula}C(D−E) such that {a mathematical formula}P⊆C′. Since {a mathematical formula}P⊆C′ and {a mathematical formula}(F,G)∉Cl(C′), we have {a mathematical formula}(F,G)∉Cl(P), so that {a mathematical formula}P∉C(F−G). Then {a mathematical formula}P∈C(D−E) and {a mathematical formula}P∉C(F−G) contrary to {a mathematical formula}C(D−E)=C(F−G).(⇐) Suppose that {a mathematical formula}C(D−E)≠C(F−G). We may assume that there is some path {a mathematical formula}P∈C(D−E) such that {a mathematical formula}P∉C(F−G). There are two cases:</paragraph><list><list-item label="–">{a mathematical formula}(F,G)∉Cl(P): then we have {a mathematical formula}(D,E)∈Cl(P) and {a mathematical formula}(F,G)∉Cl(P), showing that the conditions of the proposition are not satisfied.</list-item><list-item label="–">{a mathematical formula}(F,G)∈Cl(P): then it follows from {a mathematical formula}P∉C(F−G) that there is some {a mathematical formula}P′ such that {a mathematical formula}P′⊂P and {a mathematical formula}(F,G)∈Cl(P′). We then have {a mathematical formula}(F,G)∈Cl(P′) and {a mathematical formula}(D,E)∉Cl(P′), showing that the conditions of the proposition are not satisfied. □</list-item></list><paragraph label="Theorem 1">Given{a mathematical formula}C∈C, “{a mathematical formula}⊖σ↓” is a C-contraction using reliability for{a mathematical formula}Cif and only if it satisfies success (C1), inclusion (C2), and safe retainment (C3).</paragraph><paragraph label="Proof">• Postulates to construction. We need to show that if an operator (−) satisfies the enumerated postulates, then it is possible to build an operator in the way specified in the theorem ({a mathematical formula}⊖σ↓).<list>Let “{a mathematical formula}σ↓” be a function such that, for every credibility base {a mathematical formula}C∈C and for every tuple {a mathematical formula}(A,B) holds that {a mathematical formula}σ↓(C(A−B))=C∖C−(A,B).1. “</list><paragraph>{a mathematical formula}σ↓” is a well defined function.“{a mathematical formula}σ↓” is defined over the whole domain. Let {a mathematical formula}(D,E) and {a mathematical formula}(F,G) be such that {a mathematical formula}C(D−E)=C(F−G). We need to show {a mathematical formula}σ↓(C(D−E))=σ↓(C(F−G)). It follows from {a mathematical formula}C(D−E)=C(F−G), by Proposition 6, for all subsets {a mathematical formula}C′ of {a mathematical formula}C, {a mathematical formula}(D,E)∈Cl(C′) iff {a mathematical formula}(F,G)∈Cl(C′). Thus, by Proposition 3, {a mathematical formula}(D,E)=(F,G) and {a mathematical formula}C−(D,E)=C−(F,G). Then, following (i), {a mathematical formula}σ↓(C(D−E))=σ↓(C(F−G)).2. {a mathematical formula}σ↓(C(D−E))⊆⋃(C(D−E)).Let {a mathematical formula}T2=(D,E) and {a mathematical formula}[T1,H]∈σ↓(C(D−E)). Following (i), {a mathematical formula}[T1,H]∈C∖C−T2. Thus, {a mathematical formula}[T1,H]∈C and {a mathematical formula}[T1,H]∉C−T2. It follows by safe retainment that {a mathematical formula}[T1,H] is not a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C. Then, there is some path in {a mathematical formula}C(D−E) that contains {a mathematical formula}[T1,H]. Hence, {a mathematical formula}[T1,H]∈⋃(C(D−E)).3. For each {a mathematical formula}P∈C(D−E), {a mathematical formula}P∩σ↓(C(D−E))≠∅.Let {a mathematical formula}∅≠P∈C(D−E), we need to show that {a mathematical formula}P∩σ↓(C(D−E))≠∅. We should prove that, there exists {a mathematical formula}[T1,H]∈P such that {a mathematical formula}[T1,H]∈σ↓(C(D−E)). Suppose {a mathematical formula}T2=(D,E), by success, {a mathematical formula}T2∉Cl(C−T2). Since {a mathematical formula}P≠∅ then {a mathematical formula}T2∈Cl(P) and {a mathematical formula}P⊈C−T2; i.e., there is some {a mathematical formula}[T1,H] such that {a mathematical formula}[T1,H]∈P and {a mathematical formula}[T1,H]∉C−T2. Since {a mathematical formula}P⊆C it follows that {a mathematical formula}[T1,H]∈(C∖C−T2); i.e., by (i) {a mathematical formula}[T1,H]∈σ↓(C(D−E)). Therefore, {a mathematical formula}P∩σ↓(C(D−E))≠∅.4. If {a mathematical formula}[T1,F]∈σ↓(C(D−E)) then {a mathematical formula}∃P∈C(D−E) such that {a mathematical formula}[T1,F]∈P, and for all {a mathematical formula}[T2,G]∈P, {a mathematical formula}(G,F)∉Cl(C).Let {a mathematical formula}T2=(D,E) and suppose that {a mathematical formula}[T1,F]∈σ↓(C(D−E)). Then, by (i), {a mathematical formula}[T1,F]∈C∖C−T2. Thus, {a mathematical formula}[T1,F]∈C and {a mathematical formula}[T1,F]∉C−T2. It follows by safe retainment that {a mathematical formula}[T1,F] is not a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C. Then, there is some path P in {a mathematical formula}C(D−E) that contains {a mathematical formula}[T1,F] and for all {a mathematical formula}[T3,G]∈P, {a mathematical formula}(G,F)∉Cl(C).Proof of part B. “{a mathematical formula}⊖σ↓” is equal to “−”, that is, {a mathematical formula}C⊖σ↓(D,E)=C−(D,E).Let “{a mathematical formula}⊖σ↓” a CR-contraction operator defined as {a mathematical formula}C⊖σ↓(D,E)=C∖σ↓(C(D−E)) and {a mathematical formula}σ↓ defined as in (i).(⊇) Let {a mathematical formula}[T1,H]∈C−(D,E). It follows by inclusion that {a mathematical formula}C−(D,E)⊆C and {a mathematical formula}[T1,H]∈C. It follows from {a mathematical formula}[T1,H]∈C−(D,E) and {a mathematical formula}[T1,H]∈C that {a mathematical formula}[T1,H]∉(C∖C−(D,E)). Thus, by (i), {a mathematical formula}[T1,H]∉σ↓(C(D−E)). Hence, {a mathematical formula}[T1,H]∈C⊖σ↓(D,E).(⊆) Let {a mathematical formula}[T1,H]∈C⊖σ↓(D,E). By definition {a mathematical formula}[T1,H]∈C∖σ↓(C(D−E)). Then, {a mathematical formula}[T1,H]∈C and {a mathematical formula}[T1,H]∉σ↓(C(D−E)). Thus, by (i), {a mathematical formula}[T1,H]∉C∖C−(D,E). Hence, {a mathematical formula}[T1,H]∈C−(D,E).• Construction to postulates. Let {a mathematical formula}⊖σ↓ be a C-contraction using reliability for {a mathematical formula}C. We need to show that it satisfies the three conditions of the theorem.(C1) Success:{a mathematical formula}(D,E)∉Cl(C⊖σ↓(D,E)).Proof. Suppose to the contrary that {a mathematical formula}(D,E)∈Cl(C⊖σ↓(D,E)). There is then a path {a mathematical formula}P∈C(D−E) such that {a mathematical formula}P⊆C⊖σ↓(D,E). By Remark 1, {a mathematical formula}C is irreflexive and then {a mathematical formula}D≠E. Therefore, {a mathematical formula}P≠∅. By clause (2) of Definition 10, there is some {a mathematical formula}[T1,F]∈P such that {a mathematical formula}[T1,F]∈σ↓(C(D−E)). By Definition 13, {a mathematical formula}[T1,F]∉(C⊖σ↓(D,E)), contrary to {a mathematical formula}[T1,F]∈P with {a mathematical formula}P⊆C⊖σ↓(D,E).(C2) Inclusion:{a mathematical formula}C⊖σ↓(D,E)⊆C.Proof. Straightforward by definition.(C3) Safe retainment: {a mathematical formula}[T1,D]∈C⊖σ↓T2 if and only if {a mathematical formula}[T1,D] is a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C.Proof.(⇒) Suppose that {a mathematical formula}[T1,D]∈C⊖σ↓T2 with {a mathematical formula}T2=(E,F). Following Definition 13, {a mathematical formula}[T1,D]∈C∖σ↓(C(E−F)) and {a mathematical formula}[T1,D]∉σ↓(C(E−F)). Then, by Definition 12, for every path P from E to F if {a mathematical formula}[T1,D]∈P then {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,D)∈Cl(C). Thus, {a mathematical formula}[T1,D] is a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C.(⇐) Suppose that {a mathematical formula}[T1,D] is a safe element with respect to {a mathematical formula}T2 in {a mathematical formula}C with {a mathematical formula}T2=(E,F). Then, for every path {a mathematical formula}P∈C(E−F) either {a mathematical formula}[T1,D]∉P, or {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,D)∈Cl(C). Thus, following Definition 12, {a mathematical formula}[T1,D]∉σ↓(C(E−F)). Hence, {a mathematical formula}[T1,D]∈C∖σ↓(C(E−F)) and by Definition 13{a mathematical formula}[T1,D]∈C⊖σ↓T2. □</paragraph></paragraph><paragraph label="Theorem 2">Given{a mathematical formula}C∈C, “{a mathematical formula}⊛σ↓” is a prioritized revision using reliability for{a mathematical formula}Cif and only if it satisfies success (PR1), inclusion (PR2), soundness (PR3), uniformity (PR4), and safe retainment (PR5).</paragraph><paragraph label="Proof">• Postulates to construction. We need to show that if an operator (⁎) satisfies the enumerated postulates, then it is possible to build an operator in the way specified in the theorem ({a mathematical formula}⊛σ↓).<list>Let “{a mathematical formula}σ↓” be a function such that for every credibility base {a mathematical formula}C∈C and for every tuple {a mathematical formula}(D,E) holds {a mathematical formula}σ↓(C(E−D))=C∖C⁎[(D,E),F].1. “</list><paragraph>{a mathematical formula}σ↓” is a well defined function.“{a mathematical formula}σ↓” is defined over the whole domain. Let {a mathematical formula}(E,D) and {a mathematical formula}(G,F) be such that {a mathematical formula}C(E−D)=C(G−F). We need to show {a mathematical formula}σ↓(C(E−D))=σ↓(C(G−F)). It follows from {a mathematical formula}C(E−D)=C(G−F), by Proposition 6, for all subsets {a mathematical formula}C′ of {a mathematical formula}C, {a mathematical formula}(E,D)∈Cl(C′) if and only if {a mathematical formula}(G,F)∈Cl(C′). Then, by Proposition 3, {a mathematical formula}(E,D)=(G,F). Thus, by uniformity, {a mathematical formula}C∩(C⁎[(D,E),H])=C∩(C⁎[(F,G),I]). Then, {a mathematical formula}C∖(C⁎[(D,E),H])=C∖(C⁎[(F,G),I]). Therefore, by (ii), {a mathematical formula}σ↓(C(E−D))=σ↓(C(G−F)).2. {a mathematical formula}σ↓(C(E−D))⊆⋃(C(E−D)).Let {a mathematical formula}[(F,G),H]∈σ↓(C(E−D)). Following (ii), {a mathematical formula}[(F,G),H]∈C∖C⁎[(D,E),I]. Thus, {a mathematical formula}[(F,G),H]∈C and {a mathematical formula}[(F,G),H]∉C⁎[(D,E),I]. It follows by safe retainment that {a mathematical formula}[(F,G),H] is not a safe element with respect to {a mathematical formula}(E,D) in {a mathematical formula}C. Then, there is some path in {a mathematical formula}C(E−D) that contains {a mathematical formula}[(F,G),H]. Hence, {a mathematical formula}[(F,G),H]∈⋃(C(E−D)).3. For each {a mathematical formula}P∈C(E−D), {a mathematical formula}P∩σ↓(C(E−D))≠∅.Let {a mathematical formula}∅≠P∈C(E−D), we need to show that {a mathematical formula}P∩σ↓(C(E−D))≠∅. We should prove that, there exists {a mathematical formula}[T1,G]∈P such that {a mathematical formula}[T1,G]∈σ↓(C(E−D)). Suppose {a mathematical formula}T2=(D,E). Since we have assumed that {a mathematical formula}C is sound, by soundness, {a mathematical formula}C⁎[T2,F] is a sound credibility base. Since {a mathematical formula}P∪{[T2,F]} is not sound then {a mathematical formula}P⊈C⁎[T2,F] by success. This means that there is some {a mathematical formula}[T1,G]∈P and {a mathematical formula}[T1,G]∉C⁎[T2,F]. Since {a mathematical formula}P⊆C it follows that {a mathematical formula}[T1,G]∈(C∖C⁎[T2,F]); i.e., by (ii) {a mathematical formula}[T1,G]∈σ↓(C(E−D)). Therefore, {a mathematical formula}P∩σ↓(C(E−D))≠∅.4. If {a mathematical formula}[T1,H]∈σ↓(C(E−D)) then {a mathematical formula}∃P∈C(D−E) such that {a mathematical formula}[T1,H]∈P, and for all {a mathematical formula}[T2,I]∈P, {a mathematical formula}(I,H)∉Cl(C).Suppose that {a mathematical formula}[(F,G),H]∈σ↓(C(E−D)). Then, by (ii), {a mathematical formula}[(F,G),H]∈(C∖C⁎[(D,E),L]). Thus, {a mathematical formula}[(F,G),H]∈C and {a mathematical formula}[(F,G),H]∉C⁎[(D,E),L]. It follows by safe retainment that {a mathematical formula}[(F,G),H] is not a safe element with respect to {a mathematical formula}(E,D) in {a mathematical formula}C. Then, there is some path P in {a mathematical formula}C(E−D) that contains {a mathematical formula}[(F,G),H] and for all {a mathematical formula}[(J,K),I]∈P, {a mathematical formula}(I,H)∉Cl(C).Part B.“{a mathematical formula}⊛σ↓” is equal to “⁎”, that is, {a mathematical formula}C⊛σ↓[(D,E),H]=C⁎[(D,E),H].Let “{a mathematical formula}⊛σ↓” a CR-revision operator defined as {a mathematical formula}C⊛σ↓[(D,E),H]=(C∖σ↓(C(E−D)))∪{[(D,E),H]} and {a mathematical formula}σ↓ defined as in (ii).(⊇) Let {a mathematical formula}[(F,G),I]∈C⁎[(D,E),H]. It follows by inclusion that {a mathematical formula}C⁎[(D,E),H]⊆C∪{[(D,E),H]} and {a mathematical formula}[(F,G),I]∈C∪{[(D,E),H]}. Then, {a mathematical formula}[(F,G),I]∈C. It follows from {a mathematical formula}[(F,G),I]∈C⁎[(D,E),H] and {a mathematical formula}[(F,G),I]∈C that {a mathematical formula}[(F,G),I]∉(C∖C⁎[(D,E),H]). Thus, by (ii), {a mathematical formula}[(F,G),I]∉σ↓(C(E−D)). Hence, {a mathematical formula}[(F,G),I]∈C⊛σ↓[(D,E),H].(⊆) Let {a mathematical formula}[(F,G),I]∈C⊛σ↓[(D,E),H]. By definition, {a mathematical formula}C⊛σ↓[(D,E),H]⊆C∪{[(D,E),H]} and {a mathematical formula}[(F,G),I]∈C∪{[(D,E),H]}. Then, {a mathematical formula}[(F,G),I]∈C. It follows from definition that {a mathematical formula}[(F,G),I]∈C∖σ↓(C(E−D)). Then, {a mathematical formula}[(F,G),I]∈C and {a mathematical formula}[(F,G),I]∉σ↓(C(E−D)). Thus, by (ii), {a mathematical formula}[(F,G),I]∉C∖C⁎[(D,E),H]. Hence, {a mathematical formula}[(F,G),I]∈C⁎[(D,E),H]. □• Construction to postulates. Let {a mathematical formula}⊛σ↓ be a prioritized C-revision using reliability for {a mathematical formula}C. We need to show that it satisfies the five conditions of the theorem.(PR1) Success:{a mathematical formula}[T,D]∈C⊛σ↓[T,D].Proof. Straightforward by definition.(PR2) Inclusion:{a mathematical formula}C⊛σ↓[T,D]⊆C∪{[T,D]}.Proof. Straightforward by definition.(PR3) Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C⊛σ↓[T,D] is sound.Proof. Straightforward by definition.(PR4) Uniformity:{a mathematical formula}C∩(C⊛σ↓[T,D])=C∩(C⊛σ↓[T,E]).Proof. Suppose to the contrary that {a mathematical formula}C∩(C⊛σ↓[(F,G),D])≠C∩(C⊛σ↓[(F,G),E]). Then, suppose that {a mathematical formula}[(H,I),J]∈C∩(C⊛σ↓[(F,G),D]). Thus, {a mathematical formula}[(H,I),J]∈C and {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),D]. Following Definition 14, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),D]. Then, by Definition 9, {a mathematical formula}[(H,I),J]∈C⊖σ↓(G,F). Thus, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))∪[(F,G),E], and by Definition 9, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),E]. Then, by Definition 14, {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),E], contrary to {a mathematical formula}[(H,I),J]∈C∩(C⊛σ↓[(F,G),D]) with {a mathematical formula}C∩(C⊛σ↓[(F,G),D])≠C∩(C⊛σ↓[(F,G),E]).(PR5) Safe retainment: {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I] if and only if {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.Proof.(⇒) Suppose that {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I].Following Definition 14, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Thus, by Definition 9, {a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Then, following Definition 13, {a mathematical formula}[(D,E),F]∈C∖σ↓(C(H−G)) and {a mathematical formula}[(D,E),F]∉σ↓(C(H−G)). Then, by Definition 12, for every path P from H to G if {a mathematical formula}[(D,E),F]∈P then {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,F)∈Cl(C). Thus, {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.(⇐) Suppose that {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C. Then, for every path {a mathematical formula}P∈C(H−G) either {a mathematical formula}[(D,E),F]∉P, or {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,F)∈Cl(C). Thus, following Definition 12, {a mathematical formula}[(D,E),F]∉σ↓(C(H−G)). Then, {a mathematical formula}[(D,E),F]∈C∖σ↓(C(H−G)) and by Definition 13{a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Following Definition 9, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Hence, by Definition 14, {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I]. □</paragraph></paragraph><paragraph label="Proposition 4">If “⊕” satisfies E1, E2, E3, E4, E5 and E6, and “{a mathematical formula}⊖σ↓” satisfies C1, C2 and C3, then “{a mathematical formula}⊛σ↓” satisfies PR1, PR2, PR3, PR4, and PR5.</paragraph><paragraph label="Proof">Let “{a mathematical formula}⊛σ↓” be a prioritized C-revision using reliability for {a mathematical formula}C, defined as {a mathematical formula}C⊛σ↓[(D,E),H]=(C⊖σ↓(E,D))⊕[(D,E),H]. We need to show that it satisfies {a mathematical formula}PR1,…,PR5 from the postulates of C-expansion using reliability and from the postulates of C-contraction using reliability.(PR1) Success:{a mathematical formula}[T,D]∈C⊛σ↓[T,D].Proof. Let {a mathematical formula}T=(E,F). By Definition 14, {a mathematical formula}C⊛σ↓[(E,F),D]=(C⊖σ↓(F,E))⊕[(E,F),D]. Then, following C1, {a mathematical formula}(F,E)∉Cl(C⊖σ↓(F,E)). Hence, by E2, {a mathematical formula}[(E,F),D]∈(C⊖σ↓(F,E))⊕[(E,F),D]. Therefore, {a mathematical formula}[T,D]∈C⊛σ↓[T,D].(PR2) Inclusion:{a mathematical formula}C⊛σ↓[T,H]⊆C∪{[T,H]}.Proof. Let {a mathematical formula}T=(D,E). It follows from C2 that {a mathematical formula}C⊖σ↓(E,D)⊆C. Then, {a mathematical formula}(C⊖σ↓(E,D))∪{[(D,E),H]}⊆C∪{[(D,E),H]}. Thus, by C1 and Definition 9{a mathematical formula}(C⊖σ↓(E,D))⊕[(D,E),H]⊆C∪{[(D,E),H]}. Hence, by Definition 14, {a mathematical formula}C⊛σ↓[(D,E),H]⊆C∪{[(D,E),H]}.(PR3) Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C⊛σ↓[(D,E),H] is sound.Proof. By Definition 14, {a mathematical formula}C⊛σ↓[(D,E),H]=(C⊖σ↓(E,D))⊕[(D,E),H]. From E5, C1, C2 and Proposition 2 it follows that {a mathematical formula}C⊛σ↓[(D,E),H] is sound.(PR4) Uniformity:{a mathematical formula}C∩(C⊛σ↓[T,D])=C∩(C⊛σ↓[T,E]).Proof. Suppose to the contrary that {a mathematical formula}C∩(C⊛σ↓[(F,G),D])≠C∩(C⊛σ↓[(F,G),E]). Then, suppose that {a mathematical formula}[(H,I),J]∈C∩(C⊛σ↓[(F,G),D]). Thus, {a mathematical formula}[(H,I),J]∈C and {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),D]. Following Definition 14, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),D]. Then, by E3 and E6, {a mathematical formula}[(H,I),J]∈C⊖σ↓(G,F). Thus, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))∪[(F,G),E], and by C1 and E2, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),E]. Then, by Definition 14, {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),E], contrary to {a mathematical formula}[(H,I),J]∈C∩(C⊛σ↓[(F,G),D]) with {a mathematical formula}C∩(C⊛σ↓[(F,G),D])≠C∩(C⊛σ↓[(F,G),E]).(PR5) Safe retainment: {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I] if and only if {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.Proof.(⇒) Suppose that {a mathematical formula}[(D,E),F]≠[(G,H),I] and {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I]. Following Definition 14, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Then, by E3 and E6, {a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Thus, by C3, {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.(⇐) {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C. Then, by C3, {a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Thus, by E3, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Hence, following Definition 14, {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I]. □</paragraph><paragraph label="Proposition 5">Given{a mathematical formula}C∈C, if “{a mathematical formula}⊚⊚σ↓” is a non-prioritized revision using reliability for{a mathematical formula}Cthen “{a mathematical formula}⊚⊚σ↓” satisfies relative success (NPR1), weak success (NPR2), conditional success (NPR3), inclusion (NPR4), soundness (NPR5), uniformity (NPR6), and safe retainment (NPR7).</paragraph><paragraph label="Proof">Let {a mathematical formula}⊚⊚σ↓ be a non-prioritized revision using reliability for {a mathematical formula}C. We need to show that it satisfies the seven conditions of the proposition.(NPR1) Relative success: {a mathematical formula}C⊚⊚σ↓[T,S]=C or {a mathematical formula}[T,S]∈C⊚⊚σ↓[T,S].Proof. Straightforward by definition.(NPR2) Weak success: if {a mathematical formula}(B,A)∉Cl(C) then {a mathematical formula}[(A,B),S]∈C⊚⊚σ↓[(A,B),S].Proof. Straightforward by definition.(NPR3) Conditional success:{a mathematical formula}[(A,B),S]∈C⊚⊚σ↓[(A,B),S] when for all objects {a mathematical formula}[(D,E),F] that are no safe with respect to {a mathematical formula}(B,A) in {a mathematical formula}C it holds that {a mathematical formula}(F,S)∈Cl(C).Proof. Let {a mathematical formula}[(A,B),S] be a credibility object and suppose that for all objects {a mathematical formula}[(D,E),F] that are not safe with respect to {a mathematical formula}(B,A) in {a mathematical formula}C it holds that {a mathematical formula}(F,S)∈Cl(C). Then, for every path {a mathematical formula}P∈C(B−A) with {a mathematical formula}[(D,E),F]∈P, it does not hold that there is {a mathematical formula}[(I,J),K]∈P with {a mathematical formula}(K,F)∈Cl(C); thus, by Definition 11{a mathematical formula}[(D,E),F]∈minC(P). Then, for all objects {a mathematical formula}[T,Y]∈⋃P∈C(B−A)minC(P) it holds that {a mathematical formula}(Y,S)∈Cl(C); thus, following Definition 15, Definition 16, Definition 17, for all {a mathematical formula}X∈Rl((B,A),C), {a mathematical formula}(X,S)∈Cl(C). Then, by Definition 18, {a mathematical formula}C⊚⊚σ↓[(A,B),S]=C⊛σ↓[(A,B),S]. Hence, by Definition 14, {a mathematical formula}[(A,B),S]∈C⊚⊚σ↓[(A,B),S].(NPR4) Inclusion:{a mathematical formula}C⊚⊚σ↓[T,D]⊆C∪{[T,D]}.Proof. Straightforward by definition.(NPR5) Soundness: if {a mathematical formula}C is sound then {a mathematical formula}C⊚⊚σ↓[T,D] is sound.Proof. Straightforward by definition.(NPR6) Uniformity: If it holds that {a mathematical formula}[T,D]∈C⊚⊚σ↓[T,D] if and only if {a mathematical formula}[T,E]∈C⊚⊚σ↓[T,E], then {a mathematical formula}C∩(C⊚⊚σ↓[T,D])=C∩(C⊚⊚σ↓[T,E]).Proof. Suppose to the contrary that {a mathematical formula}[(F,G),D]∈C⊚⊚σ↓[(F,G),D] iff {a mathematical formula}[(F,G),E]∈C⊚⊚σ↓[(F,G),E] and suppose that {a mathematical formula}C∩(C⊚⊚σ↓[(F,G),D])≠C∩(C⊚⊚σ↓[(F,G),E]). Then, suppose that {a mathematical formula}[(H,I),J]∈C∩(C⊚⊚σ↓[(F,G),D]). Thus, {a mathematical formula}[(H,I),J]∈C and {a mathematical formula}[(H,I),J]∈C⊚⊚σ↓[(F,G),D]. Since {a mathematical formula}[(H,I),J]∈C⊚⊚σ↓[(F,G),D], by Definition 18, {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),D]. Following Definition 14, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),D]. Then, by Definition 9, {a mathematical formula}[(H,I),J]∈C⊖σ↓(G,F). Thus, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))∪[(F,G),E], and by Definition 9, {a mathematical formula}[(H,I),J]∈(C⊖σ↓(G,F))⊕[(F,G),E]. By Definition 14, {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),E]. Since {a mathematical formula}[(F,G),E]∈C⊚⊚σ↓[(F,G),E], by Definition 18, {a mathematical formula}[(H,I),J]∈C⊛σ↓[(F,G),E] contrary to {a mathematical formula}[(H,I),J]∈C∩(C⊛σ↓[(F,G),D]) with {a mathematical formula}C∩(C⊛σ↓[(F,G),D])≠C∩(C⊛σ↓[(F,G),E]).(NPR7) Safe retainment: If {a mathematical formula}[(G,H),I]∈C⊚⊚σ↓[(G,H),I] then {a mathematical formula}[(D,E),F]∈C⊚⊚σ↓[(G,H),I] if and only if {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.Proof. Suppose that {a mathematical formula}[(G,H),I]∈C⊚⊚σ↓[(G,H),I].(⇒) Suppose that {a mathematical formula}[(D,E),F]∈C⊚⊚σ↓[(G,H),I]. Then, since {a mathematical formula}[(G,H),I]∈C⊚⊚σ↓[(G,H),I], by Definition 18, {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I]. Then, following Definition 14, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Thus, by Definition 9, {a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Then, following Definition 13, {a mathematical formula}[(D,E),F]∈C∖σ↓(C(H−G)) and {a mathematical formula}[(D,E),F]∉σ↓(C(H−G)). Then, by Definition 12, for every path P from H to G if {a mathematical formula}[(D,E),F]∈P then {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,F)∈Cl(C). Thus, {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C.(⇐) Suppose that {a mathematical formula}[(D,E),F] is a safe element with respect to {a mathematical formula}(H,G) in {a mathematical formula}C. Then, for every path {a mathematical formula}P∈C(H−G) either {a mathematical formula}[(D,E),F]∉P, or {a mathematical formula}∃[(I,J),K]∈P with {a mathematical formula}(K,F)∈Cl(C). Thus, following Definition 12, {a mathematical formula}[(D,E),F]∉σ↓(C(H−G)). Then, {a mathematical formula}[(D,E),F]∈C∖σ↓(C(H−G)) and by Definition 13{a mathematical formula}[(D,E),F]∈C⊖σ↓(H,G). Following Definition 9, {a mathematical formula}[(D,E),F]∈(C⊖σ↓(H,G))⊕[(G,H),I]. Hence, by Definition 14, {a mathematical formula}[(D,E),F]∈C⊛σ↓[(G,H),I]. Since {a mathematical formula}[(G,H),I]∈C⊚⊚σ↓[(G,H),I], by Definition 18, {a mathematical formula}[(D,E),F]∈C⊚⊚σ↓[(G,H),I]. □</paragraph></section></appendices><references><reference label="[1]"><authors>Carlos Alchourrón,Peter Gärdenfors,David Makinson</authors><title>On the logic of theory change: partial meet contraction and revision functions</title><host>J. Symb. Log.50 (2)(1985) pp.510-530</host></reference><reference label="[2]"><authors>Carlos Alchourrón,David Makinson</authors><title>On the logic of theory change: safe contraction</title><host>Stud. Log.44 (1985) pp.405-422</host></reference><reference label="[3]"><authors>Hajnal Andréka,Mark Ryan,Pierre-Yves Schobbens</authors><title>Operators and laws for combining preference relations</title><host>J. Log. Comput.12 (1)(2002) pp.13-53</host></reference><reference label="[4]"><authors>Kathleen Suzanne Barber,Joonoo Kim</authors><title>Belief revision process based on trust: simulation experiments</title><host>Proceedings of Autonomous Agents '01 Workshop on Deception, Fraud, and Trust in Agent Societies(2001) pp.1-12</host></reference><reference label="[5]"><authors>Salem Benferhat,Didier Dubois,Henri Prade,Mary-Anne Williams</authors><title>A practical approach to revising prioritized knowledge bases</title><host>Stud. Log.70 (1)(2002) pp.105-130</host></reference><reference label="[6]"><authors>Salem Benferhat,Sylvain Lagrue,Odile Papini</authors><title>Revision of partially ordered information: axiomatization, semantics and iteration</title><host>Leslie Pack KaelblingAlessandro SaffiottiIJCAI 2005(2005)Professional Book Center pp.376-381</host></reference><reference label="[7]"><authors>Richard Booth</authors><title>Social contraction and belief negotiation</title><host>Inf. Fusion7 (1)(2006) pp.19-34</host></reference><reference label="[8]"><authors>Craig Boutilier</authors><title>Revision sequences and nested conditionals</title><host>Proc. of the 13th Int. Joint Conf. on Artificial IntelligenceIJCAI, Chambéry, France(1993) pp.519-525</host></reference><reference label="[9]"><authors>Craig Boutilier,Nir Friedman,Joseph Y. Halpern</authors><title>Belief revision with unreliable observations</title><host>Jack MostowChuck RichAAAI/IAAI(1998)AAAI Press/The MIT Press pp.127-134</host></reference><reference label="[10]"><authors>John Cantwell</authors><title>Resolving conflicting information</title><host>J. Log. Lang. Inf.7 (2)(1998) pp.191-220</host></reference><reference label="[11]"><authors>Laurence Cholvy</authors><title>Plausibility of information reported by successive sources</title><host>Amol DeshpandeAnthony HunterSUMLecture Notes in Computer Sciencevol. 6379 (2010)Springer pp.126-136</host></reference><reference label="[12]"><authors>Samir Chopra,Aditya Ghose,Thomas Meyer</authors><title>Non-prioritized ranked belief change</title><host>J. Philos. Log.32 (4)(2003) pp.417-443</host></reference><reference label="[13]"><authors>Adnan Darwiche,Judea Pearl</authors><title>On the logic of iterated belief revision</title><host>Artif. Intell.89 (1–2)(1997) pp.1-29</host></reference><reference label="[14]"><authors>Chrysanthos Dellarocas</authors><title>The digitalization of word-of-mouth: promise and challenges of online reputation mechanisms</title><host>Management Science(2003)</host></reference><reference label="[15]"><authors>Aldo Dragoni,Paolo Giorgini,Paolo Puliti</authors><title>Distributed belief revision versus distributed truth maintenance</title><host>Proceedings of the Sixth IEEE International Conference on Tools with Artificial IntelligenceTAI 94(1994)IEEE Computer Society Press pp.499-505</host></reference><reference label="[16]"><authors>Marcelo A. Falappa,Gabriele Kern-Isberner,Guillermo R. Simari</authors><title>Explanations, belief revision and defeasible reasoning</title><host>Artif. Intell.141 (1)(2002) pp.1-28</host></reference><reference label="[17]"><authors>Eduardo L. Fermé,Sven Ove Hansson</authors><title>Selective revision</title><host>Stud. Log.63 (3)(1999) pp.331-342</host></reference><reference label="[18]"><authors>Eduardo L. Fermé,Juan Mikalef,Jorge Taboada</authors><title>Credibility-limited functions for belief bases</title><host>J. Log. Comput.13 (1)(2003) pp.99-110</host></reference><reference label="[19]"><authors>Eduardo L. Fermé,Maurício D.L̃. Reis</authors><title>Possible worlds semantics for partial meet multiple contraction</title><host>J. Philos. Log.41 (1)(2012) pp.7-28</host></reference><reference label="[20]"><authors>Eduardo L. Fermé,Maurício D.L̃. Reis</authors><title>System of spheres-based multiple contractions</title><host>J. Philos. Log.41 (1)(2012) pp.29-52</host></reference><reference label="[21]"><authors>André Fuhrmann,Sven Ove Hansson</authors><title>A survey of multiple contractions</title><host>J. Log. Lang. Inf.3 (1994) pp.39-76</host></reference><reference label="[22]"><authors>Peter Gärdenfors</authors><title>An epistemic approach to conditionals</title><host>Am. Philos. Q.18 (3)(1981) pp.203-211</host></reference><reference label="[23]"><authors>Peter Gärdenfors</authors><title>Knowledge in Flux: Modeling the Dynamics of Epistemic States</title><host>(1988)The MIT Press, Bradford BooksCambridge, Massachusetts</host></reference><reference label="[24]"><authors>Sven Ove Hansson</authors><title>A dyadic representation of belief</title><host>Belief Revis. (1992) pp.89-121</host></reference><reference label="[25]"><authors>Sven Ove Hansson</authors><title>Kernel contraction</title><host>J. Symb. Log.59 (1994) pp.845-859</host></reference><reference label="[26]"><authors>Sven Ove Hansson</authors><title>Semi-revision</title><host>J. Appl. Non-Class. Log. (1997) pp.151-175</host></reference><reference label="[27]"><authors>Sven Ove Hansson</authors><title>A Textbook of Belief Dynamics: Theory Change and Database Updating</title><host>(1999)Kluwer Academic Publishers</host></reference><reference label="[28]"><authors>Sven Ove Hansson,Eduardo L. Fermé,John Cantwell,Marcelo A. Falappa</authors><title>Credibility limited revision</title><host>J. Symb. Log.66 (4)(2001) pp.1581-1596</host></reference><reference label="[29]"><authors>Hirofumi Katsuno,Alberto Mendelzon</authors><title>Propositional knowledge base revision and minimal change</title><host>Artif. Intell.52 (1991) pp.263-294</host></reference><reference label="[30]"><authors>Noa E. Kfir-Dahav,Moshe Tennenholz</authors><title>Multi-agent belief revision</title><host>Theoretical Aspects of Rationality and Knowledge: Proceeding of the Sixth Conference (TARK 1996)(1996)Morgan Kaufmann Publishers Inc.San Francisco pp.175-196</host></reference><reference label="[31]"><authors>Sébastien Konieczny,Ramón Pino Pérez</authors><title>Merging information under constraints: a logical framework</title><host>J. Log. Comput.12 (5)(2002) pp.773-808</host></reference><reference label="[32]"><authors>Sébastien Konieczny,Ramón Pino Pérez</authors><title>Improvement operators</title><host>Gerhard BrewkaJérôme LangKR(2008)AAAI Press pp.177-187</host></reference><reference label="[33]"><authors>Patrick Krümpelmann,Luciano H. Tamargo,Alejandro J. García,Marcelo A. Falappa</authors><title>Forwarding credible information in multi-agent systems</title><host>Proceedings of the 3rd International Conference on Knowledge Science, Engineering and ManagementKSEM 2009Lecture Notes in Computer Sciencevol. 5914 (November 2009) pp.41-53</host></reference><reference label="[34]"><authors>Isaac Levi</authors><title>Subjunctives, dispositions and chances</title><host>Synthese34 (1977) pp.423-455</host></reference><reference label="[35]"><authors>Wei Liu,Mary-Anne Williams</authors><title>A framework for multi-agent belief revision, part i: The role of ontology</title><host>Australian Joint Conference on A. I.(1999) pp.168-179</host></reference><reference label="[36]"><authors>Wei Liu,Mary-Anne Williams</authors><title>A framework for multi-agent belief revision</title><host>Stud. Log.67 (2)(2001) pp.291-312</host></reference><reference label="[37]"><authors>Jianbing Ma,Salem Benferhat,Weiru Liu</authors><title>Revising partial pre-orders with partial pre-orders: a unit-based revision framework</title><host>Proceedings of the 13th International Conference on Principles of Knowledge Representation and ReasoningKR'12(2012) pp.633-637</host></reference><reference label="[38]"><authors>Jianbing Ma,Weiru Liu</authors><title>A framework for managing uncertain inputs: an axiomization of rewarding</title><host>Int. J. Approx. Reason.52 (7)(2011) pp.917-934</host></reference><reference label="[39]"><authors>David Makinson</authors><title>Screened revision</title><host>Special Issue on Non-Prioritized Belief RevisionTheoria63 (1997) pp.14-23</host></reference><reference label="[40]"><authors>Benedita Malheiro,Nicholas Jennings,Eugenio Oliveira</authors><title>Belief revision in multi-agent systems</title><host>Proceeding of the 11th European Conference on Artificial IntelligenceECAI 94(1994) pp.294-298</host></reference><reference label="[41]"><authors>Abhaya C. Nayak</authors><title>The deficit and dynamics of trust</title><host>EUC(2010) pp.517-522</host></reference><reference label="[42]"><authors>Abhaya C. Nayak</authors><title>Trust in context</title><host>Australasian Conference on Artificial Intelligence(2012) pp.517-529</host></reference><reference label="[43]"><authors>Jordi Sabater,Carles Sierra</authors><title>Regret: a reputation model for gregarious societies</title><host>Proceedings of the Fourth Workshop on Deception, Fraud and Trust in Agent Societies(2001) pp.61-69</host></reference><reference label="[44]"><authors>Jordi Sabater,Carles Sierra</authors><title>Review on computational trust and reputation models</title><host>Artif. Intell. Rev.24 (1)(2005) pp.33-60</host></reference><reference label="[45]"><authors>Abraham P. Schwab</authors><title>Epistemic trust, epistemic responsibility, and medical practice</title><host>J. Med. Philos.33 (4)(2008) pp.302-320</host></reference><reference label="[46]"><authors>Patricio D. Simari,Marcelo A. Falappa</authors><title>Revision of informant plausibility in multi-agent systems</title><host>J. Comput. Sci. Technol.2 (5)(2001)</host></reference><reference label="[47]"><authors>Luciano H. Tamargo,Marcelo A. Falappa,Alejandro J. García,Guillermo R. Simari</authors><title>A change model for credibility partial order</title><host>Proceeding of the 5th International Conference on Scalable Uncertainty ManagementSUM(2011) pp.317-330</host></reference><reference label="[48]"><authors>Luciano H. Tamargo,Alejandro J. García,Marcelo A. Falappa,Guillermo R. Simari</authors><title>Consistency maintenance of plausible belief bases based on agents credibility</title><host>12th International Workshop on Non-Monotonic ReasoningNMR(2008) pp.50-58</host></reference><reference label="[49]"><authors>Luciano H. Tamargo,Alejandro J. García,Marcelo A. Falappa,Guillermo R. Simari</authors><title>Modeling knowledge dynamics in multi-agent systems based on informants</title><host>Knowl. Eng. Rev.27 (1)(2012) pp.87-114</host></reference></references><footnote/></root>