<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370214000551</url><title>Potential-based bounded-cost search and Anytime Non-Parametric A⁎</title><authors>Roni Stern,Ariel Felner,Jur van den Berg,Rami Puzis,Rajat Shah,Ken Goldberg</authors><abstract>This paper presents two new search algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-Parametric A⁎ ( APTS/ANA⁎). Both algorithms are based on a new evaluation function that is easy to implement and does not require user-tuned parameters. PTS is designed to solve bounded-cost search problems, which are problems where the task is to find as fast as possible a solution under a given cost bound. APTS/ANA⁎ is a non-parametric anytime search algorithm discovered independently by two research groups via two very different derivations. In this paper, co-authored by researchers from both groups, we present these derivations: as a sequence of calls to PTS and as a non-parametric greedy variant of Anytime Repairing A⁎. We describe experiments that evaluate the new algorithms in the 15-puzzle, KPP-COM, robot motion planning, gridworld navigation, and multiple sequence alignment search domains. Our results suggest that when compared with previous anytime algorithms, APTS/ANA⁎: (1) does not require user-set parameters, (2) finds an initial solution faster, (3) spends less time between solution improvements, (4) decreases the suboptimality bound of the current-best solution more gradually, and (5) converges faster to an optimal solution when reachable.</abstract><keywords>Heuristic search;Anytime algorithms;Robotics</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>Heuristic search algorithms are widely used to compute minimum-cost paths in graphs. Applications of heuristic search range from map navigation software and robot path planning to automated planning and puzzle solving. Different search algorithms return solutions of varying quality, which is commonly measured by a cost, where high quality solutions are those with a low cost. Ideally, one would like to find optimal solutions, i.e., those with minimum cost. Given an admissible heuristic, some search algorithms, such as {a mathematical formula}A⁎[1] or {a mathematical formula}IDA⁎[2], return optimal solutions. However, many problems are very hard to solve optimally [3] even with such algorithms.</paragraph><paragraph>In this paper we propose two algorithms: Potential Search (PTS) and Anytime Potential Search/Anytime Non-Parametric {a mathematical formula}A⁎ ({a mathematical formula}APTS/ANA⁎). These algorithms are especially suited for cases where an optimal solution is hard to find. PTS is designed to solve problems where any solution with cost less than C, an input to the problem, is acceptable, while solutions with cost ≥C are useless. We call such problems bounded-cost search problems. Bounded-cost search problems arise, for example, when the expense budget for a business trip is limited and the trip (e.g., flights and hotels) should be planned as quickly as possible but within the budget limit. If an online travel agency such as Expedia or Priceline is planning the trip, computational resources could be diverted to other clients once a plan is found within the budget limits (see Priceline's “Name Your Own Price” option).</paragraph><paragraph>The second algorithm we present, {a mathematical formula}APTS/ANA⁎, is an anytime search algorithm, i.e., an algorithm “whose quality of results improves gradually as computation time increases” [4]. {a mathematical formula}APTS/ANA⁎ can be viewed as a translation of an anytime search algorithm into a sequence of bounded-cost search problems solved by PTS, or as an intelligent approach to avoid the parameter setting problem of Weighted {a mathematical formula}A⁎-based anytime search algorithms. Setting parameters to bounded-suboptimal search algorithms is a known problem in the heuristic search literature [5]. A key benefit of {a mathematical formula}APTS/ANA⁎ is that it does not require users to set parameters, such as the {a mathematical formula}w0 and Δw parameters of {a mathematical formula}ARA⁎[6]. Furthermore, experiments suggest that {a mathematical formula}APTS/ANA⁎ improves upon previous anytime search algorithms in most cases by (1) finding an initial solution faster, (2) spending less time between solution improvements, (3) decreasing the suboptimality bound of the current-best solution more gradually, and (4) converging faster to an optimal solution when reachable.</paragraph><paragraph>Both PTS and {a mathematical formula}APTS/ANA⁎ are based on a new evaluation function {a mathematical formula}u(n)=C−g(n)h(n) that was discovered independently by two research groups via two very different derivations. In this paper, co-authored by researchers from both groups, we present both derivations. The first derivation of {a mathematical formula}u(⋅) is based on a novel concept called the potential of a node. The potential of a node n is defined with respect to a given value C, and is the probability that a node n is part of a solution of cost lower than C. We prove that the node with the highest {a mathematical formula}u(⋅) is the node with the highest potential, under certain probabilistic relation between the heuristic function and the cost it estimates.</paragraph><paragraph>The second derivation of {a mathematical formula}u(⋅) is based on the desire for a non-parametric version of the Anytime Repairing {a mathematical formula}A⁎ algorithm [6]. We show that expanding the node with the highest {a mathematical formula}u(⋅) has the same effect as setting the parameters of {a mathematical formula}ARA⁎ dynamically to improve the best solution found so far as fast as possible. In addition, we show that {a mathematical formula}u(⋅) bounds the suboptimality of the current solution.</paragraph><paragraph>We compare PTS and {a mathematical formula}APTS/ANA⁎ with previous anytime algorithms on five representative search domains: the 15-puzzle, robot motion planning, gridworld navigation, Key player problem in communication (KPP-COM), and multiple sequence alignment. As mentioned above, the experimental results suggest that {a mathematical formula}APTS/ANA⁎ improves upon previous anytime search algorithms in terms of key metrics that determine the quality of an anytime algorithm. As a bounded-cost algorithm, our results suggest that PTS, which is specifically designed for bounded-cost problems, outperforms competing algorithms for most cost bounds and exhibits an overall robust behavior.</paragraph><paragraph>This paper extends our preliminary work [7], [8], [9] by (1) providing a substantially more rigorous theoretical analysis of the presented algorithms, (2) extending the experimental results, (3) adding a comprehensive discussion on the relation between bounded-cost search and anytime search, and (4) discussing the limitations of PTS and {a mathematical formula}APTS/ANA⁎.</paragraph><paragraph>The structure of this paper is as follows. First, we provide background and related work. In Section 3, we introduce the bounded-cost search problem and present Potential Search (PTS). In Section 4, we present Anytime Potential Search (APTS) [7], [8] and Anytime Non-Parametric {a mathematical formula}A⁎ ({a mathematical formula}ANA⁎) [9], showing that they are equivalent and discussing their theoretical properties. Section 5 presents experimental results comparing PTS and {a mathematical formula}APTS/ANA⁎ with previous algorithms. Finally, we discuss a generalization of PTS (Section 6) and conclude with suggestions for future work (Section 7).</paragraph></section><section label="2"><section-title>Background and related work</section-title><paragraph>Search algorithms find a solution by starting at the initial state and traversing the problem space graph until a goal state is found. Various search algorithms differ by the order in which they decide to traverse the problem space graph. Traversing the problem space graph involves generating and expanding its nodes. The term generating a node refers to creating a data structure that represents it, while expanding a node means generating all its children.</paragraph><paragraph>One of the most widely used search frameworks is best–first search (BFS) [10]. BFS keeps two lists of nodes: an open list (denoted hereafter as OPEN), which contains all the generated nodes that have not been expanded yet, and a closed list (denoted hereafter as CLOSED), which contains all the nodes that have been previously expanded. Every generated node in OPEN is assigned a value by an evaluation function. The value assigned to a node is called the cost of the node. In every iteration of BFS, the node in OPEN with the lowest cost is chosen to be expanded. This lowest-cost node is moved from OPEN to CLOSED, and the children of this node are inserted to OPEN. The purpose of CLOSED is to avoid inserting nodes that have already been expanded into OPEN. CLOSED is also used to help reconstruct the solution after a goal is found. Once a goal node is chosen for expansion, i.e., it is the lowest-cost node in OPEN, BFS halts and that goal is returned.{sup:1} Alternatively, BFS can be defined such that every node is assigned a value, and in every iteration the node with the highest value is expanded.</paragraph><paragraph>BFS is a general framework, and many well-known algorithms are special cases of it. For example, Dijkstra's single-source shortest-path algorithm [12] and the {a mathematical formula}A⁎ algorithm [1] are both special cases of BFS, differing only in their evaluation function.{sup:2} Dijkstra's algorithm is BFS with an evaluation function that is {a mathematical formula}g(n), which is the shortest path found so far from the start of the search to node n. {a mathematical formula}A⁎ is BFS with an evaluation function that is {a mathematical formula}f(n)=g(n)+h(n), where {a mathematical formula}h(n) is a heuristic function estimating the cost from state n to a goal node. We use the notation {a mathematical formula}h⁎(n) to denote the lowest-cost path from node n to a goal. {a mathematical formula}h(n) is said to be admissible if it never overestimates the cost of the lowest-cost path from n to a goal, i.e., if {a mathematical formula}h(n)≤h⁎(n) for every node n. Using an admissible {a mathematical formula}h(n), {a mathematical formula}A⁎ is guaranteed to have found a lowest-cost path to a goal when a goal node is chosen for expansion. In general, we use the term optimal search algorithms to denote search algorithms that guarantee returning an optimal solution. Other known optimal search algorithms include {a mathematical formula}IDA⁎[2] and RBFS [15].</paragraph><paragraph>Finding an optimal solution to search problems is often infeasible. Additionally, it is often the case that non-optimal solutions are good enough. Hence, there are search algorithms that provide a weaker guarantee on the solution they return, with respect to optimal search algorithms. We list below several types of search algorithms that provide such weaker guarantees.</paragraph><section label="2.1"><section-title>Bounded-suboptimal search algorithms</section-title><paragraph>Bounded-suboptimal algorithms guarantee that the solution returned is no more than w times the cost of an optimal solution, where {a mathematical formula}w&gt;1 is a predefined parameter. These algorithms are also called w-admissible, and the value of w is referred to as the “desired suboptimality”. We use the term suboptimality of a solution of cost C to denote the ratio between the cost of an optimal solution and C. Thus, the suboptimality of the solution returned by a w-admissible algorithm is bounded (from above) by the desired suboptimality w.</paragraph><paragraph>The most well-known bounded-suboptimal search algorithm is probably Weighted {a mathematical formula}A⁎ ({a mathematical formula}WA⁎) [16].{sup:3}{a mathematical formula}WA⁎ extends {a mathematical formula}A⁎ by trading off running time and solution quality. It is similar to {a mathematical formula}A⁎, except that it inflates the heuristic by a value {a mathematical formula}w≥1. Thus, {a mathematical formula}WA⁎ expands the node n in OPEN with minimal {a mathematical formula}fw(n)=g(n)+w⋅h(n). The higher w, the greedier the search, and the sooner a solution is typically found. If {a mathematical formula}h(⋅) is an admissible heuristic, then {a mathematical formula}WA⁎ is a bounded-suboptimal search algorithm, i.e., the suboptimality of the solutions found by {a mathematical formula}WA⁎ is bounded by w. Other examples of a bounded-suboptimal search algorithm include {a mathematical formula}Aϵ⁎[18], Optimistic Search [19] and Explicit Estimation Search [20].</paragraph></section><section label="2.2"><section-title>Any solution algorithms</section-title><paragraph>In some cases, the solution quality is of no importance. This may be the case in problems that are so hard that obtaining any meaningful bound on the quality of the solution is not possible. We call algorithms for such settings any solution algorithms. Such algorithms usually find a solution faster than algorithms of the first two classes, but possibly with lower quality. Examples of any solution algorithms include pure heuristic search (a BFS using {a mathematical formula}h(⋅) as its evaluation function),{sup:4} beam search variants [21], as well as many variants of local search algorithms such as Hill climbing and Simulated annealing [10].</paragraph></section><section label="2.3"><section-title>Anytime search algorithms</section-title><paragraph>Another class of search algorithms that lies in the range between any solution algorithms and optimal algorithms is anytime algorithms. An anytime search algorithm starts, conceptually, as an any solution algorithm.{sup:5} After the first solution is found, it continues to run, finding solutions of better quality (with or without guarantee on their suboptimality). Anytime algorithms are commonly used in many domains, since they provide a natural continuum between any solution algorithms and optimal solution algorithms. Some anytime algorithms, such as {a mathematical formula}AWA⁎[22] and {a mathematical formula}ARA⁎[6] that are introduced below, are guaranteed to converge to finding an optimal solution if enough time is given.</paragraph><paragraph>Many existing anytime search algorithms are loosely based on {a mathematical formula}WA⁎. Since this paper addresses anytime search algorithms in depth, we next provide a brief survey of existing {a mathematical formula}WA⁎-based anytime search algorithms. A commonly used anytime algorithm that is not related to {a mathematical formula}WA⁎ is Depth-first branch and bound (DFBnB) [23]. DFBnB runs a depth-first search, pruning nodes that have a cost higher than the incumbent solution ({a mathematical formula}=best solution found so far). DFBnB does not require any parameters. However, DFBnB is highly ineffective in domains with many cycles and large search depth.{sup:6}</paragraph></section><section label="2.4">{a mathematical formula}WA⁎-based anytime search algorithms<paragraph>Anytime Weighted{a mathematical formula}A⁎ ({a mathematical formula}AWA⁎) [22] is an anytime version of {a mathematical formula}WA⁎. It runs {a mathematical formula}WA⁎ with a given value of w until it finds the first solution. Then, it continues the search with the same w. Throughout, {a mathematical formula}AWA⁎ expands a node in OPEN with minimal {a mathematical formula}fw(n)=g(n)+w⋅h(n), where w is a parameter of the algorithm. Each time a goal node is extracted from OPEN, an improved solution may have been found. Let G denote the cost of the incumbent solution. If {a mathematical formula}h(⋅) is admissible, then the suboptimality of the incumbent solution can be bounded by {a mathematical formula}G/minn∈OPEN{g(n)+h(n)}, as G is an upper bound of the cost of an optimal solution, and {a mathematical formula}minn∈OPEN{g(n)+h(n)} is a lower bound of the cost of an optimal solution. Given enough runtime, {a mathematical formula}AWA⁎ will eventually expand all the nodes with {a mathematical formula}g(n)+h(n) larger than the incumbent solution, and return an optimal solution.</paragraph><paragraph>Anytime Repairing{a mathematical formula}A⁎ ({a mathematical formula}ARA⁎) [6] is also based on {a mathematical formula}WA⁎. First, it finds a solution for a given initial value of w. It then continues the search with progressively smaller values of w to improve the solution and reduce its suboptimality bound. The value of w is decreased by a fixed amount each time an improved solution is found or the current-best solution is proven to be w-suboptimal. Every time a new value is determined for w, the {a mathematical formula}fw(n)-value of each node {a mathematical formula}n∈OPEN is updated to account for the new value of w and OPEN is re-sorted accordingly. The initial value of w and the amount by which it is decreased in each iteration (denoted as Δw) are parameters of the algorithm.</paragraph><paragraph>Restarting Weighted{a mathematical formula}A⁎ ({a mathematical formula}RWA⁎) [24] is similar to {a mathematical formula}ARA⁎, but each time w is decreased it restarts the search from the root node. That is, every new search is started with only the initial node in OPEN. It takes advantage of the effort of previous searches by putting the nodes explored in previous iterations on a SEEN list. Each time the search generates a seen node, it puts that node in OPEN with the best g-value known for it. Restarting has proven to be effective (in comparison to continuing the search without restarting) in situations where the quality of the heuristic varies substantially across the search space. As with {a mathematical formula}ARA⁎, the initial values of w and Δw are parameters of the algorithm.</paragraph><paragraph>Anytime Window{a mathematical formula}A⁎ ({a mathematical formula}AWinA⁎) [25], Beam-Stack Search (BSS) [26], and BULB [21] are not based on {a mathematical formula}WA⁎, but rather limit the “breadth” of a regular {a mathematical formula}A⁎ search. Iteratively increasing this breadth provides the anytime characteristic of these algorithms. For a comprehensive survey and empirical comparison of anytime search algorithms, see [27].</paragraph><paragraph>Most existing {a mathematical formula}WA⁎-based anytime search algorithms require users to set parameters, for example the w factor used to inflate the heuristic. {a mathematical formula}ARA⁎[6], for instance, has two parameters: the initial value of w and the amount by which w is decreased in each iteration. Setting these parameters requires trial-and-error and domain expertise [25]. One of the contributions of this paper is a non-parametric anytime search algorithm that is based on solving a sequence of bounded-cost search problems (Section 4).</paragraph></section></section><section label="3"><section-title>Bounded-cost search and potential search</section-title><paragraph label="Definition 1">In this section we define the bounded-cost search problem, where the task is to find, as quickly as possible, a solution with a cost that is lower than a given cost bound. We then explain why existing search algorithms, such as optimal search algorithms and bounded-suboptimal search algorithms, are not suited to solve bounded-cost search problems. Finally, we introduce a new algorithm called Potential Search (PTS), specifically designed for solving bounded-cost search problems. We define a bounded-cost search problem as follows. Bounded-cost search problemGiven an initial state s, a goal test function, and a constant C, a bounded-cost search problem is the problem of finding a path from s to a goal state with cost less than C.</paragraph><section label="3.1"><section-title>Applications of bounded-cost search</section-title><paragraph>In Section 4 we show that solving bounded-cost search problems can be a part of an efficient and non-parametric anytime search. While constructing efficient anytime algorithms is a noteworthy achievement, solving bounded-cost search problems is important in its own right and has many practical applications.</paragraph><paragraph>Generally, when a search algorithm is part of a larger system, it is reasonable to define for the search algorithm what an acceptable solution is in terms of cost. Once such a solution is found, system resources can be diverted to other tasks instead of optimizing other search-related criteria.</paragraph><paragraph>For example, consider an application server for an online travel agency such as Expedia, where a customer requests a flight to a specific destination within a given budget. In fact, Priceline allows precisely this option when booking a hotel (the “Name Your Own Price” option). This can be naturally modeled as a bounded-cost problem, where the cost is the price of the flight/hotel.</paragraph><paragraph>Furthermore, recent work has proposed to solve conformant probabilistic planning (CPP) problems by compiling them into a bounded-cost problem [28]. In CPP, the identity of the start state is uncertain. A set of possible start states is given, and the goal is to find a plan such that the goal will be reached with probability higher than {a mathematical formula}1−ϵ, where ϵ is a parameter of the search. We refer the reader to Taig and Brafman's paper [28] for details about how they compiled a CPP problem to a bounded-cost search problem.</paragraph><paragraph>A more elaborate application of bounded-cost search exists in the task of recognizing textual entailment (RTE). RTE is the problem of checking whether one text, referred to as the “text”, logically entails another, referred to as the “hypothesis”. For example, the text “Apple acquired Anobit” entails the hypothesis that “Anobit was bought”. Recent work modeled RTE as a search problem, where a sequence of text transformation operators, referred to as a “proof”, is used to transform the text into the hypothesis [29], [30]. Each proof is associated with a cost representing the confidence that the proof preserves the semantic meaning of the text. Stern et al. [29] used Machine Learning to learn a cost threshold for RTE proofs such that only proofs with cost lower than this threshold are valid. Thus, solving an RTE problem (i.e., determining whether a given text entails a given hypothesis) becomes a bounded-cost problem of finding a proof under the learned cost threshold.</paragraph><paragraph>A bounded-cost search problem can be viewed as a constraint satisfaction problem (CSP), where the desired cost bound is simply a constraint on the solution cost. However, modeling a search problem as a CSP is non-trivial if one does not know the depth of the goal in the search tree.{sup:7} Furthermore, many search problems have powerful domain-specific heuristics, and it is not clear if general CSP solvers can use such heuristics. The bounded-cost search algorithm presented in Section 3.3 can use any given heuristic.</paragraph><paragraph>Finally, most state-of-the-art CSP solvers use variants of depth-first search. Such algorithms are known to be highly inefficient in problems like pathfinding, where there are usually many cycles in the state space. Nonetheless, the potential-based approach described in Section 3.3 is somewhat reminiscent of CSP solvers that are based on solution counting and solution density, where assignments estimated to allow the maximal number of solutions are preferred [31].</paragraph><paragraph>Another topic related to the bounded-cost setting is resource-constrained planning [32], [33], where resources are limited and may be consumed by actions. The task is to find a lowest cost feasible plan, where a feasible plan is one where resources are available for all the actions in it. One may view bounded-cost search as a resource-constrained problem with a single resource – the plan cost. However, in bounded-cost search we do not want to minimize the cost of the plan. Any plan under the cost bound is acceptable. Once such a plan is found, it is wasteful to invest CPU time in improving the cost, and computation resources can be diverted elsewhere.</paragraph></section><section label="3.2"><section-title>Naïve approaches to bounded-cost search</section-title><paragraph>It is possible to solve a bounded-cost search problem by running an optimal search algorithm. If the optimal solution cost is less than C, return it; otherwise return failure, as no solution of cost less than C exists. One could even use C for pruning purposes, and prune any node n with {a mathematical formula}f(n)≥C. However, this technique for solving the bounded-cost search problem might be very inefficient as finding a solution with cost less than C can be much easier than finding an optimal solution.</paragraph><paragraph>One might be tempted to run any of the bounded-suboptimal search algorithms. However, it is not clear how to tune any of the suboptimal algorithms (for example, which weight to use in {a mathematical formula}WA⁎ and its variants), as the cost of an optimal solution is not known and therefore the ratio between the cost of the desired solution C and the optimal cost is also unknown.</paragraph><paragraph>A possible direction for solving a bounded-cost search problem is to run any suboptimal best–first search algorithm, e.g., pure heuristic search, and prune node with {a mathematical formula}g+h≥C. Once a solution is found, it is guaranteed to have a cost lower than C. In fact, using this approach with pure heuristic search was shown to be effective in domain independent planning problems with non-unit edge costs [34]. The main problem with all these ad-hoc bounded-cost algorithms is, however, that the desired goal cost bound is not used to guide the search, i.e., C is not considered when choosing which node to expand next.</paragraph><paragraph>Having defined the notion of bounded-cost search and its relation to existing search settings and algorithms, we next introduce the PTS algorithm, which is specifically designed to solve such problems.</paragraph></section><section label="3.3"><section-title>The Potential Search algorithm (PTS)</section-title><paragraph>The Potential Search algorithm (PTS) is specifically designed to focus on solutions with cost less than C, and the first solution it finds meets this requirement. PTS is basically a best–first search algorithm that expands the node from OPEN with the largest{a mathematical formula}u(⋅), where {a mathematical formula}u(⋅) is defined as follows{sup:8}:{a mathematical formula}</paragraph><paragraph>Choosing the node with the highest {a mathematical formula}u(⋅) can be intuitively understood as selecting the node that is most likely to lead to a solution of cost less than C, as {a mathematical formula}u(n) is a ratio of the “budget” that is left to find a solution under C (this is {a mathematical formula}C−g(n)) and the estimate of the cost between n and the goal (this is {a mathematical formula}h(n)). In Sections 3.4 and 4.3 we discuss two analytical derivations of the {a mathematical formula}u(⋅) evaluation function.</paragraph><paragraph>The complete pseudo-code of PTS is provided in Algorithm 1. The input to PTS, and in general to any bounded-cost search algorithm, is the initial state s from which the search begins, and the cost bound C. In every iteration, the node with the highest {a mathematical formula}u(⋅), denoted as n, is expanded from OPEN (line 3). For every generated node {a mathematical formula}n′, duplicate detection is performed, ignoring {a mathematical formula}n′ if it exists in OPEN or CLOSED with smaller or equal g value (line 7). Otherwise, the value of {a mathematical formula}g(n′) is updated (line 9). If the heuristic function {a mathematical formula}h(⋅) is admissible, then PTS prunes any node {a mathematical formula}n′ for which {a mathematical formula}g(n′)+h(n′)≥C (line 12). This is because these nodes can never contribute to a solution of cost smaller than C. If {a mathematical formula}h(⋅) is not admissible, then {a mathematical formula}n′ is pruned only if {a mathematical formula}g(n′)≥C. Any bounded-cost search should perform this pruning, and indeed in our experiments we implemented this for all of the competing algorithms. If {a mathematical formula}n′ is not pruned and it is a goal, the search halts. Otherwise, {a mathematical formula}n′ is inserted into OPEN and the search continues.</paragraph></section><section label="3.4"><section-title>The potential</section-title><paragraph>PTS is based on the novel {a mathematical formula}u(⋅) evaluation function. Next, we provide the first analytical derivation of {a mathematical formula}u(n), relating it to the probability that n leads to a goal of cost smaller than C. We call this probability the potential of a node.</paragraph><paragraph>To motivate the concept of the potential of a node, consider the graph presented in Fig. 1. Assume that we are searching for a path from s to g. After expanding s, the search algorithm needs to decide which node to expand next: node a or node b. If the task is to find an optimal path from s to g, then clearly b should be expanded first, since there may be a path from s to g that passes through b whose cost is lower than the cost of the path that passes through a (as {a mathematical formula}f(b)=g(b)+h(b)=100&lt;f(a)=g(a)+h(a)=103).</paragraph><paragraph>If, however, the task is to find a path of cost less than 120 ({a mathematical formula}C=120), then expanding b is not necessarily the best option. For example, it might be better to expand a, which is probably very close to a goal of cost less than 120 (as {a mathematical formula}h(a)=3). Informally, we may say that a has more potential to lead to a solution of cost lower than C than b. Next, we define the notion of potential, and show its relation to {a mathematical formula}u(⋅).</paragraph><paragraph label="Definition 2">The potential of a node n is defined as the probability that a node with h value equal to {a mathematical formula}h(n) has a path to a goal with a cost smaller than {a mathematical formula}C−g(n). For clarity, we omit here the mathematical prerequisites for defining probabilities in this context and provide them later (see Definition 4). PotentialGiven a heuristic function h and a cost bound C, we define the potential of node n, denoted {a mathematical formula}PTh,C(n), as{a mathematical formula}</paragraph><paragraph>Clearly, the potential of a node depends on the relation between the heuristic function that is used ({a mathematical formula}h(⋅)) and the value it estimates ({a mathematical formula}h⁎(⋅)). In some domains, the relation between h and {a mathematical formula}h⁎ is a known property of h (e.g., a precision parameter of a sensor). In other domains, it is possible to evaluate how close h is to {a mathematical formula}h⁎ using attributes of the domain. In general, one would expect {a mathematical formula}h(n) to be closer to {a mathematical formula}h⁎(n) if {a mathematical formula}h(n) is small. For example, consider a shortest path problem in a map, using the air distance as a heuristic. If the air distance between two nodes is very large, it is more likely that obstacles exist between them. More obstacles imply a greater difference between the air distance and the real shortest path.</paragraph><paragraph>Consider the case where for a node n there is a linear stochastic relation between {a mathematical formula}h(n) and {a mathematical formula}h⁎(n), i.e., {a mathematical formula}h⁎(n)=h(n)⋅Xn, where {a mathematical formula}Xn∼X is a random variable drawn from a probability distribution X. We assume that the distribution X may be unknown, but that all {a mathematical formula}Xn (for every node n) are independent and identically distributed (i.i.d.) according to X. We denote these assumptions about the relation between h and {a mathematical formula}h⁎ as the linear-relative assumption.{sup:9} Assuming the linear-relative assumption, the potential of a node n is given by:{a mathematical formula}</paragraph><paragraph label="Lemma 1">If we do not know the distribution X that {a mathematical formula}Xn is drawn from, the potential of a node cannot be explicitly calculated. However, given any two nodes {a mathematical formula}n1 and {a mathematical formula}n2, we can determine which node has a higher potential by comparing their {a mathematical formula}u(⋅) values. This is true because {a mathematical formula}Xn1 and {a mathematical formula}Xn2 are i.i.d. ({a mathematical formula}Xn1,Xn2∼X), and therefore:{a mathematical formula} This idea is summarized in Lemma 1 below. Under the linear-relative assumption, for any pair of nodes{a mathematical formula}n1and{a mathematical formula}n2, we have that{a mathematical formula}u(n1)≥u(n2)iff{a mathematical formula}n1's potential is greater than or equal to{a mathematical formula}n2's potential.</paragraph><paragraph label="Theorem 1">Consequently, for any problem where the linear-relative assumption holds, a BFS that expands the node with the highest {a mathematical formula}u(⋅) in OPEN (≡ PTS) will expand nodes exactly according to their potential. This result is summarized in Theorem 1: Under the linear-relative assumption, PTS always expands the node with the highest potential.</paragraph><paragraph>It might be hard to find a domain where the linear-relative assumption holds exactly. However, this assumption holds approximately for many domains. For example, consider the 15-puzzle, a well-known search benchmark. We solved optimally each of the 1000 standard random instances [36]. For each of these instances we considered all the states on the optimal path, to a total of 52 523 states. Each of these states was assigned a 2-dimensional point, where the x value denotes the Manhattan Distance (MD) heuristic of the state and the y value denotes its optimal cost to the goal. The plot of these points is presented in Fig. 2. The dashed line indicates the best linear fit for the plot, which is the line {a mathematical formula}y=1.31⋅x−2.19. It is easy to observe that a linear fit is very close, suggesting that the linear-relative assumption approximately holds in this domain. Appendix A shows two other domains where this also occurs. In Section 6 we generalize PTS to handle cases where the linear-relative assumption does not hold.</paragraph></section><section label="3.5"><section-title>Limitations of PTS</section-title><paragraph>Later in this paper (Section 5) we provide experimental results on five domains showing that PTS is effective and robust in practice. However, we would also like to point out two limitations of PTS.</paragraph><section label="3.5.1"><section-title>Memory requirements</section-title><paragraph>PTS is a best–first search, storing all the nodes visited during the search in OPEN and CLOSED. Thus, the memory required for PTS to solve a problem is, in the worst case, exponential in the depth of the search. This prevents running PTS to solve problems in large domains such as the 24-puzzle for close to optimal cost bounds. One might consider running an iterative deepening scheme (like {a mathematical formula}IDA⁎[2]) with the potential utility function {a mathematical formula}u(⋅). This would be problematic as {a mathematical formula}u(⋅) is a non-integer number and thus setting the thresholds of the iterative deepening procedure would be non-trivial (although there are methods to cope with that [37], [38]).</paragraph></section><section label="3.5.2"><section-title>Distance vs. cost heuristics</section-title><paragraph>In some domains, the cost of reaching the goal and the distance (number of steps) to reach the goal are not correlated [39]. Effective search algorithms for such domains employ two types of heuristics – one that estimates the cost of reaching a goal, denoted by {a mathematical formula}h(⋅), and one that estimates the number of steps required to reach a goal, denoted by {a mathematical formula}d(⋅)[20]. The PTS evaluation function {a mathematical formula}u(⋅) considers only {a mathematical formula}h(⋅). Thus PTS may be less effective in domains where {a mathematical formula}d(⋅) and {a mathematical formula}h(⋅) are very different. Work on combining {a mathematical formula}h(⋅) and {a mathematical formula}d(⋅) for bounded-cost search showed promising results [40].</paragraph><paragraph>Resolving these two problems is beyond the scope of this paper and remains as a challenge for future work. Next, we describe {a mathematical formula}APTS/ANA⁎, which is a non-parametric anytime search algorithm using the PTS evaluation function {a mathematical formula}u(⋅).</paragraph></section></section></section><section label="4">Anytime Non-Parametric {a mathematical formula}A⁎ and Anytime Potential Search<paragraph>In this section we present a framework for constructing a non-parametric anytime search algorithm by solving a sequence of bounded-cost search problems. As an instance of this framework, we present Anytime Potential Search (APTS), which uses PTS to solve these bounded-cost search problems. Then, in Section 4.3 we present a different analytical derivation of APTS as a non-parametric modification of the {a mathematical formula}ARA⁎ anytime search algorithm. The result of this derivation is known as Anytime Non-Parametric {a mathematical formula}A⁎ ({a mathematical formula}ANA⁎) [9]. {a mathematical formula}ANA⁎ and APTS are the same algorithm, which we call {a mathematical formula}APTS/ANA⁎ to reflect its dual origin.</paragraph><section label="4.1"><section-title>Rationale for a non-parametric anytime search algorithm</section-title><paragraph>In general, the need for non-parametric algorithms is prevalent in many fields of computer science and AI [41], [42], [43]. The main reason is that algorithms with parameters require some method of selecting the values for this parameter, i.e., a method for parameter tuning. Parameter tuning are often:</paragraph><list><list-item label="•">Time consuming. Parameter tuning are commonly done by running the parametric algorithm several times on a range of instances and parameter values.</list-item><list-item label="•">Crucial for a successful implementation. Different parameter values can have great impact on the performance of parametric algorithms. This is known to occur in parametric search algorithms [5] and we observe this as well in our experimental results (given later in the paper).</list-item></list><paragraph>As a result, non-parametric algorithms are more accessible to practitioners. Thus, the need for a non-parametric anytime search algorithm is great.</paragraph></section><section label="4.2"><section-title>A greedy non-parametric anytime search</section-title><paragraph>Algorithm 2 presents a high-level view of an anytime search algorithm. It consists of iteratively calling the ImproveSolution procedure (line 4), which searches for a solution that is better than the incumbent solution (named “Incumbent” in Algorithm 2), whose cost is denoted by {a mathematical formula}cost(Incumbent) and maintained in the variable G. Initially, there is no incumbent solution, so G is set to ∞ (line 1). When there is no solution better than G, then G is proven to be the optimal solution cost and the search can halt (line 9).{sup:10} Alternatively, the search may be halted earlier, in which case {a mathematical formula}Incumbent is returned (line 12).</paragraph><paragraph>Different anytime algorithms vary by the implementation of the ImproveSolution procedure (line 4). For example, one can apply a depth first search for ImproveSolution. If every call to ImproveSolution resumes the same depth-first search, then this is identical to DFBnB. Many efficient anytime search algorithms, such as {a mathematical formula}AWA⁎[22], {a mathematical formula}ARA⁎[6] and {a mathematical formula}RWA⁎[24], implement ImproveSolution as different variants of {a mathematical formula}WA⁎. These {a mathematical formula}WA⁎-based anytime search algorithms require one or more parameters to set the w for {a mathematical formula}WA⁎'s {a mathematical formula}fw evaluation function. Tuning these parameters is often non-trivial.</paragraph><paragraph>It is sometimes possible to intelligently customize the parameters of an anytime search algorithm. For example, if one does know beforehand exactly when the search will be halted, it is possible to employ Deadline-Aware Search [44], which estimates during the search which paths to the goal will be achievable before the search is halted. Another example is when there exists a known utility tradeoff between computation time and solution quality. In this case, it is possible to use Best–First Utility-Guided Search [45], which tries to optimize this tradeoff.</paragraph><paragraph>In this paper we do not assume any prior knowledge on the termination time of the search, nor do we assume a given utility function that trades off computation for solution quality. In the absence of these, we propose the following greedy approach to anytime search. In every call to ImproveSolution, try to find a solution with cost lower than G as fast as possible. It is easy to see that every such call to ImproveSolution is exactly a bounded-cost search problem, where the cost-bound C is set to be the cost of the incumbent solution (G). Thus, we can use PTS in every call to ImproveSolution (line 4) with cost bound G. The resulting anytime search algorithm does not require parameter tuning (e.g., of w) and is shown empirically to be superior to other anytime search algorithms on a wide range of domains (see Section 5). This anytime search algorithm, which uses PTS for its Improve Solution part, is called Anytime Potential Search (APTS). As stated above, we refer to it as {a mathematical formula}APTS/ANA⁎ to emphasize its second derivation, described later in Section 4.3.</paragraph><paragraph>Because initially there is no incumbent solution, the purpose of the first iteration of {a mathematical formula}APTS/ANA⁎ is to find a solution as fast as possible, without any bound on its cost. Thus, {a mathematical formula}C=∞ and as a result the PTS evaluation function {a mathematical formula}u(n)=C−g(n)h(n) is also equal to ∞ for all the nodes in OPEN, making them indistinguishable.</paragraph><paragraph>However, as C approaches infinity, the node in OPEN with the highest {a mathematical formula}u(n)=C−g(n)h(n) is actually the node with the lowest {a mathematical formula}h(n). Thus, as C approaches infinity, PTS converges to pure heuristic search. Therefore, we define the first ImproveSolution call of {a mathematical formula}APTS/ANA⁎ to run pure heuristic search until the first solution is found.{sup:11}</paragraph><section label="4.2.1"><section-title>Reusing information between PTS calls</section-title><paragraph>There are several known approaches for using knowledge from previous calls to ImproveSolution. In some cases it is best to ignore it completely [24] and restart the search from the initial state. In other cases, a more sophisticated mechanism called repairing is preferred [6] (this is what gave the Anytime Repairing {a mathematical formula}A⁎ algorithm its name). For a comprehensive survey and empirical evaluation of the different ways to consider knowledge from previous calls to ImproveSolution, see [27]. No approach has dominated the others in all domains. For simplicity, we chose to implement all anytime algorithms in this paper such that OPEN is passed between calls to ImproveSolution. However, modifying {a mathematical formula}APTS/ANA⁎ to use any of the other approaches is trivial.</paragraph><paragraph>Consequently, when PTS is called with a new cost bound (which is the cost of the solution found by the previous call to PTS), it does not start from the initial node. Instead, PTS will expand nodes from OPEN of the previous PTS call. However, this incurs an overhead, as all the nodes in OPEN need to be reordered according to {a mathematical formula}u(⋅), as the cost of the incumbent solution has changed.</paragraph><paragraph>Next, we give a different derivation of {a mathematical formula}APTS/ANA⁎, as a non-parametric improvement of the {a mathematical formula}ARA⁎ anytime search algorithm.</paragraph></section></section><section label="4.3">{a mathematical formula}APTS/ANA⁎ as an improved Anytime Repairing {a mathematical formula}A⁎<paragraph>{a mathematical formula}ARA⁎[6] is a well-known anytime search algorithm shown to be effective in many domains [27]. For completeness, a simplified version of the {a mathematical formula}ARA⁎ algorithm is listed in Algorithm 3, Algorithm 4. {a mathematical formula}ARA⁎ is a special case of the high-level anytime algorithm described in Algorithm 2. It repeatedly calls its version of ImproveSolution, called here {a mathematical formula}ARA⁎-ImproveSolution, which aims to find a solution that is w-suboptimal. Initially, {a mathematical formula}w=w0, and it is decreased by a fixed amount Δw after every call to {a mathematical formula}ARA⁎-ImproveSolution (line 11 in Algorithm 3).</paragraph><paragraph>{a mathematical formula}ARA⁎-ImproveSolution, listed in Algorithm 4, is a variant of {a mathematical formula}WA⁎, expanding the node {a mathematical formula}n∈OPEN with minimal {a mathematical formula}fw(n)=g(n)+w⋅h(n). It terminates either when an improved solution is found (line 10 in Algorithm 4), or when {a mathematical formula}G≤minn∈OPEN{fw(n)} (line 4 in Algorithm 4), in which case the incumbent solution is proven to be w-suboptimal [6]. An open challenge that we address next is how to set the value of {a mathematical formula}ARA⁎'s parameters ({a mathematical formula}w0 and Δw) intelligently.</paragraph><paragraph>A property of a good anytime algorithm is that it finds an initial solution as soon as possible, so that a solution can be returned even if little time is available. In general, the higher w is, the greedier the search is and the sooner a solution will be found. Therefore, ideally, {a mathematical formula}w0 would be set to ∞. However, setting {a mathematical formula}w0=∞ is not possible in {a mathematical formula}ARA⁎, as w is later decreased with finite steps (line 11 in Algorithm 3). For that reason, in {a mathematical formula}ARA⁎w is initialized with a finite value {a mathematical formula}w0.</paragraph><paragraph>A second desirable property of an anytime algorithm is to reduce the time spent between improvements of the solution, such that when the incumbent solution is requested, the least amount of time has been spent in vain. The amount Δw by which w is decreased should therefore be as small as possible (this is also argued in [6]). However, if w is decreased by too little, the subsequent iteration of {a mathematical formula}ARA⁎-ImproveSolution might not expand a single node. This is because {a mathematical formula}ARA⁎-ImproveSolution returns when {a mathematical formula}minn∈OPEN{fw(n)}&gt;G (line 4 in Algorithm 4). If w is hardly decreased in the next iteration, it might still be the case that {a mathematical formula}minn∈OPEN{fw(n)}&gt;G.</paragraph><paragraph>So, what is the maximal value of w for which at least one node can be expanded? That is when{a mathematical formula} which follows from the fact that{a mathematical formula} The one node that can then be expanded is indeed the node {a mathematical formula}n∈OPEN with a maximal value of {a mathematical formula}u(n). This is precisely the node that {a mathematical formula}APTS/ANA⁎ expands.</paragraph><paragraph>One could imagine an adapted version of {a mathematical formula}ARA⁎ that uses Eq. (1) to set w after each iteration of {a mathematical formula}ARA⁎-ImproveSolution. This would also allow initializing w to ∞ for the first iteration, as is done in {a mathematical formula}APTS/ANA⁎. However, even such a variation of {a mathematical formula}ARA⁎ is not maximally greedy to find an improved solution, as explained next. Assume that {a mathematical formula}ARA⁎-ImproveSolution is called with {a mathematical formula}w=maxn∈OPEN{u(n)}, and let {a mathematical formula}wˆ denote this specific value of w. In {a mathematical formula}ARA⁎, the value of w is fixed throughout a call to {a mathematical formula}ARA⁎-ImproveSolution. However, during an {a mathematical formula}ARA⁎-ImproveSolution call a node n might be generated for which {a mathematical formula}fwˆ(n)&lt;G. If {a mathematical formula}fwˆ(n)&lt;G, then node n could have been expanded if w was increased even further (up to {a mathematical formula}u(n)). A higher w corresponds to a greedier search, so instead one could always maximize w such that there is at least one node {a mathematical formula}n∈OPEN for which {a mathematical formula}fw(n)≤G. This is equivalent to what {a mathematical formula}APTS/ANA⁎ does, by continually expanding the node {a mathematical formula}n∈OPEN with a maximal value of {a mathematical formula}u(n). Thus, {a mathematical formula}APTS/ANA⁎ can be derived as non-parametric tuning of w, such that the search is as greedy as possible, but still has nodes that can be expanded with {a mathematical formula}fw smaller than G.</paragraph><paragraph>Additionally, every time w is changed in {a mathematical formula}ARA⁎, all the nodes in OPEN must be reordered to account for the new w value (line 12 in Algorithm 3). w is updated not only when a new solution is found, but also when the incumbent solution is proven to be w-suboptimal (line 4 in Algorithm 4). Reordering all the nodes in OPEN takes {a mathematical formula}O(|OPEN|) time, which can be very large.{sup:12} Thus, an additional benefit of {a mathematical formula}APTS/ANA⁎ over {a mathematical formula}ARA⁎ is that OPEN needs to be reordered only when a new solution is found.</paragraph></section><section label="4.4">Suboptimality bounds of {a mathematical formula}APTS/ANA⁎<paragraph label="Proof">Consider the case where h is an admissible heuristic. In this case there is a strong relation between the u-value of the node expanded by {a mathematical formula}APTS/ANA⁎ and the suboptimality bound of the incumbent solution: each time a node n is selected for expansion by {a mathematical formula}APTS/ANA⁎, {a mathematical formula}u(n) bounds the suboptimality of the incumbent solution. We prove this theorem below. We use {a mathematical formula}G⁎ to denote the cost of an optimal solution, so {a mathematical formula}GG⁎ is the true suboptimality of the incumbent solution. {a mathematical formula}g⁎(n) denotes the cost of an optimal path between the start state and n. If{a mathematical formula}h(n)is admissible then{a mathematical formula}maxn∈OPEN{u(n)}≥GG⁎. In other words, if a node n is selected by{a mathematical formula}APTS/ANA⁎for expansion, then{a mathematical formula}u(n)is an upper bound on the suboptimality of the current solution.{a mathematical formula}APTS/ANA⁎ prunes any node n with {a mathematical formula}g(n)+h(n)≥G. Thus, for every node n in OPEN it holds that:{a mathematical formula} Hence, all the nodes in OPEN have {a mathematical formula}u(n)≥1. Thus, Theorem 2 holds trivially if the current solution is optimal. If an optimal solution has not yet been found, there must be a node {a mathematical formula}n′∈OPEN that is on an optimal path to a goal and whose g value is optimal, i.e., {a mathematical formula}g(n′)=g⁎(n′) (see Lemma 1 in [1]). The minimal cost to move from {a mathematical formula}n′ to the goal is {a mathematical formula}G⁎−g⁎(n′), since {a mathematical formula}n′ is on an optimal path to a goal. As the heuristic is admissible, {a mathematical formula}h(n′)≤G⁎−g⁎(n′). Therefore:{a mathematical formula} where the last inequality follows as {a mathematical formula}G&gt;G⁎≥g⁎(n′)≥0. As a result,{a mathematical formula}  □</paragraph><paragraph>Theorem 2 provides an interesting view on how {a mathematical formula}APTS/ANA⁎ behaves. The suboptimality bound is given by the maximum value of {a mathematical formula}u(⋅), and {a mathematical formula}APTS/ANA⁎ always expands that node. Thus, {a mathematical formula}APTS/ANA⁎ can be viewed as an informed effort to gradually decrease the suboptimality bound of the incumbent solution. Of course, the children of the expanded node n may have a larger {a mathematical formula}u(⋅) value than n, in which case {a mathematical formula}maxn∈OPEN{u(n)} may even increase, resulting in a worse bound than before the node expansion. This can be overcome by maintaining the best (i.e., the lowest) suboptimality bound seen so far.</paragraph><paragraph>Note that this suboptimality bound is available when running {a mathematical formula}APTS/ANA⁎ with almost no additional overhead. Previous approaches to provide a suboptimality bound to an anytime search algorithm used {a mathematical formula}fmin=minn∈OPENg(n)+h(n). Given {a mathematical formula}fmin the suboptimality of the incumbent solution is at most {a mathematical formula}Gfmin. While this bound can be shown to be tighter than the bound provided by {a mathematical formula}u(⋅), calculating it required maintaining {a mathematical formula}fmin, which requires an additional priority queue that is ordered by {a mathematical formula}g(n)+h(n), while {a mathematical formula}APTS/ANA⁎ uses only a single priority queue.{sup:13}</paragraph><paragraph>In summary, {a mathematical formula}APTS/ANA⁎ improves on {a mathematical formula}ARA⁎ in five ways: (1) {a mathematical formula}APTS/ANA⁎ does not require parameters to be set; (2) {a mathematical formula}APTS/ANA⁎ is maximally greedy to find an initial solution; (3) {a mathematical formula}APTS/ANA⁎ is maximally greedy to improve the incumbent solution; (4) {a mathematical formula}APTS/ANA⁎ only needs to update the keys of the nodes in OPEN when an improved solution is found; and (5) {a mathematical formula}APTS/ANA⁎ makes an informed effort to gradually decrease the suboptimality bound.</paragraph></section><section label="4.5">Limitations of {a mathematical formula}APTS/ANA⁎<paragraph>While {a mathematical formula}APTS/ANA⁎ has all the attractive properties listed above, it also has some limitations. Since {a mathematical formula}APTS/ANA⁎ runs a sequence of PTS calls, all the limitations described for PTS in Section 3.5 apply also to {a mathematical formula}APTS/ANA⁎. In addition, {a mathematical formula}APTS/ANA⁎ has two further limitations:</paragraph><section label="4.5.1"><section-title>Finding the initial solution</section-title><paragraph>If the heuristic is inaccurate and there are not many goals, finding even a single, unbounded solution can be hard. As defined above, until the first solution is found, {a mathematical formula}APTS/ANA⁎ runs a pure heuristic search. Thus, {a mathematical formula}APTS/ANA⁎ would be inefficient in domains where pure heuristic search is inefficient. For example, in domains where there is a distance-to-go heuristic ({a mathematical formula}d(n)), a much more effective way to find a solution fast is to search according to {a mathematical formula}d(n) rather than {a mathematical formula}h(n)[46], [39].</paragraph></section><section label="4.5.2"><section-title>Finding too many solutions</section-title><paragraph>Every time a better solution is found, {a mathematical formula}APTS/ANA⁎ is required to re-sort all the nodes in OPEN (Algorithm 2) to account for the new incumbent solution (the {a mathematical formula}u(⋅) values change). Thus, if there are many solutions, each slightly better than the previous, then {a mathematical formula}APTS/ANA⁎ would suffer from the overhead of re-sorting OPEN every time a new, better, solution is found.</paragraph><paragraph>There are ad hoc solutions to these limitations. Instead of using {a mathematical formula}APTS/ANA⁎ to find the first solution, it is possible to use another algorithm (e.g., Speedy search [46]) to find the first solution and provide it to {a mathematical formula}APTS/ANA⁎ as an initial incumbent solution. Additionally, the bound of the next PTS can be set to be lower than the incumbent solution by some Δ, to avoid finding too many solutions. Such a Δ, however, would be a parameter of the algorithm and setting it raises the parameter tuning problem we aim to avoid.</paragraph></section></section></section><section label="5"><section-title>Experimental results</section-title><paragraph>In this section we empirically evaluate the performance of PTS as a bounded-cost search algorithm, and {a mathematical formula}APTS/ANA⁎ as an anytime search algorithm. This is done over a range of domains: 15-puzzle, KPP-COM, robot arm, grid world planning and multiple sequence alignment (MSA). Next, we describe the domains used in our experiments.</paragraph><section label="5.1"><section-title>Domains</section-title><paragraph>For every domain, we provide the domain details (what is a state etc.), the heuristic function used, and how the problem instances were generated.</paragraph><section label="5.1.1"><section-title>The 15-puzzle</section-title><paragraph>The 15-puzzle is a very well-known puzzle that consists of 15 numbered tiles that can be moved in a {a mathematical formula}4×4 grid. There is one blank location in the grid. The blank can be swapped with an adjacent tile. The left part of Fig. 3 shows the goal state that we used for the 15-puzzle while the right part shows a state created from the goal state by applying two operators, namely swapping the blank with tile 1 and then swapping it with tile 5. The number of states reachable from any given state is {a mathematical formula}(42)!/2[47]. The task is to find a short path from a given starting state to the goal state. The 15-puzzle is a common search benchmark [2], [15], [36], [48], [49].</paragraph><paragraph>There are many advanced heuristics for the 15-puzzle. In the experiments below we chose the simple Manhattan Distance heuristic (MD) because our goal is to compare search algorithms and not different heuristics. The experiments were performed on Korf's standard 100 random 15-puzzle instances [2].</paragraph></section><section label="5.1.2"><section-title>Key Player Problem in Communication (KPP-COM)</section-title><paragraph>The Key Player Problem in Communication (KPP-COM) is the problem of finding a set of k nodes in a graph with the highest Group Betweenness Centrality (GBC). GBC is a metric for centrality of a group of nodes [50]. It is a generalization of the betweenness metric, which measures the centrality of a node with respect to the number of shortest paths that pass through it [51]. Formally, the betweenness of a node n is {a mathematical formula}Cb(n)=∑s,t∈Vs,t≠nσst(n)σst, where {a mathematical formula}σst is the number of shortest paths between s and t and {a mathematical formula}σst(n) is the number of shortest paths between s and t that pass through n. The betweenness of a group of nodes A, termed group betweenness, is defined as {a mathematical formula}Cb(A)=∑s,t∈V∖Aσst(A)σst, where {a mathematical formula}σst(A) is the number of shortest paths between s and t that pass through at least one of the nodes in A.</paragraph><paragraph>KPP-COM is known to be NP-Hard [52]. It has important network security applications, such as optimizing the deployment of intrusion detection devices [53]. KPP-COM can be solved as a search problem. Let {a mathematical formula}G=(V,E) be the input graph in which we are searching for a group of k vertices with the highest GBC. A state in the search space consists of a set of vertices {a mathematical formula}N⊆V, {a mathematical formula}|N|≤k. N is considered as a candidate to be the group of vertices with the highest GBC. The initial state of the search is an empty set, and each child of a state corresponds to adding a single vertex to the set of vertices of the parent state. Every state has a value, which is the GBC of the set of vertices it contains. While the goal in the previous domain (the 15-puzzle) is to find a solution of minimal cost, the goal in KPP-COM is to find a solution with maximum value. We call problems of the former type MAX problems and problems of the latter type MIN problems. An admissible heuristic for MAX problems is required to be an upper bound on the optimal value. Similarly, a suboptimal solution is one with a smaller value than the optimal solution.</paragraph><paragraph>A number of efficient admissible (overestimating) heuristics for this problem exist [52] and in our experiments we used the best one, calculated as follows. Consider a state consisting of a set of m vertices {a mathematical formula}Vm. First, the contribution of every individual vertex {a mathematical formula}v∈V∖Vm is calculated. This is the {a mathematical formula}Cb(Vm∪{v})−Cb(Vm). Then, the contribution of the topmost {a mathematical formula}k−m vertices is summed and used as an admissible heuristic, where k is the total number of vertices that needs to be selected (see [52] for a more detailed discussion about this heuristic).</paragraph><paragraph>Since the main motivation for the KPP-COM problem is in communication network domains, all our experiments were performed on graphs generated by the Barabási–Albert model [54]. This random graph model is a well-used model of Internet topology and the web graph, which accepts two parameters: the number of vertices in the graph and a density factor. We have experimented with a variety of graph sizes and density factor values, and present the average results over 25 graphs with 600 vertices with a density factor of 2. Additionally, we have limited the size of the searched group of vertices to be 20 (i.e., {a mathematical formula}k=20).</paragraph></section><section label="5.1.3"><section-title>Robot arm</section-title><paragraph>The robot arm domain is taken from Maxim Likhachev's publicly available SBPL library (http://www.sbpl.net). This problem illustrates the performance of the proposed algorithms in a domain with a high branching factor and few duplicate states.</paragraph><paragraph>We consider both a 6 degrees of freedom (DoF) arm and a 20 DoF arm with a fixed base in a 2D environment with obstacles, shown in Fig. 4. The objective is to move the end-effector from its initial location to a goal location while avoiding obstacles. An action is defined as a change of the global angle of any particular joint (i.e., the angle with respect to a fixed initial point) having the next joint further along the arm rotate in the opposite direction to maintain the global angle of the remaining joints. All actions have the same cost.</paragraph><paragraph>The environment is discretized into a {a mathematical formula}50×50 2D grid. The heuristic is calculated as the shortest distance from the current location of the end-effector to the goal location that avoids obstacles. To avoid having the heuristic overestimate true costs, joint angles are discretized so as to never move the end-effector by more than one cell on the {a mathematical formula}50×50 grid in a single action. Note that the size of the state space for this domain is 10{sup:9} states for the 6 DoF robot arm and more than 10{sup:26} states for the 20 DoF robot arm.</paragraph></section><section label="5.1.4"><section-title>Gridworld planning</section-title><paragraph>The next domain we considered is that of two planar gridworld path-planning problems with different sizes and numbers of obstacles, also taken from Likhachev's SBPL library. This problem illustrates the performance of the algorithms in a domain with many transpositions and a relatively small branching factor. We set the start state as the cell at the top left corner, and the goal state at the bottom right cell. The first gridworld problem is a {a mathematical formula}100×1200 8-connected grid with obstacles, with unit cost to move between adjacent obstacle-free cells. The second gridworld problem is a {a mathematical formula}5000×5000 4-connected grid in which each transition between adjacent cells is assigned a random cost between 1 and 1000. For the {a mathematical formula}5000×5000 4-connected grid problem with non-unit edge cost, we considered two cases, one with obstacles and one without.</paragraph></section><section label="5.1.5"><section-title>Multiple sequence alignment (MSA)</section-title><paragraph>Our final domain is the MSA problem. The uniqueness of this domain (in comparison to the domains above) is its high branching factor and non-uniform edge costs (i.e., costs of different edges may vary).</paragraph><paragraph>MSA is a central problem for computational molecular biology when attempting to measure similarity between a set of sequences [55]. The input to MSA is a set of sequences of items (e.g., gene or protein sequences). Every sequence is mapped to an array, while possibly leaving empty spaces. This mapping is referred to as an alignment. Fig. 5 shows an example of an alignment of 8 sequences. Alignments have a cost, according to a biologically motivated interpretation of the alignment. We used the sum-of-pairs cost function, used by many previous works [56], [57], [55]. According to this cost function the alignment cost of k sequences is the sum of the alignment costs of all {a mathematical formula}(k2) pairs of sequences. The alignment cost of a pair of sequences x and y considers the number of matches, gaps and substitutions in the alignment. A match occurs when two identical items (e.g., the same protein) are mapped to the same array index. A gap occurs when only a single sequence is using an index. A substitution occurs when different items are mapped to the same index. The alignment cost we used assigned to every match, gap and substitution a cost of zero, one and two, respectively.</paragraph><paragraph>MSA can be formalized as a shortest-path problem in an n-dimensional lattice, where n is the number of sequences to be aligned [58]. A state is a (possibly partial) alignment represented by the items aligned so far from each sequence. A goal is reached when all the characters in all the sequences are aligned. A move in the search space assigns a specific index to an item in one or more sequences. The cost of a move is computed as the cost of the partial alignment. The MSA problem instances we experimented with consist of five dissimilar protein sequences obtained from [59] and [60]. The heuristic is based on summing the optimal pairwise alignments, which were precomputed by dynamic programming [60].</paragraph></section></section><section label="5.2"><section-title>Bounded-cost experiments</section-title><paragraph>In this section we empirically evaluate the performance of PTS. In every experiment, the cost bound C was set, and PTS and the competing algorithms were run until a solution with cost lower than C was found. This was repeated for a range of cost bounds (i.e., a range of C values). In domains where instances could be solved optimally in reasonable time, we chose the range of C values to cover bounds close to the average optimal solution as well as substantially higher bounds. In domains where solving instances optimally was not feasible, we chose the cost bounds that were solvable by the compared algorithms in reasonable time. The performance of the various algorithms was measured in runtime.</paragraph><paragraph>We compared PTS against a range of existing anytime search algorithms: {a mathematical formula}AWA⁎[22], {a mathematical formula}ARA⁎[6] and DFBnB [23]. To make the comparison to PTS fair, we also modified these anytime algorithms to prune every node n with {a mathematical formula}g(n)+h(n) larger than the cost bound, as is done for PTS (line 12 in Algorithm 1). Thus, DFBnB can also be viewed as a depth-first search with node pruning, where nodes with {a mathematical formula}g(n)+h(n) larger than the cost bound are pruned.</paragraph><paragraph>Different anytime search algorithms performed differently, and in the rest of this section we only show results of the best performing anytime search algorithms for every domain. Table 1 lists the best performing algorithms for every domain. For KPP-COM, these were {a mathematical formula}AWA⁎ and DFBnB. The effectiveness of DFBnB in KPP-COM was not surprising, as DFBnB is known to be effective when the depth of the solution is known in advance (in KPP-COM this is k, the size of the searched group) [61], [62]. This was also confirmed in our KPP-COM experiments and in previous work [52]. DFBnB is less effective in other domains, where the depth of the search tree varies and there are many cycles. The relative performance of {a mathematical formula}AWA⁎ and {a mathematical formula}ARA⁎ varies between domains. Our experiments showed that {a mathematical formula}AWA⁎ outperformed {a mathematical formula}ARA⁎ in the 15-puzzle (previous work showed this in the 8-puzzle domain [22]), while {a mathematical formula}ARA⁎ performed better in all other domains.{sup:14} Both {a mathematical formula}ARA⁎ and {a mathematical formula}AWA⁎ are parametric algorithms. We experimented with a range of parameters and show the results of the best performing parameter settings we found.</paragraph><paragraph>Table 2 displays the results for the 15-puzzle domain. Results in this domain are traditionally shown in terms of nodes expanded, to avoid comparing implementation details. Therefore, in addition to comparing the runtime of each algorithm we also measured the number of nodes expanded. The number of nodes expanded is given in Table 2 as the percentage of nodes expanded with respect to the number of nodes expanded by {a mathematical formula}A⁎ until an optimal solution is found. Runtime is shown in the same table in brackets, and measured in milliseconds. The best performing algorithm for every cost bound is marked in bold.</paragraph><paragraph>Results clearly show a drastic reduction in the size of the searched state space (yielding a substantial speedup) over trying to find an optimal solution. For example, PTS can find a solution under a cost bound of 70 by expanding on average only 5% of the nodes that will be expanded by {a mathematical formula}A⁎ to find an optimal solution.</paragraph><paragraph>In addition, we see that PTS performs best for the vast majority of cost bounds. PTS also performs relatively well even for the few cost bounds where it is not the best performing algorithm. We can also see the large impact of the w parameter on the performance of {a mathematical formula}AWA⁎. For example, for cost bound 65, {a mathematical formula}AWA⁎ with {a mathematical formula}w=3 performed more than 9 times worse than {a mathematical formula}AWA⁎ with {a mathematical formula}w=2. This emphasizes the robustness of PTS, which does not require any parameter.</paragraph><paragraph>Due to implementation details, there was not a perfect correlation between the number of nodes expanded by an algorithm and its runtime, as part of the runtime is used to allocate memory for the required data structures and other algorithm initialization processes. Nonetheless, similar trends as those noted above can also be seen for runtime (these are the values in brackets in Table 2).</paragraph><paragraph>Deeper inspection of the results shows that for the lowest cost bound (55), PTS is outperformed by {a mathematical formula}AWA⁎ with {a mathematical formula}w=1.5. The average cost of an optimal solution for the 15-puzzle instances we experimented with is 52. This suggests that PTS might be less effective for cost bounds that are close to the optimal solution cost. In such cases, a more conservative {a mathematical formula}A⁎-like behavior, exhibited by {a mathematical formula}AWA⁎ with w close to one, might be beneficial, as {a mathematical formula}A⁎ is tuned to find an optimal solution. We observed a similar trend in some of the other domains we experimented with.</paragraph><paragraph>Next, consider the results for KPP-COM, shown in Table 3. Values are runtime in seconds until a solution below the cost bound C was found. Similar trends are observed in this domain: PTS performs best for most cost bounds and the w parameter greatly influences the performance of {a mathematical formula}AWA⁎.</paragraph><paragraph>The differences in performance of PTS, {a mathematical formula}AWA⁎-0.7 and DFBnB are relatively small in this domain. This is because DFBnB is known to be very efficient in this domain [52]. Hence, PTS could not substantially improve over DFBnB. As for {a mathematical formula}AWA⁎-0.7, consider the case where w reaches zero. In such a case, {a mathematical formula}AWA⁎ behaves like uniform cost search, a best–first search using only g to evaluate nodes. In MAX problems with non-negative edge costs, as is the case for KPP-COM, a uniform cost search behaves like DFBnB. Thus, decreasing w towards zero results in {a mathematical formula}AWA⁎ behaving more and more like DFBnB, until eventually converging to DFBnB when {a mathematical formula}w=0. This explains the similar performance of {a mathematical formula}AWA⁎-0.7 and DFBnB.</paragraph><paragraph>Results for the robot arm, gridworld planning, and multiple sequence alignment domains are shown in Table 4, Table 5, Table 6, respectively. PTS's favorable behavior can be viewed across all domains. For example, in the {a mathematical formula}100×1200 gridworld planning domain, PTS is two orders of magnitude faster than {a mathematical formula}ARA⁎ for a cost bound of 1050. Following all the bounded-cost results shown above, we conclude that PTS outperforms the best performing anytime search algorithm for almost all cost bounds and across the entire range of domains we used. Furthermore, PTS exhibits the most robust performance, without any parameter tuning required.</paragraph><section label="5.2.1">The effect of w in MAX problems<paragraph>The KPP-COM results highlight an interesting question – how does the w parameter affect the performance of {a mathematical formula}AWA⁎ for MAX problems? The best performing instance of {a mathematical formula}AWA⁎ in our KPP-COM experiments used {a mathematical formula}w=0.7, the lowest w we experimented with. Thus, one might think that decreasing w has an equivalent effect to increasing w in MIN problems. Indeed, decreasing w for {a mathematical formula}w&gt;1 in MAX problems is similar to increasing w for {a mathematical formula}w&lt;1 in MIN problems – making an admissible heuristic more informed and the search more efficient. In the limit, however, decreasing w in MAX problems and increasing w in MIN problems have completely different effects. As mentioned above, for MAX problems setting {a mathematical formula}w=0 results in {a mathematical formula}AWA⁎ behaving like uniform cost search. For MIN problems, {a mathematical formula}w=∞ results in {a mathematical formula}AWA⁎ behaving like pure heuristic search. Pure heuristic search is expected to find solutions fast but of low quality,{sup:15} while uniform cost search ignores the heuristic completely and is therefore expected to be slower than a search that uses a heuristic. Exploring the effect of w in MAX problems is left for future work.</paragraph></section></section><section label="5.3"><section-title>Anytime experiments</section-title><paragraph>Next, we present experimental results to evaluate the performance of {a mathematical formula}APTS/ANA⁎ on the same range of domains described in Section 5.1. In every experiment, we ran {a mathematical formula}APTS/ANA⁎ and the best-performing anytime search algorithms (different for each domain), and recorded the suboptimality of the incumbent solution as a function of the runtime. In the following figures, {a mathematical formula}ARA⁎(X) will denote {a mathematical formula}ARA⁎ using {a mathematical formula}w0=X ({a mathematical formula}w0 is the initial value of w used by {a mathematical formula}ARA⁎; see Section 2.3).</paragraph><paragraph>First, consider the results for the 6 DoF robot arm experiments, shown in Fig. 6(a). The y-axis shows the reported suboptimality, where 1 corresponds to a solution that is optimal. The x-axis shows the runtime in seconds. The benefits of {a mathematical formula}APTS/ANA⁎ in this domain are very clear. {a mathematical formula}APTS/ANA⁎ dominates all other algorithms throughout the search. Although not visible in the figure, we also report that {a mathematical formula}APTS/ANA⁎ found an initial solution faster than {a mathematical formula}ARA⁎.</paragraph><paragraph>Next, consider the performance of {a mathematical formula}APTS/ANA⁎ in the 20 DoF robot arm experiments, shown in Fig. 6(b). In this domain {a mathematical formula}APTS/ANA⁎ is not always the best performing algorithm. For some weights and time ranges, {a mathematical formula}ARA⁎ is able to find solutions of better quality. However, the rapid convergence of {a mathematical formula}APTS/ANA⁎ towards an optimal solution and consistent decrease in suboptimality are very clear in this domain, demonstrating the anytime behavior of {a mathematical formula}APTS/ANA⁎. As in the 6 DoF experiments, in this domain too {a mathematical formula}APTS/ANA⁎ found an initial solution faster than all other algorithms.</paragraph><paragraph>The above robot arm results are for a single but representative instance. We also experimented on a set of randomly generated 6 DoF and 20 DoF robot arm instances (20 instances each) showing, in general, very similar trends. As an aggregated view showing the relative anytime performance of {a mathematical formula}APTS/ANA⁎ with respect to the other algorithms, we also analyzed which was the most effective algorithm throughout the search. This was measured by counting for every algorithm A and every millisecond t, the number of problem instance where the incumbent solution found by A after running t milliseconds is smaller than or equal to the incumbent solution found by all other algorithms after running t milliseconds. This measures the number of instances where algorithm A was the best algorithm if halted after t milliseconds. Fig. 7 shows the results of this analysis, where the x-axis is the runtime (in milliseconds) and the y-axis is the number of instances where each algorithm was best. For both 20 DoF (left) and 6 DoF (right), the results clearly show that {a mathematical formula}APTS/ANA⁎ is the best performing algorithm throughout the search for the majority of problem instances.</paragraph><paragraph>The results for the MSA domain, shown in Fig. 8, show that {a mathematical formula}APTS/ANA⁎ (as in the 6 DoF robot arm) dominates all other algorithms throughout the search. For both robot arm and MSA experiments, {a mathematical formula}APTS/ANA⁎ has the largest number of steps in its decrease to a lower suboptimality. Correspondingly, the time between solution improvements is smaller. For example, in the MSA experiments, {a mathematical formula}APTS/ANA⁎ spent an average of 18 s between solution improvements, while in the best run of {a mathematical formula}ARA⁎, it took 200 s on average to find a better solution. As discussed in Section 4, this is intuitively a desirable property of an anytime algorithm.</paragraph><paragraph>Next, consider the results for the gridworld domain, given in Fig. 9, Fig. 10. For the {a mathematical formula}100×1200 grid with unit edge cost experiments (Fig. 9) and the {a mathematical formula}5000×5000 grid with random edge cost experiments (Fig. 10(a)), {a mathematical formula}APTS/ANA⁎ dominates all other algorithms throughout the search. However, the results for the {a mathematical formula}5000×5000 domain with obstacles (Fig. 10(b)) show a different behavior: after 30 seconds of runtime, {a mathematical formula}ARA⁎ with {a mathematical formula}w0=500 returned solutions of lower cost than the solutions returned by APTS. While not shown in the figure, we report that {a mathematical formula}APTS/ANA⁎ required an additional 193 s to find a solution of the same cost as this {a mathematical formula}ARA⁎ instance.</paragraph><paragraph>Note that the performance of {a mathematical formula}ARA⁎ varied greatly with the value of {a mathematical formula}w0 in all the domains we experimented with. For the {a mathematical formula}5000×5000 gridworld with no obstacles, {a mathematical formula}w0=30 is the best {a mathematical formula}w0 value of those tested, while for the {a mathematical formula}5000×5000 gridworld with obstacles {a mathematical formula}w0=500 is the best {a mathematical formula}w0 value. The challenge of tuning {a mathematical formula}w0 in {a mathematical formula}ARA⁎ is especially evident in the {a mathematical formula}100×1200 gridworld experiment (seen in Fig. 9). The disparity in the {a mathematical formula}ARA⁎ results for different values of {a mathematical formula}w0 illustrates a non-linear relationship between {a mathematical formula}w0 and {a mathematical formula}ARA⁎'s performance. This emphasizes that setting this value is non-trivial, as a higher or lower {a mathematical formula}w0 value does not necessarily guarantee better or worse performance. Thus, even if for some problem instances {a mathematical formula}ARA⁎ with some parameter settings outperforms {a mathematical formula}APTS/ANA⁎, {a mathematical formula}APTS/ANA⁎ still has the benefit of not depending on any parameter.</paragraph><paragraph>Next, consider the results for the KPP-COM domain, seen in Fig. 11(a). The y-axis denotes the suboptimality of the incumbent solution as a function of the computation time, shown on the x-axis. Since KPP-COM is a MAX problem, the suboptimality starts very close to zero and converges to one from below when an optimal solution is found.</paragraph><paragraph>The results in Fig. 11(a) clearly show that in this domain as well, {a mathematical formula}APTS/ANA⁎ performs consistently no worse and often better than the other algorithms. As discussed in Section 5.2, DFBnB is known to be highly effective in this domain [52]. Indeed, the results of {a mathematical formula}APTS/ANA⁎ and DFBnB are almost identical, with a slight advantage for {a mathematical formula}APTS/ANA⁎ when the runtime was more than 5 seconds.</paragraph><paragraph>Negative results for {a mathematical formula}APTS/ANA⁎ were obtained for the 15-puzzle domain, shown in Fig. 11(b). Running {a mathematical formula}APTS/ANA⁎ yielded worse results than {a mathematical formula}AWA⁎ with a tuned w value ({a mathematical formula}w=2). This is because, as explained in Section 4, {a mathematical formula}APTS/ANA⁎ runs pure heuristic search until it finds the initial solution. In many domains, including all those described above, this results in finding an initial solution very fast. With proper tie-breaking, this is also the case for the 15-puzzle domain. The quality of this initial solution, however, is very poor. Thus, {a mathematical formula}APTS/ANA⁎ wastes a significant amount of time improving solutions that have very high suboptimality, until it converges to an optimal solution. By contrast, the initial solution found by {a mathematical formula}AWA⁎ with {a mathematical formula}w=2 ({a mathematical formula}AWA⁎-2.0 in Fig. 11(b)) has a suboptimality of at most 2, and can be found relatively easily in this domain.</paragraph><paragraph>As a partial remedy for this problem, we tried first running {a mathematical formula}WA⁎ with different weights and then giving {a mathematical formula}APTS/ANA⁎ the initial solution, after which it continues to run as usual. Results show that this {a mathematical formula}APTS/ANA⁎ variant performed the same as the best performing anytime search algorithm for this domain.</paragraph><paragraph>To summarize, on all the domains except the 15-puzzle, {a mathematical formula}APTS/ANA⁎ was competitive, and in most cases significantly better than existing anytime search algorithms in that: (1) {a mathematical formula}APTS/ANA⁎ finds an initial solution faster, (2) {a mathematical formula}APTS/ANA⁎ improves the incumbent solution faster and more often, and (3) {a mathematical formula}APTS/ANA⁎ converges faster to solutions of higher quality. Moreover, in all of the domains we experimented with, we found that the performance of existing parametric anytime search algorithms is greatly affected by the parameter values. By contrast, {a mathematical formula}APTS/ANA⁎ does not require any parameters to be set, and still manages to outperform existing anytime algorithms.</paragraph></section></section><section label="6"><section-title>Generalized Potential Search (GPTS)</section-title><paragraph>In Section 3 we presented the PTS algorithm, and showed that under the linear-relative assumption PTS always expands the node with the highest potential (Theorem 1). In this section we generalize PTS to cases where this assumption does not hold. We call the resulting algorithm General Potential Search (GPTS) – a search algorithm that always expands the node with the highest potential.</paragraph><paragraph label="Definition 3">GPTS can be implemented as a BFS with an evaluation function that orders nodes according to their potential (denoted earlier in this paper as {a mathematical formula}PTh,C). We call such an evaluation function a Potential Ordering Function (POF). Potential Ordering Function (POF)A function F is called a Potential Ordering Function (POF) if for any pair of nodes {a mathematical formula}n1 and {a mathematical formula}n2, we have that{a mathematical formula}</paragraph><paragraph>Of course, {a mathematical formula}PTh,C itself is a trivial POF. Calculating {a mathematical formula}PTh,C, however, may be non-trivial. Next, we propose practical POFs for a wide range of domains that do not require calculating {a mathematical formula}PTh,C for any node. This suggests the applicability of GPTS.</paragraph><paragraph label="Definition 4">As a preliminary, we provide a more rigorous definition of the potential than given in Definition 2. Let {a mathematical formula}S be the searched state space, and let {a mathematical formula}D be a probability distribution over the nodes in {a mathematical formula}S. S denotes a random variable corresponding to a state from {a mathematical formula}S randomly drawn according to distribution {a mathematical formula}D. We denote by {a mathematical formula}Pr(h⁎(S)=X|h(S)=Y) the probability that X is the cost of the lowest cost path to a goal from a random state S with heuristic value Y. The potential of a node n is defined as the probability that a random state S with the same h value as node n will have a path to a goal of cost lower than {a mathematical formula}C−g(n). We next define this formally. PotentialGiven a heuristic function h and a cost bound C, we define the potential of node n, denoted {a mathematical formula}PTh,C(n), as{a mathematical formula}</paragraph><paragraph label="Definition 5">The potential of a node, as defined above, depends on the relation between {a mathematical formula}h(⋅) and {a mathematical formula}h⁎(⋅). We formalize this h-to-{a mathematical formula}h⁎ relation by introducing the notion of a heuristic model, or h-model in short. An h-model of a heuristic function is a function that captures the probabilistic relation between a heuristic and the lowest cost path to the goal that it estimates. h-ModelA function {a mathematical formula}e(⋅) is said to be an h-model of a heuristic function h, if for every h-value v of the heuristic function, and every {a mathematical formula}h⁎-value K of a state in the state space,{a mathematical formula}</paragraph><paragraph>Domains with the linear-relative assumption (described in Section 3) are simply domains with an h-model {a mathematical formula}e(v)=X⋅v, where X is a random independent identically distributed (i.i.d.) variable. Correspondingly, we call this type of h-model the linear-relative h-model. Using this notation, Lemma 1 (given in Section 3) states that the PTS evaluation function {a mathematical formula}u(n)=C−g(n)h(n) is a POF for the linear-relative h-model. Next, we describe POFs for other h-models.</paragraph><section label="6.1">Additive h-model<paragraph>Consider the following h-model: {a mathematical formula}e(v)=v+X, where X is an i.i.d. random variable. This does not imply that the distribution of X is uniform, but just that the additive error of every node is taken from the same distribution (independently). We call such an h-model an additive h-model.{sup:16}</paragraph><paragraph label="Proof">If the distribution of X is known, no non-trivial POF is required, as the potential can be easily calculated:{a mathematical formula} For example, in the special case where X is a constant K, the potential of a node is a simple binary function:{a mathematical formula} If the distribution of X is not known, then directly computing {a mathematical formula}PTh,C is impossible. Next, we show that even if the distribution of X is unknown, it is still possible to have a POF. Corollary 1 presents a theoretical POF that applies to any given h-model. {a mathematical formula}FC(n)=Pr(e(h(n))&lt;C−g(n))is a POF.For any pair of nodes {a mathematical formula}n1,n2, if {a mathematical formula}PTh,C(n1)≥PTh,C(n2) then:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} Proving the reverse direction is straightforward, and thus {a mathematical formula}FC is a POF.  □</paragraph><paragraph label="Proof">Using the POF given in Corollary 1 requires calculating {a mathematical formula}FC(n)=Pr(e(h(n))&lt;C−g(n)). For an additive h-model, {a mathematical formula}FC(n) still depends on X, since {a mathematical formula}e(h(n))=h(n)+X. Theorem 3 provides an applicable POF that does not depend on X. If the h-model is additive then{a mathematical formula}−f(n)=−(g(n)+h(n))is a POF.For any pair of nodes {a mathematical formula}n1,n2, if {a mathematical formula}PTh,C(n1)≥PTh,C(n2) then:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} The reverse direction is straightforward.  □</paragraph><paragraph>A direct result of Theorem 3 is that for an additive h-model, GPTS and {a mathematical formula}A⁎ expand nodes in the same order.</paragraph></section><section label="6.2">General h-model<paragraph label="Proof">Consider the more general case, where the h-model {a mathematical formula}e(v) is an algebraic combination of v and a random i.i.d. variable X. We overload the function e to describe this algebraic combination, and write {a mathematical formula}e(v)=e(v,X). Note that this model generalizes the previously discussed h-models. Let {a mathematical formula}er be the inverse function of e such that {a mathematical formula}er(e(v),v)=X. We denote an h-model as invertible if such an inverse function {a mathematical formula}er exists. Theorem 4 shows that if the h-model is invertible and {a mathematical formula}er is monotonic, then {a mathematical formula}Pgen(n)=er(C−g(n),h(n)) is a POF. For any i.i.d. random variable X and invertible h-model{a mathematical formula}e(v)=e(v,X), if{a mathematical formula}eris monotonic then{a mathematical formula}Pgenis a POF.For any pair of nodes {a mathematical formula}n1,n2, if {a mathematical formula}PTh,C(n1)≥PTh,C(n2) then according to Corollary 1:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} The reverse direction is straightforward.  □</paragraph><paragraph>Notice that Lemma 1 and Theorem 3 are special cases of Theorem 4. Table 7 presents a few examples of how Theorem 4 can be used to obtain corresponding POFs for various h-models.</paragraph><paragraph>The exact h-model is domain and heuristic dependent. Analyzing a heuristic in a given domain and identifying its h-model may be done analytically in some domains with explicit knowledge about the domain. Another option for identifying an h-model is to add a preprocessing stage in which a set of problem instances are solved optimally, and the h-model is discovered using curve fitting methods. In our experiments, we found the linear-relative h-model to be sufficiently accurate and saw no justification for using more complex h-models. This option is given since such cases may theoretically exist.</paragraph></section></section><section label="7"><section-title>Conclusions and future work</section-title><paragraph>This paper discussed two search problems: bounded-cost search, and anytime search. In a bounded-cost search, once a solution of cost lower than a given cost is found, the search can halt. In an anytime search, the search continues, returning better and better solutions until the search is either halted by the user, or until an optimal solution has been found. Both types of problems have important applications and this paper presents PTS and {a mathematical formula}APTS/ANA⁎ to solve them.</paragraph><paragraph>We showed that an efficient bounded-cost search algorithm can be easily converted to an efficient anytime search algorithm. This is done by running the bounded-cost search algorithm iteratively, giving the bounded-cost search algorithm a lower cost bound in every iteration. An attractive property of the resulting algorithm is that there is no need for parameter tuning, in contrast to most common anytime search algorithms.</paragraph><paragraph>The relation between bounded-cost and anytime search problems emphasizes the need for an efficient bounded-cost search algorithm. In this paper we propose such an algorithm, called PTS. PTS is a best–first search that expands nodes in order of their potential, which is the probability that a node will lead to a solution under the cost bound. The relation between a given heuristic and the optimal cost is used to develop a cost function that can order the nodes in OPEN approximately according to their potential, without actually calculating it. Both PTS and its corresponding anytime algorithm {a mathematical formula}APTS/ANA⁎ outperform competitive algorithms on a wide range of domains.</paragraph><section label="7.1"><section-title>BEES, BEEPS, AEES, and incorporating distance estimates</section-title><paragraph>The heuristic {a mathematical formula}h(⋅) estimates the minimum cost of reaching a goal. Recent work has shown that in domains with non-unit edge cost, {a mathematical formula}h(⋅) may not be correlated with the number of actions needed to reach a goal [39]. In such cases, prior work has shown that it is very beneficial to incorporate into the search algorithm an additional heuristic that estimates the minimum actions needed to reaching a goal [46]. Such a “distance” heuristic, commonly denoted as {a mathematical formula}d(⋅), together with an online learned inadmissible heuristic {a mathematical formula}hˆ(⋅), has been used in a new suboptimal search algorithm called EES [20], a new anytime search algorithm called AEES [63] and a new bounded-cost search algorithm called BEES [40].</paragraph><paragraph>BEES was shown to outperform PTS in domains with non-unit edge costs, including “Zenotravel” and “Elevators”, two domains from the International Planning Competition (IPC) that were solved with a domain independent planner. Follow up work showed that in several other IPC benchmarks with non-unit edge cost, PTS can even be outperformed by a pure heuristic search [34]. Similar results appear when comparing AEES to {a mathematical formula}APTS/ANA⁎[63].</paragraph><paragraph>However, PTS is competitive with BEES in domains with unit edge costs. See the results for the Tiles domain (which is the 15-puzzle) [40] and Tinybot domain [34], which were the only unit edge-cost domains they experimented with.{sup:17} When PTS is as good as BEES, one would probably prefer using PTS since implementing it is much simpler: BEES requires maintaining at least two open lists as well as online learning an improved heuristic, while PTS is a simple best–first search algorithm with an easy to compute evaluation function. Similar reasoning applies for comparing {a mathematical formula}APTS/ANA⁎ and AEES.</paragraph><paragraph>This emphasizes the need for PTS to consider {a mathematical formula}d(⋅) in domains with non-unit edge cost. A first attempt to do so was in the BEEPS algorithm [63], which is equivalent to BEES except for using the PTS evaluation function when all nodes in OPEN are estimated to be above the bound. Empirically, this combination of BEES and PTS performed almost exactly like BEES. Thus, incorporating {a mathematical formula}d(⋅) into PTS in an effective manner is still an open challenge. A possible direction for doing this is by considering explicitly the probabilistic relation between {a mathematical formula}h(n), {a mathematical formula}d(n) and {a mathematical formula}h⁎(n). For example, one could apply machine learning techniques to learn this relation from past experience.</paragraph></section><section label="7.2"><section-title>Expected search effort instead of potential</section-title><paragraph>PTS aims at expanding the node with the highest probability to lead to a solution under the bound. The task in a bounded-cost search is, however, to find such a solution as fast as possible. Thus, we might also consider the expected effort of finding such a solution, and not just the probability that such a solution exists. Estimating search effort may be done with search effort prediction formulas and algorithms [64], [65], [66]. Future work will investigate how to incorporate such estimates, in addition to the potential of a node. For example, a node that is very close to a goal might be preferred to a node that has a slightly higher potential but is farther from a goal.</paragraph><paragraph>This paper combines results from two research groups who independently discovered {a mathematical formula}APTS/ANA⁎. One group derived the anytime search algorithm APTS by studying bounded-cost search problems [7], [8]. The other research group derived {a mathematical formula}ANA⁎ motivated by a desire to avoid parameter tuning [9]. Both groups had papers under review simultaneously and subsequently published in 2011. We thank Wheeler Ruml for pointing out this relationship.</paragraph></section><section-title>Acknowledgements</section-title></section></content><acknowledgements><paragraph>This research was supported by the Israel Science Foundation (ISF) under grant number 417/13 to Ariel Felner. This work was supported in part (for Goldberg and van den Berg) by the US National Science Foundation under Award IIS-1227536. We thank Maxim Likhachev for making his implementation of {a mathematical formula}ARA⁎ available to us, as well as publishing the code for {a mathematical formula}ANA⁎. Our implementation of {a mathematical formula}ANA⁎ is freely available in his Search-based Planning Library (SBPL) at: http://www.sbpl.net. </paragraph></acknowledgements><appendices><section label="Appendix A">Domains and their h-models<paragraph>In this appendix we show the h-models of two domains and heuristics. These models were obtained by optimally solving a set of problem instances. Then we backtracked from the goal to the start, and for every node on that path plotted its {a mathematical formula}h⁎ value versus its heuristic value (according to the selected heuristic).</paragraph><section label="A.1"><section-title>Key Player Problem in Communication (KPP-COM)</section-title><paragraph>Fig. 12(a) shows the h-to-{a mathematical formula}h⁎ relation for 100 KPP-COM problem instances. See Section 5.1.2 for details on this domain and the heuristic we used for it. Each problem instance is a graph, randomly generated according to the Barabási–Albert model [54] (the choice of this type of graphs is motivated in Section 5.1), having 700 nodes and a density factor of 3.</paragraph><paragraph>The dashed black line in Fig. 12(a) is a linear fit of the data. As can be seen, a slight curve (e.g., a logarithmic model) would fit nicely. However, the linear fit is simpler and is also quite accurate.</paragraph></section><section label="A.2"><section-title>Blocks world</section-title><paragraph>Next, we analyzed the h-to-{a mathematical formula}h⁎ relation for the blocks world domain, which is one of the well-known planning domains. We used the Fast Downward planner [67] with the admissible LM-cut heuristic [68]. Fig. 12(b) shows the h-to-{a mathematical formula}h⁎ relation for all the blocks world problem instances from the International Planning Competition '06, which are publicly available in the Fast Downward software suite. Again, the dashed black line is a linear fit of the data. As can be seen, this heuristic in this domain also exhibits a clear linear relative h-model.</paragraph></section></section></appendices><references><reference label="[1]"><authors>P.E. Hart,N.J. Nilsson,B. Raphael</authors><title>A formal basis for the heuristic determination of minimum cost paths</title><host>IEEE Trans. Syst. Sci. Cybern.SSC-4 (2)(1968) pp.100-107</host></reference><reference label="[2]"><authors>R.E. Korf</authors><title>Depth-first iterative-deepening: an optimal admissible tree search</title><host>Artif. Intell.27 (1)(1985) pp.97-109</host></reference><reference label="[3]"><authors>M. Helmert,G. Röger</authors><title>How good is almost perfect?</title><host>AAAI(2008) pp.944-949</host></reference><reference label="[4]"><authors>S. Zilberstein</authors><title>Using anytime algorithms in intelligent systems</title><host>AI Mag.17 (3)(1996) pp.73-83</host></reference><reference label="[5]"><authors>R.A. Valenzano,N.R. Sturtevant,J. Schaeffer,K. Buro,A. Kishimoto</authors><title>Simultaneously searching with multiple settings: an alternative to parameter tuning for suboptimal single-agent search algorithms</title><host>ICAPS(2010) pp.177-184</host></reference><reference label="[6]"><authors>M. Likhachev,G.J. Gordon,S. Thrun</authors><title>ARA⁎: anytime A⁎ with provable bounds on sub-optimality</title><host>NIPS(2003)</host></reference><reference label="[7]"><authors>R. Stern,R. Puzis,A. Felner</authors><title>Potential search: a new greedy anytime heuristic search</title><host>SoCS(2010) pp.119-120</host></reference><reference label="[8]"><authors>R. Stern,R. Puzis,A. Felner</authors><title>Potential search: a bounded-cost search algorithm</title><host>ICAPS(2011) pp.234-241</host></reference><reference label="[9]"><authors>J. van den Berg,R. Shah,A. Huang,K.Y. Goldberg</authors><title>Anytime nonparametric A⁎</title><host>AAAI(2011) pp.105-111</host></reference><reference label="[10]"><authors>S. Russell,P. Norvig</authors><title>Artificial Intelligence: A Modern Approach</title><host>3rd edition(2010)Prentice-HallEnglewood Cliffs, NJ</host></reference><reference label="[11]"><authors>R. Stern,T. Kulberis,A. Felner,R. Holte</authors><title>Using lookaheads with optimal best–first search</title><host>AAAI(2010) pp.185-190</host></reference><reference label="[12]"><authors>E.W. Dijkstra</authors><title>A note on two problems in connexion with graphs</title><host>Numer. Math.1 (1959) pp.269-271</host></reference><reference label="[13]"><authors>A. Felner</authors><title>Position paper: Dijkstra's algorithm versus uniform cost search or a case against Dijkstra's algorithm</title><host>SOCS(2011) pp.47-51</host></reference><reference label="[14]"><authors>T.H. Cormen,C.E. Leiserson,R.L. Rivest,C. Stein</authors><title>Introduction to Algorithms</title><host>2nd edition(2001)The MIT Press</host></reference><reference label="[15]"><authors>R.E. Korf</authors><title>Linear-space best–first search</title><host>Artif. Intell.62 (1)(1993) pp.41-78</host></reference><reference label="[16]"><authors>I. Pohl</authors><title>Heuristic search viewed as path finding in a graph</title><host>Artif. Intell.1 (3–4)(1970) pp.193-204</host></reference><reference label="[17]"><authors>I. Pohl</authors><title>The avoidance of (relative) catastrophe, heuristic competence, genuine dynamic weighting and computational issues in heuristic problem solving</title><host>IJCAI(1973) pp.12-17</host></reference><reference label="[18]"><authors>J. Pearl,J. Kim</authors><title>Studies in semi-admissible heuristics</title><host>IEEE Trans. Pattern Anal. Mach. Intell.4 (4)(1982) pp.392-400</host></reference><reference label="[19]"><authors>J.T. Thayer,W. Ruml</authors><title>Faster than weighted A⁎: an optimistic approach to bounded suboptimal search</title><host>ICAPS(2008) pp.355-362</host></reference><reference label="[20]"><authors>J.T. Thayer,W. Ruml</authors><title>Bounded suboptimal search: a direct approach using inadmissible estimates</title><host>IJCAI(2011) pp.674-679</host></reference><reference label="[21]"><authors>D. Furcy,S. Koenig</authors><title>Limited discrepancy beam search</title><host>IJCAI(2005) pp.125-131</host></reference><reference label="[22]"><authors>E.A. Hansen,R. Zhou</authors><title>Anytime heuristic search</title><host>J. Artif. Intell. Res.28 (2007) pp.267-297</host></reference><reference label="[23]"><authors>E. Balas,P. Toth</authors><title>Branch and bound methods</title><host>E.L. LawlerJ.K. LenstraA.H.G. Rinnooy KanD.B. ShwoysTraveling Salesman Problem: A Guided Tour of Combinatorial Optimization(1985)WileyChichester</host></reference><reference label="[24]"><authors>S. Richter,J.T. Thayer,W. Ruml</authors><title>The joy of forgetting: faster anytime search via restarting</title><host>ICAPS(2010) pp.137-144</host></reference><reference label="[25]"><authors>S. Aine,P.P. Chakrabarti,R. Kumar</authors><title>AWA⁎ – a window constrained anytime heuristic search algorithm</title><host>IJCAI(2007) pp.2250-2255</host></reference><reference label="[26]"><authors>R. Zhou,E.A. Hansen</authors><title>Beam-stack search: integrating backtracking with beam search</title><host>ICAPS(2005) pp.90-98</host></reference><reference label="[27]"><authors>J.T. Thayer,W. Ruml</authors><title>Anytime heuristic search: frameworks and algorithms</title><host>SOCS(2010) pp.121-128</host></reference><reference label="[28]"><authors>R. Taig,R.I. Brafman</authors><title>Compiling conformant probabilistic planning problems into classical planning</title><host>ICAPS(2013) pp.197-205</host></reference><reference label="[29]"><authors>A. Stern,I. Dagan</authors><title>A confidence model for syntactically-motivated entailment proofs</title><host>RANLP(2011) pp.455-462</host></reference><reference label="[30]"><authors>A. Stern,R. Stern,I. Dagan,A. Felner</authors><title>Efficient search for transformation-based inference</title><host>ACL(2012) pp.283-291</host></reference><reference label="[31]"><authors>A. Zanarini,G. Pesant</authors><title>Solution counting algorithms for constraint-centered search heuristics</title><host>Constraints14 (2009) pp.392-413</host></reference><reference label="[32]"><authors>P. Haslum,H. Geffner</authors><title>Heuristic planning with time and resources</title><host>European Conference on Planning (ECP)vol. 1 (2001) pp.121-132</host></reference><reference label="[33]"><authors>H. Nakhost,J. Hoffmann,M. Müller</authors><title>Improving local search for resource-constrained planning</title><host>SOCS(2010) pp.81-82</host></reference><reference label="[34]"><authors>P. Haslum</authors><title>Heuristics for bounded-cost search</title><host>ICAPS(2013) pp.312-316</host></reference><reference label="[35]"><authors>J. Pearl</authors><title>Heuristics: Intelligent Search Strategies for Computer Problem Solving</title><host>(1984)Addison-Wesley Pub. Co., Inc.Reading, MA</host></reference><reference label="[36]"><authors>A. Felner,R.E. Korf,S. Hanan</authors><title>Additive pattern database heuristics</title><host>J. Artif. Intell. Res.22 (2004) pp.279-318</host></reference><reference label="[37]"><authors>U. Sarkar,P. Chakrabarti,S. Ghose,S. De Sarkar</authors><title>Reducing reexpansions in iterative-deepening search by controlling cutoff bounds</title><host>Artif. Intell.50 (2)(1991) pp.207-221</host></reference><reference label="[38]"><authors>E. Burns,W. Ruml</authors><title>Iterative-deepening search with on-line tree size prediction</title><host>LION(2012) pp.1-15</host></reference><reference label="[39]"><authors>C.M. Wilt,W. Ruml</authors><title>When does weighted A⁎ fail?</title><host>SOCS(2012) pp.137-144</host></reference><reference label="[40]"><authors>J.T. Thayer,R. Stern,W. Ruml,A. Felner</authors><title>Faster bounded-cost search using inadmissible estimates</title><host>ICAPS(2012) pp.270-278</host></reference><reference label="[41]"><authors>M. Boullé</authors><title>A parameter-free classification method for large scale learning</title><host>J. Mach. Learn. Res.10 (2009) pp.1367-1385</host></reference><reference label="[42]"><authors>G.R. Harik,F.G. Lobo</authors><title>A parameter-less genetic algorithm</title><host>GECCOvol. 99 (1999) pp.258-267</host></reference><reference label="[43]"><authors>A. Foss,O.R. Zaïane</authors><title>A parameterless method for efficiently discovering clusters of arbitrary shape in large datasets</title><host>International Conference on Data Mining (ICDM)(2002)IEEE pp.179-186</host></reference><reference label="[44]"><authors>A.J. Dionne,J.T. Thayer,W. Ruml</authors><title>Deadline-aware search using on-line measures of behavior</title><host>SOCS(2011) pp.39-46</host></reference><reference label="[45]"><authors>W. Ruml,M.B. Do</authors><title>Best-first utility-guided search</title><host>IJCAI(2007) pp.2378-2384</host></reference><reference label="[46]"><authors>J.T. Thayer,W. Ruml</authors><title>Using distance estimates in heuristic search</title><host>ICAPS(2009) pp.382-385</host></reference><reference label="[47]"><authors>W.E. Story</authors><title>Notes on the “15” puzzle</title><host>Am. J. Math.2 (4)(1879) pp.397-404</host></reference><reference label="[48]"><authors>R.C. Holte,A. Felner,J. Newton,R. Meshulam,D. Furcy</authors><title>Maximizing over multiple pattern databases speeds up heuristic search</title><host>Artif. Intell.170 (16–17)(2006) pp.1123-1136</host></reference><reference label="[49]"><authors>U. Zahavi,A. Felner,R.C. Holte,J. Schaeffer</authors><title>Duality in permutation state spaces and the dual search algorithm</title><host>Artif. Intell.172 (4–5)(2008) pp.514-540</host></reference><reference label="[50]"><authors>M.G. Everett,S.P. Borgatti</authors><title>The centrality of groups and classes</title><host>J. Math. Sociol.23 (3)(1999) pp.181-201</host></reference><reference label="[51]"><authors>L.C. Freeman</authors><title>A set of measures of centrality based on betweenness</title><host>Sociometry40 (1)(1977) pp.35-41</host></reference><reference label="[52]"><authors>R. Puzis,Y. Elovici,S. Dolev</authors><title>Finding the most prominent group in complex networks</title><host>AI Commun.20 (4)(2007) pp.287-296</host></reference><reference label="[53]"><authors>S. Dolev,Y. Elovici,R. Puzis,P. Zilberman</authors><title>Incremental deployment of network monitors based on group betweenness centrality</title><host>Inf. Process. Lett.109 (20)(2009) pp.1172-1176</host></reference><reference label="[54]"><authors>A.L. Barabási,R. Albert</authors><title>Emergence of scaling in random networks</title><host>Science286 (5439)(1999) pp.509-512</host></reference><reference label="[55]"><authors>D.J. Lipman,S.F. Altschul,J.D. Kececioglu</authors><title>A tool for multiple sequence alignment</title><host>Proc. Natl. Acad. Sci. USA86 (12)(1989) pp.4412-4415</host></reference><reference label="[56]"><authors>T. Ikeda,H. Imai</authors><title>Enhanced A⁎ algorithms for multiple alignments: optimal alignments for several sequences and k-opt approximate alignments for large cases</title><host>Theor. Comput. Sci.210 (2)(1999) pp.341-374</host></reference><reference label="[57]"><authors>A.S. Konagurthu,P.J. Stuckey</authors><title>Optimal sum-of-pairs multiple sequence alignment using incremental Carrillo and Lipman bounds</title><host>J. Comput. Biol.13 (3)(2006) pp.668-685</host></reference><reference label="[58]"><authors>T. Yoshizumi,T. Miura,T. Ishida</authors><title>A⁎ with partial expansion for large branching factor problems</title><host>AAAI(2000) pp.923-929</host></reference><reference label="[59]"><authors>T. Ikeda,H. Imai</authors><title>Fast A⁎ algorithms for multiple sequence alignment</title><host>Workshop on Genome Informatics(1994) pp.90-99</host></reference><reference label="[60]"><authors>H. Kobayashi,H. Imai</authors><title>Improvement of the A⁎ algorithm for multiple sequence alignment</title><host>Genome Informatics Series(1998) pp.120-130</host></reference><reference label="[61]"><authors>W. Zhang,R.E. Korf</authors><title>Performance of linear-space search algorithms</title><host>Artif. Intell.79 (2)(1995) pp.241-292</host></reference><reference label="[62]"><authors>W. Zhang</authors><title>Depth-first branch-and-bound versus local search: a case study</title><host>AAAI/IAAI(2000) pp.930-935</host></reference><reference label="[63]"><authors>J.T. Thayer,J. Benton,M. Helmert</authors><title>Better parameter-free anytime search by minimizing time between solutions</title><host>SOCS(2012) pp.120-128</host></reference><reference label="[64]"><authors>L.H.S. Lelis,S. Zilles,R.C. Holte</authors><title>Predicting the size of IDA⁎'s search tree</title><host>Artif. Intell.196 (2013) pp.53-76</host></reference><reference label="[65]"><authors>L. Lelis,R. Stern,A. Felner,S. Zilles,R.C. Holte</authors><title>Predicting optimal solution cost with bidirectional stratified sampling</title><host>ICAPS(2012) pp.155-163</host></reference><reference label="[66]"><authors>R.E. Korf,M. Reid,S. Edelkamp</authors><title>Time complexity of iterative-deepening-A⁎</title><host>Artif. Intell.129 (1–2)(2001) pp.199-218</host></reference><reference label="[67]"><authors>M. Helmert</authors><title>The fast downward planning system</title><host>J. Artif. Intell. Res.26 (2006) pp.191-246</host></reference><reference label="[68]"><authors>M. Helmert,C. Domshlak</authors><title>Landmarks, critical paths and abstractions: what's the difference anyway?</title><host>ICAPS(2009) pp.162-169</host></reference></references><footnote><note-para label="1">This is the textbook version of BFS [10]. However, there are variants of BFS where the search is halted earlier (e.g., BFS with lookaheads [11]).</note-para><note-para label="2">In this paper we consider Dijkstra's algorithm in its best–first search variant, which is also known as Uniform Cost Search. It has been shown [13] that this variant of Dijkstra is more efficient than the implementation of Dijsktra detailed in the common algorithm textbook [14].</note-para><note-para label="3">The proof for the w-admissibility of {a mathematical formula}WA⁎ is given in the Appendix of a later paper [17]. That paper proposed a variation on {a mathematical formula}WA⁎ (dynamic weighting) but the same proof holds for plain {a mathematical formula}WA⁎.</note-para><note-para label="4">Pure heuristic search is sometimes called Greedy best–first search in the literature.</note-para><note-para label="5">One can use virtually any search algorithm to find an initial solution in an anytime algorithm.</note-para><note-para label="6">Large solution depth can be partially remedied by applying an iterative deepening framework on top of DFBnB.</note-para><note-para label="7">Note that even if the cost bound is C, the search tree might be much deeper if there are edges of cost smaller than one (e.g., zero cost edges).</note-para><note-para label="8">For cases where {a mathematical formula}h(n)=0, we define {a mathematical formula}u(n) to be ∞, causing such nodes to be expanded first.</note-para><note-para label="9">This model is reminiscent of the constant relative error[35], where {a mathematical formula}h⁎(n)≤T⋅h(n) for some constant T.</note-para><note-para label="10">Some anytime search algorithms cannot guarantee that no better solution is found. We do not discuss such algorithms in this paper.</note-para><note-para label="11">An alternative approach is to use the function {a mathematical formula}u′(n)=1−h(n)C−g(n) instead of {a mathematical formula}u(n). It is easy to see it achieves the same node ordering, but there increasing C to infinity results in an elegant convergence to pure heuristic search.</note-para><note-para label="12">In fact, reordering OPEN requires {a mathematical formula}O(|OPEN|log|OPEN|) in general. However, it might be possible to use bucket sort to achieve an {a mathematical formula}O(|OPEN|) runtime.</note-para><note-para label="13">Note that maintaining {a mathematical formula}fmin requires more than simply storing the lowest f value seen in the search, since {a mathematical formula}fmin increases during the search when the node with f value of {a mathematical formula}fmin is expanded. This requires going over OPEN to find the node with the minimal f value, or maintaining an additional priority queue as mentioned above.</note-para><note-para label="14">For some of the results of the other algorithms, see http://goldberg.berkeley.edu/ana/ANA-techReport-v7.pdf.</note-para><note-para label="15">This is a general guideline [6], but deeper study of the effect of w in MIN problems is needed [39].</note-para><note-para label="16">This is reminiscent of the bounded constant absolute error model described by Pearl [35] where the difference between h and {a mathematical formula}h⁎ is bounded by a constant (i.e., {a mathematical formula}h⁎(n)≤h(n)+K). Here, K is the largest value for X.</note-para><note-para label="17">Further experimental results for other domain-independent planning domains with unit edge-cost are needed to provide a conclusive statement about the performance of PTS in domain-independent planning.</note-para></footnote></root>