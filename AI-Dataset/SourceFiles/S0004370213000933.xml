<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370213000933</url><title>An analysis on recombination in multi-objective evolutionary optimization</title><authors>Chao Qian,Yang Yu,Zhi-Hua Zhou</authors><abstract>Evolutionary algorithms (EAs) are increasingly popular approaches to multi-objective optimization. One of their significant advantages is that they can directly optimize the Pareto front by evolving a population of solutions, where the recombination (also called crossover) operators are usually employed to reproduce new and potentially better solutions by mixing up solutions in the population. Recombination in multi-objective evolutionary algorithms is, however, mostly applied heuristically. In this paper, we investigate how from a theoretical viewpoint a recombination operator will affect a multi-objective EA. First, we employ artificial benchmark problems: the Weighted LPTNO problem (a generalization of the well-studied LOTZ problem), and the well-studied COCZ problem, for studying the effect of recombination. Our analysis discloses that recombination may accelerate the filling of the Pareto front by recombining diverse solutions and thus help solve multi-objective optimization. Because of this, for these two problems, we find that a multi-objective EA with recombination enabled achieves a better expected running time than any known EAs with recombination disabled. We further examine the effect of recombination on solving the multi-objective minimum spanning tree problem, which is an NP-hard problem. Following our finding on the artificial problems, our analysis shows that recombination also helps accelerate filling the Pareto front and thus helps find approximate solutions faster.</abstract><keywords>Evolutionary algorithms;Multi-objective optimization;Recombination;Crossover;Running time;Computational complexity</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>Multi-objective optimization [48] requires one to find a set of solutions called the optimal Pareto set, because the objectives usually conflict with each other. Evolutionary algorithms (EAs), which are a kind of stochastic metaheuristic optimization approach [4], are becoming increasingly popular for multi-objective optimization [6]. EAs maintain a population of solutions, and iteratively improve the population by reproducing new solutions from the population and updating the population to contain the best-so-far solutions. Because EAs are population-based approaches, they have an advantage of directly optimizing the Pareto front, instead of, e.g., running an algorithm many times each for a Pareto optimal solution.</paragraph><paragraph>A characterizing feature of EAs is the recombination operator for reproducing new solutions. Recombination (also called crossover) operators take two or more individual solutions from the maintained population and mix them up to form new solutions. Thus, they are population-based operators and typically appear in multi-objective EAs (MOEAs), e.g. the popular NSGA-II [7]. The MOEAs that use recombination operators have been successful in solving many real-world problems, e.g., electric power dispatch problem [1], multiprocessor system-on-chip design [15], aeronautical and aerospace engineering [3], and multicommodity capacitated network design [25]. However, recombination operators are understood only at the introductory level. Discovering the effect of recombination in MOEAs not only can enhance our understanding of this kind of nature-inspired operators, but also be helpful for designing improved algorithms. This paper studies the effect of recombination from a theoretical viewpoint.</paragraph><section label="1.1"><section-title>Related work</section-title><paragraph>The theoretical foundation of EAs has developed quickly in the past few decades, e.g. [12], [21], [51], [38]. Most of the previous analyses focused on EAs with mutation operators, while only a few include recombination operators. We briefly review theoretical work on recombination operators.</paragraph><paragraph>Properties of recombination operators have been addressed in the scenario of single-objective optimization. Early empirical analyses include [31] and [47]. Later, running time analyses provided a theoretical understanding of recombination operators. Several crossover-only evolutionary algorithms were shown to be effective on the H-IFF problem which is difficult for any kind of mutation-based EAs [50], [8]. Jansen and Wegener [22], [23] proved that crossover operators can be crucially important on some artificial problems. Crossover operators subsequently have been shown to be useful in more cases. These include Ising models [16], [49], the TwoPaths instance class of the problem of computing unique input–output sequences [30], some instance classes of the vertex cover problem [39], and the all-pairs-shortest-path problem [10], [9], [11]. Meanwhile, on the contrary, Richter et al. [44] produced the Ignoble Trail functions where a crossover operator was shown to be harmful. Recently, Kötzing et al. [27] found that crossover with ideal diversity can lead to drastic speedups on the OneMax and Jump problems, and they also analyzed how crossover probability and population size affect population diversity. The analysis approaches for recombination have been developed such as the switch analysis approach [52], [53] that compares the running time of an EA turning recombination on and off. While all these studies are in the scenario of single-objective optimization, the results are difficult to generalize to the scenario of multi-objective optimization. In particular, multi-objective optimization aims at finding a set of optimal and non-dominated solutions rather than a single optimal solution, where the situation becomes more complex and is untouched.</paragraph><paragraph>Early analyses of multi-objective EAs concentrate on the conditions under which MOEAs can find the Pareto optimal solutions given unlimited time, e.g., [20], [45], [46]. For running time analyses, studies on two bi-objective pseudo-Boolean functions the LOTZ and COCZ problems extended respectively from the well-studied LeadingOnes and OneMax problems [12] have led to some disclosure of limited time behaviors of MOEAs. Note that none of these previously analyzed MOEAs uses recombination operators. We rename the previous MOEAs in Table 1 for a clearer presentation. Table 2 lists the previous analyses results of these MOEAs for the two problems.</paragraph><paragraph>The recent work by Neumann and Theile [35] is, to the best of our knowledge, the first and only work analyzing crossover operators in MOEAs. They proved that a crossover operator can speed up evolutionary algorithms for the multi-criteria all-pairs-shortest-path problem. As discovered through their analysis, the crossover operator can be helpful in the interplay with the mutation operator, such that good solutions can be evolved efficiently.</paragraph><paragraph>We also note that there are studies that analyze MOEAs for solving single-objective problems, e.g., [36], [17], [34]. However, we concern ourselves with multi-objective problems.</paragraph></section><section label="1.2"><section-title>Our contribution</section-title><paragraph>Multi-objective optimization aims at finding a set of optimal solutions with different balances of the objectives, which was not involved in the analysis for single-objective optimization. This paper extends our preliminary work [40] to investigate whether recombination operators can have any effect on solving the multi-objective optimization tasks.</paragraph><paragraph>We study the effect of recombination by comparing the performance of MOEAs using the diagonal multi-parent crossover [14] to that using only mutation. We derive the expected running time of the MOEAs using recombination together with the one-bit mutation and the bit-wise mutation, denoted respectively as {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise. The one-bit mutation implies a kind of local search, and the bit-wise mutation is regarded as a global search. We further indicate the probability of applying the recombination by using the subscript following “recomb”, e.g., {a mathematical formula}MOEArecomb,0.5onebit uses the recombination with probability 0.5 and {a mathematical formula}MOEArecomb,0onebit does not use the recombination. Since EAs are a kind of metaheuristic optimization approach, i.e., they are problem-independent, a typical way to study EAs theoretically is to use model problems to disclose the properties of EAs. In this paper, we first extend our preliminary work [40] to employ two artificial multi-objective problems: the Weighted LPTNO (Weighted Leading Positive Ones Trailing Negative Ones) problem and the well-studied COCZ (Count Ones Count Zeros) problem, for analyzing MOEAs. Note that Weighted LPTNO is generalized from the well-studied LOTZ (Leading Ones Trailing Zeros) problem. We then study MOEAs for the multi-objective minimum spanning tree (MST) problem, an NP-hard problem [2], [13], which is more representative of real-world problems.</paragraph><paragraph>For the artificial problems, we derive the expected running time of {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise. We respectively compare them to that of {a mathematical formula}MOEArecomb,0onebit and {a mathematical formula}MOEArecomb,0bitwise as well as previously analyzed MOEAs without recombination on the LOTZ and COCZ problems. Their expected running time is listed in Table 2. From the results, we can conclude that, among the MOEAs with one-bit mutation, {a mathematical formula}MOEArecomb,0.5onebit achieves the best performance, which is faster than the other mutation only MOEAs; among the MOEAs with bit-wise mutation, {a mathematical formula}MOEArecomb,0.5bitwise is also better than the other mutation only MOEAs. We further carry out experiments to compensate for the theoretical bounds in Table 2 that are not tight, e.g., where only the upper bound is known for the {a mathematical formula}MOEAonebit on COCZ. The empirical observations suggest that, for the MOEAs whose exact asymptotic running time complexities are unknown, their running time is close to the derived upper bounds. Thus, the empirical observations confirm that {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise are the best among the compared MOEAs.</paragraph><paragraph>Through the analysis of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise for the artificial problems, we discover that the recombination operator works in the studied situation by accelerating the filling of the Pareto front through recombining the diverse optimal solutions that have been found. It is worth noting that this mechanism is different from that analyzed in [35], where the crossover operator works by its interplay with mutation. Moreover, this finding is unique to multi-objective optimization, as there is no Pareto front in single-objective situations.</paragraph><paragraph>On the multi-objective MST problem, we follow the idea that recombination can accelerate the filling of the Pareto front by recombining diverse solutions, and analyze the expected running time of {a mathematical formula}MOEArecombbitwise. Let m and n denote the number of edges and nodes respectively. Let {a mathematical formula}wmax and {a mathematical formula}wmin denote the maximum and minimum among the maximum values for each kind of weight respectively. Let {a mathematical formula}|F⁎| and {a mathematical formula}|conv(F⁎)| denote the size of the optimal Pareto front and its convex sub-front (definitions are in Section 5.1) respectively, and {a mathematical formula}Ngc⩾0, {a mathematical formula}Cmin⩾1 be two parameters that depend on concrete problem instances. First, on a subclass of bi-objective MST problem with a strictly convex optimal Pareto front, we find that the expected running time of {a mathematical formula}MOEArecomb,0.5bitwise has the upper bound of{a mathematical formula} By comparing with the previous result for {a mathematical formula}MOEAbitwise[33]{a mathematical formula}{a mathematical formula}MOEArecomb,0.5bitwise appears to be more efficient. Moreover, to obtain the 2-approximation solutions for the general bi-objective MST problem, the expected running time of {a mathematical formula}MOEArecomb,0.5bitwise has the upper bound of{a mathematical formula} which improves the previous result for {a mathematical formula}MOEAbitwise[33]{a mathematical formula} The comparisons imply that recombination operators may help MOEAs in solving real-world multi-objective optimizations.</paragraph><paragraph>The rest of this paper is organized as follows. Section 2 introduces the preliminaries on multi-objective optimization. Section 3 presents the {a mathematical formula}MOEArecombonebit and the {a mathematical formula}MOEArecombbitwise algorithms. Section 4 studies these two algorithms on the artificial problems, and Section 5 studies them on the multi-objective minimum spanning tree problem. Section 6 concludes.</paragraph></section></section><section label="2"><section-title>Multi-objective optimization</section-title><paragraph>Multi-objective optimization requires to simultaneously optimize two or more objective functions, as in Definition 1. When there are two objective functions, it is also called as bi-objective optimization. We consider maximization here, while minimization can be defined similarly.</paragraph><paragraph label="Definition 1">Multi-objective optimizationGiven a feasible solution space {a mathematical formula}X and objective functions {a mathematical formula}f1,…,fm, the maximum multi-objective optimization aims to find the solution {a mathematical formula}x⁎ satisfying{a mathematical formula} where {a mathematical formula}f(x)=(f1(x),f2(x),…,fm(x)) is the objective vector of the solution x.</paragraph><paragraph>Usually, the objectives are conflicted, i.e., optimization of one objective alone will degrade the other objectives, and it is impossible to have one solution that optimizes all the objectives simultaneously. Therefore, multi-objective optimization tries to find a set of solutions according to some criteria. One commonly used criterion is the Pareto optimality, which utilizes the domination relation between solutions as in Definition 2. The solution set by Pareto optimality is called Pareto set, as in Definition 3.</paragraph><paragraph label="Definition 2">DominationLet {a mathematical formula}f=(f1,f2,…,fm):X→Rm be the objective vector, where {a mathematical formula}X is the feasible solution space, and {a mathematical formula}Rm is the objective space. For two solutions x and {a mathematical formula}x′∈X:</paragraph><list><list-item label="1.">x weakly dominates{a mathematical formula}x′ if, for all i that {a mathematical formula}1⩽i⩽m, {a mathematical formula}fi(x)⩾fi(x′), denoted as {a mathematical formula}≽f;</list-item><list-item label="2.">x dominates{a mathematical formula}x′ if, x weakly dominates {a mathematical formula}x′ and {a mathematical formula}fi(x)&gt;fi(x′) for some i, denoted as {a mathematical formula}≻f.</list-item></list><paragraph label="Definition 3">Pareto optimalityLet {a mathematical formula}f=(f1,f2,…,fm):X→Rm be the objective vector, where {a mathematical formula}X is the feasible solution space, and {a mathematical formula}Rm is the objective space. A solution x is Pareto optimal if there is no other solution in {a mathematical formula}X that dominates x. A set of solutions is called Pareto set if it contains only Pareto optimal solutions. The collection of objective values of a set of solutions is called the front of the set. If a set is a Pareto set, its front is also called the Pareto front.</paragraph><paragraph>With the goal of finding the largest Pareto set, or called the optimal Pareto set, the running time of an MOEA is counted as the number of calls to f until it finds the Pareto front of the optimal Pareto set, or called the optimal Pareto front. That is, the MOEA should find at least one corresponding solution for each element in the optimal Pareto front. Note that this definition agrees with that in [28], [18], [29]. Since MOEAs are naturally stochastic algorithms, we measure the performance of MOEAs by the expected running time.</paragraph><paragraph>SEMO[28], as described in Algorithm 1, is a simple MOEA, and also the first analyzed MOEA due to its simplicity, which explains the common structure of various MOEAs. In the SEMO, {a mathematical formula}X is the solution space, and it employs the one-bit mutation operator (i.e., step 5) where the action of “flipping” is implemented problem-specifically. Usually, when {a mathematical formula}X={0,1}n, the “flipping” action interchanges between 0 and 1 of a solution bit. A newly generated solution is compared with the solutions in the population, and then only non-dominated solutions are kept in the population.</paragraph><paragraph label="Algorithm 1">SEMO[28]Given solution space {a mathematical formula}X and objective function vector f, SEMO consists of the following steps:{an inline-figure}</paragraph><paragraph>Following SEMO, two modifications of SEMO, i.e., FEMO and GEMO, were proposed. FEMO[28] accelerates the exploration of the optimal set by using a fair sampling strategy, which makes that every solution produces the same number of offspring solutions at the end. GEMO[29] extends FEMO to achieve maximum progress toward the Pareto front by using a greedy selection mechanism, which allows only the newly included solution dominating some current solutions to have reproduction chance. All of these MOEAs use one-bit mutation operator. By replacing the one-bit mutation operator which searches locally in SEMO with the bit-wise mutation operator which searches globally, the global SEMO (GSEMO) algorithm [18] was proposed and analyzed. That is, GSEMO is the same as SEMO except that step 5 in Algorithm 1 changes to be “Create {a mathematical formula}x′ by flipping each bit of x with probability {a mathematical formula}1n”, where n is the solution length. For presenting these MOEAs clearly, we rename them in this paper, as in Table 1.</paragraph></section><section label="3"><section-title>Recombination enabled MOEAs</section-title><paragraph>The recombination-incorporated MOEA ({a mathematical formula}MOEArecombonebit) studied in this paper is depicted in Algorithm 2, which is extended from the algorithm {a mathematical formula}MOEAonebit by incorporating a recombination operator. The components of {a mathematical formula}MOEArecombonebit are explained in the following.</paragraph><paragraph>It is well known that the diversity of a population is important to the success of recombination operators, since recombination makes no progress from similar solutions. Therefore, we should employ some diversity control in {a mathematical formula}MOEArecombonebit. We use objective diversity (od) measure based on the assumption that the diversity of a set of solutions is consistent with the difference of their objective vectors. By this assumption, a population has a high diversity if it contains solutions with good objective values on different objectives. Thus, we define objective diversity of a set of solutions as the number of objectives, on which at least one solution in this set has a good objective value. Formally, for a set of solutions S, define a variable {a mathematical formula}qi for the i-th objective {a mathematical formula}(1⩽i⩽m),{a mathematical formula} where {a mathematical formula}θi is the “goodness” threshold of the i-th objective, then the objective diversity of S{a mathematical formula} Given m objectives, the largest value of objective diversity is m. Here, we use the objective diversity with {a mathematical formula}θi= the minimal local optimal value of the i-th objective.</paragraph><paragraph>To make the initial population diverse enough, we use an initialization process, described in Definition 4. In the initialization process, m independent runs of randomized local search (RLS) are employed to optimize the m objective functions {a mathematical formula}f1,f2,…,fm, each RLS corresponds to one objective. In the RLS, the solution is examined whether it is local optimal for an objective every N mutation steps, where N is the size of the neighbor space of a solution. When to check whether a solution is local optimal for an objective, we use the solutions having Hamming distance 1 with the current solution as the neighborhood. Thus, {a mathematical formula}N=n, i.e., the length of a solution. This initialization procedure is terminated when local optimal solutions are found for all the objectives.</paragraph><paragraph label="Definition 4">InitializationInput: m solutions {a mathematical formula}x1,x2,…,xm from {a mathematical formula}X; Output: m local optimal solutions corresponding to one of the m objectives respectively; the Initialization procedure consists of the following steps:{an inline-figure}</paragraph><paragraph>This process makes the initial population contain one good solution for each objective, i.e., {a mathematical formula}qi=1(1⩽i⩽m). Thus, the objective diversity of the initial population is m. Since a solution in the population is eliminated only if it is dominated by a new solution, there always exist good solutions for each objective. As the result, the objective diversity of the population always keeps m, the maximal objective diversity, throughout the evolution process.</paragraph><paragraph>In each reproduction step, {a mathematical formula}MOEArecombonebit picks a set of m solutions with the objective diversity at least {a mathematical formula}m/2 from the current population to carry out recombination. In order to do so, the best solutions each for one of the randomly selected {a mathematical formula}m/2 objectives are selected at first, denoted as a set {a mathematical formula}Ps1. The remaining {a mathematical formula}m−|Ps1| solutions are randomly chosen from the population excluding {a mathematical formula}Ps1. Thus, the selected solutions for recombination have an objective diversity at least {a mathematical formula}m/2.</paragraph><paragraph>In the reproduction procedure, we use the parameter {a mathematical formula}pc to control the use of recombination. That is, in each reproduction step, the offspring solutions are generated by recombination with probability {a mathematical formula}pc, and otherwise generated by mutation. In the end of each iteration, the offspring solutions {a mathematical formula}Po are used to update the current population. For an offspring solution, if there is no solution in the current population which can weakly dominate it, it will be included into the population, and then the population is cleaned up by removing all solutions that are no longer non-dominated.</paragraph><paragraph label="Algorithm 2">{a mathematical formula}MOEArecombonebitGiven solution space {a mathematical formula}X and objective function vector f of length m, {a mathematical formula}MOEArecombonebit consists of the following steps:{an inline-figure}</paragraph><paragraph>The recombination operator employed in {a mathematical formula}MOEArecombonebit is the diagonal multi-parent crossover [14], as in Definition 5. For m solutions, diagonal multi-parent crossover randomly selects {a mathematical formula}m−1 crossover points between adjacent bits and creates m offspring solutions by sequentially combining the components partitioned by the crossover points, which is a generalization of one-point crossover over two solutions.</paragraph><paragraph label="Definition 5">Recombination [14]Given m solutions whose length is n, randomly select {a mathematical formula}m−1 crossover points from {a mathematical formula}n−1 positions between adjacent bits, and create m offspring solutions as follows. Denote the order of the m parents as {a mathematical formula}1,2,…,m. The m offspring solutions are generated by combining m components partitioned by the {a mathematical formula}m−1 crossover points, where the components of the i-th {a mathematical formula}(1⩽i⩽m) offspring solution sequentially come from parents {a mathematical formula}i,i+1,…,m−1,m,1,…,i−1.</paragraph><paragraph>In the algorithm {a mathematical formula}MOEArecombonebit, the employed mutation operator is the one-bit mutation operator (i.e., step 10), which searches locally. If there are a set of non-dominated solutions such that they weakly dominate all their Hamming neighbors, and the current population is contained in this set, the population cannot escape from this set through the one-bit mutation operator. To solve such difficulty, we can modify the one-bit mutation operator in {a mathematical formula}MOEArecombonebit to a more general mutation operator, the bit-wise mutation operator which searches globally. We call the modified algorithm {a mathematical formula}MOEArecombbitwise, which will also be studied in our paper. {a mathematical formula}MOEArecombbitwise is almost the same algorithm as {a mathematical formula}MOEArecombonebit. The only difference is that step 10 of {a mathematical formula}MOEArecombbitwise is “{a mathematical formula}Po← for each solution {a mathematical formula}x∈Ps, flip each bit with probability {a mathematical formula}1n” while that of {a mathematical formula}MOEArecombonebit is “{a mathematical formula}Po← for each solution {a mathematical formula}x∈Ps, flip a randomly chosen bit”. Since {a mathematical formula}MOEArecombonebit is an extension of {a mathematical formula}MOEAonebit by incorporating a recombination operator, {a mathematical formula}MOEArecombbitwise can also be viewed as an extension of {a mathematical formula}MOEAbitwise using the same way.</paragraph></section><section label="4"><section-title>Analysis of recombination on artificial problems</section-title><section label="4.1"><section-title>The problems</section-title><paragraph>Two bi-objective pseudo-Boolean model problems LOTZ (Leading Ones Trailing Zeros) and COCZ (Count Ones Count Zeros) are usually used to investigate the properties of MOEAs [28], [18], [29], as the listed in Table 2.</paragraph><paragraph>For LOTZ, the first objective is to maximize the number of leading one bits (the same as the LeadingOnes problem [12]), and the other objective is to maximize the number of trailing zero bits. These two objectives have n-order bit interactions.</paragraph><paragraph label="Definition 6">LOTZ[28]The pseudo-Boolean function {a mathematical formula}LOTZ:{0,1}n→N2 is defined as follows:{a mathematical formula}</paragraph><paragraph>As analyzed in [28], the objective space of LOTZ can be partitioned into {a mathematical formula}n+1 subsets {a mathematical formula}Fi, where {a mathematical formula}i∈{0,…,n} is the sum of the two objective values, i.e., {a mathematical formula}f(x)∈Fi if {a mathematical formula}f1(x)+f2(x)=i. Obviously, {a mathematical formula}Fn={(0,n),(1,n−1),…,(n,0)} is the optimal Pareto front, and the optimal Pareto set has {a mathematical formula}n+1 elements, which are {a mathematical formula}0n,10n−1,…,1n.</paragraph><paragraph>For COCZ, the two objectives are linear functions. The first objective is to maximize the number of one bits (the same as the OneMax problem [12]), and the other objective is to maximize the number of one bits in the first half of the solution plus the number of zero bits in the second half. The two objectives are corporative in maximizing the number of one bits in the first half of the solution, but conflict in the second half.</paragraph><paragraph label="Definition 7">COCZ[29]The pseudo-Boolean function {a mathematical formula}COCZ:{0,1}n→N2 is defined as follows:{a mathematical formula} where n is even.</paragraph><paragraph>As analyzed in [29], the objective space of COCZ can be partitioned into {a mathematical formula}n/2+1 subsets {a mathematical formula}Fi, where {a mathematical formula}i∈{0,…,n/2} is the number of one bits in the first half of the solution. It is obvious that each {a mathematical formula}Fi contains {a mathematical formula}n/2+1 different objective vectors {a mathematical formula}(i+j,i+n/2−j), where {a mathematical formula}j∈{0,…,n/2} is the number of one bits in the second half. The optimal Pareto front is {a mathematical formula}Fn/2={(n2,n),(n2+1,n−1),…,(n,n2)}, and the optimal Pareto set is {a mathematical formula}{1n2⁎n2;⁎∈{0,1}}, the size of which is {a mathematical formula}2n2.</paragraph><paragraph>In this paper, we will use Weighted LPTNO (Weighted Leading Positive Ones Trailing Negative Ones) and COCZ to investigate the effect of recombination operators for MOEAs. Weighted LPTNO as in Definition 8 is a bi-objective pseudo-Boolean problem class, which is generalized from LOTZ. The first objective is to maximize the number of leading positive one bits, and the other objective is to maximize the number of trailing negative one bits.</paragraph><paragraph label="Definition 8">Weighted LPTNOThe function Weighted LPTNO: {a mathematical formula}{−1,1}n→R2 is defined as follows:{a mathematical formula} where for {a mathematical formula}1⩽i⩽n, {a mathematical formula}wi,vi&gt;0.</paragraph><paragraph>The objective vector of Weighted LPTNO can be represented as {a mathematical formula}(∑k=1i2kwk,∑k=n−j+1n2n+1−kvk), where i and j are the number of leading positive one bits and trailing negative one bits, respectively. The optimal Pareto set has {a mathematical formula}n+1 elements, which are {a mathematical formula}1n,1n−1(−1),…,1(−1)n−1,(−1)n. The optimal Pareto front is {a mathematical formula}{(∑k=1i2kwk,∑k=i+1n2n+1−kvk)|0⩽i⩽n}.</paragraph><paragraph>It is worthwhile to note that Weighted LPTNO, though which can be considered as an extension of LOTZ by shifting the solution space from {a mathematical formula}{0,1}n to {a mathematical formula}{−1,1}n and adding weights {a mathematical formula}wi and {a mathematical formula}vi, has very different properties from LOTZ. For LOTZ, the optimal Pareto front is symmetric, i.e., if {a mathematical formula}(a,b) is in the optimal Pareto front, so is {a mathematical formula}(b,a), and is thus convex. However, for Weighted LPTNO, the optimal Pareto front can be nonsymmetric and nonconvex in general, which may result in much more complicated situations.</paragraph></section><section label="4.2">Analysis on the Weighted LPTNO problem<paragraph>First, we derive the running time of the initialization procedure of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise. The initialization is to optimize the two objectives of a problem separately by two independent RLS. For Weighted LPTNO, the objectives have the same structure as the LeadingOnes problem, which we know that RLS takes {a mathematical formula}Θ(n2) time to optimize by Theorem 13 in [24].</paragraph><paragraph>During the optimization of RLS in the initialization, a solution is examined whether it is local optimal for an objective every n mutation steps. The running time of examining once is n because the neighborhood size of a solution is n. Thus, the total running time of examining is the same as that of optimization. We then have the following lemma.</paragraph><paragraph label="Lemma 1">On Weighted LPTNO, the expected running time of the initialization procedure of{a mathematical formula}MOEArecombonebitand{a mathematical formula}MOEArecombbitwiseis{a mathematical formula}Θ(n2).</paragraph><paragraph>Then, we focus on the size of the population during the evolution process.</paragraph><paragraph label="Lemma 2">On Weighted LPTNO, the population size of MOEAs maintaining non-dominated solutions is always not larger than{a mathematical formula}n+1, and equals to{a mathematical formula}n+1iff the population is the optimal Pareto set.</paragraph><paragraph label="Proof">Because the solutions in the population have a one-to-one correspondence with the objective vectors in the front of the population, the size of the population equals to the size of its front. Thus, we just need to investigate the size of the front of the population.For the first objective of Weighted LPTNO, there are {a mathematical formula}n+1 possible values, {a mathematical formula}{∑i=1j2iwi|0⩽j⩽n}. In the front of the current population, any possible value of the first objective can have at most one corresponding value of the second objective, because two solutions with the same first objective value and different second objective values are comparable, which violates the property that the solutions in the population are non-dominated. Thus, the size of the front is not larger than {a mathematical formula}n+1. If the size of the front equals to {a mathematical formula}n+1, the values on the first dimension of the {a mathematical formula}n+1 elements in the front are {a mathematical formula}0,2w1,∑i=122iwi,…,∑i=1n2iwi, respectively. Because the solutions in the population are non-dominated, the corresponding values on the second dimension must decrease, i.e., they are {a mathematical formula}∑i=1n2n+1−ivi,∑i=2n2n+1−ivi,…,2vn,0, respectively. Thus, the front is just the optimal Pareto front. □</paragraph><paragraph>In the evolution process of the MOEAs analyzed in this paper, it is easy to see that the population contains at most one Pareto optimal solution for each element in the optimal Pareto front, and the Pareto optimal solution will never be eliminated once it has been found. Thus, to find the optimal Pareto front, it is sufficient to increase the number of Pareto optimal solutions enough (e.g., the size of the optimal Pareto front) times. We call the event that the number of Pareto optimal solutions increases in one step a success. Then, by analyzing the expected steps for a success and summing up the expected steps for all the required successes, we can get the expected running time bound of the MOEAs. In the following proof, we will often use this idea.</paragraph><paragraph>Note that we investigate the bi-objective problems in this paper, thus when selecting solutions for reproduction in {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise, the best solution in the current population for a randomly selected objective is selected first, and then the other solution is randomly chosen from the remaining solutions. Also since the bi-objective problems are considered in this paper, the recombination operator used is just one-point crossover. In the following analysis, we always denote {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise with crossover probability {a mathematical formula}pc=0.5 by {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise respectively, and denote them with crossover probability {a mathematical formula}pc=0 by {a mathematical formula}MOEArecomb,0onebit and {a mathematical formula}MOEArecomb,0bitwise respectively.</paragraph><paragraph label="Theorem 1">On Weighted LPTNO, the expected running time of{a mathematical formula}MOEArecomb,0.5onebitand{a mathematical formula}MOEArecomb,0.5bitwiseis{a mathematical formula}Θ(n2).</paragraph><paragraph label="Proof">For Weighted LPTNO, the size of the optimal Pareto front is {a mathematical formula}n+1. After the initialization, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}(−1)n have been found. Thus, it is sufficient to increase the number of Pareto optimal solutions {a mathematical formula}n−1 times for finding the optimal Pareto front.Then, we consider the expected steps for a success when starting from a population P containing {a mathematical formula}i+1{a mathematical formula}(1⩽i⩽n−1) Pareto optimal solutions. In the selection procedure, since the two solutions {a mathematical formula}1n and {a mathematical formula}(−1)n, which are optimal for the two objectives of Weighted LPTNO respectively, have been found, it actually selects one solution x randomly from {a mathematical formula}{1n,(−1)n} first, and then selects the other solution randomly from the remaining solutions {a mathematical formula}P−{x}. We then consider two cases in selection for the probability p of generating one new Pareto optimal solution by one-point crossover in one step: the two solutions {a mathematical formula}1n and {a mathematical formula}(−1)n are selected; one selected solution is either {a mathematical formula}1n or {a mathematical formula}(−1)n and the other selected one is a Pareto optimal solution from {a mathematical formula}P−{1n,(−1)n}. In the former case which happens with probability {a mathematical formula}1|P|−1, {a mathematical formula}p=n−in−1. In the latter case which happens with probability {a mathematical formula}12(|P|−1), suppose that the selected Pareto optimal solution from {a mathematical formula}P−{1n,(−1)n} has {a mathematical formula}k(0&lt;k&lt;n) leading positive ones, the number of Pareto optimal solutions having more than k leading positive ones in the current population is {a mathematical formula}k′(1⩽k′⩽i−1) and the other selected solution is {a mathematical formula}1n, then {a mathematical formula}p=n−k−k′n−1. Correspondingly, when the other selected solution is {a mathematical formula}(−1)n, then {a mathematical formula}p=k−i+k′n−1. Thus, in the latter case, {a mathematical formula}p=12(|P|−1)⋅n−k−k′n−1+12(|P|−1)⋅k−i+k′n−1=n−i2(|P|−1)(n−1). By combining these two cases, {a mathematical formula}p=1|P|−1⋅n−in−1+(i−1)⋅n−i2(|P|−1)(n−1)=(i+1)(n−i)2(|P|−1)(n−1), where the factor {a mathematical formula}(i−1) is because there are {a mathematical formula}i−1 Pareto optimal solutions in {a mathematical formula}P−{1n,(−1)n} for selection in the latter case. Because the crossover probability is {a mathematical formula}12, the number of Pareto optimal solutions increases in one step with probability at least {a mathematical formula}(i+1)(n−i)4(|P|−1)(n−1)⩾(i+1)(n−i)4(n−1)2, where the inequality is by {a mathematical formula}|P|⩽n from Lemma 2. Thus, the expected steps for a success when starting from a population containing {a mathematical formula}i+1 Pareto optimal solutions is at most {a mathematical formula}4(n−1)2(i+1)(n−i).Because two offspring solutions need to be evaluated in one reproduction step, the running time of one step is counted as 2. Thus, the expected running time to find the optimal Pareto front after initialization is at most {a mathematical formula}2⋅∑i=1n−14(n−1)2(i+1)(n−i), i.e., {a mathematical formula}O(nlnn). By combining the expected running time {a mathematical formula}Θ(n2) of the initialization in Lemma 1, the expected running time of {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise on Weighted LPTNO is {a mathematical formula}Θ(n2). □</paragraph><paragraph>Therefore, we have proved that the expected running time of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise with crossover probability 0.5 on Weighted LPTNO is {a mathematical formula}Θ(n2). The running time on the LOTZ problem, a special case of Weighted LPTNO, has been well studied for the MOEAs with only mutation. Compared with all the previously analyzed MOEAs with one-bit mutation or bit-wise mutation as in the 3rd column of Table 2, {a mathematical formula}MOEArecomb,0.5onebit/MOEArecomb,0.5bitwise has better running time on LOTZ.</paragraph><paragraph>Then, we also analyze the running time of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise turning off recombination on Weighted LPTNO to see whether recombination is crucial for the efficiency of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise on this problem.</paragraph><paragraph label="Theorem 2">On Weighted LPTNO, the expected running time of{a mathematical formula}MOEArecomb,0onebitis{a mathematical formula}Θ(n3).</paragraph><paragraph label="Proof">For Weighted LPTNO, the offspring Pareto optimal solution generated by one-bit mutation on a Pareto optimal solution must be adjacent to the parent Pareto optimal solution. After the initialization, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}(−1)n have been found. Thus, it is easy to see that the population in any step of the evolutionary process is always constructed by two continuous subsets L and R of the optimal Pareto set {a mathematical formula}{1n,1n−1(−1),…,(−1)n}, where {a mathematical formula}1n∈L and {a mathematical formula}(−1)n∈R. Then, we divide the optimization process into n phases, where the population in the i-th phase {a mathematical formula}(1⩽i⩽n) consists of {a mathematical formula}i+1 Pareto optimal solutions and the n-th phase corresponds to that the optimal Pareto set has been found. In the following, we will consider the probability of generating new Pareto optimal solutions in one step in each phase.In the first phase, {a mathematical formula}|L|=1 and {a mathematical formula}|R|=1, where {a mathematical formula}|⁎| denotes the size of a set. For the reproduction, the two solutions {a mathematical formula}1n and {a mathematical formula}(−1)n are selected. For {a mathematical formula}1n, the offspring solution generated by one-bit mutation can be accepted only if the rightmost positive one bit is mutated. For {a mathematical formula}(−1)n, only if the leftmost negative one bit is mutated, the offspring solution can be accepted. Thus, in one step, two new Pareto optimal solutions will be generated simultaneously with probability {a mathematical formula}1n2; only one new Pareto optimal solution will be generated with probability {a mathematical formula}2(n−1)n2; otherwise, no new Pareto optimal solution will be generated.Then, we consider the i-th phase {a mathematical formula}(1&lt;i⩽n−1). In the selection procedure of reproduction, since {a mathematical formula}1n and {a mathematical formula}(−1)n, which are optimal for the two objectives of Weighted LPTNO respectively, have been found, one solution will be randomly selected from {a mathematical formula}{1n,(−1)n}, and the other solution will be randomly selected from the remaining solutions. The probabilities for two selected solutions by this procedure are {a mathematical formula}12 and {a mathematical formula}1i, respectively. Then, there are two cases.Case 1: {a mathematical formula}min{|L|,|R|}&gt;1. In this case, one-bit mutation on either {a mathematical formula}1n or {a mathematical formula}(−1)n will never generate new Pareto optimal solutions, and only the rightmost solution of L or the leftmost solution of R can generate one new Pareto optimal solution with probability {a mathematical formula}1n by one-bit mutation. Thus, one new Pareto optimal solution can be generated in one step with probability {a mathematical formula}2in; otherwise, no new Pareto optimal solution will be generated.Case 2: {a mathematical formula}min{|L|,|R|}=1. Suppose that {a mathematical formula}|L|=1. If the selected solution from {a mathematical formula}{1n,(−1)n} is {a mathematical formula}(−1)n, one-bit mutation on {a mathematical formula}(−1)n will never generate new Pareto optimal solutions, and only when the other selected solution is {a mathematical formula}1n or the leftmost solution of R, mutation on it can generate one new Pareto optimal solution with probability {a mathematical formula}1n. If the selected solution from {a mathematical formula}{1n,(−1)n} is {a mathematical formula}1n, by mutation on {a mathematical formula}1n, one new Pareto optimal solution {a mathematical formula}1n−1(−1) can be generated with probability {a mathematical formula}1n, and only when the other selected solution is the leftmost solution of R, mutation on it can generate one new Pareto optimal solution with probability {a mathematical formula}1n. Thus, when {a mathematical formula}i&lt;n−1, in one step, only one new Pareto optimal solution will be generated while {a mathematical formula}min{|L|,|R|} is still 1 with probability {a mathematical formula}1in−12in2; one or two new Pareto optimal solutions will be generated while {a mathematical formula}min{|L|,|R|}&gt;1 with probability {a mathematical formula}12n+12in; otherwise, no new Pareto optimal solution will be generated. When {a mathematical formula}i=n−1, the last undiscovered Pareto optimal solution will be found in one step with probability {a mathematical formula}n2+2n−12(n−1)n2.We know that during the evolution process after initialization, the state of the population will change as follows:<list>start at the 1st phase;transfer to case 2;stay at case 2;transfer to case 1;stay at case 1;end at the n-th phase, i.e, the optimal Pareto front is found.From the analysis above, we know that the probability of generating one new Pareto optimal solution in the process of steps 3 and 5 is </list><paragraph>{a mathematical formula}Θ(1in). Moreover, the probability of transferring at steps 2 and 4 is {a mathematical formula}Ω(1n2). Thus, the expected steps after the initialization procedure to generate the optimal Pareto front is {a mathematical formula}Θ(∑i=1n−1in)=Θ(n3). By combining the expected running time {a mathematical formula}Θ(n2) of the initialization in Lemma 1, the expected running time of {a mathematical formula}MOEArecomb,0onebit on Weighted LPTNO is {a mathematical formula}Θ(n3). □</paragraph></paragraph><paragraph label="Theorem 3">On Weighted LPTNO, the expected running time of{a mathematical formula}MOEArecomb,0bitwiseis{a mathematical formula}Ω(n2)and{a mathematical formula}O(n3).</paragraph><paragraph label="Proof">After the initialization procedure, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}(−1)n have been found. Thus, it is sufficient to increase the number of Pareto optimal solutions {a mathematical formula}n−1 times to find the optimal Pareto front.Before finding the optimal Pareto front, there always exists at least one Pareto optimal solution in the current population which can generate one new Pareto optimal solution by flipping just the rightmost positive one bit or the leftmost negative one bit. Because the probability of selecting a specific solution is at least {a mathematical formula}1n−1 by Lemma 2, the number of Pareto optimal solutions increases in one step with probability at least {a mathematical formula}1n−11n(1−1n)n−1⩾1en(n−1).Thus, the expected running time to find the optimal Pareto front after the initialization procedure is at most {a mathematical formula}2en(n−1)2. By combining the expected running time {a mathematical formula}Θ(n2) of the initialization procedure in Lemma 1, the expected running time of the whole evolution process is {a mathematical formula}Ω(n2) and {a mathematical formula}O(n3).  □</paragraph><paragraph>We have proved that the expected running time of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise without crossover on Weighted LPTNO is {a mathematical formula}Θ(n3)/Ω(n2), which increases from {a mathematical formula}Θ(n2) of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise with crossover probability 0.5. Thus, recombination is crucial for the efficiency of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise on Weighted LPTNO.</paragraph><paragraph>From the analysis of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise on Weighted LPTNO, we can find that recombination works by accelerating the filling of the Pareto front through recombining diverse optimal solutions found-so-far. For example, when the two diverse Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}1n/2(−1)n/2 are selected for reproduction, the probability of generating offspring Pareto optimal solutions which are different from the parents by one-point crossover is {a mathematical formula}n/2−1n, while the probability on any two selected solutions by mutation (one-bit or bit-wise) is at most {a mathematical formula}4n.</paragraph></section><section label="4.3">Analysis on the COCZ problem<paragraph>First, the initialization of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise is to optimize the two objectives of COCZ, which have the same structure as the OneMax problem, by two independent RLS. By Theorem 11 in [24], it is known that the running time of RLS on OneMax is {a mathematical formula}Θ(nlnn). During the optimization of RLS in the initialization, a solution is examined whether it is local optimal for an objective every n mutation steps. The running time of examining once is n. Thus, the total running time of examining is the same as that of optimization. Then, we can get the following lemma.</paragraph><paragraph label="Lemma 3">On COCZ, the expected running time of the initialization procedure of{a mathematical formula}MOEArecombonebitand{a mathematical formula}MOEArecombbitwiseis{a mathematical formula}Θ(nlnn).</paragraph><paragraph>Then, we bound the size of the population during the evolution.</paragraph><paragraph label="Lemma 4">On COCZ, the population size of MOEAs maintaining non-dominated solutions is always not larger than{a mathematical formula}n/2+1.</paragraph><paragraph label="Proof">By the definition of COCZ, the objective vector can be represented as {a mathematical formula}(i+j,i+n/2−j), where i and j{a mathematical formula}(0⩽i,j⩽n/2) are the number of one bits in the first and second half of a solution, respectively. For each value of j, there can be only one corresponding value of i, because two objective vectors with the same j value and different i values are comparable, which violates the property that the MOEAs maintain non-dominated solutions. Thus, the front of the population contains at most {a mathematical formula}n/2+1 objective vectors.Because the population has a one-to-one correspondence with its front, the size of the population equals to the size of its front. Thus, the population size is not larger than {a mathematical formula}n/2+1.  □</paragraph><paragraph label="Theorem 4">On COCZ, the expected running time of{a mathematical formula}MOEArecomb,0.5onebitand{a mathematical formula}MOEArecomb,0.5bitwiseis{a mathematical formula}Θ(nlnn).</paragraph><paragraph label="Proof">For COCZ, the size of the optimal Pareto front is {a mathematical formula}n2+1. After the initialization procedure, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}1n20n2 have been found. Thus, it is sufficient to increase the number of Pareto optimal solutions {a mathematical formula}n2−1 times to find the optimal Pareto front.Then, we consider the expected steps for a success when starting from a population P containing {a mathematical formula}i+1(1⩽i⩽n2−1) Pareto optimal solutions. In the selection procedure, since the two solutions {a mathematical formula}1n and {a mathematical formula}1n20n2, which are optimal for the two objectives of COCZ respectively, have been found, the algorithm actually selects one solution x randomly from {a mathematical formula}{1n,1n20n2} first, and then selects the other solution randomly from the remaining solutions {a mathematical formula}P−{x}. Then, we consider two cases in selection for the probability p of generating one or two new Pareto optimal solutions by one-point crossover in one step: the two solutions {a mathematical formula}1n and {a mathematical formula}1n20n2 are selected; one selected solution is either {a mathematical formula}1n or {a mathematical formula}1n20n2 and the other selected one is a Pareto optimal solution from {a mathematical formula}P−{1n,1n20n2}. In the former case which happens with probability {a mathematical formula}1|P|−1, {a mathematical formula}p⩾n/2−in−1. In the latter case which happens with probability {a mathematical formula}12(|P|−1), suppose that the selected Pareto optimal solution from {a mathematical formula}P−{1n,1n20n2} has k{a mathematical formula}(1⩽k⩽n2−1) 0 bits, the number of Pareto optimal solutions having less than k 0 bits in the current population is {a mathematical formula}k′{a mathematical formula}(1⩽k′⩽i−1) and the other selected solution is {a mathematical formula}1n, then {a mathematical formula}p⩾k−k′n−1. Correspondingly, when the other selected solution is {a mathematical formula}1n20n2, then {a mathematical formula}p⩾n/2−k−i+k′n−1. Thus, in the latter case, {a mathematical formula}p⩾12(|P|−1)⋅k−k′n−1+12(|P|−1)⋅n/2−k−i+k′n−1=n/2−i2(|P|−1)(n−1). By combining these two cases, {a mathematical formula}p⩾1|P|−1⋅n/2−in−1+(i−1)⋅n/2−i2(|P|−1)(n−1)=(i+1)(n/2−i)2(|P|−1)(n−1). Because the crossover probability is {a mathematical formula}12, the number of Pareto optimal solutions increases in one step with probability at least {a mathematical formula}(i+1)(n/2−i)4(|P|−1)(n−1)⩾(i+1)(n/2−i)2n(n−1), where the inequality is by {a mathematical formula}|P|⩽n/2+1 from Lemma 4. Thus, the expected steps for a success is at most {a mathematical formula}2n(n−1)(i+1)(n/2−i).Therefore, the expected running time to find the optimal Pareto front is at most {a mathematical formula}2⋅∑i=1n2−12n(n−1)(i+1)(n/2−i), i.e., {a mathematical formula}O(nlnn). By combining the expected running time {a mathematical formula}Θ(nlnn) of the initialization procedure in Lemma 3, the expected running time of {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise on COCZ is {a mathematical formula}Θ(nlnn). □</paragraph><paragraph>Therefore, we have proved that the expected running time of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise with crossover probability 0.5 on COCZ is {a mathematical formula}Θ(nlnn). Compared with all the previously analyzed MOEAs with one-bit mutation as in the last cell of the 2nd row of Table 2, {a mathematical formula}MOEArecomb,0.5onebit has better running time on COCZ. For {a mathematical formula}MOEArecombbitwise, it uses bit-wise mutation. Note that {a mathematical formula}MOEAbitwise is the only previously analyzed MOEA with bit-wise mutation, and its expected running time on COCZ is unknown. Thus, for the comparison purpose, we derive the running time of {a mathematical formula}MOEAbitwise on COCZ.</paragraph><paragraph label="Theorem 5">On COCZ, the expected running time of{a mathematical formula}MOEAbitwiseis{a mathematical formula}O(n2lnn).</paragraph><paragraph label="Proof">We divide the evolutionary process into two phases. The first phase starts after initialization and finishes until the first Pareto optimal solution is found. The second phase finishes until the optimal Pareto front is found.For the first phase, let {a mathematical formula}j(0⩽j⩽n/2) denote the maximal number of 1 bits in the first half of the solutions in the current population. Because a solution with less 1 bits in its first half cannot dominate a solution with more 1 bits in its first half, j cannot decrease. Then, j increases in one step with probability at least {a mathematical formula}1n/2+1n/2−jn(1−1n)n−1⩾n/2−jen(n/2+1), since it is sufficient to select the solution with j number of 1 bits in its first half for mutation, flip one 0 bit in the first half of this solution and keep the other bits unchanged, where the probability of selection is at least {a mathematical formula}1n/2+1 by Lemma 4 and the probability of mutation is {a mathematical formula}n/2−jn(1−1n)n−1. Because any solution with {a mathematical formula}n2 number of 1 bits in its first half is a Pareto optimal solution, {a mathematical formula}n2 such steps increasing the value of j are sufficient to find the first Pareto optimal solution. Thus, the expected running time of the first phase is at most {a mathematical formula}∑j=0n/2−1en(n/2+1)n/2−j, i.e., {a mathematical formula}O(n2lnn).For the second phase, before finding the optimal Pareto front, there always exists at least one Pareto optimal solution in the current population which can generate one new Pareto optimal solution by flipping just one 1 bit or one 0 bit in its second half. We call such Pareto optimal solutions boundary Pareto optimal solutions. Thus, the number of Pareto optimal solutions can increase by 1 in one step with probability at least {a mathematical formula}1n/2+1min{i,n/2−i}n(1−1n)n−1⩾min{i,n/2−i}en(n/2+1), since it is sufficient to select one boundary Pareto optimal solution for mutation, and flip just one 1 bit or one 0 bit in its second half, where the probability of selection is at least {a mathematical formula}1n/2+1 by Lemma 4, the probability of mutation is at least {a mathematical formula}min{i,n/2−i}n(1−1n)n−1, and i is the number of 1 bits in the second half of the selected boundary Pareto optimal solution. Because {a mathematical formula}n2 such steps increasing the number of Pareto optimal solutions are sufficient to find the optimal Pareto front of COCZ, the expected running time of the second phase is at most {a mathematical formula}∑i=1⌈n/4⌉2⋅en(n/2+1)i, i.e., {a mathematical formula}O(n2lnn).By combining the running time of these two phases, the expected running time of the whole evolution process is {a mathematical formula}O(n2lnn).  □</paragraph><paragraph>Therefore, compared with {a mathematical formula}MOEAbitwise on COCZ, {a mathematical formula}MOEArecomb,0.5bitwise has better upper bound of running time. Then, we analyze the running time of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise turning off recombination on COCZ to see whether recombination is crucial for the efficiency of {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise on this problem.</paragraph><paragraph label="Theorem 6">On COCZ, the expected running time of{a mathematical formula}MOEArecomb,0onebitis{a mathematical formula}Ω(n2)and{a mathematical formula}O(n2lnn).</paragraph><paragraph label="Proof">For COCZ, we define that two Pareto optimal solutions are consecutive if the difference of the number of 0 bits for these two solutions is 1. Then, the offspring Pareto optimal solution generated by one-bit mutation on a Pareto optimal solution must be consecutive with the parent Pareto optimal solution. After the initialization, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}1n20n2 have been found. Then, it is easy to see that the population in the evolutionary process is always constructed by two continuous set of Pareto optimal solutions L and R, where {a mathematical formula}1n∈L, {a mathematical formula}1n20n2∈R, and every two adjacent Pareto optimal solutions in L or R are consecutive. Then, we divide the optimization process into {a mathematical formula}n2 phases, where the population in the i-th phase {a mathematical formula}(1⩽i⩽n2) consists of {a mathematical formula}i+1 Pareto optimal solutions and the {a mathematical formula}n2-th phase corresponds to that the optimal Pareto front has been found. In the following, we will consider the probability of generating new Pareto optimal solutions in one step in each phase.In the first phase, {a mathematical formula}|L|=1 and {a mathematical formula}|R|=1. For the reproduction, the two solutions {a mathematical formula}1n and {a mathematical formula}1n20n2 are selected. For {a mathematical formula}1n, the offspring solution generated by one-bit mutation will be accepted if the 1 bit in the second half is mutated. For {a mathematical formula}1n20n2, if the 0 bit is mutated, the offspring solution will be accepted. Thus, in one step, two new Pareto optimal solutions will be generated simultaneously with probability {a mathematical formula}14; only one new Pareto optimal solution will be generated with probability {a mathematical formula}12; otherwise, no new Pareto optimal solution will be generated.Then, we consider the i-th phase {a mathematical formula}(1&lt;i⩽n2−1). In the selection procedure of reproduction, since {a mathematical formula}1n and {a mathematical formula}1n20n2, which are optimal for the two objectives of COCZ respectively, have been found, one solution will be randomly selected from {a mathematical formula}{1n,1n20n2}, and the other solution will be randomly selected from the remaining solutions. The probabilities for two selected solutions by this procedure are {a mathematical formula}12 and {a mathematical formula}1i, respectively. Then, there are two cases.Case 1: {a mathematical formula}min{|L|,|R|}&gt;1. In this case, one-bit mutation on either {a mathematical formula}1n or {a mathematical formula}1n20n2 will never generate new Pareto optimal solutions, and only the rightmost solution in L and the leftmost solution in R can generate one new Pareto optimal solution with probability {a mathematical formula}n/2−(|L|−1)n and {a mathematical formula}n/2−(|R|−1)n respectively by one-bit mutation. Thus, one new Pareto optimal solution can be generated in one step with probability {a mathematical formula}n/2−(|L|−1)in+n/2−(|R|−1)in=n−i+1in; otherwise, no new Pareto optimal solution will be generated.Case 2: {a mathematical formula}min{|L|,|R|}=1. Suppose that {a mathematical formula}|L|=1. If the selected solution from {a mathematical formula}{1n,1n20n2} is {a mathematical formula}1n20n2, one-bit mutation on it will never generate new Pareto optimal solutions, and only when the other selected solution is {a mathematical formula}1n or the leftmost solution of R, mutation on it can generate one new Pareto optimal solution with probability {a mathematical formula}12 and {a mathematical formula}n/2−(i−1)n, respectively. If the selected solution from {a mathematical formula}{1n,1n20n2} is {a mathematical formula}1n, by mutation on {a mathematical formula}1n, one new Pareto optimal solution can be generated with probability {a mathematical formula}12, and only when the other selected solution is the leftmost solution of R, mutation on it can generate one new Pareto optimal solution with probability {a mathematical formula}n/2−(i−1)n. Thus, when {a mathematical formula}i&lt;n2−1, in one step, only one new Pareto optimal solution will be generated while {a mathematical formula}min{|L|,|R|} is still 1 with probability {a mathematical formula}3(n/2−i+1)4in; one or two new Pareto optimal solutions will be generated while {a mathematical formula}min{|L|,|R|}&gt;1 with probability {a mathematical formula}i+14i; otherwise, no new Pareto optimal solution will be generated. When {a mathematical formula}i=n2−1, the last undiscovered Pareto optimal solution will be found in one step with probability {a mathematical formula}n2+124n2−8n.The state of the population during the evolution will change as similar as that in the proof of Theorem 2. From the analysis above, we know that the probabilities of generating one new Pareto optimal solution in the process of steps 3 and 5 are {a mathematical formula}Θ(n/2−i+1in) and {a mathematical formula}Θ(n−i+1in), respectively. Moreover, the probability of transferring at steps 2 and 4 is {a mathematical formula}Θ(1). Thus, the expected steps after the initialization procedure to generate the optimal Pareto front is {a mathematical formula}Ω(∑i=1n/2−1inn−i+1) and {a mathematical formula}O(∑i=1n/2−1inn/2−i+1), i.e., {a mathematical formula}Ω(n2) and {a mathematical formula}O(n2lnn). By combining the expected running time {a mathematical formula}Θ(nlnn) of the initialization in Lemma 3, the expected running time of {a mathematical formula}MOEArecomb,0onebit on COCZ is {a mathematical formula}Ω(n2) and {a mathematical formula}O(n2lnn).  □</paragraph><paragraph label="Theorem 7">On COCZ, the expected running time of{a mathematical formula}MOEArecomb,0bitwiseis{a mathematical formula}Ω(nlnn)and{a mathematical formula}O(n2lnn).</paragraph><paragraph label="Proof">After the initialization procedure, the two Pareto optimal solutions {a mathematical formula}1n and {a mathematical formula}1n20n2 have been found. Thus, it is sufficient to increase the number of Pareto optimal solutions {a mathematical formula}n2−1 times to find the optimal Pareto front.Before finding the optimal Pareto front, there always exists at least one Pareto optimal solution in the current population which can generate one new Pareto optimal solution by flipping just one 1 bit or one 0 bit in its second half. Because the probability of selecting a specific solution is at least {a mathematical formula}1n/2 by Lemma 4, the number of Pareto optimal solutions increases in one step with probability at least {a mathematical formula}1n/2min{i,n/2−i}n(1−1n)n−1⩾min{i,n/2−i}en2/2, where i is the number of 1 bits in the second half of the selected Pareto optimal solution.Then, the expected running time to find the optimal Pareto front after the initialization is at most {a mathematical formula}2⋅∑i=1⌈(n−2)/4⌉2⋅en2/2i, i.e., {a mathematical formula}O(n2lnn). By combining the running time {a mathematical formula}Θ(nlnn) of the initialization in Lemma 3, the expected running time of the whole evolution process is {a mathematical formula}Ω(nlnn) and {a mathematical formula}O(n2lnn).  □</paragraph><paragraph>We have proved that the expected running time of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise without crossover on COCZ is {a mathematical formula}Ω(n2)/Ω(nlnn), which increases from {a mathematical formula}Θ(nlnn) of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise with crossover probability 0.5. Thus, recombination is crucial for the efficiency of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise on the COCZ problem. From the analysis, we can also find that recombination works by accelerating the filling of the Pareto front through recombining diverse optimal solutions found-so-far, as that we have found from the analysis on the Weighted LPTNO problem.</paragraph></section><section label="4.4"><section-title>Empirical verification</section-title><paragraph>Some running time bounds in Table 2 are not tight, which makes the comparison of performance between MOEAs not strict. For example, when comparing {a mathematical formula}MOEArecomb,0.5onebit with {a mathematical formula}MOEAonebit on COCZ, we can only say that the expected running time of {a mathematical formula}MOEArecomb,0.5onebit is better than the upper bound of the expected running time of {a mathematical formula}MOEAonebit proved-so-far. To have a more meaningful comparison, we estimate the running time order by experiments. On each problem size, we repeat independent runs of an MOEA 1000 times, and then the average running time is recorded as an estimation of the expected running time, which will be called as ERT for short. Fig. 1, Fig. 2 plot the results.</paragraph><paragraph>From Fig. 1(a), we can observe that for {a mathematical formula}MOEAfaironebit on LOTZ, the curve of the ERT divided by {a mathematical formula}n2lnn tends to a constant, and both the curve of the ERT divided by {a mathematical formula}n2 and the curve of {a mathematical formula}n2ln2n divided by the ERT grow in a closely logarithmic trend. Therefore, the observation suggests that the expected running time of {a mathematical formula}MOEAfaironebit is approximately in the order of {a mathematical formula}n2lnn. Similarly, Figs. 1(b) and 1(c) suggest that both the ERT of {a mathematical formula}MOEAgreedyonebit on LOTZ and the ERT of {a mathematical formula}MOEAonebit on COCZ is approximately in the order of {a mathematical formula}n2lnn. Therefore, by combining the proved results, we can conclude that {a mathematical formula}MOEArecomb,0.5onebit is the most efficient algorithm among the MOEAs with one-bit mutation on LOTZ and COCZ.</paragraph><paragraph>Fig. 2 suggests that the ERT of {a mathematical formula}MOEAbitwise and {a mathematical formula}MOEArecomb,0bitwise on LOTZ is approximately in the order of {a mathematical formula}n3, and the ERT of {a mathematical formula}MOEAbitwise and {a mathematical formula}MOEArecomb,0bitwise on COCZ is approximately in the order of {a mathematical formula}n2lnn and {a mathematical formula}n2/lnn, respectively. Therefore, we can conclude that {a mathematical formula}MOEArecomb,0.5bitwise is the most efficient algorithm among the MOEAs with bit-wise mutation on the two problems.</paragraph><paragraph>Then, in Fig. 3, we compare the expected running time of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise with other MOEAs empirically when the problem size is not large. The problem size for LOTZ is set in the range from 2 to 100, and that for the COCZ problem is set even integers in the range from 2 to 200. It can be observed that even in this empirical comparison, the ERT of {a mathematical formula}MOEArecomb,0.5onebit and {a mathematical formula}MOEArecomb,0.5bitwise on the two problems is the smallest among the corresponding MOEAs.</paragraph></section></section><section label="5"><section-title>Analysis of recombination on the multi-objective minimum spanning tree problem</section-title><section label="5.1"><section-title>The problem</section-title><paragraph>The single-objective minimum spanning tree (MST) problem is a classical polynomial solvable combinatorial problem, which is to find a connected subgraph with the minimum weight from an undirected connected graph. However, the multi-objective MST problem with at least two objectives, where each edge of a graph is assigned to a weight vector rather than a single weight, has been proved to be NP-hard [2], [13]. It has found many real applications in designing networks. For example, in the design for a layout of telecommunication systems, besides the cost for connection between terminals, other factors, e.g., the time for communication and the network reliability, may also need to be considered. For solving this problem, many algorithms have been proposed for approximation, e.g., deterministic algorithms [19], [43] and evolutionary algorithms [55], [5].</paragraph><paragraph>The multi-objective MST problem can be described as follows. Given an undirected connected graph {a mathematical formula}G=(V,E) on n vertices and m edges where V and {a mathematical formula}E={e1,e2,…,em} are the vertex set and edge set respectively, each edge {a mathematical formula}ei has a weight vector {a mathematical formula}(w1i,w2i,…,wki), where {a mathematical formula}wji&gt;0 is the value of edge {a mathematical formula}ei with respect to the j-th weight. The goal is to find connected subgraphs {a mathematical formula}G′=(V,E′⊆E) which minimize the objective vector{a mathematical formula} The special case with {a mathematical formula}k=1 is just the single-objective MST problem. Let {a mathematical formula}wjmax denote the maximal value for the j-th weight (i.e., {a mathematical formula}wjmax=max{wji|1⩽i⩽m}), {a mathematical formula}wmax=max{wjmax|1⩽j⩽k} and {a mathematical formula}wmin=min{wjmax|1⩽j⩽k}.</paragraph><paragraph>For MOEAs solving the multi-objective MST problem, a solution x is usually represented by a Boolean string of length m, i.e., {a mathematical formula}x∈{0,1}m, where {a mathematical formula}xi=1 means that the edge {a mathematical formula}ei is selected by x[42]. A commonly used fitness function for minimizing the j-th objective [33] is{a mathematical formula} where {a mathematical formula}c(x) is the number of connected components of the subgraph described by x, and {a mathematical formula}wub=n2wmax. Note that in this fitness function, the first term {a mathematical formula}(c(x)−1)wub2 makes that a subgraph with fewer connected components is better, the second term {a mathematical formula}(∑i=1mxi−n+1)wub makes that a connected subgraph with fewer edges is better, and the last term {a mathematical formula}∑i=1mxiwji makes that a spanning tree with a smaller weight is better. That is, {a mathematical formula}fj(x) is minimized with respect to the lexicographic order of {a mathematical formula}(c(x),∑i=1mxi,∑i=1mxiwji).</paragraph><paragraph>By the fitness function of Eq. (1), all the objectives are consistent on decreasing the number of connected components and decreasing the number of edges of a connected subgraph. Thus, a Pareto optimal solution must be a spanning tree.</paragraph><paragraph>We will consider the bi-objective MST problem in our analysis. In particular, we will analyze solving a subclass of bi-objective MST problem with a strictly convex optimal Pareto front, and approximating the general bi-objective MST problem. The two tasks are described as follows.</paragraph><paragraph>Let F denote a Pareto front of a bi-objective minimization problem. The convex and strictly convex sub-front of F, denoted as {a mathematical formula}conv(F) and {a mathematical formula}sconv(F) respectively, is defined in Definition 9.</paragraph><paragraph label="Definition 9">(Strictly) convex sub-frontGiven a Pareto front F of a bi-objective minimization problem, let the convex sub-front {a mathematical formula}conv(F) be the smallest subset of F such that{a mathematical formula} and let the strictly convex sub-front {a mathematical formula}sconv(F) be the smallest subset of F such that{a mathematical formula}</paragraph><paragraph>For example, in Fig. 4, F consists of all the points represented by •, ∘ and ×, then {a mathematical formula}conv(F) consists of the points represented by both • and ∘, and {a mathematical formula}sconv(F) consists of the points represented by •.</paragraph><paragraph>Let {a mathematical formula}F⁎ denote the optimal Pareto front. Our first task is to analyze MOEAs solving a subclass of bi-objective MST problem where {a mathematical formula}F⁎=sconv(F⁎), i.e., the optimal Pareto front equals its strictly convex sub-front.</paragraph><paragraph>Our second task is to approximate the optimal Pareto front of the general bi-objective MST problem, particularly, find {a mathematical formula}(1+ϵ)-approximation as defined in Definition 10, which means that for every Pareto optimal solution we have a solution that is {a mathematical formula}(1+ϵ) close on every objective. Note that, approximation here is considered for minimization. Then, the expected running time of MOEAs for approximation is the number of fitness evaluations until a desired approximation of the optimal Pareto front is found.</paragraph><paragraph label="Definition 10">{a mathematical formula}(1+ϵ)-approximationGiven a k-objective optimization task, for any {a mathematical formula}ϵ&gt;0, a set P of solutions is a {a mathematical formula}(1+ϵ)-approximation of the optimal Pareto front if {a mathematical formula}∀q⁎=(q1⁎,…,qk⁎)∈F⁎, i.e., any point in the optimal Pareto front, there exists a solution {a mathematical formula}x∈P such that {a mathematical formula}∀i=1,…,k:fi(x)⩽(1+ϵ)⋅qi⁎.</paragraph></section><section label="5.2"><section-title>Analysis</section-title><paragraph>In this section, we analyze the expected running time of {a mathematical formula}MOEArecombbitwise on the bi-objective MST problem for the above two tasks, i.e., finding the optimal Pareto front for the bi-objective MST problem with {a mathematical formula}F⁎=sconv(F⁎), and finding a 2-approximation of the optimal Pareto front for the general bi-objective MST problem.</paragraph><paragraph>For the first task, we first analyze the initialization procedure of {a mathematical formula}MOEArecombbitwise on the bi-objective MST problem. From Definition 4, we know that the initialization is to optimize two single-objective MST problems with respect to {a mathematical formula}w1 and {a mathematical formula}w2 separately by two independent RLS. For RLS, it generates an offspring solution by flipping a randomly chosen bit of the parent solution. For a spanning tree, it cannot be improved by one-bit flip, which will lead to either an unconnected subgraph or a non-spanning tree; it can decrease its weight by flipping two proper bits, which inserts an edge leading to a cycle and deletes an existed edge with a larger weight in the created cycle. Thus, we modify the RLS by its reproduction behavior. That is, with probability 0.5, it generates an offspring by flipping a randomly chosen bit of the parent; otherwise, it generates an offspring solution by flipping two randomly chosen bits. From Theorem 2 in [37], it is known that the expected running time of such RLS for finding a minimum spanning tree with respect to {a mathematical formula}w1 (or {a mathematical formula}w2) is upper bounded by {a mathematical formula}O(m2(lnn+lnw1max)) (or {a mathematical formula}O(m2(lnn+lnw2max))). Here, when examining whether a solution is local optimal for an objective, we use the solutions having Hamming distance not larger than 2 with the current solution as its neighbor space. Thus the parameter N in Definition 4 is {a mathematical formula}Θ(m2), i.e., the examining will be done every {a mathematical formula}Θ(m2) iteration. Because the running time of examining once is {a mathematical formula}Θ(m2) by the neighborhood size {a mathematical formula}Θ(m2) of a solution, the total running time of examining in the initialization is as same as that of optimization. Then, we have the following lemma.</paragraph><paragraph label="Lemma 5">On the bi-objective MST problem, the expected running time of the initialization procedure of{a mathematical formula}MOEArecombbitwiseis{a mathematical formula}O(m2(lnn+lnwmax)).</paragraph><paragraph>Lemma 6 gives a property for the points in {a mathematical formula}sconv(F⁎), which will be used in the following analysis. We denote these points by {a mathematical formula}q1,…,qr in the lexicographic order (i.e., the first value of {a mathematical formula}qi increases with i), as showed in Fig. 4. Let {a mathematical formula}d(T,T′)=|E(T)−E(T′)| denote the distance of two spanning trees T and {a mathematical formula}T′, i.e., the minimum number of two edge exchanges for constructing {a mathematical formula}T′ from T, where {a mathematical formula}E(T) denotes the edge set of T.</paragraph><paragraph label="Lemma 6">(See[33].) If{a mathematical formula}F⁎=sconv(F⁎), for each Pareto optimal spanning tree T with objective vector{a mathematical formula}qi{a mathematical formula}(1⩽i&lt;r), there always exists a Pareto optimal spanning tree{a mathematical formula}T′with objective vector{a mathematical formula}qi+1such that{a mathematical formula}d(T,T′)=1.</paragraph><paragraph>We then define a specific optimization path of MOEAs for finding {a mathematical formula}sconv(F⁎) of a bi-objective MST problem instance, as in Definition 11. At any time of the optimization, it uses crossover if crossover can produce new elements in {a mathematical formula}sconv(F⁎); otherwise, it uses mutation.</paragraph><paragraph label="Definition 11">Crossover-first-mutation-second pathFor a bi-objective MST problem instance, assume that two Pareto optimal solutions {a mathematical formula}T1⁎ and {a mathematical formula}Tr⁎ for {a mathematical formula}q1 and {a mathematical formula}qr respectively have been found. A crossover-first-mutation-second path is an optimization path of MOEAs for finding the remaining part of {a mathematical formula}sconv(F⁎) (i.e., {a mathematical formula}{q2,…,qr−1}), which behaves as follows: at any time of the optimization, if crossover on {a mathematical formula}T1⁎ (or {a mathematical formula}Tr⁎) and any other Pareto optimal solution with objective vector {a mathematical formula}qi that has been found can generate a Pareto optimal solution with objective vector {a mathematical formula}qj that has not been found, it will always apply crossover until crossover generates it; otherwise, assuming that {a mathematical formula}{q1,…,qi} have been found and {a mathematical formula}qi+1 has not been found, it will always apply mutation until mutation generates a Pareto optimal solution with objective vector {a mathematical formula}qi+1. The process of generating a new {a mathematical formula}qi by crossover only and that by mutation only on this path are called good crossover and good mutation, respectively.</paragraph><paragraph>In the following analysis, we will not distinguish a solution and the subgraph that it represents for convenience, and we will use {a mathematical formula}wj(ei) and {a mathematical formula}wj(T) to denote the value of an edge {a mathematical formula}ei and a spanning tree T for the j-th weight {a mathematical formula}wj respectively, i.e., {a mathematical formula}wj(ei)=wji and {a mathematical formula}wj(T)=∑e∈E(T)wj(e). Given a bi-objective MST problem instance and two Pareto optimal solutions {a mathematical formula}T1⁎ and {a mathematical formula}Tr⁎ for {a mathematical formula}q1 and {a mathematical formula}qr respectively, let {a mathematical formula}Ngc(T1⁎,Tr⁎) denote the maximum number of good crossover for all possible crossover-first-mutation-second paths starting from {a mathematical formula}T1⁎ and {a mathematical formula}Tr⁎, and let {a mathematical formula}Ngc=min{Ngc(T1⁎,Tr⁎)|f(T1⁎)=q1∧f(Tr⁎)=qr}.</paragraph><paragraph label="Theorem 8">The expected running time of{a mathematical formula}MOEArecomb,0.5bitwiseon the bi-objective MST problem with{a mathematical formula}F⁎=sconv(F⁎)until finding the optimal Pareto front is{a mathematical formula}O(mnwminNgc+m2nwmin(|F⁎|−Ngc)+m2(lnn+lnwmax)), where{a mathematical formula}0⩽Ngc⩽|F⁎|.</paragraph><paragraph label="Proof">We divide the optimization process into two phases. The first phase starts after initialization and finishes until two Pareto optimal solutions for {a mathematical formula}q1 and {a mathematical formula}qr respectively are found. The second phase finishes until the optimal Pareto front is found.In the first phase, two minimum spanning trees with respect to {a mathematical formula}w1 and {a mathematical formula}w2 respectively have been found after the initialization procedure. Then, we are to analyze the expected running time until a Pareto optimal solution {a mathematical formula}T1⁎ for {a mathematical formula}q1 is found. {a mathematical formula}T1⁎ is actually a minimum spanning tree for {a mathematical formula}w1; meanwhile, it is also Pareto optimal, i.e., it has the minimum weight for {a mathematical formula}w2 among all minimum spanning trees for {a mathematical formula}w1. Note that, a minimum spanning tree for {a mathematical formula}w1 will be always existed in the population, because it has the minimum value on the first objective {a mathematical formula}f1 with respect to {a mathematical formula}w1, and a non-minimum spanning tree for {a mathematical formula}w1 has a larger value on {a mathematical formula}f1 and thus cannot dominate it. Let {a mathematical formula}T1 denote the minimum spanning tree for {a mathematical formula}w1 in the current population. Then, we analyze the expected running time for constructing {a mathematical formula}T1⁎ from {a mathematical formula}T1. As {a mathematical formula}T1⁎ is a minimum spanning tree for {a mathematical formula}w1, from [32], we know that there exists a bijection α from {a mathematical formula}E(T1⁎)−E(T1) to {a mathematical formula}E(T1)−E(T1⁎) such that for each edge {a mathematical formula}e∈E(T1⁎)−E(T1), {a mathematical formula}α(e)∈Cyc(T1,e) and {a mathematical formula}w1(e)⩽w1(α(e)), where {a mathematical formula}Cyc(T1,e) is the cycle led by the insertion of e into {a mathematical formula}T1. Because {a mathematical formula}T1 is also a minimum spanning tree for {a mathematical formula}w1, it must hold that {a mathematical formula}w1(e)=w1(α(e)). We also have {a mathematical formula}w2(e)⩽w2(α(e)), because otherwise we can construct a spanning tree {a mathematical formula}T1′ with {a mathematical formula}w2(T1′)&lt;w2(T1⁎) and {a mathematical formula}w1(T1′)=w1(T1⁎), which contradicts that {a mathematical formula}T1⁎ is Pareto optimal. Thus, we have shown that for constructing {a mathematical formula}T1⁎ from {a mathematical formula}T1, there always exist k{a mathematical formula}(k=|E(T1⁎)−E(T1)|&gt;0) number of two edge exchanges which can keep the offspring spanning tree minimum for {a mathematical formula}w1 and improve it for {a mathematical formula}w2. Note that, {a mathematical formula}(1+1)-EA is a simple single-objective EA which maintains one solution, reproduces an offspring solution by bit-wise mutation and updates the parent solution if the offspring is better in every iteration. Thus, if we assume that {a mathematical formula}T1 is always selected for mutation in every iteration, the process of constructing {a mathematical formula}T1⁎ from {a mathematical formula}T1 follows the optimization procedure of {a mathematical formula}(1+1)-EA for constructing a minimum spanning tree from a non-minimum spanning tree with respect to {a mathematical formula}w2, the expected running time of which has been proved to be {a mathematical formula}O(m2(lnn+lnw2max)) from Theorem 2 in [37]. Since {a mathematical formula}T1 is optimal for the first objective, it will be selected for reproduction with probability at least {a mathematical formula}12 in every iteration. The probability of employing mutation in reproduction for {a mathematical formula}MOEArecomb,0.5bitwise is {a mathematical formula}12. Thus, the probability of selecting {a mathematical formula}T1 for mutation in each iteration is {a mathematical formula}Θ(1), which implies that the expected running time for finding {a mathematical formula}T1⁎ is {a mathematical formula}O(m2(lnn+lnw2max)). Similarly, we can prove that the expected running time for finding a corresponding Pareto optimal solution {a mathematical formula}Tr⁎ for {a mathematical formula}qr is {a mathematical formula}O(m2(lnn+lnw1max)). Thus, the expected running time of the first phase is {a mathematical formula}O(m2(lnn+lnwmax)).Then, in the second phase, we are to analyze the expected running time for finding the remaining part of the optimal Pareto front (i.e., {a mathematical formula}{q2,…,qr−1}). We consider an arbitrary crossover-first-mutation-second path starting from {a mathematical formula}T1⁎ and {a mathematical formula}Tr⁎. Obviously, its expected running time is an upper bound on the expected running time of this phase, because at any time of the optimization, there are many other possible ways to find new Pareto optimal solutions, except the way used by the path. Let P denote the current population. Because {a mathematical formula}T1⁎ and {a mathematical formula}Tr⁎ that have been found are optimal for the two objectives with respect to {a mathematical formula}w1 and {a mathematical formula}w2 respectively, in the selection procedure for reproduction, a solution {a mathematical formula}x1 will be first selected from {a mathematical formula}{T1⁎,Tr⁎} randomly, and then another solution {a mathematical formula}x2 will be selected randomly from the remaining solutions {a mathematical formula}P−{x1}. The probabilities for two selected solutions by this procedure are {a mathematical formula}12 and {a mathematical formula}1|P|−1, respectively. Then, for good crossover, the probability of generating a new {a mathematical formula}qi in one step is at least {a mathematical formula}12⋅(12⋅1|P|−1)⋅1m, where {a mathematical formula}12 is the probability of applying crossover, {a mathematical formula}(12⋅1|P|−1) is the probability of selecting two specific Pareto optimal solutions and {a mathematical formula}1m is the probability of selecting a proper crossover point; and for good mutation, the probability of generating a new {a mathematical formula}qi in one step is at least {a mathematical formula}12⋅1|P|−1⋅1m2(1−1m)m−2 by Lemma 6, where {a mathematical formula}12 is the probability of applying mutation, {a mathematical formula}1|P|−1 is the lower bound for the probability of selecting a specific solution, and {a mathematical formula}1m2(1−1m)m−2 is the probability of flipping two specific bits. Because for any value of one objective, there exists at most one corresponding solution in the population, we have {a mathematical formula}|P|⩽nwmin. Thus, the above two probabilities become at least {a mathematical formula}14mnwmin and {a mathematical formula}12em2nwmin respectively, which implies that the expected running time of a good crossover and a good mutation is at most {a mathematical formula}4mnwmin and {a mathematical formula}2em2nwmin respectively. Then, we can get that the expected running time of the crossover-first-mutation-second path with the maximum number of good crossover is at most {a mathematical formula}4mnwmin⋅Ngc(T1⁎,Tr⁎)+2em2nwmin⋅(r−2−Ngc(T1⁎,Tr⁎))⩽4mnwmin⋅Ngc+2em2nwmin⋅(r−2−Ngc), which is also an upper bound for the expected running time of this phase.By combining the expected running time of the above two phases and that of the initialization in Lemma 5, we can get that the expected running time of the whole process is upper bounded by {a mathematical formula}O(mnwminNgc+m2nwmin(r−Ngc)+m2(lnn+lnwmax)), where {a mathematical formula}r=|F⁎|.  □</paragraph><paragraph>Then, we analyze the approximation for the general bi-objective MST problem. By Lemma 7, we know that we can find a 2-approximation of the optimal Pareto front by finding {a mathematical formula}sconv(F⁎). For deriving its expected running time, we can follow the above proof except that the expected steps for a good mutation is different, because {a mathematical formula}F⁎ usually does not equal to {a mathematical formula}sconv(F⁎) which makes Lemma 6 not hold. Let {a mathematical formula}Ci={r∈conv(F⁎)|qi,qi+1∈sconv(F⁎)∧r1&gt;qi,1∧r1⩽qi+1,1}, where {a mathematical formula}r1,qi,1,qi+1,1 are the first value of {a mathematical formula}r,qi,qi+1, respectively. That is, {a mathematical formula}Ci consists of points on the i-th linear segment of {a mathematical formula}conv(F⁎). From the proof of Theorem 9 in [33], it is known that for constructing {a mathematical formula}qi+1 from {a mathematical formula}qi, there exists an evolution path where the elements are from {a mathematical formula}Ci and in the lexicographic order, and the adjacent two elements can be reached by a single two edge exchange. The expected running time for a specific two edge exchange on a specific solution is {a mathematical formula}O(m2nwmin). Thus, a good mutation needs {a mathematical formula}O(m2nwmin|Ci|) expected running time. Let {a mathematical formula}Cmin=min{|Ci||1⩽i⩽r−2}. Then, we can derive Theorem 9.</paragraph><paragraph label="Lemma 7">(See[33].) For the minimization of two objective functions with positive objective values, a solution set containing a corresponding solution for each point in{a mathematical formula}sconv(F⁎)is a 2-approximation of the optimal Pareto front{a mathematical formula}F⁎.</paragraph><paragraph label="Theorem 9">The expected running time of{a mathematical formula}MOEArecomb,0.5bitwiseon the bi-objective MST problem until finding a 2-approximation of the optimal Pareto front is{a mathematical formula}O(mnwminNgc+m2nwmin(|conv(F⁎)|−NgcCmin)+m2(lnn+lnwmax)), where{a mathematical formula}0⩽Ngc⩽|sconv(F⁎)|.</paragraph><paragraph>Neumann [33] has derived the expected running time of {a mathematical formula}MOEAbitwise on the bi-objective MST problem for the two tasks. The results are showed in Theorem 10.</paragraph><paragraph label="Theorem 10">(See[33].) For{a mathematical formula}MOEAbitwiseon the bi-objective MST problem,</paragraph><list><list-item label="(1)">if{a mathematical formula}F⁎=sconv(F⁎), the expected running time until finding the optimal Pareto front is{a mathematical formula}O(m2nwmin(|F⁎|+lnn+lnwmax));</list-item><list-item label="(2)">in general cases, the expected running time until finding a 2-approximation of the optimal Pareto front is{a mathematical formula}O(m2nwmin(|conv(F⁎)|+lnn+lnwmax)).</list-item></list><paragraph>By comparing Theorems 10 with Theorem 8, Theorem 9, we find that recombination can make MOEAs more efficient on the bi-objective MST problem. For the special case with {a mathematical formula}F⁎=sconv(F⁎), we can observe that the expected running time for finding {a mathematical formula}q1 and {a mathematical formula}qr decreases from {a mathematical formula}m2nwmin(lnn+lnwmax) to {a mathematical formula}m2(lnn+lnwmax), and the expected running time for finding the remaining part of {a mathematical formula}sconv(F⁎) decreases by {a mathematical formula}Ngc(m2nwmin−mnwmin). For the approximation in general cases, we can observe the similar result.</paragraph></section><section label="5.3"><section-title>Empirical verification</section-title><paragraph>We give some examples to show that {a mathematical formula}Ngc is usually larger than 0. Fig. 5 lists three complete graphs with 4 nodes, where each edge has two weights. We use a Boolean string of length 6 to represent a solution, where the bits correspond to the edges {a mathematical formula}1↔2,1↔3,1↔4,2↔3,2↔4,3↔4, respectively. For a complete graph with 4 nodes, there are 16 possible spanning trees, as in the 1st column of Table 3. Table 3 also shows the objective value of each spanning tree for each example problem, and the elements of the optimal Pareto front are denoted by †. The optimal Pareto fronts of these three examples are plotted in the left part of Fig. 6, where the corresponding convex sub-front consists of the points on the piece-wise linear function. We can observe that {a mathematical formula}F⁎=sconv(F⁎) for Examples 1 and 2. In Table 3, we also denote the points of {a mathematical formula}sconv(F⁎) in the lexicographic order by {a mathematical formula}q1,q2,…,qr, where {a mathematical formula}r=|sconv(F⁎)|. We then construct the crossover-first-mutation-second paths of these three examples, and show them in the right part of Fig. 6, where ‘cor’ and ‘mut’ represent the crossover and mutation respectively, and the number i represents the execution order of the current operator on the path. Letʼs look at the path of Example 1. First, crossover on the two corresponding Pareto optimal solutions for {a mathematical formula}q1 and {a mathematical formula}q4 can generate the Pareto optimal solution for {a mathematical formula}q2; after that, crossover cannot generate new Pareto optimal solutions, then mutation applies to the solution for {a mathematical formula}q2 to generate the Pareto optimal solution for {a mathematical formula}q3. We can observe that {a mathematical formula}Ngc&gt;0 on these examples. We also compare the expected running time of {a mathematical formula}MOEAbitwise and {a mathematical formula}MOEArecomb,0.5bitwise on these example problems empirically. For each MOEA, we repeat independent runs for 1000 times, and then the average running time is recorded as an estimation of the expected running time. The results are showed in Table 4. We can observe that {a mathematical formula}MOEArecomb,0.5bitwise is always better than {a mathematical formula}MOEAbitwise, which is consistent with our theoretical result.</paragraph><paragraph>The comparison in Table 4 is on three specific bi-objective MST problem instances. We also generally compare the performance of {a mathematical formula}MOEAbitwise and {a mathematical formula}MOEArecomb,0.5bitwise by experiments. We use the complete graphs with the number of nodes {a mathematical formula}n=4,5,6, respectively. For each size of n, the average running time of 1000 independent runs will be used as an estimation of the expected running time. For each independent run, following [55], [26], the graph is constructed by setting the weight vector of each edge be two integers uniformly randomly selected from {a mathematical formula}[10,100] and {a mathematical formula}[10,50], respectively. The results are showed in Table 5. We can observe that {a mathematical formula}MOEArecomb,0.5bitwise always needs less expected running time than {a mathematical formula}MOEAbitwise.</paragraph></section></section><section label="6"><section-title>Discussions and conclusions</section-title><paragraph>This paper extends our preliminary work [40]. Multi-objective evolutionary algorithms, which typically use recombination operators, have been successfully applied in many practical situations, and some theoretical results of MOEAs have been derived in recent years. However, previously analyzed MOEAs rarely incorporate recombination operators. This paper theoretically investigates whether recombination operators can be useful in the scenario of multi-objective optimization.</paragraph><paragraph>The Pareto front is a property of multi-objective optimization that is not involved in single-objective optimization, thus we investigate whether a recombination operator can have an effect on solving the Pareto front of multi-objective problems. First, we analyze the running time of two multi-objective evolutionary algorithms with a recombination operator: {a mathematical formula}MOEArecombonebit using one-bit mutation and {a mathematical formula}MOEArecombbitwise using bit-wise mutation, on two artificial model problems Weighted LPTNO and COCZ. The analytic results of {a mathematical formula}MOEArecombonebit/MOEArecombbitwise turning recombination on and off on these two problems show the helpfulness of crossover. By comparing with the previously analyzed MOEAs on the LOTZ (a special case of Weighted LPTNO) and COCZ problems, we find that {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise are the most efficient. This supports the conclusion that recombination operators can be useful for multi-objective optimization. The analysis discloses that the recombination operator works in the studied situation by accelerating the filling of the Pareto front through recombining diverse optimal solutions found-so-far. Then, we further examine the effect of recombination for solving the multi-objective minimum spanning tree problem, which is an NP-hard problem. We derive the expected running time of {a mathematical formula}MOEArecombbitwise with crossover probability 0.5, and by comparing with the previously analyzed {a mathematical formula}MOEAbitwise, we find that recombination can still work.</paragraph><paragraph>We observe that the use of the bit-wise mutation does not show advantages over the one-bit mutation in the studied cases, while they have been shown to have different ability [54]. A question that will be investigated in the future is that when the bit-wise mutation leads to a better performance than the one-bit mutation. We shall analyze {a mathematical formula}MOEArecombonebit and {a mathematical formula}MOEArecombbitwise on more realistic problems with more kinds of objective functions, and we will also try to identify problem classes for which the investigated recombination operator is helpful following [41]. There are several possible directions to extend this work in the future: first, other types as well as other usages of recombination operators in MOEAs could be investigated; second, it is also interesting to study the effect of recombination in different stages of MOEAs as well as the effect of different initialization of MOEAs; third, the interaction between mutation, recombination and selection operators is an important aspect for a full characterization of MOEAs; and moreover, analyzing MOEAs on more than two objectives is an interesting topic.</paragraph><section-title>Acknowledgements</section-title></section></content><acknowledgements><paragraph>We want to thank the associate editor and anonymous reviewers for their helpful comments and suggestions. This work was supported by the National Science Foundation of China (61375061, 61333014), the Jiangsu Science Foundation (BK2012303), and the National Fundamental Research Program of China (2014CB340501).</paragraph></acknowledgements><references><reference label="[1]"><authors>M. Abido</authors><title>Multiobjective evolutionary algorithms for electric power dispatch problem</title><host>IEEE Trans. Evol. Comput.10 (3)(2006) pp.315-329</host></reference><reference label="[2]"><authors>K.A. Andersen,K. Jörnsten,M. Lind</authors><title>On bicriterion minimal spanning trees: An approximation</title><host>Comput. Oper. Res.23 (12)(1996) pp.1171-1182</host></reference><reference label="[3]"><authors>A. Arias-Montano,C. Coello Coello,E. Mezura-Montes</authors><title>Multiobjective evolutionary algorithms in aeronautical and aerospace engineering</title><host>IEEE Trans. Evol. Comput.16 (5)(2012) pp.662-694</host></reference><reference label="[4]"><authors>T. Bäck</authors><title>Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms</title><host>(1996)Oxford University PressOxford, UK</host></reference><reference label="[5]"><authors>G. Chen,S. Chen,W. Guo,H. Chen</authors><title>The multi-criteria minimum spanning tree problem based genetic algorithm</title><host>Inf. Sci.177 (22)(2007) pp.5050-5063</host></reference><reference label="[6]"><authors>K. Deb</authors><title>Multi-Objective Optimization Using Evolutionary Algorithms</title><host>(2001)John Wiley &amp; Sons, Inc.New York, NY</host></reference><reference label="[7]"><authors>K. Deb,A. Pratap,S. Agarwal,T. Meyarivan</authors><title>A fast and elitist multiobjective genetic algorithm: NSGA-II</title><host>IEEE Trans. Evol. Comput.6 (2)(2002) pp.182-197</host></reference><reference label="[8]"><authors>M. Dietzfelbinger,B. Naudts,C. Van Hoyweghen,I. Wegener</authors><title>The analysis of a recombinative hill-climber on H-IFF</title><host>IEEE Trans. Evol. Comput.7 (5)(2003) pp.417-423</host></reference><reference label="[9]"><authors>B. Doerr,M. Theile</authors><title>Improved analysis methods for crossover-based algorithms</title><host>Proceedings of the 11th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ09)Montreal, Canada(2009) pp.247-254</host></reference><reference label="[10]"><authors>B. Doerr,E. Happ,C. Klein</authors><title>Crossover can provably be useful in evolutionary computation</title><host>Proceedings of the 10th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ08)Atlanta, GA(2008) pp.539-546</host></reference><reference label="[11]"><authors>B. Doerr,D. Johannsen,T. Kötzing,F. Neumann,M. Theile</authors><title>More effective crossover operators for the all-pairs shortest path problem</title><host>Proceedings of the 11th International Conference on Parallel Problem Solving from Nature (PPSNʼ10)Krakow, Poland(2010) pp.184-193</host></reference><reference label="[12]"><authors>S. Droste,T. Jansen,I. Wegener</authors><title>On the analysis of the (1+1) evolutionary algorithm</title><host>Theor. Comput. Sci.276 (1–2)(2002) pp.51-81</host></reference><reference label="[13]"><authors>M. Ehrgott</authors><title>Multicriteria Optimization</title><host>(2005)Springer-VerlagBerlin, Germany</host></reference><reference label="[14]"><authors>A.-E. Eiben,P.-E. Raué,Z. Ruttkay</authors><title>Genetic algorithms with multi-parent recombination</title><host>Proceedings of the 3rd International Conference on Parallel Problem Solving from Nature (PPSNʼ94)Jerusalem, Israel(1994) pp.78-87</host></reference><reference label="[15]"><authors>C. Erbas,S. Cerav-Erbas,A.D. Pimentel</authors><title>Multiobjective optimization and evolutionary algorithms for the application mapping problem in multiprocessor system-on-chip design</title><host>IEEE Trans. Evol. Comput.10 (3)(2006) pp.358-374</host></reference><reference label="[16]"><authors>S. Fischer,I. Wegener</authors><title>The one-dimensional Ising model: Mutation versus recombination</title><host>Theor. Comput. Sci.344 (2–3)(2005) pp.208-225</host></reference><reference label="[17]"><authors>T. Friedrich,J. He,N. Hebbinghaus,F. Neumann,C. Witt</authors><title>Approximating covering problems by randomized search heuristics using multi-objective models</title><host>Proceedings of the 9th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ07)London, UK(2007) pp.797-804</host></reference><reference label="[18]"><authors>O. Giel</authors><title>Expected runtimes of a simple multi-objective evolutionary algorithm</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ03)Canberra, Australia(2003) pp.1918-1925</host></reference><reference label="[19]"><authors>H.W. Hamacher,G. Ruhe</authors><title>On spanning tree problems with multiple objectives</title><host>Ann. Oper. Res.52 (4)(1994) pp.209-230</host></reference><reference label="[20]"><authors>T. Hanne</authors><title>On the convergence of multiobjective evolutionary algorithms</title><host>Eur. J. Oper. Res.117 (3)(1999) pp.553-564</host></reference><reference label="[21]"><authors>J. He,X. Yao</authors><title>Drift analysis and average time complexity of evolutionary algorithms</title><host>Artif. Intell.127 (1)(2001) pp.57-85</host></reference><reference label="[22]"><authors>T. Jansen,I. Wegener</authors><title>The analysis of evolutionary algorithms-a proof that crossover really can help</title><host>Algorithmica34 (1)(2002) pp.47-66</host></reference><reference label="[23]"><authors>T. Jansen,I. Wegener</authors><title>Real royal road functions-where crossover provably is essential</title><host>Discrete Appl. Math.149 (1–3)(2005) pp.111-125</host></reference><reference label="[24]"><authors>D. Johannsen,P. Kurur,J. Lengler</authors><title>Can quantum search accelerate evolutionary algorithms?</title><host>Proceedings of the 12th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ10)Portland, OR(2010) pp.1433-1440</host></reference><reference label="[25]"><authors>M.P. Kleeman,B.A. Seibert,G.B. Lamont,K.M. Hopkinson,S.R. Graham</authors><title>Solving multicommodity capacitated network design problems using multiobjective evolutionary algorithms</title><host>IEEE Trans. Evol. Comput.16 (4)(2012) pp.449-471</host></reference><reference label="[26]"><authors>J.D. Knowles,D.W. Corne</authors><title>A comparison of encodings and algorithms for multiobjective minimum spanning tree problems</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ01)Korea(2001) pp.544-551</host></reference><reference label="[27]"><authors>T. Kötzing,D. Sudholt,M. Theile</authors><title>How crossover helps in pseudo-Boolean optimization</title><host>Proceedings of the 13th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ11)Dublin, Ireland(2011) pp.989-996</host></reference><reference label="[28]"><authors>M. Laumanns,L. Thiele,E. Zitzler,E. Welzl,K. Deb</authors><title>Running time analysis of multi-objective evolutionary algorithms on a simple discrete optimization problem</title><host>Proceedings of the 7th International Conference on Parallel Problem Solving from Nature (PPSNʼ02)Birmingham, UK(2002) pp.44-53</host></reference><reference label="[29]"><authors>M. Laumanns,L. Thiele,E. Zitzler</authors><title>Running time analysis of multiobjective evolutionary algorithms on pseudo-Boolean functions</title><host>IEEE Trans. Evol. Comput.8 (2)(2004) pp.170-182</host></reference><reference label="[30]"><authors>P.K. Lehre,X. Yao</authors><title>Crossover can be constructive when computing unique input output sequences</title><host>Proceedings of the 7th International Conference on Simulated Evolution and Learning (SEALʼ08)Melbourne, Australia(2008) pp.595-604</host></reference><reference label="[31]"><authors>G. Lin,X. Yao</authors><title>Analysing crossover operators by search step size</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ97)Indianapolis, IN(1997) pp.107-110</host></reference><reference label="[32]"><authors>E.W. Mayr,C.G. Plaxton</authors><title>On the spanning trees of weighted graphs</title><host>Combinatorica12 (4)(1992) pp.433-447</host></reference><reference label="[33]"><authors>F. Neumann</authors><title>Expected runtimes of a simple evolutionary algorithm for the multi-objective minimum spanning tree problem</title><host>Eur. J. Oper. Res.181 (3)(2007) pp.1620-1629</host></reference><reference label="[34]"><authors>F. Neumann,J. Reichel</authors><title>Approximating minimum multicuts by evolutionary multi-objective algorithms</title><host>Proceedings of the 10th International Conference on Parallel Problem Solving from Nature (PPSNʼ08)Dortmund, Germany(2008) pp.72-81</host></reference><reference label="[35]"><authors>F. Neumann,M. Theile</authors><title>How crossover speeds up evolutionary algorithms for the multi-criteria all-pairs-shortest-path problem</title><host>Proceedings of the 11th International Conference on Parallel Problem Solving from Nature (PPSNʼ10)Krakow, Poland(2010) pp.667-676</host></reference><reference label="[36]"><authors>F. Neumann,I. Wegener</authors><title>Minimum spanning trees made easier via multi-objective optimization</title><host>Nat. Comput.5 (3)(2006) pp.305-319</host></reference><reference label="[37]"><authors>F. Neumann,I. Wegener</authors><title>Randomized local search, evolutionary algorithms, and the minimum spanning tree problem</title><host>Theor. Comput. Sci.378 (1)(2007) pp.32-40</host></reference><reference label="[38]"><authors>F. Neumann,C. Witt</authors><title>Bioinspired Computation in Combinatorial Optimization - Algorithms and Their Computational Complexity</title><host>(2010)Springer-VerlagBerlin, Germany</host></reference><reference label="[39]"><authors>P. Oliveto,J. He,X. Yao</authors><title>Analysis of population-based evolutionary algorithms for the vertex cover problem</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ08)Hong Kong, China(2008) pp.1563-1570</host></reference><reference label="[40]"><authors>C. Qian,Y. Yu,Z.-H. Zhou</authors><title>An analysis on recombination in multi-objective evolutionary optimization</title><host>Proceedings of the 13th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ11)Dublin, Ireland(2011) pp.2051-2058</host></reference><reference label="[41]"><authors>C. Qian,Y. Yu,Z.-H. Zhou</authors><title>On algorithm-dependent boundary case identification for problem classes</title><host>Proceedings of the 12th International Conference on Parallel Problem Solving from Nature (PPSNʼ12)Taormina, Italy(2012) pp.62-71</host></reference><reference label="[42]"><authors>G.R. Raidl,B.A. Julstrom</authors><title>Edge sets: an effective evolutionary coding of spanning trees</title><host>IEEE Trans. Evol. Comput.7 (3)(2003) pp.225-239</host></reference><reference label="[43]"><authors>R. Ramos,S. Alonso,J. Sicilia,C. González</authors><title>The problem of the optimal biobjective spanning tree</title><host>Eur. J. Oper. Res.111 (3)(1998) pp.617-628</host></reference><reference label="[44]"><authors>J. Richter,A. Wright,J. Paxton</authors><title>Ignoble trails-where crossover is provably harmful</title><host>Proceedings of the 10th International Conference on Parallel Problem Solving from Nature (PPSNʼ08)Dortmund, Germany(2008) pp.92-101</host></reference><reference label="[45]"><authors>G. Rudolph</authors><title>On a multi-objective evolutionary algorithm and its convergence to the Pareto set</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ98)Piscataway, NJ(1998) pp.511-516</host></reference><reference label="[46]"><authors>G. Rudolph,A. Agapie</authors><title>Convergence properties of some multi-objective evolutionary algorithms</title><host>Proceedings of the IEEE Congress on Evolutionary Computation (CECʼ00)Piscataway, NJ(2000) pp.1010-1016</host></reference><reference label="[47]"><authors>W. Spears</authors><title>Evolutionary Algorithms: The Role of Mutation and Recombination</title><host>(2000)Springer-VerlagBerlin, Germany</host></reference><reference label="[48]"><authors>R. Steuer</authors><title>Multiple Criteria Optimization: Theory, Computations, and Application</title><host>(1986)John Wiley &amp; Sons, Inc.New York, NY</host></reference><reference label="[49]"><authors>D. Sudholt</authors><title>Crossover is provably essential for the Ising model on trees</title><host>Proceedings of the 7th ACM Annual Conference on Genetic and Evolutionary Computation (GECCOʼ05)Washington, DC(2005) pp.1161-1167</host></reference><reference label="[50]"><authors>R.A. Watson</authors><title>Analysis of recombinative algorithms on a non-separable buildingblock problem</title><host>Proceedings of the 6th International Workshop on Foundations of Genetic Algorithms (FOGAʼ00)San Mateo, CA(2000) pp.69-89</host></reference><reference label="[51]"><authors>Y. Yu,Z.-H. Zhou</authors><title>A new approach to estimating the expected first hitting time of evolutionary algorithms</title><host>Artif. Intell.172 (15)(2008) pp.1809-1832</host></reference><reference label="[52]"><authors>Y. Yu,C. Qian,Z.-H. Zhou</authors><title>Towards analyzing recombination operators in evolutionary search</title><host>Proceedings of the 11th International Conference on Parallel Problem Solving from Nature (PPSNʼ10)Krakow, Poland(2010) pp.144-153</host></reference><reference label="[53]">Y. Yu,C. Qian,Z.-H. ZhouTowards analyzing crossover operators in evolutionary search via general Markov chain switching theoremCoRR<host>abs/1111.0907(2011)</host></reference><reference label="[54]"><authors>Y. Yu,X. Yao,Z.-H. Zhou</authors><title>On the approximation ability of evolutionary optimization with application to minimum set cover</title><host>Artif. Intell.180–181 (2012) pp.20-33</host></reference><reference label="[55]"><authors>G. Zhou,M. Gen</authors><title>Genetic algorithm approach on multi-criteria minimum spanning tree problem</title><host>Eur. J. Oper. Res.114 (1)(1999) pp.141-152</host></reference></references><footnote/></root>