<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370216301175</url><title>An approach to decision making based on dynamic argumentation systems</title><authors>Edgardo Ferretti,Luciano H. Tamargo,Alejandro J. García,Marcelo L. Errecalde,Guillermo R. Simari</authors><abstract>In this paper we introduce a formalism for single-agent decision making that is based on Dynamic Argumentation Frameworks. The formalism can be used to justify a choice, which is based on the current situation the agent is involved. Taking advantage of the inference mechanism of the argumentation formalism, it is possible to consider preference relations, and conflicts among the available alternatives for that reasoning. With this formalization, given a particular set of evidence, the justified conclusions supported by warranted arguments will be used by the agent's decision rules to determine which alternatives will be selected. We also present an algorithm that implements a choice function based on our formalization. Finally, we complete our presentation by introducing formal results that relate the proposed framework with approaches of classical decision theory.</abstract><keywords>Single-agent decision making;Dynamic argumentation frameworks;Argumentation in decision making</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>Argumentation systems are based on the construction and evaluation of interacting arguments that are intended to support, explain, or attack statements which can be decisions, opinions, etc. Argumentation has been applied to different domains [50], such as non-monotonic reasoning, handling inconsistency in knowledge bases, and modeling different kinds of dialogs, in particular persuasion and negotiation. An argumentation-based approach to negotiation has the advantage that in addition to the exchange of offerings, also provides reasons to support these offerings. In this way, adopting this kind of approach to decision problems has the benefit that besides choosing a proper alternative, the decision maker could also ponder the underlying reasons supporting the decision in a more understandable manner. That is, giving explanations and justifications of the choices in terms of arguments is more informative and more open to discussion and criticism than referring to a formula for a utility function [65]. Therefore, the idea of articulating decisions based on arguments became relevant to different approaches to decision making, such as decision under uncertainty [2], multi-criteria decision [47], rule-based decisions [37], and case-based decisions [15].</paragraph><paragraph>Following this trend, we propose an approach to single-agent decision making based on Dynamic Argumentation Frameworks. Dynamic Argumentation Frameworks (or DAF for short) were introduced in [55] and provide a formalization for abstract argumentation systems where the current set of evidence dynamically activates arguments that belong to a working set of arguments. The main objective of DAFs is to extend Argumentation Frameworks [23] to provide the ability of handling dynamics; for achieving that, at a given moment, the set of available evidence determines which arguments are active and can be used to make inferences to obtain justified conclusions.</paragraph><paragraph>In our proposal of an Abstract Decision Framework, a DAF is used for representing preference relations and the conflicts among the available alternatives. Four other components complete the formalism: a set of mutually exclusive alternatives which are available to the agent; a set of distinguished literals representing different binary preference relations for comparing the alternatives; a strict total order over the set of distinguished literals to represent the priority among the preference criteria provided to the agent; and a set of decision rules that implement the agent's decision making policy. Taking advantage of the argumentation formalism, preference relations and conflicts among the available alternatives can be considered for that reasoning. With this formalization, given a particular set of evidence, the justified conclusions supported by warranted arguments will be used by the agent's decision rules to determine which alternatives will be selected. We will also introduce an algorithm that implements a choice function based on our formalization. We will complete the presentation introducing formal results that relate the choice behavior of our proposed framework to Classical Decision Theory [4], [39], [51].</paragraph><paragraph>In classical approaches to decision making, the objectives of a decision maker are summarized in a rational preference relation, or in a utility function representing this relation. Despite the criticisms received, expected utility theory has become ‘the major paradigm in decision making’ [58]. As suggested by Parsons and Fox in [48], this may be due to the solid theoretical underpinning that numerical methods have; that is why they have stated that when developing decision making models based on argumentation formalisms, a key issue is to formally relate them to classical approaches to decision theory.</paragraph><paragraph>A particular feature of our approach is that the formalism is not attached to any particular agent architecture. Since it is based on a dynamic abstract argumentation framework, some elements of the formalism can be instantiated with a particular argumentation system. Another feature of our proposal is that using a DAF allows us to apply our framework to environments where the scenario (i.e., the available evidence) can change dynamically.</paragraph><paragraph>Next, we include an application example that will serve two purposes: to motivate the main ideas of our proposal and as a running example to be used in the rest of the paper.</paragraph><paragraph label="Example 1">In this application the domain consists of a mobile robotic agent that performs a cleaning task. In this environment, the agent has to decide which box has to be carried next to a defined area called {a mathematical formula}store. Boxes can be of different sizes, can be spread over the environment, and each box represents an alternative to be chosen.The agent has a set {a mathematical formula}P={p1,p2,p3} with three possible preference criteria to compare alternatives: {a mathematical formula}p1 for representing that the robot will prefer to choose a small box over a bigger one, {a mathematical formula}p2 for representing that a box nearer to the store will be preferred, and {a mathematical formula}p3 for representing that the robot prefers a box that is near to itself. A strict total order over these criteria is also considered: the agent first will prefer boxes nearer to it, i.e., nearer boxes, then boxes nearer to the store, and finally the smaller ones. Fig. 1 shows a particular scenario of our application domain where the robot has to decide among three alternatives: {a mathematical formula}box1, {a mathematical formula}box2, and {a mathematical formula}box3. Observe that {a mathematical formula}box1 and {a mathematical formula}box2 have the same size and both are smaller than {a mathematical formula}box3; {a mathematical formula}box1 is closer to the robot than the other two; {a mathematical formula}box2 is closer to the robot than {a mathematical formula}box3; {a mathematical formula}box2 is closer to the store than the other two; and that {a mathematical formula}box1 is closer to the store than {a mathematical formula}box3.</paragraph><paragraph>Consider a scenario as the one introduced in Example 1 where the robot is faced with three alternatives. Following our proposal, as will be explained below, this application domain will be represented with a dynamic argumentation framework that will provide: a working set of arguments, a way of representing the conflict among these arguments, and a preference relation for deciding between conflictive arguments. Then, the available evidence of a particular scenario will be used to identify the arguments that are active, and these arguments will be used to obtain justified conclusions with respect to this evidence. In the situation of Example 1, as will be shown, our proposed framework will select {a mathematical formula}box1.</paragraph><paragraph>As it was mentioned before, the use of argumentative reasoning for decision making has been studied in other approaches such as [3], [7], [27], [48], and the subject will be thoroughly analyzed in Section 6 where the related work is discussed. In particular, [27] proposes a framework to represent the agent's preferences and its knowledge using Possibilistic Defeasible Logic Programming [1]; there, warranted information is used in decision rules that implement the agent's decision-making policy. In contrast to [27], we develop a more general proposal since our formalization is based on an abstract dynamic argumentation framework that allows the creation of different instantiations. Like [27], in this article we propose to use decision rules and an algorithm for computing the acceptable alternatives; however, both elements were reformulated with respect to [27].</paragraph><paragraph>The article is organized as follows. In Section 2 we will introduce the basic concepts of decision-making from the point of view of the standard theory of individual rationality, and the development of the contribution of this work spans from Section 3 to Section 5. In Section 3 we will present the main results of our approach which consists of an abstract framework for decision making based on decision rules and dynamic argumentation; we will also introduce in that section the formalization of the epistemic component of our abstract decision framework. We will present the algorithm for selecting acceptable alternatives in Section 4. In Section 5 we will lay down a formal comparison of the choice behavior of the proposed framework with respect to Classical Decision Theory; furthermore, we will discuss how our proposal is related to other significant decision-making approaches in Section 6. Finally, we will offer the conclusions and consider future work in Section 7.</paragraph></section><section label="2"><section-title>Preliminaries</section-title><paragraph>We will introduce here a brief overview of the theory of individual decision making as presented in [39], where two related approaches to model the agent's decision are considered. Later on, in Section 5, the choice behavior of the argumentation-based decision framework proposed in this paper, will be formally related with these approaches to model the agent's decisions.</paragraph><paragraph>The starting point for any individual decision problem in classical approaches to decision making is the characterization of a set of possible (mutually exclusive) alternatives from which the decision maker (an agent in our case) must choose. Following the notation commonly used in the literature this set of alternatives will be denoted by X. For instance, consider the example we have already introduced (see Fig. 1) where the robot has three alternatives to select: {a mathematical formula}box1, {a mathematical formula}box2 or {a mathematical formula}box3; in that case, X becomes {a mathematical formula}{box1,box2,box3}.</paragraph><paragraph>In classical decision making approaches it is usually assumed the agent's choice behavior is modeled with a binary preference relation ≿, where given {a mathematical formula}{x,y}⊆X, {a mathematical formula}x≿y means that “x is at least as good as y”. As usual, from ≿ it is possible to derive two other important relations:</paragraph><list><list-item label="•">The strict preference relation ≻, defined as {a mathematical formula}x≻y⇔x≿y but not y≿x which is read as “x is preferred to y”.</list-item><list-item label="•">The indifference relation ∼, defined as {a mathematical formula}x∼y⇔x≿y and y≿x and which is read as “x is indifferent to y”.</list-item></list><paragraph label="Definition 1">It is customary to require the preference relation ≿ to be rational (see Definition 1) and this becomes a necessary condition when ≿ is represented by a utility function. The hypothesis of rationality is embodied in two basic assumptions concerning the preference relation ≿ as defined next. Rational preference relationA preference relation ≿ is rational if it verifies the following two properties{sup:1}:</paragraph><list><list-item label="1.">Completeness: for all {a mathematical formula}x,y∈X, {a mathematical formula}x≿y or {a mathematical formula}y≿x (or both).</list-item><list-item label="2.">Transitivity: for all {a mathematical formula}x,y,z∈X, if {a mathematical formula}x≿y and {a mathematical formula}y≿z, then {a mathematical formula}x≿z.</list-item></list><paragraph>The assumption that ≿ is complete requires that the agent has a well-defined preference between any two possible alternatives. Also, transitivity implies that it is impossible for the decision maker to be faced with a sequence of pairwise choices in which her preferences appear to cycle. For instance, following our running example we can consider that the robot will prefer to select a box that is near to itself, then, in the scenario described in Fig. 1: {a mathematical formula}box1≿box2, {a mathematical formula}box1≿box3, and {a mathematical formula}box2≿box3.</paragraph><paragraph>Considering the choice behavior of a decision maker with a rational preference relation ≿ over X, when facing a non-empty set of alternatives {a mathematical formula}B⊆X, her preference-maximizing behavior will choose any of the elements in the following set: {a mathematical formula}C⁎(B,≿)={x∈B|x≿yfor eachy∈B}. Following our running example, if we consider {a mathematical formula}B={box2,box1} then {a mathematical formula}C⁎(B,≿)={box1}, however, if we consider {a mathematical formula}B={box2,box3} then {a mathematical formula}C⁎(B,≿)={box2}. If {a mathematical formula}B={box2,box1,box3} then {a mathematical formula}C⁎(B,≿)={box1}.</paragraph><paragraph>It is a well known fact in decision theory community that completeness and transitivity assumptions are usually hard to satisfy in real-world problems (see e.g., [60], [64]), still the preference-based approach (PBA) is very relevant from a theoretical point of view. In fact, this approach is the most traditional way of modeling individual choice behavior. Nonetheless, the choice-based approach introduced next is an interesting proposal which is a more flexible formal model of theory of decision making, since it is based on entirely behavioral foundations rather than being limited to consider individual decision making as an introspection-based process.</paragraph><paragraph>The choice-based approach (CBA for short) [51] takes the choice behavior of the individual as a primitive object which is represented by means of a choice structure ({a mathematical formula}B, {a mathematical formula}C(⋅)) consisting of two elements:</paragraph><list><list-item label="•">{a mathematical formula}B is a set of subsets of X. Intuitively, each set B∈ {a mathematical formula}B represents a set of alternatives (or choice experiment) that can be conceivably posed to the decision maker. In this way, if {a mathematical formula}X={x,y,z} and {a mathematical formula}B={{x,y},{x,y,z}} we will assume that the sets {a mathematical formula}{x,y} and {a mathematical formula}{x,y,z} are valid choice experiments to be presented to the decision maker.</list-item><list-item label="•">{a mathematical formula}C(⋅) is a choice rule which basically assigns to each set of alternatives {a mathematical formula}B∈B a non-empty set that represents the alternatives that the decision maker might choose when presented the alternatives contained in B. Note that {a mathematical formula}C(B)⊆B for every {a mathematical formula}B∈B. When {a mathematical formula}C(B) contains a single element, this element represents the individual's choice among the alternatives in B. The set {a mathematical formula}C(B) might, however, contain more than one element and in this case they would represent the acceptable alternatives in B for the agent.</list-item></list><paragraph label="Example 2">Returning to the scenario shown in Fig. 1 where {a mathematical formula}X={box1,box2, {a mathematical formula}box3}. Consider the set {a mathematical formula}B={{box1},{box2},{box3},{box1,box2},{box1,box3},{box2,box3},{box1,box2,box3}}. Suppose that the choice experiment is {a mathematical formula}B={box1,box3}. If {a mathematical formula}C(B)={box1} then {a mathematical formula}box1 is the individual's choice.</paragraph><paragraph label="Definition 2">As in the rationality assumption of the PBA (Definition 1), in the CBA there is a central assumption, called the weak axiom of revealed preference (or WARP for short) [57]. As it will be explained next, this axiom imposes an element of consistency on choice behavior that is similar to the rationality assumptions of the PBA. The following definition recalls the WARP axiom: Weak axiom of revealed preferenceA choice structure {a mathematical formula}(B,C(⋅)) satisfies the weak axiom of revealed preference (WARP) if the following property holds: If for some {a mathematical formula}B∈B with {a mathematical formula}x,y∈B we have {a mathematical formula}x∈C(B), then for any {a mathematical formula}B′∈B with {a mathematical formula}x,y∈B′ and {a mathematical formula}y∈C(B′), we must also have {a mathematical formula}x∈C(B′).</paragraph><paragraph>The weak axiom requires that if there is some choice experiment {a mathematical formula}B∈B such that x and y are presented as alternatives ({a mathematical formula}x,y∈B) and “x is revealed at least as good as y” (i.e., {a mathematical formula}x∈C(B)) then there does not exist another choice experiment {a mathematical formula}B′∈B where “y is revealed strictly preferred to x” (i.e., {a mathematical formula}x,y∈B′, {a mathematical formula}y∈C(B′) and {a mathematical formula}x∉C(B′)).</paragraph><paragraph>Intuitively, the WARP principle reflects the expectation that an individual's observed choices will display a certain amount of coherence. That is to say, in our example, if given {a mathematical formula}X={box1,box2,box3}, {a mathematical formula}B={{box1,box2},{box1,box2,box3}} and a choice rule C, {a mathematical formula}C({box1,box2})={box1}, then the axiom says that it cannot be the case that {a mathematical formula}C({box1,box2,box3})={box2}. In fact, it says more: we must have {a mathematical formula}C({box1,box2,box3})={box1}, or {a mathematical formula}C({box1,box2,box3})={box3}, or {a mathematical formula}C({box1,box2,box3})={box1,box3}.</paragraph><paragraph>As mentioned above, the PBA and CBA approaches present different perspectives of the theory of individual decision making. The former considers it as a process of introspection while the latter makes assumptions about objects that are directly observable (choice behavior) rather than things that are not (preferences). In spite of these differences, under certain conditions these two approaches are related. Below, we introduce a well known and important result which states that if a decision maker has a rational preference ordering ≿, when faced with a choice experiment, her choices will necessarily generate a choice structure that satisfies the WARP principle:</paragraph><paragraph>Suppose that ≿ is a rational preference relation then the choice structure generated by ≿,{a mathematical formula}(B,C⁎(⋅,≿))satisfies the weak axiom of revealed preference.</paragraph></section><section label="3"><section-title>Argumentation-based abstract framework for decision making</section-title><paragraph>We will now introduce the main contribution of our approach: an abstract framework for decision making based on decision rules and dynamic argumentation. Later, in Section 5 our proposal will be formally related to Classical Decision Theory.</paragraph><paragraph>Our abstract decision framework will integrate five components: a set of all the available alternatives X that the decision maker has, a set of distinguished literals that refer to the agent's preferences, a strict total order over the set of distinguished literals to represent the priority among the preference criteria provided to the agent, an epistemic component that will be used for representing preference relations and conflicts among the available alternatives, and a decision component that effectively implements the agent's decision making policy based on decision rules. Next, we will define our framework and we will devote the rest of this section to present the epistemic component, while the decision component will be developed and explained in the following section. Since this is an abstract framework, the representation language will not be instantiated; however, we assume that this representation language includes constants, predicates, and classical negation (¬). In our formalization, will refer to this base language as {a mathematical formula}L.</paragraph><paragraph label="Definition 3">Abstract decision frameworkAn abstract decision framework for a language {a mathematical formula}L, is a tuple {a mathematical formula}〈X,C,&gt;C,K,Γ〉{a mathematical formula}L where:</paragraph><list><list-item label="•">{a mathematical formula}X⊂L is the set of all possible alternatives;</list-item><list-item label="•">{a mathematical formula}C⊂L is a set of distinguished literals;</list-item><list-item label="•">{a mathematical formula}&gt;C is a strict total order among elements of {a mathematical formula}C;</list-item><list-item label="•">{a mathematical formula}K, which is referred to as the epistemic component, is a dynamic argumentation framework; and</list-item><list-item label="•">Γ, called the decision component, is a set of decision rules.</list-item></list><paragraph>When no confusion could possibly arise we will drop the subindex {a mathematical formula}L from {a mathematical formula}〈X,C,&gt;C,K,Γ〉L to simplify notation. The epistemic component {a mathematical formula}K, that will be introduced next, will include evidence and arguments that the decision maker will use for reasoning, and the set Γ, explained in the next section, will be used for implementing the agent's decision making policy.</paragraph><paragraph>Following our running example we can define the abstract decision framework {a mathematical formula}〈Xr,Cr,&gt;Cr,Kr,Γr〉, with the set of alternatives {a mathematical formula}Xr={box1,box2,box3}. The epistemic component {a mathematical formula}Kr (explained in detail below) will contain evidence obtained from the domain (e.g., {a mathematical formula}smaller(box1,box3), {a mathematical formula}smaller(box2,box3)) and arguments for and against considering one box better than another one. These arguments will be considered by the dynamic argumentation framework to obtain the agent's conclusions (e.g., {a mathematical formula}better(box1,box3)). This epistemic component provides a knowledge representation tool that allows for the representation of preferences and conflicts among the agent's available alternatives.</paragraph><paragraph>In what follows, we will explain how to formalize the epistemic component of our abstract decision framework using a Dynamic Argumentation Framework. DAFs were introduced in [55] and provide a formalization for abstract argumentation systems where the current set of evidence dynamically activates arguments that belong to a working set of arguments. DAFs have been defined as a specialization of Dung's argumentation framework (AF) [23], with the main objective of extending AFs to handle dynamics. To cope with this, at any given moment, the set of available evidence will determine which arguments are active becoming usable in producing inferences. In contrast, in Dung's approach the consideration of a changing set of active arguments would involve passing from a framework to another. To keep our presentation as self-contained as possible, we refer the interest reader to our Appendix where a concise but complete description of DAFs is included.</paragraph><paragraph>The remainder of this section will be dedicated to explain how to build a particular DAF that will formalize the epistemic component for our abstract decision framework that will be responsible of obtaining the agents' conclusions. This component will consider all the evidence the agent is in possession regarding the current situation of environment which can change dynamically upon perception; different instances of this set of evidence will determine different instances of the DAF. The epistemic component will also handle the working set of arguments the decision maker will use for reasoning to obtain conclusions; for that reason, preference relations and conflicts among the available alternatives should be considered. The working set of arguments contains every argument that could be available to be used in the reasoning process. According to the available set of evidence, there is a subset of this working set that contains the arguments that are active in function of the currently present evidence.</paragraph><paragraph>In order to make a decision an agent equipped with our framework may have at its disposal one or more preference criteria which will be used to compare the alternatives in X; an important requirement is that no preference criterion generates cyclic preferences. All these preference criteria will be considered to define the preference function {a mathematical formula}pref for the DAF of the epistemic component.</paragraph><paragraph label="Example 3">Continuing with our running example, we will consider three preference criteria: the robot prefers to choose a small box over a bigger one, the robot prefers to choose a box nearer to the store over a box far to store, and the robot prefers to choose a box that is near to itself.</paragraph><paragraph>In our framework, each preference criterion will be associated with a literal in {a mathematical formula}L. These literals will be called distinguished as defined next.</paragraph><paragraph label="Definition 4">Set of distinguished literalsLet X be a set of alternatives. The set of distinguished literals {a mathematical formula}C={c1,…,cn} is a non-empty set of literals from {a mathematical formula}L. Each literal in {a mathematical formula}C represents a different binary preference relation for comparing alternatives in X.</paragraph><paragraph>Given a distinguished literal {a mathematical formula}c∈C and {a mathematical formula}x,y∈X then {a mathematical formula}c(x,y) means that “x is preferred to y with respect to the preference criterion c”. Consider the comparison criteria mentioned in Example 3, in our running example the set of distinguished literals will be {a mathematical formula}Cr={nearer_robot, {a mathematical formula}nearer_store, {a mathematical formula}smaller}; thus, considering the scenario depicted in Fig. 1, it holds {a mathematical formula}smaller(box1,box3). In our formalization, the literal {a mathematical formula}same_att(x,y) states that alternatives {a mathematical formula}x,y∈X have the same attribute values with respect to every {a mathematical formula}c∈C; e.g., {a mathematical formula}same_att(box4,box5) means that the two boxes have the same attributes for each preference criterion of the agent. Note that in our running example (Fig. 1) there are no pair of alternatives with the same attribute values; however, in Example 8 below we will introduce a scenario where there are two boxes with the same attribute values for all the preference criteria.</paragraph><paragraph label="Example 4">Since an agent can have more than one preference criterion represented by elements of the set of distinguished literals {a mathematical formula}C, then in our formalization we consider a strict total order {a mathematical formula}&gt;C among these elements. If the pair {a mathematical formula}(c′,c)∈&gt;C then the criterion represented by the distinguished literal {a mathematical formula}c′ is considered better than the one represented by c. Consider the comparison criteria mentioned in Example 3. Then, for our running example the set of distinguished literals is {a mathematical formula}Cr={nearer_robot, {a mathematical formula}nearer_store, {a mathematical formula}smaller}. We will use the following total order for representing the agent's preferences among {a mathematical formula}Cr:{a mathematical formula} That is, in our running example the agent will have three criteria available, and it will prefer first its nearer boxes, then boxes nearer to the store, and finally the smaller ones.</paragraph><paragraph>Next, in Definition 5, we will introduce the formalization of the epistemic component {a mathematical formula}K of Definition 3 with a particular DAF described as {a mathematical formula}〈E,W,⋈,pref〉. In a DAF (see the Appendix), the set of evidence E may change dynamically upon perception, and different instances of this set will determine different instances of the DAF; thus, for a given set E there will be a subset of the working set of arguments W that contains the arguments that are active. In our approach, the set E will contain a snapshot of all the information relative to the current relations among the alternatives of the set X with respect to the preference criteria represented in {a mathematical formula}C, e.g., {a mathematical formula}nearer_robot(box1,box2) belongs to the evidence in the scenario depicted in Fig. 1.</paragraph><paragraph>The working set W will contain arguments for reasoning about when an alternative is better than other. Note that in a DAF, an argument {a mathematical formula}A is a reasoning step for a claim α from a set of premises {a mathematical formula}{β1,…,βn} denoted as the pair {a mathematical formula}〈{β1,…,βn},α〉. An argument will be active if its premises are satisfied based on the current evidence. Given an evidence set E, an argument's premise is satisfied whether it belongs to E, or it is the conclusion of an active argument according to E. In this DAF the set ⋈ will contain the conflicts among arguments in W. Given an argument {a mathematical formula}A∈W, {a mathematical formula}cl(A) denotes the claim of {a mathematical formula}A and {a mathematical formula}cl(A)‾ represents the complement of {a mathematical formula}cl(A) with respect to negation (¬). Finally, the preference function {a mathematical formula}pref will consider all the agents' criteria represented in {a mathematical formula}C, and, if it is possible, it will return the argument that is based on a better distinguished literal with respect to the order {a mathematical formula}&gt;C. Since our epistemic component is defined in an abstract form, the function {a mathematical formula}pref is defined in terms of argumental structures (denoted with Σ) which are built with one or more arguments from W (see Appendix). In order to compare two argumental structures, distinguished literals will be used.</paragraph><paragraph label="Definition 5">Epistemic componentLet X be the set of all the possible candidate alternatives, {a mathematical formula}C be a set of distinguished literals in {a mathematical formula}L and {a mathematical formula}&gt;C be a strict total order over {a mathematical formula}C. An epistemic component {a mathematical formula}K, is a DAF {a mathematical formula}〈E,W,⋈,pref〉 where:</paragraph><list><list-item label="·">The evidence E is a consistent set of sentences of the form {a mathematical formula}same_att(x,y) or {a mathematical formula}c(x,y), such that {a mathematical formula}x,y∈X and {a mathematical formula}c∈C.</list-item><list-item label="·">The working set W will be such that if {a mathematical formula}c∈C, {a mathematical formula}{x,y}⊆X(x≠y) and {a mathematical formula}better∉C then:{a mathematical formula}</list-item><list-item label="·">{a mathematical formula}⋈={(A,B)|{A,B}⊆W,cl(A)=cl(B)‾}.</list-item><list-item label="·">Let {a mathematical formula}Σ1 and {a mathematical formula}Σ2 be two argumental structures in W, then{a mathematical formula} where {a mathematical formula}dlits(Σ)⊆C is the set of distinguished literals that are contained in arguments of an argumental structure Σ.</list-item></list><paragraph>In the preceding definition, each argument in W has a set of premises containing only one element: a distinguished literal {a mathematical formula}c∈C comparing alternatives {a mathematical formula}x,y∈X, such that {a mathematical formula}c(x,y) means that “x is preferred to y”; or a literal {a mathematical formula}same_att(x,y) stating that alternatives {a mathematical formula}x,y∈X have the same attribute values for each preference criterion provided to the agent. Given a pair of alternatives {a mathematical formula}x,y∈X(x≠y), the conclusion of each argument in W states that: “x is better than y” ({a mathematical formula}better(x,y)) or “x is not better than y” ({a mathematical formula}¬better(x,y)) or “y is better than x” ({a mathematical formula}better(y,x)) or “y is not better than x” ({a mathematical formula}¬better(y,x)).</paragraph><paragraph>A Dynamic Argumentation Framework imposes that all arguments must be coherent, that is, any argument {a mathematical formula}A in W must satisfy: {a mathematical formula}cl(A)‾∉pr(A), {a mathematical formula}cl(A)‾∉E, {a mathematical formula}cl(A)∉pr(A), and {a mathematical formula}cl(A)∉E (see Definition 11 in Appendix). The following proposition shows that in an epistemic framework built as stated by Definition 5, since the literal {a mathematical formula}better∉C, all arguments in the working set are coherent.</paragraph><paragraph label="Proposition 1">Given an epistemic component{a mathematical formula}K=〈E,W,⋈,pref〉, all the arguments in W are coherent.</paragraph><paragraph label="Proof">Straightforward from Definition 5.  □</paragraph><paragraph>As it is explained in detail in the Appendix, when two arguments are in conflict, the function {a mathematical formula}pref will determine which one is a defeater of the other. Then, an argument will be warranted with respect to a DAF if it has no warranted defeater. A conclusion is justified if it is the conclusion of a warranted argument.</paragraph><paragraph label="Example 5">Consider the running example where {a mathematical formula}Xr={box1,box2,box3}. In Example 4, we have introduced the set {a mathematical formula}Cr={nearer_robot,nearer_store,smaller} and {a mathematical formula}&gt;Cr={(nearer_robot,nearer_store),(nearer_robot,smaller),(nearer_store,smaller)}. Then, {a mathematical formula}Kr=〈Er,Wr,⋈r,prefr〉 is the epistemic component for the scenario depicted in Fig. 1 (where the robot r is currently involved) with the following set of evidence:{a mathematical formula}Given the set of alternatives {a mathematical formula}Xr and the distinguished literals {a mathematical formula}Cr, then, following Definition 5, the working set {a mathematical formula}Wr has forty-two arguments that are depicted with triangles in Fig. 2. White triangles denote the subset of {a mathematical formula}Wr which are active with respect to {a mathematical formula}Er, and black triangles are the inactive arguments of {a mathematical formula}Wr with respect to {a mathematical formula}Er. The text above each triangle is the conclusion of the argument, and the text below a triangle is its premise. The label inside white triangles will be used for referencing the argument along the paper. A solid arrow that connects two active arguments represents that the argument at the beginning of the arrow defeats (see Definition 15 in the Appendix) the argument at the arrow's end. In Fig. 2, {a mathematical formula}same_att, smaller, {a mathematical formula}nearer_store, {a mathematical formula}nearer_robot, better, {a mathematical formula}¬better, {a mathematical formula}box1, {a mathematical formula}box2, {a mathematical formula}box3 are abbreviated as: sa, sm, ns, nr, b, ¬b, 1, 2 and 3 respectively.Given the working set {a mathematical formula}Wr depicted in Fig. 2 and considering the evidence set {a mathematical formula}Er we obtain the following list of active arguments:{a mathematical formula} In the list above, those active arguments supporting that an alternative is better than other appear first and those supporting that an alternative is not better than other appear later. Note that the only conflicts among active arguments are {a mathematical formula}⋈r={(A6,A11),(A11,A6),(A5,A12),(A12,A5)}.Observe that argument {a mathematical formula}A11 supports that {a mathematical formula}box1 is better than {a mathematical formula}box2, based on the premise that {a mathematical formula}box1 is nearer to the robot than {a mathematical formula}box2; whereas {a mathematical formula}A6 supports that {a mathematical formula}box1 is not better than {a mathematical formula}box2 based on the premise that {a mathematical formula}box2 is nearer to the store than {a mathematical formula}box1. In the particular case of our running example, all argumental structures have only one argument which has one distinguished literal as a premise, hence, for all arguments {a mathematical formula}Ai∈Wr, the set {a mathematical formula}dlits(Ai) will be a singleton. For instance: {a mathematical formula}dlits(A6)={nearer_store} and {a mathematical formula}dlits(A11)={nearer_robot}. Since {a mathematical formula}(nearer_robot,nearer_store)∈{a mathematical formula}&gt;Cr (i.e., the robot prefers to carry boxes near to itself than boxes close to the store) then, {a mathematical formula}prefr(A11,A6)=A11. Thus, {a mathematical formula}A11 defeats {a mathematical formula}A6 but {a mathematical formula}A6 does not defeat {a mathematical formula}A11 (see Definition 15). Therefore, {a mathematical formula}A11 is warranted in {a mathematical formula}Kr and hence, the conclusion {a mathematical formula}better(box1,box2) is justified in {a mathematical formula}Kr.Arguments {a mathematical formula}A5 and {a mathematical formula}A12 are also in conflict, and we have that {a mathematical formula}dlits(A5)={nearer_store} and {a mathematical formula}dlits(A12)={nearer_robot}. Since {a mathematical formula}(nearer_robot,nearer_store)∈{a mathematical formula}&gt;Cr then, {a mathematical formula}prefr(A5,A12)=A12; hence, {a mathematical formula}A12 defeats {a mathematical formula}A5, and {a mathematical formula}A12 is thus warranted in {a mathematical formula}Kr and {a mathematical formula}¬better(box2,box1) is justified in {a mathematical formula}Kr.Finally, note that the active arguments {a mathematical formula}A1, {a mathematical formula}A2, {a mathematical formula}A3, {a mathematical formula}A4, {a mathematical formula}A7, {a mathematical formula}A8, {a mathematical formula}A9, {a mathematical formula}A10, {a mathematical formula}A13, {a mathematical formula}A14, {a mathematical formula}A15, {a mathematical formula}A16 are not in conflict with any other active argument, and therefore, they are all warranted. Observe that one conclusion can be supported by more than one argument. For instance, {a mathematical formula}A1, {a mathematical formula}A7 and {a mathematical formula}A13 are three warranted arguments that support the same conclusion: {a mathematical formula}better(box1,box3). Then, from the warranted arguments mentioned above, the set of justified conclusions in {a mathematical formula}Kr is {a mathematical formula}{better(box1,box3),better(box2,box3),better(box1,box2),¬better(box3,box1),¬better(box3,box2),¬better(box2,box1)}.</paragraph><paragraph>We have shown in Example 5 that given a working set of arguments {a mathematical formula}Wr, the available evidence {a mathematical formula}Er will determine a set {a mathematical formula}Activer⊆Wr with the current set of active arguments. Then, the conflict relation {a mathematical formula}⋈r and the preference function {a mathematical formula}prefr are used for determining the set {a mathematical formula}Warrantedr⊆Activer of the current warranted arguments. We will introduce next the decision component of our framework; this component will use the justified conclusions supported by arguments in {a mathematical formula}Warrantedr to determine which alternatives will be selected.</paragraph></section><section label="4"><section-title>Accepting alternatives</section-title><paragraph>We will formalize now the decision component Γ of our proposed abstract decision framework {a mathematical formula}〈X,C,&gt;C,K,Γ〉L, and we will propose an algorithm for computing the selecting alternatives. As we have mentioned, the decision component is a set of decision rules that will effectively implement the agent's decision making policy. Decision rules [27], that will be used to decide among alternatives from a choice experiment {a mathematical formula}B⊆X, are formalized in following definition.</paragraph><paragraph label="Definition 6">Decision ruleLet X be a set of alternatives and {a mathematical formula}B⊆X be a choice experiment {a mathematical formula}(B≠∅). A decision rule is denoted {a mathematical formula}(D⇐BP,T), where {a mathematical formula}D⊆B represents the set of alternatives that this rule will select, P⊆ {a mathematical formula}L represents preconditions for using this rule, and {a mathematical formula}T⊆L represents the constraints that the rule has for its usage.</paragraph><paragraph label="Definition 7">A decision rule “{a mathematical formula}D⇐BP,T” can be read as “if all the preconditions included in P hold and no constraint of the set T holds then D is the subset of alternatives from B to be selected”. Hence, D will represent those alternatives that this rule decides to adopt from the choice experiment B posed to the decision maker. The following definition introduces our proposed decision component. Decision componentGiven a set of alternatives {a mathematical formula}B⊆X, and the schematic variables W, Y, and Z. The decision component is the set {a mathematical formula}Γ=DR1∪DR2, where:</paragraph><list><list-item label="·">{a mathematical formula}DR1 is a set of decision rules obtained instantiating the variables {a mathematical formula}W,Y, and Z with constants from B in the decision rule{a mathematical formula}</list-item><list-item label="·">{a mathematical formula}DR2 is a set of decision rules obtained instantiating the variables {a mathematical formula}W,Y, and Z with constants from B in the decision rule{a mathematical formula}</list-item></list><paragraph>On the one hand, a decision rule in the set {a mathematical formula}DR1 states that an alternative W∈ B will be chosen, if W is better than another alternative Y and there is no better alternative Z than W. On the other hand, a decision rule in the set {a mathematical formula}DR2 states that two alternatives W and Y will be chosen when W and Y have the same attributes, and there is not other alternative Z better than them.</paragraph><paragraph>The following definition states when a decision rule will be applicable with respect to a particular scenario which will be represented by the epistemic component {a mathematical formula}K.</paragraph><paragraph label="Definition 8">Applicable decision ruleLet {a mathematical formula}B⊆X be a choice experiment and {a mathematical formula}K be an epistemic component. A decision rule ({a mathematical formula}D⇐BP,T) is applicable with respect to {a mathematical formula}K, if every precondition in P is justified in {a mathematical formula}K and every constraint in T fails to be justified in {a mathematical formula}K.</paragraph><paragraph>Then, to determine which alternatives will be selected from a choice experiment B it is necessary to consider all the decision rules from Γ that are applicable with respect to the justified conclusions that can be inferred from the active arguments of {a mathematical formula}K. The set of acceptable alternatives can be defined as follows.</paragraph><paragraph label="Definition 9">Set of acceptable alternativesLet {a mathematical formula}B⊆X be a set of alternatives posed to the agent and {a mathematical formula}〈X,C,&gt;C,K,Γ〉 be the agent's decision framework. Then, the set of acceptable alternatives {a mathematical formula}ΩB of the agent will be defined as follows:{a mathematical formula}</paragraph><paragraph>Clearly, if {a mathematical formula}B=∅ then no alternative is eligible, and if B is a singleton then there is no choice and the unique element of B should be selected. In Fig. 3 we propose an algorithm for selecting acceptable alternatives from B given a decision framework {a mathematical formula}〈X,C,&gt;C,K,Γ〉.</paragraph><paragraph label="Remark 1">Algorithm 1 implements a choice rule.</paragraph><paragraph>Note that this algorithm implements a choice rule as introduced in Section 2. That is because the algorithm assigns to each set of alternatives {a mathematical formula}B∈B a non-empty set that represents the alternatives that the decision maker might choose when presented with the alternatives in B.</paragraph><paragraph label="Example 6">Given the set of justified conclusions from {a mathematical formula}Kr=〈Er,Wr,⋈r,prefr〉 of Example 5: {a mathematical formula}{better(box1,box3),better(box2,box3),better(box1,box2),¬better(box3,box2),¬better(box2,box1)}.Consider now that Algorithm 1 is applied with {a mathematical formula}B={box3,box2,box1} and {a mathematical formula}Kr. Observe that if {a mathematical formula}e=box3 then the rule {a mathematical formula}({e}⇐B{better(e,Y)},{better(Z,e)}) with {a mathematical formula}{Z,Y}⊆B is not applicable with respect to {a mathematical formula}Kr and therefore {a mathematical formula}box3 will not be selected. This is so because there is no justification indicating that {a mathematical formula}box3 is better than another box. Consider now {a mathematical formula}e=box2, then {a mathematical formula}box2 is not selected because there is a justification for {a mathematical formula}better(box1,box2). Nevertheless, when the algorithm considers {a mathematical formula}e=box1 then {a mathematical formula}box1 is selected {a mathematical formula}(S={box1}) because the rule {a mathematical formula}({e}⇐B{better(e,Y)},{better(Z,e)}) is applicable with respect to {a mathematical formula}Kr with {a mathematical formula}Y=box2 and {a mathematical formula}Z∈B. Finally note that no decision rule in {a mathematical formula}DR2 of Γ is applicable with respect to {a mathematical formula}Kr. Therefore, the output of Algorithm 1 is {a mathematical formula}S={box1}.</paragraph><paragraph>In Example 5, the justified conclusions of the epistemic component {a mathematical formula}Kr were obtained considering a particular order among distinguished literals that was introduced in Example 4:{a mathematical formula} We will show next that if a different order is considered then the justified conclusions can change.</paragraph><paragraph label="Example 7">Consider again our running example (Fig. 1), where {a mathematical formula}B={box3,box2,box1}, now with a new order of distinguished literals:{a mathematical formula} That is, in contrast to {a mathematical formula}&gt;Cr, with the new order {a mathematical formula}&gt;Cr′ the agent will prefer first boxes that are near to the store, and then boxes near to itself and then the smaller ones. With this new order {a mathematical formula}prefr(A11,A6)=A6, and {a mathematical formula}prefr(A5,A12)=A5. Then, the set of justified conclusions in {a mathematical formula}Kr is:{a mathematical formula}{better(box1,box3),better(box2,box3),better(box2,box1), {a mathematical formula}¬better(box3,box1),¬better(box3,box2),¬better(box1,box2)}.And then, with this set of justified conclusions the output of Algorithm 1 is {a mathematical formula}S={box2}.</paragraph><paragraph label="Example 8">Given the new scenario depicted in Fig. 4 where {a mathematical formula}X={box4,box5, {a mathematical formula}box6}. We will use the following set of distinguished literals {a mathematical formula}C2={nearer_robot,nearer_store,smaller} and the order {a mathematical formula}&gt;C2={(nearer_store,nearer_robot),(nearer_robot,smaller),(nearer_store,smaller)}. Note that {a mathematical formula}&gt;C2 prefers boxes near the store, then boxes close to the robot, and finally small boxes. The epistemic component {a mathematical formula}K2=〈E2,W2,⋈2,pref2〉 for the scenario of Fig. 4 will have the following set of evidence:{a mathematical formula} The working set {a mathematical formula}W2 of {a mathematical formula}K2 is depicted in Fig. 5. There are fourteen active arguments (white triangles) with respect to {a mathematical formula}E2; as introduced above, arrows depict the defeat relation. The details of active arguments are showed below.{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} Note that, {a mathematical formula}⋈2={(A21,A30),(A25,A30),(A23,A32),(A27,A32),(A29,A22),(A29,A26),(A31,A24),(A31,A28)} are the conflicts between active arguments. Note that active arguments {a mathematical formula}A34 and {a mathematical formula}A36 are not in conflict with any other argument. Considering the order {a mathematical formula}&gt;Cr then,{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} Since {a mathematical formula}prefr(A25,A30)=A25, then {a mathematical formula}A25 is not defeated and hence, {a mathematical formula}A25 is a warranted argument in {a mathematical formula}K2. Note that {a mathematical formula}A30 is defeated and therefore is not a warranted argument. Finally, note that {a mathematical formula}A21 is defeated by {a mathematical formula}A30, and {a mathematical formula}A30 is in turn defeated by {a mathematical formula}A25, then {a mathematical formula}A21 is a warranted argument (for more details see Definition 22 at the Appendix). Thus, the set of warranted arguments in {a mathematical formula}K2 is {{a mathematical formula}A25, {a mathematical formula}A21, {a mathematical formula}A22, {a mathematical formula}A27, {a mathematical formula}A34, {a mathematical formula}A36, {a mathematical formula}A23, {a mathematical formula}A26, {a mathematical formula}A24, {a mathematical formula}A28}. Hence, the set of justified conclusions in {a mathematical formula}K2 is {a mathematical formula}{better(box4,box6),better(box5,box6),¬better(box4,box5), {a mathematical formula}¬better(box5,box4),¬better(box6,box4),¬better(box6,box5)}.And then, with this set of justified conclusions the output of Algorithm 1 is {a mathematical formula}S={box4,box5}.</paragraph><paragraph>In Example 8, the justified conclusions of the epistemic component {a mathematical formula}K2 were obtained considering a particular order among distinguished literals. When considering different orders imposed on the distinguished literals it is possible that the set of justified conclusions could change as we will show next.</paragraph><paragraph label="Example 9">Consider again the scenario depicted in Fig. 4, with the set of alternatives {a mathematical formula}B={box4,box5,box6} but the distinguished literals with a different order:{a mathematical formula} That is, in contrast to {a mathematical formula}&gt;C2, with the order {a mathematical formula}&gt;C2′ the agent will prefer first boxes that are near to itself, then boxes close to the store and finally smaller boxes. Note that the active arguments are the same of Fig. 5 but the preference between conflictive arguments change (see Fig. 6). Then, with {a mathematical formula}&gt;C2′ we have:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula} Hence, the set of justified conclusions is{a mathematical formula}{better(box6,box4),better(box6,box5), {a mathematical formula}¬better(box4,box5),¬better(box5,box4),¬better(box4,box6)¬better(box5,box6)}.And with this set of justified conclusions, since {a mathematical formula}box6 is nearer to the robot, the output of Algorithm 1 is {a mathematical formula}S={box6}.</paragraph><paragraph>The precedent examples were designed to show the behavior of our proposal in some selected special cases. Nevertheless, our framework is conceived to work in a dynamic environment where the attribute values of the alternatives can change. Every time the decision maker perceives a change in the environment this event will change the available evidence. In a DAF, when the set of evidence E changes, the set of active arguments of W can change, and hence, warranted arguments and justified conclusions can change. Therefore, a change in the set E can affect the set of acceptable alternatives of the agent introducing changes in it; thus, one feature of our formalization is that there is no need to have an explicit formalization of time. For instance, if in the scenario depicted in Fig. 4, {a mathematical formula}box5 is moved next to the robot, this change in the evidence set will change the set of acceptable alternatives, and the algorithm will choose {a mathematical formula}box5. As a further example, if in the scenario depicted in Fig. 4{a mathematical formula}box6 is moved down to the leftmost corner, the algorithm will choose {a mathematical formula}{box4,box5}.</paragraph><paragraph>Next, in Section 5, we will present results that show what happens when two alternatives have different attribute values and what happens when they have the same attribute values. These propositions will be used to relate the choice behavior exhibited by the decision framework with the choice behavior from the approaches based on preferences and choice rules of classical decision theory.</paragraph></section><section label="5"><section-title>Formal comparison with classical decision theory</section-title><paragraph>Hereinafter, we will formally relate our proposal to Classical Decision Theory. The first two propositions show what happens when two alternatives have different properties and what occurs when they have the same attributes (i.e., they have the same attribute values for each preference criterion); these propositions will be used to formalize the choice behavior of the abstract decision framework introduced in Definition 3. The formalization comprises Lemma 1, and Theorem 1, Theorem 2 which relate the choice behavior exhibited by the abstract decision framework with the choice behavior from the approaches of classical decision theory which are based on preferences and choice rules. For some of the proofs in this section we will use some DAF's concepts and notation [55]; to facilitate reading, we have included part of this formalism in the Appendix, in particular, the corresponding definitions for {a mathematical formula}args(⋅), cl{a mathematical formula}(⋅), {a mathematical formula}int(⋅), pr{a mathematical formula}(⋅), dialectical tree{a mathematical formula}TF(⋅), argumentation line λ, and skeptical marking function {a mathematical formula}me(⋅), which are used below, can be found there.</paragraph><paragraph label="Proposition 2">Let{a mathematical formula}K=〈E,W,⋈,pref〉be an abstract epistemic component, X be the set with all the possible alternatives, and let{a mathematical formula}x,y∈Xbe two alternatives with different properties. Then, either there exist an argumental structure{a mathematical formula}Σ∈strKthat is warranted from{a mathematical formula}Kand{a mathematical formula}cl(Σ)=better(x,y)or there exist an argumental structure{a mathematical formula}Σ′∈strKthat is warranted in{a mathematical formula}Kand{a mathematical formula}cl(Σ′)=¬better(x,y).</paragraph><paragraph label="Proof">By hypothesis, alternatives x and y have different properties. This means that their attribute values differ in at least one preference criterion.If {a mathematical formula}pj is just the one criterion where x and y differ, either {a mathematical formula}cj(x,y) or {a mathematical formula}cj(y,x) will be an element of evidence set E (Definition 5). If {a mathematical formula}cj(x,y)∈E, then (by Definition 5) there exists a primitive argumental structure {a mathematical formula}Σj such that {a mathematical formula}args(Σj)={Aj} and {a mathematical formula}int(Aj) = {a mathematical formula}〈{cj(x,y)},better(x,y)〉, which is active with respect to E. Besides, an active dialectical tree {a mathematical formula}TK({a mathematical formula}Σj) will be built for {a mathematical formula}Σj that will consist of only one argumentation line {a mathematical formula}λ=[Σj], such that it trivially holds that {a mathematical formula}me(Σj,λ,TK(Σj))=U.Conversely, if {a mathematical formula}cj(y,x)∈E, then a primitive argumental structure {a mathematical formula}Σj′ will exist such that {a mathematical formula}args(Σj′)={Aj′} and {a mathematical formula}int(Aj′) = {a mathematical formula}〈{cj(y,x)},¬better(x,y)〉, which is active with respect to E. Moreover, an active dialectical tree {a mathematical formula}TK({a mathematical formula}Σj′) will be built for {a mathematical formula}Σj′ that will consist of only one argumentation line {a mathematical formula}λ′=[Σj′], such that it also holds that the marking function {a mathematical formula}me(Σj′,λ′,TK(Σj′))=U.Alternatively, if more than one preference criteria exist where x and y differ, two cases may hold:<list>that one alternative (x or y) is better than the other one with respect to all the preference criteria where they differ, orthere are at least two criteria according to which one alternative is considered better than the other one and vice versa.Case (</list><paragraph>i) is a generalization of the case analyzed above, where x and y only differ in exactly one preference criterion; and the result of the dialectical analysis is the same. Only one primitive argumental structure will be warranted from {a mathematical formula}K supporting either {a mathematical formula}better(x,y) or {a mathematical formula}¬better(x,y), depending on which alternative is deemed better w.r.t. all preference criteria.In case (ii), two types of primitive argumental structures are distinguished; namely those supporting {a mathematical formula}better(x,y) and the ones supporting {a mathematical formula}¬better(x,y). These argumental structures will be organized in an acceptable argumentation line λ that can be decomposed in a set of argumental structures pro{a mathematical formula}λ+=[Σ1,…] (those supporting conclusion {a mathematical formula}better(x,y)) and another set cons{a mathematical formula}λ−=[Σ2,…] (those supporting conclusion {a mathematical formula}¬better(x,y)). If {a mathematical formula}&gt;C is a strict total order, given two argumental structures {a mathematical formula}Σi{a mathematical formula}∈λ+ and {a mathematical formula}Σj{a mathematical formula}∈λ−, {a mathematical formula}pref(Σi,Σj)=Σi or {a mathematical formula}pref(Σi,Σj)=Σj. This is due to the fact that in this case {a mathematical formula}pref(Σi,Σj) will never be ϵ, since alternatives x and y have different properties.In this way, for {a mathematical formula}Σ1 there will be just one active dialectical tree {a mathematical formula}TK({a mathematical formula}Σ1) containing only one argumentation line λ, such that {a mathematical formula}me(Σ1,λ,TK(Σ1))=U if {a mathematical formula}|λ+|&gt;|λ−|, and {a mathematical formula}me(Σ1,λ,TK(Σ1))=D otherwise.  □</paragraph></paragraph><paragraph label="Corollary 1">Let{a mathematical formula}K=〈E,W,⋈,pref〉be an abstract epistemic component, X be the set with all the possible alternatives, and let{a mathematical formula}x,y∈Xbe two alternatives with different properties. If{a mathematical formula}&gt;Cis a strict total order and either conclusion{a mathematical formula}better(x,y)or{a mathematical formula}¬better(x,y)is warranted in{a mathematical formula}K, then either{a mathematical formula}¬better(y,x)or{a mathematical formula}better(y,x)is also warranted in{a mathematical formula}K, respectively.</paragraph><paragraph>Proposition 2 states that either {a mathematical formula}better(x,y) or {a mathematical formula}¬better(x,y) will be warranted by the epistemic component when two alternatives {a mathematical formula}x,y∈X with different properties are compared; this means that it is always possible to decide which alternative is preferred. In Definition 5, the features of arguments belonging to the working set are introduced, and hence how a piece of evidence {a mathematical formula}c(x,y) activates arguments supporting {a mathematical formula}better(x,y) or {a mathematical formula}¬better(y,x). Corollary 1 states that when {a mathematical formula}better(x,y) or {a mathematical formula}¬better(x,y) is warranted, it will also be the case that {a mathematical formula}¬better(y,x) or {a mathematical formula}better(y,x) is also warranted; this corollary, complements the above-mentioned proposition in the symmetry of comparing alternative x versus y, or the opposite, depending on how they are presented in the facts available in the evidence set.</paragraph><paragraph>In a similar manner, Proposition 3 below states that when two alternatives {a mathematical formula}x,y∈X have the same attributes, comparing them in the epistemic component will result in warranting conclusions {a mathematical formula}¬better(x,y) and {a mathematical formula}¬better(y,x), stating the indifferent preference among them.</paragraph><paragraph label="Proposition 3">Let{a mathematical formula}K=〈E,W,⋈,pref〉be an abstract epistemic component, X be the set with all the possible alternatives, and let{a mathematical formula}x,y∈Xbe two alternatives with the same attributes. If{a mathematical formula}&gt;Cis a total strict order, then there exist two argumental structures{a mathematical formula}Σ,Σ′∈strKwarranted in{a mathematical formula}Ksuch that{a mathematical formula}cl(Σ)=¬better(x,y)and{a mathematical formula}cl(Σ′)=¬better(y,x).</paragraph><paragraph label="Proof">By hypothesis, alternatives x and y have the same attributes, therefore a fact {a mathematical formula}same_att(x,y) will belong to evidence set E (Definition 5). Thus, by the definition of working set W (Definition 5) two primitive structures Σ and {a mathematical formula}Σ′ exist such that set of arguments in Σ and {a mathematical formula}Σ′ are respectively {a mathematical formula}args(Σ) ={{a mathematical formula}A}, {a mathematical formula}args(Σ′) ={{a mathematical formula}A{a mathematical formula}}′,{sup:2} with the corresponding interfaces{a mathematical formula} and{a mathematical formula} and which are active with respect to E. Moreover, two active dialectical trees, {a mathematical formula}TK(Σ) and {a mathematical formula}TK({a mathematical formula}Σ′), will be built each one consisting of only one argumentation line {a mathematical formula}λ=[Σ] and {a mathematical formula}λ′=[Σ′], respectively, such that it trivially holds that {a mathematical formula}me(Σ,λ,TK(Σ))=U and {a mathematical formula}me(Σ′,λ′,TK(Σ′))=U.  □</paragraph><paragraph>The results stated in Proposition 2, Proposition 3 provide formal support for Lemma 1, which states that given two alternatives x and y it will always be possible to compare them in the epistemic component, whether to express indifference or a preference for one of the alternatives (completeness). Besides, this lemma also states that the epistemic component satisfies the property of transitivity when all alternatives are pairwise compared.</paragraph><paragraph label="Lemma 1">Let{a mathematical formula}K=〈E,W,⋈,pref〉be an abstract epistemic component. If{a mathematical formula}&gt;Cis a strict total order, then{a mathematical formula}Kimplements{sup:3}a rational preference relation ≿.</paragraph><paragraph label="Proof">By Definition 1, given two alternatives {a mathematical formula}x,y∈X, then {a mathematical formula}x≿y⇔x≻y∨x∼y. From Definition 5, the evidence set E will contain all the facts of the kind {a mathematical formula}c(x,y) relating alternatives x and y (that belong to the choice experiment posed to the decision maker) with respect to all the preference criteria referred by the distinguished literals in {a mathematical formula}C. In this way, by Proposition 2 and Corollary 1 it will always be possible to activate a primitive argumental structure Σ, warranted in {a mathematical formula}K, such that {a mathematical formula}cl(Σ)=Z with {a mathematical formula}Z∈{better(x,y),better(y,x),¬better(x,y),¬better(y,x)}, thus stating a strong preference (≻) in favor of one of the alternatives. Conversely, if alternatives x and y have the same attributes, by Proposition 3, conclusions {a mathematical formula}¬better(x,y) and {a mathematical formula}¬better(y,x) will be warranted by two active primitive argumental structures, which are warranted in {a mathematical formula}K, thus stating the indifference (∼) on the preference between the alternatives. Therefore, the completeness property is satisfied.In order to check transitivity property, we must prove that for all {a mathematical formula}x,y,z∈X, if {a mathematical formula}x≿y and {a mathematical formula}y≿z, then {a mathematical formula}x≿z. If {a mathematical formula}x≿y is satisfied, this means that:<list>{a mathematical formula}x≻y: by Proposition 2, the conclusion {a mathematical formula}better(x,y) is warranted given that a primitive argumental structure {a mathematical formula}Σi exists (active w.r.t. E), which is warranted in {a mathematical formula}K such that {a mathematical formula}cl(Σi)=better(x,y), or{a mathematical formula}x∼y: by Proposition 3, the conclusions {a mathematical formula}¬better(x,y) and {a mathematical formula}¬better(y,x) are warranted since two active primitive argumental structures {a mathematical formula}Σj and {a mathematical formula}Σj′ exist and they are warranted in {a mathematical formula}K and {a mathematical formula}cl(Σj)=¬better(x,y) and {a mathematical formula}cl(Σj′)=¬better(y,x), respectively.Likewise, if case (</list><paragraph>iii) holds, then an active dialectical tree {a mathematical formula}TK(Σk) exists such that {a mathematical formula}me(Σk,λk,TK(Σk))=U where {a mathematical formula}λk=[Σk,…,Σm].{sup:5} Given that {a mathematical formula}Σm is the last argumental structure in the argumentation line, this implies that a distinguished literal {a mathematical formula}cm exists such that {a mathematical formula}pr(args(Σm))={cm(y,z)} and no literal {a mathematical formula}c′∈C exists with higher priority than {a mathematical formula}cm such that {a mathematical formula}c′(z,y)∈E. Again, if {a mathematical formula}&gt;C is a strict total order, based on Definition 5, it can be stated that z is not better than y with respect to any preference criterion with higher priority than {a mathematical formula}cm. As mentioned in the analysis of case (i), this is due to the fact that if another criterion with higher priority would exist, for which z is preferred to y, {a mathematical formula}Σm would not be the last structure in the argumentation line since there would be another one attacking it based on this supposed criterion.When considering cases (i) and (iii) together, it remains to compare {a mathematical formula}cn with {a mathematical formula}cm to determine whether {a mathematical formula}better(x,z) can be warranted; it can be the case that {a mathematical formula}cn=cm, or {a mathematical formula}cn&gt;cm, or {a mathematical formula}cm&gt;cn. Independently of how these criteria are related each other, it will always be possible to guarantee that z is not better than x with respect to preference criteria of higher or equal priority than {a mathematical formula}c″=max⁡(cn,cm).In this way, based on Definition 5, we know that {a mathematical formula}c″(x,z)∈E when x and z belong to the same choice experiment, and consequently, a primitive argumental structure {a mathematical formula}Σ″ will be activated such that {a mathematical formula}cl(Σ″)=better(x,z), {a mathematical formula}pr(args(Σ″))={c″(x,z)} and it will be warranted in {a mathematical formula}K. This is due to the fact that an active dialectical tree {a mathematical formula}TK(Σ) will exist such that {a mathematical formula}me(Σ,λ,TK(Σ))=U where {a mathematical formula}λ=[Σ,…,Σ″].{sup:6}If case (iv) holds, this means that y and z have the same attributes. Hence, if we consider this case together with case (i), it will be possible to build a dialectical tree analogous to the one built for case (i), but warranting the conclusion {a mathematical formula}better(x,z).If case (ii) holds, this means that x and y have the same attributes. In this way, if we consider this case together with case (iii), it will be possible to build a dialectical tree analogous to the one built for case (iii), but warranting the conclusion {a mathematical formula}better(x,z).Finally, if case (ii) and (iv) are considered together, by Proposition 3 it can be stated that the conclusions {a mathematical formula}¬better(x,z) and {a mathematical formula}¬better(z,x) will be warranted since two active primitive argumental structures Σ and {a mathematical formula}Σ′ exist which are warranted in {a mathematical formula}K and {a mathematical formula}cl(Σ)=¬better(x,z) and {a mathematical formula}cl(Σ′)=¬better(z,x), respectively.All in all, from the case analysis carried out above, it can be concluded that {a mathematical formula}x≻z∨x∼z, and hence {a mathematical formula}x≿z. Therefore, the completeness and transitivity properties are both satisfied.  □</paragraph></paragraph><paragraph>The previous results (Lemma 1, Proposition 2, Proposition 3) are aimed at formally characterizing properties of the epistemic component. As described in Section 4, the decision component of the framework consists of a set of decision rules that will effectively implement the agent's decision making policy. These rules use warranted information from the epistemic component to compare all the alternatives belonging to the choice experiment posed to the agent. The choice behavior of the decision framework is the result of this interaction between decision rules and the epistemic component; in particular, the following theorem establishes the coincidence of the choices made by our framework and the preference-based approach presented in Section 2.</paragraph><paragraph label="Theorem 1">Let{a mathematical formula}〈X,C,&gt;C,K,Γ〉{a mathematical formula}Lbe an abstract decision framework, where{a mathematical formula}K=〈E,W,⋈,pref〉. Given a choice experiment B⊆ X posed to the agent, if{a mathematical formula}&gt;Cis a strict total order among elements of{a mathematical formula}C, the choice behavior of{a mathematical formula}〈X,C,&gt;C,K,Γ〉Lcoincides with the optimum one of a rational preference relation.</paragraph><paragraph label="Proof">As stated in Section 2, an individual having a rational preference relation ≿ on X, will choose any element of the set {a mathematical formula}C⁎(B,≿) when facing a choice experiment {a mathematical formula}B⊆X; this is due to the fact of her preference-maximizing behavior. Besides, by Definition 9, {a mathematical formula}ΩB=⋃i=1nDi, where each set {a mathematical formula}Di contains the alternatives chosen by the applicable decision rule i. By Definition 8, a decision rule can be applied if its preconditions are warranted in {a mathematical formula}K, and its restrictions do not. As it can be observed by Definition 3, decision rules in Γ have as restriction that an alternative W will belong to {a mathematical formula}ΩB if conclusion {a mathematical formula}better(Z,W) cannot be warranted in {a mathematical formula}K; that is, no alternative {a mathematical formula}Z∈B exists such that {a mathematical formula}Z≻W. The precondition of decision rules belonging to {a mathematical formula}DR1 requires that the conclusion {a mathematical formula}better(W,Y) be warranted in {a mathematical formula}K (W must be strictly preferred over another alternative {a mathematical formula}Y∈B); likewise, the precondition of decision rules belonging to {a mathematical formula}DR2 requires that the conclusions {a mathematical formula}¬better(W,Y) and {a mathematical formula}¬better(Y,W) be warranted in {a mathematical formula}K (W must be indifferent w.r.t. another alternative Y∈ B). Moreover, by Lemma 1 it can be stated that given the evidence set E, if {a mathematical formula}&gt;C is a strict total order, it will always be possible to warrant the preconditions and/or restrictions of the decision rules in Γ. In this way, in {a mathematical formula}ΩB there will only be alternatives {a mathematical formula}x∈B strictly preferred or indifferent w.r.t. any other alternative {a mathematical formula}y∈B; that is {a mathematical formula}x≿y. Hence, {a mathematical formula}ΩB={x∈B|x≿y for each {a mathematical formula}y∈B}=C⁎(B,≿).  □</paragraph><paragraph>As mentioned in Section 2, notwithstanding their differences, under certain conditions the PBA and CBA approaches are related. Below, we present a theorem where the choice behavior of our framework is related with the CBA and its principle of consistency in the decisions made, viz. the weak axiom of revealed preference. To introduce next result, Algorithm 1 will be considered as the function {a mathematical formula}μ(⋅,⋅) with two arguments: an abstract decision framework and a set of alternatives.</paragraph><paragraph label="Theorem 2">Let{a mathematical formula}〈X,C,&gt;C,K,Γ〉Lbe an abstract decision framework, where{a mathematical formula}K=〈E,W,⋈,pref〉. Given the set{a mathematical formula}Bwhich contains all the possible choice experiment, and function{a mathematical formula}μ(⋅,⋅)described inAlgorithm 1, if{a mathematical formula}&gt;Cis a strict total order among elements of{a mathematical formula}C, then the choice structure ({a mathematical formula}B,{a mathematical formula}μ(⋅,⋅)) satisfies the weak axiom of revealed preference.</paragraph><paragraph label="Proof">As stated in Remark 1, we know that function {a mathematical formula}μ(⋅,⋅) described in Algorithm 1 implements a choice rule. In this way, it only remains to check that ({a mathematical formula}B,μ(⋅,⋅)) satisfies the restrictions imposed by the weak axiom on the choice behavior.From Lemma 1 we know that {a mathematical formula}K implements a rational preference relation ≿, and by Theorem 1 it holds that given a choice experiment {a mathematical formula}B∈B, {a mathematical formula}ΩB=C⁎(B,≿).Let us suppose that for some {a mathematical formula}B∈B, it holds that {a mathematical formula}x,y∈B and {a mathematical formula}x∈C⁎(B,≿); so, from the definition of {a mathematical formula}C⁎(B,≿), {a mathematical formula}x≿y. To check if the weak axiom holds, let us suppose that for some {a mathematical formula}B′∈B with {a mathematical formula}x,y∈B′ it holds that {a mathematical formula}y∈C⁎(B,≿). This implies that {a mathematical formula}y≿z for all {a mathematical formula}z∈B′; but we already know that {a mathematical formula}x≿y. Thus, by transitivity {a mathematical formula}x≿z for all {a mathematical formula}z∈B′, and hence {a mathematical formula}x∈C⁎(B′,≿). This is exactly the conclusion required by the weak axiom of revealed preference.  □</paragraph><paragraph>As stated in the introductory section, the expected utility theory is a major paradigm in decision making, in spite of its limiting characteristics. The abstract decision framework introduced in previous sections shares some of these characteristics. Both approaches assume: (i) that the decision-maker knows all the options in advance of making the decision; (ii) that options are comparable using whatever criteria the decision-maker uses; (iii) that the decision-maker knows her preferences over these options in advance of making the decision; and (iv) decision rules are independent of the options and preferences, and may be defined in advance.</paragraph><paragraph>In this regard, assumptions (i) and (iii) preclude the emergence of options or preferences in the decision making process. In complex domains, deciding preference may be a computationally non-trivial task, and so it is by no means certain that a decision-maker knows her own preferences for all combinations of options. However, these limitations on our model arise because of the fact that it was conceived in such a way its choice behavior was consistent with the classical approaches described in Section 2. The main reason we have developed this approach is that we agree with the position stated by Parsons and Fox in [48], on the importance of formally relating argumentation-based decision models to classical approaches to decision theory, for the guarantees exhibited in the decisions made. In the following section, where related work is presented, we can see that this formal relation is not accomplished in many recent argumentation-based proposals.</paragraph></section><section label="6"><section-title>Related work</section-title><paragraph>The use of argumentative reasoning for decision making has been investigated in other proposals, and in this section, we will review those which are more related to our approach. Most of the proposals to qualitative decision making in argumentation literature (e.g., [3], [6], [46], [48]) share a common view with respect to decision making, because they conceive it as a form of reasoning oriented towards action. That is why, all of them consider the decision maker's goals or the expected values of actions, to decide which action to accomplish. This is the main difference with respect to our proposal that is based on the Marketing literature point of view [52], [53], where each alternative is conceived as a product that the consumer (decision maker) is evaluating to buy (selection). This approach is detailed next in Subsection 6.1. Then, Subsections 6.2 to 6.5 describe main research lines in argumentation-based decision making approaches. Finally, Subsections 6.6 and 6.7 give a more general picture of the decision making problem by connecting our proposal with other relevant approaches, namely, logics of preferences and utilities, and non-rational decision making.</paragraph><section label="6.1"><section-title>Marketing approach to decision making</section-title><paragraph>To the best of our knowledge, the first work on symbolic decision making explicitly following the point of view of the literature on Marketing in decision making was [34], where the application of Defeasible Logic for automated negotiation was investigated. In [34], decision making is performed as a two-stage process formalized in terms of two correlated defeasible theories: the first one for filtering the set of acceptable alternatives based on the buyer's requirements, and the second one, for choosing a particular alternative. In our proposal, the decision maker is provided with a choice experiment which resembles the set of acceptable alternatives built by the first defeasible theory mentioned above, and we concentrate on choosing what we have called the “acceptable alternatives”, which would correspond to the chosen ones by the second defeasible theory referred above.</paragraph><paragraph>However, the filtering process accomplished by the first defeasible theory of [34], could be naturally modeled with a DAF {a mathematical formula}〈E,W,⋈,pref〉 as follows: (i) The evidence E would be a consistent set of sentences of the form {a mathematical formula}a(x), such that {a mathematical formula}x∈X, {a mathematical formula}a∈F. In this case X refers to the set that is the first component of the ADF introduced in Definition 3, and {a mathematical formula}F would be the threshold criteria set that would be used to evaluate alternatives individually. (ii) The working set W will be such that if {a mathematical formula}x∈X, {a mathematical formula}a∈F and {a mathematical formula}acceptable∉F then, for all {a mathematical formula}w∈W,cl(w)=acceptable(x)orcl(w)=∼acceptable(x) and {a mathematical formula}pr(w)={a(x)}. (iii) The conflict relation would remain the same as the one specified in Definition 5, and (iv) {a mathematical formula}pref relation could be defined analogously as the one of Definition 5, by considering an ordering in terms of {a mathematical formula}F instead of {a mathematical formula}C.</paragraph><paragraph>If the proposed decision framework would be used together with the DAF mentioned above to filter alternatives in X, the output of this DAF, let us call it {a mathematical formula}Xf, should be used instead of X in Definition 3. Independently of whether X or {a mathematical formula}Xf is used, a key issue of the decision framework proposed in our work, is that its choice behavior has been formalized with respect to the general theory of choice of Classical Decision Theory and [34] has not.</paragraph><paragraph>Other works, based on concrete argumentation formalisms, that follow this viewpoint to decision making, are those by Ferretti et al., [26], [27], where Defeasible Logic Programming (DeLP) [33] and Possibilistic Defeasible Logic Programming (P-DeLP) [1], have been used, respectively. These two works could be conceived as particular instances of the abstract decision framework proposed in our work. The advantage of having an interpreter available like the one built for DeLP [32], is that it makes possible to directly tackle real-world decision-making problems (e.g., see [28]). Regarding abstract argumentation frameworks, as far as we know, the one presented here is the first one proposed for decision making having the aforementioned conceptualization of Marketing literature to decision making.</paragraph></section><section label="6.2"><section-title>Abstract argumentation-based decision making</section-title><paragraph>A notable abstract argumentation-based framework for decision-making was introduced by Amgoud and Prade in [3], where the decision process within the framework follows two main steps. First, arguments for beliefs and arguments for options are built and evaluated using classical (Dung's [23]) acceptability semantics. Second, pairs of options are compared using decision principles; these principles are based on the accepted arguments supporting the decisions and they are classified into three categories, whether they consider only arguments in favor or against a decision, both types of arguments, or an aggregation of them into a meta-argument. This work remains close to the classical view of decision making in that it leaves aside aspects of practical reasoning, such as goal generation, feasibility and planning, to concentrate on the issue of justifying (based on argumentation) the best decision to make in a given situation; besides, it has a logical view of decision that unifies the treatment of multiple criteria decision and decision under uncertainty. As indicated by Amgoud and Prade, in multiple criteria decision-making each candidate decision {a mathematical formula}d∈D is evaluated from a set C of m different points of view called criteria. Thus, two families of approaches can be distinguished. On one hand, we have those based on a global aggregation of value criteria-based functions, where the obtained global absolute evaluations are of the form {a mathematical formula}g(f1(C1(d)),…,fm(Cm(d))) and the mappings {a mathematical formula}fi map the original evaluations on a unique scale, which assumes commensurability. On the other hand, we have the ones that aggregate the preference indices {a mathematical formula}Ri(d,d′) into a global preference {a mathematical formula}R(d,d′). Amgoud and Prade follow the former approach while we follow the latter.</paragraph><paragraph>An interesting extension to the proposal of Amgoud and Prade, was introduced in [46], where the use of the grounded extension is proposed as acceptability criterion for arguments supporting goals and where a new method for generating decisions is presented. The proposed approach describes a method for decision analysis in engineering design processes, such as those practiced in the aerospace industry, but also the approach provides support to document the reasons behind decisions for future reference (decision documentation). A novel issue of this approach is that decisions are modeled as sets of literals rather than as single literal, as usual in argumentation-based decision making literature. This conceptualization of decisions which may partially overlap, results in a more finely tuned set of decisions when argumentation systems have to be built to derive arguments about the goals achieved when certain decisions are made. As already mentioned, this proposal extends Amgoud and Prade's approach and hence, differs with our conceptualization of a multi-criteria decision making problem.</paragraph></section><section label="6.3"><section-title>Assumption-based argumentation approaches to decision making</section-title><paragraph>Fan and Toni in [25] proposed two different formal frameworks for representing decision making, where this activity is conceived as concerning three related processes: (a) representing information that is relevant to decision making; (b) choosing the decision criteria to represent “good” decisions; and (c) computing and explaining the desired decision based on the selected criteria. This work differ from ours in that Fan and Toni use Assumption-based Argumentation (ABA) [63], whereas we use abstract argumentation frameworks; moreover, and more significantly, our approach uses pair-wise comparison between decisions to select the “winning” decision, whereas in [25] a unified process to map decision frameworks into ABA and then compute admissible arguments is developed. A relation between Fan and Toni's proposal and ours is that both approaches guarantee to choose the best possible decision by constraining the underlying argumentation framework through certain characteristics. In our case this is attained by defining the epistemic component of the decision framework as a DAF with particular features on the evidence set (i.e., the working set), the conflict relation, and preference function (see Definition 5 for details), and in [25] this is accomplished by defining ABA frameworks with different properties so that admissible arguments in those frameworks correspond to strongly dominant, dominant, or weakly dominant decisions in the corresponding mapped decision frameworks, in this way, the decisions made exhibit an element of consistency with respect to the accepted arguments in ABA. However, as pointed-out by the authors in [25] it still remains linking this work to the existing decision theoretic results, which in our case has been accomplished.</paragraph><paragraph>Regarding the last observation, Zhong et al. [67], pushed the proposal in [25] one step further to connecting it to existing decision theoretic work; towards that goal, they formally defined a decision ranking mechanism by giving a total order ordering amongst all decisions, but the notion of rationality used relies on the fact that best decisions meet most goals and exhibits fewest redundant attributes (i.e., attributes not contributing to meeting goals). This leads to the proposal of a new decision criterion, the so-called minimal deviation, and its combination with two notions of dominance to select a decision result in the development of two new mappings from decision frameworks onto ABA, in a similar manner as accomplished in [25]. However, the main objective of [67] is the proposal of an algorithm for generating natural language explanations for decisions, on the grounds that existing approaches to argumentation-based decision making either lack automatic support for generating explanations, or directly use the outputs of argumentation engines as explanations.</paragraph><paragraph>Another work related to the ABA framework for decision making is that of Matt et al. [40]. The differences between this work and [25] is that in the latter three different notions of dominant decisions (referred above) have been studied, whereas in the former, only one was studied. Besides, one of the frameworks proposed in [25] allows the introduction of preferences over goals, while in [40] all goals were considered as equally important. All in all, these works together with other recent papers on ABA frameworks for decision making [17], [19], [24], have shown the suitability of ABA frameworks for dealing with real-world decisions. In particular, in [17] besides ABA frameworks two other argumentation formalisms are reviewed; namely: Bipolar Argumentation Frameworks [18] and Value-based Argumentation Frameworks (VAFs) [10].</paragraph></section><section label="6.4"><section-title>Value-based argumentation frameworks for decision making</section-title><paragraph>Following the work on VAFs [10], in [12], the authors introduced the definition of promoted value, a concept used to define the preference ordering of arguments within the logical formalization developed for Atkinson's analysis of practical syllogism in [5]; in this work, the use of argumentation in practical reasoning is studied, proposing a persuasion theory that uses argumentation techniques for obtaining reasons for and against possible actions; then, in [7] an application of this approach to a particular medical domain is described. A significant difference is that, although the approach employs argumentative reasoning to decide among actions, the work does not focus on a general formalization for decision making through argumentation; also, this approach is integrated in a BDI architecture.</paragraph><paragraph>In Bench-Capon et al. [11], to model agent decision making in experiments in economics, Bench-Capon et al. proposed a qualitative framework for decision making based on the general argumentation approach to practical reasoning developed in [6]. This approach is also based on Atkinson's account of practical syllogism [5], where values that are promoted and demoted by alternative actions are explicitly represented by organizing arguments into a VAF. The main objective of Bench-Capon et al. is to explore and provide evidence that in economics an argumentative approach of this kind is a better device to explain data from behavioral experiments than the classical approaches to decision making, where agents are expected to be self-interested utility-maximizers. Towards this goal, the Ultimatum game and the Dictator game were modeled, and then the results were compared with results reported by humans with different cultural background. The proposed framework is intended for use in situations where agents are required to be adaptable; for instance, where the agent may prefer different outcomes depending on the counter-parties is involved with. The conceptual difference between this work and our proposal is that we present an argumentation-based decision framework for agents behaving rationally as conceived by classical decision theory, while in [11], the proposed model is intended to provide a good fit to actual human decision-making processes.</paragraph></section><section label="6.5"><section-title>The logic of argumentation approach to decision making</section-title><paragraph>Works such as [17], [19], [24], [25], [40], [46] can be considered as good examples of the position stated by Fox et al. in [29] remarking the importance of developing technologies to support decision making which are grounded on solid theoretical foundations and not only on ad hoc methods. In fact, Fox's position on this matter can be traced to earlier works (see for instance [48]), where an important conclusion is that when developing decision making models based on argumentation formalisms, a key issue is to formally relate them to classical approaches to decision theory.</paragraph><paragraph>In [48], Parsons and Fox delineated a proposal in the form of a position paper which advanced the idea that argumentation constitutes a useful framework to reason under uncertainty that can unify different formalisms, such as the possibilistic and probabilistic approaches, and appropriately dealing with inconsistent information; thus, argumentation can become the support of a symbolic model for decision making in practical reasoning. Later on, Fox and Parsons in [30], [31] proposed to use the non-standard logic LA (Logic of Argumentation) developed by Krause et al. in [38] in the development of an argumentation system capable of making decisions about the expected values of actions; the resulting approach is similar to the decision theoretic notion of expected value. The system builds compound arguments, following three stages to construct and combine belief arguments and value arguments. First, an argument in LA is built supporting that the state associated with a proposition C will occur if action A is taken. Second, a mechanism LV (Logic of Value) simply assigns a confidence value to C. Finally, a mechanism LEV (Logic of Expected Value) derives arguments over sentences in LA and LV to conclude an expected value for A, consistent with the value assigned to C. To choose among alternative actions, the expected value is used to construct a preference ordering over the set of alternative actions. In this manner, in the context of having sets of arguments that support different actions, the action with highest aggregated value will be selected; this value represents the force of the set of arguments that support that action.</paragraph><paragraph>The main idea of our proposal maintains certain similarities to the line of research followed by Fox and Parsons [30], [31], [48]. In both approaches, an existing argumentation system for handling belief is chosen as the reasoning formalism to develop a system capable of deciding among competing alternatives. Nevertheless, our formalization was achieved following different intuitions. Fox and Parsons built a combined system LA/LV/LEV where the arguments promote different actions; then, the supporting set of arguments with aggregated value is chosen. The formalism introduced here relies in an underlying abstract dynamic argumentation framework (DAF) where some components are instantiated and others can be adapted to the application domain, and we have a set of decision rules that work over justified conclusions.</paragraph><paragraph>Finally, both approaches are related to Classical Decision Theory but they differ in the manner this relation is accomplished. Fox and Parsons conceive argumentation as a symbolic model of decision-making and use as underlying argumentation formalism the logic LA, whose theoretic proof method to reason under uncertainty is coherent with Dempster–Shafer theory. In our case, the whole design of the framework contributes to get a choice behavior consistent with the general theory of choice of Classical Decision Theory.</paragraph></section><section label="6.6"><section-title>Logics of preference and utility functions</section-title><paragraph>The notion of preference and its role vary in different disciplines; for instance, in the above-mentioned approaches, we find applications of preference principles rather than philosophical foundations. As mentioned by Hansson [36], the study of general principles for preferences could be traced back to Aristotle's time, but the first complete systems of preference logics were proposed during the second half of twentieth century [35], [66]; since then, many contributions have followed this line of research [20], [22], [44]. As von Wright [66] stated, the existing disagreements on the intuitions about underlying concepts of preference relations of various researchers into this field, can lead to the case where alternative logics of preference can be built in correspondence to these various points of view regarding the matter.</paragraph><paragraph>As Doyle and Thomason observed in [21], logics of preference could serve as a useful way of organizing and comparing qualitative approaches to decision making. Our proposal is not the exception to this claim and, in general, many of the concepts and principles used in the framework proposed in the present article are compatible (and could be compared) with similar concepts from logics of preferences. In the same manner as logics of preference do, our approach allows decision makers more flexibility in expressing incomplete or fewer preferences, or leaving strengths of preferences unspecified [43]. However, unlike previous sections where comparisons were focused on other argumentative approaches, a fair comparison between logics of preference and our proposal would require more general criteria to compare approaches based on very different principles.</paragraph><paragraph>McGeachie in [43] addresses this last issue by proposing an interesting set of criteria that could be used to compare computational properties of (very) different preference representations and their accompanying reasoning methods. Those criteria include: (i) basic qualitative comparisons, (ii) complex preferences, (iii) utility independence, (iv) (quantitative) tradeoffs, (v) contexts, and (vi) incomplete preferences. Here, in the context of the logics of preference, a fundamental class of preference representations, termed ceteris paribus, is analyzed. Preference semantics in ceteris paribus allow specifying preferences that apply the “keeping other things equal” principle, that is, they capture the intuitive idea that unmentioned qualities in preferences might affect the decision making process [43].</paragraph><paragraph>With respect to the above-mentioned criteria, the ceteris paribus assumption proposed in [20] satisfies all of them except the context and tradeoff aspects (criteria (v) and (vi), respectively). In a nutshell, that means that ceteris paribus semantics cannot specify that more specific preferences override less specific ones. Besides, they fail in expressing quantitative tradeoffs between variables. Our proposed framework also exhibits this last limitation in dealing with quantitative tradeoffs; however, context-dependent preferences seem to be naturally captured by our argumentation-based approach. The direct ceteris paribus preferences were later extended with explicit quantification of the “strength” of the preference [62], graph representations of preferences [13], and trade-off ratios between features [14]. Most of these extensions dealt with efficiency aspects of preferences computation or tried alleviating some weaknesses of ceteris paribus to fulfill the above-mentioned criteria.</paragraph><paragraph>The consideration of utilities constitute another mainstream in preference reasoning formalisms which is based on modeling utility functions and computing maximum expected utility, following economic theory of humans as rational decision makers. As pointed out in [43], this approach is effective, but can be labor and information-intensive depending heavily on the accuracy of the utility and probability estimates. Traditional economic utility functions succeed in many of the criteria considered above (criteria (ii), (iii), and (iv)) but they cannot allow more specific preferences (criterion (v) related to context), are notoriously poor with incomplete information (criterion (vi) incomplete information) and the computation required in many complex situations can be prohibitive [43]. In this context, when considering the traditional approaches to Classical Decision Theory, our work mainly differs in that the analysis is directly addressed on the agent's preference relation and not on a utility function that represents this relation, as usual in these cases. This is an important feature since to change the preference criteria in our proposal can be easily accomplished by conveniently modifying the order {a mathematical formula}&gt;C. In contrast, in other approaches using a utility function, this cannot be performed in a direct way or even the whole recalculation of the utility function might be needed; besides, considering the agent's preference relation allowed us to establish a direct connection between our argumentation-based decision-making approach and more essential approaches to modeling individual choice behavior, such as the choice-based approach.</paragraph><paragraph>Finally, some recent works have tried to get the best of both, quantitative and qualitative approaches by proposing hybrid approaches that, for instance, combine ceteris paribus preferences and utility functions [42], [44], [45]. That is an interesting line of research that we will consider in future works.</paragraph></section><section label="6.7"><section-title>Non-rational decision making</section-title><paragraph>The preferences studied in preference logics are usually the preferences of rational individuals but, as stated in [36], they are also used in psychological research where the emphasis is on actual preferences as revealed in behavior. In this respect, at present, there exist several research programs in psychology and behavioral economics based on Simon's criticism of mainstream economic models of perfect rationality (e.g., see [59]). As stated in [16], the decision making research program in psychology was dominated by Tversky and Kahneman's approach (e.g., see [8], [64]) empirically testing Simon's suggestions and showing that they were correct.</paragraph><paragraph>Simon's rejection of the assumption of perfect rationality, led him to develop the concept of bounded rationality (e.g., see [60]). As suggested in [60], individuals are limited in their rationality for at least these reasons: (i) in order for someone to be rational, she has to fully know and understand the future consequences of her decision-making in the present; (ii) nobody can know in the present the future worth and the impact her actions will have in the future; (iii) in order for someone to be rational she has to know all of the alternatives (usually in decision-making the alternatives someone has in mind are limited and humans are restrained from making optimum decisions). Considering that our approach to decision making is influenced by the point of view of the literature on Marketing, only point (iii) related to bounded rationality in the choice of alternatives can be related to our work. In theory, it could be the case that {a mathematical formula}B=2X∖{∅}, but in practice the choice experiments presented to the agent will be a significatively smaller set; in this way, in the context of bounded rationality as it was stated by Simon, the rationality of our decision maker is naturally limited to the alternatives the agent has available.</paragraph><paragraph>Finally, it is worth noticing that there is also important research indirectly related to our work. For instance, the distinction we make between the epistemic component and the decision component closely resembles Philippe Smets' notions of credal and pignistic probabilities mentioned in [61], where an interpretation of the Dempster–Shafer model is presented as the transferable belief model. Besides, the game-theoretic semantics proposed in [41] is quite similar to the underlying answer-set semantics of the DAF used to model the epistemic component (see the appendix for details), since both are based on a dialogical view of a process of argumentation that will decide which arguments are finally accepted. In [41], this argumentation process (dialogical deliberation) will be carried out by several agents, while in our case the process will be performed inside the agent's “mind” (monological deliberation).</paragraph></section></section><section label="7"><section-title>Conclusions and future work</section-title><paragraph>In this work we have introduced an argumentative approach to single-agent decision making. The proposed formalism, called Abstract Decision Framework, was defined as a tuple {a mathematical formula}〈X,C,&gt;C,K,Γ〉 and involves: a set X of mutually exclusive alternatives, a set of distinguished literals {a mathematical formula}C where each {a mathematical formula}ci∈C represents a different binary preference relation for comparing alternatives in X, a strict total order {a mathematical formula}&gt;C among elements of {a mathematical formula}C, a dynamic argumentation framework {a mathematical formula}K used for representing preferences relations and conflicts among the available alternatives, and a set of decision rules Γ that implements the agent's decision making policy.</paragraph><paragraph>Our formalism is not attached to any particular agent architecture, and since is based on abstract argumentation framework, some elements of the formalism can be instantiated with a particular argumentation system. This is a key issue, given that this abstract argumentation-based framework for decision making can be conceived as a template for building decision frameworks based on concrete argumentation formalisms. Besides, the resulting concrete instantiation, would result in a decision framework having a choice behavior consistent with the PBA and CBA approaches described in Section 2.</paragraph><paragraph>Our proposal takes advantage of the formalism of dynamic argumentation frameworks [55], where the set of available evidence (that represents the situation of a particular environment where the agent is immersed) activates some arguments of the framework, and those arguments are used for computing the agent's justified conclusions with respect to that evidence. For deciding between conflicting arguments, the formalization relies in an order over the preference criteria defined for the application domain.</paragraph><paragraph>In this article, we focused on the “argumentation-based view” to decision making and establishing formal connections to Classical Decision Theory. However, as we saw in Section 6.6, other qualitative, quantitative, and hybrid approaches have played a key role in decision making research. As future work, we plan to establish explicit connections with those influential approaches; our studies will include a formal comparison with other qualitative representations such as multi-attribute ceteris paribus preference statements [20], [22] and semantics for extensions that support quantitative comparisons involving tradeoffs [42], [44], [45]. In this context, an important aspect to analyze is the computational burden involved in recompiling utility functions in some recent hybrid approaches [42] versus the flexibility provided by argumentation approaches that support numeric strengths in their arguments in the context of changing environments. Therefore, to get some insights on this matter, it would be interesting to model the decision making formalism presented in [27] (based on P-DeLP) as an instance of our abstract framework. Also, to test its adequacy as an abstract decision framework, other instantiations will be performed with argumentative formalisms having semantics resembling a dialogical discussion; for instance [49].</paragraph><paragraph>Moreover, as aforementioned in Section 6.7, new research lines arising from psychology and behavioral economics are taking into account non-rational behavior in decision making based on Simon's seminal works (e.g., see [59], [60]). Nevertheless, as stated in [16], perfect rational models are still the prevailing models; hereof, we have formalized the choice behavior of the proposed framework with respect to the general theory of choice of Classical Decision Theory (as motivated by Parsons and Fox in [48] and already mentioned in Sections 1 and 6). As future work, following the thorough presentation in [16], we will also study how our framework can be redefined to model some of the proposals concerning non-rational decision making, given that argumentation-based approaches are alike to human reasoning.</paragraph><section-title>Acknowledgements</section-title></section></content><acknowledgements><paragraph>This work was partially supported by PGI-UNS (grants 24/N035, 24/N030), PIP-CONICET (grant 112-201101-01000), Universidad Nacional de San Luis (PROICO 30312) and EU H2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No. 690974 for the project MIREL: MIning and REasoning with Legal texts.</paragraph></acknowledgements><appendices><section label="Appendix A"><section-title>Dynamic Argumentation Framework (DAF)</section-title><paragraph>We will introduce here the main concepts of the Dynamic Argumentation Framework (DAF) proposed by Rotstein et al. in [54], [55]; this framework was used in Section 3 to formalize our abstract decision framework. DAFs have been built as a refinement of Dung's argumentation framework (AF) [23], which is defined as a pair containing a set of arguments and a defeat relation ranging over pairs of them. The objective of the approach proposed in [54], [55] was to extend Dung's AFs to handle dynamics. To cope with this, it was considered a set of available evidence, which determines which arguments can be used to make inferences. In Dung's approach, the consideration of a changing set of arguments would involve passing from one framework to another.</paragraph><paragraph>In DAFs, the notion of evidence is a key concept. Evidence is considered to be an entity represented on a logical language, denoted as {a mathematical formula}L, whose sentences correspond to facts in the domain, also this language will be used as the base language to represent the arguments' premises and conclusions. The arguments supported by the current evidence will be considered as active; on the other hand, the set of evidence contains those sentences that are undisputed in the situation at hand. Likewise, arguments are considered the smallest reasoning steps to be represented in the DAF; that is, the smallest piece of reasoning that provides backing for a claim from a set of premises, as formally stated in Definition 10. The complement notation will be used to state that a sentence is the negation of another one: {a mathematical formula}α‾=¬α,¬α‾=α.</paragraph><paragraph label="Definition 10">Given a language {a mathematical formula}L, an argument{a mathematical formula}A is a reasoning step for a claim {a mathematical formula}α∈L from a non-empty set of premises {a mathematical formula}{β1,…,βn}⊆L such that {a mathematical formula}βi≠α,βi≠α‾, and {a mathematical formula}βi≠βj‾ for every {a mathematical formula}i,j,1≤i,j≤n.</paragraph><paragraph>Given an argument {a mathematical formula}A, we will identify both its claim and its set of premises through the functions {a mathematical formula}cl(A) and {a mathematical formula}pr(A), respectively. Given {a mathematical formula}pr(A)={β1,…,βn} and {a mathematical formula}cl(A)=α, the interface of {a mathematical formula}A is denoted as {a mathematical formula}int(A)=〈{β1,…,βn},α〉. In a DAF, given an evidence set E, an argument's premise is satisfied if it belongs to E, or it is the conclusion of an active argument according to E; an argument will be considered active if its premises are satisfied. Notice that an argument {a mathematical formula}A not having enough evidential support for all its premises may have active supporting arguments for the remaining unsatisfied premises, i.e., active arguments whose claims are the unsatisfied premises of {a mathematical formula}A. An argument {a mathematical formula}B is a supporting argument of an argument {a mathematical formula}A iff {a mathematical formula}cl(B)∈pr(A). Let {a mathematical formula}cl(B)=β, then we say that {a mathematical formula}Bsupports{a mathematical formula}A through β.</paragraph><paragraph>The DAF imposes as a requirement that all the arguments be coherent. The concept of a coherent argument is related to the fact that certain restrictions must be addressed in order to consider an argument as a consistent reasoning step.</paragraph><paragraph label="Definition 11">An argument {a mathematical formula}A is coherent w.r.t. a set E of evidence iff {a mathematical formula}A verifies:</paragraph><list><list-item label="•">Internal Consistency: {a mathematical formula}cl(A)‾∉pr(A).</list-item><list-item label="•">Consistency w.r.t. E: {a mathematical formula}cl(A)‾∉E.</list-item><list-item label="•">No Internal Redundancy: {a mathematical formula}cl(A)∉pr(A).</list-item><list-item label="•">No Redundancy w.r.t. E: {a mathematical formula}cl(A)∉E.</list-item></list><paragraph label="Definition 12">Given a set {a mathematical formula}Args of arguments and a set E of evidence, an argument {a mathematical formula}A∈Args is active w.r.t. E iff {a mathematical formula}A is coherent and for each β∈ pr({a mathematical formula}A) either {a mathematical formula}β∈E, or there is an active argument {a mathematical formula}B∈Args that supports {a mathematical formula}A through β.</paragraph><paragraph label="Definition 13">Given a set {a mathematical formula}Args of arguments, an argumental structure for a claim α from {a mathematical formula}Args is a tree of arguments Σ verifying:</paragraph><list><list-item label="1.">The root argument {a mathematical formula}At∈Args, called top argument, is such that {a mathematical formula}cl(At)=α and is noted as {a mathematical formula}top(Σ);</list-item><list-item label="2.">A node is an argument {a mathematical formula}Ai∈Args such that for each premise {a mathematical formula}β∈pr(Ai) there is at most one child argument in {a mathematical formula}Args supporting {a mathematical formula}Ai through β;</list-item><list-item label="3.">A leaf is an argument {a mathematical formula}Ah∈Args such that there is no argument in {a mathematical formula}Args supporting it.</list-item></list><paragraph>Regarding notation for an argumental structure Σ:</paragraph><list><list-item label="•">The set of arguments belonging to Σ is denoted as {a mathematical formula}args(Σ).</list-item><list-item label="•">The set of premises of Σ is: {a mathematical formula}pr(Σ)=⋃A∈args(Σ)pr(A)∖⋃A∈args(Σ)cl(A).</list-item><list-item label="•">The claim of Σ is denoted as {a mathematical formula}cl(Σ)=α.</list-item></list><paragraph label="Definition 14">Functions {a mathematical formula}pr(⋅) and {a mathematical formula}cl(⋅) are also applied to argumental structures. It is important to stress that, within an argumental structure, if a premise which is unsupported by the evidential set appears more than once, that premise must be supported by the same argument. Moreover, when the set of arguments in an argumental structure is a singleton, the argumental structure is called primitive. In DAF, the defeat relationship is obtained by applying a preference function on pairs of argumental structures in conflict. As mentioned above, arguments are the finest grained steps in the reasoning process, so it makes sense to define the conflict relationship on arguments first, and then to extend it to argumental structures. This gives rise to the notion of conflict among argumental structures; when all these conflicts are determined, a preference function decides which argument (supported by an argumental structure) prevails. Given a set of arguments {a mathematical formula}Args, the set {a mathematical formula}⋈⊆Args×Args denotes a conflict relation over {a mathematical formula}Args, verifying {a mathematical formula}⋈⊇{(A,B)|{A,B}⊆Args,cl(A)=cl(B)‾}. Given a set {a mathematical formula}Args of arguments, an argument {a mathematical formula}Aitransitively supports an argument {a mathematical formula}Ak within {a mathematical formula}Args iff there is a sequence of arguments {a mathematical formula}[Ai,…,Ak] in {a mathematical formula}Args where {a mathematical formula}cl(Aj)∈pr(Aj+1), for every j such that {a mathematical formula}i≤j≤k−1. Let Args be a set of arguments and {a mathematical formula}⋈⊆Args×Args be a conflict relation, an argumental structure {a mathematical formula}Σ∈Args is well-formed w.r.t. ⋈, iff Σ verifies:</paragraph><list><list-item label="•">Premise Consistency: There are no {a mathematical formula}α,β∈pr(Σ) such that {a mathematical formula}α‾=β.</list-item><list-item label="•">Consistency: For each argument {a mathematical formula}A∈args(Σ) there is no argument {a mathematical formula}B∈args(Σ), such that {a mathematical formula}A⋈B.</list-item><list-item label="•">Non-Circularity: No argument {a mathematical formula}A∈args(Σ) transitively supports an argument {a mathematical formula}B∈args(Σ) if {a mathematical formula}cl(B)∈pr(A).</list-item><list-item label="•">Uniformity: If {a mathematical formula}A∈args(Σ) supports {a mathematical formula}B∈args(Σ) through β, then for all {a mathematical formula}Bi∈args(Σ) having β as premise, {a mathematical formula}A supports {a mathematical formula}Bi through β.</list-item></list><paragraph>The domain of all well-formed argumental structures w.r.t. Args and ⋈ is denoted as {a mathematical formula}str(Args,⋈). Since a set of evidence is always consistent, a structure with inconsistent premises would never become active. However, as stated above, it is useful to validate also inactive argumental structures. The property of consistency invalidates inherently contradictory argumental structures. The requirement of non-circularity avoids taking into consideration structures yielding infinite reasoning chains. Finally, the restriction of uniformity does not allow heterogeneous support for a premise throughout a structure. These constraints are defined so that we can trust a well-formed structure as a sensible reasoning chain, independently from the set of evidence.</paragraph><paragraph>From a knowledge representation perspective, the objective of an argumental structure is comparable to that of its composing arguments: both support claims from a set of premises. The difference relies on the fact that arguments cannot be decomposed into smaller pieces. Conversely, argumental structures can be decomposed into subsets (aggregations of arguments) referred as argumental substructures, as defined below. Given two argumental structures Σ and {a mathematical formula}Σ′ from a set of arguments Args, {a mathematical formula}Σ′ is an argumental substructure of Σ (denoted as {a mathematical formula}Σ′⊑Σ) iff {a mathematical formula}args(Σ′)⊆args(Σ). If {a mathematical formula}args(Σ′)⊂args(Σ), then {a mathematical formula}Σ′ is a proper argumental substructure of Σ (denoted as {a mathematical formula}Σ′⊏Σ). Given a set Args of arguments, a conflict relation {a mathematical formula}⋈⊆Args×Args, and two argumental structures {a mathematical formula}Σ1,Σ2∈str(Args,⋈), structure {a mathematical formula}Σ1 is in conflict with {a mathematical formula}Σ2 iff {a mathematical formula}top(Σ1)⋈top(Σ2). The conflict between argumental structures is denoted as “{an inline-figure}”.</paragraph><paragraph>The preference function is defined over argumental structures and not over arguments, since, in order to decide which argument prevails, all the knowledge giving support to them should be considered. Moreover, when facing different scenarios, the same argument might be active from different active argumental structures and, consequently, the preference could change along with evidence.</paragraph><paragraph>Given two argumental structures {a mathematical formula}Σ1,Σ2∈str(Args,⋈), the preference function{a mathematical formula}pref:str(Args,⋈)×str(Args,⋈)↦str(Args,⋈)∪{ϵ} on argumental structures, {a mathematical formula}pref(Σ1,Σ2)=[Σ1|Σ2|ϵ], determines the preferred argumental structure; if none is preferred, the function returns the constant ϵ.</paragraph><paragraph label="Definition 15">Given two argumental structures {a mathematical formula}Σ1,Σ2∈str(Args,⋈), {a mathematical formula}Σ1defeats{a mathematical formula}Σ2, iff there is an argumental substructure {a mathematical formula}Σ⊑Σ2, such that {a mathematical formula}Σ1{an inline-figure} Σ and {a mathematical formula}pref(Σ1,Σ)=Σ1. The defeat relation between argumental structures is denoted as “⇒”.</paragraph><paragraph>When a structure defeats another, the attack comes from the claim of the former to any claim of a substructure of the latter. The attack is not directed to an argument, but to a substructure, which is the actual portion of the structure under attack.</paragraph><paragraph label="Definition 16">A dynamic argumentation framework (DAF) is a four tuple {a mathematical formula}〈E,W,⋈,pref〉, composed by a set E of evidence, a working set W of arguments, a conflict relation {a mathematical formula}⋈⊆W×W, and a preference function {a mathematical formula}pref defined over {a mathematical formula}str(W,⋈).</paragraph><paragraph label="Definition 20">The working set of arguments contains every argument that is available for use by the reasoning process. At any given moment, the set of active arguments will represent the current situation. Different instances of the set of evidence will determine different instances of the DAF; thus, when “restricting” a DAF to its associated set of evidence, we obtain an abstract argumentation framework AF in the classical sense [23], i.e., a duple with the set of active arguments, and the attack relation between pairs of active arguments. This “restriction” is called an active instance and it is addressed in Definition 20. Below, other necessary definitions are introduced first. Given a DAF {a mathematical formula}F=〈E,W,⋈,pref〉, the set of active argumental structures in F w.r.t. E is {a mathematical formula}S={A∈W|Ais activew.r.t.E}.Given a DAF {a mathematical formula}F=〈E,W,⋈,pref〉, a well-formed argumental structure Σ in F is active w.r.t. E iff {a mathematical formula}pr(Σ)⊆E and each argument in {a mathematical formula}args(Σ) is coherent w.r.t. E.Given a DAF {a mathematical formula}F=〈E,W,⋈,pref〉 and the set {a mathematical formula}S of active argumental structures in F w.r.t. E, the active defeat relation over argumental structures in F is {a mathematical formula}{an inline-figure}={(Σ1,Σ2)∈⇒|Σ1,Σ2∈S}.Given a DAF {a mathematical formula}F=〈E,W,⋈,pref〉, the active instance of F is the abstract argumentation framework AF {a mathematical formula}(S,{an inline-figure}), where {a mathematical formula}S is the set of the active argumental structures from W w.r.t. E, and {an inline-figure} is the active attack relation between structures in {a mathematical formula}S.</paragraph><paragraph>Every DAF, at any given moment, has an associated active instance, i.e., an abstract argumentation framework AF; therefore, all the work done on acceptability of arguments and argumentation semantics for the abstract frameworks can be applied to the DAF just by finding from its active instance the set of accepted argumental structures. Moreover, since structures hold a claim, we can go a step further and consider justification of claims, either skeptically or cautiously. In this way, the study of semantics on the DAF relating arguments, structures and substructures, it is not only faced calculating the active instance but tools are also defined to directly calculate semantics in the DAF. With this aim, as detailed next, dialectical trees are used.</paragraph><paragraph>A natural choice to obtain the supported conclusions from a set of arguments is to resort to one of the many possible semantics developed for abstract argumentation frameworks. In his landmark work, Dung [23] described preferred, stable, grounded and complete semantics based on the notion of the admissibility; subsequently, other semantics where introduced: ideal, semi-stable, stage, and CF2, although the last two are not based on admissibility (see [9] for an excellent introduction to the topic of argumentation semantics). An interesting observation is that our formalism requires a skeptical posture regarding the inferential result; that is to say, if the semantics chosen is not skeptical, we would need to consider those arguments that appear in all the extensions of the framework under scrutiny. In this paper, as an alternative semantics, we have introduced an answer-set semantics which is based on a dialogical view of the process of argumentation that will decide which arguments are finally accepted; this approach will be formulated below.</paragraph><paragraph>An argumentative approach based on dialectical trees corresponds to the intuition of a discussion around a topic. That is, the argumental structure on the top of the tree is not only supporting a claim α, but also a topic of discussion. In this respect, it will be discussed in terms of α, ¬α and additionally, the topics introduced by all the argumental structures involved in supporting sentences, since they contain substructures that might be attacked (see Definition 15). Next, all the basic notions related to argument interactions are described to address the formal definition of dialectical tree.</paragraph><paragraph>Given a DAF F, an argumentation line is a sequence {a mathematical formula}λ=[Σ1,…,Σn], where each {a mathematical formula}Σi(1≤i≤n) is a well-formed argumental structure in F attacking its predecessor. The root of λ is {a mathematical formula}Σ1 and the leaf is {a mathematical formula}Σn. Given an argumentation line {a mathematical formula}λ=[Σ1,…,Σn], the top segment of {a mathematical formula}Σi(1&lt;i≤n) in λ is {a mathematical formula}[Σ1,…,Σi] and it is denoted as {a mathematical formula}λ↑(Σi). The proper top segment of {a mathematical formula}Σi in λ is {a mathematical formula}[Σ1,…,Σi−1] and is denoted as {a mathematical formula}λ↑[Σi].</paragraph><paragraph>As already mentioned, the exchange of arguments resembles a dialogical discussion; as such, it makes sense that the introduction of a new argument by one of the participants should be consistent with her previously posed arguments. Indeed, it is also desirable to require that none of the parties be allowed to introduce an argument already posed by them. We will refer as pro and con each of the parties involve in the dialogical argumentation process. The following definition precedes the formalization of the intuitions referred above on an acceptable argumentation line. Given a set S of structures and a conflict relation {an inline-figure}{a mathematical formula}⊆S×S, the set S is consistent w.r.t. {an inline-figure}, iff there is no {a mathematical formula}{Σ1,Σ2}⊆S such that {a mathematical formula}Σ1{an inline-figure}{a mathematical formula}Σ2. Given an argumentation line {a mathematical formula}λ=[Σ1,…,Σn], the set pro (con) of argumental structures is composed by all the {a mathematical formula}Σi(1≤i≤n), with odd (even) i values. The set pro (con) of structures in λ is denoted {a mathematical formula}λ+ ({a mathematical formula}λ−). Given an argumentation line λ within the context of a DAF {a mathematical formula}F=〈E,W,⋈,pref〉, λ is acceptable in F iff the following restrictions hold: (1) Non-circularity: there is no repetition of structures in λ, and (2) Concordance: sets pro and con are consistent w.r.t. {an inline-figure}. It is worth mentioning that an acceptable argumentation line is exhaustive if it is not possible to insert more argumental structures in the sequence.</paragraph><paragraph label="Definition 21">Given a DAF F and a set S of exhaustive argumentation lines in F rooted in {a mathematical formula}Σ1, such that S is maximal w.r.t. set inclusion, a dialectical tree for an argumental structure {a mathematical formula}Σ1 is a tree {a mathematical formula}TF(Σ1) verifying:</paragraph><list><list-item label="•">{a mathematical formula}Σ1 is the root.</list-item><list-item label="•">A structure {a mathematical formula}Σi≠1 in a line {a mathematical formula}λi∈S is an inner node, iff has as children all the {a mathematical formula}Σj in lines {a mathematical formula}λj∈S such that {a mathematical formula}Σj⇒Σi and {a mathematical formula}λ↑[Σi]=λ↑(Σj).</list-item><list-item label="•">The leaves of the tree correspond to the leaves of the lines in S.</list-item></list><paragraph>Dialectical trees are defined over the working set of arguments, and hence they can contain active and inactive argumental structures. A dialectical tree that contains only active structures is called active dialectical tree, and it is denoted {a mathematical formula}TF(Σ). Once a dialectical tree has been built for an argumental structure, a marking criterion determines which structures in the tree are defeated and which ones remain undefeated. This criterion is specified by a marking function. In [56] different marking approaches are described. As stated next, a structure can be marked as “defeated” or “undefeated”. Given a DAF F and an argumental structure {a mathematical formula}Σi in a line {a mathematical formula}λi in a dialectical tree {a mathematical formula}TF(Σ), a marking function{a mathematical formula}m is {a mathematical formula}m(Σi,λi,TF(Σ))=[U|D], where U represents “undefeated” and D “defeated”. A choice for this marking function is the one defined in DeLP [33], where the evaluation is done in a skeptical manner; that is, an argumental structure is considered as undefeated only when all its defeaters have been defeated. Given a dialectical tree {a mathematical formula}TF(Σ), the skeptical marking function{a mathematical formula}me is defined as follows: {a mathematical formula}me(Σi,λi,TF(Σ))=Diff{a mathematical formula}∃Σjme(Σj,λj,TF(Σ))=U, where {a mathematical formula}Σj is a child of {a mathematical formula}Σi in {a mathematical formula}TF(Σ). Once the marking function has been defined, the warranty status of the root of a dialectical tree can be determined, as defined next.</paragraph><paragraph label="Definition 22">Given a DAF F and a marking function {a mathematical formula}m, an argumental structure Σ from F is warranted in F, iff {a mathematical formula}m(Σ,λ,TF(Σ))=U, where λ is any argumentation line from {a mathematical formula}TF(Σ). The conclusion {a mathematical formula}cl(Σ) is justified by F.</paragraph><paragraph>Naturally, if a different marking function is considered, the definition of warrant consequently changes. The warranted argumental structures will be determined by Definition 22, giving rise to the notion of semantics on the DAF. It is worth mentioning that the notion of warrant is defined on active dialectical trees, since all the reasoning only can be carried out over the set of active arguments.</paragraph></section></appendices><references><reference label="[1]"><authors>T. Alsinet,C.I. Chesñevar,L. Godo,G.R. Simari</authors><title>A logic programming framework for possibilistic argumentation: formalization and logical properties</title><host>Fuzzy Sets Syst.159 (10)(2008) pp.1208-1228</host></reference><reference label="[2]"><authors>L. Amgoud,H. Prade</authors><title>Explaining qualitative decision under uncertainty by argumentation</title><host>21st Conference on Artificial IntelligenceAAAI, July 16–20(2006) pp.219-224</host></reference><reference label="[3]"><authors>L. Amgoud,H. Prade</authors><title>Using arguments for making and explaining decisions</title><host>Artif. Intell.173 (3–4)(2009) pp.413-436</host></reference><reference label="[4]"><authors>K.J. Arrow</authors><title>Rational choice functions and ordering</title><host>Econometrica26 (102)(1959) pp.121-127</host></reference><reference label="[5]">K. AtkinsonWhat Should We Do? Computational Representation of Persuasive Argument in Practical ReasoningPhD thesis<host>(2005)Department of Computer Science, University of LiverpoolLiverpool, UK</host></reference><reference label="[6]"><authors>K. Atkinson,T. Bench-Capon,P. McBurney</authors><title>Computational representation of practical argument</title><host>Synthese152 (2)(2006) pp.157-206</host></reference><reference label="[7]"><authors>K. Atkinson,T. Bench-Capon,S. Modgil</authors><title>Argumentation for decision support</title><host>17th International Conference on Database and Expert Systems ApplicationsDEXA(2006)Springer pp.822-831</host></reference><reference label="[8]"><authors>J. Baron</authors><title>Thinking and Deciding</title><host>4th edition(2008)Cambridge University Press</host></reference><reference label="[9]"><authors>P. Baroni,M. Caminada,M. Giacomin</authors><title>An introduction to argumentation semantics</title><host>Knowl. Eng. Rev.26 (4)(2011) pp.365-410</host></reference><reference label="[10]"><authors>T. Bench-Capon</authors><title>Persuasion in practical argument using value-based argumentation frameworks</title><host>J. Log. Comput.13 (3)(June 2003) pp.429-448</host></reference><reference label="[11]"><authors>T. Bench-Capon,K. Atkinson,P. McBurney</authors><title>Using argumentation to model agent decision making in economic experiments</title><host>Auton. Agents Multi-Agent Syst.25 (1)(2011) pp.183-208</host></reference><reference label="[12]"><authors>T. Bench-Capon,H. Prakken</authors><title>Justifying actions by accruing arguments</title><host>1st International Conference on Computational Models of ArgumentCOMMA(2006)IOS Press pp.247-258</host></reference><reference label="[13]"><authors>C. Boutilier,R. Brafman,C. Geib,D. Poole</authors><title>A constraint-based approach to preference elicitation and decision making</title><host>Working Papers of the AAAI Spring Symposium on Qualitative Preferences in Deliberation and Practical Reasoning(1997) pp.19-28</host></reference><reference label="[14]"><authors>R. Brafman,C. Domshlak</authors><title>Introducing variable importance tradeoffs into CP-nets</title><host>Proceedings of the 18th Conference in Uncertainty in Artificial IntelligenceUAI-02(2002)Morgan Kaufmann pp.69-76</host></reference><reference label="[15]"><authors>S. Bruninghaus,K.D. Ashley</authors><title>Predicting outcomes of case based legal arguments</title><host>9th International Conference on Artificial Intelligence and LawICAIL '03(2003)ACM Press pp.233-242</host></reference><reference label="[16]"><authors>G. Campitelli,F. Gobet</authors><title>Herbert Simon's decision-making approach: investigation of cognitive processes in experts</title><host>Rev. Gen. Psychol.14 (4)(2010) pp.354-</host></reference><reference label="[17]"><authors>L. Carstens,X. Fan,Y. Gao,F. Toni</authors><title>An overview of argumentation frameworks for decision support</title><host>Graph Structures for Knowledge Representation and Reasoning: 4th International Workshop, Revised Selected PapersGKR 2015(2015)Springer pp.32-49</host></reference><reference label="[18]"><authors>C. Cayrol,M.C. Lagasquie-Schiex</authors><title>On the acceptability of arguments in bipolar argumentation frameworks</title><host>Symbolic and Quantitative Approaches to Reasoning with Uncertainty: 8th European ConferenceECSQARU 2005(2005)Springer pp.378-389</host></reference><reference label="[19]"><authors>R. Craven,F. Toni,C. Cadar,A. Hadad,M. Williams</authors><title>Efficient argumentation for medical decision-making</title><host>Principles of Knowledge Representation and Reasoning: 13th International ConferenceKR 2012(2012)</host></reference><reference label="[20]"><authors>J. Doyle,Y. Shoham,M.P. Wellman</authors><title>A logic of relative desire</title><host>Methodologies for Intelligent Systems: 6th International SymposiumISMIS '91(1991)SpringerBerlin, Heidelberg pp.16-31</host></reference><reference label="[21]"><authors>J. Doyle,R.H. Thomason</authors><title>Background to qualitative decision theory</title><host>AI Mag.20 (3)(1999) pp.55-68</host></reference><reference label="[22]"><authors>J. Doyle,M.P. Wellman</authors><title>Representing preferences as ceteris paribus comparatives</title><host>Proceedings of the AAAI Spring Symposium on Decision-Theoretic Planning(1994) pp.69-75</host></reference><reference label="[23]"><authors>P.M. Dung</authors><title>On the acceptability of arguments and its fundamental role in nonmonotonic reasoning, logic programming and n-person games</title><host>Artif. Intell.77 (2)(1995) pp.321-358</host></reference><reference label="[24]"><authors>X. Fan,R. Craven,R. Singer,F. Toni,M. Williams</authors><title>Assumption-based argumentation for decision-making with preferences: a medical case study</title><host>Computational Logic in Multi-Agent Systems: 14th International WorkshopCLIMA XIV(2013)Springer pp.374-390</host></reference><reference label="[25]"><authors>X. Fan,F. Toni</authors><title>Decision making with assumption-based argumentation</title><host>Theory and Applications of Formal Argumentation: Second International Workshop, Revised Selected PapersTAFA 2013(2014)SpringerBerlin, Heidelberg pp.127-142</host></reference><reference label="[26]"><authors>E. Ferretti,M. Errecalde,A.J. García,G.R. Simari</authors><title>Decision rules and arguments in defeasible decision making</title><host>Ph. BesnardS. DoutreA. Hunter2nd International Conference on Computational Models of ArgumentsCOMMA(2008)IOS Press pp.171-182</host></reference><reference label="[27]"><authors>E. Ferretti,M. Errecalde,A.J. García,G.R. Simari</authors><title>A possibilistic defeasible logic programming approach to argumentation-based decision-making</title><host>J. Exp. Theor. Artif. Intell.26 (4)(2014) pp.519-550</host></reference><reference label="[28]"><authors>E. Ferretti,R. Kiessling,A. Silnik,R. Petrino,M. Errecalde</authors><title>New trends in electrical engineering automatic control, computing and communication sciences</title><host>Integrating Vision-Based Motion Planning and Defeasible Decision Making for Differential-Wheeled Robots: A Case of Study with the Khepera 2 Robot(2010)LOGOS VerlagBerlin, Germany</host></reference><reference label="[29]"><authors>J. Fox,D. Glasspool,V. Patkar,M. Austin,L. Black,M. South,D. Robertson,C. Vincent</authors><title>Delivering clinical decision support services: there is nothing as practical as a good theory</title><host>J. Biomed. Inform.43 (5)(2010) pp.831-843</host></reference><reference label="[30]"><authors>J. Fox,S. Parsons</authors><title>On using arguments for reasoning about actions and values</title><host>Jon DoyleRichmond H. ThomasonWorking Papers of the AAAI Spring Symposium on Qualitative Preferences in Deliberation and Practical ReasoningMarch 24–26(1997) pp.55-63</host></reference><reference label="[31]"><authors>J. Fox,S. Parsons</authors><title>Arguing about beliefs and actions</title><host>Applications of Uncertainty FormalismsLNCSvol. 1455 (1998)Springer pp.266-302</host></reference><reference label="[32]"><authors>A.J. García,N. Rotstein,M. Tucat,G.R. Simari</authors><title>An argumentative reasoning service for deliberative agents</title><host>Knowledge Science, Engineering and Management: Second International ConferenceKSEM 2007LNCSvol. 4798 (2007)Springer pp.128-139</host></reference><reference label="[33]"><authors>A.J. García,G.R. Simari</authors><title>Defeasible logic programming: an argumentative approach</title><host>Theory Pract. Log. Program.4 (1–2)(2004) pp.95-138</host></reference><reference label="[34]"><authors>G. Governatori,A.H.M. ter Hofstede,P. Oaks</authors><title>Defeasible logic for automated negotiation</title><host>Proceedings of CollECTeR(2000)Deakin University</host></reference><reference label="[35]"><authors>S. Halldén</authors><title>On the logic of better</title><host>C.W.K. GleerupE. MunksgaardLibrary of Theoria(1957)</host></reference><reference label="[36]"><authors>S.O. Hansson</authors><title>Preference logic</title><host>D.M. GabbayF. GuenthnerHandbook of Philosophical Logic, vol. 42nd edition(2001)Kluwer Academic Publishers pp.319-393</host></reference><reference label="[37]"><authors>A. Kakas,P. Moraïtis</authors><title>Argumentation based decision making for autonomous agents</title><host>2nd International Joint Conference on Autonomous Agents and Multiagent SystemsAAMAS(2003)ACM Press pp.883-890</host></reference><reference label="[38]"><authors>P. Krause,S. Ambler,M. Elvang-Gøransson,J. Fox</authors><title>A logic of argumentation for reasoning under uncertainty</title><host>Comput. Intell.11 (1)(1995) pp.113-131</host></reference><reference label="[39]"><authors>A. Mas-Collel,M.D. Whinston,J.R. Green</authors><title>Microeconomic Theory</title><host>(1995)Oxford University Press</host></reference><reference label="[40]"><authors>P. Matt,F. Toni,J.R. Vaccari</authors><title>Dominant decisions by argumentation agents</title><host>Argumentation in Multi-Agent Systems: 6th International Workshop. Revised Selected and Invited PapersArgMAS 2009(2010)SpringerBerlin, Heidelberg pp.42-59</host></reference><reference label="[41]"><authors>P. McBurney,D. Hitchcock,S. Parsons</authors><title>The eightfold way of deliberation dialogue</title><host>Int. J. Intell. Syst.22 (1)(2007) pp.95-132</host></reference><reference label="[42]"><authors>M. McGeachie</authors><title>Recompiling utility functions in a changing world</title><host>AAAISS(2005)</host></reference><reference label="[43]">M. McGeachieThe Local Geometry of Multiattribute Tradeoff PreferencesPhD thesis<host>(2007)Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</host></reference><reference label="[44]"><authors>M. McGeachie,J. Doyle</authors><title>Utility functions for ceteris paribus preferences</title><host>Comput. Intell.20 (2)(2004) pp.158-217</host></reference><reference label="[45]"><authors>M. McGeachie,J. Doyle</authors><title>The local geometry of multiattribute tradeoff preferences</title><host>Artif. Intell.175 (7–8)(2011) pp.1122-1152</host></reference><reference label="[46]"><authors>J. Müller,A. Hunter</authors><title>An argumentation-based approach for decision making</title><host>IEEE 24th International Conference on Tools with Artificial IntelligenceICTAI 2012(2012) pp.564-571</host></reference><reference label="[47]"><authors>W. Ouerdane,N. Maudet,A. Tsoukiàs</authors><title>Arguing over actions that involve multiple criteria: a critical review</title><host>9th European Conference on Symbolic and Quantitative Approaches to Reasoning with UncertaintyECSQARU(2007)Springer pp.308-319</host></reference><reference label="[48]"><authors>S. Parsons,J. Fox</authors><title>Argumentation and decision making: a position paper</title><host>Dov M. GabbayHans Jürgen OhlbachInternational Conference on Formal and Applied Practical ReasoningFAPR, June 3–7, 1996LNCSvol. 1085 (1996)Springer pp.705-709</host></reference><reference label="[49]"><authors>H. Prakken,G. Sartor</authors><title>Argument-based extended logic programming with defeasible priorities</title><host>J. Appl. Non-Class. Log.7 (1997) pp.25-75</host></reference><reference label="[50]"><host>I. RahwanG.R. SimariArgumentation in Artificial Intelligence(2009)Springer</host></reference><reference label="[51]"><authors>M.K. Ritcher</authors><title>Rational choice</title><host>Preferences, Utility, and Demand(1971)Harcourt Brace Jovanovich</host></reference><reference label="[52]">J.H. Roberts,J.M. LattinDevelopment and testing of a model of consideration set compositionJ. Mark. Res.28 (November 1991) pp.429-440American Marketing Association</reference><reference label="[53]"><authors>J.H. Roberts,G.L. Lilien</authors><title>Explanatory and predictive models of consumer behavior</title><host>Handbooks in Operations Research and Management Science(1993)North-Holland Publishing CompanyAmsterdam</host></reference><reference label="[54]"><authors>N. Rotstein,M. Moguillansky,A.J. García,G.R. Simari</authors><title>An abstract argumentation framework for handling dynamics</title><host>12th International Workshop on Non-Monotonic ReasoningNMR 2008(2008) pp.131-139</host></reference><reference label="[55]"><authors>N. Rotstein,M. Moguillansky,A.J. García,G.R. Simari</authors><title>A dynamic argumentation framework</title><host>Computational Models of Argument: Proceedings of COMMA 2010(2010) pp.427-438</host></reference><reference label="[56]"><authors>N. Rotstein,M. Moguillansky,G.R. Simari</authors><title>Dialectical abstract argumentation: a characterization of the marking criterion</title><host>21st International Joint Conference on Artificial IntelligenceIJCAI(2009) pp.898-903</host></reference><reference label="[57]"><authors>P.A. Samuelson</authors><title>A note on the pure theory of consumer's behaviour</title><host>Economica5 (1938) pp.61-71</host></reference><reference label="[58]"><authors>P. Schoemaker</authors><title>The expected utility model: its variants, purposes, evidence and limitations</title><host>J. Econ. Lit.20 (1982) pp.529-563</host></reference><reference label="[59]"><authors>H.A. Simon</authors><title>A behavioral model of rational choice</title><host>Q. J. Econ.69 (1)(1955) pp.99-118</host></reference><reference label="[60]"><authors>H.A. Simon</authors><title>Theories of bounded rationality</title><host>Decision and Organizations(1972)North-Holland Publishing Company</host></reference><reference label="[61]"><authors>P. Smets,R. Kennes</authors><title>The transferable belief model</title><host>Artif. Intell.66 (2)(1994) pp.191-234</host></reference><reference label="[62]"><authors>S. Tan,J. Pearl</authors><title>Qualitative decision theory</title><host>Proceedings of AAAI-94Menlo Park, CA(1994)AAAI Press pp.928-933</host></reference><reference label="[63]"><authors>F. Toni</authors><title>A tutorial on assumption-based argumentation</title><host>Argum. Comput.5 (1)(2014) pp.89-117</host></reference><reference label="[64]"><authors>A. Tversky,D. Kahneman</authors><title>Rational choice and the framing of decisions</title><host>J. Bus.59 (4)(1986)</host></reference><reference label="[65]"><authors>J. von Neumann,O. Morgenstern</authors><title>Theory of Games and Economic Behavior</title><host>3rd edition(1953)Princeton University Press</host></reference><reference label="[66]"><authors>G.H. Von Wright</authors><title>The logic of preference reconsidered</title><host>Theory Decis.3 (2)(1972) pp.140-169</host></reference><reference label="[67]"><authors>Q. Zhong,X. Fan,F. Toni,X. Luo</authors><title>Explaining best decisions via argumentation</title><host>Proceedings of the European Conference on Social IntelligenceECSI-2014(2014) pp.224-237</host></reference></references><footnote><note-para label="1">In Order Theory, a binary relation satisfying these properties is called a total pre-order.</note-para><note-para label="2">See Appendix for notation.</note-para><note-para label="3">This term means that given two alternatives x and y it will always be possible to compare them. In fact, there will always be an active argumental structure Σ warranted in {a mathematical formula}K such that {a mathematical formula}cl(Σ)=Z with {a mathematical formula}Z∈{better(x,y),better(y,x),¬better(x,y),¬better(y,x)}, depending on the properties of the alternatives.</note-para><note-para label="5">It is worth noting that in the case of {a mathematical formula}m=k it results in the argumentation line {a mathematical formula}λk=[Σk].</note-para><note-para label="6">Note that it could be the case of {a mathematical formula}λ=[Σ″].</note-para></footnote></root>