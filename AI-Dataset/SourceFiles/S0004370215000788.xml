<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370215000788</url><title>Auction optimization using regression trees and linear models as integer programs</title><authors>Sicco Verwer,Yingqian Zhang,Qing Chuan Ye</authors><abstract>In a sequential auction with multiple bidding agents, the problem of determining the ordering of the items to sell in order to maximize the expected revenue is highly challenging. The challenge is largely due to the fact that the autonomy and private information of the agents heavily influence the outcome of the auction. The main contribution of this paper is two-fold. First, we demonstrate how to apply machine learning techniques to solve the optimal ordering problem in sequential auctions. We learn regression models from historical auctions, which are subsequently used to predict the expected value of orderings for new auctions. Given the learned models, we propose two types of optimization methods: a black-box best-first search approach, and a novel white-box approach that maps learned regression models to integer linear programs (ILP), which can then be solved by any ILP-solver. Although the studied auction design problem is hard, our proposed optimization methods obtain good orderings with high revenues. Our second main contribution is the insight that the internal structure of regression models can be efficiently evaluated inside an ILP solver for optimization purposes. To this end, we provide efficient encodings of regression trees and linear regression models as ILP constraints. This new way of using learned models for optimization is promising. As the experimental results show, it significantly outperforms the black-box best-first search in nearly all settings.</abstract><keywords>Auction design;Machine learning;Optimization;Integer linear programming;Regression</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>One of the main challenges of mathematical optimization is to construct a mathematical model describing the properties of a system. When the structure of a system cannot be fully determined from the knowledge at hand, machine learning and data mining techniques have been used in optimization instead of this knowledge. They have, for example, been used in order to obtain decision values [1], fitness functions [2], or model parameters [3]. Models that have been learned from data are frequently used in a black-box manner, e.g., using only the predictions of learned models but not their internal structure. It is also possible to use these models in a white-box manner, for instance in order to determine search space cuts and parameter bounds. Neural networks have in this way been used to model unknown relations in constraint programming [4]. In this paper, we develop such a white-box optimization method for regression models in integer linear programming, that is, we map these entire models to sets of variables and constraints and solve them using an off the shelf solver. This white-box method together with a proposed black-box method provides a solution to an optimization problem of key interest to the artificial intelligence and operations research communities: auction design. We briefly introduce this problem domain before going into the details of our methods.</paragraph><section label="1.1"><section-title>Sequential auction design</section-title><paragraph>Auctions are becoming increasingly popular for allocating resources or items in business-to-business and business-to-customer markets. Often sequential auctions [5] are adopted in practice, where items are sold consecutively to bidders. Sequential auctions are in particular desirable when the number of items for sale is large (e.g., flower auctions [6]), or when the buyers enter and leave the auction dynamically (e.g., online auctions [7]). In a sequential auction, an auctioneer may tune several auction parameters to influence the outcome of an auction, such as reserve prices for items and in which order to sell them. In other words, (s)he can design auctions for the purpose of achieving some predefined goal. In this paper, we solve one specific auction design problem, namely, deciding the optimal ordering of items to sell in a sequential auction in order to maximize the expected revenue (OOSA in short). We assume bidders in such auctions are budget constrained. This is a highly relevant problem in today's auctions since bidders almost always have limited budget, as seen for instance in industrial procurement [8]. Previous research has shown that with the presence of budget constraints, the revenue collected by the auctioneer is heavily dependent on the ordering of items to sell [9], [10], [11]. This holds already for a toy problem with 2 items. Let us use a simple example to illustrate the importance of ordering in such cases.</paragraph><paragraph label="Example 1">Two agents {a mathematical formula}A1 and {a mathematical formula}A2 take part in a sequential auction of items. For sale are items {a mathematical formula}r1 and {a mathematical formula}r2. Suppose the items are sold by means of first-price, English auction.{sup:1} Assume the reserve prices, which are the lowest prices at which the auctioneer is willing to sell the times, for both items are 1. The amount that agent {a mathematical formula}A1 and agent {a mathematical formula}A2 are willing to pay for two items are: {a mathematical formula}ν1(r1)=10, {a mathematical formula}ν1(r2)=15, {a mathematical formula}ν2(r1)=12, {a mathematical formula}ν2(r2)=10. Furthermore, the budgets of {a mathematical formula}A1 and {a mathematical formula}A2 are 15 and 25 respectively.We assume a simple bidding strategy in this example. The agents bid myopically on each item, that is, their highest bid on one item is the lower value between the amount that they are willing to pay and their remaining budget. The auctioneer's goal is to maximize the total sold price of the items. Consider one situation where the auctioneer sells first {a mathematical formula}r2 and then {a mathematical formula}r1. {a mathematical formula}A1 will get {a mathematical formula}r2 when she just over-bids {a mathematical formula}A2 with 11, and then when {a mathematical formula}r1 is auctioned, {a mathematical formula}A1 bids maximally 4 due to her budget limit, and {a mathematical formula}A2 will win the item with the price of 5. The total revenue is 16. However, if the selling sequence is ({a mathematical formula}r1, {a mathematical formula}r2), {a mathematical formula}A2 will win {a mathematical formula}r1 with the bid 11, and then {a mathematical formula}A2 will win {a mathematical formula}r2 with price 11. The collected revenue is 22 in this case. □</paragraph><paragraph>Most of the current approaches to the ordering problem in sequential auctions assume a very restricted market environment. They either study the problem of ordering two items, see [11], [12], or a market with homogeneous bidders [13]. To the best of our knowledge, we are the first to consider how to order items for realistic auction settings with many heterogeneous bidders competing for many different items. This problem is highly complex—a good design on ordering needs to take care of many uncertainties in the system. For instance, in order to evaluate the revenue given an ordering, the optimization algorithm needs to know the bidders' budgets and preferences on items, which are usually private and unshared. Furthermore, the large variety of possible bidding strategies that bidders may use in auctions are unknown. This auction design problem is a typical example where the mathematical optimization model cannot be fully determined, and hence, machine learning and data mining techniques can come into play. This is exactly what our approach builds upon.</paragraph></section><section label="1.2"><section-title>Learning models for white-box and black-box optimization</section-title><paragraph>Nowadays more and more auctions utilize information technology, which makes it possible to automatically store detailed information about previous auctions along with their selling sequences and the selling price per auctioned item. Our approach to solving the problem of optimal ordering for sequential auctions starts with the historical auction data. We define and compute several relevant features and then use them to learn regression trees and linear regression models for the expected revenue. Given the models, we propose two approaches to find the optimal ordering for a new set of items: (1) a best-first search that uses the models as a black-box to evaluate different orderings of the items; and (2) a novel white-box optimization method that translates the models and the set of items into a mixed-integer program (MIP) and runs this in an ILP-solver (CPLEX). Fig. 1 displays the general framework of our approaches using these two optimization methods.</paragraph><paragraph>Just like the traditional black-box optimization approach (see, e.g. [14], [15]), our best-first search is ignorant of the internal structure of the models and only calls it to perform function evaluations, i.e., predicting the revenue of an ordering of the items. Optimization is possible by means of a search procedure that uses heuristics to produce new orderings depending on previously evaluated ones. Our best-first search makes use of dynamic programming cuts inspired by sequential decision making in order to reduce the search space.</paragraph><paragraph>One of the main contributions of this paper is the realization that learned regression models can be evaluated efficiently inside modern mathematical optimization solvers. This evaluation includes the computation of feature values (the input to machine learning), the evaluation of these features using a learned model (the output from machine learning), and a possible feedback from such evaluations to new features. In this paper, we efficiently translate all of these steps for two types of learned models (regression trees and linear regression models) into mixed-integer constraints. The resulting mixed-integer program can then be evaluated in any modern integer linear programming (ILP) solver.</paragraph><paragraph>In this way, modern exact solvers can be used instead of a heuristic search. These solvers use (amongst others) advanced branch-and-bound methods to cut the search space, compute and optimize a dual solution, and can prove optimality without testing every possible solution. This is the main benefit of using the white-box method over a black-box one. The downside, however, is that when the learned model is complex, the white-box method may lead to a large mathematical model that is difficult to optimize. We compare these two approaches and investigate this trade-off by applying them to the OOSA problem.</paragraph><section><section><section-title>Contributions and organization</section-title><paragraph>Although we use sequential auction design to illustrate our method, all of our constructions are general and can be applied to any optimization setting where unknown relations can be represented using regression models that have been learned from data. The only constraint for using the white-box method is that the feature values need to be computable using integer linear functions from intermediate solutions. Our approach can thus be applied to complex optimization settings where entire orders, schedules, or plans need to be constructed beforehand.</paragraph><paragraph>We list our main contributions as follows:</paragraph><list><list-item label="•">We demonstrate how to apply regression methods from machine learning to OOSA.</list-item><list-item label="•">We give an efficient encoding of regression trees and linear regressors into MIP constraints.</list-item><list-item label="•">We prove OOSA with budget constrained bidders to be NP-hard, also when using these regression models.</list-item><list-item label="•">We provide the first method that tackles OOSA in realistic settings.</list-item><list-item label="•">We demonstrate experimentally that white-box methods outperform black-box methods when the models are not overly complex.</list-item></list><paragraph>In Section 2, we formally introduce the problem of optimal ordering for sequential auctions (OOSA), and then we show how to learn regression models from historical auction data in Section 3 using standard machine learning methods. Based on the learned models, our white-box optimization method and a black-box optimization are introduced to find the optimal ordering for OOSA in Section 4. Extensive experiments are presented in Section 5 where we compare the performance of the two proposed optimization methods using both the learned models and the auction simulator. Before we conclude, we compare and discuss more related works in Section 6.</paragraph></section></section></section></section><section label="2"><section-title>Optimal ordering for sequential auctions OOSA</section-title><paragraph>We assume there is a finite set of bidders (or agents). Let {a mathematical formula}R={r1,…,rl} denote the collection of the item types, and the quantity of each item type can be more than 1. When it is clear from the context, we will slightly abuse the notation and use {a mathematical formula}S={r1,r2…,r1,…} to denote the multiset of all available items. Each bidder agent i has a valuation (or preference) for each type of item {a mathematical formula}vi:R→R+. In addition, each agent has a budget {a mathematical formula}bi on purchasing items, and (s)he desires to win as many items as are being auctioned within the budget limit.</paragraph><paragraph>In one auction, a set of n items S with type set {a mathematical formula}R′⊆R will be auctioned sequentially using a predetermined order. We use {a mathematical formula}(s1,s2,…,sn) to denote such an ordering. For example, given types {a mathematical formula}r1 and {a mathematical formula}r2 with quantities of 1 and 2 respectively, there are three possible orderings of items: {a mathematical formula}(s1=r1,s2=r2,s3=r2), {a mathematical formula}(s1=r2,s2=r1,s3=r2), and {a mathematical formula}(s1=r2,s2=r2,s3=r1). For each {a mathematical formula}rj that is being auctioned, agent {a mathematical formula}Ai puts a bid on {a mathematical formula}rj that is the minimum between the amount she is willing to pay for {a mathematical formula}rj and the remaining budget. We point out that in the case of unconstrained budget, the maximum amount an agent is willing to pay for {a mathematical formula}rj, defined as {a mathematical formula}νi(rj), is equal to her valuation {a mathematical formula}vi(rj).</paragraph><paragraph>Each item {a mathematical formula}rj comes with a reserve price that is the lowest price at which the auctioneer is willing to sell {a mathematical formula}rj. If the received bids are all below the reserve price of {a mathematical formula}rj, {a mathematical formula}rj is not sold. Otherwise, the agent who bids highest on {a mathematical formula}rj wins {a mathematical formula}rj. The winners of items transfer some payment to the auctioneer depending on the auction rule. For example, in a first-price auction, the winner pays an amount equal to her bid, and in a second-price auction, she pays the second highest bid (or the reserve price for the item if it is higher). The revenue of the auctioneer is the sum of the total payment on the sold items and the total reserve values of the unsold items. This sequential auction ends when all items have been auctioned, or when all agents run out of their respective budgets.</paragraph><paragraph>We assume that such an auction is repeated over time, and each auction sells possibly different items S. At the end of each auction, we have the following information at our disposal: (1) the ordering of auctioned items; and (2) the allocation of items to agents with their payments. The optimization problem we study is: given a set of items and budget constrained bidders, finding an optimal ordering of items in sequential auctions such that the expected revenue is maximized. We call the problem OOSA.</paragraph><paragraph>We now show that the decision version of this optimization problem is NP-hard, even if we have complete information on bidders' preferences and they are not strategic (i.e., they bid truthfully according to their preferences).</paragraph><paragraph label="Theorem 1">Given a set of items S, preferences{a mathematical formula}vi:S→R+, and budgets{a mathematical formula}bifor every bidder i. The problem of deciding whether there exists an ordering that obtains a revenue of at least{a mathematical formula}K∈R+is NP-hard.</paragraph><paragraph label="Proof">The construction is clearly polynomial time. □</paragraph><paragraph>Several related works deal with this type of ordering optimization problem. For example, the authors of [11] investigate the optimal ordering strategy for the case where the auctioneer has two items to sell. They show that when the items are different in value, the higher valued items should be auctioned first in order to increase the seller's revenue. Pitchik [12] points out that in the presence of budget constraints, in a sealed-bid sequential auction, if the bidder who wins the first good has a higher income than the other one, the expected revenue is maximized. These greatly simplified auction settings make it possible to derive bidders' equilibrium bidding strategies. With some assumptions on the distributions of bidders' budgets and preferences, the optimal ordering can be theoretically derived. However, as real-world auctions are much more complex and uncertain in terms of the sizes of items/bidders, agents' preferences and bidding strategies, these existing results cannot be applied. In this paper, we instead focus on learning the overall behaviors of the group of bidders from historical auction data by machine learning techniques, as the first step of solving OOSA.</paragraph><paragraph>In order to apply ML techniques, we assume in every sequential auction the set of participating bidders and their characteristics (preferences, budgets, bidding strategies) to be similar. This simplifies the problem of learning a good ordering. Instead of learning the individual valuations/budget/bidding strategies of agents, we can treat the agent population as a single entity for which we need to find a single global function. Obviously, such an approach will fail if the agents are radically different in every auction. However we consider this assumption sensible in many auctions such as industrial procurement auctions where the same companies repeatedly join the auctions with similar interests, and the Dutch flower auction where there can be different bidders every day, but it seldom occurs that one day bidders are only interested in roses and the next day they only want tulips. Although the different participants can be interested in different item types, the interests of the group of participants remain stable.</paragraph></section><section label="3"><section-title>Learning predictive models for OOSA</section-title><paragraph>At the end of each sequential auction, we have the following information at our disposal: (1) the ordering of auctioned items; and (2) the price of each sold item. Before we build the optimization model to solve the OOSA problem, we need to find a suitable way to model the expected revenue of given orderings of auctioned items.</paragraph><paragraph>An ordering can be thought of as a sequence of items. However, to the best of our knowledge none of the existing sequence models fit our auction setting, see also Section 6.2. In this work, we view the prediction of an auction's outcome as a regression problem. We split this problem into the subproblems of predicting the value of the auctioned items. We then sum these up to obtain the overall objective function, i.e., the expected revenue {a mathematical formula}P(S) given a set S ({a mathematical formula}|S|=n) of items:{a mathematical formula} where {a mathematical formula}G(sk,J,L) is a regression function that determines the expected value of {a mathematical formula}sk given that J was auctioned before and L will be auctioned afterwards. The main benefit of this representation is that modern machine learning methods can be used to learn this function G from data. In addition, since every item sold represents a single sample, every auction contains many samples that can be used for learning, further reducing the amount of required data. We study two popular regressions functions.</paragraph><section label="3.1"><section-title>Two regression functions</section-title><paragraph>In this paper, we use regression trees [17] and least absolute shrinkage and selection operator (LASSO) [18] as regression functions, and train them using features based on the items auctioned before and after the current item. We first briefly introduce these regressors.</paragraph><section><section><section-title>Regression trees</section-title><paragraph>Regression trees are a form of decision trees where the predicted values are real numbers. A decision tree is one of the most popular predictive models for mapping feature values to a target value. It is a tree-shaped graph with a root node, interior nodes, and leaf nodes. The root and every interior node contains a Boolean test for a specific feature value f, such as {a mathematical formula}f&gt;5. Every leaf node contains an output value p. It maps the feature values to an output by performing all the tests along a path from the root to a leaf. For every test performed, if the outcome is true ({a mathematical formula}f&gt;5), the path is continued along the left branch, if the outcome is false ({a mathematical formula}f≤5), the path is continued along the right branch. Once a leaf is reached, it outputs the value it contains p.</paragraph><paragraph>A regression tree learner aims to find a tree that minimizes the mean squared error of the predicted and the actual observed values. Most regression tree learning algorithms follow a greedy strategy that splits interior nodes as long as the decrease in error is significant. A split replaces one leaf node by an interior node connected with two new leaf nodes. The interior node receives as Boolean constraint one that minimizes the mean-squared error of the resulting tree, where the leaf nodes predict the mean value of all observed data values that end up in that leaf after mapping all data samples to leaf nodes.</paragraph></section><section><section-title>LASSO</section-title><paragraph>LASSO is a method for constructing a linear regression function {a mathematical formula}p(f1,…,fm)=c1f1+c2f2+…+cmfm+d, where p is the value to predict, {a mathematical formula}ci are constants, {a mathematical formula}fi are feature values, and d is the intercept. The standard approach to find such a function is to minimize the mean squared error, which is easy to compute. LASSO is a popular regularized version of this simple estimation that penalizes the absolute values of the regression coefficients {a mathematical formula}c1,…,cm. Formally, given a dataset of features {a mathematical formula}fid and target values {a mathematical formula}pd, with {a mathematical formula}1≤d≤k where k is the number of samples, it uses convex optimization in order to find a regression function that solves the following problem{sup:2}:{a mathematical formula} where {a mathematical formula}0≤α≤1 is a parameter for the effect of the regularization. Intuitively, the larger α, the larger the penalty of having large coefficients {a mathematical formula}ci. Consequently, a larger value of α will drive more coefficients to zero. LASSO is a useful method when there are several correlated feature values, which could make an ordinary least squares model overfit on these values. We use LASSO regression because more zero coefficients implies we need to compute less feature values in order to evaluate the learned model, which has a positive effect on the optimization performance that we will discuss in Section 4.</paragraph></section></section></section><section label="3.2"><section-title>Learning regression functions for predicting revenues</section-title><paragraph>We first give an overview in Fig. 1 of the connection between the regression models and the optimization models for solving OOSA. Given historical auction data, a regression tree (or a LASSO linear regression function) is learned for each item type. The regression tree (or LASSO) can be used to evaluate the values of selling different items based on the feature values that are computed on a given ordering of the items. The learned regression trees (or LASSO functions) are then used in two ways to model the optimization problem OOSA: (1) Black-box optimization. In this paper, we use a best-first search heuristic to come up orderings of the items, and then use the learned regression trees (or LASSO) to compute the expected revenue of these orderings; (2) White-box optimization. We formulate the optimization problem of finding an optimal ordering as a mixed integer linear program (MIP), which is shown to be automatically constructed from the learned regression tress (or LASSO functions).</paragraph><paragraph>For every item, the index at which it was auctioned.</paragraph><paragraph>Other sequential features such as sliding windows and N-grams (see, e.g., [20]) can of course be added to the model. However, since our white-box method computes these values inside an ILP solver, the only requirement is that they can be represented using an integer linear formulation. Although the diff feature can be determined using the first, we add it for convenience of learning a regression tree, which requires many nodes to represent such values. The influence of budget constraints is only directly modeled by the fourth feature: once the amount paid for {a mathematical formula}r1 items reaches a certain (to be learned) bound, we can expect all agents that only want {a mathematical formula}r1 items to be out of budget. Although, there only exists an indirect relation between the budget constraints and the first three features, including them can be beneficial and these are easier to compute. If used by the regression model, these features thus reduce the time needed to solve the auction design problem. For similar reasons, we add the last feature. Below we give an example of how an ordering and its obtained values is transformed into a data set using these 5 types of features.</paragraph><paragraph label="Example 2">Consider the setting of Example 1. Assume two auctions have been carried out. One sold {a mathematical formula}r2 first and then {a mathematical formula}r1. The other reversed. As shown in Example 1, the first auction would obtain a revenue of 16, and the second auction would receive 22. We compute feature values from these two auctions as depicted in Table 1. Subsequently, we learn regression trees for both item types {a mathematical formula}r1 and {a mathematical formula}r2, as shown in Fig. 2.{sup:3}After learning these regression trees, we can optimize the ordering for a new (unseen) multiset of items {a mathematical formula}{r1,r1,r1,r2} by trying all orderings and choosing one with maximum expected revenue: {a mathematical formula}(r1,r1,r1,r2) gives {a mathematical formula}11+11+11+11=44, {a mathematical formula}(r1,r1,r2,r1) gives {a mathematical formula}11+11+11+5=38, {a mathematical formula}(r1,r2,r1,r1) gives {a mathematical formula}11+11+5+5=32, and {a mathematical formula}(r2,r1,r1,r1) returns {a mathematical formula}11+5+5+5=26. Hence, the optimizer will choose to schedule the {a mathematical formula}r2 item after all {a mathematical formula}r1 items. □</paragraph><paragraph>The example showed how to evaluate different orderings of items using the learned regression trees. In general, trying all possible orderings will be impossible: for a multiset of items {a mathematical formula}S={r1,…,rm} of m types, there are a total of {a mathematical formula}|S|!∏1≤i≤m|{ri|ri∈S}|! unique orderings, which blows up very quickly.</paragraph></section><section label="3.3"><section-title>Modeling power and trade-off</section-title><paragraph>Our method of regression modeling allows the use of any regression method from machine learning for predicting unknown quantities in optimization, such as objective values and parameters. In addition, since the regression function G uses other values in a (proposed) solution as input ({a mathematical formula}J,L) instead of only external parameters/data, a learned regression model represents unknown relations between the different values in a solution. The model thus answers the question “What is the value of X given that we do Y?”, as opposed to “What is the value of X?” that is answered by fitting only model parameters. Answering the first question allows for many more interesting possibilities. For instance, one could use stochastic optimization with fitted parameters to produce a schedule, use regression models to predict the effect of this schedule on the parameters, and use stochastic optimization again on the newly estimated parameters. This way, one can use machine learning tools to plan further ahead. Using our white-box method, this can even be done using a single call to the optimization software (see Section 4).</paragraph><paragraph>This loop-back functionality provides a lot of power to our method, but also comes with a risk. Every time the predictive models are used there is a probability that the predictions are inaccurate. When using a loop-back, these possible inaccuracies influence all future predictions that depend on it. These future predictions are thus more inaccurate and the predicted overall objective value can potentially diverge from the true value. These cascading inaccuracies are an issue, however, the added modeling power makes up for it. We make use of it in the sum feature, which relates the predicted value to the predictions of earlier auctioned items. This feature is very important for predicting budget constraints, and consequently is often used by the regression models to produce predictions.</paragraph></section></section><section label="4"><section-title>White-box and black-box optimization for OOSA</section-title><paragraph>Given the predictive models for the expected value per item, it is not straightforward to compute a good ordering as we already showed in Example 2. For a given ordering, we can predict the individual revenues of items using the regression model, and sum these up to obtain the revenue of the ordering. However, testing all possible orderings and choosing the one with the highest revenue will take a very long time. For instance, when we want to order 40 items of 8 types (the experimental setting in Section 5) with 5 of every type, we will need to test {a mathematical formula}40!5!8≈1.9⋅1031 possible unique orderings.</paragraph><paragraph>In Appendix A, we also provide hardness results that demonstrate there is little hope (unless {a mathematical formula}P=NP) of finding an efficient (polynomial-time) algorithm that gives the optimal ordering for any regression tree or linear regression predictor. In general, we cannot do better than performing a guided search through the space formed by all possible orderings. We present two such search-based optimization methods: (1) a novel “white-box” optimization (i.e., ILP model), and (2) a “black-box” heuristic (i.e., best-first search).</paragraph><section label="4.1"><section-title>White-box optimization: an ILP model</section-title><paragraph>Given regression tree and linear regression models for the expected value per item type, we automatically formulate the problem of finding an optimal ordering as a mixed integer linear program (MIP). We discuss the encoding of a sequential auction, feature values, objective function, and translating the learned models (regression tree and linear regression respectively) below.</paragraph><section><section><section-title>Ordering an auction</section-title><paragraph>Given a multiset S of n items, each from a set of possible types R, we use the following free variables to encode any possible ordering of S: {a mathematical formula}xi,r∈{0,1}. Item i is of type r if and only if {a mathematical formula}xi,r=1. Thus, if {a mathematical formula}x3,r1 is equal to 1, it means that the third auctioned item is of type {a mathematical formula}r1. We require that at every index i at most one item type is auctioned, and that the total number of auctioned items of type r is equal to the number {a mathematical formula}nr of type r items in S.{a mathematical formula}{a mathematical formula}</paragraph><paragraph>Any assignment of ones and zeros to the x variables that satisfies these two types of constraints corresponds to a valid ordering of the items in S. The value of such an ordering is determined by the learned regression models.</paragraph></section><section><section-title>Translating feature values</section-title><paragraph>In order to compute the prediction of a regression model, we not only need to translate the models into ILP constraints, but also the values of the features used by these models.{sup:4} Feature 1, 2, 3, and 5 can be computed using linear functions from the x variables:{a mathematical formula}{a mathematical formula}{a mathematical formula}{a mathematical formula}</paragraph><paragraph>For the fourth type of feature, we use an additional variable {a mathematical formula}pj,r, which encodes the expected value of the item auctioned at index j of type r. If the item at index j is not of type r, {a mathematical formula}pj,r is equal to 0. Since the p variables are the predictions of the regression functions, we provide their definition after defining the regression models.{a mathematical formula}</paragraph><paragraph>To aid the ILP solver, we also pre-compute the minimum {a mathematical formula}mf,i and maximum {a mathematical formula}Mf,i obtainable values of every feature f at every index i and provide these as bounds to the solver.</paragraph></section><section><section-title>Constructing the objective function</section-title><paragraph>We aim to maximize the expected values {a mathematical formula}pi,r:{a mathematical formula}</paragraph><paragraph>Although it is also possible to compute both the objective function and the sum values as very large sums over the x and model variables (described next), specifying parts of these sums as intermediate continuous p variables significantly reduces both the encoding size and the computation time.</paragraph><paragraph>Finally, we discuss how to encode the learned regression tree and the linear regression model as the constraints in the ILP model.</paragraph></section><section><section-title>Encoding regression trees</section-title><paragraph>We translate the regression tree models into ILP using carefully constructed linear functions. Our encoding only requires one new set of {a mathematical formula}{0,1} variables {a mathematical formula}zi,l,r, representing whether a leaf node l is reached for item type r at index i. The internal (decision) nodes of the trees can be represented implicitly by the constraints on these new z variables. Intuitively, we encode that a z variable has to be false when the binary test of any of its parent nodes fails. By additionally requiring that exactly one z variable is true at every index, we fully encode the learned regression trees.</paragraph><paragraph>Let {a mathematical formula}Dr be the set of all decision nodes in the regression tree for type r. Every decision node in {a mathematical formula}Dr contains a boolean constraint {a mathematical formula}f≤c, which is true if and only if feature f has a value less than or equal to a constant c. A key insight of our encoding is that every such boolean constraint directly influences the value of several z variables: if it is true (at index i), then all z variables representing leafs in the right subtree are false; if it is false, then all that represent leafs in the left subtree are false. In this way, we require only two constraints per boolean constraint in order to represent all possible paths to leaf nodes.{a mathematical formula}{a mathematical formula} where {a mathematical formula}fvf,i is a calculation of feature value f for index i, L and {a mathematical formula}L′ are the leaf nodes in the left and right subtrees of the decision node with constraint {a mathematical formula}(f≤c) in the regression tree for type r, and {a mathematical formula}Mf,i and {a mathematical formula}mf,i are the maximum and minimum values of feature f at index i. For the feature calculation we simply replace {a mathematical formula}fvf,i with the right-hand sides of the corresponding feature definitions.{sup:5}</paragraph><paragraph>The above constraints ensure that when {a mathematical formula}zi,l,r obtains a value of 1, all of the binary test in the parent nodes on the path to l in the tree for type r return true at index i. By construction of the regression trees, this ensures that at most one z variable is true for every type r and index i. We require however that exactly one z variable is true at every index.{sup:6} This z has to be of the same type as the item sold at index i, denoted by the x variables:{a mathematical formula}</paragraph><paragraph>This completes our encoding of the regression trees. The predictions of the trees at every index i are given by the z variable that is true for index i. We multiply this z variable with the constant prediction in the leaf node it represents to obtain the prediction, and store it in the p variables used to compute the sum feature values.{a mathematical formula} where {a mathematical formula}cl,r is the constant prediction of leaf l in the tree for type r.</paragraph></section><section><section-title>Complexity</section-title><paragraph>Our translation of regression trees is very efficient. It requires only 2 constraints per decision node ({a mathematical formula}Dr, Equations (9) and (10)) and 1 binary variable {a mathematical formula}zi,l,r for every leaf node ({a mathematical formula}L+L′, used in Equations (9), (10), and (11)) of the tree. To encode a complete depth k tree with {a mathematical formula}2k+1−1 nodes, this thus requires only {a mathematical formula}2×(2k−1)=2k+1−2 constraints for the decision nodes and {a mathematical formula}2k binary variables for the leaf nodes. In addition, we require 1 constraint to force exactly one leaf variable to be true (the same type as {a mathematical formula}xi,r, Equation (11)). All the other variables and constraints, used to compute the feature values and {a mathematical formula}pi,r variables, can be computed directly without storing the result into a variable. Consequently, this adds zero variables and zero constraints to the translation.</paragraph><paragraph>In order to encode an entire OOSA problem, a new set of constraints representing a tree is constructed for every item type and every item index. In a problem with {a mathematical formula}|R| types and n items for sale, this creates {a mathematical formula}n×|R|×(2k+1−1) constraints and {a mathematical formula}n×|R|×(2k) variables to encode a complete tree of depth k. The ordering problem itself requires {a mathematical formula}n×|R| ({a mathematical formula}xi,r, Equations (1) and (2)) variables and {a mathematical formula}n+|R| constraints. This totals to: {a mathematical formula}n×|R|×(2k+1) variables and {a mathematical formula}n×|R|×(2k+1−1)+n+|R| constraints. Since a complete depth k tree has {a mathematical formula}2k+1−1 nodes, this is linear in the number of nodes of the tree.</paragraph><paragraph>We now discuss how to encode a linear regression model.</paragraph></section><section><section-title>Encoding linear regression model</section-title><paragraph>Due to its linear nature, implementing linear regression in ILP is very straightforward. We can directly compute the value of the p variables using the linear predictor function:{a mathematical formula} where Feat is the set of all features, {a mathematical formula}fvf,i is feature f's values at index i, and {a mathematical formula}cf,r is the constant coefficient for feature f in the regression function for type r. The only somewhat difficult part is that at every index, the used regression function can change depending on the auctioned item type r. We implemented this choice using indicator functions in CPLEX.{sup:7} This changes the above formulation as follows:{a mathematical formula}{a mathematical formula}</paragraph><paragraph>It states that if {a mathematical formula}xi,r is true, then the values of {a mathematical formula}pi,r is determined using the regression function. Otherwise, its value is 0. These are the only constraints needed to fully implement a linear regression function. When using LASSO regularization, some coefficients will receive the value 0. These are removed from the encoding, making the models smaller and easier to evaluate in the solver.</paragraph></section><section><section-title>Complexity</section-title><paragraph>The translation of regression functions is straightforward and only requires 2 constraints per item type for the indicator functions (Equations (14) and (15)). Because of these indicators, we do need to encode the {a mathematical formula}n×|R|pi,r variables. No additional constraints or variables are required. In order to encode an entire OOSA problem, we thus require only {a mathematical formula}n×|R|×2 constraints and {a mathematical formula}n×|R|×2 variables.</paragraph></section><section><section-title>An example</section-title><paragraph>Now the two ILP models are complete and ready to solve the OOSA problem. We give the following example to illustrate how the formulation of ILP works given learned regression trees.</paragraph><paragraph label="Example 3">Given the learned trees in Example 2, suppose we are asked to order a new multiset of items {a mathematical formula}{r1,r2,r2}. We translate this new set, together with the learned trees into the following integer linear program with the following {a mathematical formula}{0,1} decision variables (for all {a mathematical formula}1≤i≤3): {a mathematical formula}xi,r1,xi,r2,zi,1,r1,zi,2,r1,zi,1,r2:{a mathematical formula}{a mathematical formula}{a mathematical formula} subject to (for all {a mathematical formula}1≤i≤3){a mathematical formula}{a mathematical formula}{a mathematical formula} This denotes that exactly one x variable is true at every index i, 2x variables are true for item type {a mathematical formula}r2, and 1 for type {a mathematical formula}r1. This encodes all possible orderings. From this we compute the feature values (for all {a mathematical formula}1≤i≤3):{a mathematical formula}{a mathematical formula} that are used in the constraints denoting the Boolean tests in the internal nodes:{a mathematical formula}{a mathematical formula} where {a mathematical formula}Msold,i=100 and {a mathematical formula}msold,i=0. The first two constraints encode that if {a mathematical formula}zi,1,r1=1, {a mathematical formula}soldi,r2≤0.5; and if {a mathematical formula}zi,2,r1=1, {a mathematical formula}soldi,r2≥0.5. Thus, if a z variable is true for a leaf, then all the Boolean tests of internal nodes on the path from the root to that leaf have to succeed. At last, we require that exactly one z variable is true at every index:{a mathematical formula}{a mathematical formula} A satisfying assignment to the x variables is {a mathematical formula}x1,r1,x2,r2,x3,r2 set to 1, the rest to 0, corresponding to the ordering {a mathematical formula}(r1,r2,r2). Since {a mathematical formula}sold1,r2=0, this leads to {a mathematical formula}99.5z1,1,r1≤100 and {a mathematical formula}−0.5z1,2,r1≥0, forcing {a mathematical formula}z1,2,r1=0. Since {a mathematical formula}z1,1,r1+z1,2,r1=x1,r1=1, this implies {a mathematical formula}z1,1,r1=1. For the next index, since {a mathematical formula}x2,r2=1, it forces {a mathematical formula}z2,1,r2=1. Similarly, we obtain {a mathematical formula}z3,1,r2=x3,r2=1. This results in {a mathematical formula}p1,r1=11, {a mathematical formula}p2,r2=11, {a mathematical formula}p3,r2=11, and an objective value of 33. □</paragraph></section></section></section><section label="4.2"><section-title>A black-box heuristic: best-first search algorithm</section-title><paragraph>We also provide a black-box heuristic for solving the ordering problem, see also [21]. The traditional method to overcome the computational blowup caused by sequential decision making is to use a dynamic programming method. Although this lessens the computational load by combining the different paths that lead to the same sets of auctioned items, the search space is still too large and waiting for a solution will take too long. Instead, we therefore employ a best-first search strategy that can be terminated anytime in order to return the best found solution so far. We show how this best-first search strategy works in Algorithm 1.</paragraph><paragraph>The algorithm uses a hashtable and a priority queue. The hashtable is used to exclude the possibility of visiting the same nodes twice if the obtained value is less than before (just like a dynamic programming method). These dynamic programming cuts are sensible but lose optimality as on rare occasions it could be better to sell earlier items for less, leaving more budget for the remaining ones. The priority queue provides promising candidate nodes for the best-first strategy. By computing random orderings of the remaining items, the learned models can evaluate complete orderings of all items. The best one found is stored and returned if the algorithm is terminated. Unfortunately, this does not result in an admissible heuristic for an A* search procedure. Hence, even if the algorithm pops a solution from the queue, this is not necessarily optimal. In our experience, using random orderings of the remaining items in this heuristic provides a good spread over the search space. Although some nodes can be ‘unlucky’ and obtain a bad ordering of the remaining items, there are always multiple ways to reach nodes in the search space and it is very unlikely that all possibilities will be ‘unlucky’.</paragraph></section><section label="4.3"><section-title>Discussion: white-box or black-box optimization?</section-title><paragraph>The main difference between the two abovementioned approaches (see Fig. 1) is that the white-box method specifies the predictors entirely as constraints, which can be used to infer bounds on the predictions and cut the search space. The black-box method instead uses the predictors as oracles and is ignorant as to how the predictions are made, which are naturally more efficient to compute but cannot be used to infer search space cuts, i.e., to deduce that one ordering is better than another without testing both of them. Another key difference is that the white-box method results in a single optimization model that can be run in any modern solver, while the black-box method requires the use of executable code to produce the predictions. In the black-box setting, it is therefore much harder to use the powerful solving methods available in dedicated solvers for problems such as integer linear optimization (ILP), satisfiability (SAT), or constraint programming (CP). Instead, general search methods can be used such as best-first search, beam-search, meta-heuristics, genetic algorithms, etc.</paragraph><paragraph>Both black-box and white-box approaches have their advantages. The main advantage of black-box is that its performance is for a large part independent of the complexity of the used regression model. In contrast, by explicitly modeling the regression model as constraints in a white-box, more complex regression models lead to many more constraints, which can dramatically increase in the time needed to solve it. Another advantage of black-box optimization is that it is easy to include additional cuts such as the dynamic programming cuts discussed above. Such cuts can be added as constraints in an LP formulation, but this can lead to a blow-up in runtime.</paragraph><paragraph>The main benefit of using the white-box approach is the use of modern exact solvers instead of a heuristic search. These solvers use (amongst others) advanced branch-and-bound methods to cut the search space, compute and optimize a dual solution, and can prove optimality without testing every possible solution. Our white-box constructions can also be easily integrated into existing (I)LP formulations that have been used in a wide range of applications in for instance Operations Research. In this way, one can combine the vast amount of expert knowledge available in these applications with the knowledge in the readily available data.</paragraph><paragraph>The most important downside of white-box is that an evaluation of translated models likely requires more time than running the code as a black-box, especially when the models or features are somewhat complex. In our opinion, however, the advantages of white-box optimization largely outweigh those of black-box optimization and make it a very interesting topic for research in machine learning and optimization.</paragraph></section></section><section label="5"><section-title>Experiments</section-title><paragraph>Designing an optimal ordering for sequential auctions is difficult with heterogeneous bidders, as they may value items differently, have different budget constraints, and moreover, bid rationally or irrationally with various bidding strategies. To evaluate the performance of the proposed optimization methods, ideally, we should collect real auction data, build the optimization models, run real-world auctions with real bidders using different ordering of items produced by different methods, and then compare the resulting revenues. Since this evaluation method is not feasible for us, nor is it the main purpose of this paper, we opted for a widely accepted evaluation approach in research community, that is, we created an auction simulator which simulates auctions with agents. We used this simulator to generate auction data sets, and to evaluate the proposed method. An overview of this process is given in Fig. 3.</paragraph><section label="5.1"><section-title>The simulator</section-title><section><section><section-title>Simulating auctions</section-title><paragraph>We simulate several sequential auction settings with the simulator: (i) first price auctions where agents bid the lower value between the amount they are willing to pay for the item, which is no higher than their valuation on the item, and their remaining budget, as in [11]; (ii) second price sealed bid auctions, i.e. Vickrey auctions [22]. Agents bid truthfully on each item in each round based on their valuations, or in case of insufficient budget, they bid their remaining budget, as in [7]. This is the best-response bidding strategy for myopic utility-maximizing agents who only consider the current round of the auction.{sup:8} (iii) Vickrey auctions where agents bid smartly, i.e., they compare the utility obtained at the end of the auction when buying and not buying the item and place a bid based on the difference (see Section 5.4 for more details). On the last auctioned item, they bid truthfully if the budget allows.{sup:9} Otherwise, they bid their remaining budget. Given all bids on an item, the highest bid wins. If multiple agents have the same highest bid, one of these is selected as winner uniformly at random. With these different auction settings, we intend to show our method is robust to the auction rules and bidding strategies. Below we explain how we generated agents and items for these settings and what parameters we used. At the end of this chapter, we will show how well our method scales when we use different parameters for the generator.</paragraph></section><section><section-title>Item types</section-title><paragraph>We use a given set of 8 items to initialize the auction simulator. Every type {a mathematical formula}ri gets assigned a base value {a mathematical formula}μi of {a mathematical formula}25+(5⋅i), for {a mathematical formula}1≤i≤8, and a reserve price {a mathematical formula}ρi=12(25+(5⋅i)). Every type is assigned popularity and sparsity values, denoted by {a mathematical formula}γi and {a mathematical formula}λi, drawn uniformly from {a mathematical formula}[2,10]. The popularity value measures the degree of desirability of the item type by the agents. The sparsity is a measure for the frequency that an item type is available in one auction. In every auction, 40 items are generated using a roulette wheel drawing scheme using the sparsity values.</paragraph></section><section><section-title>Bidder agents</section-title><paragraph>The simulator starts with 20 randomly generated bidding agents. Every such agent {a mathematical formula}Aj gets assigned a budget {a mathematical formula}bj between 25 and 150 uniformly at random. They may desire 1 to 5 of the 8 item types, where popular types have a higher probability of being selected, drawn using a roulette wheel selection on the item types' popularity values. Every desired item type {a mathematical formula}ri assigned to an agent {a mathematical formula}Aj is also given a value of {a mathematical formula}νj(ri)=β⋅μi, where {a mathematical formula}μi is the base value of type {a mathematical formula}ri, and β is a uniform random value between 0.5 and 2.0. The value {a mathematical formula}νj(ri) is used as the amount that agent {a mathematical formula}Aj is willing to pay for {a mathematical formula}ri in the first-price auctions, and is used as the valuation of {a mathematical formula}Aj on {a mathematical formula}ri in the second-price auctions. If this value is greater than the budget of the agent, that agent's budget is increased by another value between 25 and 150 (sampled uniformly), and adding this to its budget. This is repeated until the budget is sufficient for every item type.</paragraph><paragraph label="Example 4">The following is an example of eight agents {a mathematical formula}A1,…,A8 and four item types {a mathematical formula}r1,r2,r3,r4 generated for the small-scale experiments in Section 5.5.1, where for the four item types, the reserve prices of the auctioneer are: {a mathematical formula}ρ1=12.5, {a mathematical formula}ρ2=15, {a mathematical formula}ρ3=17.5, and {a mathematical formula}ρ4=20; the sparsity values of the four item types are: {a mathematical formula}λ1=2, {a mathematical formula}λ2=7, {a mathematical formula}λ3=2, and {a mathematical formula}λ4=5; and the popularity values are {a mathematical formula}γ1=8, {a mathematical formula}γ2=8, {a mathematical formula}γ3=6, and {a mathematical formula}γ4=2. Every agent's budget is sampled between 25 and 80.{a mathematical formula}In the generated agents, we can clearly see that some item types are more popular than others. Item type {a mathematical formula}r4 is the least popular, being desired by only two agents, caused by the low popularity value of 2. The valuations are sampled uniformly using the base values. Agent {a mathematical formula}A5 has a budget greater than 80, due to the budget resampling. Five examples of the generated item sequences with corresponding revenues are:{a mathematical formula} In the sequences, items of type {a mathematical formula}r1 or {a mathematical formula}r3 occur the least frequent, due to the low sparsity values. □</paragraph></section><section><section-title>Training</section-title><paragraph>For a given set of 20 random bidders, the simulator generates 1000 historical auctions. The 40 items in these auctions are generated using the above scheme, and ordered randomly. These items are run in the simulator, where the agents use the above-mentioned bidding strategies to decide what value to bid, in order to determine the winners and the item selling prices. The total selling price of all items in one sequential auction is the collected revenue. For the 20 generated bidders, we first experiment the effect of different item orderings on the collected revenue by trying 100 random orderings and comparing the smallest, median, and largest collected revenue. If the difference between the largest and smallest is less than one tenth of the median revenue, 20 new bidders are generated. This process is repeated until we find a set of agents that passes this check, which typically occurs after a few iterations. By performing this check, we remove irrelevant problem instances. For the 20 agents that pass this check, we generate 1000 auctions of 40 items and simulate these auctions together with the agents. The resulting sequences of item-price pairs are then transformed to the features discussed in Section 3, and the resulting data set is used to train the regression trees and linear regressors.</paragraph></section><section><section-title>Testing</section-title><paragraph>For the same set of 20 bidders, we generate 5 sets of 40 items, which are used for testing. First, the regressors are tested by comparing their predictions with the revenues generated by the simulator on 50 random orderings of each of these item sets. Second, we translate each of the item sets into constraints for both the black-box and white-box optimization solvers. The best ordering found by these solvers are compared based on their values on the regression model, and in the simulator.</paragraph></section></section></section><section label="5.2"><section-title>Experimental setup</section-title><paragraph>In each experiment, we generate agents and items as described above. We use an implementation of regression trees and LASSO from the scikit-learn machine learning module [19] in Python to learn (and evaluate) the regressors. We learn trees of different depths of 3, 5, 8 (we call them tree3, tree5, tree8), and we set the minimum number of samples required to split an internal node to 10. The LASSO regressor is run with 3 different values for α: 1.0, 0.1, and 0.000001 (lasso1, lasso2, lasso3), the tolerance threshold to test for convergence is set to 0.0001 and we use a maximum of 100 000 iterations. The resulting trees and linear models then get translated to ILP, which in turn gets solved by an ILP-solver (CPLEX [24]). In addition, we provide the solver with an initial solution (the best of 1000 random orderings) in order to start the search, and set the focus of the solver to finding integer feasible solutions. We set a time limit on the ILP solver of 15 minutes for each instance using a single thread on an Intel core i-5 with 8 GB RAM and record the best ordering of items that the ILP solver has obtained. The last minute is spent on solution polishing (a local search procedure in CPLEX). We apply our best-first search method on the same problem instances with the same running time limit.</paragraph><section><section><section-title>Evaluations</section-title><paragraph>There are two levels of evaluations involved in our problem. Firstly, we determine the quality of the learned regressors, as they influence the quality of the solution after optimization. For this, we tested different regression trees with different maximum depths and linear regression models with different parameters.</paragraph><paragraph>Next, the optimization methods are evaluated in terms of the quality of the produced ordering. The optimization methods that we compare include the proposed white-box ILP model which finds a solution based on the abovementioned 6 regression models, the proposed black-box best-first search which evaluates a solution based on the 6 regression models, and in addition, two other simple ordering methods: (i) auctioning the most valuable item first (i.e., mvf), as suggested in [11]{sup:10}; and (ii) a random ordering strategy (i.e., mean5000), as seen in many real-world auctions for the purpose of fairness.</paragraph><paragraph>It is not feasible for us to compute the best solution given the problem size. Thus, we obtain a lower bound on the optimal solution as follows: given a set of items, we generate 5000 random orderings, and we use the true model (i.e., the simulator) to evaluate them and pick the one returning the highest revenue. We use the mean value of these 5000 random orderings as the output of the random ordering strategy.</paragraph><paragraph>We evaluate the 15 ordering methods in two ways:</paragraph><list><list-item label="•">Model evaluation: we use the learned regression models to evaluate the solutions returned by the ordering methods to compute the predicted revenues.</list-item><list-item label="•">Actual evaluation: we run auctions with the solutions (i.e., orderings) returned by the ordering methods in our simulator to obtain the corresponding revenues. Note that such an evaluation is possible only when a simulator is available.</list-item></list><paragraph>In addition, we investigate the scalability of our approach using the following experiments: (1) first, we test the small instances to show how close the orderings found by the learned models are to the actual optimum; (2) second, we generate a randomized population of bidders to test whether our method can handle the cases where the bidders in different auction vary a lot; (3) third, we use a larger set of items and item types to demonstrate how well our approach can be expected to perform in larger auctions with many more items of greater diversity.</paragraph></section></section></section><section label="5.3"><section-title>Experiment 1: first-price auctions</section-title><paragraph>We run 60 sets of experiments. For each set of experiment, we generate a set of agents, and generate and run new sets of items 5 times. This results in 300 models for each learning method.</paragraph><section><section><section-title>Prediction accuracy</section-title><paragraph>We first report the performance of the learned trees and linear models in terms of prediction accuracy. Given the same set of items as used during learning, we randomly generate 50 permutations of these items as orderings and compute the predicted values of these orderings using the learned models. Thus, for every set of agents, there are {a mathematical formula}50×5×40=10000 bids to predict. These predictions are compared with the evaluated values of the orderings by the simulator. We report the coefficients of determination, or {a mathematical formula}R2 scores, in Fig. 4. This coefficient is a standard measure for comparing regression models and is defined as:{a mathematical formula} where k is the number of samples, {a mathematical formula}pd is the dth data value (i.e., the revenues returned by the simulator), {a mathematical formula}p(f1d,…,fmd) the predicted values (i.e., the predicted revenues returned by the learning models: tree3lp, tree5lp, tree8lp, lasso1, lasso2, lasso3), and {a mathematical formula}mean(p) the mean of all data values. Each score is computed from 10000 values in Fig. 4. A large value (close to 1.0) means the regressor is an almost perfect predictor, and smaller values indicate worse performance. Fig. 4 shows that all regression models lead to good prediction, with the lowest {a mathematical formula}R2 score over 0.86. The learned trees with depth 8 give the best performance, followed by the trees with depth 5. Intuitively a larger tree may give a better prediction. The scores of lasso2 and lasso3 are very similar, and slightly better than lasso1. This result makes sense since LASSO with a higher regularization parameter α (i.e., lasso1) implies the use of less features, and hence, may have less prediction power. The tree with depth 3 shows much worse performance than the larger trees, and it is on average worse than the three linear regression models. This is confirmed by the frequencies of wins by comparing the {a mathematical formula}R2 scores in pairs in Table 2.</paragraph></section><section><section-title>Performance of the ordering methods</section-title><paragraph>We now discuss the actual performance of the different ordering methods. After every ordering method returns its best ordering, these orderings are then evaluated in the simulator to get corresponding revenues. As we ran 300 different instances (60 sets of different agents, each with 5 sets of different items), each method has 300 such revenues. We calculate the frequencies of wins by comparing the revenues in pairs in Table 3. One obvious conclusion from the table is that the ordering heuristic mvf (i.e., most valuable item first) performs worst, regardless of which method it compared to. In fact, this heuristic performed even worse than the random ordering strategy mean5000 (123 wins vs. 174).{sup:11} This result contradicts the theoretical finding that was concluded using much simpler auction settings. Another observation is that given the learned models, the developed white-box methods win over the black-box methods more than half of the time. This holds consistently for all 12 proposed methods (wins lp vs. bf: 171, 197, 178, 185, 195, 189). It shows that our new way of utilizing the internal structure of the learned models for optimization is promising.</paragraph><paragraph>If we look at the results of the white-box methods built from the learned regression trees, i.e., tree3lp, tree5lp, tree8lp, we notice that tree5lp and tree8lp performed similarly and they are slightly better than tree3lp. This result is consistent with the higher {a mathematical formula}R2 scores of the larger trees. Interestingly, despite their lower {a mathematical formula}R2 scores, the linear regression LP methods return good orderings especially lasso2lp and lasso3lp which are on average better than the three regression tree LP models. These are further confirmed with Fig. 5, which depicts the revenue differences in the simulator between the ordering methods and mean5000. It is more obvious from this figure that the proposed linear regression LP models are the better optimization methods than the tree LP models in practice. We believe that this is due to the cascading inaccuracies, caused by the sum feature that relates the predicted value to the predictions of earlier auctioned items (see discussions in Section 3.3). Due to the crisp boundaries in regression trees, the effect of these errors on the solution evaluation is much greater than using linear regressors. We believe the effect is smaller for larger trees because they are more accurate.</paragraph><paragraph>Fig. 6 shows the performance difference between the LP model and the best-first search, which are built upon the same learned regression model. The solutions are evaluated using the predictive models. The value differences between the white-box and the black-box methods are more significant on smaller trees than on bigger trees (tree3 vs tree5 vs tree8), and on linear models with higher regularization parameter than on lower regularization parameter (lasso1 vs lasso2 vs lasso3). This trend shown in the results is somehow expected. The smaller tree leads to a smaller LP model, which is easier to optimize by the solver and consequently gives a much better performance than the best-first search. Similarly, the linear regression with a higher regularization parameter α implies less feature values to compute during white-box optimization, and therefore, its advantage over the black-box method is more obvious than lasso2 and lasso3 which are with smaller values of α.</paragraph><paragraph>We observe that all white-box LP methods are better than the black-box methods, except the LP models resulting from the trees with depth 8. The depth 8 regression trees perform better for best-first search when evaluated on the model (Fig. 6), but better for LP when evaluated in the simulator (see Fig. 5). The most likely reason for the strange behavior of the depth 8 trees is that the best-first search outperforms LP on harder to predict instances.{sup:12} Intuitively, because harder-to-predict instances typically result in larger models, they are harder to optimize in CPLEX. We checked this cause by investigating whether the {a mathematical formula}R2 scores of the depth 8 regression tree are correlated with which method performing better in the model evaluation. The mean of these {a mathematical formula}R2 scores are 0.950 when the LP performs better, and 0.942 when the best-first performs better. Although this difference seems small, it is significant.</paragraph><paragraph>Moreover, the small difference in {a mathematical formula}R2 scores between trees with depth 5 and depth 8 also has a significant effect on the difference between their model and simulator evaluations (e.g., due to cascading errors). To demonstrate this, we report in Fig. 7 the solution differences of the same ordering methods when being evaluated by the model and the simulator. The purpose of this comparison is to test whether the predicted outcome (using learned models) corresponds to the actual outcome (using simulator). This test is important as in general, there are no simulators available to evaluate the solutions. The figure demonstrates that the linear regression based optimization methods return more reliable solutions, i.e., their solutions evaluated on the learned linear models are closer to the solution values returned by the simulator. Note that it is logical that most values are over estimated because we the optimization tries to solve a maximization problem. The trees with depth 5 and 8 show a significant difference in this evaluation. The depth 3 trees end up with the highest evaluation difference, and overestimate the solution values the most.</paragraph></section></section></section><section label="5.4"><section-title>Experiments 2 and 3: Vickrey auction with myopic and smart agents</section-title><paragraph>In order to demonstrate that our method of auction optimization using learned models is robust to the used auction rule or the bidding strategies, we test it in a second-price auction in Experiment 2, and with smart agents in Experiment 3. We generate 10 sets of agents using the settings of the main experiments. For each set of agents we run new sets of items 5 times. Fig. 8, Fig. 9 show the same plots for these settings as Fig. 5, Fig. 6 for the setting in the first experiment.</paragraph><paragraph>In the second-price experiment, we test with truth-telling bidders in second-price auctions. The only differences with the setting in the first experiment are the bidding values and the payments. As Fig. 8 shows, the results are very similar to those in the first experiments: (1) all methods outperform the naive ordering strategies from the literature, (2) the white-box outperforms the black-box methods, and (3) the linear regression models perform best. However, the difference between the best performing methods tree5 and lasso2 is no longer significant.</paragraph><paragraph>In the third experiment, we test with smart agents that aim to maximize their final utility in a second-price auction. Specifically, when deciding what value to bid on the current item {a mathematical formula}ri, they have access to the auction simulator and use it to run the remaining items {a mathematical formula}I′∖ri. For computational reasons, when running the remaining items {a mathematical formula}I′∖ri, it is assumed that all agents bid truthfully and pay according to the second-price rule in these runs. For every bid {a mathematical formula}ri, they run the simulator twice: once in the situation where they bid the item {a mathematical formula}ri with their valuations (run1), and once where they do not buy the item (run2). They then decide what value to bid according to the following rules:</paragraph><list><list-item label="•">If after run2 the agent has a remaining budget greater than its value for the item, it bids truthfully. The intuition is that it is better to buy an item than to have budget left at the end of auction.</list-item><list-item label="•">Else, if the total utility after run2 is less than after run1, it also bids truthfully. When it is better to buy an item, try to obtain it.</list-item><list-item label="•">Else, it bids its true value minus the difference in utility after run2 and run1. When it is x monetary units better not to buy an item, try to obtain it for the value minus x.</list-item></list><paragraph> Using these rules, the agents bid the highest value that they expect will give them an increase in utility.</paragraph><paragraph>As can be seen in Fig. 9, also in this challenging setting, our method performs significantly better than the naive ordering rules from the literature. There is however a much larger variance in the performance of the different methods, causing the difference between black-box and white-box to be insignificant in the simulator. When evaluated on the model, however, white-box is still better than black-box in all cases except tree8. An interesting final observation is that, with these smart agents, the mvf method does seem to perform slightly better than mean5000 (although not significantly), while in the other experiments it performed consistently worse.</paragraph></section><section label="5.5"><section-title>Experiment 4: practical issues</section-title><paragraph>Although optimizing the orderings in sequential auctions is a hard problem, the above experiments demonstrate that high revenues can be obtained, significantly outperforming the naive methods proposed in the literature. This holds even in the presence of smart bidders. They also show the advantage of using the white-box method for optimization, an interesting trade-off between modeling and optimization power, and that better predictors are not necessarily better optimizers. In this section, we investigate several practical issues of our approach. We start with the easier instances, which will be used to show how close the orderings found by the learned models are to the actual optimum. Afterwards, we test our method using two new settings: a randomized population of bidders and a larger set of items and item types. The randomized population mimics a feature of a type of real-world auctions: the agents bidding in an auction are not always the same as often seen in online auctions. The larger instances aim to demonstrate how well our approach can be expected to perform in large-scale auctions with many more items of greater diversity.</paragraph><section label="5.5.1"><section-title>Smaller auctions</section-title><paragraph>The smaller problem instances are generated with: 1) a maximum budget of 80, 2) a maximum number of 3 desired items, 3) 4 item types, 4) 15 items per auction, and 5) 8 agents. All other settings are the same as those used in the main experiments. In addition, we added a brute-force method that uses the simulator as a black-box and tests all possible ordering of the items. Although a brute-force method is infeasible for 40 items, in the case of 15 items, there are only a few million possible orderings to consider. The results of 10 sets of agents, each tested with 5 sets of items, are shown in Fig. 10. The corresponding plots for the main experiments are Fig. 5, Fig. 6.</paragraph><paragraph>The {a mathematical formula}R2 scores show a behavior similar to the main experiments, except that they range between 0.8 and 0.9. Outliers for the depth 3 trees can get as low as 0.5. This score decrease is likely caused by the decrease in data size (15 instead of 40 data rows per auction). The left plot if Fig. 10 shows the results obtained using the simulator. Any difference in performance between the different methods is insignificant except for depth 3 trees, which are significantly worse at estimating the obtained revenues and therefore result in lesser quality solutions. The improvement in performance of the other methods over random is approximately 10 on average, whilst about 20 could be obtained with perfect models in theory. Frequently, the black-box and white-box methods find an optimal solution for the learned models, so this difference is entirely due to the prediction quality of the models. It is good to see that the performance of the mean5000 method is almost indistinguishable from optimal (the last boxplot in the figure), giving confidence that this is a good approximation of the upper bound. As can be seen in the right plot, the difference between the white-box and black-box methods are negligible for these small instances.</paragraph></section><section label="5.5.2"><section-title>Randomized population</section-title><paragraph>In this set of experiments, we obtain different sets of agents by creating a large population of size 60, and drawing 20 of them at random for every auction. In addition, we generate a random set of 20 to 60 items for every auction, sampled uniformly at random. Other than that, we use the exact same settings as the main experiments. We show the results of 19 sets of agents (we increased the set to reduce noise in the results), each being tested with 5 sets of items, see Fig. 12. The {a mathematical formula}R2-scores obtained in these experiments are shown in Fig. 11.</paragraph><paragraph>From Fig. 11, we make two observations. Firstly, the performance of the predictors is much worse than in the main experiments, with median values around 0.7. As one may expect, the revenue is very hard to predict in this randomized setting, because it is heavily dependent on which agents take part in the auction. Learning larger trees does not increase this score. In fact, as the wins table shows, the depth 8 trees are clearly the worst predictor. Secondly, in contrast to the main experiments, linear regression appears to be a better estimator than a regression tree, although the difference is very small.</paragraph><paragraph>The simulator and model results in Fig. 10 confirm that the regression functions perform much worse in this randomized population setting. The linear regression models still perform better than random. The difference with the expected value of a random solution is so small that in cases with very uncertain populations it will probably not be worthwhile to model and optimize the problem. The model results show that also in these cases, white-box methods outperform black-box ones, with the only exception for depth 8 regression trees where the performance of white-box and black-box is similar.</paragraph></section><section label="5.5.3"><section-title>Larger problem instances</section-title><paragraph>The larger problem instances are generated with the same settings as those used in the main experiments, expect for: 1) 12 item types, 2) 80 items per auction, and 3) 40 agents. In addition, because the optimization problems are harder, we used a timeout of 30 minutes instead of 15. The results of 10 sets of agents, each tested with 5 sets of items, are shown in Fig. 13, Fig. 14.</paragraph><paragraph>Notice that the performance for depth 8 trees is missing in Fig. 13. The reason for this is that the CPLEX runs for these trees ran out of memory. The encoding requires {a mathematical formula}n×|R|×(2k+1) variables, and {a mathematical formula}n×|R|×(2(k+1)−1)+n+|R| constraints. If we fill in depth 8, 12 types, and 80 items, we end up with 46 720 variables and 490 652 constraints. This proved too much for our version of CPLEX (v12.5.1). Although the smaller trees did run, the depth 5 trees are now outperformed by the black-box approach. For depth 3 trees, it is still better to use white-box. A similar phenomenon is visible in Lasso results. In all previous results, white-box always outperforms black-box for the Lasso regressors. Suddenly, this is only the case for the smallest linear models, in those with more coefficients black-box performs better. These results match our intuition that using a white-box approach is beneficial when the models are not overly complex.</paragraph><paragraph>In the simulator results, we see that smaller models perform worse than larger ones, in spite of them being much harder to optimize. We believe this is due to them being worse predictors, as can be seen in the wins table in Fig. 14. Interestingly, for the larger linear models, the performance difference between black-box and white-box is no longer there. For the depth 5 tree, the difference is inverted, which we believe to be due to chance. However, it is also possible that this effect is caused by over estimation. For the black-box method, the average over estimation of solutions is 237, while it is 111 for the white-box method. This can be caused by the fact that CPLEX has problems finding solutions for these large instances, making it also harder to find very specific solutions that over estimate the solution value. Investigating this behavior further is left as future work.</paragraph><paragraph>Fig. 14 also shows an increase in {a mathematical formula}R2 scores: all median values are above the 0.92 mark. This is most likely cause by an increase in training data (twice as many items are sold per auction). The tree models are much better regressors for the large instances, although their optimization performance in the simulator is much worse. In fact, their performance is close to that of a random ordering. The larger linear models perform better than random, but are still far from optimal.</paragraph></section></section></section><section label="6"><section-title>Related work and discussion</section-title><paragraph>We discuss related works and how our work contributes to and from several related research communities.</paragraph><section label="6.1"><section-title>Interplay between mathematical optimization and machine learning</section-title><paragraph>Many studies have investigated the interplay of data mining and machine learning with mathematical modeling techniques, see overview in e.g. [25], [26], [27]. Most of these investigate how to use data mining to estimate the value of parameters in decision making models or to replace decision model structure when it cannot be fully determined from the hypotheses at hand. For instance, Brijs et al. [28] build a decision model as an integer program that maximizes product assortment of a retail store. The decision model is then refined by incorporating additional decision attributes that are the learned patterns from recorded sales data. Li and Olafsson [3] use a decision tree to learn dispatching rules that are then used to decide which job should be dispatched first. These dispatching rules are previously unknown, and it is assumed that it is worthwhile to capture the current practices from previous data. Gabel and Riedmiller [1] model production scheduling problem as multi-agent reinforcement learning where each agent makes its dispatching decisions using a reinforcement learning algorithm based on a neural network function approximation.</paragraph><paragraph>Another line of work investigates how to use learning techniques during optimization in order to learn properties of good solutions. For instance, Defourny et al. [29] combine the estimation of statistical models for returning a decision rule given a state with scenario tree techniques from multi-stage stochastic programming. This line of work shares similarities with the field of black-box optimization, see, e.g., [14], [15], [30]. In black-box optimization, methods are used to approximate a function with unknown analytical form and which typically is expensive to execute. In contrast, in multi-stage stochastic programming this form is known but stochastic. An often applied technique for black-box optimization is the use of surrogate methods, see, e.g., [31]. Surrogates are approximations of the black-box function that are less expensive to execute. Typical examples include linear/polynomial regression, neural networks, and other methods from machine learning. These functions are trained during optimization from (as few as possible) black-box function calls.</paragraph><paragraph>As learning tasks can lead to challenging optimization problems, researchers have also applied mathematical optimization methods in order to increase learning efficiency. For instance, Bennett et al. [32] use linear programming for determining linear combination splits within two-class decision trees. Chang et al. [33] propose a Constrained Conditional Model (CCM) framework to incorporate domain knowledge into a conditional model for structured learning, in the form of declarative constraints. CCMs solve prediction problems. In [34], the authors build a mixed integer program for multi-class data classification. A comprehensive overview of optimization techniques used in learning is given in [35]. Researchers are also interested in using mathematical optimization methods in order to find entire models and rules, see e.g., [36], [37], [38].</paragraph><paragraph>Our approach fits in the first line of research of this interplay. The proposed best-first search method uses regression models to learn good orderings, which is then applied during search to evaluate the solutions of OOSA. Hence, similar to the works mentioned above, the models learned from data are used in a black-box fashion. This approach shares similarities with surrogate methods for black-box optimization. An important difference is that the (surrogate) models here are learned from data. Furthermore, our proposed white-box optimization method makes all the properties of the learned models visible to the optimization solver. Bartolini et al. [4] propose a similar method by translating neural networks into constraint programming (CP) models. Their approach is simple yet effective and allows to model complex relations (such as recurrent neural networks) between any pair of decision variables based on data. This is very powerful as it allows for multiple trained neural networks to be plugged into an existing CP model that is constructed by traditional means. It is up to the system designer which relations between variables to model traditionally and which to model based on data. In contrast, we use our translation to construct (parts of) the objective function of an existing MIP model using regression functions. To the best of our knowledge, we are the first to combine regression functions that are learned from data with a MIP model in this way.</paragraph><paragraph>Other closely related work from the CP literature considers the problem of constraint acquisition [39], [40], [41], [42]. Given a large set of possible constraints L and some training data, the goal of constraint acquisition is to compose a constraint network (a graphical representation of a CP model, see, e.g., [43]) using the constraints in L such that it classifies all of the training data correctly, i.e., it should specify a language that includes all positive and excludes all negative training examples. Although this is a hard problem, several effective approaches have been proposed based on supervised [39], unsupervised [41], and active [40], [42] learning. These approaches are based on their own new learning algorithms, some with proven performance bounds (e.g., [42]). Once learned, the constraints are embedded into an existing CP model and fully integrated into the optimization process. From a modeling perspective, this method has both benefits and downside. On one hand, constraint acquisition allows the modeler to define his or her own dedicated constraint set L instead of only the features/variables, potentially resulting in more sensible models for the problem at hand. On the other hand, the learning problem itself is arguably less understood than those tackled by existing algorithms from machine learning, potentially resulting less quality classifiers.</paragraph><paragraph>In addition, in probabilistic inference, an interesting combination of machine learning and optimization has also been proposed. First, a probabilistic model is learned in the traditional way. Then, when computing the posterior distribution over some target variables given new input data, additional constraints are added in order to limit the possible assignments to the targets. While the original probabilistic inference problem can often be solved using dynamic programming methods, the additional constraints make it much harder to solve, and it is therefore translated into a MIP. This approach has successfully been applied in order to add expert knowledge to conditional random fields for semantic role labeling by Roth and Yih in [44]. Later, the same principle was used to model the dependencies among textual tokens in text-based documents for entity recognition by Fersini et al. [45]. Interestingly, in this last work, the added constraints themselves were also learned from data and added as soft constraints to the MIP model.</paragraph></section><section label="6.2"><section-title>Sequence models</section-title><paragraph>As an auction ordering is essentially a sequence of items, our work is also related to the many machine learning approaches for sequence modeling. To the best of our knowledge none of the existing sequence models fits our auction setting. Language models such as deterministic automata [46] are too powerful since they can model every possible sequence independently and therefore require too much data to learn accurately. Short sequence models such as hidden Markov models or N-grams [47] do not model the dependence on items sold a long time (more than the sliding window length) before.</paragraph><paragraph>Markov decision processes (MDPs) (see, e.g., [48]) may be closest to our auction setting, as they can directly model the expected price per item and come with methods that can be used to optimize the expected total reward (revenue). However, we notice that a straightforward implementation of the auction design problem as an MDP is not possible. Let us try to model auction design as an MDP. Because of the Markov assumption, every state in this MDP has to contain all the relevant information for the auctioneer's decision on which item to auction: the set of available items, the bidders' valuation functions, budgets and strategies, and for every bidder the items (s)he already possesses. In every state q of this process, the auctioneer can choose what item i to put to auction from a multiset of available items I. The next state {a mathematical formula}q′ resulting from auctioning item i depends on the bidders and their valuations. These are unknown to the auctioneer, but probabilities can be used to estimate them. These probabilities {a mathematical formula}Pi(q,q′) provide a distribution over the possible next states and the corresponding rewards {a mathematical formula}Ri(q,q′), given i is auctioned. In every possible next state {a mathematical formula}q′, the set of available items is equal to {a mathematical formula}I−{i}, i.e., equal to the items in q minus the sold item i. The goal of the auctioneer is to maximize the expected rewards (revenue) for a given set of items I. In every state q, (s)he thus has to take an action (choosing an item) that maximizes the sum of the expected rewards {a mathematical formula}V(q,I) of items in I starting in state q:{a mathematical formula}</paragraph><paragraph>In this equation, we separated I from q to highlight the major hurdle that needs to be overcome in order to represent the auction design problem as an MDP. I needs to be included in the MDP since it determines the set of available actions in every state. However, since the set of items is finite this makes the MDP acyclic and at least as large as the number of possible subsets of items from I (assuming the effect of their ordering is represented differently), i.e., at least {a mathematical formula}2|I|. In order to learn the rewards and transition probabilities, an auctioneer would therefore need an extremely large data sample.</paragraph><paragraph>This intuitively shows why it is difficult to represent the auction design problem as an MDP. However, with a suitable factored representation of the states and/or function approximation [48] of the rewards, it could be possible to represent our auction problem as an MDP. In this case, a major hurdle will be to find a representation that results in Markovian states, which is needed to apply the dynamic programming methods. Since the problem of deciding whether good auction ordering exists is NP-complete (Theorem 1), and these methods run in polynomial time, this is impossible without an exponentially large state space unless {a mathematical formula}P=NP. Our method relies on solvers and search methods for NP-complete problems, making a polynomial state space possible, and therefore requiring much less data to estimate the model parameters.</paragraph></section><section label="6.3"><section-title>Auction design</section-title><paragraph>In the auction literature, a few existing papers investigate the impact of ordering on the performance of sequential auctions. One line of related research focuses on theoretical analysis. In the economics literature (see [9], [12], [11]), such theoretical studies were typically carried out under very restricted markets. The main research focus there is to analyze equilibrium bidding strategies of bidders who compete for (usually) two items (heterogeneous or homogeneous), and then to gain insights on the impact of ordering on the auction outcome based on derived bidding behaviors. For instance, Elmaghraby [9] studies the influence of ordering on the efficiency of the sequential second price procurement auctions, where a buyer outsources two heterogeneous jobs to suppliers with capacity constraints. Suppliers can only win 1 job in this setting. The author shows that specific sequences lower procurement costs and identifies a class of bidders' cost functions where the efficient orderings (i.e. the auction rewards the jobs to the suppliers with the lowest total costs) and equilibrium bidding strategies exist. Pitchik [12] points out that in the presence of budget constraints, a sealed-bid sequential auction with two bidders and two goods may have multiple symmetric equilibrium bidding functions, and the ordering of sale affects the expected revenue. If the bidder who wins the first good has a higher income than the other one, the expected revenue is maximized. Subramaniam and Venkatesh [11] investigate the optimal auctioning strategy of a revenue-maximizing seller, who auctions two items, which could be complements or substitutes. They show that when the items are different in value, the higher valued item (among the two) should be auctioned first in order to increase the seller's revenue. A similar revenue-maximizing strategy is proposed by Benoit and Krishna [49] in a complete information auction setting. The authors conclude that in such a setting, when selling two items to budget constrained bidders, it is always better to sell the more valued item first. However, this strategy does not optimize the revenue anymore when more than two items are to be auctioned.</paragraph><paragraph>Empirical research has been conducted to test the theoretical findings in the economics community. Grether et al. [10] report on a field experiment that tests the ordering strategies of a seller in sequential, ascending automobile auctions. They conclude that the worst performing ordering in terms of revenue is for the seller to auction vehicles from highest to lowest values.</paragraph><paragraph>In the computer science literature, Elkind and Fatima [13] study how to maximize revenue in sequential auctions with second-price sealed-bid rules, where bidders are homogeneous, i.e., all their valuations are drawn from public known uniform distributions, and they want to win only one item (but they can bid any of items). In this setting, the authors analyze the equilibrium bids, and develop an algorithm that finds an optimal agenda (i.e., ordering). Vetsikas et al. [50] study a similar auction setting, but unlike [13], they assume the valuations are known to the bidders at the beginning of the auction. The focus of their work was to compute the equilibrium strategies for bidders. Later, Vetsikas [23] analyzes the bidding strategies for budget constrained bidders in sequential Vickrey auctions. However, it is a challenge to compute the equilibrium strategies in practice.</paragraph><paragraph>We are not the first who consider learning from the previous auctions. However, the difference lies in the fact that the most existing work study how bidders learn from the past information, and update their bids. Boutilier et al. [51] propose a learning model for bidders to update their bidding policies in sequential auctions for resources with complementarities. The bidding strategies are computed based on the estimated distribution over prices, that is modeled by dynamic programming. Goes et al. [52] present an empirical study of real sequential online auctions. They analyze the data from an online auction retailer, and show that bidders learn and update their willingness to pay in repeated auctions of the same item. In [7], the authors show the benefits of using earlier auction data for the management of sequential, multi-unit auctions, where the seller needs to split its entire inventory into sequential auctions of smaller lots in order to increase its profit. In their work, an auction feedback mechanism is developed based on a Bayesian model, and it is used to update the auctioneer's beliefs about the bidders' valuation distribution.</paragraph><paragraph>Our contribution to the auction literature lies on the fact that our approach can be applied to design optimal auctions based on historical auction data. The advantage of using machine learning and data mining methods is that they are robust to the uncertainty (or noise), and hence have high potential to be used for real-world auction design. Moreover, the approach itself is general and can be applied to many different auction optimization problems, such as finding best reserve price for items for sale, or maximizing social welfare instead of revenue. The necessary changes may include the selection of the features for learning regression models and the encoding in the white-box optimization model.</paragraph></section></section><section label="7"><section-title>Conclusions</section-title><paragraph>Mathematical optimization relies on the availability of knowledge that can be used to construct a mathematical model for the problem at hand. This knowledge is not always available. For instance, in multiagent problems, agents are autonomous and often unwilling to share their local information. Frequently, this autonomy and private information influence the outcome of the optimization, making finding an optimal solution very difficult. In this paper, we adopt the idea of using machine learning techniques to estimate these influences for an optimization problem with many unknowns: the optimal ordering for sequential auctions (OOSA) problem.</paragraph><paragraph>We have demonstrated our approach by transforming historical auctions into data sets for learning regression trees and linear regression models, which subsequently are used to predict the expected value of orderings for new auctions. We proposed two types of optimization methods with learned models, a black-box best-first search approach, and a novel white-box approach that maps learned models to integer linear programs (ILP). We built an auction simulator with a set of bidder agents to simulate an auction environment. The simulator was used for generating historical auction data, and for evaluating the orderings of items returned by our methods. We ran an extensive set of experiments with different agents and bidding strategies. Although optimizing the orderings in sequential auctions is a hard problem, our proposed methods obtained very high values, significantly outperforming the naive methods proposed in the literature. The experimental results also demonstrate the advantage of using the white-box method for optimization, which significantly outperforms the black-box approach in nearly all settings. In addition, they indicate that when the learned model becomes more complex, it potentially results in more constraints and consequently, an increase in the time needed to solve the problem in a white-box fashion. Since more complex models are (potentially) better predictors, this shows a clear trade-off between modeling and optimization power in white-box optimization. In our opinion, the benefits of the white-box approach largely outweigh the benefits of using black-box optimization.</paragraph><paragraph>Finally, the extended experiments demonstrate that although our encodings are efficient, the regression tree breaks down when the data becomes too noisy. An intriguing extension would therefore be to use regression forests instead of individual trees. These are known to handle noisy data much better because of the crisp boundaries in individual trees. The same experiments also show that our method does not yet scale very well with the number of items, most likely due to the increase in the number of trees that need to be evaluated. We expect that a method based on regression forests will therefore require several simplifications or optimizations in order to be feasible.</paragraph><paragraph>Besides an improved performance, a very big benefit of the white-box formulation is that it provides a new way of obtaining traditional mathematical models. Our method therefore has many other potential application areas, especially in problems where more and more data is being collected. Even in cases where there already exists a handcrafted optimization model, a model that is learned and translated using our method can easily be integrated into existing (I)LP formulations in order to determine part of the objective function based on data. In this way, one can combine the vast amount of expert knowledge available in these domains with the knowledge in the readily available data. We would like to investigate this combination in the future.</paragraph><paragraph>We chose a relatively simple auction model for ease of explanation in this paper. However, our approach works whenever regression models are able to provide reliable predictions of the bidding values. Hence we believe it can be applied to other auction formats with more complex valuation functions (i.e. combinatorial preferences [53]) and more complex bidding strategies. The results of our method on the larger experiments with 80 items shows that scaling the approach up to large real-world auctions will require several non-trivial simplifications. Moreover, in this paper, we learned regression trees and linear models from simulated data in order to test the optimization performance. When applying our approach to real-world data, it is important to test whether the regressors assumptions are satisfied. If not, it may be needed to transform or filter them. We plan to discover the simplifications and test our approach with real auction data in the near future.</paragraph><paragraph>Our experiments highlight some interesting properties of the white-box method. Firstly, they show an improvement in performance when the number of features is reduced and/or the models are less complex. It would therefore be very interesting to investigate the effect of pruning and feature selection or reduction on the performance of our methods. Secondly, they show a tendency of the regression tree optimizer to overestimate, i.e., find orderings that have a much higher expected revenue than their revenue in practice. Intuitively, the solver abuses the crisp nature of the regression tree in order to find a solution that satisfies exactly the right constraints. Part of the problem is that, although these constraints are learned from data, and therefore uncertain, the solver treats them as exact. Fortunately, there exists a long history of methods that try to optimize in the presence of such uncertainties in the area of robust optimization, see, e.g., [54]. As future work, we will investigate the potential uses of these techniques for learned models.</paragraph><paragraph>Recently, regression tree models with linear models in the leaf nodes have also been successfully used as black-box surrogate functions [55]. Since it is also straightforward to translate these trees given our two encodings (replace the leaf variables by indicators for which linear function to use), it would be very interesting to investigate the possibility of a white-box alternative.</paragraph><section-title>Acknowledgement</section-title></section></content><acknowledgements><paragraph>Sicco Verwer is supported by Technologiestichting STW VENI project 13136 (MANTA). We thank the reviewers for their valuable suggestions and comments, which have significantly improved the quality of the paper.</paragraph></acknowledgements><appendices><section label="Appendix A"><section-title>Hardness of auction design using learned predictors</section-title><paragraph>We show that using predictive models instead of agents with utility functions does not reduce the complexity of the problem: it remains NP-complete for both regression trees and linear regression predictors.</paragraph><paragraph label="Lemma 1">Using regression trees, the problem of whether there exists an ordering that has a total predicted value of at least K is NP-complete.</paragraph><paragraph label="Proof">The proof follows from the fact that we can use simple regression trees to model the preferences of the two agents from Theorem 1, and evaluating an ordering using these trees can be done in polynomial time. The regression tree for every item type {a mathematical formula}ri is shown in Fig. 15. □</paragraph><paragraph label="Lemma 2">Using linear regression predictors, the problem of whether there exists an ordering that has a total predicted value of at least K is NP-complete.</paragraph><paragraph label="Proof">We prove the lemma using a construction for computing the value of a quadratic function using only linear functions, the ordering problem, and our feature values. The maximum value of this quadratic function is then forced to coincide with the solution of a partition problem instance: Given a set of integers {a mathematical formula}I={v1,…,vn}, is I dividable into two sets A and B such that {a mathematical formula}∑A=∑B?From the partition instance, let {a mathematical formula}k=12∑1≤i≤nvi, we construct the following items and linear regression predictors (functions {a mathematical formula}v()):<list>n items of type {a mathematical formula}x1…xn, with {a mathematical formula}v(xi)=vi−vi⋅sum(y)2k, and1 item of type y, with {a mathematical formula}v(y)=2k−∑1≤i≤nsum(xi).(⇒) Let </list><paragraph>{a mathematical formula}A,B be a partition of I such that {a mathematical formula}∑A=∑B, and let {a mathematical formula}a1,…,a|A| and {a mathematical formula}b1,…,b|B| be the corresponding items of type {a mathematical formula}x1…xn. The following ordering then gives a value of {a mathematical formula}∑1≤i≤nvi:{a mathematical formula} In this ordering, {a mathematical formula}∑1≤i≤|A|v(ai)=k by definition of A and since {a mathematical formula}sum(y)=0 before item y is auctioned. Consequently, {a mathematical formula}∑1≤i≤nsum(xi)=∑1≤i≤|A|v(ai)=k, giving {a mathematical formula}v(y)=2k−k=k. {a mathematical formula}∑1≤i≤|A|v(a1)+v(y) thus already obtains the objective value of 2k, and therefore {a mathematical formula}∑1≤i≤|B|v(b1) should be equal to {a mathematical formula}12k. By definition of B, {a mathematical formula}∑1≤i≤|B|v(bi)=k−k⋅sum(y)2k. Since {a mathematical formula}v(y)=k, {a mathematical formula}sum(y)=k, and thus {a mathematical formula}∑1≤i≤|B|v(bi)=k−k⋅k2k=k−k2=12k, proving that the ordering obtains a value of {a mathematical formula}212k.(⇐) To prove the other direction, let us further analyze the relation between the objective function {a mathematical formula}∑1≤i≤nv(xi)+v(y) and the auction ordering. The only term in the {a mathematical formula}v(xi) predictors that depends on the ordering is {a mathematical formula}sum(y), all other terms are constants. This term is equal to zero for the {a mathematical formula}xi items auctioned before y, and equal to {a mathematical formula}v(y) for the items auctioned after y. Similar to the (⇒) part, let {a mathematical formula}a1,…,a|A| denote the {a mathematical formula}xi items before y, {a mathematical formula}b1,…,b|B| those after y, and {a mathematical formula}A,B the corresponding partition of items in I. The objective value is then given by {a mathematical formula}∑1≤i≤|A|v(ai)+v(y)+∑1≤i≤|B|v(bi). We analyze these three parts in turn.</paragraph><list><list-item label="•">{a mathematical formula}∑1≤i≤|A|v(ai)=∑vi∈Avi since {a mathematical formula}sum(y)=0 for these items.</list-item><list-item label="•">{a mathematical formula}v(y)=2k−∑1≤i≤|A|v(ai)=2k−∑vi∈Avi=∑vi∈Bvi.</list-item><list-item label="•">{a mathematical formula}∑1≤i≤|B|v(bi)=∑vi∈Bvi−∑vi∈Bvi⋅v(y)2k, since {a mathematical formula}v(y)=∑vi∈Bvi, this becomes {a mathematical formula}∑vi∈Bvi−v(y)22k.</list-item></list><paragraph>Since {a mathematical formula}∑vi∈Avi+∑vi∈Bvi=2k, the overall objective function is given by:{a mathematical formula} which is maximized when {a mathematical formula}v(y)=k (for {a mathematical formula}k&gt;0) with value {a mathematical formula}2k+k−k22k=212k. This exact value of {a mathematical formula}v(y)=k is obtained when {a mathematical formula}∑vi∈Bvi=k. The sets A and B thus give a partition of I. □</paragraph></paragraph><paragraph label="Remarks">We proved the NP-completeness for the general case of Lemma 2. However, we do not know whether the complexity holds for more realistic valuation functions that bidders have.</paragraph></section></appendices><references><reference label="[1]"><authors>T. Gabel,M. Riedmiller</authors><title>Adaptive reactive job-shop scheduling with learning agents</title><host>Int. J. Inf. Technol. Intell. Comput.2 (4)(2008) pp.1-30</host></reference><reference label="[2]"><authors>A. Huyet</authors><title>Optimization and analysis aid via data-mining for simulated production systems</title><host>Eur. J. Oper. Res.173 (3)(2006) pp.827-838</host></reference><reference label="[3]"><authors>X. Li,S. Ólafsson</authors><title>Discovering dispatching rules using data mining</title><host>J. Sched.8 (6)(2005) pp.515-527</host></reference><reference label="[4]"><authors>A. Bartolini,M. Lombardi,M. Milano,L. Benini</authors><title>Neuron constraints to model complex real-world problems</title><host>J.H.-M. LeePrinciples and Practice of Constraint ProgrammingLecture Notes in Computer Sciencevol. 6876 (2011)Springer pp.115-129</host></reference><reference label="[5]"><authors>D. Bernhardt,D. Scoones</authors><title>A note on sequential auctions</title><host>Am. Econ. Rev.84 (3)(1994) pp.653-657</host></reference><reference label="[6]"><authors>E. van Heck,P.M.A. Ribbers</authors><title>Experiences with electronic auctions in the Dutch flower industry</title><host>EM7 (4)(1997) pp.29-34</host></reference><reference label="[7]"><authors>E.J. Pinker,A. Seidmann,Y. Vakrat</authors><title>Using bid data for the management of sequential, multi-unit, online auctions with uniformly distributed bidder valuations</title><host>Eur. J. Oper. Res.202 (2)(2010) pp.574-583</host></reference><reference label="[8]"><authors>J. Gallien,L.M. Wein</authors><title>A smart market for industrial procurement with capacity constraints</title><host>Manag. Sci.51 (2005) pp.76-91</host></reference><reference label="[9]"><authors>W. Elmaghraby</authors><title>The importance of ordering in sequential auctions</title><host>Manag. Sci.49 (2003) pp.673-682</host></reference><reference label="[10]"><authors>D.M. Grether,C.R. Plott</authors><title>Sequencing strategies in large, competitive, ascending price automobile auctions: an experimental examination</title><host>J. Econ. Behav. Organ.71 (2)(2009) pp.75-88</host></reference><reference label="[11]"><authors>R. Subramaniam,R. Venkatesh</authors><title>Optimal bundling strategies in multiobject auctions of complements or substitutes</title><host>Mark. Sci.28 (2009) pp.264-27310.1287/mksc.1080.0394</host></reference><reference label="[12]"><authors>C. Pitchik</authors><title>Budget-constrained sequential auctions with incomplete information</title><host>Games Econ. Behav.66 (2)(2009) pp.928-949</host></reference><reference label="[13]"><authors>E. Elkind,S. Fatima</authors><title>Maximizing revenue in sequential auctions</title><host>Proceedings of the 3rd International Conference on Internet and Network EconomicsWINE'07(2007)Springer-VerlagBerlin, Heidelberg pp.491-502</host></reference><reference label="[14]"><authors>D.R. Jones,M. Schonlau,W.J. Welch</authors><title>Efficient global optimization of expensive black-box functions</title><host>J. Glob. Optim.13 (4)(1998) pp.455-492</host></reference><reference label="[15]"><authors>S. Shan,G.G. Wang</authors><title>Survey of modeling and optimization strategies to solve high-dimensional design problems with computationally-expensive black-box functions</title><host>Struct. Multidiscip. Optim.41 (2)(2010) pp.219-241</host></reference><reference label="[16]"><authors>M.R. Garey,D.S. Johnson</authors><title>Computers and Intractability – A Guide to the Theory of NP-Completeness</title><host>(1979)W.H. Freeman and Company</host></reference><reference label="[17]"><authors>L. Breiman,J. Friedman,R. Olshen,C. Stone</authors><title>Classification and Regression Trees</title><host>(1984)Wadsworth and BrooksMonterey, CA</host></reference><reference label="[18]"><authors>R. Tibshirani</authors><title>Regression shrinkage and selection via the lasso</title><host>J. R. Stat. Soc. B58 (1994) pp.267-288</host></reference><reference label="[19]">scikit-learn: machine learning in Python<host>http://scikit-learn.org/</host></reference><reference label="[20]"><authors>T.G. Dietterich</authors><title>Machine learning for sequential data: a review</title><host>Structural, Syntactic, and Statistical Pattern Recognition(2002)Springer pp.15-30</host></reference><reference label="[21]"><authors>S. Verwer,Y. Zhang</authors><title>Revenue prediction in budget-constrained sequential auctions with complementarities</title><host>AAMAS'12(2012) pp.1399-1400</host></reference><reference label="[22]"><authors>W. Vickrey</authors><title>Counterspeculation, auctions, and competitive sealed tenders</title><host>J. Finance16 (1)(1961) pp.8-37</host></reference><reference label="[23]"><authors>I.A. Vetsikas</authors><title>Sequential auctions with budget-constrained bidders</title><host>IEEE 10th International Conference on e-Business Engineering(2013)IEEE pp.17-24</host></reference><reference label="[24]"><authors>IBM ILOG CPLEX Optimizer</authors><host>http://www-01.ibm.com/software/integration/optimization/cplex-optimizer/</host></reference><reference label="[25]"><authors>K.P. Bennett,E. Parrado-Hernández</authors><title>The interplay of optimization and machine learning research</title><host>J. Mach. Learn. Res.7 (2006) pp.1265-1281</host></reference><reference label="[26]"><authors>S. Meisel,D. Mattfeld</authors><title>Synergies of operations research and data mining</title><host>Eur. J. Oper. Res.206 (1)(2010) pp.1-10</host></reference><reference label="[27]"><authors>D. Corne,C. Dhaenens,L. Jourdan</authors><title>Synergies between operations research and data mining: the emerging use of multi-objective approaches</title><host>Eur. J. Oper. Res.221 (3)(2012) pp.469-479</host></reference><reference label="[28]"><authors>T. Brijs,G. Swinnen,K. Vanhoof,G. Wets</authors><title>Building an association rules framework to improve product assortment decisions</title><host>Data Min. Knowl. Discov.8 (1)(2004) pp.7-23</host></reference><reference label="[29]"><authors>B. Defourny,D. Ernst,L. Wehenkel</authors><title>Scenario trees and policy selection for multistage stochastic programming using machine learning</title><host>INFORMS J. Comput.25 (3)(2013) pp.488-501</host></reference><reference label="[30]"><authors>L.M. Rios,N.V. Sahinidis</authors><title>Derivative-free optimization: a review of algorithms and comparison of software implementations</title><host>J. Glob. Optim.56 (3)(2013) pp.1247-1293</host></reference><reference label="[31]"><authors>S. Koziel,D.E. Ciaurri,L. Leifsson</authors><title>Surrogate-based methods</title><host>Computational Optimization, Methods and Algorithms(2011)Springer pp.33-59</host></reference><reference label="[32]"><authors>K.P. Bennett,O.L. Mangasarian</authors><title>Bilinear separation of two sets in n-space</title><host>Comput. Optim. Appl.2 (1993) pp.207-227</host></reference><reference label="[33]"><authors>M. Chang,L. Ratinov,D. Roth</authors><title>Structured learning with constrained conditional models</title><host>Mach. Learn.88 (3)(2012) pp.399-431</host></reference><reference label="[34]"><authors>F. Uney,M. Turkay</authors><title>A mixed-integer programming approach to multi-class data classification problem</title><host>Eur. J. Oper. Res.173 (3)(2006) pp.910-920</host></reference><reference label="[35]"><authors>S. Sra,S. Nowozin,S.J. Wright</authors><title>Optimization for Machine Learning</title><host>(2012)MIT Press</host></reference><reference label="[36]"><authors>E. Carrizosa,D. Romero Morales</authors><title>Supervised classification and mathematical optimization</title><host>Comput. Oper. Res.40 (1)(2013) pp.150-165</host></reference><reference label="[37]"><authors>L.D. Raedt,T. Guns,S. Nijssen</authors><title>Constraint programming for data mining and machine learning</title><host>AAAI(2010) pp.1671-1675</host></reference><reference label="[38]"><authors>M.J. Heule,S. Verwer</authors><title>Exact DFA identification using SAT solvers</title><host>Grammatical Inference: Theoretical Results and ApplicationsLecture Notes in Computer Sciencevol. 6339 (2010)SpringerBerlin, Heidelberg pp.66-79</host></reference><reference label="[39]"><authors>C. Bessiere,R. Coletta,F. Koriche,B. O'Sullivan</authors><title>A sat-based version space algorithm for acquiring constraint satisfaction problems</title><host>Machine Learning: ECML 2005(2005)Springer pp.23-34</host></reference><reference label="[40]"><authors>C. Bessière,R. Coletta,B. O'Sullivan,M. Paulin</authors><title>Query-driven constraint acquisition</title><host>IJCAI 2007M.M. VelosoProceedings of the 20th International Joint Conference on Artificial Intelligence (2007) pp.50-55</host></reference><reference label="[41]"><authors>N. Beldiceanu,H. Simonis</authors><title>A model seeker: extracting global constraint models from positive examples</title><host>M. MilanoPrinciples and Practice of Constraint ProgrammingLecture Notes in Computer Sciencevol. 7514 (2012)Springer pp.141-157</host></reference><reference label="[42]"><authors>C. Bessiere,R. Coletta,E. Hebrard,G. Katsirelos,N. Lazaar,N. Narodytska,C.-G. Quimper,T. Walsh</authors><title>Constraint acquisition via partial queries</title><host>International Joint Conference on Artificial Intelligence(2013)</host></reference><reference label="[43]"><authors>R. Dechter</authors><title>Constraint Processing</title><host>(2003)Morgan Kaufmann</host></reference><reference label="[44]"><authors>D. Roth,W.-T. Yih</authors><title>Integer linear programming inference for conditional random fields</title><host>Proceedings of the 22nd International Conference on Machine LearningICML '05(2005)ACMNew York, NY, USA pp.736-74310.1145/1102351.1102444</host></reference><reference label="[45]"><authors>E. Fersini,E. Messina,G. Felici,D. Roth</authors><title>Soft-constrained inference for named entity recognition</title><host>Inf. Process. Manag.50 (5)(2014) pp.807-81910.1016/j.ipm.2014.04.005</host></reference><reference label="[46]"><authors>C. de la Higuera</authors><title>Grammatical Inference: Learning Automata and Grammars</title><host>(2010)Cambridge University PressNew York, NY, USA</host></reference><reference label="[47]"><authors>C.M. Bishop</authors><title>Pattern Recognition and Machine Learning</title><host>Information Science and Statistics (2006)Springer-Verlag New York, Inc.Secaucus, NJ, USA</host></reference><reference label="[48]"><authors>M.L. Puterman</authors><title>Markov Decision Processes: Discrete Stochastic Dynamic Programming</title><host>vol. 414 (2009)John Wiley &amp; Sons</host></reference><reference label="[49]"><authors>J.-P. Benoit,V. Krishna</authors><title>Multiple-object auctions with budget constrained bidders</title><host>Rev. Econ. Stud.68 (1)(2001) pp.155-179</host></reference><reference label="[50]"><authors>I.A. Vetsikas,N.R. Jennings</authors><title>Sequential Auctions with Partially Substitutable Goods</title><host>Lecture Notes in Business Information Processingvol. 59 (2009) pp.242-258</host></reference><reference label="[51]"><authors>C. Boutilier,M. Goldszmidt,B. Sabata</authors><title>Sequential auctions for the allocation of resources with complementaritie</title><host>Proceedings of the 16th International Joint Conference on Artifical Intelligencevol. 1 (1999)Morgan Kaufmann Publishers Inc.San Francisco, CA, USA pp.527-534</host></reference><reference label="[52]"><authors>P.B. Goes,G.G. Karuga,A.K. Tripathi</authors><title>Understanding willingness-to-pay formation of repeat bidders in sequential online auctions</title><host>Inf. Syst. Res.21 (2010) pp.907-924</host></reference><reference label="[53]"><authors>P. Cramton,Y. Shoham,R. Steinberg</authors><title>Combinatorial Auctions</title><host>(2006)MIT Press</host></reference><reference label="[54]"><authors>A. Ben-Tal,L. El Ghaoui,A. Nemirovski</authors><title>Robust Optimization</title><host>Princeton Series in Applied Mathematics (2009)Princeton University Press</host></reference><reference label="[55]"><authors>D. Verbeeck,F. Maes,K. De Grave,H. Blockeel</authors><title>Multi-objective optimization with surrogate trees</title><host>Proceeding of the Fifteenth Annual Conference on Genetic and Evolutionary Computation Conference(2013)ACM pp.679-686</host></reference></references><footnote><note-para label="1">The English auction that we consider is the one where the starting price is the reserve price, and bidders bid openly against each other. Each subsequent bid should be higher than the previous bid, and the item is sold to the highest bidder at a price equal to her bid.</note-para><note-para label="2">This is the version implemented in the scikitlearn Python package [19], which we use to learn the models.</note-para><note-para label="3">The learned linear regression model is more straightforward. Hence we skip such an example here.</note-para><note-para label="4">Including any transformations applied to them.</note-para><note-para label="5">We ignore the possibility that a feature f is equal to c because, since features have a limited precision, we can always replace the constants in a decision node with one that cannot be obtained by f, without changing its behavior.</note-para><note-para label="6">Counterintuitively, it can occur that the objective function (discussed below) is maximized when every z variable is false at an index i. If a small sum is needed to reach a high revenue prediction, it can be beneficial to auction but not sell an item.</note-para><note-para label="7">Many other solvers have similar constructions. If not, these constraints can be implemented using a ‘big-M’ formulation, similar to the one we use to determine the value of the z variables in the regression tree formulation.</note-para><note-para label="8">Note that in sequential Vickrey auctions with budget constrained agents, truth-telling is not an equilibrium bidding strategy (see [23]).</note-para><note-para label="9">Vickrey [22] showed that in a sequential auction with unlimited budget, it is a weakly dominant strategy for bidders to bid their true values for the last auctioned item.</note-para><note-para label="10">We simply ordered the items according to their base values. We also tested ordering them based on their mean value in the data, but this performed worse in the test.</note-para><note-para label="11">Notice that there is one instance where mean5000 is better than best5000. This is due to the random scheme that we used in selecting winners who give two identical bids. Consequently, evaluating the same ordering twice in the simulator may result in two different revenues. We want to point out that this does not happen often and the effect is often negligible.</note-para><note-para label="12">Another possible cause is that the LP solver makes small rounding errors. Such errors are unavoidable because using both very small and very large coefficients and/or precision in one problem formulation can cause numerical instability. We therefore round the mean values of the leaf predictions to two digits after the decimal point in the regression tree models before translating it to LP. Unfortunately, due to the crisp decision boundaries in regression trees, these small errors can sometimes have a large effect.</note-para></footnote></root>