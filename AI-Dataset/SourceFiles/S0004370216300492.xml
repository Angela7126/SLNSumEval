<?xml version="1.0" encoding="UTF-8"?><root><url>https://www.sciencedirect.com/science/article/pii//S0004370216300492</url><title>Hierarchical conceptual spaces for concept combination</title><authors>Martha Lewis,Jonathan Lawry</authors><abstract>We introduce a hierarchical framework for conjunctive concept combination based on conceptual spaces and random set theory. The model has the flexibility to account for composition of concepts at various levels of complexity. We show that the conjunctive model includes linear combination as a special case, and that the more general model can account for non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence. We investigate two further aspects of human concept use, the conjunction fallacy and the ‘guppy effect’.</abstract><keywords>Conceptual spaces;Concept composition;Random sets</keywords><content><section label="1"><section-title>Introduction</section-title><paragraph>Humans undoubtedly have the ability to form new concepts by combining existing ones. The development of effective representational models of this phenomenon could potentially shed light on human cognition. Human-like reasoning has been argued to be important to artificial intelligence for its flexibility and robustness [6], [29], [44]. Further, a good representation of human concept use will aid us in considering problems of categorization and typicality, as argued by Freund [18]. Applications of AI that must interact with humans via natural language arguably need to be able to understand and to form for themselves novel combinations of concepts. Examples of theories proposed to account for such concept combination include prototype theory together with fuzzy set theory [51], conceptual spaces [19], and quantum probability [3], [9] approaches. Well-known counterexamples have been identified which suggest that fuzzy sets may not provide an appropriate formalisation in this context [25], [27], [40]. It is argued in [25] that the failure of fuzzy set theory to adequately model human concept combination results from its failure to consider the intension of concepts, i.e., the attributes that the concept possesses. In contrast, the conceptual spaces and the quantum approaches take intension into account, either by considering concepts as being comprised of a combination of properties,{sup:1} which are themselves embedded in a space of quality dimensions, or by incorporating context into the model. Our proposed approach utilises a random set interpretation of membership so as to quantify an agent's subjective uncertainty about the extent of application of a concept. We refer to this uncertainty as semantic uncertainty[33] in order to emphasise that it concerns the definition of concepts and categories. Lawry and Tang [33] combine random set theory with conceptual spaces [19] and prototype theory [43], to give a formalisation of concepts as based on a prototype and an uncertain distance threshold, located in a conceptual space. We use this account of concepts to provide a framework for conjunctive concept combination which captures the effects seen in [25], including non-compositional behaviours such as overextension, non-commutativity, preservation of necessity and impossibility of attributes and to some extent, attribute loss or emergence.</paragraph><paragraph>An outline of the paper is as follows. Section 2 overviews a range of theoretical approaches to concept combination from the literature, and summarises the results from experimental studies that we aim to model. Section 3 describes a random set and prototype theory representational model for concepts within a conceptual space. This model provides the theoretical underpinning for our work. Section 4 introduces a framework for concept combination based on a hierarchy of conceptual spaces, and in which compound concepts are defined within Boolean spaces. We prove a number of results showing the properties of this framework and compare this approach to others in the literature. Section 5 provides a discussion of our results and indicates possible future directions.</paragraph></section><section label="2"><section-title>Background</section-title><paragraph>In this section, we describe a number of approaches to concept combination that have been proposed. We consider general set-theoretic approaches, supervaluation theory, prototype theory, fuzzy set theory, conceptual spaces theory, approaches from computational linguistics and quantum cognition approaches. We further describe some results from experimental studies with which we compare the theory we develop.</paragraph><section label="2.1"><section-title>Set-theoretic approaches</section-title><paragraph>Montague semantics [39] takes a model-theoretic approach to concepts and sentences. Concepts are defined using notions from set theory, and natural language expressions are modelled as functions or relations on these sets. This gives a description of how the semantics of a language interacts with the syntax, so that the meaning of a compound expression may be systematically derived from its parts. However, as discussed in [27], [28], this is inadequate for modelling some types of adjectives. In [39], an adjective is viewed as a function from properties to properties. This allows sentences such as ‘every small elephant is small’ not to be branded as logically true, which is what we require. This enables various types of adjective to be modelled. Intersective adjectives are those where the application of that adjective may simply be viewed as an intersection of sets (such as ‘red car’). Adjectives that are not intersective may be subsective, when the adjective-noun combination is a subset of the noun, or non-subsective, for example privative adjectives like ‘fake’, or ‘former’. However, the theory of adjectives as a function of properties is inadequate, in particular because it doesn't account for comparatives, i.e. the ability to say that x is A-er than y. To account for this, Kamp introduces a theory of vague models, which are viewed as a nested sequence of partial models. In a partial model, a predicate is explained as assigning a value 1 to those objects which fall under the predicate, 0 to those that do not fall under the predicate, and no value to those for whom the predicate is indeterminate. These partial models may be completed in various ways, and the degree of truth of a sentence is related to the probability of a particular set of completions of a partial model of the sentence conditioned on all sets of completions of the model. This set of completed models forms the basis for Kamp's supervaluation, where a sentence has truth value 1 if it is true in all completions of the model, 0 if it is false in all completions of the model, and indeterminate if it is true in some and false in others.</paragraph><paragraph>Kamp's approach is similar to Fine's [17], in which the questions of the correct logic for vagueness and the correct truth conditions for a vague language are considered. Fine calls the possibility that logical relations hold between indefinite sentences penumbral connection, and truths that arise from such a connection penumbral truths, and argues that no natural truth-value approach respects such truths. He argues that differences in truth-value within penumbral truths concerning two predicates are essentially a difference in the way that these predicates can be made more precise. He describes a theory of super-truth, in which a sentence is true iff it is true in all admissible and complete specifications of the sentence.</paragraph><paragraph>Both these approaches use the idea that there are in fact precise ways of describing a concept, and that the truth value of a sentence using a vague concept is dependent on the different possible ways of making the sentence more precise. In what follows, we do not consider truth values of sentences but rather typicality of an item to a concept. However, consideration of logics using the fuzzy sets we develop would be an interesting line of future work.</paragraph><paragraph>Interestingly, [1] argue that adjective-noun combinations can be represented purely as set intersection between the adjective and the head noun. This is achieved by the use of typed sets. These are sets in which members are assigned types. So the adjective ‘clever’ is represented in the following way:{a mathematical formula} where the interpretation of j is ‘John’, and the interpretation of f is ‘Fido’. [1] argue that by using this type of representation the problems of privative adjectives can be circumvented. An example is as follows. From the two sentences ‘Maria is a former teacher’ and ‘Maria is a programmer’, we do not wish to infer ‘Maria is a former programmer’. The typed set representation is as follows:{a mathematical formula} Then, we can infer that {a mathematical formula}m∈Former∩Teacher, but not that {a mathematical formula}m∈Former∩Programmer. This is further extended to describe differences in scope when applying multiple adjectives. The approach described is interesting, and could presumably be extended to include some sort of typicality measure.</paragraph></section><section label="2.2"><section-title>Fuzzy set theory and prototype theory</section-title><paragraph>Prototype theory views concepts as being defined in terms of prototypes, rather than by a set of necessary and sufficient conditions. Elements from an underlying metric space then have graded membership in a concept depending on their similarity to a set of prototypical cases. There is some evidence that humans use natural categories in this way; see for example experiments reported in [43]. Fuzzy set theory [49] was proposed as a calculus for combining and modifying concepts with graded membership, and these ideas were then extended [51] to linguistic variables, these being variables taking words as values, rather than numbers. For example, ‘height’ can be viewed as a linguistic variable taking values ‘short,’ ‘tall’, ‘very tall’, etc.. The variable relates to an underlying universe of discourse Ω, which for the concept ‘tall’ could be {a mathematical formula}R+. Then each value L of the variable is associated with a fuzzy subset of Ω, and a function {a mathematical formula}μL:Ω→[0,1] associates with each {a mathematical formula}x∈Ω the value of its membership in L. Prototype theory gives a semantics for fuzzy set theory through the notion of similarity to a prototype, as described in [15]. In this context, concepts are represented by fuzzy sets and membership of an element in a concept is quantified by its degree of similarity to the prototype. Another possible semantic basis for fuzzy sets is random set theory (see [15] for an exposition). Here, the fuzziness of a set is a result of uncertainty about an underlying crisp set, i.e. semantic uncertainty. Fuzzy set theory seemed initially to be a natural formalisation of prototype theory, since it admits graded membership of concepts. However, work in this area has shown that it is inadequate as a model for human concept combination. A fuzzy set L is defined over a universe Ω via a membership function {a mathematical formula}μL:Ω→[0,1]. Elements {a mathematical formula}x∈Ω that are very good examples of the concept L have membership close to 1, whereas elements x that are bad examples of the concept have membership close to 0. The conjunction of two fuzzy sets is defined purely extensionally, for example {a mathematical formula}μL1∧L2(x)=min(μL1(x),μL2(x)), where {a mathematical formula}min(a,b) indicates the minimum of the two values a and b. Then, overextension of conjunctions of concepts cannot be explained using standard conjunction operators within fuzzy set theory [25], [27], [40]. Two key examples of this are the conjunction fallacy [47] and the ‘guppy effect’ [40]. The conjunction fallacy is that humans often judge more specific conditions as more probable than more general conditions. For example, one might judge a bicycle that has been painted with polka dots to be more typical of the combined concept ‘polka dot bicycle’ than of the concept ‘bicycle’. We discuss this further in section 4.4. The ‘guppy effect’ is introduced in [40], in which Osherson and Smith point out that a guppy, or goldfish, lacks many of the attributes of either a prototypical pet or a prototypical fish, whilst nonetheless being a prototypical example of a pet fish. These difficulties may be partly due to the failure of the fuzzy approach to account for the intension of concepts in the form of the attributes that the concept possesses. In contrast, conceptual space and quantum models are able to represent the intension of concepts, since in each case, a concept is viewed as being embedded in a multidimensional space, whose dimensions are, in some sense, the required attributes.</paragraph><paragraph>There is an important distinction between being a typical example of and being a member of a concept. It is entirely possible for something to be a member of a concept, but not typical of a concept. For example, a duck-billed platypus is a mammal, but it is not a typical mammal. This is explained by [45] by saying that concepts have defining and characteristic features, and that this is what determines concept membership. In [24], [26] Hampton argues against this hypothesis. He argues that membership in a conjunction of concepts may be determined by placing a threshold on a judgement of similarity of an item to a composite prototype, so that the two notions of typicality and membership may be attributed to one common cause, and furthermore, that judgements of typicality are correlated with probability of categorization. We subscribe to Hampton's view, as will be seen, allowing for the different weighting of particular attributes, which can thereby contribute to the typicality of an item to a concept. We do not discuss the similarity threshold at which a judgement of membership in a concept should be made. However, we often use the notion of membership in a fuzzy set as a proxy for typicality, and in particular we use the terminology ‘membership function’ and ‘membership value’. These should be seen as akin to typicality ratings in all that follows.</paragraph></section><section label="2.3"><section-title>Conceptual spaces</section-title><paragraph>Conceptual spaces are proposed in [19] as a framework for representing information at the conceptual level. Gärdenfors contrasts his theory with both a symbolic, logical approach to concepts, and an associationist approach where concepts are represented as associations between different kinds of basic information elements. Rather, conceptual spaces are geometrical structures based on quality dimensions such as weight, height, hue, brightness, etc. It is assumed that conceptual spaces are metric spaces, with an associated distance measure. This might be Euclidean distance, or any other appropriate metric. The distance measure can be used to formulate a measure of similarity, as needed for prototype theory, according to which similar objects are close together in the conceptual space and very different objects are far apart.</paragraph><paragraph>To develop the conceptual space framework, Gärdenfors also introduces the notion of integral and separable dimensions. Dimensions are integral if assignment of a value in one dimension implies assignment of a value in another, such as depth and breadth. Conversely, separable dimensions are those where there is no such implication, such as height and sweetness. A domain is then defined as a set of quality dimensions that are separable from all other dimensions, and a conceptual space is defined as a collection of one or more domains. Gärdenfors goes on to define a property as a convex region of a domain in a conceptual space. Finally, a concept is defined as a set of such regions that are related via a set of salience weights. This casting of (at least) properties as convex regions of a domain sits very well with prototype theory, as indeed Gärdenfors points out. If properties are convex regions of a space, then we can say that an object is more or less central to that region. Because the region is convex, its centroid will lie within the region, and this centroid can be seen as the prototype of the property.</paragraph><paragraph>There are a few approaches to defining concept composition based on conceptual spaces. Firstly, Gärdenfors proposed that when combining a pair of concepts as he defines them, properties in one concept are replaced by properties from the other, depending on the salience, or weighting, of each concept and each property. He goes on to introduce the notion of a contrast class. This has the effect that a particular property is restricted to a certain area. For example when talking about red wine, the concept ‘red’, determined by the contrast class ‘wine’, is a subset of the standard concept red. In order to model this, Gärdenfors maps the whole of the colour domain onto the subset of colours that can apply to wine. The formal rule for concept combination is then that the combination CD of two concepts C and D is determined by letting the regions for the domains of C confined to the contrast class defined by D, replace the values of the corresponding regions for D. So in the example of ‘red wine’, the space of colours has been restricted by the noun ‘wine’ to a subset of the full colour space with the same geometry. The colour of the wine is then taken to be the colour that is occupied by ‘red’ within the restricted colour space.</paragraph><paragraph>Consistent with this high level description of concept combination, we now describe below two more formal approaches based on conceptual spaces. Adams and Raubal [2] give a fairly straightforward formalisation of Gärdenfors's account, within which a conceptual space consists of a 6-tuple of domains, concepts, instances, contrast classes, contexts, and a similarity sensitivity parameter. Each domain is a set of quality dimensions. A concept is defined as a pair consisting of a set of convex regions of domains together with a prototypical instance P, and a property as a concept that includes only one domain region. A contrast class is defined as a region of a unit hypercube corresponding to a domain. Although it is not entirely clear why a unit hypercube is used rather than the domain itself, this is presumably as a way of normalising the dimensions of the domain before the contrast is applied. A context is defined as a finite set of salience weights. In [2], Adams and Raubal go on to define three types of concept combination: property–concept, concept–concept and contrast–class–concept combination and give algorithms for the implementation of each type of combination. However, they do not attempt to account for the fuzziness of natural concepts, or give any account of non-compositional features.</paragraph><paragraph>Another approach that gives a formal definition of conceptual spaces is described by Rickard et al. in [42]. This views concepts as a function from pairs of properties into a unit interval. These properties are defined as fuzzy sets in a domain {a mathematical formula}Domi. A concept C is therefore a set of correlations between pairs of properties {a mathematical formula}(a,b) where {a mathematical formula}a,b belong to a set of properties. Each pair of properties {a mathematical formula}(a,b) has a value {a mathematical formula}Cab in a concept, which gives the strength of the correlation of a and b in the concept. For example, consider the concept {a mathematical formula}Banana. The property {a mathematical formula}yellow and the property {a mathematical formula}sweet are highly correlated, and the property {a mathematical formula}green and the property {a mathematical formula}bitter are highly correlated. A context is defined as a set of properties, and the similarity between two concepts {a mathematical formula}C1 and {a mathematical formula}C2 as the mutual subsethood of {a mathematical formula}C1 and {a mathematical formula}C2 relative to that context. The mutual subsethood functions as a way of determining the overlap of two concepts. It is defined by:{a mathematical formula} where {a mathematical formula}Cab is the value of the correlation between properties a and b on concept C.</paragraph><paragraph>For example, suppose our context is the set {a mathematical formula}{red,round} and our objects are {a mathematical formula}C1=apple, {a mathematical formula}C2=cricketball. The strengths of the correlations are given in Tables 1a and 1b.</paragraph><paragraph>Then{a mathematical formula}</paragraph><paragraph>The role of the context is to determine which properties are relevant in calculating the similarity. The membership of an observation in a concept is defined as the similarity of the observation to a given concept, and the label is then assigned which has maximum membership for the given observation. Dynamics on the space are also introduced, which allow properties to be prioritised for attention. Composition of concepts is carried out by combining properties by taking the union of the property sets so that the resulting combined concept has properties that belong to both constituent concepts. Whilst Rickard et al. do model fuzziness, they do not attempt to account for non-compositional features of human concept use.</paragraph></section><section label="2.4"><section-title>Computational linguistics and vector space models</section-title><paragraph>Within the field of computational linguistics, vector-based models of word meaning have proved very fruitful. The meaning of a particular word is represented as a vector, where the basis of the vector space might be a chosen set of words (usually, the most common, excluding a list of stop-words such as ‘a’, ‘the’, ‘and’, and so on), or some other carefully chosen dimensions, and the entries in the vector are word co-occurrence statistics, or a relation between the words and the documents they occur in [10], [31], [37]. A comprehensive paper by Mitchell and Lapata [38] gives a comparison of various techniques for adjective-noun composition. Related approaches are given in [7], [11], where adjectives are viewed as matrices, and nouns as vectors. Whilst these approaches have considerable merit, the underpinning space cannot be viewed as a conceptual space that describes features of the concept. The relationship of individual dimensions to the vectors are not attributes, but could be instances, parts of, or any other incidental relationship. The development of a suitable conceptual space for these models would be an interesting line of future research.</paragraph><paragraph>Another approach within the computational linguistics framework is the development of a family of ‘microtheories’ of word meanings. [41] develop a microtheory of adjectives whereby the analysis given in [27] is extended to examine what a number of linguists determine to be the taxonomy of adjectives. Words are represented as having syntactic and semantic types. The syntactic type describes how the word can be combined with others. The semantic type describes the semantic effect of making such a combination. So, for example, the adjective ‘big’ can be applied in the combinations Adj-Noun or Noun-Copula-Adj, and has the semantic effect that it can be applied to physical objects and limits the normalised value of the size property to greater than 0.75. Adjectives are divided into scalar – based on properties, denominal – based on object, and deverbal – based on processes. The distinctions between these types lie in their semantics, namely the different ways in which they combine with nouns to form a composite. In the work we present here we focus on intersective adjectives, since as pointed out in [27] even these require work to clarify how typicality functions in a composite concept, and therefore we do examine the difference in semantic types. Explaining these differences will be an interesting area for further work, however.</paragraph></section><section label="2.5"><section-title>Quantum probability models</section-title><paragraph>The quantum probability model introduced by Aerts [3], sees a concept as a quantum entity within a vector space, the dimensions of which are the contexts of the concept. When no context is present for the concept, the concept is in its ground state. The application of a context then changes this concept into the concept under that context. Typicality of an item to a concept changes with context. As such, problems such as the ‘guppy effect’ are accounted for by noting that the typicality of a guppy to the concept pet in its ground state differs from the typicality of a guppy to the concept pet in the context ‘the pet is a fish’. Aerts et al [5] give a description of how the effects of contextuality, interference, entanglement and emergence may be seen in human concept use. Contextuality may be seen in the way that the typicality of an element to a concept changes with the context given. The phenomenon of interference in quantum vector spaces allows over- and under-extension to be modelled when combining concepts. Briefly, membership in a concept is modelled by the projection of the concept onto the subspace representing the item. When evaluating the membership of an item to the composite concept ‘A and B’, it may be the case that an interference term needs to be introduced. This interference term accounts for over- or under-extension. This idea is explained in detail in [4], in which data from [23], [24] is modelled. The phenomenon of entanglement is found to be present in data concerning the applicability of combinations of concept pairs. The concept of emergence is explained as the idea that a totally new concept has been introduced by forming a conjunction of concepts. To account for this, Aerts et al. propose the use of Fock space. In Fock space, an entity may be in a superposition of states. In the case of concept combination, one of these states is the completely new concept, and another is the concept as a combination of two concepts. Using these notions, the quantum probability model develops ways of modelling which account for both the fuzziness of human concept use and effects of non-compositionality. Within this paper, we aim to show that our approach can account for these aspects of human concept use within a simpler and more intuitive framework.</paragraph></section><section label="2.6"><section-title>Experimental studies</section-title><paragraph>Hampton [22] reports results from two experiments. The aim of the first was to generate a list of attributes for each of six pairs of concepts and their conjunctions. An example is the pair of concepts Sports and Games. A list of attributes was collected for each of these concepts, and for the conjunctions ‘Games which are Sports’ and ‘Sports which are Games’. This was repeated for each of the six pairs of concepts. Based on these lists of attributes, the second experiment asked participants how useful each attribute was in defining the concept, as measured on the scale shown in Table 2 (the numerical value was imposed later rather than given by participants).</paragraph><paragraph>Averaging across subjects then gives the mean importance rating for each attribute in each concept. Some attributes have similar importance within pairs of concepts, and some differ. For example, the attribute ‘Is used by people’ has a mean rating of 3.00 for both Machines and for Vehicles. However, ‘Replaces people’ has a mean rating of 2.00 for Machines, and −1.00 for Vehicles. The challenge then is to predict the importance of an attribute for a combined concept such as ‘Machines which are also Vehicles’ from the attribute weightings of the constituent concepts. Hampton reports that using multiple regression to obtain weight coefficients for a weighted sum provides the best predictor of attribute weightings in the combined concepts, but that noncompositionality is also observed. For example, some attributes with low importance in the constituent concepts may have a high importance in the combined concept. This is termed ‘attribute emergence’ – the attribute ‘Lives in a cage’ has low importance for ‘Pet’ and for ‘Bird’, but high importance for ‘Pet which is also a Bird’. A similar way in which noncompositionality manifests itself is in the preservation of necessary or impossible attributes. When an attribute is seen as necessary (or impossible) for one of the constituent concepts, that importance rating is carried over into the attributes for the combined concept. Therefore, there is no functional relationship between the importance of an attribute in the constituent concepts, and the importance in the combined concept. Rather, this depends on the particular concepts involved. Hampton finds that conjunction is not commutative in that the qualifying noun, i.e. the second noun in the conjunction, is given more weight. Lastly, dominance effects are also seen, in that concepts which bring more attributes to the conjunction tend to dominate.</paragraph><paragraph>Hampton therefore reports the following six main results:</paragraph><list><list-item label="•">The attribute set for combined concepts is the union of the attribute sets of the constituent concepts</list-item><list-item label="•">The importance of attributes in the combined concept is usually a weighted sum of the importance of the attributes in each individual concept</list-item><list-item label="•">Necessity and impossibility are preserved</list-item><list-item label="•">Attribute loss or emergence is observed</list-item><list-item label="•">Conjunction is not commutative</list-item><list-item label="•">Dominance effects are observed</list-item></list><paragraph>We will argue that our proposed model of concepts and concept combination can also account for these phenomena. Furthermore, our framework is a natural extension of the conceptual spaces model in which the importance of certain dimensions is related to their necessity as defined by possibility theory [16].</paragraph></section></section><section label="3"><section-title>Formal model of concepts</section-title><paragraph>In this section we outline our conceptual spaces based model of concepts which forms the theoretical underpinnings of our work. This model of concepts combines a prototype theory approach with random sets, capturing both typicality and semantic uncertainty, first outlined by Lawry and Tang in [33]. We will go on to build on this model of concepts to form a framework for concept combination.</paragraph><section label="3.1"><section-title>A prototype and random set model of concepts</section-title><paragraph>In this framework, agents use a set of labels {a mathematical formula}L={L1,L2,...,Ln} to describe an underlying conceptual space Ω which has a distance metric {a mathematical formula}d(x,y) between points.{sup:2} If one of x or y is a set then we take the distance to be the minimum distance to any point in the set. For example, suppose Y is a set, then {a mathematical formula}d(x,Y)=min{d(x,y):y∈Y}. Each label {a mathematical formula}Li is associated firstly with a set of prototype values {a mathematical formula}Pi⊆Ω, and secondly with a threshold {a mathematical formula}εi, about which the agents are uncertain. The thresholds {a mathematical formula}εi are drawn from probability distributions {a mathematical formula}δi. Labels {a mathematical formula}Li are associated with neighbourhoods {a mathematical formula}NLiεi={x∈Ω:d(x,Pi)≤εi}. The neighbourhood can be seen as the extension of the concept {a mathematical formula}Li. The intuition here is that {a mathematical formula}εi captures the idea of being sufficiently close to prototypes {a mathematical formula}Pi. In other words, {a mathematical formula}x∈Ω is sufficiently close to {a mathematical formula}Pi to be appropriately labelled as {a mathematical formula}Li providing that {a mathematical formula}d(x,Pi)≤εi. This is illustrated in Fig. 1.</paragraph><paragraph>Given an element {a mathematical formula}x∈Ω, we can ask how appropriate a given label is to describe it. This is quantified by a membership function, denoted {a mathematical formula}μLi(x), corresponding to the probability that the distance from x to {a mathematical formula}Pi, the prototype of {a mathematical formula}Li, is less than the threshold {a mathematical formula}εi, as given by:{a mathematical formula}</paragraph><paragraph>We also use the notation {a mathematical formula}∫εi∞δεi(εi)dεi=Δi(εi), according to which {a mathematical formula}μLi(x)=Δi(d(x,Pi)). The above formulation provides a link to the random set formalisation of fuzzy sets. Random sets are random variables taking sets as values. If we view {a mathematical formula}NLiεi as a random set from {a mathematical formula}R+ into {a mathematical formula}2Ω, then {a mathematical formula}μLi(x) is the single point coverage function of {a mathematical formula}NLiεi, as defined in [32].</paragraph><paragraph>Each label {a mathematical formula}Li is entirely defined by its prototype {a mathematical formula}Pi, the distance metric in the space {a mathematical formula}d(x,y) and the distribution {a mathematical formula}δi of the threshold {a mathematical formula}εi. We can therefore, given a particular conceptual space Ω, use the notation {a mathematical formula}Li=&lt;Pi,di,δi&gt; to completely describe the label {a mathematical formula}Li.</paragraph><paragraph>The idea of a membership function presented here may be compared with the similarity relation that Gärdenfors uses. A similarity relation between points in a conceptual space may be defined as a decreasing function of distance in the space. Gärdenfors gives the example that the similarity {a mathematical formula}s(x,y) between two points x and y in the conceptual space is an exponentially decaying function of the distance {a mathematical formula}d(x,y) between the two points, i.e. {a mathematical formula}s(x,y)=exp⁡(−cd(x,y)). In terms of the prototype-threshold approach outlined above, the membership of an element x in a concept L may then be defined as the similarity to the prototype P of L, where {a mathematical formula}ε∼Exp(c). More generally, {a mathematical formula}s(x,y)=Δ(d(x,y)).</paragraph><paragraph>This approach is, however, in contrast to Gärdenfors' original approach which is to view the space as partitioned by a Voronoi tessellation. If this latter approach is taken, each individual point in the conceptual space is allocated to exactly one label. With a prototype-threshold approach, it is easy to accommodate the idea of an object being accurately described by more than one concept, or conversely, some points within the space not being assigned to any concept. This difference is illustrated in Fig. 2, Fig. 3.</paragraph><paragraph>The Voronoi diagram approach to describing concepts can be extended to include graded boundaries, and such an approach is developed in [13], [14]. We argue that a drawback to this type of representation is that every single point has been categorised. In contrast, in the label semantics approach there can be points which have not been categorised. This is desirable: imagine the first Western scientists to encounter a duck-billed platypus. It is not clear how to categorise this animal, and it could be modelled as being in a region of space that has not yet been assigned to a category. Another advantage of the neighbourhood model is that concepts can overlap which allows us specifically to refer to borderline regions. However, a benefit of the Voronoi tessellation approach to concept representation is that the membership of a point in a concept depends not only on the prototype of that concept but on the proximity of other prototypes. To integrate this aspect into the label semantics approach to concepts would be an interesting area for future research.</paragraph></section></section><section label="4"><section-title>A hierarchical model of conjunctive composition</section-title><section label="4.1"><section-title>Background</section-title><paragraph>As described in section 2, Hampton [22] gives a series of results on human understanding of conjunctive concepts, such as ‘sports that are games’. It had already been shown [40], [46] that standard fuzzy set-theoretical conjunctions and disjunctions do not adequately model human understanding of composite concepts. Hampton's work elicits data that could form the basis of a model of conjunction that more accurately reflects how humans understand conjunctive concepts.</paragraph></section><section label="4.2"><section-title>A new approach to concept composition</section-title><paragraph>An initial approach to modelling Hampton's data within the conceptual spaces framework would be to view individual attributes, for example ‘Talks’, ‘Has fur’, ‘Has claws’, as each forming a dimension of the conceptual space. However, these attribute dimensions are very different from the usual conceptual space dimensions in two ways. Firstly, they are mostly binary, unlike dimensions such as ‘height’, ‘depth’ or ‘breadth’. Secondly, they are very complex in comparison to the types of dimensions proposed by Gärdenfors. For instance, having feathers seems to be a multidimensional concept in itself.</paragraph><paragraph>This motivates a new hierarchical formulation of conceptual spaces in which we model attributes as labels, each taken from individual domains. In Gärdenfors' terminology, each label would be a property from an integral domain. So an attribute like ‘rounded’ is seen as a label based in a space such as {a mathematical formula}R3, or ‘red’ as based in the CIELab colour space. From this perspective, each of the attribute labels can form a binary dimension which are then combined to form the space {a mathematical formula}{0,1}n where n is the number of attributes. Within this binary space, we take the value 1 on a particular dimension to mean that an object has that particular property. Fig. 4 gives a schematic representation of this model, within which we treat the combination space {a mathematical formula}{0,1}nitself as a conceptual space with an associated metric. This enables us to apply the neighbour-based prototype model of concepts outlined in section 3 to form compound concepts made up of many properties. The motivation for treating this combination space itself as a conceptual space is that if we view each label as a property in an integral domain, then this is precisely a formalisation of the conceptual spaces that Gärdenfors proposes. Gärdenfors suggests both a weighted sum of properties and a weighted Euclidean distance metric in the property space. The formalism we propose corresponds to the weighted sum of properties, but generalises it. If we were to use a cube {a mathematical formula}[0,1]n∈Rn, then we might be able to give the weighted Euclidean distance as a special case. This is an area for further work, however.</paragraph><paragraph>In the sequel we formalise this idea and prove a number of key results concerning conjunctive concepts defined in this way. We show that if the threshold of the compound concept in the binary combination space is uniformly distributed, the membership function for the compound concept is shown to be a weighted sum of the membership functions of the individual labels. This result nicely parallels Zadeh's operation of convex combination, and Gärdenfors' proposal that concepts should be seen as sets of properties related by salience weights. Lastly, we will show that under certain conditions, the importance of an attribute in a conjunction of two compound concepts can be calculated as the weighted sum of the importances of the individual attributes, directly mirroring Hampton's results.</paragraph><paragraph>A conjunctive label is defined in a binary space as follows. Consider a set of distinct integral domains {a mathematical formula}Ω1,…,Ωn, such as the CIELab colour space, size, and taste. We select a label from each domain for combination. So an apple might be described as red and sweet and medium sized. This gives us a set {a mathematical formula}LA={L1,…,Ln} where {a mathematical formula}Li⊆Ωi for {a mathematical formula}i=1,…,n.</paragraph><paragraph>Each label {a mathematical formula}Li is defined by the triple {a mathematical formula}&lt;Pi,di,δi&gt;, as described in section 3, where the prototype {a mathematical formula}Pi⊆Ωi, {a mathematical formula}di is the distance metric in {a mathematical formula}Ωi, the threshold {a mathematical formula}εi is a random variable into {a mathematical formula}R+ and {a mathematical formula}δi is a probability density on {a mathematical formula}εi. We can then define a Boolean variable {a mathematical formula}Xi into {a mathematical formula}{0,1} with reference to a point {a mathematical formula}Yi∈Ωi for {a mathematical formula}i=1,…,n as follows:{a mathematical formula}</paragraph><paragraph>Here {a mathematical formula}Xi=1 means that the object being described has the property {a mathematical formula}Li, i.e., {a mathematical formula}Xi=1 iff {a mathematical formula}Yi∈NLiεi, where {a mathematical formula}NLiεi is the neighbourhood of {a mathematical formula}Li, as described in section 3. Also, {a mathematical formula}P(Xi=1|Yi)=P(d(Yi,Pi)≤εi)=μLi(Yi).</paragraph><paragraph>A vector {a mathematical formula}Y→∈Ω1×…×Ωn generates a Boolean vector {a mathematical formula}X→ into {a mathematical formula}{0,1}n. In this case, the probability distribution for {a mathematical formula}Xi is determined by {a mathematical formula}δi.</paragraph><paragraph>Now consider a conjunctive concept as being defined by a conjunction of labels or their negations, covering all labels in LA. It is therefore of the following form:{a mathematical formula} where {a mathematical formula}+Li=Li and {a mathematical formula}−Li=¬Li. Expressions of this type are referred to as atoms.</paragraph><paragraph>Each atom then naturally defines a point in {a mathematical formula}{0,1}n as follows:{a mathematical formula}</paragraph><paragraph>We think of the space {a mathematical formula}{0,1}n as the binary conjunction space, and of {a mathematical formula}x→α as the prototype of the conjunctive concept α. We also allow some deviation from the prototype by taking into account the different levels of importance of each label {a mathematical formula}Li. The differing importance of the labels is characterised by a weight vector {a mathematical formula}λ→ which weights each dimension in the binary space. These ideas are illustrated in Fig. 5.</paragraph><paragraph>We can now consider membership in the conjunctive concept within the binary space. A conjunctive concept is defined by the triple {a mathematical formula}α=&lt;x→α,d,δ&gt; where α is an atom of LA, d is a distance on {a mathematical formula}{0,1}n, ε is a random variable in {a mathematical formula}R+ and δ is a probability distribution on ε. We say that an element {a mathematical formula}X→∈{0,1}n can be appropriately described by the concept α iff {a mathematical formula}d(x→α,X→)≤ε with the membership function defined by:{a mathematical formula} We can then relate membership in {a mathematical formula}Ω1×Ω2×...×Ωn to membership in the binary space {a mathematical formula}{0,1}n as follows.</paragraph><paragraph>We define a binary random variable Z into {a mathematical formula}{0,1} such that:{a mathematical formula} Clearly in this case {a mathematical formula}P(Z=1|X→)=μα(X→). Now by total probability we have that:{a mathematical formula} We may assume that {a mathematical formula}Z→ and {a mathematical formula}Y→ are conditionally independent given {a mathematical formula}X→, since {a mathematical formula}Z→ is defined purely in terms of {a mathematical formula}X→.</paragraph><paragraph>Letting {a mathematical formula}μα(Y→) denote {a mathematical formula}P(Z=1|Y→) and assuming independence of the dimensions {a mathematical formula}i=1...n we then have that:{a mathematical formula}</paragraph><paragraph>More generally, we can define a compound concept with prototypical case {a mathematical formula}θ=⋀I±Li, where {a mathematical formula}I⊆{1,...,n}, as a triple {a mathematical formula}θ=&lt;P,d,δ&gt; where:{a mathematical formula}P is therefore a set of points which all have the same values on the dimension specified by the index set I, and cover all remaining possibilities across the dimensions not in I. This implies that where {a mathematical formula}I={1,...,n}, P is a singleton.</paragraph><paragraph>In this case we have that:{a mathematical formula}</paragraph><paragraph label="Definition 1">We now define a distance metric in the binary space {a mathematical formula}{0,1}n based on Hamming distance and a weight vector. One dimensional Hamming distance{a mathematical formula}</paragraph><paragraph label="Definition 2">Weighted Hamming distanceFor {a mathematical formula}λ→∈(R+)n,{a mathematical formula}</paragraph><paragraph>The effect of this distance metric on membership in the binary space is illustrated in Fig. 6. Suppose that the concept ‘bird’ is characterised, for illustrative purposes, by two properties {a mathematical formula}L1= ‘flies’, {a mathematical formula}L2= ‘has feathers’. The property {a mathematical formula}L1 may be relaxed, since there are birds which do not fly. So animals which have feathers, but do not fly, are still considered birds but not typical birds. We characterise this using the weights in the binary space. Therefore in this case, the weight on the first dimension, {a mathematical formula}λ1 will be smaller than {a mathematical formula}λ2. The effect this has is to create elliptical neighbourhoods in the space.</paragraph><paragraph>We now outline a correspondence between our idea of a compound concept as a conjunction of attribute labels or their negations, and Hampton's account of concepts as combinations of attributes with individual weights. Firstly, as stated above, we model individual attributes as labels from conceptual spaces such as the colour space, or the taste space. We have a vector of weights, {a mathematical formula}λ→, attached to the binary space which loosely corresponds to Hampton's attribute weights. However, the weights in Hampton's account range from 4, being necessary, to −2, being impossible. In contrast, our weight vector {a mathematical formula}λ→ is always positive, and the idea of an attribute {a mathematical formula}Li being atypical or impossible is captured by the notion that the conjunction {a mathematical formula}⋀i=1n±Li includes {a mathematical formula}¬Li. The extent of the atypicality of the attribute {a mathematical formula}Li is then given by the weight {a mathematical formula}λi of the corresponding dimension.</paragraph></section><section label="4.3"><section-title>Properties of the hierarchical model</section-title><paragraph>We now give a series of results concerning the formulation and properties of compound concepts. We firstly give an example of how two properties may be combined. In section 4.3.1 we show that as a special case, the membership function of a compound concept reduces to a weighted sum of the membership functions of the individual constituent concepts, thereby giving a mathematical grounding to the ideas proposed in [19] of seeing a concept as a weighted combination of properties, or in [50] of forming complex concepts via a mechanism of convex combination. Lastly, section 4.3.2 shows how the conjunction of two compound concepts can again be modelled as a weighted sum. This result models Hampton's results [22], outlined in 4.1.</paragraph><paragraph label="Example 3">We use Beta distributions in this example, since this distribution produces various different shapes depending on the parameters used.Suppose α= ‘tall and thin’ is mapped into {a mathematical formula}{0,1}2 with {a mathematical formula}λ1=0.4, {a mathematical formula}λ2=1−λ1=0.6, and that the threshold ε is distributed according to {a mathematical formula}δ=Beta(2,1).Then {a mathematical formula}α=&lt;(1,1),Hλ→,δ&gt;, and{a mathematical formula} where {a mathematical formula}Y→=(Y1,Y2)∈R2.This membership function is illustrated in Fig. 7.</paragraph><section label="4.3.1"><section-title>Results for compound concepts using hamming distance</section-title><paragraph>The example above shows that the membership functions generated within this framework can be very flexible. However, we show that by restricting the type of membership function used in the binary combination space, we can derive an expression for the membership function {a mathematical formula}μθ(Y→) of the compound concept {a mathematical formula}θ=⋀i=1k±Li, {a mathematical formula}k≤n as a weighted sum of the membership functions for individual domains {a mathematical formula}μ±Li(Yi). This grounds proposals in [19], [30], [50] that complex concepts can be built up as sums of weighted properties.</paragraph><paragraph label="Proof">Let{a mathematical formula}α=⋀i=1n±Liand{a mathematical formula}λT=∑i=1nλi. Let δ be the uniform distribution on the interval{a mathematical formula}(0,λT). If d is the weighted Hamming distance{a mathematical formula}Hλ→then:{a mathematical formula}W.l.o.g assume {a mathematical formula}α=⋀i=1nLi. Notice that {a mathematical formula}Δ(u)=λT−uλT for {a mathematical formula}u∈[0,λT], and therefore:{a mathematical formula} From this we have that:{a mathematical formula} □</paragraph><paragraph>Theorem 4 grounds the idea that properties can be combined via a set of weights to form a concept, as proposed by Gärdenfors in [19], or the operation of convex combination proposed by Zadeh in [50]. The model sits particularly well with Gärdenfors's proposal since it uses a binary conceptual space as the mechanism for combination. Furthermore, the fact that we require specific conditions for the distribution of the threshold of the concept in the binary space is an advantage, since relaxing these conditions allows us to explain some of the characteristics of concept combination seen in psychological experiments, such as overextension or non-commutativity. We will discuss this further in section 4.3.3.</paragraph><paragraph>A key aspect of concepts in Gärdenfors's conceptual spaces is that they should be convex. In a space {a mathematical formula}Rn with the Euclidean distance metric, convexity of a set S is defined by the property that {a mathematical formula}∀x,y∈S, every point on the line segment connecting x and y is also in S. A detailed discussion is given [19] citing experimental evidence for the fact that concepts as used by humans tend to be convex, and that the use of convex concepts requires less cognitive load. We give a definition of convexity for the binary combination spaces {a mathematical formula}{0,1}n.</paragraph><paragraph label="Definition 5">Betweenness{a mathematical formula}∀x,y,z∈{0,1}n with distance metric {a mathematical formula}Hλ→, z is between x and y, {a mathematical formula}B(x,y,z) iff {a mathematical formula}Hλ→(x,y)=Hλ→(x,z)+Hλ→(z,y).</paragraph><paragraph label="Definition 6">ConvexityA set {a mathematical formula}S⊆{0,1}n is convex if {a mathematical formula}∀x,y∈S, every point z lying between x and y also belongs to S, i.e. {a mathematical formula}{z:B(x,y,z)}⊆S.</paragraph><paragraph>We can now generalise Theorem 4 to the case where {a mathematical formula}θ=⋀i=1k±Li, {a mathematical formula}k≤n. In this case, the prototype P does not specify all values of {a mathematical formula}i=1...n. We firstly introduce some notation allowing us to talk about the set of dimensions in a prototype that remain invariant. We argue that if P does not specify all dimensions of {a mathematical formula}{0,1}n, then the weight vector {a mathematical formula}λ→ must be such that only those dimensions contributing to the concept are weighted. For example, suppose {a mathematical formula}n=3, {a mathematical formula}P={(1,1,1),(1,1,0)}. Then {a mathematical formula}λ→=(0.4,0.3,0). We go on to prove that a similar result to that shown in Theorem 4 holds for θ.</paragraph><paragraph label="Definition 7">We now introduce some notation to enable us to talk about the dimensions of a set of points {a mathematical formula}S⊆{0,1}n that take a fixed value across the subset. <section-title>Fixed dimensions</section-title></paragraph><list><list-item label="•">For {a mathematical formula}S⊆{0,1}n, {a mathematical formula}Z(S)⊆{1,…,n} such that {a mathematical formula}Z(S)={i:∀x→∈S,xi=0} (the zeros of S)</list-item><list-item label="•">For {a mathematical formula}S⊆{0,1}n, {a mathematical formula}O(S)⊆{1,…,n} such that {a mathematical formula}O(S)={i:∀x→∈S,xi=1} (the ones of S)</list-item><list-item label="•">For {a mathematical formula}S⊆{0,1}n, {a mathematical formula}E(S)⊆{1,…,n} such that {a mathematical formula}E(S)={i:∀x→,y→∈S,xi=yi}. Note that {a mathematical formula}E(S)=Z(S)∪O(S) (the set of points in S that take fixed values)</list-item></list><paragraph label="Proof">Let{a mathematical formula}θ=&lt;P,Hλ→,δ&gt;where P is convex with respect to{a mathematical formula}Hλ→. Furthermore, let{a mathematical formula}θ′=&lt;P,Hλ′→,δ&gt;such that:{a mathematical formula}Then{a mathematical formula}μθ(X→)=μθ′(X→)Since P is convex we have that:{a mathematical formula} Therefore,{a mathematical formula} □</paragraph><paragraph>So with respect to membership in θ in the binary space, the weight vector {a mathematical formula}λ′ produces the same results as the weight vector λ. We now show that an analogue to Theorem 4 holds.</paragraph><paragraph label="Theorem 9">Let{a mathematical formula}θ=&lt;P,Hλ→,δ&gt;with{a mathematical formula}δ=U(0,λT), where{a mathematical formula}λT=∑i=1nλi, and{a mathematical formula}θ′=&lt;P,Hλ′→,δ′&gt;such that:{a mathematical formula}{a mathematical formula}λT′=∑i=1nλi′and{a mathematical formula}δ′=U(0,λT′)=λTλT′δ. Then{a mathematical formula}μθ(X→)=λT′λTμθ′(X→), and{a mathematical formula}μθ(Y→)=λT′λTμθ′(Y→).</paragraph><paragraph label="Proof">Since P is convex, {a mathematical formula}Hλ→(P,X→)=Hλ→′(P,X→).So{a mathematical formula}Now,{a mathematical formula} □</paragraph><paragraph>We can therefore convert any {a mathematical formula}θ=&lt;P,Hλ→,δ&gt; with {a mathematical formula}δ=U(0,λT) into {a mathematical formula}θ′, such that {a mathematical formula}i∉E(P)→λi=0 via a suitable scaling of {a mathematical formula}μθ(X→) and {a mathematical formula}μθ(Y→).</paragraph><paragraph>These results show that a compound concept can be built up out of the weighted sum of individual concepts, provided that certain key conditions hold. We now go on to look at the behaviour of the conjunction of two such concepts.</paragraph></section><section label="4.3.2"><section-title>Conjunctions of compound concepts</section-title><paragraph>Up to now we have discussed how properties from integral domains may be combined to form concepts. The results in [22] concern how the weighting of these properties change under the conjunction of two such concepts. We extend our framework to take into account the conjunction of two compound concepts. To do this, we introduce a second level binary space, illustrated in Fig. 8, and combine the two concepts within the second level space using the same approach as in section 4.2, i.e. as if they are themselves properties.</paragraph><paragraph>Let {a mathematical formula}θ=&lt;P1,d1,δ1&gt; and {a mathematical formula}φ=&lt;P2,d2,δ2&gt; be two compound concepts consisting of a conjunction of attribute labels from individual conceptual spaces {a mathematical formula}Ωi. As in section 4.2 we define the following two binary variables:{a mathematical formula}</paragraph><paragraph>Hence {a mathematical formula}X→ naturally generates {a mathematical formula}Z→=(Z1,Z2)∈{0,1}2. We now define the conjunction of compound concepts as the triple {a mathematical formula}θ∧φ=({(1,1)},d,δ) where d is a distance metric on {a mathematical formula}{0,1}2. In this case we can define a binary random variable C such that:{a mathematical formula} We also define the membership function for {a mathematical formula}θ∧φ as follows:{a mathematical formula} So that {a mathematical formula}μθ∧φ(Z→)=P(C=1|Z→). Now by applying the theorem of total probability we have that:{a mathematical formula} Then by a second application of the theorem of total probability we have that:{a mathematical formula}</paragraph><paragraph label="Theorem 10">We can now look at the behaviour of the weights in a conjunction of compound concepts. Let{a mathematical formula}θ=&lt;Pθ,Hλ→θ,δθ&gt;,{a mathematical formula}φ=&lt;Pφ,Hλ→φ,δφ&gt;, where{a mathematical formula}∑i=1nλθ,i=λθ,T,{a mathematical formula}∑i=1nλφ,i=λφ,Tand{a mathematical formula}δθ=Uniform(0,λθ,T),{a mathematical formula}δφ=U(0,λφ,T). Let{a mathematical formula}θ∧φ=&lt;{(1,1)},Hw→,δ&gt;where{a mathematical formula}w1+w2=wTand{a mathematical formula}δ=U(0,wT). Suppose that if{a mathematical formula}i∈E(Pθ)∩E(Pφ)then{a mathematical formula}Pθ,i=Pφ,i, i.e. that the prototypes have no directly contradictory attributes. Then{a mathematical formula}So{a mathematical formula}θ∧φ=&lt;Pθ∧φ,Hλ→θ∧φ,δθ∧φ&gt;where{a mathematical formula}Pθ∧φ=Pθ∩Pφ,{a mathematical formula}λθ∧φi=w1λφ,Tλθ,i+w2λθ,Tλφ,iand{a mathematical formula}δθ∧φ=U(0,wTλθ,Tλφ,T).</paragraph><paragraph label="Proof">Suppose w.l.o.g. by Theorem 9 that {a mathematical formula}i∉E(Pθ)⟹λθ,i=0, {a mathematical formula}i∉E(Pφ)⟹λφ,i=0{a mathematical formula}Now, since if {a mathematical formula}i∈E(Pθ)∩E(Pφ) then {a mathematical formula}Pθ,i=Pφ,i and {a mathematical formula}i∉E(Pθ)⟹λθ,i=0, {a mathematical formula}i∉E(Pφ)⟹λφ,i=0, we have that{a mathematical formula} □</paragraph><paragraph>So under certain conditions, the attribute weights in the conjunctive concept are a weighted sum of the attribute weights of the constituent concepts, which models one of Hampton's key findings as stated in section 4.1. Further, since {a mathematical formula}Pθ∧φ=Pθ∩Pφ, {a mathematical formula}E(Pθ∧φ)=E(Pθ)∪E(Pφ), i.e. the attribute set for the conjunctive concept is a union of the attribute sets for the constituent concepts, modelling another aspect of Hampton's results.</paragraph><paragraph label="Example 11">Concept–concept combinationSuppose one concept, {a mathematical formula}SUCCESS, is defined as a conjunction of labels {a mathematical formula}L1= ‘rich’, {a mathematical formula}L2= ‘healthy’, and suppose {a mathematical formula}HAPPY is defined as a conjunction of labels {a mathematical formula}L2= ‘healthy’ and {a mathematical formula}L3= ‘busy’. Furthermore, suppose {a mathematical formula}SUCCESS is formed in the binary space {a mathematical formula}{0,1}2 with prototype set {a mathematical formula}Ps={(1,1)}, weighting {a mathematical formula}λs→=(0.75,0.25) and {a mathematical formula}δs=U(0,1), i.e. {a mathematical formula}SUCCESS=&lt;{(1,1)},H(0.75,0.25),U(0,1)&gt; and similarly suppose {a mathematical formula}HAPPY=&lt;{(1,1)},H(0.5,0.5),U(0,1)&gt;. To combine these two concepts, we firstly expand the prototypes and weight vectors for each to encompass the dimensions of the other, i.e. they are embedded in the space {a mathematical formula}{0,1}3, where each dimension i indicates the presence or absence of the label {a mathematical formula}Li. So, for example, the point {a mathematical formula}(1,0,1) corresponds to ‘rich and not healthy and busy’. Within this expanded space, {a mathematical formula}Ps={(1,1,x3):x3∈{0,1}}, i.e., {a mathematical formula}{(1,1,0),(1,1,1)} and {a mathematical formula}λ→s=(0.75,0.25,0). Similarly, {a mathematical formula}Ph={(x1,1,1):x1∈{0,1}}, and {a mathematical formula}λ→h=(0,0.5,0.5). Now, according to Theorem 4, Theorem 9, {a mathematical formula}μS(Y→)=0.75μL1(Y1)+0.25μL2(Y2), and {a mathematical formula}μH(Y→)=0.5μL2(Y2)+0.5μL3(Y3).We combine the expanded {a mathematical formula}θ=SUCCESS∧HAPPY in the second level binary space {a mathematical formula}{0,1}2 with prototype {a mathematical formula}Pθ=(1,1), {a mathematical formula}λ→θ=(0.5,0.5), {a mathematical formula}δθ=U(0,1). Now, according to Theorem 10{a mathematical formula}</paragraph><paragraph>In many cases, we want to combine a concept with a property, such as ‘red car’, illustrated in Fig. 9. This can be implemented as a special instance of the concept–concept combination illustrated in Example 11, where the first concept has just one label.</paragraph><paragraph label="Example 12">Property–concept combinationSuppose {a mathematical formula}RED=L1, {a mathematical formula}CAR=L2∧L3∧L4, where {a mathematical formula}CAR=&lt;(1,1),Hλ→C,U(0,1)&gt; with {a mathematical formula}λ→C=(0.33,0.33,0.33) so that {a mathematical formula}μC(Y→)=0.33μL2(Y2)+0.33μL3(Y3)+0.33μL4(Y4). We may combine {a mathematical formula}θ=RED∧CAR in the space {a mathematical formula}{0,1}2 with prototype (1, 1), weight vector {a mathematical formula}λ=(0.5,0.5) and boundary distribution {a mathematical formula}δ=U(0,1). Then{a mathematical formula}</paragraph><paragraph>Two objections might be made to this approach. Firstly, the combination could be of the form ‘apple green’, where the resulting concept should be a colour, rather than an apple. The combination mechanism given in the example would return a green apple, rather than a colour. Secondly, as described here, this approach does not take into account cases like ‘red wine’, where the meaning of ‘red’ has been changed by the concept it is attached to. To answer the first objection, note that the resulting concept from a combination like ‘apple green’, or ‘green apple’ is indicated by the part of speech that each word belongs to. In English, this is indicated by word order, so we know that in the first case the resulting concept should be a colour, and in the second case the resulting concept should be a fruit. In the combination of properties and concepts, the resulting concept will be the original concept modified in the specific domain to which the property applies. So, in the case of ‘green apple’, the resulting concept is an apple in which the colour domain has been modified. In the case of ‘apple green’, we would choose just the domains from ‘apple’ that are relevant to the domains of ‘green’, i.e. colour, and form the combination ‘apple green’ using the approach outlined in Example 12. This approach is similar to that outlined by Gärdenfors [19].</paragraph><paragraph>In the second objection, the property ‘red’ in the combination ‘red wine’ refers to a particular set of shades of red which are not at all prototypical. Gärdenfors [19] has again addressed this, using the idea of contrast classes, which map the whole domain onto a subset of the domain determined by the that class. So in the case of wine, there is a range of distinctive shades of wine. When the whole colour domain is mapped down to this range, the places that the ‘red’ and the ‘white’ labels inhabited in the original labelling should now map onto the ‘red’ and the ‘white’ areas in the range of wine colours. Our approach is slightly different. As explained in the first objection, the concept ‘wine red’ can be obtained by forming a combination of ‘wine coloured’ and ‘red’. The ‘red’ in ‘red wine’ is then understood to be an instance of ‘wine red’, rather than every day ‘red’. Although this argument might appear to be circular, we argue that it is not, since the first time someone encounters the concept ‘red wine’, a mistake could be made about what colour the drink would be. Only after learning that the label ‘red’ in ‘red wine’ refers to the darkest colour of wine can they use it properly. This can be seen as an instance where the meaning of the term red, when applied to wine, is determined by convention rather than a systematic combination.</paragraph><paragraph>Furthermore, although when introducing this framework we have made a distinction between properties and concepts, this distinction is not really important in actually carrying out a combination. Increasingly complex concepts can be created and combined with other complex concepts or alternatively with simple properties utilising a single domain. The novelty of this approach is that the combination mechanism is itself characterised by a conceptual space. As a special case our framework entails that concepts may be characterised as weighted sums of properties, a characterisation of concepts proposed in [19], [51]. Hampton shows that a majority of his data may be explained by a simple multilinear regression, which can be modelled as in the example above. However, he also notes other non-compositional behaviours, which are key aspects of how humans use concepts. We show how our framework can model some of these non-compositional behaviours in the next section.</paragraph></section><section label="4.3.3"><section-title>Non-compositional behaviours</section-title><paragraph>In addition to the general rule that the importance of attributes in the conjunction is the weighted sum of the importance of attributes in the constituent concepts, Hampton identifies four additional behaviours: necessity and impossibility are preserved; attribute loss or emergence is observed; conjunction is not commutative; and dominance effects are observed. This section will discuss the capability of our model to capture these behaviours.</paragraph><paragraph>We consider firstly the ideas of necessity and impossibility. Hampton finds that necessity of dimensions is preserved, so that if an attribute is deemed necessary in a constituent concept, it is also deemed necessary in the conjunction. As outlined in section 4.2, necessity and impossibility are essentially the highest and lowest weights that can be assigned to an attribute in Hampton's experiments. Recall that we view the impossibility of an attribute {a mathematical formula}Li as equivalent to the necessity of {a mathematical formula}¬Li, and we measure the necessity of an attribute or its negation using the notion of necessity from possibility theory as outlined in Definition 13.</paragraph><paragraph>We also introduce an alternative definition of the importance of an attribute, consistent with our random set based conceptual models. Rather than simply consider the weight {a mathematical formula}λ→ to be the importance of the attribute, we use the idea of necessity from possibility theory [16]. Within possibility theory, the possibility {a mathematical formula}π(s) of a state of affairs s indicates to what extent this state of affairs is possible. {a mathematical formula}π(s) is a measure on the interval {a mathematical formula}[0,1]. The possibility of a set of states A is then defined in [16] to be:{a mathematical formula}</paragraph><paragraph>The necessity of an event A is then {a mathematical formula}N(A)=1−Π(Ac), i.e. 1 − the possibility that A does not occur.</paragraph><paragraph>Within our model, a state s is considered to be a particular point {a mathematical formula}X→ in the binary combination space {a mathematical formula}{0,1}n and {a mathematical formula}π(X→):=μθ(X→). To compute the necessity of a dimension i to a concept {a mathematical formula}θ=&lt;P,Hλ→,δ&gt;, where {a mathematical formula}P⊆{0,1}n, we consider the necessity of set {a mathematical formula}Si={X→:Xi=pi}, i.e. the set of all points that have equal value to the prototype on dimension i.{a mathematical formula} where {a mathematical formula}Nθε is the neighbourhood of θ as defined in section 3. It may be the case that P contains both points with value 0 on dimension i and points with value 1 on dimension i. In this case we say that {a mathematical formula}Si=∅, since {a mathematical formula}Si must satisfy {a mathematical formula}Si={X→:Xi=0∧Xi=1}.</paragraph><paragraph label="Definition 13">Necessity of a dimensionGiven {a mathematical formula}θ=&lt;P,Hλ→,δ&gt;, the necessity of a dimension i to θ is defined as the necessity of the set {a mathematical formula}Si={X→:Xi=pi}, where {a mathematical formula}pi is the ith dimension of {a mathematical formula}{0,1}n, by {a mathematical formula}N(Si)=δ({ε:Nθε⊆Si}).</paragraph><paragraph>If P contains both vectors with value 0 on dimension i and vectors with value 1 on dimension i, then {a mathematical formula}N(Si)=0, since {a mathematical formula}Si=∅ and therefore {a mathematical formula}N(Si)=δ({ε:Nθε⊆Si})=P(Nθε⊆∅)=0.</paragraph><paragraph label="Proof">For{a mathematical formula}α=&lt;P,Hλ→,δ&gt;,{a mathematical formula}N(Si)=1−Δ(λi).{a mathematical formula}N(Si)=P(Nαε⊆Si)=P(ε&lt;λi)=1−Δ(λi).  □</paragraph><paragraph>In particular, when {a mathematical formula}ε∼U(0,λT), {a mathematical formula}N(Si)=λiλT.</paragraph><paragraph>We have introduced the concept of the necessity of a dimension in order to account for some of the non-compositional aspects of conjunctive combinations of concepts. To examine the necessity of a dimension in a conjunction of two compound concepts, we relate the distribution of the threshold ε in the higher level binary space to the neighbourhood in the first level binary space.</paragraph><paragraph>We begin by defining the neighbourhood of a conjunction of two concepts. Suppose that two concepts θ and φ are combined in the second level space {a mathematical formula}{0,1}2, with weight vector {a mathematical formula}w→=(w1,w2) where {a mathematical formula}w1 is associated with θ and {a mathematical formula}w2 with φ. Suppose {a mathematical formula}w2≤w1. Now, if the threshold ε in the second level space is less than {a mathematical formula}w2, then an element {a mathematical formula}X→ of the first level binary space must belong to the neighbourhoods of both concepts θ and φ, i.e. {a mathematical formula}X→∈Nθεθ∩Nφεφ. When {a mathematical formula}w2≤ε≤w1, the points within ε in the second level space are {a mathematical formula}{(1,1),(1,0)}, so {a mathematical formula}X→ must belong to {a mathematical formula}Nθεθ, but does not have to belong to {a mathematical formula}Nφεφ. When {a mathematical formula}w1≤ε≤wT, where {a mathematical formula}wT=w1+w2, {a mathematical formula}X→ may belong to either neighbourhood, i.e. {a mathematical formula}X→∈Nθεθ∪Nφεφ. This is summarised in the following definition:</paragraph><paragraph label="Definition 15">For a conjunction {a mathematical formula}θ∧φ=&lt;{(1,1)},Hw→,δ&gt;, where {a mathematical formula}w→=(w1,w2) and {a mathematical formula}w2≤w1, the neighbourhood R of {a mathematical formula}θ∧φ is:{a mathematical formula}</paragraph><paragraph>This allows us to relate the necessity of a dimension to the concept {a mathematical formula}θ∧φ to the necessity of the dimension to the constituent concepts θ, φ since {a mathematical formula}Nθ∧φ(Si)=δθ∧φ(εθ,εφ:R⊂Si).</paragraph><paragraph label="Theorem 16">For a conjunction of compound concepts{a mathematical formula}θ∧φ=&lt;{(1,1)},Hw→,δ&gt;, where θ, φ are defined as forTheorem 10{a mathematical formula}</paragraph><paragraph label="Proof">{a mathematical formula} □</paragraph><paragraph label="Corollary 17">If{a mathematical formula}δ=Uniform(0,wT)then{a mathematical formula}Nθ∧φ(Si)=w1wTNθ(Si)+w2wTNφ(Si).</paragraph><paragraph label="Proof">{a mathematical formula}δ=Uniform(0,wT)⟹Δ(w1)=w2wT and {a mathematical formula}Δ(w1)=w1wT{a mathematical formula} □</paragraph><paragraph>This allows us to choose a boundary distribution δ which gives us the property that high necessity is carried through into the conjunction. This is illustrated in the following example.</paragraph><paragraph label="Example 18">Suppose that {a mathematical formula}Nθ(Si)=0.9, {a mathematical formula}Nφ(Si)=0.6, {a mathematical formula}w1=0.2, {a mathematical formula}w2=0.8. The weighted sum of the necessity of attribute i is then {a mathematical formula}0.2×0.9+0.8×0.6=0.66. Now, if {a mathematical formula}δ=Uniform(0,wT) then {a mathematical formula}Nθ∧φ(Si) is equal to the weighted sum as shown in Corollary 17 and as reported by Hampton. However, if ε is distributed over a narrower range than the whole binary space, for example {a mathematical formula}ε∼Uniform(0,0.5) then:{a mathematical formula} which is closer to 0.9, even though less weight is given to that part of the conjunction. The necessity of this attribute has therefore been, if not entirely preserved, at least emphasised in this model.</paragraph><paragraph>The fourth aspect Hampton notes is that attribute loss or emergence is observed. When the distribution of ε is defined over a narrower range than {a mathematical formula}[0,wT], the importance of attributes in the combined concept is higher than the importance of attributes in either constituent concept, as seen in Fig. 10. If the distribution of ε is over a wider range than the whole space, the importance can be lower. However, this does not account for how both phenomena can be observed together. In the example discussed and in Fig. 10, ε has a uniform distribution. Further work to investigate the behaviour of {a mathematical formula}Nθ∧φ(Si) is needed.</paragraph><paragraph>A further aspect uncovered in Hampton's results is that in general, the qualifying noun, i.e. the second concept in the conjunction, is given more weight than the first. Within our model, we can easily take account of this by setting weights in the binary combination space appropriately.</paragraph><paragraph>Lastly, Hampton finds that concepts with more attributes tend to have higher weightings. This can also be accounted for by weighting concepts θ relative to the cardinality of {a mathematical formula}E(Pθ).</paragraph></section></section><section label="4.4"><section-title>Other aspects of human concept use</section-title><paragraph>We give here some examples of how other cases of non-compositionality can be accounted for within our framework. A key example is the conjunction fallacy, in which the probability of an entity belonging to a conjunction of concepts is judged greater than the probability of that entity belonging to just one of the concepts. The example often cited is that of Linda the feminist bank teller, introduced by Tversky and Kahneman [47]. Linda is characterised as follows: Linda is 31 years old, single, outspoken, and very bright. She majored in philosophy. As a student, she was deeply concerned with issues of discrimination and social justice, and also participated in anti-nuclear demonstrations.</paragraph><paragraph>When asked to rank the probability of the statements 1) ‘Linda is a bank teller’ and 2) ‘Linda is a bank teller and is active in the feminist movement’, the majority of people rank 2) as more probable than 1), in violation of classical probability. This fallacy has been shown to dissolve when posed in frequentist terms [12]. The frequentist terms are given in the following way. Rather than being asked to rank the probability of Linda being a bank teller, participants are asked to consider 100 people who can be described as above, and decide how many of that number are bank tellers, and then how many of the 100 are feminist bank tellers. When described in this way, participants no longer give contradictory answers. However, the fallacy remains when asked for probability judgements. Within our framework we can consider the membership in a concept as the probability that a person would assert that concept to describe an object. As we see in the example below, our approach to membership in a conjunctive concept does not entail that membership in the conjunction is always less than or equal to membership in each of the constituent concepts.</paragraph><paragraph label="Example 19">Suppose T= ‘bank teller’ is defined as a conjunction of {a mathematical formula}L1= ‘good with numbers’, {a mathematical formula}L2= ‘medium intelligence’, with {a mathematical formula}PT=(1,1), {a mathematical formula}λ→T=(0.5,0.5), {a mathematical formula}εT∼U(0,1) and F= ‘feminist’ is defined as a conjunction of {a mathematical formula}L3= ‘outspoken’, {a mathematical formula}L4= ‘concerned with issues of discrimination and social justice’ {a mathematical formula}PF=(1,1), {a mathematical formula}λ→F=(0.5,0.5), {a mathematical formula}εF∼U(0,1). Suppose we combine T and F in the space {a mathematical formula}{0,1}2 with prototype {a mathematical formula}P=(1,1), weight vector {a mathematical formula}λ→=(0.5,0.5), threshold {a mathematical formula}ε∼U(0,1). Say {a mathematical formula}μL1(Linda)=0.5{a mathematical formula}μL2(Linda)=0.25, {a mathematical formula}μL3(Linda)=1, {a mathematical formula}μL4(Linda)=1 Then:{a mathematical formula} We argue here that rather than committing a fallacy, the participants are generating a new concept ‘feminist bank teller’ with a new prototype. So here the additional characteristics associated with being a feminist increase the membership of Linda in the conjunctive concept.</paragraph><paragraph>Another of the classic counterexamples relates to the fact that a goldfish, or a guppy, is a better example of a pet fish than it is of either a pet or of a fish, as introduced by Osherson and Smith [40]. The following example shows how we begin to address this.</paragraph><paragraph label="Example 20">Suppose concept {a mathematical formula}PET= ‘pet’ is defined by the conjunction of properties {a mathematical formula}L1= ‘lives in house’, {a mathematical formula}L2= ‘furry’, and {a mathematical formula}FISH= ‘fish’ is defined by the conjunction of properties {a mathematical formula}L3= ‘lives in water’, {a mathematical formula}L4= ‘scaly’. We firstly form two binary combination spaces {a mathematical formula}ΩPET={0,1}2 for pet and {a mathematical formula}ΩFISH={0,1}2 for fish, and give each a weight vector, with say {a mathematical formula}λ→PET=[0.6,0.4] and {a mathematical formula}λ→FISH=[0.5,0.5].In each case the threshold in the binary space is distributed according to {a mathematical formula}ε=U(0,1) so that {a mathematical formula}PET=&lt;[1,1],H[0.6,0.4],U(0,1)&gt; and {a mathematical formula}μPET(Y→)=0.6μL1(Y1)+0.4μL2(Y2). Also {a mathematical formula}FISH=&lt;[1,1],H[0.5,0.5],U(0,1)&gt; and {a mathematical formula}μFISH(Y→)=0.5μL3(Y3)+0.5μL4(Y4). We then expand each of the spaces {a mathematical formula}ΩPET and {a mathematical formula}ΩFISH to {a mathematical formula}{0,1}4 and expand the prototypes accordingly, setting the additional dimension weights to zero as described in Theorem 8. Suppose a goldfish (g) has membership values in the individual labels as follows: {a mathematical formula}μL1(g)=1, {a mathematical formula}μL2(g)=0, {a mathematical formula}μL3(g)=1, {a mathematical formula}μL4(g)=0.25. This gives:{a mathematical formula}Suppose the two concepts PET and {a mathematical formula}FISH are combined in a higher level binary combination space with prototype {a mathematical formula}P=(1,1), dimension weights {a mathematical formula}λ→=[0.5,0.5] and {a mathematical formula}ε∼U(0,1.25). Now, from section 4.3.2 we have{a mathematical formula} where {a mathematical formula}X→∈{0,1}4, i.e. the combination space at Level 1 in Fig. 8, {a mathematical formula}Z→∈{0,1}2, i.e. the combination space at Level 2 in Fig. 8, and {a mathematical formula}gi refers to the ith dimension of ‘goldfish’, {a mathematical formula}i=1,...,4. Recall that {a mathematical formula}P(Xi|gi)=μLi(g) if {a mathematical formula}Xi=1 and {a mathematical formula}P(Xi|gi)=1−μLi(g) if {a mathematical formula}Xi=0. Looking at the values of {a mathematical formula}μLi(g), we see that we only need to sum over two values of {a mathematical formula}X→, namely {a mathematical formula}X→0=(1,0,1,0) and {a mathematical formula}X→1=(1,0,1,1) (since in all other cases {a mathematical formula}∏i=1nP(Xi|gi)=0). We consider each of these two vectors in turn, firstly {a mathematical formula}X→=X→0. The product over individual labels, {a mathematical formula}∏i=1nP(X0,i|gi)=∏j:X0,j=1μLj(g)∏k:X0,k=0(1−μLk(g))=0.75. Also,{a mathematical formula}Now consider the sum over {a mathematical formula}Z→ in the Level 2 space:{a mathematical formula}Similarly, {a mathematical formula}∏i=1nP(X1,i|gi)=0.25 and {a mathematical formula}∑Z→μPET∧FISH(Z→)∏i=12P(Zi|X→1)=0.84, giving{a mathematical formula}Also, consider a cat, for whom {a mathematical formula}μL1(cat)=1, {a mathematical formula}μL2(cat)=1, {a mathematical formula}μL3(cat)=0, {a mathematical formula}μL4(cat)=0. We want a cat to be a worse example of a pet fish than a goldfish is. Then {a mathematical formula}μPET∧FISH(cat)=0.6&lt;μPET∧FISH(g). Similarly a cod with {a mathematical formula}μL1(cod)=0, {a mathematical formula}μL2(cod)=0, {a mathematical formula}μL3(cod)=1, {a mathematical formula}μL4(cod)=1 has membership {a mathematical formula}μPET∧FISH(cod)=0.6&lt;μPET∧FISH(g).</paragraph><paragraph>There are a couple of points to mention regarding this treatment of the pet fish problem. Firstly, the result is reliant on the values chosen for e.g. {a mathematical formula}λ→PET. Choosing {a mathematical formula}λ→PET=[0.75,0.25] with the other values the same does not produce the same set of inequalities. Further analysis of the model is needed to elucidate these limitations, and modelling with actual data would be useful. Secondly, consider an entity for which {a mathematical formula}μLi(Yi)=0∀i, i.e. all attributes for either pet or fish are lacking. This might be a tree, for example. With the choice of {a mathematical formula}ε∼U(0,1.25), the membership {a mathematical formula}μPET∧FISH(tree)=0.2, when this value should clearly be 0, since a tree is not a pet fish in any way. This objection may be dealt with, however, by choosing a distribution for ε for which {a mathematical formula}Δ(1)=0. This could be done piecewise, or by choosing a distribution that has this property such as a {a mathematical formula}Beta(2,1) distribution. Lastly, an entity for which {a mathematical formula}μLi(Yi)=1∀i will have a higher membership in ‘pet fish’ than the goldfish, since the prototype for a pet fish which we have specified here is something that lives in the house and is furry and lives in water and is scaly. The issue here is of interaction between dimensions, such as ‘furry’ and ‘scaly’. We have not touched upon this type of interaction between dimensions in any examples thus far, and this is an area for further research.</paragraph></section></section><section label="5"><section-title>Discussion and future directions</section-title><paragraph>We have proposed here a formalism extending Gärdenfors' conceptual spaces theory, so as to incorporate the vagueness of natural language using a random set based prototype model. The framework we propose gives a mechanism for forming concepts as a combination of properties from integral domains. The innovation we have introduced here is that these properties are mapped into a binary combination space which itself is treated as a conceptual space. We have shown that the idea of concepts as weighted sums of properties, proposed by Gärdenfors and Zadeh, arises naturally as a special case of our framework, namely when the threshold of the concept in the binary combination space is uniformly distributed across the whole space (Theorem 4). We also characterise the combination weights as the necessity of a property to the concept, using the technical definition of necessity from possibility theory.</paragraph><paragraph>The framework we propose is hierarchical. Therefore, combinations may consist of multiple properties, as described above, or, as we describe in section 4.3.2, of two or more concepts which are themselves defined as combinations of properties. Again, under certain specific conditions, we can recover the results reported in [22] that the importance of properties in a conjunction of concepts is a weighted sum of the importance of the properties to the individual concepts. We also show how our framework can be applied to property–concept combination. In fact, the distinction between properties and concepts is somewhat artificial, and the conjunctive combination of any sort of concept can be performed within this framework.</paragraph><paragraph>A key element of human concept use, however, is that there are various instances where concepts cannot be adequately characterised as a simple weighted sum of properties. We can account for this by using our more general model, in which the threshold in the binary combination space does not have to be distributed according to the uniform distribution. A key result is that necessity and impossibility are carried through from constituent concepts into the combined concept. We have shown in Example 18 how our characterisation of the importance of an attribute in terms of the concept of necessity from possibility theory allows us to take account of this phenomenon. We have further shown how attribute loss and emergence, characterised as the diminished or increased importance of an attribute to a combined concept, may occur, as illustrated in Fig. 10.</paragraph><paragraph>We have also explained how non-commutativity and dominance effects may be modelled, by setting the weights used in the binary combination space. Hampton finds that in general, the second noun in the conjunction is given more weight than the first. This aspect could simply be built in to the weighting. Dominance effects are seen when one concept has more features than the other. Again, weightings could take this into account. We have given examples to show how two of the key problems in this area may be accounted for. These are the conjunction fallacy and the guppy effect, illustrated in Example 19, Example 20 respectively.</paragraph><paragraph>We therefore argue that our framework is better able to account for key aspects of human use of concepts than standard conceptual spaces approaches [2], [6], which do not attempt to account for these non-compositional features. In contrast, the quantum approach has shown examples of how to account for this type of problem, and has done so successfully. We argue, however, that our approach is more conceptually straightforward than the quantum approach, with the formulation of the latter requiring high dimensional Hilbert spaces and the mathematics of quantum mechanics.</paragraph><paragraph>At present, our model does not distinguish between membership in and typicality to a concept. There is certainly a difference between these two notions, and an effective model of concepts should elucidate how these two ideas can be unified, or accounted for. Hampton [24] argues that membership and typicality may be subsumed within one approach, on the basis that membership may be decided by applying a suitable threshold to typicality. This type of approach could easily be incorporated into our model. We might ask where the threshold should be placed. However, we could simply place the threshold at 0.5 everywhere and then tune the weights of the model, rather than having separate thresholds for each concept.</paragraph><paragraph>The approach we have proposed here is particularly well-suited to concepts that can be described via a collection of attributes. However, some types of concepts are less well-suited to this type of description. For example, some concepts may be defined crisply in terms of necessary and sufficient conditions, such as the concept of even numbers. Another example, given by Barsalou [8] is that of goal-derived categories. These are defined by the extent to which they allow a goal to be reached. So attributes for ‘things to eat on a diet’ has as an ideal ‘foods with zero calories’. These tend not to be central to a concept, although they could still be seen as prototypical in some way. Another example given is that of ‘ad-hoc categories’, in particular ‘things to sell at a garage sale’. Barsalou argues that these cannot really be defined by a specific set of attributes.</paragraph><paragraph>With regard to goal-derived categories, we argue that to a certain extent, we can view the ideals as attributes to be achieved. Therefore, these could still be used as dimension in a conceptual space. Ideals may not be central tendencies, however, we do not require this in our model, since typicality to a concept is defined via a probability distribution based on distance to a prototype. Simply setting the probability to 0 on one side of the prototype allows for non-central ideals. However, the example of ad-hoc categories does suggest further work. We may view categories defined via attributes as conjunctive in some sense: we use conjunctions of attributes. However ad-hoc categories are defined disjunctively: this old bicycle or these tins of paint etc. A movement from disjunctive to conjunctively defined categories might be viewed as a type of learning: children might see the concept ‘cat’ as defined by ‘Tibbles or Patch’, but later extract the attributes that allow generalisation. This would be an interesting area for further work. In particular, when using a semantic vector space approach, for example in statistical analysis of text corpora, the vectors created are formed of a mixture of instances of the concept, that would go into a disjunctive definition of the concept, and attributes, that would go into a conjunctive definition. An analysis of when a disjunctive or conjunctive definition is more appropriate, and the interaction between the two in, for example, learning concepts, would be of interest.</paragraph><paragraph>A further area for investigation would be to look at the questions raised by [1], [27] concerning privative adjectives, i.e., those where the application of the adjective entails that the adjective-noun combination is no longer an instance of the noun. Examples are ‘artificial’, ‘former’, ‘fake’, and so on. Using the combination of the conjunctive and the hedged approach given in [36] might be of use here, to develop these more complex ‘type 2’ hedges, as Lakoff calls them [30]. An analysis of the effects of the hedges might be to say, for example, that the hedge ‘fake’ increases the weight of those attributes that are visually important, and decreases the weight of the other most important attributes. An alternative approach would be to tag ‘definitional’ attributes that the hedge ‘fake’ can then negate. More generally, the semantic differences between different types of adjectives that [41] discuss should be considered in further work. Adjectives that consist of modifying one property of a concept are well described by our model. Some of the more complicated adjectives such as ‘abusive’ may be more difficult to describe. Part of the work must be done by giving such an adjective an adequate representation in a conceptual space. Then the application of the adjective may consist of adding domains to its noun, or modifying existing domains.</paragraph><paragraph>The potential for application of this model should be discussed. As presented here, in its full generality, the model has a large number of free parameters, and a number of these need to be pinned down before they can be used. Various choices must be made before the model can be applied. For example, the type of threshold distribution is likely to be very dependent on the type of concept or property that is being described. Further, the type of normalisation that we might want to apply to the dimensions must be carefully chosen or learned from the data. We give here a number of possible applications of the model and describe how the parameters can be limited in those cases.</paragraph><paragraph>Firstly, the model can be applied as a model of concept combination in examining psychological data. In [34] the model is applied to a range of data from [24], [23], [22]. An example of the type of data is as follows. Participants were asked to rate the membership of instances such as ‘Penguin’, ‘Dog’, ‘Cockatoo’, and so on in concepts and their combinations – in this example, the concepts would be ‘Birds’, ‘Pets’, ‘Birds which are Pets’, and ‘Pets which are Birds’.</paragraph><paragraph>Hampton's original analysis finds that mean typicality ratings can be systematically predicted using a multilinear regression. We apply the same analysis to the mean membership ratings of the items. The model we use maps each of the constituent concepts into a binary combination space {a mathematical formula}{0,1}2. Each dimension of this space is weighted, with the weights summing to 1, resulting in weight vector {a mathematical formula}(λ,1−λ). The threshold ε in the binary space is distributed uniformly, {a mathematical formula}ε∼U(0,b). We therefore fit just two parameters λ and b. This gives us the expression{a mathematical formula}</paragraph><paragraph>Hampton uses a multilinear regression given by:{a mathematical formula}</paragraph><paragraph>We therefore use fewer parameters than does Hampton to fit this data. The fit we achieve is comparable to Hampton's when using Akaike's ‘An Information Criterion’ for small samples ({a mathematical formula}AICc).</paragraph><paragraph>Another way to reduce the number of parameters is to make the simplifying assumption that the threshold in the higher level space is distributed according to the assumptions of Theorem 4, i.e., that the combination of concepts is simply a weighted sum of membership values. This assumption was used in investigating the adoption of conjunctive concepts in a multi-agent simulation of language evolution [34], [35]. In this application, agents are equipped with a range of basic concepts which they use to communicate about points in a conceptual space. Via iterated dialogues, agents converge onto a shared set of dimension weights that characterise the space. The weights to which agents converge is determined by the distribution of objects within the conceptual space.</paragraph><paragraph>Applications of the theory might also be possible in online classification tasks, for example in film. In an analogue to the ‘pet fish’ phenomenon, a film might not have typical characteristics of a horror film, nor of a comedy film, but be prototypical of a ‘comedy horror’. In this cases, a weighted sum formulation on its own is not able to account for these phenomena. The fact that comedies and horror do not share many characteristics might be taken to be diagnostic of the fact that ‘non-compositional’ effects may be seen here. Further, we have not yet developed a theory for how to deal with contradictory attributes. These will be key to how non-compositional effects arise, and a simple weighted sum combination does not explain these in a satisfactory manner.</paragraph><paragraph>Within the framework we have discussed conjunction and disjunction of nouns and adjectives. There are, of course, many other operators and word types that should be captured in a full account of concepts. Gärdenfors and Warglien have started to develop conceptual spaces for verbs [21], [48], and Gärdenfors has begun the development of a semantics for conceptual spaces [20]. Other approaches to developing a full semantics use the notion of a semantic vector space, based on text corpora [11], [38]. Our model could be extended to include other word types and composition types. Within our framework we have explicitly avoided the problem of conflicting prototypes. However, this is an area which must be developed. One important aspect of conflicting prototypes is that having conflicting attributes allows interesting phenomena to emerge. This goes hand in hand with another aspect that we have not discussed: the need for some sort of inference system.</paragraph><paragraph>A key element of our framework is the weights given to dimensions in the combination space. Results in [35] and ongoing work show that within a multi-agent model of language users, these weights can be related to the distribution of elements in the conceptual space, explaining why and how different dimensions should have different weights.</paragraph><paragraph>Further research will investigate how attributes may affect one another. For instance, in the pet fish example, the attributes ‘furry’ and ‘scaly’ might interact since they are, to some extent, incompatible. This is not examined so far, and indeed we require that the constituent concepts may not have contradictory prototypes. Further developing the framework for these cases is likely to allow even more effective modelling of non-compositional effects.</paragraph><section-title>Acknowledgements</section-title></section></content><acknowledgements><paragraph>Martha Lewis was supported by EPSRC Grant No. EP/E501214/1. Due to the nature of the research described in the paper there is no associated data.</paragraph></acknowledgements><references><reference label="[1]"><authors>Nabil Abdullah,Richard A. Frost</authors><title>Adjectives: a uniform semantic approach</title><host>Advances in Artificial Intelligence(2005)Springer pp.330-341</host></reference><reference label="[2]"><authors>Benjamin Adams,Martin Raubal</authors><title>A metric conceptual space algebra</title><host>Spatial Information Theory(2009)Springer pp.51-68</host></reference><reference label="[3]"><authors>D. Aerts,L. Gabora</authors><title>A theory of concepts and their combinations I: the structure of the sets of contexts and properties</title><host>Kybernetes34 (1/2)(2005) pp.167-191</host></reference><reference label="[4]"><authors>Diederik Aerts</authors><title>Quantum structure in cognition</title><host>J. Math. Psychol.53 (5)(2009) pp.314-348</host></reference><reference label="[5]"><authors>Diederik Aerts,Liane Gabora,Sandro Sozzo</authors><title>Concepts and their dynamics: a quantum-theoretic modeling of human thought</title><host>Top. Cogn. Sci.5 (4)(2013) pp.737-772</host></reference><reference label="[6]"><authors>Janet Aisbett,Greg Gibbon</authors><title>A general formulation of conceptual spaces as a meso level representation</title><host>Artif. Intell.133 (1)(2001) pp.189-232</host></reference><reference label="[7]"><authors>Marco Baroni,Roberto Zamparelli</authors><title>Nouns are vectors, adjectives are matrices: representing adjective-noun constructions in semantic space</title><host>Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing(2010)Association for Computational Linguistics pp.1183-1193</host></reference><reference label="[8]"><authors>Lawrence W. Barsalou</authors><title>Ideals, central tendency, and frequency of instantiation as determinants of graded structure in categories</title><host>J. Exp. Psychol. Learn. Mem. Cogn.11 (4)(1985) pp.629-</host></reference><reference label="[9]"><authors>Peter D. Bruza,Kirsty Kitto,B. Ramm,Laurianne Sitbon,D. Song,S. Blomberg</authors><title>Quantum-like non-separability of concept combinations, emergent associates and abduction</title><host>Log. J. IGPL20 (2)(2012) pp.445-457</host></reference><reference label="[10]"><authors>John A. Bullinaria,Joseph P. Levy</authors><title>Extracting semantic representations from word co-occurrence statistics: a computational study</title><host>Behav. Res. Methods39 (3)(2007) pp.510-526</host></reference><reference label="[11]">Bob Coecke,Mehrnoosh Sadrzadeh,Stephen ClarkMathematical foundations for a compositional distributional model of meaningarXiv preprint<host>arXiv:1003.4394(2010)</host></reference><reference label="[12]"><authors>Leda Cosmides,John Tooby</authors><title>Are humans good intuitive statisticians after all? Rethinking some conclusions from the literature on judgment under uncertainty</title><host>Cognition58 (1)(1996) pp.1-73</host></reference><reference label="[13]"><authors>Lieven Decock,Igor Douven</authors><title>What is graded membership?</title><host>Noûs48 (4)(2014) pp.653-682</host></reference><reference label="[14]">Igor Douven,Lieven DecockWhat verities may beMind (2015)in press</reference><reference label="[15]"><authors>D. Dubois,H. Prade</authors><title>The three semantics of fuzzy sets</title><host>Fuzzy Sets Syst.90 (2)(1997) pp.141-150</host></reference><reference label="[16]"><authors>Didier Dubois,Henri Prade</authors><title>Possibility Theory</title><host>(1988)Springer</host></reference><reference label="[17]"><authors>Kit Fine</authors><title>Vagueness, truth and logic</title><host>Synthese30 (3)(1975) pp.265-300</host></reference><reference label="[18]"><authors>M. Freund</authors><title>On the notion of concept I</title><host>Artif. Intell.172 (4–5)(2008) pp.570-590</host></reference><reference label="[19]"><authors>P. Gärdenfors</authors><title>Conceptual Spaces: The Geometry of Thought</title><host>(2004)The MIT Press</host></reference><reference label="[20]"><authors>Peter Gärdenfors</authors><title>The Geometry of Meaning: Semantics Based on Conceptual Spaces</title><host>(2014)MIT Press</host></reference><reference label="[21]"><authors>Peter Gärdenfors,Massimo Warglien</authors><title>Using conceptual spaces to model actions and events</title><host>J. Semant. (2012)ffs007</host></reference><reference label="[22]"><authors>J. Hampton</authors><title>Inheritance of attributes in natural concept conjunctions</title><host>Mem. Cogn.15 (1)(1987) pp.55-71</host></reference><reference label="[23]"><authors>J. Hampton</authors><title>Disjunction of natural concepts</title><host>Mem. Cogn.16 (6)(1988) pp.579-591</host></reference><reference label="[24]"><authors>J. Hampton</authors><title>Overextension of conjunctive concepts: evidence for a unitary model of concept typicality and class inclusion</title><host>J. Exp. Psychol. Learn. Mem. Cogn.14 (1)(1988) pp.12-</host></reference><reference label="[25]"><authors>J. Hampton</authors><title>Conceptual combinations and fuzzy logic</title><host>R. BelohlavekG.J. KlirConcepts and Fuzzy Logic(2011)The MIT Press</host></reference><reference label="[26]"><authors>James A. Hampton</authors><title>Testing the prototype theory of concepts</title><host>J. Mem. Lang.34 (5)(1995) pp.686-708</host></reference><reference label="[27]"><authors>H. Kamp,B. Partee</authors><title>Prototype theory and compositionality</title><host>Cognition57 (2)(1995) pp.129-191</host></reference><reference label="[28]"><authors>J.A.W. Kamp</authors><title>Two theories about adjectives</title><host>Edward KeenanFormal Semantics of Natural Language(1975)Cambridge University PressCambridge pp.123-155</host></reference><reference label="[29]"><authors>Sarit Kraus,Daniel Lehmann,Menachem Magidor</authors><title>Nonmonotonic reasoning, preferential models and cumulative logics</title><host>Artif. Intell.44 (1)(1990) pp.167-207</host></reference><reference label="[30]"><authors>G. Lakoff</authors><title>Hedges: a study in meaning criteria and the logic of fuzzy concepts</title><host>J. Philos. Log.2 (4)(1973) pp.458-508</host></reference><reference label="[31]"><authors>Thomas K. Landauer,Susan T. Dumais</authors><title>A solution to plato's problem: the latent semantic analysis theory of acquisition, induction, and representation of knowledge</title><host>Psychol. Rev.104 (2)(1997) pp.211-</host></reference><reference label="[32]"><authors>J. Lawry</authors><title>Modelling and Reasoning with Vague Concepts, vol. 12</title><host>(2006)Springer</host></reference><reference label="[33]"><authors>J. Lawry,Y. Tang</authors><title>Uncertainty modelling for vague concepts: a prototype theory approach</title><host>Artif. Intell.173 (18)(2009) pp.1539-1558</host></reference><reference label="[34]">Martha LewisModelling compositionality of vague conceptsPhD thesis<host>(2015)University of Bristol</host></reference><reference label="[35]"><authors>Martha Lewis,Jonathan Lawry</authors><title>Emerging dimension weights in a conceptual spaces model of concept combination</title><host>Proceedings of the 50th Anniversary Convention of the AISB(2014)Society for the Study of Artificial Intelligence and the Simulation of Behaviour</host></reference><reference label="[36]"><authors>Martha Lewis,Jonathan Lawry</authors><title>A label semantics approach to linguistic hedges</title><host>Int. J. Approx. Reason.55 (5)(2014) pp.1147-1163</host></reference><reference label="[37]"><authors>Kevin Lund,Curt Burgess</authors><title>Producing high-dimensional semantic spaces from lexical co-occurrence</title><host>Behav. Res. Methods Instrum. Comput.28 (2)(1996) pp.203-208</host></reference><reference label="[38]"><authors>Jeff Mitchell,Mirella Lapata</authors><title>Composition in distributional models of semantics</title><host>Cogn. Sci.34 (8)(2010) pp.1388-1429</host></reference><reference label="[39]"><authors>Richard Montague</authors><title>The Proper Treatment of Quantification in Ordinary English</title><host>(1973)Springer</host></reference><reference label="[40]"><authors>D.N. Osherson,E.E. Smith</authors><title>On the adequacy of prototype theory as a theory of concepts</title><host>Cognition9 (1)(1981) pp.35-58</host></reference><reference label="[41]">Victor Raskin,Sergei NirenburgLexical semantics of adjectivesNew Mexico State University, Computing Research Laboratory Technical Report, MCCS-95-288<host>(1995)</host></reference><reference label="[42]"><authors>John T. Rickard,Janet Aisbett,Greg Gibbon</authors><title>Reformulation of the theory of conceptual spaces</title><host>Inf. Sci.177 (21)(2007) pp.4539-4565</host></reference><reference label="[43]"><authors>E. Rosch</authors><title>Cognitive representations of semantic categories</title><host>J. Exp. Psychol. Gen.104 (3)(1975) pp.192-</host></reference><reference label="[44]"><authors>Steven Schockaert,Henri Prade</authors><title>Interpolative and extrapolative reasoning in propositional theories using qualitative knowledge about conceptual spaces</title><host>Artif. Intell.202 (0)(2013) pp.86-131</host></reference><reference label="[45]"><authors>Edward E. Smith,Edward J. Shoben,Lance J. Rips</authors><title>Structure and process in semantic memory: a featural model for semantic decisions</title><host>Psychol. Rev.81 (3)(1974) pp.214-</host></reference><reference label="[46]"><authors>E.E. Smith,D.N. Osherson</authors><title>Conceptual combination with prototype concepts</title><host>Cogn. Sci.8 (4)(1984) pp.337-361</host></reference><reference label="[47]"><authors>Amos Tversky,Daniel Kahneman</authors><title>Extensional versus intuitive reasoning: the conjunction fallacy in probability judgment</title><host>Psychol. Rev.90 (4)(1983) pp.293-</host></reference><reference label="[48]">Massimo Warglien, Peter Gärdenfors, Matthijs Westera, Event structure, conceptual spaces and the semantics of verbs, 2012.</reference><reference label="[49]"><authors>L.A. Zadeh</authors><title>Fuzzy sets</title><host>Inf. Control8 (3)(1965) pp.338-353</host></reference><reference label="[50]"><authors>L.A. Zadeh</authors><title>A fuzzy-set-theoretic interpretation of linguistic hedges</title><host>J. Cybern. (1972)</host></reference><reference label="[51]"><authors>L.A. Zadeh</authors><title>The concept of a linguistic variable and its application to approximate reasoning – I</title><host>Inf. Sci.8 (3)(1975) pp.199-249</host></reference></references><footnote><note-para label="1">In the current paper, we use the terms ‘attribute’ and ‘property’ interchangeably.</note-para><note-para label="2">In fact, it is sufficient that {a mathematical formula}d(x,y) be a pseudo distance.</note-para></footnote></root>