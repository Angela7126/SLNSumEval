<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:151">
</head>
<body bgcolor="white">
<a href="#0" id="0">We first introduce the notion of a constrained dataset, which implies a corresponding constrained log likelihood.</a>
<a href="#1" id="1">For each constrained variable, we randomly sampled a proportion of the hidden values under constraints; the proportions that we constrained were also varied, using separate curves.</a>
<a href="#2" id="2">“has genetic variant” (V), which can be true or false, “has diabetes” (D), which can be true or false, “has increased hunger” (H), which can be true or false, “has increased thirst” (T), which can be true or false.</a>
<a href="#3" id="3">In this way, a practitioner can “debug”, or otherwise have some refined mechanism to control, the topics that are learned by a topic model.</a>
<a href="#4" id="4">In some (restricted) cases, however, the resulting computations may still be exact, allowing us to evaluate the CLL exactly (as well as certain marginals).</a>
<a href="#5" id="5">As we just discussed, exact inference is in general intractable in the constrained meta-network, so we must appeal to approximate inference algorithms.</a>
</body>
</html>