<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:227">
</head>
<body bgcolor="white">
<a href="#0" id="0">Even when a POMDP is defined over only two world states, {a mathematical formula}s1 and {a mathematical formula}s2, the space of belief states is infinite, since a belief state can be an arbitrary combination of {a mathematical formula}b(s1)=p and {a mathematical formula}b(s2)=1−p where p can be any real number in {a mathematical formula}[0,1].</a>
<a href="#1" id="1">It is interesting to note that both processes managed to find the origin of the image.</a>
<a href="#2" id="2">As an alternative, direct expert estimation is less complex.</a>
<a href="#3" id="3">We see that while AgentHuntRL achieves a slightly higher accuracy than AgentHunt, the difference between their net utilities is not statistically significant ({a mathematical formula}p=0.4), which means AgentHuntRL is comparable to AgentHunt, suggesting that AgentHunt can perform in an “out of the box” mode, without needing a training phase.</a>
<a href="#4" id="4">Fig. 8 shows that using our model (learned from both the supervised and the unsupervised learning algorithms) consistently outperforms the majority-vote baseline.</a>
<a href="#5" id="5">To solve POMDPs, we run the ZMDP package{sup:8} for 300 s using the default Focused Real-Time Dynamic Programming search strategy [57].</a>
<a href="#6" id="6">Evaluation task: NER tagging</a>
<a href="#7" id="7">(Step 3) The agent creates a ballot job, and receives a vote that {a mathematical formula}α2 is better than {a mathematical formula}α1.</a>
<a href="#8" id="8">(2) How many ballots should be used for voting?</a>
<a href="#9" id="9">We reject ballot and scoring jobs if they are returned so quickly that the worker could not have made a reasonable judgment.</a>
</body>
</html>