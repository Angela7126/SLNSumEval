<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:213">
</head>
<body bgcolor="white">
<a href="#0" id="0">To complete the scenario successfully, the robot needed to place the pegs but they could only be placed when the separator was not in place, so it had to be removed first, which required that a new action was demonstrated.</a>
<a href="#1" id="1">A NID rule represents only one action.</a>
<a href="#2" id="2">TAMER [21] is a framework where the teacher provides reinforcement rewards that evaluate the performance of the robot, and the system exploits its current model by choosing the actions that are expected to be the most highly reinforced.</a>
<a href="#3" id="3">The improvements obtained by using subgoals in terms of reducing the number of demonstration requests (see Section 5.4).</a>
<a href="#4" id="4">Warning about missing effects.</a>
<a href="#5" id="5">We will suppose that excuses found point at the problems explained in the previous propositions.</a>
<a href="#6" id="6">The agent can employ two strategies to solve the task, as follows.</a>
<a href="#7" id="7">Although the actual number of experiences required to learn this domain is much lower (the rule only has four preconditions and the initial state also limits the number of incorrect experiences that can be performed), these theoretical numbers reflect the reduction in complexity obtained through demonstrations.</a>
<a href="#8" id="8">However, if no guidance is provided to the teacher, he may demonstrate an action that is already known by the system.</a>
<a href="#9" id="9">REX-D rules+sub: The REX-D algorithm with rule alternatives and subgoals (Section 5.4).</a>
</body>
</html>