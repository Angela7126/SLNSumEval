<html>
<head>
<meta name="TextLength" content="SENT_NUM:10, WORD_NUM:203">
</head>
<body bgcolor="white">
<a href="#0" id="0">Spark embeds an amodal (as defined by Mavridis and Roy in [55]: the different perceptual modalities are abstracted away into a blended spatial model) geometric model of the environment that serves both as basis for the fusion of the perception modalities and as bridge with the symbolic layer.</a>
<a href="#1" id="1">Sometimes the human wants to do more, or on the contrary, prefers to leave the robot do most of the work;</a>
<a href="#2" id="2">Explicit knowledge in our architecture.</a>
<a href="#3" id="3">In our model, we suggest that the interactions between components within this deliberative level have to be essentially bidirectional.</a>
<a href="#4" id="4">This effectively leads to independent declarative (the Oro knowledge base) and procedural (the planner) knowledge stores.</a>
<a href="#5" id="5">However, the main point for us was to refine and study in detail the internals of the deliberative layer.</a>
<a href="#6" id="6">We summarise them as the “W-questions”: What, Who, When, Where and How?</a>
<a href="#7" id="7">The goal is first received by the execution controller (after processing of the user request by the Dialogs module, not shown on the figure).</a>
<a href="#8" id="8">Ros et al. [17] provides a detailed account of our approach to interactive concept clarification and discrimination, along with the related algorithms.</a>
<a href="#9" id="9">For example, the subclasses of PartiallyTangibleThing (i.e. what we commonly call objects) are shown in Fig. 4.</a>
</body>
</html>