<html>
<head>
<meta name="TextLength" content="SENT_NUM:6, WORD_NUM:131">
</head>
<body bgcolor="white">
<a href="#0" id="0">The basic building block of many graphical models is the “Influence Diagram” (ID) [148], [147].</a>
<a href="#1" id="1">Carmel and Markovitch [64] show how such a model can be learned from observed actions.</a>
<a href="#2" id="2">The proposed method proceeds similarly to the original work by defining the plan inference based on dynamic Bayesian networks and using particle filtering to perform the inference.</a>
<a href="#3" id="3">Fig. 2).</a>
<a href="#4" id="4">Schadd et al. [236] propose domain-specific classifiers to predict the play style (e.g. “aggressive”, “defensive”) of players in the game Spring.</a>
<a href="#5" id="5">We assume that the modelling agent has some means to identify actions during the interaction, e.g. by using domain-specific heuristics as is often done in the robot soccer domain (e.g. [164]), training an action classifier using supervised machine learning (e.g. [184]), or reasoning about the probabilities of possible observations (e.g. [214]).</a>
</body>
</html>