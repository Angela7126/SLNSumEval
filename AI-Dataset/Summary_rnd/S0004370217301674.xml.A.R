<html>
<head>
<meta name="TextLength" content="SENT_NUM:9, WORD_NUM:168">
</head>
<body bgcolor="white">
<a href="#0" id="0">In such applications, RL suffers from the combinatorial explosion of complexity, which occurs when a Centralized RL (CRL) scheme is used [31].</a>
<a href="#1" id="1">RL algorithm and optimized parameters</a>
<a href="#2" id="2">For instance, the 3DMC example can be designed with those two individual rewards ({a mathematical formula}rx and {a mathematical formula}ry) defined as in Section 3.3, observing the full joint state space {a mathematical formula}[x,x˙,y,y˙].</a>
<a href="#3" id="3">ObsF and ObsL are Full Observability and Limited observability of the joint state space respectively.</a>
<a href="#4" id="4">Results and analysis</a>
<a href="#5" id="5">The Cooperative Adaptive Learning Rate DRL (DRL-CA) and the extended Lenient DRL (DRL-Lenient) algorithms add coordination mechanisms to the independent DRL scheme.</a>
<a href="#6" id="6">A basic description of this problem is given below, and it will be detailed in depth in Section 5.1.</a>
<a href="#7" id="7">So, total discrete actions are: {a mathematical formula}NT=NvlNaw=15 for the CRL scheme, and {a mathematical formula}NT=7+3 for the DRL-Ind.</a>
<a href="#8" id="8">As part of our ongoing research agenda, we plan to combine the benefits of both DRL-CAdec and DRL-CAinc, in order to develop a unique and improved cooperative adaptive method.</a>
</body>
</html>