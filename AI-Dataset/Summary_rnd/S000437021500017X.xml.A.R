<html>
<head>
<meta name="TextLength" content="SENT_NUM:16, WORD_NUM:271">
</head>
<body bgcolor="white">
<a href="#0" id="0">The problem is formalized as follows:</a>
<a href="#1" id="1">Finding such bottlenecks in visual input spaces is a relatively new concept, and one we exploit in the iCub experiments.</a>
<a href="#2" id="2">In each state {a mathematical formula}siint, the agent is allowed to take only one of the two actions ({a mathematical formula}Aint): stay or switch.</a>
<a href="#3" id="3">Fig. 9(a) shows the ROC cluster centers that map the feature outputs {a mathematical formula}(y) to each of the {a mathematical formula}10Ã—5 abstracted states.</a>
<a href="#4" id="4">Hierarchical extensions of IncSFA (H-IncSFA) over an expanded input in quadratic space [82] may remedy this.</a>
<a href="#5" id="5">Once the transition and reward functions are learned, a deterministic policy is learned via model-based Least-Squares Policy Iteration (LSPI; [53]).</a>
<a href="#6" id="6">From a set of input video streams, Curious Dr.</a>
<a href="#7" id="7">The simplest exploratory-option policy is a random walk.</a>
<a href="#8" id="8">We use a fixed parameter setting for the entire experiment.</a>
<a href="#9" id="9">As soon as the experimenter replaces the cup, the iCub repeats the pick and place behavior until the external reward is removed.</a>
<a href="#10" id="10">Since it doesn't get any reward in this case, the initialized values to the visited state-actions tuples vanish and it explores the neighboring state-action tuples.</a>
<a href="#11" id="11">Each target option learned is added to the target-option set {a mathematical formula}OL and the learning process iterates until all the learnable exploratory option streams are encoded.</a>
<a href="#12" id="12">An abstraction maps the high-dimensional input to a low-dimensional output.</a>
<a href="#13" id="13">3.</a>
<a href="#14" id="14">Constraint (2) requires a unique abstraction be learned that encodes at least one of the input observation streams, avoiding redundancy.</a>
<a href="#15" id="15">IncSFA has two learning update rules [46]: Candid-Covariance free Incremental Principal Component Analysis (CCIPCA; [80]) for normalizing the input and Minor Component Analysis (MCA; [81]) for extracting slow features.</a>
</body>
</html>